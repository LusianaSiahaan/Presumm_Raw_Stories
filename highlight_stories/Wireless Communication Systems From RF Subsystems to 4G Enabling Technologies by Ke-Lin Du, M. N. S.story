This page intentionally left blank      Wireless Communication Systems  This practically-oriented, all-inclusive guide covers all the major enabling techniques for current and next-generation cellular communications and wireless networking systems. Technologies covered include CDMA, OFDM, UWB, turbo and LDPC coding, smart antennas, wireless ad hoc and sensor networks, MIMO, and cognitive radios, providing readers with everything they need to master wireless systems design in a single volume.  Uniquely, a detailed introduction to the properties, design, and selection of RF sub- systems and antennas is provided, giving readers a clear overview of the whole wireless system. It is also the ﬁrst textbook to include a complete introduction to speech coders and video coders used in wireless systems.  Richly illustrated with over 400 ﬁgures, and with a unique emphasis on practical and state-of-the-art techniques in system design, rather than on the mathematical foundations, this book is ideal for graduate students and researchers in wireless communications, as well as for wireless and telecom engineers.  Ke-Lin Du is currently a researcher in the Center for Signal Processing and Communications at Concordia University, Canada. Prior to joining Concordia University in 2001, he held positions with Huawei Technologies, the China Academy of Telecommunication Technol- ogy, and the Chinese University of Hong Kong. He visited the Hong Kong University of Science and Technology in 2008. His current research interests include signal processing, wireless communications, RF systems, and neural networks. He is a Senior Member of the IEEE.  M. N. S. Swamy is currently a Director of the Center for Signal Processing and Communi- cations in the Department of Electrical and Computer Engineering, Concordia University, where he was Dean of the Faculty of Engineering and Computer Science from 1977 to 1993. He has published extensively in the areas of circuits, systems, and signal processing, co-authoring four books. Professor Swamy is a Fellow of the IEEE, IET  UK , and EIC  Canada , and has received many IEEE-CAS awards, including the Guillemin-Cauer award in 1986, as well as the Education Award and the Golden Jubilee Medal, both in 2000.      Wireless Communication  From RF Subsystems to 4G Enabling  Systems  Technologies  KE-LIN DU and M. N. S. SWAMY  Concordia University, Canada      C A M B R I D G E U N I V E R S I T Y P R E S S  Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore,  São Paulo, Delhi, Dubai, Tokyo  Cambridge University Press  The Edinburgh Building, Cambridge CB2 8RU, UK  Published in the United States of America by Cambridge University Press, New York  Information on this title: www.cambridge.org 9780521114035  www.cambridge.org  c cid:2  Cambridge University Press 2010  This publication is in copyright. Subject to statutory exception and to the provisions of relevant collective licensing agreements, no reproduction of any part may take place without the written  permission of Cambridge University Press.  First published 2010  Printed in the United Kingdom at the University Press, Cambridge  A catalog record for this publication is available from the British Library  Library of Congress cataloging in Publication data  Du, K.-L.  p.  cm.  Wireless communication systems   Ke-Lin Du and M. N. S. Swamy.  Includes bibliographical references and index.  ISBN 978-0-521-11403-5  1. Wireless communication systems.  I. Swamy, M. N. S.  II. Title.  TK5103.2.D825  2010  621.382–dc22 2009051702  ISBN 978-0-521-11403-5 Hardback  Additional resources for this publication at www.cambridge.org 9780521114035  Cambridge University Press has no responsibility for the persistence or accuracy of URLs for external or third-party internet websites referred to  in this publication, and does not guarantee that any content on such  websites is, or will remain, accurate or appropriate.      To My Son Cynric  K.-L. Du  and  To My Parents M. N. S. Swamy          Contents  Preface Abbreviations  Introduction 1.1 1.2 1.3 1.4  1.5  1  2  The wireless age Spectrum of electromagnetic waves Block diagram of a communication system Architecture of radio transceivers 1.4.1 1.4.2 Organization of the book References  Super-heterodyne transceivers Direct-conversion transceivers  2.2  Circuit packet switching  First-generation systems Second-generation systems Third-generation systems Fourth-generation systems Satellite communications  An overview of wireless communications 2.1 Roadmap of cellular communications 2.1.1 2.1.2 2.1.3 2.1.4 2.1.5 Mobile cellular networks 2.2.1 Roadmap for wireless networking 2.3.1 2.3.2 2.3.3 2.3.4 2.3.5 Other applications 2.4.1 2.4.2 2.4.3  Paging systems Digital broadcasting systems RF identiﬁcation  Wireless local-area networks Wireless personal-area networks Wireless metropolitan-area networks Wireless regional-area networks Ad hoc wireless networks  2.3  2.4  page xxiii xxvi  1 1 2 3 3 4 5 7 10  11 11 11 12 14 18 20 21 22 24 25 26 28 29 30 32 32 33 33      viii   cid:2   Contents  2.5  Open systems interconnect  OSI  reference model Problems References  3  Channel and propagation 3.1  Free-space loss Plane earth loss model Okumura-Hata model COST-231-Hata model Other empirical models COST-231-Walﬁsch-Ikegami model Indoor propagation models Channel models in wireless standards  Log-normal shadowing Rayleigh fading Two-path model of Rayleigh fading Random frequency modulation Ricean fading Other fading models Outage probability  Doppler spectrum Level crossing rates Average duration of fades  Propagation loss 3.1.1 3.1.2 3.1.3 3.1.4 3.1.5 3.1.6 3.1.7 3.1.8 Channel fading 3.2.1 3.2.2 3.2.3 3.2.4 3.2.5 3.2.6 3.2.7 Doppler fading 3.3.1 3.3.2 3.3.3 WSSUS model 3.4.1 3.4.2 3.4.3 3.4.4 3.4.5 Propagation mechanisms 3.5.1 3.5.2 3.5.3 Atmospheric effects 3.6.1 3.6.2 Channel sounding Problems References  Reﬂection and refraction Scattering Diffraction  Tropospheric effects Ionospheric effects  Delay spread Correlation coefﬁcient Channel coherent bandwidth Doppler spread and channel coherent time Angle spread and coherent distance  3.2  3.3  3.4  3.5  3.6  3.7  34 37 38  39 39 39 39 41 42 43 43 45 46 48 48 50 53 55 56 58 58 60 60 63 64 65 67 68 69 70 71 73 73 75 76 78 79 80 82 84 86      ix   cid:2   Contents  4  Cellular and multiple-user systems 4.1  Cell planning Increasing capacity of cellular networks Interference in multiuser systems Power control Channel assignment Handoff  Duplexing: FDD versus TDD FDMA TDMA CDMA OFDMA SDMA  The cellular concept 4.1.1 4.1.2 4.1.3 4.1.4 4.1.5 4.1.6 Multiple access techniques 4.2.1 4.2.2 4.2.3 4.2.4 4.2.5 4.2.6 Random multiple access 4.3.1 4.3.2 4.3.3 Erlang capacity in uplink 4.4.1 4.4.2 Protocol design for wireless networks 4.5.1 4.5.2 Quality of service User location Problems References  ALOHA Carrier-sense multiple access Scheduling access  Layered protocol design Cross-layer design  Erlang B equation Erlang C equation  5  Diversity 5.1 5.2  Selection diversity Maximum ratio combining Equal gain combining Switch diversity Optimum combining  Diversity methods Combining multiple signals 5.2.1 5.2.2 5.2.3 5.2.4 5.2.5 Transmit diversity 5.3.1 5.3.2 Multiuser diversity 5.4.1 5.4.2  Open-loop transmit diversity Closed-loop transmit diversity  Pdf and cdf Multiuser diversity versus classical diversity  4.2  4.3  4.4  4.5  4.6 4.7  5.3  5.4  92 92 93 95 96 98 98 99 101 102 104 104 105 106 106 108 108 109 113 114 114 115 117 117 120 121 123 126 128  130 130 133 134 137 143 145 145 148 149 150 150 151 152      x   cid:2   Contents  Problems References  6  Channel estimation and equalization 6.1  6.2  6.3  Adaptive channel estimation Blind channel estimation  Optimum sequence detection Linear equalizers Decision-feedback equalizers MLSE equalizer Viterbi algorithm Frequency-domain equalizers Blind equalizers Precoding  Channel estimation 6.1.1 6.1.2 Channel equalization 6.2.1 6.2.2 6.2.3 6.2.4 6.2.5 6.2.6 6.2.7 6.2.8 Pulse shaping 6.3.1 6.3.2 Problems References  Raised-cosine ﬁltering Root-raised-cosine ﬁltering  Amplitude modulation Phase modulation and frequency modulation  Signal space diagram Demodulation and detection Error probability in the Gaussian channel  7.1  7.3  7.2  7 Modulation and detection Analog modulation 7.1.1 7.1.2 Introduction to digital modulation 7.2.1 7.2.2 7.2.3 Baseband modulation Line codes 7.3.1 7.3.2 Pulse time modulation Pulse amplitude modulation Phase shift keying 7.5.1 7.5.2 7.5.3 Frequency shift keying 7.6.1 7.6.2 7.6.3 7.6.4 7.6.5  7.4 7.5  7.6  Binary phase shift keying M-ary phase shift keying Quaternary phase shift keying  Binary frequency shift keying M-ary frequency shift keying Minimum shift keying Gaussian minimum shift keying Continuous phase modulation  153 154  158 158 159 160 160 161 162 166 167 168 170 171 172 172 173 175 176 177  180 180 180 182 183 184 185 186 188 188 190 191 195 195 197 202 207 207 211 213 215 217      xi   cid:2   Contents  7.7 7.8 7.9 7.10  7.11 7.12  7.13 7.14  Carrier synchronization Symbol timing recovery  Quadrature amplitude modulation Bandwidth efﬁciencies of M-ary modulation Matched ﬁltering Synchronization 7.10.1 7.10.2 Differential modulation Error probability in fading channels Flat Rayleigh fading channel 7.12.1 Flat Ricean fading channel 7.12.2 Alternative form of the Q-function 7.12.3 7.12.4 Error probability using moment-generating functions Error probabilities due to delay spread and frequency dispersion Error probability in fading channels with diversity reception Problems References  8  Spread spectrum communications 8.1 8.2  Introduction Spreading sequences Properties of spreading sequences 8.2.1 Pseudo-noise sequences 8.2.2 Gold sequences 8.2.3 Kasami sequences 8.2.4 Walsh sequences 8.2.5 Orthogonal variable spreading factor sequences 8.2.6 Barker sequences 8.2.7 8.2.8 Complementary codes Direct-sequence spread spectrum 8.3.1 8.3.2 8.3.3 8.3.4 8.3.5 8.3.6 Multiuser detection 8.4.1 8.4.2 8.4.3 8.4.4 8.4.5 Bit error probability and system capacity 8.5.1 8.5.2  Introduction Optimum multiuser detector Linear multiuser detection Serial parallel interference cancellation Combination of linear MUD and nonlinear SIC  DS-CDMA model Conventional receiver Rake receiver Synchronization in CDMA Power control Soft handoff  BER performance Uplink capacity  8.3  8.4  8.5  218 224 225 226 227 228 231 231 232 235 236 237 238 239 241 243  246 246 248 248 249 252 252 253 254 255 255 256 257 259 260 263 263 264 265 265 267 268 269 271 272 272 274      xii   cid:2   Contents  9  8.6 8.7 8.8  Other DSSS techniques DSSS and DS-CDMA in wireless standards Frequency-hopping spread spectrum 8.8.1 8.8.2 Problems References  Error performance of FHSS FHSS versus DSSS  Pilot arrangement for channel estimation Pilot-assisted channel estimation  9.8  Orthogonal frequency division multiplexing 9.1 9.2 9.3 9.4 9.5 9.6 9.7  Introduction Principle of OFDM OFDM transceivers Cyclic preﬁx Spectrum of OFDM Fading mitigation in OFDM Channel estimation 9.7.1 9.7.2 Peak-to-average power ratio 9.8.1 9.8.2 9.8.3 Intercarrier interference Synchronization 9.10.1 9.10.2 9.10.3 9.10.4 OFDM-based multiple access Performance of OFDM systems  9.11 9.12 9.13 Multi-carrier CDMA 9.14  9.9 9.10  Inﬂuence of frequency offset Phase noise effects on OFDM Inﬂuence of timing offset Implementation of synchronization  Peak factor: deﬁnition and impact Peak factor reduction techniques Amplitude clipping or companding  Other OFDM-associated schemes Problems References  10 Antennas  10.1 Maxwell’s equations 10.2  Method of moments Finite difference time-domain method Finite element method  Introduction to computational electromagnetics 10.2.1 10.2.2 10.2.3 Antenna fundamentals 10.3.1 10.3.2  Radiation patterns Antenna ﬁeld zones  10.3  276 277 280 282 283 284 285  290 290 291 293 294 297 300 301 302 303 305 305 306 308 312 314 314 317 318 318 322 324 326 329 330 331  337 337 338 339 339 340 341 342 343      xiii   cid:2   Contents  10.4  10.5  10.6  10.7 10.8  11.1  11.2  11.3  10.3.3 10.3.4 10.3.5 10.3.6 10.3.7  Antenna gain and directivity Effective area and effective height Antenna temperature Polarization Receiving and transmitting power efﬁciency  Antennas for base stations Antennas for mobile stations  Wire dipole antennas Baluns Wire monopoles  Antennas for wireless communications 10.4.1 10.4.2 Dipole antennas 10.5.1 10.5.2 10.5.3 Patch antennas 10.6.1 10.6.2 Polarization-agile antennas Antenna arrays 10.8.1 10.8.2  Microstrip antennas Broadband microstrip antennas  Array factor Mutual coupling and spatial correlation  10.9 Wideband antennas  10.9.1 10.9.2 Problems References  Implementation of wideband antennas Ultra wideband antennas  11 RF and microwave subsystems  Receiver performance requirements Architecture of RF subsystems  Introduction 11.1.1 11.1.2 RF system analysis 11.2.1 11.2.2 11.2.3 Transmission lines 11.3.1 11.3.2  Noise Noise ﬁgure Link budget analysis  Fundamental theory Types of transmission line  11.4 Microwave network analysis 11.5  Impedance matching 11.5.1 11.5.2 11.5.3  Stub tuners Quarter-wave transformer Multisection matching transformers  11.6 Microwave resonators  11.6.1  RLC resonant circuits  344 345 346 346  347 349 349 350 351 353 355 356 356 357 358 359 360 361 362 364 364 366 367 369  373 373 373 374 375 376 378 379 380 380 384 385 388 388 389 389 390 390      xiv   cid:2   Contents  11.7  11.8  Three-port networks Four-port networks  Transmission line resonators Waveguide cavities  11.6.2 11.6.3 Power dividers and directional couplers 11.7.1 11.7.2 RF microwave ﬁlters 11.8.1 11.8.2 11.8.3 11.8.4 11.8.5 11.8.6  Insertion loss method Prototyping Stub ﬁlters Stepped-impedance lowpass ﬁlters Coupled line bandpass ﬁlters Computer-aided design for RF microwave ﬁlter design Filters for wireless communications  11.8.7 Phase shifters  11.9 11.10 Basic concepts in active RF circuits 11.11 Modeling of RF components  11.11.1 11.11.2  Diodes Transistors  11.12 Switches 11.13 Attenuators 11.14 Mixers 11.14.1 11.14.2  11.15 Ampliﬁers  Operation of mixers Types of mixers  Requirements in wireless systems Structure of ampliﬁers Classiﬁcation of ampliﬁers Linearization techniques  11.15.1 11.15.2 11.15.3 11.15.4 11.15.5 Microwave transistors for ampliﬁers 11.15.6 11.15.7  Stability Transistor ampliﬁer design  11.16 Oscillators  11.17 Frequency synthesis  11.16.1 11.16.2 11.16.3  11.17.1 11.17.2 11.17.3  Analysis methods Phase noise Classiﬁcation of RF oscillators  Composition of phase-locked loops Dynamics of phase-locked loops Direct frequency synthesis  11.18 Automatic gain control 11.19 MICs and MMICs  11.19.1 Major MMIC technologies 11.19.2 Approach to MMIC design  391 393 393 393 395 397 397 400 401 402 403  405 406 408 410 414 414 417 422 424 425 425 427 428 428 429 430 433 435 436 436 437 437 439 440 443 443 446 448 449 451 451 452      xv   cid:2   Contents  Passive lumped components RF CMOS Impedance matching  11.19.3 11.19.4 11.19.5 Problems References  12 A D and D A conversions  12.1 12.2  12.3  12.4 12.5  12.6  12.7 12.8  13.1  13.2  13.3  Uniform quantization Improving resolution by oversampling  Ideal and natural sampling Sampling theorem Aliasing and antialiasing Oversampling and decimation Bandpass sampling theorem  Introduction Sampling 12.2.1 12.2.2 12.2.3 12.2.4 12.2.5 Quantization 12.3.1 12.3.2 Analog reconstruction Parameters for A D and D A converters 12.5.1 12.5.2 A D converter circuits 12.6.1 12.6.2 12.6.3 D A converter circuits A D and D A converters for software-deﬁned radios Problems References  SNR of A D and D A converters SFDR and dithering  Flash A D converters Successive-approximation register A D converters Sigma-delta A D converters  13 Signals and signal processing  Fourier transform Laplace transform z-transform  Basic transforms 13.1.1 13.1.2 13.1.3 Discrete-time Fourier transform 13.2.1 13.2.2 13.2.3 Digital ﬁlters 13.3.1 13.3.2 13.3.3  FIR and IIR ﬁlters Stability Inverse ﬁlters  Windowing DFT FFT  453 455 456 457 461  464 464 464 464 466 466 468 468 470 470 472 473 475 476 477 479 480 480 481 484 485 486 487  489 489 489 490 491 494 495 498 499 501 501 502 503      xvi   cid:2   Contents  13.4  13.5  13.6  13.7  13.3.4  Minimum-, maximum-, and mixed-phase systems Notch and comb ﬁlters  Wiener solution LMS algorithm RLS algorithm  FIR digital ﬁlter design IIR ﬁlter design Hardware implementation of digital ﬁlters  13.3.5 Digital ﬁlter design 13.4.1 13.4.2 13.4.3 Adaptive ﬁlters 13.5.1 13.5.2 13.5.3 Digital up-conversion and digital down-conversion 13.6.1 13.6.2 Sampling-rate conversion 13.7.1 13.7.2 13.7.3 13.7.4 Discrete cosine transform  Interpolation Decimation Sample rate converters Cascaded integrator comb  CIC  ﬁlters  Numerically controlled oscillators Direct digital frequency synthesis  13.8 13.9 Wavelet transform  13.9.1 13.9.2  Discrete wavelet transform Multiresolution analysis  13.10 Filter banks 13.11 Sub-band coding  Two-channel perfect reconstruction ﬁlter banks 13.11.1 13.11.2 Pseudo-QMF ﬁlter bank 13.11.3 Modiﬁed DCT  MDCT  Problems References  14 Fundamentals of information theory  14.1 14.2  14.3 14.4  Basic deﬁnitions Lossless data compression 14.2.1 14.2.2 14.2.3 14.2.4 14.2.5 Rate-distortion theorem Channel capacity 14.4.1  Source coding theorem Huffman coding Exponential-Golomb variable-length codes Arithmetic coding Dictionary-based coding  Capacity of the AWGN channel for Gaussian distributed input  504 505 507 508 511 513 513 514 515 515 516 517 518 520 521 524 525 525 527 530 532 533 535 538 539 541 542 543 545  550 550 555 556 557 559 560 563 565 567  568      xvii   cid:2   Contents  14.4.2  Capacity of the AWGN channel for discrete input alphabets Area spectral efﬁciency  Capacity with CSI at receiver only Capacity with CSI at transmitter and receiver Capacity of frequency-selective fading channels  14.4.3 Source-channel coding theorem Capacity of fading channels 14.6.1 14.6.2 14.6.3 Channel capacity for multiuser communications 14.7.1 14.7.2 Estimation theory Problems References  AWGN channel Flat-fading channels  15 Channel coding  14.5 14.6  14.7  14.8  15.1 15.2  15.3 15.4  15.5 15.6  15.7 15.8  15.9  Encoder and decoder Types of cyclic codes  Error detection correction Simple parity check and Hamming codes Syndrome decoding  Preliminaries Linear block codes 15.2.1 15.2.2 15.2.3 Hard soft decision decoding Cyclic codes 15.4.1 15.4.2 Interleaving Convolutional codes 15.6.1 15.6.2 15.6.3 15.6.4 15.6.5 15.6.6 15.6.7 15.6.8 Conventional concatenated codes Turbo codes 15.8.1 15.8.2 15.8.3 15.8.4 Serially concatenated convolutional codes 15.9.1 15.9.2  Turbo encoder Turbo decoder MAP algorithm Analysis of the turbo code  Encoding of convolutional codes Encoder state and trellis diagrams Sequence decoders Trellis representation of block codes Coding gain and error probability Convolutional coding with interleaving Punctured convolutional codes Trellis-coded modulation  Design of the SCCC Decoding of the SCCC  571 574 575 576 577 579 581 582 582 585 585 586 589  591 591 592 593 595 596 597 600 600 603 606 607 608 611 613 616 618 619 620 621 622 625 625 627 630 635 639 640 640      xviii   cid:2   Contents  15.10 Low-density parity-check codes  15.10.1 15.10.2  LDPC code: a linear block code LDPC encoder and decoder  15.11 Adaptive modulation and coding 15.12 ARQ and hybrid-ARQ  Problems References  16 Source coding I: speech and audio coding  16.1  16.2  16.3  16.4  16.5  16.6  Coding for analog sources  Speech production Psychoacoustics  Scalar quantization Vector quantization  Subjective quality measures Objective quality measures  Introduction 16.1.1 Quantization 16.2.1 16.2.2 Speech production and auditory systems 16.3.1 16.3.2 Speech audio quality 16.4.1 16.4.2 Speech coding 16.5.1 16.5.2 16.5.3 16.5.4 16.5.5 16.5.6 16.5.7 16.5.8 16.5.9 16.5.10 Wideband speech coding Audio coding 16.6.1 16.6.2 Problems References  Logarithmic PCM coding Linear prediction analysis and synthesis Predictive coding Frequency-domain waveform coding Voice activity detection Linear predictive coding Pitch period estimation Analysis by synthesis CELP-based codecs  MPEG-1 and MPEG-2 Audio MPEG-4 Audio  17 Source coding II: image and video coding  17.1 17.2  17.3 17.4  Introduction Perception of human vision 17.2.1 17.2.2 Quality of image and video coding Predictive coding  Human visual system Color spaces  641 641 644 646 649 652 654  659 659 659 661 661 662 663 663 665 668 668 670 672 673 674 680 683 683 684 686 688 691 696 697 699 701 703 705  707 707 709 709 710 712 713      xix   cid:2   Contents  17.5 17.6  Transform-based image compression JPEG standard 17.6.1 17.6.2 17.6.3  Four modes of operation Quantization Coding  17.7 Wavelet-transform-based image coding  17.7.1 17.7.2 17.7.3  Sub-band decomposition Wavelet ﬁlter design Coding of wavelet subimages  17.8 Wavelet-based image coding standards  17.9  JPEG2000 standard MPEG-4 still image mode  17.8.1 17.8.2 Comparison of image coding standards 17.9.1 17.9.2  Comparison of six popular standards DjVu and adaptive binary optimization  ABO   17.10 Video data compression Frame format Frame types  17.10.1 17.10.2 17.10.3 Motion compensation 17.10.4 17.10.5 17.10.6 17.10.7 17.10.8 17.10.9 17.10.10 Rate control Introduction to video standards Problems References  Basic structure of video Video encoder decoder Scalability Integer DCT transform Shape coding Object-based coding and sprite coding  17.11  18.1  18.2  18.3  18.4  18 Multiple antennas: smart antenna systems  The concept of smart antennas Smart antennas in mobile communications  Pseudospectrums MUSIC  Introduction 18.1.1 18.1.2 Direction-ﬁnding 18.2.1 18.2.2 Beamforming 18.3.1 18.3.2 18.3.3 Adaptive beamforming 18.4.1  Blind source separation ZF, MRC, and Wiener beamformers Switched-beam antennas  DoA-based beamforming  715 716 716 718 720 721 721 722 724 729 729 730 731 731  733 733 734 734 735 739 740 742 743 744 745 746 747 752 754  757 757 757 758 759 760 761 763 764 764 765 767 767      xx   cid:2   Contents  18.5  Training-based beamforming 18.4.2 18.4.3 Blind beamforming Cyclostationary beamforming 18.5.1 18.5.2 18.5.3  Preliminaries on cyclostationarity Summary of some algorithms ACS algorithm  18.6 Wideband beamforming  Tapped-delay-line structure Pure delay-line wideband transmitter beamformer  18.6.1 18.6.2 Problems References  19 Multiple antennas: MIMO systems  Introduction  19.1 19.2 MIMO system  19.2.1 19.2.2  MIMO system model Spatial correlation and MIMO channel model MIMO decoding MIMO channel decomposition Channel estimation CSI or partial CSI at the transmitter  19.2.3 19.2.4 19.2.5 19.2.6 Capacity in i.i.d. slow fading channels 19.3.1 19.3.2 19.3.3  No CSI at the transmitter CSI known at the transmitter Channel capacities for transmitter with versus without CSI  Outage and ergodic capacities Capacity bounds Ricean channels  Performance analysis of space-time codes Orthogonal space-time block codes Space-time trellis codes Differential space-time coding  Capacity in i.i.d. fast fading channels 19.4.1 19.4.2 19.4.3 Space-time coding 19.5.1 19.5.2 19.5.3 19.5.4 Spatial multiplexing 19.6.1 19.6.2 19.6.3 19.6.4 19.6.5 Diversity, beamforming, versus spatial multiplexing 19.7.1  Layered space-time receiver structures Space-time receivers Spatial precoding Other closed-loop MIMO schemes Beamspace MIMO  19.3  19.4  19.5  19.6  19.7  Diversity, beamforming, and spatial multiplexing gains  770 774 776 776 778 780 782 782 783 785 785  788 788 788 788  789 791 791 792 794 795 797 798  800 801 801 807 808 809 810 813 817 819 819 820 822 826 828 829 830 830      xxi   cid:2   Contents  19.7.2 19.7.3  Error probabilities for MIMO systems MIMO beamforming  19.8 MIMO for frequency- or time-selective fading channels  MIMO-SC MIMO-OFDM MIMO for time-selective channels  19.8.1 19.8.2 19.8.3 Space-time processing 19.9.1 19.9.2  Linear space-time processing model ZF and MMSE receivers  19.9  19.10 Space-time processing for CDMA systems  19.10.1 19.10.2 19.10.3  Signal model Space-time detection algorithms Adaptive implementation of ST-MUD  19.11 MIMO in wireless standards  20 Ultra wideband communications  20.1 20.2 20.3 20.4  Problems References  Introduction UWB indoor channel UWB capacity Pulsed UWB 20.4.1 20.4.2 20.4.3 20.4.4 20.4.5 20.4.6 20.4.7  20.5 Multiband UWB  20.5.1 20.5.2 Problems References  21 Cognitive radios  Pulse shape Modulation and multiple access for pulsed UWB Time-hopping and direct-sequence UWB signals Pulsed-UWB transceivers Challenges for pulsed UWB systems Rake receivers Transmitted-reference receivers  Modulation of pulsed multiband UWB MB-OFDM UWB  21.1 21.2 21.3  21.4  Conception of software-deﬁned radio Hardware software architecture of software-deﬁned radio Conception of cognitive radio 21.3.1 21.3.2 Spectrum sensing 21.4.1 21.4.2  Secondary user-based local spectrum sensing Cooperative spectrum sensing  Topics in cognitive radio Cognitive radio in wireless standards  832 835 836 837 838 841 841 842 842 844 844 846 850 855 857 859  870 870 873 876 877 877 879 881 883 885 886 887 890 891 891 893 894  898 898 899 901 902 904 905 905 908      xxii   cid:2   Contents  Spectrum-cyclic-analysis-based spectrum sensing Cyclostationary beamforming-based spectrum sensing  Spectrum sensing using cyclostationary property 21.5.1 21.5.2 Dynamic spectrum access 21.6.1 21.6.2 21.6.3 21.6.4 Problems References  Water-ﬁlling for dynamic spectrum access Basic game theory Four persona models Game-theoretic models for dynamic resources allocation  21.5  21.6  22.1  22.2 22.3  22.4 22.5 22.6  22.7  22 Wireless ad hoc and sensor networks  Wireless sensor networks  Security problems Encryption  Introduction 22.1.1 Routing Security 22.3.1 22.3.2 Technical overview for wireless ad hoc networks Technical overview for wireless sensor networks Data aggregation and routing for WSNs 22.6.1 22.6.2 Relay, user cooperation, and MIMO relay networks 22.7.1 22.7.2 22.7.3 Problems References  Relay User cooperation MIMO relay networks  Data aggregation Routing  Appendix A The Q-function  Reference  Appendix B Wirtinger calculus  Reference  Index  910 910 911 915 915 921 924 925 928 929  932 932 932 935 936 936 938 940 943 948 948 949 951 952 954 956 959 960  965 966  967 969  970      Preface  In the last three decades, the explosive growth of mobile and wireless communica- tions has radically changed the life of people. Wireless services have migrated from the conventional voice-centric services to data-centric services. The circuit-switched commu- nication network is now being replaced by the all-IP packet-switched network. Mobile communications have also evolved from the ﬁrst-generation  1G  analog systems to the third-generation  3G  systems now being deployed, and the fourth-generation  4G  sys- tems are now under development and are expected to be available by 2010. The evolution of wireless networking has also taken place rapidly during this period, from low-speed wireless local-area networks  LANs  to broadband wireless LANs, wireless metropolitan- area networks  MANs , wireless wide-area networks  WANs , and wireless personal-area networks  PANs . Also, broadband wireless data service has been expanded into broad- casting service, leading to satellite TV broadcasting and wireless regional-area networks  RANs  for digital TV. The data rate has also evolved from the 10 kbits s voice communi- cations to approximately 1 Gbit s in the 4G wireless network. In addition, the 4G wireless network will provide ubiquitous communications.  Scope and Purpose  A complete wireless system involves many different areas. However, most existing text- books on wireless communications focus only on the fundamental principles of wireless communications, while many other areas associated with a whole wireless system, such as digital signal processing, antenna design, microwave and radio frequency  RF  subsystem design, speech coding, video coding, and channel coding, are left to other books.  This book provides a broad, also in certain depth, technical view of wireless communica- tions, covering various aspects of radio systems. Various enabling technologies for modern wireless communications are also included. Unlike the existing books in the ﬁeld, this book is organized from a wireless system designer’s viewpoint. We give wide coverage to the techniques that are most relevant to the design of wireless communication and networking systems. We focus ourselves on the lower layers of wireless systems, since the upper lay- ers such as network layers and transport layers are topics of general data communication systems. Due to limited space, we do not provide lengthy mathematical details, but rather emphasize the practical aspects.  The book is divided into twenty-two chapters, including introduction, overwiew of wire- less communications and networking, wireless channel and radio propagation, cellular systems and multiple access, diversity, channel equalization, modulation and detection, spread-spectrum communications, orthogonal frequency division multiplexing  OFDM ,      xxiv   cid:2   Preface  antennas, RF and microwave subsystems, A D and D A conversions, digital signal processing, information theory, ultra wideband  UWB  communications, speech audio coding, image video coding, channel coding, smart antennas, multiple input multiple out- put  MIMO  systems, cognitive radios, and wireless ad hoc sensor networks. Each chapter contains some examples and problems.  Intended Audience  This book is primarily intended as a textbook for advanced undergraduate and graduate stu- dents specializing in wireless communications and telecommunication systems. It is also a good reference book for practicing engineers. The reader is supposed to have a background in electrical engineering and to be familiar with the theory of signals and systems, probabil- ities and stochastic processes, basic circuits, basic digital communications, linear algebra, and advanced calculus. These courses are offered in most electrical engineering under- graduate programs. The contents are useful for mobile cellular communications, satellite communication, and wireless networking.  The material in this book can be taught in two semesters. The ﬁrst semester may cover Chapters 1 to 13, which deal with the principles of wireless communications, and the ana- log and digital designs. The second semester could cover the remaining chapters, including information theory and coding, and some advanced and emerging technologies. If only one semester is available for this course, we suggest teaching Chapters 1 to 13, 15, and selected sections from Chapters 18 to 22. Since each chapter is rather comprehensive on the topics treated and is relatively self-contained, the reader can select to read only those chapters that are of interest. MATLAB codes for the examples in the book are downloadable from the book website.  Acknowledgments  First of all, we would like to thank the anonymous reviewers, whose comments have enriched this book. Our appreciation is extended to Ayhan Altintas of Bilkent University  Turkey  for commenting on Chapters 3 and 10, Chunjiang Duanmu of Zhejiang Normal University  China  for reviewing Chapter 17, and Wai Ho Mow of Hong Kong Univer- sity of Science and Technology  China  for his valuable comments on Chapter 21. The authors would like to express their special thanks to Ezio Biglieri and Giorgio Taricco from Politecnico di Torino  Italy  for helpful discussion.  K.-L. Du would like to express his gratitude to Wei Wu of Concordia University  Canada , Doru Florin Chiper of Technical University “Gh. Asachi” Iasi  Romania , Jie Zeng of Meidian Technologies  China , Yi Shen of Huazhong University of Science and Technology  China , Hong Bao and Jiabin Lu of Guangdong University of Technology  China , Qiang Ni of Brunel University  UK , Yin Yang and Daniel Gaoyang Dai from Hong Kong University of Science and Technology  China , Xiangming Li of Beijing Institute of Technology  China , Qingling Zhang of ZTE Corporation  China , Yi Zhang of Huawei Technologies  China , and Andrew Chi-Sing Leung from City University of Hong Kong  China  for their personal help during the period of preparing this book.      xxv   cid:2   Preface  M. N. S. Swamy also wishes to thank his family for their support during the period of preparing this book.  We feel extremely fortunate to have worked with Cambridge University Press. We express our utmost appreciation to Philip Meyler, Publishing Director, Engineering, Math- ematical and Physical Sciences, at Cambridge University Press, for his guidance. The encouragement and support provided by Philip Meyler has made the process of writing this book very joyful. Finally, special thanks go to the staff from Cambridge University Press: Sabine Koch, Sarah Matthews, Caroline Brown, Anna Marie Lovett, Richard Marston, and Sehar Tahir, without whose help the production of the book would have been impossible.  Feedback  A book of this length is certain to have some errors and omissions. While we have made signiﬁcant attempts to a comprehensive description of major techniques related to modern wireless communications, there are many new emerging techniques, some of which may not have been included. Feedback is welcome via email at kldu@ieee.org or swamy@ece.concordia.ca, and we promise to reply to all the messages.  Concordia University Montreal, Canada      Abbreviations  1xEV-DO  1xEV-DV nG 3DES 3GPP  3GPP2  4GFSK AAC ACAB ACELP  ACF ACI ACLR  ACPR ACS ACTS  A D ADC ADPCM AES  AF AFC AGC AM AMC  AMI AMPS  1x Evolution, Data Optimized 1x Evolution, Data and Voice nth generation Triple DES Third-Generation Partnership Project Third-Generation Partnership Project 2 quaternary GFSK Advanced Audio Coding adaptive CAB algebraic codebook excited linear prediction autocorrelation function adjacent channel interference adjacent channel leakage ratio adjacent channel power ratio adaptive cross-SCORE Advanced Communication Technology Satellite analog-to-digital A D converter adaptive differential PCM Advanced Encryption Standard amplify-and-forward automatic frequency control automatic gain control amplitude modulation adaptive modulation and coding alternative mark inversion Advanced Mobile Phone Services  AMR AMR-WB  ANSI  APS ARQ ASIC  ASK AVC AWGN  balun  BAN BCH  BCJR BER BER BFSK BICM  BJT BLAST  BPSK BRAN  adaptive multi-rate adaptive multi-rate wideband American National Standards Institute adaptive phase-SCORE automatic repeat request application-speciﬁc integrated circuit amplitude shift keying Advanced Video Coding additive white Guaasian noise balanced-to-unbalanced transformer body area network Bose-Chaudhuri- Hocquenghem Bahl-Cocke-Jelinek-Raviv bit error probability bit error rate binary FSK bit-interleaved coded modulation bipolar junction transistor Bell Labs Layered Space-Time binary phase shift keying Broadband Radio Access Network base station binary symmetric channel  BS BSC BS-CDMA block-spreading CDMA CAB CABAC  cyclic adaptive beamforming context-based adaptive binary arithmetic coding      xxvii   cid:2   List of Abbreviations  CAVLC  CCF CCI CCK CCSDS  cdf  CDMA CDPD CELP  CF CFO CIC CIF CIR CLS CNR CORBA  CORDIC  context-based adaptive variable-length code cross-correlation function co-channel interference complementary code keying Consultative Committee for Space Data Systems cumulative distribution function code division multiple access Cellular Digital Packet Data code-excited linear prediction compress-and-forward carrier frequency offset cascaded integrator comb common intermediate format carrier-to-interference ratio constrained least-squares carrier-to-noise ratio common object request broker architecture Coordinate Rotation Digital Computer  CP-CDMA cyclic preﬁx assisted CDMA CPFSK CPM CQF CRC CRLB CRSC  continuous phase FSK continuous phase modulation conjugate quadrature ﬁlters cyclic redundancy check Cramer-Rao lower bound circular recursive systematic convolutional  CS-ACELP Conjugate Structure ACELP CSI CSMA CSMA CA CSMA with collision  channel state information carrier sense multiple access  avoidance  CSMA CD CSMA with collision  CT2  CVSDM  D A  detection Second Generation Cordless Telephone continuous variable slope DM digital-to-analog  DAB DAC D-BLAST DBPSK DCT DDCR  DDS DEBPSK  DECT  DEMPSK  DEQPSK  DES DF DFE  DFT DiffServ DM DMB  DMPSK DNL DoA DoD  DPCM DPSK  DQPSK  Digital Audio Broadcasting D A converter diagonal BLAST differential BPSK discrete cosine transform decision-directed carrier recovery direct digital synthesis differentially encoded BPSK Digital Enhanced Cordless Telephone differentially encoded MPSK differentially encoded QPSK Data Encryption Standard decode-and-forward decision-feedback equalization Discrete Fourier transform differential services delta modulation Digital Multimedia Broadcasting differential MPSK differential nonlinearity direction-of-arrival Department of Defense; also direction-of-departure differential PCM differential phase-shift keying differential quarternary phase shift keying dielectric resonator direct sequence double sideband DSB-large carrier DSB-small carrier  DR DS DSB DSB-LC DSB-SC DSL, xDSL digital subscriber line DS-CDMA direct-sequence CDMA DSCQS  double stimulus continuous quality scale      xxviii   cid:2   List of Abbreviations  ETSI  DSMA  DSP DSSS  DST DSTTD DTFT  digital sense multiple access digital signal processor direct-sequence spread spectrum discrete sine transform double-STTD discrete-time Fourier transform DVB-Handheld  DVB-H DVB-RCL Digital Video  Broadcasting–Return Channel for LMDS  DVB-RCS DVB-Return Channel via  DVB-S  DVB-S2  DVB-T DVB-T2  DWT DySPAN  EBCOT  ECMA  EDGE  EFR EGC EIA  EM ENOB EPC ESPAR  ESPRIT  Satellite Digital Video Broadcasting Satellite DVB-Satellite Second Generation Terrestrial DVB Terrestrial DVB Second Generation discrete wavelet transform Dynamic Spectrum Access Networks Embedded block coding with optimized truncation European Computer Manufacturers Association Enhanced Data for GSM Evolution enhanced full rate equal gain combining Electronics Industry Association electromagnetic effective number of bits Electronic Product Code electronically steerable parasitic array radiator Estimation of Signal Parameters via Rotational Invariance Techniques  European Telecommunications Standards Institute Evolved UTRA  FDMA  FDD FDE  enhanced variable rate codec  E-UTRA E-UTRAN Evolved UTRA Network EVRC EVRC-WB EVRC-Wideband EXIT  EZW FBSS FCC  extrinsic information transfer embedded zero-tree wavelet fast base station switching Federal Communications Commission frequency division duplexing frequency-domain equalization frequency division multiple access ﬁnite difference time domain forward error correction ﬁnite element method ﬁeld-effect transistor fast Fourier transform frequency hopping  FIR FM FPGA  FDTD FEC FEM FET FFT FH FH-CDMA frequency-hopping CDMA FHSS frequency-hopping spread spectrum ﬁnite impulse response frequency modultion ﬁeld programmable gate array full-rate frequency shift keying fast wavelet transform gallium arsenide geostationary earth orbit Gaussian FSK generalized multi-carrier Gaussian minimum shift keying group of blocks group of pictures grade of service General Packet Radio Service  FR FSK FWT GaAs GEO GFSK GMC GMSK  GOB GOP GoS GPRS      xxix   cid:2   List of Abbreviations  HFET HiperACCESS High-Performance  GPS  GSC GSM  HAPS  HARQ H-BLAST  HBT  HDTV HEMT  HiperLAN  HiperMAN  HiSWAN  HILN  HLR HR HSCSD  HSDPA  H-S MRC  HSPA  HSUPA  HTS  I IC  Global Positioning System Golay Sequential Code Global System for Mobile Communications high-altitude aeronautical platform system hybrid-ARQ Horizontal encoding BLAST heterojunction bipolar transistor high deﬁnition television high electron mobility transistor heterostructure FET  Access High Performance Radio LAN High Performance Metropolitan Area Network High Speed Wireless Access Network harmonic and individual lines plus noise home location register half-rate High Speed Circuit Switched Data High-Speed Downlink Packet Access hybrid selection maximum ratio combining High-Speed Packet Access High-Speed Uplink Packet Access high-temperature superconductor in-phase integrated circuit  ICI IDCT IDMA  IDWT IEC  IETF  IF IIP3 IIR IMD IMDCT IMI  IMPATT  IMT-2000  IntServ INL IP IP3 IPv4 v6  IS ISI ISM  ISO  ITU  ITU-R  ITU-T  JPEG  JTRS  intercarrier interference inverse DCT interleave division multiple access inverse DWT International Electrotechnical Commission Internet Engineering Task Force intermediate frequency input IP3 inﬁnite impulse response intermodulation distortion inverse MDCT intermodulation interference impact avalanche and transit time International Mobile Telecommunications 2000 integrated services integral nonlinearity Internet Protocol third-order intercept point Internet Protocol version 4 version 6 Interim Standard intersymbol interference industrial, scientiﬁc, medical International Organization for Standardization International Telecommunication Union ITU’s Radiocommunication Sector ITU’s Telecomunication Standarization Sector Joint Photographic Experts Group Joint Tactical Radio System      xxx   cid:2   List of Abbreviations  LAN LBG LCC LCH LCMV  LCR LD-CELP LDPC LEACH  LEO LHCP  LINC  LLC LLR LMDS  LSF LSP LTCC  LTE LTI LTP LUT MAC  MAD MAHO MAI MAN  local area network Linde-Buzo-Gray lost call clearing lost call hold linearly constrained minimum variance level crossing rate low-delay CELP low density parity code low-energy adaptive clustering hierarchy low earth orbit left-hand circular polarization linear ampliﬁcation using nonlinear components logical link control log-likelihood ratio Local Multipoint Distribution Service least mean squares low-noise ampliﬁer local oscillator line-of-sight lapped orthogonal transform linear predictive coding least squares least signiﬁcant bit  respread multitarget array line spectral frequency linear spectral pair low-temperature coﬁred ceramic Long-Term Evolution linear time-invariant long-term prediction look-up table medium access control; also multiply-accumulate mean absolute difference mobile-assisted handoff multiple-access interference metropolitan-area network  MANET MAP MASK  mobile ad hoc networking maximum a posteriori M-ary amplitude-shift keying  MB-OFDM multiband OFDM-based MCA  maximally constrained autocorrelation  multi-carrier DS-CDMA  MC-CDMA multi-carrier CDMA MC-DS- CDMA MCM MCU MDCT MDF  multicarrier modulation microcontroller unit modiﬁed DCT magnitude difference function macro diversity handoff minimum detectable signal mixed excitation linear prediction micro-electromechanical system metal-semiconductor ﬁeld effect transistor M-ary FSK microwave integrated circuit metal-insulator-metal multiple input multiple output  MDHO MDS MELP  MEMS  MESFET  MFSK MIC MIM MIMO  MISO ML MLSE  MIMO-SC MIMO single carrier MIMO-SS MIMO spread spectrum million instructions per MIPS second multiple-input single-output maximum-likelihood maximum-likelihood sequence estimation maximal length shift register modulated lapped transform Multichannel Multipoint Distribution Service monolithic microwave integrated circuit minimum mean squared error  MLSR MLT MMDS  MMSE  MMIC  LMS LNA LO LOS LOT LPC LS LSB LS-DRMTA least squares despread      xxxi   cid:2   List of Abbreviations  MPAM  MPE MPEG  MPLS MP-MLQ  MoM MOS MOSFET  method of moments mean opinion score metal-oxide-semiconductor ﬁeld effect transistor M-ary pulse amplitude modulation multipulse excitation Moving Pictures Experts Group multiprotol label switching multipulse maximum likelihood quantization M-ary PSK M-ary QAM maximum ratio combining mobile station mobile switching center mean squared error minimum shift keying  MPSK MQAM MRC MS MSC MSE MSK MT-CDMA multi-tone CDMA multiuser detection MUD MUI multiple-user interference MUltiple SIgnal MUSIC Classiﬁcations minimum variance distortionless response North American Digital Cellular numerically controlled oscillator Nordic Mobile Telephone nonreturn-to-zero -level - mark -space Nippon Telephone and Telegraph orthogonal complementary code orthogonal frequency division multiplexing orthogonal frequency division multiple access on-off keying offset QPSK Open Systems Interconnect  NMT NRZ -L - M -S NTT  OOK OQPSK OSI  OFDMA  MVDR  OFDM  NADC  NCO  OCC  OSIC  OSTBC  OVSF  PABX  PACS  PAE PAL PAM PAN PAPR PCCC  PCM PCS  PDC pdf  PDF PDP PEAQ  PESQ  PHS  PIC  PLL PM PN POCSAG  PPM PSD PSI-CELP  PSK PSNR  ordered serial  successive  interference cancellation orthogonal space-time block code orthogonal variable spreading factor private automatic branch exchange Personal Access Communication System power-added efﬁciency Phase Alternation Line pulse amplitude modulation personal area network peak-to-average power ratio parallel concatenated convolutional code pulse code modulation Personal Communications Service Personal Digital Cellular probability distribution function Portable Document Format power delay proﬁle perceptual evaluation of audio quality perceptual evaluation of speech quality Personal Handyphone System  parallel interference cancellation phase-locked loop phase modulation pseudo-noise Post Ofﬁce Code Standard Advisory Group pulse position modulation power spectral density pitch synchronous innovation CELP phase-shift keying peak signal-to-noise ratio      xxxii   cid:2   List of Abbreviations  PSTN  PWM Q Q2PSK QAM  QCELP QCIF QMF QO-STBC QoS QPSK  QS-CDMA QSIF RAN RCELP RCPC  RELP  RF RFID  RHCP  RLE RLS rms ROC ROI RPE RPE-LTP  RS RSSI  RTMS  RTP  RZ SA-DCT  public switched telephone network pulse-width modulation quadrature-phase quadrature quadrature PSK quadrature amplitude modulation Qualcomm CELP quarter-CIF quadrature mirror ﬁlter quasi-orthogonal STBC quality of service quaternary phase shift keying quasi-synchronous CDMA quarter-SIF regional area network relaxed CELP rate-compatible punctured convolutional residual excited linear prediction radio frequency radio frequency identiﬁcation right-hand circular polarization run-length encoding recursive least-squares root-mean-squared region of convergence region of interest regular pulse excitation regular pulse excitation with long-term prediction Reed-Solomon radio signal strength indication Radio Telephone Mobile System Real-time Transport Protocol return-to-zero shape-adaptive DCT  SA-DWT SAR  shape-adaptive DWT successive approximation register SAW surface acoustic wave SB-ADPCM subband-split ADPCM SC SCCC  single-carrier serially concatenated convolutional code spectrum cyclic density Signal Communication by Orbital Relay Equipment; also self-coherence restoral space division multiple access software-deﬁned radio SEquential Couleur Avec Memoire segmental SNR symbol error probability symbol error rate space–frequency block code spurious-free dynamic range spatial ﬁltering for interference reduction space-frequency coded OFDM sample-and-hold serial interference cancellation symbol-interleaved coded modulation source input format silicon-germanium single-input multiple-output signal-to-noise-and- distortion signal-to-interference-plus- noise ratio signal-to-interference ratio soft-in soft-out selectable mode vocoder  SCD SCORE  SDMA  SDR SECAM  SEGSNR SEP SER SFBC  SFDR  SFIR  SF-OFDM  S H SIC  SICM  SIF SiGe SIMO SINAD  SINR  SIR SISO SMV      xxxiii   cid:2   List of Abbreviations  SNDR  SNR SOI SOVA SPIHT  SPIN  SQNR  SS7 SSB SSMA  SUI  TACS  TCM TCP  TDAC  T-DMB TDD TDoA TD- SCDMA  TDMA  STBC STDO ST-MF ST-MUD STF-OFDM space-time-frequency coded  OFDM  ST-OFDM space-time coded OFDM STP STS STTC STTD  signal-to-noise-plus- distortion ratio signal-to-noise radio signal-of-interest soft output Viterbi algorithm set partitioning in hierarchical trees Sensor Protocols for Information via Negotiation signal-to-quantization-noise ratio Signaling System No. 7 single sideband spread spectrum multiple access space-time block code space-time Doppler space-time matched ﬁlter space-time MUD  short-term prediction space-time spreading space-time trellis code space-time transmit diversity Standford University Interim Total Access Communication System trellis-coded modulation Transmission Control Protocol time domain aliasing cancellation Terrestrial-DMB time-division duplexing time-difference-of-arrival Time Division-Synchronous Code Division Multiple Access time division multiple access  TDRSS  TEC TEM TH THSS  TIA  ToA TR TXCO  UDP UMB UMTS  UPE UQ-DZ  USB UTRA  UWB UWC-136  V-BLAST VCO VGA VLR VMR-WB  VO VoIP VOP VQ VSELP  VSWR VTC WAN WCDMA WiBro  Tracking and Data Relay Satellite System total electron content transverse electromagnetic time hopping time-hopping spread spectrum Telecommunications Industry Association time-of-arrival transmitted reference temperature-controlled crystal oscillator User Datagram Protocol Ultra Mobile Broadband Universal Mobile Telecommunications System unequal error protection uniform quantizer with dead zone Universal Serial Bus UMTS Terrestrial Radio Access ultra wideband Universal Wireless Communication 136 vertical encoding BLAST voltage-controlled oscillator variable gain ampliﬁer visitor location register variable multi-rate wideband video object voice over IP video object plane vector quantization vector-sum excited linear prediction voltage standing-wave ratio Visual Texture Coding wide area network Wideband CDMA Wireless Broadband      xxxiv   cid:2   List of Abbreviations  Wi-Fi WiMAX Worldwide Interoperability for  Wireless Fidelity  WSN WSSUS  Microwave Access wireless sensor network wide sense stationary, uncorrelated scattering  XPD  cross-polarization discrimination zero-crossing rate zero-forcing  ZCR ZF ZMCSCG zero-mean circularly  symmetric complex Gaussian      1  Introduction  1.1 The wireless age  Subsequent to the mathematical theory of electromagnetic waves formulated by James Clerk Maxwell in 1873 [3] and the demonstration of the existence of these waves by Heinrich Hertz in 1887, Guglielmo Marconi made history by using radio waves for transat- lantic wireless communications in 1901. In 1906, amplitude modulation  AM  radio was invented by Reginald Fessenden for music broadcasting. In 1913, Edwin H. Armstrong invented the superheterodyne receiver, based on which the ﬁrst broadcast radio transmis- sion took place at Pittsburgh in 1920. Land-mobile wireless communication was ﬁrst used in 1921 by the Detroit Police Department. In 1929, Vladimir Zworykin performed the ﬁrst experiment of TV transmission. In 1933, Edwin H. Armstrong invented frequency mod- ulation  FM . The ﬁrst public mobile telephone service was introduced in 1946 in ﬁve American cities. It was a half-duplex system that used 120 kHz of FM bandwidth [4]. In 1958, the launch of the SCORE  Signal Communication by Orbital Relay Equipment  satellite ushered in a new era of satellite communications. By the mid-1960s, the FM bandwidth was cut to 30 kHz. Automatic channel trunking was introduced in the 1950s and 1960s, with which full-duplex was introduced. The most important breakthrough for modern mobile communications was the concept of cellular mobile systems by AT&T Bell Laboratories in the 1970s [2].  The last two decades have seen an explosion in the growth of radio systems. Wireless communication systems migrated from the ﬁrst-generation  1G  narrowband analog sys- tems in the 1980s, to the second-generation  2G  narrowband digital systems in the 1990s, to the current third-generation  3G  wideband multimedia systems that are being deployed. Meanwhile, research and development in the future-generation wideband multimedia radio systems is actively being pursued worldwide.  We have experienced a cellular revolution. In 2002, mobile phones worldwide began to outnumber ﬁxed-line phones. By November 2007, the total number of worldwide mobile phone subscriptions had reached 3.3 billion, and by 2007 over 798 million people around the world accessed the Internet or equivalent mobile Internet services at least occasionally using a mobile phone.1 This also makes the mobile phone the most common electronic device in the world. In addition to its multimedia services such as speech, audio, video,  1 http:  en.wikipedia.org wiki Mobile_phone, retrieved on Oct 21, 2008      2   cid:2   Introduction  Table 1.1. Division of electromagnetic waves.  Electromagnetic waves  Frequency  Extremely low frequency  ELF  30–300 Hz 300–3,000 Hz 3–30 kHz 30–300 kHz 300–3,000 kHz 3–30 MHz 30–300 MHz 300–3,000 MHz 3–30 GHz 30–300 GHz 300–3,000 GHz 43,000–416,000 GHz 430,000–750,000 GHz 750,000–3,000,000 GHz  Wavelength  10–1,000 km 1–100 km 100–10 km 10–1 km 1,000–100 m 100–10 m 10–1 m 100–10 cm 10–1 cm 10–1 mm 1–0.1 mm 7–0.7 μm 0.4–0.7 μm 0.4–0.1 μm  VLF LF MF HF VHF UHF SHF EHF  Very low frequency Low frequency Medium frequency High frequency Very high frequency Ultra high frequency Super high frequency Extreme high frequency  Infrared rays Visible light Ultravioleta  a Beyond ultraviolet are X-rays and Gamma-rays.  and data, the pervasive use of wireless communications has also entered many aspect of our life, including health care, home automation, etc.  1.2 Spectrum of electromagnetic waves  The medium for wireless communications is open space, and information is transferred via electromagnetic waves. In order to separate different wireless systems, the spectrum of electromagnetic waves is divided into many frequency bands. The wavelengths and frequencies of electromagnetic waves are listed in Table 1.1.  At lower frequencies, radio waves tend to follow the earth’s surface, while at higher fre- quencies, e.g., above about 300 MHz, they propagate in straight lines. The range from dc to SHF has been widely used for communications and other purposes such as radar, indus- try, heating, spectroscopy, radio astronomy, medicine, power transmission, and science. In contrast, the region of EHF waves and beyond is wide open due to technical difﬁculties. This is due to considerable attenuation in the atmosphere, and there are many difﬁcul- ties in wave generation, ampliﬁcation, detection, and modulation techniques. At above 1,000 GHz, the wave propagation turns optical. Optical communications are now restricted to optical ﬁbers.      3   cid:2   1.4 Architecture of radio transceivers  Source  Source encoder  Channel encoder  Modulator  Waveform  Transmitter  Receiver  Channel  Destination  Source decoder  Channel decoder  Demodulator   cid:2 Figure 1.1  Block diagram of a general communication system.  1.3 Block diagram of a communication system  A communication system deals with information or data transmission from one point to another. The block diagram of a general digital communication system is given in Fig. 1.1. This block diagram is also applicable to remote sensing systems, such as radar and sonar, in which the transmitter and receiver may be located at the same place.  The source generates either analog signals such as speech, audio, image, and video, or digital data such as text or multimedia. The source encoder generates binary data from the source. The generated binary data is then subject to a channel encoder so that the binary data sequences can be reliably reproduced at the receiver. The channel-encoded data stream is then modulated to generate waveforms for transmission over a channel, which is a physical link such as a telephone line, a high frequency radio link, or a storage medium. The channel is subject to various types of noise. At the receiver, the above procedure is reversed so as to ﬁnally restore the original source information.  There are three types of common transmission channels: wireless channels, guided electromagnetic wave channels, and optical channels. The wireless channel can be the atmosphere or free space. Due to its open nature, there are various noise sources added to the channel. Coaxial cable line was once a major guided wave channel, and optical ﬁber is a special type of guided wave channel. The long-distance telephone network once used coaxial cable lines, which has now been replaced by optical ﬁber.  1.4 Architecture of radio transceivers  The well-known super-heterodyne receiver architecture was invented by Armstrong in 1913. Armstrong also demonstrated frequency modulation in 1933. In this section, we introduce two architectures of radio transceivers: the super-heterodyne transceiver and the direct-conversion transceiver.      4   cid:2   Introduction  1.4.1 Super-heterodyne transceivers  Conventional super-heterodyne transceivers  The 1G radio systems were analog systems using frequency division multiple access  FDMA . For each user, there is a ﬁxed super-heterodyne transceiver. The received signal is ﬁrst passed through surface acoustic wave  SAW  ﬁlters for image suppression. The ﬁltered signal is low-noise ampliﬁed, and is then subject to one or more intermediate frequency  IF  stages  mixing and bandpass ﬁltering  and baseband processing. For transmission, the baseband signal is ﬁrst ﬁltered, then upconverted by multiple IF conversion stages, power ampliﬁed, and ﬁnally passed to an antenna for transmission. The oscillators and ﬁlters are generally not adjustable.  The 2G systems use the same super-heterodyne transceiver architecture for conversion between radio frequency  RF  and baseband signals. Analog-to-digital  A D  converters and digital-to-analog  D A  converters are used for conversion between analog and dig- ital baseband signals. The receiver typically converts the RF signal to a baseband signal after applying a few IF stages, and then separates orthogonal in-phase  I  and quadrature- phase  Q  baseband signals prior to applying A D conversion for each of these. Due to the application of time division multiple access  TDMA  and or code division mul- tiple access  CDMA , each transceiver can support multiple users and this requires a wider frequency slice for each transceiver. In the digital part, many dedicated digital application-speciﬁc integrated circuits  ASICs  as well as general-purpose digital signal processors  DSPs  are used to perform various signal processing tasks such as equalization, modulation demodulation, channel coding decoding, and voice coding decoding.  The super-heterodyne architecture achieves good I Q matching, and has no problems of dc offset and LO  local oscillator  leakage. However, it suffers from the image problem, as is illustrated in Fig. 1.2. For two signals x1 t  = A1 cos ω1t and x2 t  = A2 cos ω2t, after lowpass ﬁltering the product x1 t x2 t , we get a signal of the form cos ω1 − ω2 t, which is the same as cos ω2 − ω1 t. Thus the bands that are symmetrical above or below the LO frequency will be downconverted to the same band. In order to suppress the image, an image-rejection ﬁlter has to be placed before the mixer. Since the image-rejection ﬁl- ter is typically realized as a passive, external component, it requires the preceding low noise-ampliﬁer  LNA  to drive a 50-ohm load. Most RF transceivers employ two stages of downconversion to relax the Q required for each ﬁlter. In most RF applications, the overall image suppression is required to be around 60 to 70 dB [6].  Image  Desired  band   cid:2 Figure 1.2  ω1  ωLO  ω2  ωIF  Illustration of the image problem.      5   cid:2   1.4 Architecture of radio transceivers  Super-heterodyne transceivers for software-deﬁned radio  In conventional super-heterodyne transceivers, the analog ﬁlters are designed for a car- rier frequency and a channel bandwidth. This is not suitable for multiband systems. More recent transceivers employ low-IF sampling rather than baseband sampling. The low-IF scheme has a number of advantages. First, the dc offset problem does not occur. Second, the expensive IF SAW ﬁlter, IF phase-locked loop  PLL , and image rejection ﬁlter are not necessary. Also, the impact of near-dc ﬂicker  1 f   noise on the receiver performance is signiﬁcantly reduced. As to the downside, it suffers from LO pulling leakage due to cou- pling or imperfect isolation between the RF components; it also requires stringent image rejection to suppress strong interferers from adjacent channels, which are images of the desired signals arising from the low IF.  The low-IF scheme is employed in the classical architecture for software-deﬁned radio  SDR  at the base station  BS , as shown in Fig. 1.3. The wideband RF front-end replaces many narrowband transceivers used in 1G or 2G systems. The wideband front-end converts an entire band containing multiple carriers to a suitable IF signal, which is then digitalized, while conventional 2G systems shift individual carriers to baseband prior to digitalization. Note, that in Fig. 1.3, BP3 is the anti-aliasing bandpass ﬁlter. The selection of IFD is dependent on the frequency converters that are COTS  commercial off-the-shelf  available. Note that the RF ﬁlters can be inserted between the LNA and mixer in the receiver, and between the mixer and power ampliﬁer in the transmitter, to reject any signal generated by the nonlinearity of the LNA or mixer.  The digital signal processing module implements an independent digital front-end, base- band processing for each carrier, and O&M  operation and management  signaling. For each carrier, a digital front-end downconverts the digital IF signal to I and Q baseband sig- nals by a numerically controlled oscillator  NCO ; this is followed by baseband processing that contains sampling rate conversion, demodulation and ﬁltering, channel decoding, and source decoding. The transmit path is the reverse of the receive path. Note that on the transmit path the signals of all carriers are summed before D A conversion is applied. Care must be taken to avoid numerical overﬂow.  1.4.2 Direct-conversion transceivers  Another common transceiver architecture is the direct-conversion or zero-IF system, also known as homodyne system. A direct-conversion receiver downconverts the RF signal directly to baseband by using an LO, whose frequency is exactly equal to the frequency of the RF signal. Direct conversion requires only a single frequency synthesizer and avoids an off-chip IF ﬁlter, and thus is preferred in a fully integrated design.  Since the intermediate frequency ωIF is zero, the image to the RF signal is the RF signal itself. Thus, the image problem does not arise and the method eliminates the use of bulky, off-chip, front-end image rejection ﬁlters. However, since the synthesizer operates at the same frequency as the RF signal, LO leakage and frequency pulling occur. Other disad- vantages include the problems of dc offset, ﬂicker or 1 f noise and I Q mismatch. These      C A M  r e y a l  o T  c e d o C  r e i r r a c    h c a e   r o F  n o i t a m i c e D  g n i r e t l i  F  n o i t a m i c e D  g n i r e t l i  F  n o i t a l o p r e t n I  g n i r e t l i  F  n o i t a l o p r e t n I  g n i r e t l i  F  l e n n a h C  g n i d o c e d  n o i t a l u d o m e D  g n i r e t l i  F  IQ  O C N  0 9  h c a e    o T  r e i r r a c  e l u d o m  D F I  C D A  A G V  C G A    D     F I      2 F I  1 F I  3 P B  2 P B  1 P B  s  f  2 O L  1 O L  r e n i b m o c   F R  l e n n a h C  g n i d o c  n o i t a l u d o M  g n i r e t l i  F  Q  I  O C N  0 9  Σ  Σ  C A D     f o m u S    s r e i r r a c   l l a  4 P B  5 P B  6 P B  A N L  A P     e l u d o m g n i s s e c o r p    l a n g i s   l a t i g i D  d n e − t n o r f   d n a b e d i w g o l a n A     D F I  e h t  r o f n O L  , r e t l ﬁ s s a p d n a b h t n e h t  r o f n P B  , F I  i  l a t i g d e h t  r o f  , e g a t s  F I  h t n e h t  r o f  s d n a t s n F I  . S B e h t  t a n o i t a t n e m e p m  l  i  R D S  l a c i s s a l c A  , r e t r e v n o c A   D r o f  C A D  , r e t r e v n o c D   A r o f  C D A  , r o t p a d a n i a g e b a i r a v  l  r o f A G V , r e ﬁ  i l  p m a  r e w o p r o f A P , r e ﬁ  i l  p m a  e s i o n w o  l  r o f A N L  ,  O L h t n  . r o t a l l i c s o d e  l l  o r t n o c  y l l a c i r e m u n r o f O C N d n a  , l o r t n o c n i a g c i t a m o t u a  r o f  C G A  .  3 1 e r u g   cid:2 F  i      7   cid:2   1.5 Organization of the book  disadvantages can be overcome in the super-heterodyne architecture by using an off-chip IF ﬁlter and an extra frequency synthesizer.  LO leakage arises due to limited isolation between the LO port and the inputs of the mixer and the LNA, causing a leakage LO signal to feed through the LNA and the mixer or a large leakage interfering signal to feed through the LO input. The original RF signal as well as the LO leakage is then mixed with the LO, and a dc offset is generated in both the cases. This is known as the self-mixing phenomenon. Cancellation of the dc offsets is a primary concern in direct-conversion receiver design. Thus, this method requires an LO with a very high precision and stability. The LO leakage to antenna may be reradiated, creating interference to other receivers. The Federal Communications Commission  FCC  requires that the upper bounds of the in-band LO radiation is typically between −50 dBm and −80 dBm for wireless standards [6]. In direct-conversion transceivers, I Q mismatch can be viewed as the so-called self- image problem, where the baseband equivalent signal is essentially interfered by its own complex conjugate [7]. I Q mismatch at the receiver will corrupt the downconverted signal constellation, leading to a higher BER, while I Q mismatch at the transmitter can lead to increased out-of-band emissions with nonlinear power ampliﬁers. Signal processing techniques may be used to correct the I Q mismatch [1, 7].  In addition, 1 f noise is a severe problem in CMOS implementations, with a ﬂicker noise corner frequency in the vicinity of 1 MHz [5]. The ﬂicker noise in SiGe and BiCOMS technologies are much lower than that in CMOS technology. The 1 f noise can be reduced by incorporating large devices at the stages following the mixers, since the operating frequency is relatively low. The CMOS technology is not suitable for high- sensitivity direct-conversion receivers such as narrow-band systems, while the SiGe and BiCMOS technologies make it possible to achieve higher receiver sensitivity for wideband systems.  For the transmitter part, the power ampliﬁer will disturb the transmit LO, and will corrupt the oscillator spectrum, despite the shielding techniques used. This is the injection- pulling or injection-locking mechanism. This inﬂuence can be reduced if the power ampliﬁer output spectrum is sufﬁciently away from the LO frequency. This can be achieved by offsetting the LO frequency by mixing two voltage-controlled oscillators  VCOs . Another way to prevent LO pulling is to upconvert the baseband signal in two steps, yielding the power ampliﬁer output spectrum that is far from the frequency of the VCOs. This is implemented in modern super-heterodyne transceivers.  1.5 Organization of the book  This book gives a comprehensive introduction to wireless communication systems. The contents are organized into four parts. Part 1  Chapters 2 to 9  introduces the principles of wireless communications. Part 2  Chapters 10 to 13  deals with the analog and digital implementation of wireless communication systems. Information theory and coding are      8   cid:2   Introduction  treated in Part 3  Chapters 14 to 17 . Part 4  Chapters 18 to 22  describes some advanced and emerging technologies for future-generation wireless communications.  The contents by chapters are listed below.   In Chapter 2, we give an overview of wireless communications and its history. Circuit packet switching and the OSI reference model are also described in this chapter.   Electromagnetic wave propagation is subject to propagation loss. Chapter 3 introduces propagation loss models, characteristics of wireless channels, and the mechanisms of signal propagation in the channel.   Fundamentals on multiuser communications are developed in Chapter 4. This chapter treats the cellular concept, various multiple access techniques, Erlang capacity, protocol design, quality of service  QoS , and user location.   Wireless channels are usually in a fading state. Diversity is the common method for combating fading. Diversity ensures that the same information reaches the receiver from statistically independent channels. By combining multiple independently fading copies of the same signal, fading can be substantially reduced. Diversity is examined in Chapter 5.   Channel estimation and equalization are necessary for signal detection. Channel estima- tion ﬁnds the channel information when the transmission signal propagates through the channel. Using this channel information, the equalizer can remove the inﬂuences of fad- ing and other undesirable channel conditions, and thus restore the original transmitted signal. These topics are discussed in Chapter 6.   Modulation is a process that incorporates the message into a carrier for transmission. The message can be embedded into the amplitude, frequency, or phase of the carrier, or a combination of these. Modulation and demodulation, which are subject to RF or microwave operations, are necessary for signal transmission. Chapter 7 introduces digital modulation and demodulation.   Spread spectrum communications, or CDMA technology, spread each user’s signal over the same wider bandwidth for transmission. At the receivers, these user signals are sep- arated by using their speciﬁc codes. CDMA is the underlying technology for 3G cellular communications, and is introduced in Chapter 8.   OFDM technology transmits messages simultaneously over multiple carriers in a linear band-limited channel. It is robust against multipath fading, but with a low complexity. OFDM technology has been widely implemented in high-speed wireless networking and is an enabling technique for 4G mobile communications. Chapter 9 introduces OFDM technology.   An antenna is the interface between the RF microwave circuits and the free space. It transmits the generated RF or microwave signals over the wireless channel, and at the same time, passes the received signal on to the RF microwave circuits at the receiver. Antennas are described in Chapter 10.   RF microwave subsystems, known as the front-ends of wireless transceivers, are the ana- log circuits in wireless communication systems. They convert RF signals into baseband signals, and vice versa. RF microwave subsystems are introduced in Chapter 11.   Modern wireless communication systems are digital systems, where information pro- cessing is performed in digital form, whereas the received transmitted signal at the      9   cid:2   1.5 Organization of the book  antenna is in analog form. A D and D A converters are used for conversion between the analog and digital signals within the wireless transceiver. A D and D A converters are described in Chapter 12.   Digital signal processing is an enabling technique for digital communication systems. Chapter 13 introduces basic digital signal processing techniques that are used in wireless communications and source coding.   Information theory was established by Shannon. It lays the theoretical foundation for source coding and channel coding, as well as the entire communication networks. Information theory is the subject of Chapter 14.   Source coding or data compression is performed to remove redundancy in the original data so as to maximize the information storage and transmission. Speech communication is the most fundamental service provided by wireless networks. Source coding of speech and audio signals is presented in Chapter 16.   Wireless communications are being escalated to deliver multimedia service. This involves image and video coding. Source coding for images and videos is introduced in Chapter 17.   After the redundancy in a message is removed during source coding, the message is more vulnerable to errors. For the purpose of reliable storage or transmission over a noisy channel, error-correcting codes are used for error recovery. This is the topic of channel coding. Channel coding is described in Chapter 15.   Use of multiple antennas is an effective solution for high-speed or high-reliability communications. Smart antennas and MIMO communications are two major multiple- antenna technologies. Smart antennas can be used for diversity combining and beam- forming. Chapter 18 discusses smart antenna technology.   Chapter 19 continues with the discussion of multiple antenna systems: MIMO tech- nology. MIMO technology can be implemented as space-time coding or spatial multiplexing. MIMO is an enabling technique for 4G mobile communications and future-generation wireless networks.   Ultra wideband  UWB  technology employs a spectrum in excess of 500 MHz that over- laps licensed bands in an unlicensed mode. It is an enabling technique for gigabits s wireless networking. UWB technology is described in Chapter 20.   Software-deﬁned radio  SDR , or software radio, provides a solution for one hardware platform, multiple wireless standards. It makes possible multiband, multimode, mul- tistandards low-power radio communications. Cognitive radio, based on the platform provided by SDR, solves the problem of crowded spectrum allocation. Both technologies are enabling techniques for 3G and 4G wireless systems. They are treated in Chapter 21.   Wireless ad hoc networks are playing an increasing role in current and future-generation wireless and mobile networks. Wireless sensor networks, as an emerging technology, are being employed in a range of applications such as home, industry, military, public security, environment monitoring, and medical applications. Both the wireless ad hoc and sensor networks are important for ubiquitous networking. These topics are described in Chapter 22.  In each chapter, some problems are included and should be helpful to students to review the contents of the chapter.      10   cid:2   Introduction  References  [1] J. J. de Witt & G.-J. van Rooyen, A blind I Q imbalance compensation technique for direct-conversion digital radio transceivers. IEEE Trans. Veh. Tech., 58:4  2009 , 2077–2082.  [2] V. H. MacDonald, The cellular concept. Bell Sys. Tech. J., 58:1  1979 , 15–41. [3] J. C. Maxwell, A Treatise on Electricity and Magnetism  Oxford: Clarendon Press,  1873; New York: Dover, 1954 .  [4] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall PTR, 2002 .  [5] B. Razavi, Design Consideration for direct-conversion receiver. IEEE Trans. Circ. Syst.  II, 44:6  1997 , 428–435.  [6] B. Razavi, RF Microelectronics  Upper Saddle River, NJ: Prentice Hall, 1998 . [7] M. Valkama, M. Renfors & V. Koivunen, Advanced methods for I Q imbalance com- pensation in communication receivers. IEEE Trans. Signal Process., 49:10  2001 , 2335–2344.      2  An overview of wireless communications  2.1 Roadmap of cellular communications  2.1.1 First-generation systems  The 1G mobile cellular systems were analog speech communication systems. They were mainly deployed before 1990. They are featured by FDMA  frequency division multiple access  coupled with FDD  frequency division duplexing , analog FM  frequency mod- ulation  for speech modulation, and FSK  frequency shift keying  for control signaling, and provide analog voice services. The 1G systems were mainly deployed at the frequency bands from 450 MHz to 1 GHz. The cell radius is between 2 km and 40 km.  The AMPS  Advanced Mobile Phone Services  technique was developed by Bell Labs in the 1970s and was ﬁrst deployed in late 1983. Each channel occupies 30 kHz. The speech modulation is FM with a frequency deviation of ±12 kHz, and the control sig- nal is modulated by FSK with a frequency deviation of ±8 kHz. The control channel transmits the data streams at 10 kbits s. AMPS was deployed in the USA, South America, Australia, and China. In 1991, Motorola introduced the N-AMPS to support three users in a 30 kHz AMPS channel, each with a 10 kHz channel, thus increasing the capacity threefold.  The European TACS  Total Access Communication System  was ﬁrst deployed in 1985. TACS is identical to AMPS, except for the channel bandwidth of 25 kHz. Speech is mod- ulated by FM with a frequency deviation of ±12 kHz, and the control signal is modulated by FSK with a frequency deviation of ±6.4 kHz, achieving a data rate of 8 kbits s. TACS has various versions: ETACS deployed in UK in 1987 and NTACS JTACS that came into service in Japan in June 1991.  The NTT  Nippon Telephone and Telegraph  system, ﬁrst deployed in Japan in 1979, is also based on AMPS. The NTT system has a channel spacing of 25 kHz and overlapped channels of 12.5 kHz are used to increase frequency utilization. The speech signal is FM modulated with a ±5 kHz deviation. The control signaling uses FSK with a deviation of ±8 kHz, and the data rate is 0.3 kbits s. The NMT  Nordic Mobile Telephone  system, developed by Ericsson, was introduced in Sweden in 1981. It uses a channel spacing of 25 kHz. The modulation for speech is FM with a frequency deviation of ±5 kHz. It transmits 1.2 kbits s using FSK with a frequency deviation of ±3.5 kHz. C-Netz C-450 was deployed in Germany, Austria, Portugal, and South Africa from 1981. C-450 has a channel spacing of 20 kHz. It employs FM speech modulation with ±4 kHz      12   cid:2   An overview of wireless communications  deviation and FSK signaling with ±2.5 kHz deviation, achieving a signaling data rate of 5.28 kbits s.  During this period, several other systems were deployed, such as RadioCom in France in 1985, Comvik in Sweden in 1981, and RTMS  Radio Telephone Mobile System  in Italy in 1985. There were also some cordless telephone systems, which are low-power, low-range systems that allow a user to move in a house or a building.  For the 1G systems, the use of FDMA FDD demands each user to occupy two slices of frequency bands, one for the uplink and the other for the downlink. For each slice of the frequency band, a transceiver must be designed, leading to a high cost. While the 1G systems aroused the market popularity internationally, they were restricted by the small coverage areas, poor speech quality, and poor battery performance. These shortcomings were overcome by introducing digital communication systems, resulting in the 2G systems.  2.1.2 Second-generation systems  The 2G systems were introduced in the early 1990s. They provide wireline-quality digital voice services based on circuit-switched data communications. These systems are featured by digital implementation. New access techniques, such as TDMA  time division multiple access  and CDMA  code division multiple access , were also introduced. In addition to 2G cellular systems, many 2G cordless phone, wireless LAN and satellite radios were also developed during this period.  The most dominant 2G cellular standards are GSM  Global System for Mobile Commu- nications  and IS-95  Interim Standard 95  CDMA. As of the second quarter of 2007, GSM had 2.3 billion subscribers worldwide, while CDMA had 450 million [9]. Other regional 2G cellular standards are IS-54 IS-136 TDMA and PDC  Personal Digital Cellular  TDMA in Japan. The operating frequency bands are typically between 900 MHz and 1.9 GHz.  The GSM air interface, introduced in 1990 by ETSI  European Telecommunications Standards Institute , is based on FDMA TDMA FDD and GMSK  Gaussian minimum shift keying  modulation. The spectrum is divided into many channels of 200 kHz band- width, with a channel data rate of 270.833 kbits s. Each channel is time-divided for eight users.  IS-54,  introduced in 1991 by TIA EIA  Telecommunications Industry Associa- tion Electronics Industry Association  of the USA and deployed in 1993, is also known as NADC  North American Digital Cellular  or D-AMPS  Digital-AMPS  system. IS-54 employs FDMA TDMA FDD with π 4-DQPSK  differential quaternary phase shift key- ing  modulation. It uses the same 30-kHz channels and frequency bands as AMPS, but has six times the capacity of AMPS. Each channel has a bit rate of 48.6 kbits s. IS-54 uses the same 10 kbits s FSK signaling scheme of AMPS for the forward  downlink  and reverse  uplink  control channels. IS-136, as a modiﬁcation of IS-54, uses π 4-DQPSK modu- lation for the control channels, resulting in a higher control channel data rate for paging and short messaging. IS-136 is not compatible with IS-54. PDC, introduced in 1993, is somewhat similar to IS-54 IS-136. It is a TDMA FDMA FDD system with π 4-DQPSK.      13   cid:2   2.1 Roadmap of cellular communications  Each carrier is 25 kHz wide, and supports a raw data rate of 42 kbits s. Each carrier is time-divided into 3 full-rate  6 half-rate  channels.  The TIA EIA IS-95 standard was introduced in 1993, and the IS-95A revision was released in 1995. IS-95A interoperates with the analog AMPS, and is the basis for the 2G CDMA deployment. The ﬁrst IS-95A system was deployed in Hong Kong in 1996. IS-95 employs CDMA FDD with OQPSK  offset quaternary phase shift keying  modu- lation. It uses the same bands as IS-54, but each channel is 1.2288 MHz wide, and each user has a data rate of 9.6 kbits s. IS-95 allows variable data rates of 1.2, 2.4, 4.8, and 9.6 kbits s. Compared to the other 2G technologies, IS-95 is signiﬁcantly more complex. It also employs some techniques, such as power control, frequency and delay diversity, variable-rate coding, and soft handoff, which were later adopted in the 3G standards. The IS-95B revision uses the same physical layer as IS-95A, but further provides 64 kbits s packet-switched data, in addition to voice services; thus, IS-95B is treated as a 2.5G tech- nology. IS-95B was ﬁrst deployed in Korea in 1999. IS-95 95A 95B are collectively known as CDMAOne or IS-95.  GSM and IS-136 migrated to 3G in two phases. In the ﬁrst phase, the GPRS  General Packet Radio Service  increased the data rate to around 115 kbits s, though the theoretical peak rate is 172.2 kbits s if all the eight time slots in a GSM frame are used. GPRS made a transition from circuit-switched data that are used in GSM to packet-switched data. The data rate for circuit-switched data on GSM is 9.6 kbits s. HSCSD  High Speed Circuit Switched Data , as a new implementation to transmit circuit-switched data over GSM, supports data rates up to 38.4 kbits s, by allocating all the eight slots to one user. GPRS was also deployed over IS-136. In the second phase, the EDGE  Enhanced Data for GSM Evolution  standard further enhances the data rate to 384 kbits s. In EDGE, a high-rate 8PSK modulation coexists with the GMSK modulation. EDGE is a convergence of the GSM and IS-136 standards.  In addition, the Cellular Digital Packet Data  CDPD  overlay network, released in 1995, provides a low-speed packet data service over the US AMPS network. It provides a data rate of 19.2 kbits s over the 30-kHz AMPS channel.  Cordless telephone  In addition to the 2G cellular standards, there are also many 2G cordless telephone or wireless local loop  WLL  technologies such as PHS  Personal Handyphone System  in Japan, CT2  Second Generation Cordless Telephone  in UK, CT2+ in Canada, CT3 in Sweden, DECT  Digital Enhanced Cordless Telephone  in Europe, and PACS  Personal Access Communication System  in USA.  A cordless telephone system is similar to a cellular telephone system, but provides low mobility at pedestrian speeds over a smaller area such as a building and usually as a private automatic branch exchange  PABX  or connected to the public switched telephone network  PSTN . These systems are limited to low power transmission. Cord- less telephone systems are designed for microcell indoor PCS  Personal Communications Service  use, and they typically provide coverage within a range of a few hundred meters.      14   cid:2   An overview of wireless communications  CT2, introduced in 1989, is a digital version of the 1G cordless telephones. CT2 employs FDMA TDD  time-division duplexing  with GFSK  Gaussian FSK  modulation; it uses a carrier spacing of 100 kHz, with a channel bit rate of 72 kbits s. Both CT2+ and CT3 standards are very similar to CT2, with difference in details on available slots in the frame organization.  DECT, an ETSI standard ﬁnalized in 1992, is based on TDMA FDMA TDD transmis- sion with GFSK modulation, and each channel is 1.728 MHz wide, achieving a channel bit rate of 1152 kbits s. Each channel consists of 24 slots per 10 ms long frame, time-shared among 12 users.  PACS, introduced in 1992, is a FDMA TDMA FDD or  TDD technique with π 4-QPSK  quaternary phase shift keying  modulation; each carrier is 300 kHz wide, achieving a chan- nel bit rate of 384 kbits s, which is shared by 8  FDD  or 4  TDD  users. PHS employs FDMA TDMA TDD and π 4-DQPSK; each carrier is 300 kHz wide, achieving a channel bit rate of 384 kbits s.  2.1.3 Third-generation systems  Currently, 3G cellular systems are being deployed worldwide. The 3G standards were developed by ITU  International Telecommunication Union  under the name of IMT-2000  International Mobile Telecommunications 2000  or UMTS  Universal Mobile Telecom- munications System  in ITU-R Rec. M.1457. The 3G cellular system is featured by wideband communications. As general requirements, it demands a data rate of 2 Mbits s at stationary mobiles, 384 kbits s for a user at pedestrian speed, and 144 kbits s in a moving vehicle. It is targeted to be a global system supporting global roaming. The 3G network uses packet switching, and is typically deployed at the 2 GHz frequency band.  In June 1998, ITU-R  ITU’s Radiocommunication Sector  received 11 competing pro- posals for terrestrial mobile systems, and approved ﬁve. Two mainstream 3G standards are WCDMA and CDMA2000, which are administered by two bodies in ITU, 3GPP  Third- Generation Partnership Project  and 3GPP2  Third-Generation Partnership Project 2 , respectively. In October 2007, ITU-R elected to include WiMAX  802.16e  in the IMT- 2000 suite of wireless standards and updated ITU-R Rec. M.1457. WiMAX now is a strong contender to WCDMA and CDMA2000.  UTRA WCDMA  WCDMA  Wideband CDMA , also known as UTRA  UMTS Terrestrial Radio Access , was jointly developed by ARIB, Japan and ETSI. It is a wideband solution, with a carrier bandwidth of 5 MHz and a chip rate of 3.84 Mchips s. WCDMA has a ﬂexible carrier spacing with a 200 kHz carrier raster, to improve the spectrum utilization efﬁciency by providing ﬂexibility to conform with that of GSM. WCDMA supports the legacy GSM at the network level, and 3GPP keeps the core network to be as close to GSM core network as possible. WCDMA employs CDMA FDD with QPSK BPSK  binary phase shift keying  modulation in its ﬁrst release completed in 1999. WCDMA supports user data rates up to      15   cid:2   2.1 Roadmap of cellular communications  2.3 Mbits s both in the uplink and the downlink. The duration of a frame is 10 ms. The ﬁrst commercial launch of WCDMA was in Japan in 2001.  The HSDPA  High-Speed Downlink Packet Access, 3GPP TR25.858  and HSUPA  High-Speed Uplink Packet Access, 3GPP TS25.896  standards evolved as a consequence of 3GPP to high-speed data services. HSDPA was included in 3GPP Release 5 in March 2002, and HSUPA was included in Release 6 in December 2004. They together are known as HSPA  High-Speed Packet Access . They use different physical layers from WCDMA, and employ many new features. HSDPA employs orthogonal frequency division multiplex- ing  OFDM  technology for transmission. HSDPA supports 16QAM  quadrature amplitude modulation , achieving a data rate of up to 14.4 Mbits s. HSUPA uses QPSK modulation only, and has a speed of up to 5.76 Mbits s. HSDPA and HSUPA are both treated as 3.5G  3.5th generation  systems, and they have both FDD and TDD modes; they both evolved to HSPA+  3.9G, short for 3.9th generation , which was speciﬁed in 3GPP Release 7. Downlink MIMO  multiple input multiple output  is supported in HSPA+. WCDMA was deployed in 2003, HSDPA in 2006, and HSUPA in 2007.  CDMA2000  CDMA2000, also known as IS-2000, was proposed by TIA EIA. It is a narrowband mul- ticarrier solution, with a carrier width of 1.25 MHz and a chip rate of 1.2288 Mchips s, achieving a maximum data rate of 2.457 Mbits s in the downlink. CDMA2000 supports the legacy IS-95 at the air interface. It adopts CDMA FDD in the FDD mode, and TDMA CDMA TDD in the TDD mode. The modulation schemes are BPSK, QPSK, 8PSK and 16QAM. The use of N = 1 and 3 carriers has been speciﬁed, and it can be extended to 6, 9, and 12 carriers in the future, achieving an effective chip rate of 1.2288N Mchips s. The frame duration is 20 ms or 5 ms.  The CDMA2000 family includes 1x  Phase 1 , 1xEV-DO  Evolution, Data Optimized, CDMA2000 Rev.0 , and 1xEV-DV  Evolution, Data and Voice  standards. 1xEV-DO and 1xEV-DV, together known as IS-856 of TIA EIA, are both backward-compatible with IS- 95 and 1x. CDMA2000 1x was ﬁrst deployed in Korea in October 2000, and 1xEV-DO was launched in Korea in 2002.  CDMA2000 1x is four times more efﬁcient than TDMA networks, and has a voice capacity that is twice that of IS-95. It delivers a peak data rate of 144 kbits s in loaded network, and delivers a peak packet data rate of 307 kbits s in mobile environments. 3GPP2 published 1x Advanced in August 2009 for upgrading the 1x platform while sus- taining backward compatibility. By taking advantage of several interference cancellation and radio link enhancements, 1x Advanced enahncements can theoretically quadruple the voice capacity of 1x systems in the same 1.25 MHz of spectrum. 1xEV-DO provides peak forward data rates of up to 2.4 Mbits s in a 1.25 MHz channel, and achieves an aver- age throughput of over 700 kbits s, equivalent to cable modem speeds. The data rate on the reverse link is up to 153.6 kbits s. 1xEV-DO offers multicast services, which enable multimedia services, such as real-time TV broadcast and movies, to an unlimited num- ber of users. 1xEV-DV Release D  CDMA2000 Rev. D, 3GPP2 C.S0002-D  supports a peak data rate of 3.09 Mbits s in the forward link and 1.8456 Mbits s in the reverse link      16   cid:2   An overview of wireless communications   3.5G ; it supports voice as well as data to offer smooth support for voice and legacy services. NxEV-DO or EV-DO Multicarrier  3GPP2 C.S0024-B  was published in 2006. It pro- vides a peak forward link data rate of N × 4.9 Mbits s, and a peak reverse link data rate of N × 1.8 Mbits s. It is capable of delivering a peak data rate of 73.5 Mbits s in the forward link and 27 Mbits s in the reverse link by using 15 carriers. This can be treated a 3.9G technology.  UTRA-TDD and TD-SCDMA  TDD avoids the uplink downlink spectrum pair required in FDD; this is ideal for asym- metric services and is especially suitable for highly populated areas. 3GPP also has two TDD modes: UTRA-TDD and TD-SCDMA  Time Division-Synchronous Code Division Multiple Access . UTRA-TDD, developed by ETSI, is the TDD mode of UMTS. UTRA- TDD employs TDMA  CDMA TDD with QPSK modulation. It uses the same bandwidth  5 MHz  and chip rate  3.84 Mchips s  as UTRA-FDD. Like UTRA-FDD, UTRA-TDD supports the legacy GSM at the network level. The frame of 10 ms length is divided into 16 slots, and each slot allows up to 8 CDMA channels.  TD-SCDMA was proposed in China in 1998. It is similar to UTRA-TDD in many aspects, but uses a bandwidth of 1.6 MHz and a chip rate of 1.28 Mchips s. TD-SCDMA is also known as the low chiprate TDD mode of UMTS. It employs QPSK 8PSK modulation. The maximum data rate is 2 Mbits s. The frame duration is 5 ms, which is divided into 10 time slots. Each time slot allows up to 16 CDMA channels. The spectral efﬁciency of TD-SCDMA is almost twice that of UTRA-TDD. TD-SCDMA provides a cost-effective way to upgrade existing GSM networks to 3G core networks. TD-SCDMA was ﬁrst deployed in China on April 1, 2008.  UWC-136 EDGE  ITU also approved UWC-136  Universal Wireless Communication 136  EDGE as a can- didate for IMT-2000 3G standards. UWC-136 EDGE was developed by TIA EIA to maximize commonality between IS-136 and GPRS, and to meet the ITU-R requirements for IMT-2000. UWC-136 provides backward compatibility with IS-136 and IS-136+.  UWC-136 increases the voice and data capacity of the 30 kHz channels by using enhanced modulations  π 4-DQPSK and 8PSK  with the exisiting 30 kHz IS-136+. A complementary wideband TDMA is deﬁned to provide high data rate. By adding a 200 kHz carrier component to provide a data rate of 384 kbits s, compatibility with GPRS and EDGE is possible. For transmission at a data rate of 2M bits s, a carrier component of 1.6 MHz is added. EDGE also evolved to EDGE Evolution  3.5G .  DECT was also approved by ITU as a PCS solution for the IMT-2000 standard. DECT employs FDMA TDMA TDD. In order to increase the data rate to meet IMT-2000  DECT      17   cid:2   2.1 Roadmap of cellular communications  requirements, in addition to its original GMSK modulation, other modulation schemes such as π 2-DBPSK, π 4-DQPSK, and π 8-D8PSK are also used.  Mobile WiMAX  Mobile WiMAX, developed on the basis of IEEE 802.16e, is a wireless metropolitan- area network  MAN  technology. IEEE 802.16e was completed in December 2005. IEEE 802.16e is based on OFDM technology. It allows OFDMA  orthogonal frequency division multiple access  with both FDD and TDD operations. MIMO technology is supported in WiMAX. It can deliver a maximum of 75 Mbits s and cover a range of 70 miles. Mobile WiMAX can be treated as 3.9G. Mobile WiMAX is deployed in the 2 to 6 GHz licensed bands. The ﬁrst commercial mobile WiMAX network was launched in Korea in June 2006.  3GPP LTE  3GPP LTE  Long-Term Evolution , also referred to as E-UTRA  Evolved UTRA  or E-UTRAN  Evolved UTRA Network , is the project name for the evolution of UMTS, which was started in 2005. In June 2005, 3GPP approved the further study of six physical layer proposals: multicarrier WCDMA, multicarrier TD-SCDMA, and four OFDMA-based pro- posals. LTE is targeted at the development of a new air interface, but the evolution of UMTS via HSDPA and HSUPA is still being pursued.  LTE, publicized in 3GPP Release 8, was ﬁnalized in December 2008. LTE with OFDMA air interface is expected to be deployed in 2010 or 2011. LTE uses a number of bandwidths scalable from 1.25 MHz to 20 MHz, and both FDD and TDD can be used. Both OFDM and MIMO technologies are employed to enhance the data rate to 172.8 Mbits s for the downlink and 86.4 Mbits s for the uplink. LTE uses OFDM in the downlink, while in the uplink a single-carrier  SC  FDMA is used. The bandwidth of LTE is more than twice that of HSDPA. LTE has a 2 to 6 dB peak-to-average power ratio  PAPR  advantage over the OFMDA method used in mobile WiMAX.  For a 5 MHz band, HSPA+ achieves 42 Mbits s downlink and 10 Mbits s uplink, while LTE achieves 43.2 Mbits s downlink and 21.6 Mbits s uplink. But HSPA+ does not support over 5 MHz band, while LTE supports up to 20 MHz band. The modulation used in LTE is QPSK, 16QAM, or 64QAM. LTE can be treated as 3.9G.  Ultra Mobile Broadband  Ultra Mobile Broadband  UMB  is 3GPP2’s project for evolution to 4G. UMB has a scalable bandwidth between 1.25 to 20 MHz with noncontiguous and dynamic channel  bandwidth  allocations, within a band between 450 MHz and 2500 MHz. It uses a com- bined OFDMA OFDM CDMA TDMA modulation with FDD or TDD and is an all-IP network. MIMO and SDMA  space division multiple access  technologies are also used. UMB supports a forward link data rate of up to 288 Mbits s and a reverse link data rate of up to 75 Mbits s. UMB was published in September 2007  3GPP2 C.S0084-0 v2.0 , and is expected to be deployed in 2009. It can be treated as 3.9G.      18   cid:2   An overview of wireless communications  IEEE 802.20  Mobile-Fi   The IEEE 802.20 standard, nicknamed Mobile-Fi, was started in December 2002. It was approved in June 2008. It is targeted for mobile broadband wireless access, with broadband packet-based air interface for mobile users at speeds of up to 250 km h. It is somewhat similar to IEEE 802.16e. IEEE 802.20 is targeted at licensed bands below 3.5 GHz. It supports a peak data rate in excess of 1 Mbits s in the downlink and 300 kbits s in the uplink per 2.5 MHz channel bandwidth. The standard supports both TDD and FDD operations, and can be deployed by using up to 40 MHz frequency band. IEEE 802.20 can be treated as 3.9G.  The standard includes an OFDM wideband mode and a 625k-multicarrier mode. The OFDM wideband mode supports both TDD and FDD, whereas the 625k-multicarrier mode supports TDD only. Both modes are designed to support a full range of QoS attributes. The wideband mode is based on the OFDMA technique. The 625k-multicarrier mode was developed to extract maximum beneﬁt from adaptive, multiple-antenna signal processing.  2.1.4 Fourth-generation systems  Research in 4G mobile radio systems is now underway. ITU-R deﬁned IMT-Advanced in 2007 based on ITU-R Rec. M.1645, and it targets peak data rates of about 100 Mbits s for highly mobile access  at speeds of up to 250 km hr , and 1 Gbit s for low mobility  pedestrian speeds or ﬁxed  access. Development of IMT-Advanced standards is likely to be completed by 2010, with deployment expected around 2015. The 4G wireless systems are supposed to support the following.   Ubiquitous, mobile, seamless communications.   A downlink date rate of 100 Mbits s at stationary conditions and 100 Mbits s at 250 miles hour in wide coverage.   A data rate of 1 Gbit s at stationary conditions in local area.   Internet-based mobility with IPv6  Internet Protocol version 6 .   QoS  quality of service -driven.   A high capacity with a spectral efﬁciency up to 10 bits s Hz.   Smart spectrum with dynamic spectrum allocation within 3 to 10 GHz.   Dynamic soft channel management.  This will enable us to watch TV and movies on a moving cellular phone. The 4G system will integrate both mobile cellular and wireless networking functions.  OFDM is the main technique to be employed for 4G radio systems. OFDM can be extended to OFDMA, or combined with CDMA or TDMA for multiple access. Some other enabling techniques for 4G mobile radio systems are the following.   Software-deﬁned radio enables a wide variation in adaptive RF bands, channel access modes, data rates, bit error rates  BERs , and power control that are demanded by 4G      19   cid:2   2.1 Roadmap of cellular communications  systems [8]. Software-deﬁned radio also enables seamless adaptation of radio access technologies  RATs , which is required for 4G.   Cognitive radio is required for dynamic spectrum management. It provides real-time band allocation for each user.   MIMO or multiple antenna techniques permit a high spectral efﬁciency.   Adaptive modulation and coding  AMC  jointly selects the most appropriate modulation and coding scheme according to channel conditions. AMC is more effective in packet networks, as used by 4G.   Hybrid-ARQ  HARQ  increases the throughput by combining the advantages of ARQ  automatic repeat request  and channel coding.  These techniques have been incorporated into some 3G standards such as HSDPA, HSUPA, WiMAX, IEEE 802.20, CDMA2000, 3GPP HSPA+, 3GPP LTE, and 3GPP2 UMB. In addition, spectrum ﬂexibility is identiﬁed as one main requirement for 4G systems, and multihop relaying is useful to extend the range for the high data rates [1].  Some standards that pave the way to 4G systems are mobile WiMAX, HiperMAN  High Performance Metropolitan Area Network , and WiBro  Wireless Broadband, Korean . These are point-to-multipoint broadband wireless access techniques. These techniques are wireless MANs. Mobile WiMax supports a mobility of up to 70–80 miles hour. WiMedia, which is based on ultra wideband  UWB  modulation, is suitable for 4G at stationary con- ditions in local area. A framework for 4G systems was presented from Ericsson in 2005 [1]. In August 2006, Samsung demonstrated 4G services based on mobile WiMAX, which supported a data rate of 1 Gbit s at stationary and 100 Mbits s on the move.  The IEEE is developing extensions to both IEEE 802.11 and 802.16 to meet IMT- Advanced  4G  requirements. The IEEE 802.16 Work Group is developing its 802.16m speciﬁcation, also called WiMAX II, which provides continuing support for legacy 802.16- OFDMA  802.16e  equipment, as a high-data-rate  100 Mbits s  extension at 250 km h. IEEE 802.16m also employs OFDM, AMC, HARQ, and MIMO technologies. It also supports intelligent multi-hop relays to achieve high data rate over a wide area. The trans- mission range is expected to be between 2 km in urban environments and 10 km in rural areas. In the meanwhile, IEEE 802.11 Working Group has launched a very high through- put  VHT  study to develop a radio capable of data rates up to 1 Gbit s at stationary or pedestrian speeds. IEEE 802.21, a standard in its ﬁnal development, deﬁnes link-layer ser- vices to enable handovers among different radio air interfaces. The combination of IEEE 802.11VHT and 802.16m via 802.21 creates a single integrated system, which is likely to be IEEE’s proposal for IMT-Advanced [3]. The formal completion of this work is expected in early 2010.  Since 2008, 3GPP has also been developing the LTE Advanced as the enhancement to its LTE standard for 4G requirements. The LTE Advanced is scheduled to be published as 3GPP Release 10.  Generally, 2G systems have a spectral efﬁciency of less than 1 bit s Hz, the current 3G systems have a spectral efﬁciency of 1–3 bits s Hz, and the desired spectral efﬁ- ciency for 4G systems is 10 bits s Hz. The evolution of mobile communication systems is demonstrated in Fig. 2.1.      EDGE  EDGE  Evolution  N−AMPS  IS−136  IS−54  GRPS  An overview of wireless communications  LTE  802.20  HSPA+  WiMAX  802.16e   LTE−Advanced  802.11VHT  802.16m  HSDPA  HSUPA  WCDMA  TD−CDMA  TD−SCDMA  CDMA2000  1x  1xEV−DV  HiperMAN  1x EV-DO  WiBro  1x Advanced  20   cid:2   C−450  AMPS  NMT  TACS  NTT  1980  1G  Analog   cid:2 Figure 2.1  DECT  CDPD  GSM  PHS  PDC  IS−95  PACS  1990  2G  2.5G  2000  3G  Digital  3.5G  3.9G  2010  4G  year generation  Evolution of mobile communication systems.  According to In-Stat, nearly 11% of worldwide wireless subscriptions were 3G at the end of 2008. In-Stat predicts that the percentage of 3G and 4G subscriptions will reach 30% by the end of 2013.1  2.1.5 Satellite communications  The concept of communications by satellite was ﬁrst suggested by Arthur C. Clarke in 1945 [2]. In 1957, the USSR launched Sputnik I, and the USA launched SCORE in 1958. Satellites are used for mobile communications. The major differences between satellite and terrestrial mobile channels are the lower elevation angle and the larger distance for the satellite case. For mobile satellite communications, low earth orbit  LEO  satellites are used so as to keep the time delays as small as possible. Mobile satellite systems not only function as standalone wireless systems, but also provide integration with terrestrial mobile systems. Mobile satellite networks have become a crucial component for future global telecommunication infrastructure, and they are standardized by several organizations such as 3GPP and Satellite UMTS. They are intended to complement and extend the existing terrestrial networks so as to provide complete global coverage. Currently, the cost and handset weight are two major obstacles for the commercial success of satellite networks. Iridium and Globalstar are two famous ﬁrst-generation LEO satellite constellations that provide hand-held telephony services, primarily for remote areas. Iridium, proposed by  1 http:  www.instat.com       21   cid:2   2.2 Mobile cellular networks  Motorola, consists of 66 LEO satellites in six orbital planes at an altitude of 780 km. Irid- ium provides global access to personal communications. It operates in the 1.5 to 1.6 GHz band and the channel data rate is 2.4 kbits s. Iridium communication service was commer- cially available in 1998, but is no longer available since 2000 due to bankruptcy of its operator. Globalstar was deployed in 2001. The constellation consists of 48 satellites in with eight planes at an altitude of 1414 km. The data rates range from orbit inclined at 52 1.2 kbits s to 9.6 kbits s.  ◦  High-altitude aeronautical platform systems  HAPSs  are wireless infrastructures located on unmanned aircraft to provide radio access to a relatively large area on the ground [6]. HAPSs are quasi-stationary aeronautical platforms operating at 17–22 km above the earth’s surface, which is in the stratosphere layer of the atmosphere. This avoids the high cost associated with a satellite network. HAPS has been recognized as a possible high-bandwidth solution within the 3G IMT-2000 platform.  In additional to mobile communications, satellites are also used for broadcasting, such as the DVB-S  Digital Video Broadcasting Satellite  system. Satellite broadcasting uses geostationary earth orbit  GEO  satellites, since it can tolerate longer time delays and one satellite can cover one-third of the earth. GEO satellites are deployed at an altitude of 35,786 km above the equator line.  Next-generation satellite communication systems are currently being developed to sup- port multimedia and Internet-based applications [5]. For instance, the Spaceway satellite system consists of 16 GEO and 20 medium-earth-orbit  MEO  satellites operating in the Ka band and utilizing FDMA TDMA with QPSK modulation; it provides downlink rates of up to 100 Mbits s, uplink rates of 16 kbits s–6 Mbits s, and a total capacity of up to 4.4 Gbits s. Astrolink, Cyberstar, Skybridge and Celestri are also examples of this generation of satellite communication networks.  The Global Positioning System  GPS  is another popular application for satellite com- munications. It determines the position of a user, and is attractive in both military and consumer markets. GPS uses spread-spectrum code tracking circuitry to accurately track the propagation delay between the transmitter and receiver. The system has 24 GPS satel- lites in circular orbits 12,211 miles above the earth, eight satellites in each of three orbits ◦ . that are inclined 55 The orbital period of each satellite is exactly 12 hours. Each satellite uses two carrier fre- quencies at 1572.42 and 1227.60 MHz, and is differentiated by using a different Gold code. Any point on the earth is illuminated by at least four satellites.  with respect to the equator and are separated in longitude by 120  ◦  2.2 Mobile cellular networks  The mobile telecommunication network model has ﬁve basic network entities: radio systems, switching systems, location registers, processing networks, and interconnected external networks. The radio system  base station, BS  is comprised of antennas, radio transceivers, and its controller. The switching system transmits and switches the trafﬁc from end to end. The location register is a database that stores and retrieves the location      22   cid:2   An overview of wireless communications  and service information of the users. The processing center provides a computing platform to enhance the capabilities of the network.  The network structure consists of three fundamental components: access network  AN , core network  CN , and intelligent network  IN . The access network connects the user equipment and the BS. The radio access network consists of BSs and radio network con- troller. The core network, also called ﬁxed network, handles all the internal connections. The core network consists of mobile switching center  MSC , visitor location register  VLR , home location register  HLR , authentication center  AuC , gateway MSC, etc. The intelligent network is in charge of billing, location management, roaming, handover, etc.  A general mobile cellular network includes mobile stations  MSs , BSs, and MSCs. The MSCs maintain all the mobile-related information, and are in charge of mobile handoffs. The mobile cellular network relies heavily on landline connections. For general 1G and 2G mobile communication networks, as illustrated in Fig. 2.2, the MSCs are interconnected by the PSTN or data networks for carrying trafﬁc, and by the Signaling System No. 7  SS7  signaling network for carrying signaling information. The 3G network is highly dependent on the Internet Protocol  IP  network. Each MS has its home MSC. MSCs are usually implemented with the three modules: HLR, VLR, and AuC.  The hierarchical cell structure for future mobile communications is illustrated in Fig. 2.3.  2.2.1 Circuit packet switching  The 2G networks are based on the circuit-switched telephone system. Every call is assigned a dedicated communication path and bandwidth. Each call is set up ahead of the transmission of the data. If there is no circuit available, the caller must try again at a later  BS  BS  BS  MSC  Voice data  traffic  PSTN, Data  networks  Packet data  SS7  BS  BS  BS  BS  BS  BS  MSC   cid:2 Figure 2.2  General cell network used in 1G and 2G mobile communication networks.      23   cid:2   2.2 Mobile cellular networks  Global  Wild  Macrocell  Suburban  Network  Megacell  Macrocell  Urban  Office  Picocell  Microcell   cid:2 Figure 2.3  Hierarchical cell structure for future mobile communications.  time. Circuit switching is efﬁcient for continuous data transmission such as speech com- munications. It is not efﬁcient for wireless data communications, due to their short, bursty transmissions; more often the time required for setting up a circuit connection exceeds the duration of the data transmission.  Packet switching is usually used for computer networking and wireless data communi- cations. Packet switching does not assign a physical connection for each user, but rather all users share the network bandwidth. Data are ﬁrst divided into individual packets, each containing a header, the data load and also error control information. The header consists of a ﬂag that indicates the beginning of a packet, the addresses of the source and the des- tination, and a control ﬁeld that contains packet numbering, acknowledgments, and ARQ. These packets are then transmitted and routed by the network. The user does not have to establish a connection to the destination before sending the data. At the destination, the packets are reassembled into the original message.  Most modern WAN protocols, such as TCP IP, X.25, and frame relay, are based on the packet switching technique. X.25 and frame relay employ the technique of virtual cir- cuit packet switching, while the Internet implements datagram packet switching. Packet switching is also called packet radio in case of a wireless link.  The Internet, which uses the IP network protocol, is based on packet switching. Unlike circuit switching, Internet is never busy or never refuses packets. However, a congested network may have the problem of large packet delays or packet loss. Internet offers only best-effort QoS, on a ﬁrst-come-ﬁrst-served basis for packet routing.  Signaling System No. 7  Signaling constitutes the command control infrastructure of the modern telecommunica- tion networks. The SS7 is the most widely used one for common channel signaling between      24   cid:2   An overview of wireless communications  interconnected networks, being a large set of common channel signaling protocols deﬁned by ITU-T.  SS7 is based on packet switching. It carries signaling information from end to end through multiple switching nodes. It is composed of the SS7 Network Services Part  NSP  and SS7 User Part. The SS7 NSP corresponds to the ﬁrst three layers of the OSI  Open Sys- tems Interconnect  reference model. The GSM MAP  Mobile Application Part  signaling protocol rides on top of SS7.  Internet Protocol in wireless standards  IP is a network-layer protocol that can run over any link layer and allows a variety of applications. The modularity and simplicity of IP have made it the basic networking proto- col for modern communication systems, for data communications as well as voice, video, and multimedia communications. VoIP and video over IP are emerging as strong rivals to traditional circuit-switched voice and cable TV. IP-based protocols and architecture are now the basis for the 3G and future-generation mobile communications and wireless networking.  The 3G and 4G wireless networks are on top of the Internet. To deal with the address shortage of IPv4, mobile IP addressing is employed, which is based on the IP address of the MS’s home agent and a temporary IP address called a care-of address  CoA . The home agent redirects data from the home network to the care-of address by constructing a new IP header that contains the care-of address as the destination IP address. The IPSec protocol adds security communication that IPv4 lacks.  IPv6  RFC 2460  increases the IP address size from 32 bits to 128 bits. Mobility is built into IPv6. The mobile IPv6 protocol does not require foreign agents in foreign subnets to conﬁgure the care-of address of the mobile nodes. Route optimization is an integral feature of IPv6. Mobile IPv6 uses IPSec for all its security requirements.  The IEEE 802.16 family of standards deﬁnes a convergence sublayer for asynchronous transfer mode  ATM  and packet services, but WiMAX is based on only IP and Eth- ernet  IEEE 802.3  convergence sublayer. 1xEV-DO is completely decoupled from the legacy circuit-switched wireless voice network, and this enables building all-IP 1xEV-DO networks. 3GPP LTE and WiBro support all-IP packet switching only.  2.3 Roadmap for wireless networking  The cellular wireless mobile and satellite communication systems can be treated as wire- less wide area networks  WANs , since they provide wide geographical or global coverage. Wireless WANs can also be implemented through satellites. Wireless data networks are generally classiﬁed as wireless local-area networks  LANs , wireless personal-area net- works  PANs , wireless metropolitan-area networks  MANs , and wireless regional-area networks  RANs , according to the range of coverage.      25   cid:2   2.3 Roadmap for wireless networking  Wireless LANs and wireless PANs are typically deployed in the unlicensed industrial, scientiﬁc, medical  ISM  2.4 GHz band. Wireless networking provides complementary radio access for 3G and future mobile communications.  2.3.1 Wireless local-area networks  Wireless LANs typically cover a range of a few meters to a few hundred meters. The most well-known wireless LAN standards are the IEEE 802.11 standards. Other wireless LANs are the European HiperLAN  High Performance Radio LAN  and the Japanese HiSWAN  High Speed Wireless Access Network .  IEEE 802.11 a b g n VHT  The baseline IEEE 802.11 standard, introduced in 1997, deﬁnes 1 and 2 Mbits s modes. It supports three different physical layers, namely frequency-hopping spread spectrum  FHSS , direct-sequence spread spectrum  DSSS , and infrared. The modulation for the FHSS scheme is GFSK for 1 Mbits s and 4GFSK  quaternary GFSK  for 2 Mbits s. The DSSS scheme uses DBPSK for transmission at 1 Mbits s and DQPSK at 2 Mbits s. Both of the spread spectrum schemes occupy the 2.4 GHz ISM band. The infrared physical layer has almost never been deployed, since it is severely limited by the short connection distance of 1 m and the line-of-sight  LOS  requirement.  IEEE 802.11b, also known as Wi-Fi  Wireless Fidelity , is the most popular wire- less LAN technology. It was released in October 1999. It achieves a data rate of 5.5 or 11 Mbits s, and uses complementary code keying  CCK  modulation, which is a kind of DSSS, for backward compatibility with the DSSS-based 802.11. It uses a bandwidth of 22 MHz, and covers a range of 100 meters.  IEEE 802.11a, released in October 1999, is based on OFDM technology. IEEE 802.11g, released in June 2003, is the same as 802.11a, except that 802.11a operates in the 5 GHz band while 802.11g in the 2.4 GHz ISM band. They use BPSK, QPSK, 16QAM  quadra- ture amplitude modulation  and 64QAM modulations, achieving a scalable data rate of up to 54 Mbits s. Both standards use 20 MHz bandwidth for operation, and 802.11a covers a range of 50 meters.  IEEE 802.11n, ratiﬁed on September 11, 2009, is a new generation of wireless LAN standard that achieves raw data rates of up to 300 Mbits s by combining multiple antennas, clever encoding, and coexistence of 20 and 40 MHz bands in the 2.4 and 5 GHz bands. IEEE 802.11n supports mission-critical applications with throughput, QoS and security rivaling the Ethernet standard 100Base-T. Prior to its ratiﬁcation, many draft-n products were available on the market.  It is a MIMO-OFDM system, and mandates the interoperation with the legacy 802.11a g systems. Adaptive beamforming, space–time block code  STBC , and low density parity code  LDPC  techniques are also used as options for increasing the range and reliability of communications.      26   cid:2   An overview of wireless communications  Meanwhile, since March 2007, IEEE 802.11 Working Group has been developing 802.11VHT  very high throughput  to support data rates of up to 1 Gbit s at stationary or pedestrian speeds in the 6 GHz and 60 GHz bands, for the IMT-Advanced requirements. IEEE 802.11 standards do not inherently support QoS due to the use of CSMA CA  car- rier sense multiple access with collision avoidance . To improve IEEE 802.11 standards, IEEE 802.11e was speciﬁed to provide QoS enhancement and 802.11i to provide secu- rity enhancements. On the basis of IEEE 802.11i, IEEE 802.11w increases the security for selected IEEE 802.11 management frames. The 802.11r task group is currently addressing secure fast roaming, and IEEE 802.11u is being proposed for interworking with non-802.11 networks.  HiperLANs  Under the project name Broadband Radio Access Network  BRAN , ETSI introduced its HiperLAN 1 standard in 1996 as a competitor to IEEE 802.11b. HiperLAN 1 uses FSK and GMSK modulations, achieving a maximum bit rate of 23.5 Mbits s, operating in the 5 GHz band. Like IEEE 802.11b, HiperLAN 1 uses a distributed MAC protocol based on CSMA CA.  HiperLAN 2, completed in February 2000, is another ETSI standard competing with IEEE 802.11a. The HiperLAN 2 standard was derived from 802.11a. The primary differ- ence from IEEE 802.11a arises in the medium access control  MAC  layer: HiperLAN 2 employs reservation-based TDMA TDD protocol, instead of the CSMA CA employed in IEEE 802.11a, for QoS support. Like 802.11a, it operates in the 5 GHz band with a maximum data rate of 54 Mbits s.  2.3.2 Wireless personal-area networks  Wireless PANs typically cover a short range that is below ten meters. Wireless PANs are characterized by low-cost low-power implementation. Popular wireless PAN stan- dards are the IEEE 802.15 family and ITU HomeRF. Wireless PANs typically operate in the unlicensed 2.4 GHz ISM band. They are useful in a wide variety of applications, including industrial control, public safety, automotive sensing, and home automation and networking. The concept of the wireless PAN is further extended to the wireless body area network  BAN , as wireless devices that are transported in pockets or worn on the body communicate with one another. Wireless BANs are promising in healthcare, sports and entertainment.  HomeRF  The HomeRF Shared Wireless Access Protocol  SWAP  was designed to carry voice and data within the home. HomeRF makes use of the existing PC industry infrastructure, as well as the Internet, TCP IP and Ethernet. HomeRF achieves a maximum rate of 10 Mbits s in its version 2.0 and a coverage range of 50 m. The HomeRF working group was disbanded in January 2003 after the IEEE 802.11b network became accessible and Microsoft began including support for Bluetooth in its Windows operating systems.      27   cid:2   2.3 Roadmap for wireless networking  IEEE 802.15.1  Bluetooth   The IEEE 802.15 standards include several wireless PAN standards. IEEE 802.15.1, more widely known as Bluetooth, is the most widely used wireless PAN. Its ﬁrst speciﬁcation was published in 1999. Bluetooth, developed by Bluetooth SIG  Special Interest Group , is widely used for the interconnection of consumer electronics and computer peripherals. It is based on DS-FH  direct-sequence frequency-hopping  technology, and has a channel bandwidth of 2 MHz. Depending on its maximum transmitted power, it covers a range of up to 1 m, 10 m or 100 m. Bluetooth 1.2, ratiﬁed as IEEE 802.15.1-2005, supports a data rate of 780 kbits s. Bluetooth 2.0, speciﬁed in November 2004, supports a data rate of up to 3 Mbits s. Up to eight devices can be networked in an ad hoc piconet.  Bluetooth 3.0 was approved by Bluetooth SIG on April 21, 2009. It supports data rates up to 24 Mbits s. It adds IEEE 802.11 as a high speed transport. UWB was antipated, but is missing in Bluetooth 3.0, because WiMedia Alliance announced in March 2009 that it was disbanding. In October 2009 Bluetooth SIG dropped development of UWB as part of the alternative MAC PHY, Bluetooth 3.0 High Speed solution. Bluetooth 4.0 was approved on December 17, 2009. Aiming mainly at consuming less power. It can run on a standard coin-cell battery for several years. Bluetooth 4.0 supports sending small data packets at a data rate of up to 1 Mbit s.  IEEE 802.15.3 3a  WiMedia  3c  IEEE 802.15.3 standards are used for high-rate wireless PANs. These standards use the same MAC layer, but differ in the physical layer. IEEE 802.15.3-2003, approved in June 2003, supports a scalable data rate from 11 to 55 Mbits s. It employs TDMA with QPSK, DQPSK, 16QAM, 32QAM, and 64QAM modulations. It is a single-carrier system operating in the 2.4 GHz band.  IEEE 802.15.3a, introduced in 2003, enhanced the data rate of 802.15.3 by using UWB technology. It uses three 528 MHz band between 3 and 5 GHz, and has a data rate of up to 480 Mbits s at a distance of 2 m and 110 Mbits s at 10 m. A multiband OFDM  MB-OFDM -based UWB scheme and a direct sequence-based UWB  DS-UWB  scheme were proposed, but due to strong disputes between the two parties, the IEEE P802.15 TG3a project authorization request  PAR  was withdrawn on January 19, 2006.  WiMedia is based on the MB-OFDM UWB scheme of IEEE 802.15.3a. Wireless USB shares the same UWB physical layer with WiMedia, but it addresses very differ- ent architectural goals. Both standards have been completed. Wireless USB employs the centrally-controlled piconet architecture of the 802.15 wireless PAN, while WiMedia MAC diverges from the piconet architecture. Wireless USB has its origin in USB  Universal Serial Bus  that focuses on the host and its set of associated devices. Thus, either the host role or the device role is executed in Wireless USB. In contrast, WiMedia has its origin in consumer electronics that operates in a dynamic, even mobile environment, where every device executes all required protocol functions.  Currently, IEEE 802.15.3c wireless PAN is under development, and is expected to be approved in September 2009. IEEE 802.15.3c targets a data rate of over 2 Gbits s and operates in millimeter wavebands including the 57–64 GHz unlicensed band. It is an OFDM implementation of UWB.      28   cid:2   An overview of wireless communications  IEEE 802.15.4  ZigBee  4a  The IEEE 802.15.4 standards are targeted for ultralow complexity, ultralow cost, ultralow power consumption, and low-data-rate wireless connectivity. It can be used for interac- tive toys, wireless sensor networks  WSNs , industrial control, home  ofﬁce, building, or factory  automation, and tagging and tracking. The IEEE 802.15.4 standard employs a distributed MAC protocol based CSMA CA. ZigBee does not use all abilities of IEEE 802.15.4.  IEEE 802.15.4 employs DSSS coding and OQPSK BPSK modulation. The basic chan- nel access mode speciﬁed by IEEE 802.15.4-2003 is unslotted CSMA CA. Other mech- anisms are also used for beacon transmission and message acknowledgements by using a ﬁxed timing schedule or Guaranteed Time Slots  GTS . It uses a channel of 2 MHz for operation, and achieves a data rate from 20 to 250 kbits s.  The ZigBee 1.0 speciﬁcation, ratiﬁed in December 2004, is based on IEEE 802.15.4- 2003. While IEEE 802.15.4 focuses only on the lower two layers, ZigBee also provides the upper layers for the protocol stack. ZigBee operates in the ISM radio bands, which are 868 MHz in Europe, 915 MHz in USA and Australia, and 2.45 GHz in most jurisdictions worldwide. BPSK is used in the 868 and 915 MHz bands, and OQPSK in the 2.45 GHz band. The raw data rate per channel is 250 kbits s in the 2.45 GHz band  with 16 chan- nels , 40 kbits s in the 915 MHz band  with 10 channels , and 20 kbits s in the 868 MHz band  with 1 channel . At the 2450 MHz band, OQPSK modulation is employed while the 868 915 MHz bands rely on BPSK. Transmission range can be up to 75 meters, and the maximum output power of the radios is generally 0 dBm. ZigBee Pro was approved in October 2007. ZigBee Pro adds some new application proﬁles such as automatic meter reading.  IEEE 802.15.4a is targeted for the merging market of ZigBee and active radio fre- quency identiﬁcation  RFID . IEEE 802.15.4a was completed in January 2007. The baseline consists of two optional physical schemes: a UWB impulse radio  operating in unlicensed UWB band  and a chirp spread spectrum  operating in unlicensed 2.4GHz band . The coverage can be beyond 100m. It provides communications and high-precision ranging location with an accuracy of 1 m and better.  2.3.3 Wireless metropolitan-area networks  Wireless MANs cover a range of dozens of kilometers. They are targeted at ﬁlling the gap between high-data-rate wireless LANs and high mobility cellular wireless WANs.  IEEE 802.16  WiMAX   IEEE 802.16 standards, also known as wireless MAN or WiMAX  Worldwide Interoperabil- ity for Microwave Access , provide broadband wireless access. The baseline IEEE 802.16, approved in 2001, uses the frequency band from 10 to 66 GHz. It requires LOS propaga- tion, and uses single-carrier modulation and TDMA. The baseline 802.16 has a channel      29   cid:2   2.3 Roadmap for wireless networking  bandwidth of 20, 25, or 28 MHz. IEEE 802.16a d e use the frequency band from 2 to 11 GHz, and are based on OFDM technology. IEEE 802.16a was completed in January 2003, and 802.16-2004, which consists of 802.16a d, was completed in June 2004.  WiMAX is based on 802.16-2004 and 802.16e. It is built on all-IP network architecture for plug and play network deployments. IEEE 802.16e provides support in low mobility, with speeds up to 70 km h. WiMAX can be used to connect Wi-Fi hotspots to each other or the Internet, to act as a wireless alternative for the last mile broadband services, or to provide 3.9G mobile communications. WiMAX supports a variety of QoS requirements. Multicast and broadcast services are supported in WiMAX.  WiMAX employs TDMA FDMA OFDMA with both TDD and FDD. The modulation techniques used are QPSK, 16QAM and 64QAM. IEEE 802.16a d e  WiMAX  support a scalable channel bandwidth from 1.75 to 20 MHz, with a peak data rate is 75 Mbits s, and covers a range of 70 miles. IEEE 802.16a d e deﬁne three different physical layer air interfaces: single-carrier, OFDM, and OFDMA schemes. IEEE 802.16m  WiMAX II  is targeted for completion in early 2010.  HiperMAN and WiBro  ETSI also deﬁned the HiperACCESS  High-Performance Access  standard as an alterna- tive to the baseline IEEE 802.16. Both standards operate in licensed bands between 10 and 66 GHz, and have channel bandwidths of 20 or 25  for USA , and 28 MHz  for Europe , with data rates in excess of 120 Mbits s. The baseline 802.16 employs the single-carrier modulation air interface.  The HiperMAN standard is a subset of IEEE 802.16a, due to the collaboration between ETSI and IEEE. Among the three air interfaces of IEEE 802.16a, HiperMAN uses only the OFDM scheme.  The Korean WiBro standard is based on IEEE 802.16, and provides seamless multime- dia Internet services under medium or low mobility. WiBro employs OFDMA with TDD. WiBro has joined WiMAX, and promised to harmonize with the IEEE 802.16e OFDMA scheme with a FFT size of 1,024 [7]. In June 2006, WiBro was launched for commercial services in Korea.  2.3.4 Wireless regional-area networks  Wireless broadband data services were ﬁrst employed in LMDS  Local Multipoint Dis- tribution Service  and MMDS  Multichannel Multipoint Distribution Service  in the late 1990s. LMDS was deployed at 2.5 GHz, 3.5 GHz, and millimeter wave frequency bands over a range of 3–6 km. LMDS was targeted at business users and provides a data rate of up to several hundreds Mbits s. The baseline IEEE 802.16 standard can be treated as an LMDS technology. LMDS had a rapid and short-lived success, but was phased out due to its short range and rooftop antenna installation. MMDS was deployed at 2.5 GHz to provide broadcast video services over a range of 30 to 70 km, and is now replaced by satellite TV.      30   cid:2   An overview of wireless communications  IEEE 802.22, unofﬁcially known as Wi-TV, was started in October 2004 and is now under development. IEEE 802.22, like WiMAX and LMDS, provides a point-to-multipoint service. It is also based on OFDMA. It is scheduled to have a cognitive radio-based air interface for use by license-exempt devices to share the underused UHF VHF TV bands between 54 and 862 MHz in the U.S., since the band is being vacated as broadcasters move to digital systems. It can support as far as 40 km to serve as an alternative to cable or DSL, for rural ﬁxed wireless access.  While IEEE 802.22 was targeted as a wireless RAN to complement both Wi-Fi wireless LAN and WiMAX wireless MAN, WiMAX is trying to reuse the UHF VHF band based on cognitive radio. This introduces a great advantage to WiMAX since the coverage is much wider than at the 2.4 GHz band, leading to a signiﬁcant reduction in the number of BSs.  Other broadband wireless access technologies  The high-rate wireless networks, such as IEEE 802.11, 802.16, 802.22, and 802.15.3 standards, basically provide broadband ﬁxed wireless access. High-frequency broadband ﬁxed wireless access provides cellular broadband two-way communications above 20 GHz. The high frequency demands LOS, and the atmospheric conditions signiﬁcantly inﬂu- ence the signal propagation, and this limits the range to 5 km for reliable services. Due to the wide range of spectrum available, high-frequency broadband ﬁxed wireless access is suitable for triple play, that is, fast Internet, multicasting broadcasting, and telephony. This provides each user a capacity of 15–20 Mbits s on the downlink. LMDS is such a system.  Major high-frequency broadband ﬁxed wireless access standards are ETSI HiperACESS BRAN, IEEE 802.16, DVB-RCL  Digital Video Broadcasting–Return Channel for LMDS  on the uplink, and DVB-S on the downlink.  Next-generation high-frequency broadband ﬁxed wireless access will be based on TDD rather than FDD, since TDD can signiﬁcantly increase ﬂexibility and spectral efﬁciency and cut the costs in user terminals. This technique may require adaptive power control to compensate for rain attenuation. Frequency reuse can be optimized by using the same frequencies for separate cells, separate sectors, or alternating polarization for each channel. Note that rainfall may depolarize the channel.  The evolution of wireless networking is shown in Fig. 2.4.  2.3.5 Ad hoc wireless networks  Wireless communications and networking are traditionally infrastructure-based. There are BSs, also called access points, that provide access  gateway  for MSs to a backbone wire- less network. The BSs and backbone networks perform all networking functions, and they are usually connected for better coordination. There is no peer-to-peer communication between MSs.  Recently, ad hoc wireless networks, also known as packet radio networks or multihop wireless networks, have attracted a lot of interest. Ad hoc networks are telecommunication      31   cid:2   2.3 Roadmap for wireless networking  LMDS MMDS  HiperACCESS, 802.16m  802.16, 802.16a, 802.16d  Hi−freq BFWA  802.16e  WiMax  HiperMAN, WiBro 802.22  Wi−Fi TV  802.20  Mobile Fi   802.15.3c  UWB   802.15.3a  UWB   >2 Gb s  1 Gb s  600 Mb s  110 Mb s  75 Mb s  802.11VHT  802.11n  54 Mb s  802.15.3  HiperLAN 2  802.11g 802.11a  HiperLAN 1  HiSWAN  11 Mb s  802.11b  Wi−Fi   HomeRF  802.11  1 Mb s  802.15.1  Bluetooth   250kb s  0  Wireless  PAN  802.15.4  ZigBee   10  802.15.4a  UWB   100  n x 100  70 miles  Wireless LAN  Wireless MAN  Range  m    cid:2 Figure 2.4  Evolution of wireless networking. BFWA stands for broadband ﬁxed wireless access.  networks without a pre-existing infrastructure. An ad hoc wireless network is composed of many wireless mobile nodes that self-conﬁgure to form a network “on the ﬂy”. Thus, ad hoc architectures are concerned with peer-to-peer communications. Infrastructure is not used in ad hoc wireless networks. Control and networking are processed using distributed control algorithms at each node, and multihop routing is used for packet transmission. Ad hoc networking is important for future high-performance core networks, since it provides the networks with inherent ﬂexibility and survivability, and also reduces the number of BSs required to cover a given area. In ad hoc networking, the security problem is more severe due to the distributed operation at each node.  Without the use of infrastructure ad hoc wireless networks are low cost to deploy and maintain, and also easy for network reconﬁguration. Ad hoc wireless networks can form a node hierarchy, either permanently or dynamically. However, multihop and distributed control also lead to performance degradation. The need for all the nodes to collaborate in order to perform infrastructural tasks like routing and forwarding may not be solved since there is no centralized authority: Some nodes may not cooperate to keep the network running. Energy constraints are also a challenge for the design and implementation of ad hoc wireless networks.      32   cid:2   An overview of wireless communications  Ad hoc wireless networks are especially useful for applications where infra-structure is difﬁcult to deploy rapidly, such as battleﬁeld military communications, emergency rescue, and space monitoring. They also provide a cheap alternative to their infrastructure coun- terparts for home networking. They can also be used for data networks, device networks, and sensor networks.  The MANET  Mobile Ad Hoc Networking  working group within IETF  Internet Engi- neering Task Force  is now developing IP-based protocols for ad hoc networking. Ad hoc networking is supported in IEEE 802.11, Bluetooth, 802.15.3, 802.15.4, and HiperLAN. The HiperLAN 1 is designed for ad-hoc networking that works in the 5 GHz band and is based on CSMA CA.  2.4 Other applications  2.4.1 Paging systems  Paging is a simplex system, where brief text or voice messages are sent only from the service provider to subscribers. It is a one-way, forward direction  BS-to-MS  data com- munication in packet mode. Paging is the most elementary form of mobile communication, and can work as an independent network. Communication from the user to the BS is via PSTN or other public data networks. Paging is now integrated as a service into cellular systems. The paging terminal stores and forwards voice messages.  There are several propriety systems designed by Motorola, NEC, Ericsson, and the British Post Ofﬁce. There is no single universal standard, and ITU-R has recommended several standards, including POCSAG  Post Ofﬁce Code Standard Advisory Group  pro- posed by British Post Ofﬁce in the late 1970s, Golay Sequential Code  GSC  paging system by Motorola, NEC by NTT, and RDS by Radio Data System.  Each packet starts with a dotting sequence  10101010. . .  or a preamble to establish bit timing. A word synchronization ﬁeld follows the preamble, in order to mark the beginning of message words. The synchronization word is usually selected as a sequence with good correlation properties such as Barker sequences.  PSCSAG has a transmission rate of 512 bits s using FSK modulation, and supports FSK signaling at up to 2400 bits s with a channel bandwidth of 12.5 kHz [10]. The GSC system uses a data rate of 300 bits s for word sync and address, 600 bits s for preamble and data, and FSK with a deviation of ±5 kHz. The NEC system transmits at a rate of 200 bits s using FSK with a peak deviation of ±5 kHz. The RDS system is a paging digital broadcast system which uses a channel bandwidth of 57 kHz on FM broadcast stations. It achieves a data rate of 1187.5 bits s with a deviation of ±2 kHz. Newer paging systems such as FLEX in USA and ERMES in Europe, both intro- duced in 1993, provide up to 6400 bits s by using FSK and 4FSK modulation. For FLEX, the BS transmitters are synchronized by GPS. The possible frequency devi- ations are ±1.6 KHz for FSK modulation, and ±1.6 kHz and ±4.8 kHz for 4FSK modulation.      33   cid:2   2.4 Other applications  2.4.2 Digital broadcasting systems  Broadcasting systems are now a part of a daily life. The use of AM radio, analog TV, and FM radio dates back to the ﬁrst half of the twentieth century, and these technologies are based on analog communications. In order to increase the quality of reception and increase the spectrum efﬁciency, digital broadcasting began to replace the analog broadcasting tech- niques in the past few years. As of late 2009, ten countries had completely shut down analog TV broadcasts. Many countries will shut down such broadcasts within a few years. In the USA, all high-power analog TV transmissions were turned off on June 12, 2009.  The European DAB  Digital Audio Broadcasting  standard was designed in the 1980s. It is based on the OFDM technology, and the MPEG-1 Audio Layer II codec is employed. In February 2007, DAB+ was released as an upgraded version of the system. DAB+ is approximately 4 times more efﬁcient than DAB due to the adoption of the MPEG-4 AAC+  ISO IEC 14496-3  audio codec.  The ESI DVB project was started in September 1993. The major DVB standards include DVB-S, DVB-S2  DVB-Satellite Second Generation  for satellites, DVB-C for cable, DVB-T, DVB-T2  Terrestrial DVB Second Generation  for terrestrial television, and DVB- H  DVB-Handheld  for terrestrial handhelds.2 DVB-S and DVB-C were ratiﬁed in 1994, and DVB-T was ratiﬁed in early 1997, and DVB-S2 was ratiﬁed in March 2005. DVB-T2 has been completed and is expected to be ratiﬁed in April 2009. For DVB standards, all data is transmitted in MPEG-2 transport streams with some additional constraints  DVB- MPEG . These distribution systems differ mainly in the modulation schemes and the error correcting codes used. DVB-T T2 are based on OFDM technology. DVB-S2 T2 use the H.264 MPEG4-AVC codec.  The ETSI DMB  Digital Multimedia Broadcasting, TS 102 427 and TS 102 428  stan- dard is based on the DAB standard, and has some similarity with the competing mobile TV standard, DVB-H; like DVB, DMB can be either T-DMB  Terrestrial-DMB  or S-DMB  Satellite-DMB . T-DMB uses MPEG-4 Part 10  H.264  for the video and MPEG-4 Part 3 BSAC or HE-AAC V2 for the audio. The audio and video are encapsulated in MPEG-2 TS. The ﬁrst DMB service started in South Korea in May 2005. In December 2007, ITU approved T-DMB and DVB-H as the global standards.  2.4.3 RF identiﬁcation  RF  radio frequency  identiﬁcation systems, also called RFIDs, are small low-cost tags on objects in order to track their positions [4]. RFID systems are now being typically deployed at low  125 kHz , medium  13.56 MHz , and high frequency  868 MHz, 2.45 GHz  bands. At 125 kHz and 13.56 MHz, inductive coupling is used to communicate between readers and tags, whereas electromagnetic coupling is used at 868 MHz and 2.4 GHz. Systems using electromagnetic coupling often have a better reading range. The ability to propagate through solid material depends on the carrier frequency, and lower frequencies give better  2 http:  www.dvb.org       34   cid:2   An overview of wireless communications  propagation than higher frequencies. RFID is continuously replacing the barcoding sys- tems, as it gets cheaper when volumes rise. RFID typically uses amplitude shift keying  ASK  and or FSK modulation.  In USA, the American National Standards Institute  ANSI ’s X3T6 group is developing a standard for operation at the 2.45 GHz band. The International Organization for Standard- ization  ISO  published ISO 11784 and 11785 for animal tracking at 135 kHz, ISO 14443 for a proximity card used for RFID at 13.56 MHz, and ISO 15693 and 18092 for a vicinity card  with a maximum distance of 1 to 1.5 meters  at 13.56 MHz. ISO IEC 18000, which is jointly developed by the ISO and the IEC  International Electrotechnical Commission , is a series of RFID standards for item management at all the RFID frequency bands. The EPCglobal Network has also developed the Electronic Product Code  EPC .  As a wireless system, the RFID tag contains a transceiver and an antenna. It can be either passive, active, or semi-passive. A passive tag contains no power source, and it responds only when a nearby reader powers it. Passive tags have a read distance ranging from about 10 cm  ISO 14443  up to a few meters  EPC and ISO 18000-6 , depending on the cho- sen radio frequency and antenna design. Passive tags can be manufactured with a printed antenna.  The semi-passive and active tags contain a battery, which is used to power the circuit. This leads to a greater sensitivity than that of passive tags, typically 20 dB or more. Thus, it can reach a distance that is ten times longer, or provide a better reliability. An active tag also broadcasts to the reader, thus it is much more reliable even in a very adverse RF environment, or can reach a range of 500 m, but with a shorter life. Semi-passive tags use the battery only to power the circuits, but not to broadcast a signal. Like a passive tag, a semi-passive tag uses the RF energy received from the reader to respond. The battery may also store energy from the reader.  RFIDs are gaining popularity in consumer market. Both the U.S. Department of Defense  DoD  and the world’s biggest retailer Wal-Mart are fully incorporating RFID into their supply chain and logistics. The U.S. DoD is using active RFID tags to reduce logistics costs and increase the visibility. RFID tags are also used in passports, as a replacement for the traditional barcodes  for example, in libraries , and for transportation payments and product tracking.  Wireless sensor networks  WSNs  are used for manufacturing and plant control that requires reliability, throughput, distributed control, and data synchronization. Sensor net- works are also self-organizing networks, but with a data rate typically much lower than in a telecommunication network. RFID is potentially useful in every sector of industry and commerce that require data collection. The combination of RFID and wireless sensor networking provides a total inventory asset visibility.  2.5 Open systems interconnect  OSI  reference model  Communication network design is based on a layered protocol structure. Layering enables design modularity for network design. The OSI reference model proposed by ISO and      35   cid:2   2.5 Open systems interconnect  OSI  reference model  Transmitter  Application  layer  Presentation  layer Session layer  Transport  layer  Network  layer  Data link  layer  Physical  layer  Protocol  Protocol  Protocol  Protocol  H  H  Data  H  Data  H  Data  H  Data  H  Data  Data  Data  Bitstream  T  Receiver  Application  layer  Presentation  layer Session layer  Transport  layer  Network  layer  Data link  layer  Physical  layer   cid:2 Figure 2.5  Data transmission path  Data transmission in the OSI reference model.  ITU-T is a widely accepted framework for data network protocols. It is composed of seven layers: physical, data link, network, transport, session, presentation, and application layers. A protocol stack is a set of protocols consisting of all the layers of the network.  Each layer has its speciﬁc packet format or frame structure. The protocol structure of the OSI model is shown in Fig. 2.5. At the transmitter, the data is preﬁxed with a layer header at each layer, which is used to identify the layer and apply the layer functionality, and is passed downward. At the data link layer, an additional tail is added for the channel error coding. The data is then transmitted as bitstream at the physical layer. At the receiver, the process is reversed: the headers are removed at each layer, until the original data is obtained.  Physical layer  The physical layer, also called the link layer, is responsible for reliable transmission of raw bitstreams over a point-to-point physical link such as radio frequency, microwave, or copper wires, regardless of the types of data. The physical layer deﬁnes all the electrical and physical speciﬁcations for devices. All operations associated with real signals, such as modulation, coding, diversity, multiple-antenna techniques, equalization, and spread spectrum, are in charge of the physical layer.  Data link layer  The data link layer is the second layer. It transforms the raw transmission bitstreams, which may be corrupted by interference and noise, into a stream that appears free of transmission errors to the network layer. It is also used for trafﬁc regulation when the transmitter is faster than the receiver.  The data link layer is typically subdivided into two sublayers: the access layer or MAC sublayer, and the logical link control  LLC  sublayer. The MAC sublayer is in charge of      36   cid:2   An overview of wireless communications  the allocation of bandwidth resources to multiple users. It decides which users are allowed to participate in a simultaneous transmission so as to provide service with acceptable qual- ity to each user, taking into account their QoS requirements. The upper LLC sublayer is independent of the media, and deals with addressing and multiplexing on multiaccess media, ﬂow control, error detection and packet retransmission by the ARQ protocol, and encryption. The most important data link control protocol is HDLC  High-level Data Link Control, ISO 3009, ISO 4335 . HDLC is widely used, and it is also the basis for many other important data link control protocols.  The network layer is in charge of the establishment and maintenance of end-to-end connec- tions in the network. In the network layer, a routing protocol dictates the route for a packet to arrive at its destination from a source node. Dynamic resource allocation can increase the capacity, and ﬂow control also helps to minimize the delay. These three aspects are interdependent, for QoS. IP is the network protocol for Internet.  Network layer  Transport layer  The transport layer is responsible for the end-to-end functions such as error recovery, retransmission request, reordering of packages, and ﬂow control to further strengthen error protection.  TCP  Transmission Control Protocol  and UDP  User Datagram Protocol  are the two traditional transport layer protocols in the IP network. TCP ensures reliable end-to-end transmission but has no delay bounds. UDP lacks the congestion control, and it may cause delay as well as packet loss. Neither TCP nor UDP is suitable for multimedia sessions, and Real-time Transport Protocol  RTP , deﬁned in RFC 1889, is the popular transport protocol for this purpose. RTP typically runs over UDP but provides ordering and timing information for real-time applications. TCP also assumes that all packet losses are caused by congestion and the loss rate is small. This is not valid in a wireless network, since packet errors are very frequent due to the poor channel conditions. To improve the performance of TCP in wireless networks, the link can be made more reliable by strong error correction and link-layer ARQ. Cross-layer design for improving the interaction between the link layer and higher layers helps to improve the performance.  In Fig. 2.5, if there are intermediate nodes, the intermediate nodes perform only the functions of the ﬁrst three layers, namely, physical, data link, and network layers, as the transport layer protocol functions in only the source and destination nodes to provide reliable end-to-end communications.  Session layer  The session layer controls the end-to-end dialogues connections  sessions . It establishes, manages and terminates the connections between the local and remote applications. The session layer provides protocol negotiation, protocol conﬁguration, and session state      37   cid:2   Problems  maintenance services. The session layer functions are performed by TCP in the TCP IP suite.  Presentation layer  The presentation layer establishes different syntax and semantics for application layer entities. End-to-end encryption between application entities is also a presentation layer function.  In the TCP IP suite, the MIME  Multipurpose Internet Mail Extensions  format, and the TLS  Transport Layer Security  and SSL  Secure Sockets Layer  cryptographic protocols correspond to presentation layer functions. For a video network, the presentation layer is concerned with the different encoding format of the media objects, such as MPEG, AVI, and WAV.  Application layer  The application layer provides services to user-deﬁned application processes. It also issues requests to the presentation layer. The application layer produces data to transmit over the network and processes data received over the network. The application layer provides functions such as remote procedure call.  The upper application layer contains the user application programs. In the TCP IP suite, FTP  File Transfer Protocol , SMTP  Simple Mail Transfer Protocol , POP3  Post Ofﬁce Protocol  , IMAP  Internet Message Access Protocol , and HTTP  Hypertext Transfer Protocol  are user application programs. Wireless Application Protocol  WAP , devel- oped by WAP Forum, is a set of standards for accessing online services from mobile devices.  Problems  2.1 Assume the energy of a battery for a cellular phone is 2 Amp-hour. If the cellular phone draws 30 mA in idle mode and 250 mA during a call, what is the battery life if the phone is on and has 2 3-minute calls every day?  2.2 Name all the possible applications you can think of for wireless communications.  2.3 Give the reasons that FM, rather than AM, is used in the 1G systems.  2.4 Tabulate all the cellular communication standards by listing the channel bandwidth, channel spacing, peak data rate, typical data rate, modulation type, duplexing, standard body, maximum number of concurrent users.  2.5 A cellular system uses FDMA with a spectrum allocation of 12.8 MHz in each direc- tion, a guard band of 10 kHz at the edge of the allocated spectrum, and a channel bandwidth of 30 kHz. How many channels are available?      38   cid:2   An overview of wireless communications  2.6 A GEO satellite is in an equatorial orbit with orbital period ts = 24 h. It appears stationary over a ﬁxed point on the earth surface. Verify that the altitude of a GEO satellite is 35,784 km.  2.7 What are the goals of 4G wireless systems? Name the enabling techniques for achieving these goals.  References  [1] D. Astely, E. Dahlman, P. Frenger, R. Ludwig, M. Meyer, S. Parkvall, P. Skillermark, & N. Wiberg, A future radio-access framework. IEEE J. Sel. Areas Commun., 24:3  2006 , 693–706.  [2] A. C. Clark, Extraterrestrial relays. Wireless World, 51  1945 , 305–308. [3] L. F. Eastwood, Jr., S. F. Migaldi, Q. Xie, & V. G. Gupta, Mobility using IEEE 802.21 in a heterogeneous IEEE 802.16 802.11-based, IMT-Advanced  4G  network. IEEE Wireless Commun., 15:2  2008 , 26–34.  [4] K. Finkenzeller, RFID Handbook: Fundamentals and Applications in Contactless  Smart Cards and Identiﬁcation, 2nd edn  Chichester, England: Wiley, 2003 .  [5] M. Ibnkahla, Q. M. Rahman, A. I. Sulyman, H. A. Al-Asady, J. Yuan, & A. Safwat, High-speed satellite mobile communications: technologies and challenges. Proc. IEEE, 92:2  2004 , 312–339.  [6] S. Karapantazis, F.-N. Pavlidou, Broadband communications via high-altitude plat-  forms: a survey. IEEE Commun. Surv. & Tutor., 7:1  2005 , 2–31.  [7] W. Konhauser, Broadband wireless access solutions – progressive challenges and potential value of next generation mobile networks. Wireless Pers. Commun., 37  2006 , 243–259.  [8] J. Mitola, The software radio architecture. IEEE Commun. Mag., 33:5  1995 , 26–38. [9] S. Ortiz, Jr., 4G wireless begins to take shape. IEEE Computer, 40:11  2007 , 18–21. [10] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall PTR, 2002 .      3  Channel and propagation  3.1 Propagation loss  The underpinning principle for electromagnetic wave propagation is Maxwell’s equations. Examples of solutions of Maxwell’s equations over very large terrain proﬁles can be found in [73, 81]. However, due to the complex environment of wireless channels that pro- duce reﬂected, diffracted, or scattered copies of the transmitted signal, analysis based on Maxwell’s equations is extremely complex and also impractical since it has to be based on a lot of assumptions. This section describes a number of models, mainly empirical models, for estimating the propagation loss.  3.1.1 Free-space loss   cid:2    cid:3 2  ,  Pr d  ≈ PtGtGr  λ  4πd  In free space, the propagation loss from the transmit antenna to the receive antenna can be derived by the Friis power transmission equation [55]   3.1   where d is the distance between the transmit and receiver antennas, Gr and Gt are the gains of the receive and transmit antennas, respectively, Pt, Pr are the transmitted and received −2. power, and λ is the wavelength of the carrier frequency. Thus, the power decays as d  In the logarithmic form, we have the free-space loss  Lfs d  = PtGtGr Pr  = −147.6 + 20 log10 d + 20 log10 f   dB ,   3.2   where f is the transmission frequency. Thus, the free-space loss increases by 20 dB, if the distance increases by ten times. The free-space loss model is only suitable for a LOS path with no reﬂection multipath, such as in the case of satellite communications.  3.1.2 Plane earth loss model  −4 power law, is a popular empirical law in wireless The plane earth loss model, as a d communications [25, 46, 56, 62]. Measurement in macrocells typically gets a path loss exponent that is close to 4.      40   cid:2   Channel and propagation  ht  d1  d2  hr  d  Ground   cid:2 Figure 3.1  Physical model for plane earth loss.  The model assumes a main path accompanied by a ground-reﬂected path, as shown in  Fig. 3.1.  The distance difference of the two paths d2 and d1 is given by  d2 − d1 ≈ 2hthr d  ,   3.3    cid:2   The path loss can be expressed by  where d is the ground distance between the transmit and receive antennas, and ht, hr are the heights of the transmit and receive antennas, respectively.   cid:3 2 cid:4  cid:4  cid:4 1 + Re jβ 2hthr 4πd where R is the reﬂection loss, and β = 2π  cid:3 2 cid:5   cid:2  , the magnitude of the Since the angle of incidence with the ground is close to 90 reﬂection coefﬁcient is close to unity. For horizontally polarized antennas, R ≈ −1, thus  λ is the wave number.   cid:3  cid:6    cid:4  cid:4  cid:4 2   cid:2   Pr Pt   3.4   =  ◦  λ  ,  d   3.5  The cosine term can be approximated as 1 − cos x ≈ x2 2 for small x. This approximation can be applied when hthr  cid:5  d. By taking the gains Gt and Gr into consideration, we have  4πd  d  .  = 2  Pr Pt  2βhthr  λ  1 − cos  cid:2    cid:3 2  .  Pr d  = PtGtGr  hthr d2  In decibels, the loss is given by Lpel = PtGtGr Pr  = 40 log10 d − 20 log10 ht − 20 log10 hr  dB .  This approximation is valid only when d is greater than a critical distance   3.6    3.7    3.8   d > dc = 4hthr  .  λ      41   cid:2   3.1 Propagation loss     Free space: d−2−law Original PEL PEL: d−4−law  0  −50  −100  −150     B d     s s o L h t a P     −200  101  102  103 d  m   104  105   cid:2 Figure 3.2  Simulation of plane earth loss for ht = 40 m, hr = 1.5 m, and f = 1800 MHz.  In this case, the received power becomes independent of the frequency and decays as the fourth power of the distance d.  Example 3.1: Given ht = 40 m, hr = 1.5 m, and f = 1800 MHz, the loss versus the distance d is plotted in Fig. 3.2, by using  3.2 ,  3.5 ,  3.7 . It shows that the plane earth loss model can be approximated by the d  −4 law when d > dc = 1440 m.  −2 law; when d > dc, it obeys the d  The critical distance dc can be used for cellular planning. When d < dc, the propagation −4 law. Thus, when the two-ray model obeys the d is suitable, this makes dc the natural size of a cell. If dc is very large, the cell size can be further shrunk for microcells in order to increase the capacity and reduce the transmit power.  3.1.3 Okumura-Hata model  The Okumura-Hata model is a good, but more complex propagation model that is based on extensive empirical measurements taken in urban environments [49], and was further approximated by Hata [29]. The model includes parameters such as frequency, frequency range, heights of the transmitter and receiver, and building density. The model is the most popular model for macrocell loss prediction. The model for urban areas was standardized in ITU-R Rec. P.529.  Based on the clutter and terrain conditions, the model varies. The loss is given by [29, 62]  L = cid:7  + cid:7  69.55 + 26.16 log10 fc − 13.82 log10 ht 44.9 − 6.55 log10 ht   cid:8  log10 d − C  dB ,   cid:8    3.9       42   cid:2   Channel and propagation   3.10    3.11    3.12   where d  in km  is the distance between the transmitter and receiver, ht  in m  is the BS height, hr  in m  is the MS height, fc  in MHz  is the carrier frequency, and C is given by  a    cid:2    cid:3   fc 28  C = 2 log2  10  + 5.4  for suburban areas,  b   for open areas, and  c   ⎧⎨⎩3.2 log2  cid:7   C =  for urban areas.  C = 4.78 log2  10 fc + 18.33 log10 fc + 40.94   11.75hr  − 4.97,  1.54hr  − 1.1,   cid:8  10 8.29 log2 1.1 log10 fc − 0.7 10  hr − cid:7    cid:8  1.56 log10 fc − 0.8  large cities, fc ≥ 300MHz large cities, fc < 300MHz  , medium or small cities  The model was intended for macrocells, and is applicable over distances of 1–100 km, frequency range 150–1500 MHz, BS height 30–200 m, and MS height 1–10 m. The model is satisfactory in urban and suburban areas, but is not that good in rural areas. This model is suitable for 1G cellular systems, but is not applicable for current cellu- lar systems that have smaller cell sizes and higher frequencies, and for indoor wireless systems.  3.1.4 COST-231-Hata model  The COST-231-Hata model is an extension of the Okumura-Hata model to 2 GHz. It is also an empirical model, and is suitable for microcells and small macrocells. This model is suitable when fc is within 1.5 GHz–2 GHz, ht is within 30–200 m, hr is within 1–10 m, and d is within 1–20 km. It is used by the ITU-R IMT-2000 standards for the outdoor case.  The COST-231 model is given by [15, 25]  Lurban = cid:7  + cid:7  46.3 + 33.9 log10 fc − 13.82 log10 ht 44.9 − 6.55 log10 ht   cid:8    cid:8   log10 d  − C + CM  dB ,   3.13   where C is the correction factor for mobile antenna height in urban areas, as deﬁned in  3.12  for small to medium-sized cities, and for larger cities at frequencies fc > 300 MHz, CM is 0 dB for medium-sized cities and suburbs, and 3 dB for metropolitan areas.  Although both the Okumura-Hata and COST-231-Hata models are speciﬁed to have a BS antenna height above 30 m, they can be used when ht is less than 30 m, as long as the surrounding buildings are well below this height. They are not suitable for microcells like urban canyons.      43   cid:2   3.1 Propagation loss  3.1.5 Other empirical models   cid:2    cid:3   d d0  The propagation loss can generally be written as a linear equation in decibels  Pr = Pt + KdB − 10γ log10   dBm ,   3.14   where K is a constant, d0 is a reference distance for the antenna far ﬁeld, γ is the path- loss exponent, and Pt, Pr are measured in dBm. In real environments, γ varies from 2.5 to 6 [53]. To avoid the scattering phenomenon in the antenna near ﬁeld, d is required to be greater than d0, and d0 is typically taken as 1–10 m for indoor environments and 10–100 m for outdoor environments. This simpliﬁed model is usually used to approximate the ﬁeld measurements. K is sometimes selected to be the free-space path gain at distance d0 [25]  K = 20 log10  λ  4πd0   dB .   3.15   Lee’s model [42] is used to predict the path loss over ﬂat terrain. It also takes into account the inﬂuence of the heights of the transmit and receive antennas, ht and hr, but it is based on measurement at 900 MHz. For suburban areas, it has a d3.84 power law. IMT- 2000 also gives the outdoor-to-indoor and pedestrian models [10], both of which lead to more loss than Lee’s model for certain scenarios. The IEEE 802.16 standardization group have proposed a path loss model for propagation in suburban environments [20].  The accuracy of these models typically has a difference of a few dB when compared with ﬁeld measurements. In industry, it is common practice to use the ﬁeld measurement and to modify the slope of the linear model over certain range of distance from the BS. These models cannot be used for microcell regions, whose distance is typically less than one mile from the BS, since other propagation phenomena dominate.  One parameter that inﬂuences the propagation loss is frequency. For millimeter waves  30–300 GHz , the attenuation is at least 20 dB more than that of a wave of 3 GHz, from the above models. Due to the small wavelength, millimeter waves cannot penetrate solid materials very well, and scattering and diffraction also occur. In addition, they suffer from foliage loss, and are signiﬁcantly inﬂuenced by atmospheric gaseous losses and weather conditions such as rain fall [43]. Due to the wide range of spectrum available, they are of increasing interest.  The Olsen-Segal model [50] has been approved for terrestrial point-to-point LOS links by ITU-R. The model takes into account both the atmospheric impairments and the ground reﬂection. It is usually used for fading-depth predictions on satellite links, where the fading depth is deﬁned as the ratio of the average signal power to the minimum signal power.  3.1.6 COST-231-Walﬁsch-Ikegami model  Although the plane earth model has a path loss exponent close to measurement, the two- path model is inapplicable since the MS typically operates without a LOS path or a ground reﬂection. In fact, in most cases, diffraction is a major propagation mechanism. A num- ber of physical models based on diffraction analysis, such as the Ikegami model [31], the      44   cid:2   ht  r   cid:2 Figure 3.3  d  b  l  Channel and propagation  Building  hroof  ϕ  Incident wave  hr  w  A typical propagation scenario in urban areas and deﬁnition of the parameters used in the COST-WI model.  ﬂat-edge model, and the Walﬁsch-Bertoni model [74], are discussed in [62]. Theoretical analysis from these physical models can also yield a path-loss exponent close to 4, but provides more insight into the propagation mechanism.  The COST-231-Walﬁsch-Ikegami  COST-WI  model combines the Walﬁsch-Bertoni model and the Ikegami model plus some empirical correction factors to improve the agree- ment with the measurements in the urban environment [15, 28].1 The model, shown in Fig. 3.3, deﬁnes more parameters, namely heights of buildings hroof, widths of roads w, building separation b, and road orientation with respect to the direct radio path ϕ.  In the LOS case, when a mobile antenna is within a street canyon, a simple propagation  loss formula based on measurement, and different from free space loss, is applied:  L = 42.6 + 26 log10 d + 20 log10 fc   dB ,  where d is in km and fc is in MHz.  For the non-LOS case, the total loss is given by L = Lfs + Lmsd + Lrts   dB ,   3.16    3.17   where Lfs is the free-space loss, Lmsd is the loss of multiple-screen diffraction to the top of the ﬁnal building, and Lrts, the rooftop-to-street loss, is for the single diffraction and scattering process down to the mobile at the street level. The expressions for Lmsd and Lrts for non-LOS propagation are given in [15, 62, 69].  The COST-231-Walﬁsch-Ikegami model  is applicable for frequency in the range 800–2000 MHz, ht in the range of 4–50 m, hr in the range of 1–3 m, and distance in the range from 20 m to 5 km. The model achieves the best approximation when the BS antenna height ht is much greater than the roof height of the buildings, ht  cid:7  hroof. The mean error in the estimation of the path loss is in the range of ±3 dB and the standard deviation is 4–8 dB [15]. Large prediction errors arise when ht ≈ hroof, while the performance is very poor when ht  cid:5  hroof. This model is used in ITU-R IMT-2000 standards in the form of ITU-R Rec. P.1411, but the applicable frequency is extended to 5 GHz [32]. It is also recommended by the WiMAX Forum for system modeling in case of standard non-LOS.  1 The COST-231 ﬁnal report is available at http:  www.lx.it.pt cost231 final_report.htm,  where the COST-WI model is introduced in Chapter 4.      45   cid:2   3.1 Propagation loss  3.1.7 Indoor propagation models  Indoor propagation models must be considered for PCS. Indoor radio propagation is dom- inated by the same mechanisms as the outdoor, but the conditions are more variable inside a building. House and ofﬁce buildings have different internal and external structures. The wide variety in partitions as well as their physical and electrical characteristics makes it very difﬁcult to ﬁnd a general model to a speciﬁc indoor environment. Experimental mea- surements for various common building material and indoor and in-building partitions are tabulated in [56].  ITU-R Rec. P.1238 [38] gives a total path loss model for propagation within buildings  L = 20 log10 fc + 10γ log10 r + Lf  nf   − 28   dB ,   3.18   where γ is the path loss exponent, Lf  nf   is the the ﬂoor penetration loss, which varies with the number of penetrated ﬂoors nf . Corresponding parameters are given in [38]. COST-231 also has some models for indoor multi-wall propagation and propagation into buildings [15].  For an external signal source, each ﬂoor may introduce a loss of 1.9 dB [75]. The base- ment may introduce an additional 10-dB penetration loss. Inside elevators, the signal level may drop as much as 20 dB.  Radio propagation within tunnels is also important for providing communications to people in trains and mine trolleys passing through tunnels. For very short tunnels, they can be illuminated by using transmit antennas at both ends. For long tunnels, a leaky feeder radiator runs along the whole length of the tunnel to provide illumination. The major sources of attenuation are the bends and obstructions in the tunnels. Radio propagation in tunnels and mines has been studied for the frequency range 438 MHz to 24 GHz [18]. In an underground mine tunnel channel, the path amplitude distribution tends to follow a Rice distribution in the LOS case, and a Rayleigh distribution otherwise [9].  In an indoor wideband wireless body-to-body MIMO channel for wireless PANs, the measured path-loss exponent is less than 2.0, and the log-normal distributed shadowing has a standard deviation of 4.8 dB [78]. These indicate that body shadowing causes a prominent power loss in short-range body-to-body communications. The small path-loss exponent is associated with the scattering environments.  For wireless BANs, on-body channel characterization at 2.45 GHz has been investigated in [26]. Propagation measurements show that variability in the path loss due to differ- ent antenna placements and due to posture changes can be as much as 50 dB. On-body propagation channels are measured for UWB channels in [3], and at 868 MHz in [16].  A good text on propagation loss models is by Saunders and Aragon-Zavala [62], where  a detailed exposition of various propagation channels is given.  Extended Saleh-Valenzuela model  The well-known Saleh-Valenzuela indoor channel model [61] was based on measurements utilizing low power ultra-short pulses  of width 10 ns and center frequency 1.5 GHz  in a medium-size, two-story ofﬁce building [61].      46   cid:2   Channel and propagation  Overall envelope  Cluster envelope  e s n o p s e r   e s l u p m  i   l e n n a h C   cid:2 Figure 3.4  The double exponential decay of the Saleh-Valenzuela model: the mean cluster amplitude and the ray amplitude within each cluster have exponential decays.  Time  In this model, multipath components arrive in groups  clusters , or in rays within a clus- ter. Cluster arrivals are Poisson-distributed with rate  cid:8 . Within each cluster, ray arrivals are also Poisson-distributed. This model requires four parameters, namely the cluster arrival rate  cid:8 , the ray arrival rate within a cluster λ  λ >  cid:8  , the cluster decay factor  cid:9 , and the ray decay factor γ . It is further observed that clustering also takes place in the angular domain [68]. The double-exponential decay is illustrated in Fig. 3.4.  Ray-tracing  Ray-tracing or geometrical optics and the uniform theory of diffraction  UTD  techniques are usually used to approximate the accurate solution based on Maxwell’s equations. The error of geometrical optics approximation is very small when the receiver is many wavelengths away from the nearest scatter, or when all the scatters are smooth and large compared to a wavelength. The ray representation of radio propagation is especially useful at microwave and millimeter wave bands. This method is appropriate for characterizing radio wave propagation in cities, since the wavelength is much smaller compared to the dimensions of the buildings.  A number of software tools based on ray tracing are widely used for both indoor and out- door system planning: Lucent’s Wireless Systems Engineering  WiSE , Wireless Valley’s Site-Planner, and Marconi’s Planet EV.  3.1.8 Channel models in wireless standards  The European COST-259 directional channel model was developed as an empirical model for simulation of systems with multiple antenna elements at either the BS or the MS. The model takes into account small-scale as well as large-scale effects, and covers the macro,      47   cid:2   3.1 Propagation loss  micro, and picocellular scenarios. The European project COST-273 extends the COST-259 model to the double-directional case.  The COST-273 model is suitable as a space-time model. The 3GPP channel model [1], which is based on COST-273, is widely used for modeling the outdoor macro- and microcell wireless environments. It is suitable for WiMAX, and can be used for other systems such as IEEE 802.11n and 802.20, with minor modiﬁcations to the parameters.  The 3GPP channel model uses too many parameters to build a fully empirical channel model. 3GPP2 provides simpler semi-empirical channel models. It deﬁnes pedestrian A and pedestrian B models for low-mobility pedestrian mobile users  at 3 km h , and vehic- ular A and vehicular B models for higher-mobility vehicular mobile users  at 30 km h . These models deﬁne the multipath proﬁles according to the number of multipath taps, and the power and delay of each multipath component. Each multipath component is modeled as an independent Rayleigh fading, and the correlation in the time domain is due to the Doppler effect of the speciﬁed speed.  The Erceg model [19] was obtained based on extensive measurement at 1.9 GHz in 95 macrocells across the USA. It has three modes: Erceg A for hilly terrain with moderate to heavy tree density, Erceg B for hilly terrain with light tree density or ﬂat terrain with mod- erate to heavy tree density, and Erceg C for ﬂat terrain with light tree density. The Erceg model is valid for the frequency range 1900–3500 MHz, BS height 10–80 m, MS height 2–10 m, and distance 100 m–8 km. These models correspond to the six SUI  Stanford Uni- versity Interim  channel models: SUI-1 to SUI-6, with terrain type C corresponding to SUI-1 and SUI-2, terrain type B to SUI-3 and SUI-4, and terrain type A to SUI-5 and SUI-6. The Erceg model is applicable for ﬁxed wireless deployment with MS installed under the eave or on the rooftop, and has been adopted in IEEE 802.16 for ﬁxed broadband applications [20].  The IEEE 802.11 TGn models [21] are a set of models, which are an improved and standardized version of the extended Saleh-Valenzuela model, with overlapping delay clusters. The models are for indoor MIMO wireless LANs at both 2 and 5 GHz and for bandwidths of up to 100 MHz. Six canonical channels are modeled, namely, ﬂat fading, res- idential, small ofﬁce, typical ofﬁce, large ofﬁce, and large open spaces. For each canonical channel, the number of clusters, the values of the DoD  direction-of-departure  and DoA  direction-of-arrival  and the cluster angular spreads are ﬁxed, and the tap-delay proﬁles are represented in the delay domain.  The ITU channel models, unlike the 3GPP channel model, do not model any correlation between the fading waveforms across the transmit and receive antennas. These models were developed for single-input single-output channels. They are also widely used for link-level and system-level performance simulation of 1xEV-DO and HSDPA. In case of correlation of multiple antennas, correlation matrices can be multiplied with the channel matrix H at both the transmit and receive ends. More details are given in Chapter 19. ITU has speciﬁed two multipath proﬁles  A and B  for vehicular, pedestrian, and indoor channels, respectively. Channel A is suitable for urban macro-cellular environments, while channel B is suitable for modeling rural macrocells and microcells with cell radius less than 500 m. The ITU channel models are tabulated in Table 3.1 [4].      48   cid:2   Channel and propagation  Table 3.1. ITU channel models.  Model  Multipath proﬁle  μs   Relative power proﬁle  dB    <3 km h  Pedestrian A Pedestrian B  60–120 km h  Vehicular A Vehicular B Indoor A Indoor B  [0, 0.11, 0.19, 0.41] [0, 0.2, 0.8, 1.2, 2.3, 3.7]  [0, 0.31, 0.71, 1.09, 1.73, 2.51] [0, 0.3, 8.9, 12.9, 17.1, 20.0] [0, 0.05, 0.11, 0.17, 0.29, 0.31] [0, 0.1, 0.2, 0.3, 0.5, 0.7]  [0,−9.7,−19.2,−22.8] [0,−0.9,−4.9,−8.0,−7.8,−23.9] [0,−1,−9,−10,−15,−20] [−2.5, 0,−12.8,−10.0,−25.2,−16.0] [0,−3,−10,−18,−26,−32] [0,−3.6,−7.2,−10.8,−18.0,−25.2]  3.2 Channel fading  There are usually three types of channel fading for mobile communications: shadow- ing  slow fading , multipath Rayleigh fading, and frequency-selective fading. Reﬂection, diffraction, and scattering are the three major mechanisms that inﬂuence the signal propagation.  3.2.1 Log-normal shadowing  During the motion of an MS, clutter such as trees, buildings, and moving vehicles partially block and reﬂect the signal, thus resulting in a drop in the received power. In the frequency domain, there is a power decrease in a wide frequency range. Hence, it is called slow fading. The slow power variation relative to the average can be modeled by a log-normal probability distribution function  pdf .  For the log-normal distribution, the logarithm of the random variable has a normal  distribution. The pdf and cumulative distribution function  cdf  are given by  p r  =  √ 1  rσ  −  ln r−m 2 e 2σ 2  ,  2π   cid:5    cid:2    cid:3  cid:6   ln r − m 2  √  σ  D r  = Pr x < r  = 1 2  1 + erf   3.20  where m and σ are the mean and deviation, Pr ·  is the probability function, and erf x  is the well-known error function, deﬁned in Appendix A. In the shadowing model, the transmit-to-receive power ratio ψ = Pt Pr is assumed to be random with a log-normal distribution [25]  ,   3.19       49   cid:2   3.2 Channel fading   cid:12  −  ψdB − mψdB 2   cid:13   exp  2σ 2  ψdB  √  p ψ  = 10  ln 10 2π σψdB  ψ  , ψ > 0,   3.21   where ψdB = 10 log10 ψ in decibels, and mψdB, σψdB are the mean and standard deviation of ψdB. In this model, it is possible for ψ to take on a value within 0 and 1, which corre- sponds to Pr > Pt, but this is physically impossible. Nevertheless, this probability is very small when mψdB is a large and positive number. By a change of variable, the distribution of the dB value of ψ, p ψdB , is Gaussian with mψdB and σψdB.  Shadowing typically causes a standard deviation σψdB of 4–13 dB [4, 25, 64], and a typical value of σψdB is 8 dB; the mean power mψdB depends on the path loss and the surrounding. This ﬂuctuation in mean power occurs on a large scale, typically dozens or hundreds of wavelengths, and thus, is also known as large-scale fading or macroscopic fading. Statistically, macroscopic fading is determined by the local mean of a fast fading signal.  Trees cause an important class of environmental clutter. A tree with heavy foliage causes shadowing. A tree with full foliage in summer has approximately a 10 dB higher loss due to shadowing than the same tree without leaves in winter as it acts as a wave diffractor [57].  Example 3.2: Given σψdB Note that the cdf at ψ = 1.0 is very small, and is negligible as mψdB becomes larger.  = 10, the pdf of shadowing is plotted in Fig. 3.5.  = 6 and mψdB  Percentage of coverage area  The probability of coverage area, U  P0 , is deﬁned as the percentage of area with a received signal that is equal or greater than the threshold P0, given a likelihood of coverage at the cell boundary. U  P0  is deﬁned from shadowing by [39]  0.08  0.06    ψ   p  0.04  0.02   cid:2 Figure 3.5  0  0  10  20 ψ  30  40  The pdf for shadowing: σψdB = 6 and mψdB = 10.      50   cid:2   Channel and propagation   cid:14   U  P0  = 1 πR2  cid:15   1 − erf a  + e √  where dA is an incremental area, Pr is the average received power, and R is the radius of a cell.  Pr  Pr r  > P0  dA,   3.22    cid:5   1−2ab b2  1 − erf   cid:3  cid:6  cid:16    cid:2   1 − ab  b  ,   3.23   U P0  is derived as [39, 56] U  P0  = 1 2  √  , b = 10n log10 e  where a = Pr r −P0 , n the path-loss exponent, and σ the standard deviation, in decibels. In the special case when the average received level at the cell boundary Pr R  = P0, U  P0  is given as  2  2  σ  σ   cid:2    cid:3  cid:6    cid:5   U  P0  = 1 2 In this case, U  P0  is independent of P0.  1 + e  1 b2 erfc  1 b  .   3.24   Example 3.3: Given the average received level at the cell boundary Pr R  = P0, from  3.24  , the relation of U  P0  versus n σ is plotted in Fig. 3.6.  3.2.2 Rayleigh fading  Rayleigh distribution   cid:17   When both the I and Q components of the received signal, xI and xQ, are normally dis- tributed, the received signal is a complex Gaussian variable. The envelope of the received signal, r = , is Rayleigh distributed, and r2 has an exponential distribution.  + x2  x2 I  Q   cid:18 1 2  1  0.9  0.8  0.7  0.6     0 P      U  0.5  0  2  4  6  σ n  8  10   cid:2 Figure 3.6  Fraction of total area with signal above the threshold P0, U  P0 , for the average received level at the cell boundary P0.      51   cid:2   3.2 Channel fading  Note that the exponential distribution is a special case of the central-χ 2 distribution with m = 1. The χ 2 distribution is the distribution of Y = X2, where X is a Gaussian distribution.  Assuming both xI and xQ have a standard deviation of σ , the total power in the received  signal is E  r2   2 = σ 2, and we have the pdfs as   cid:19    cid:20   − r2 2σ 2 ,  pr r  = r σ 2 e  cid:21  pr2 r  = 1 2σ 2 e  0 ≤ r < ∞, − r  2σ 2 .   3.25    3.26   π  2 , and the root-mean-squared  rms  value of the distribution   cid:23    cid:22 √ The mean of r is E[r] = σ is E  = √  2σ .  r2  Example 3.4: The magnitude of a complex Gaussian random variable for σ = 1 obtained for 1,000 and 10,000 samples is shown in Fig. 3.7. It is seen that as the number of samples increases, the magnitude approximates a Rayleigh distribution.  The Rayleigh distribution has a pdf deﬁned by  3.25 , where r is the amplitude of the received signal and r2 = 2σ 2 is the predicted mean power or mean squared value of the signal amplitude. The pdf has its maximum at r = σ with its mean value at ¯r = σ π 2, and has a variance of 0.429σ 2.  √  P R  = Pr r < R  = 1 − e  − R2 2σ 2 .   3.27   The cdf is given by  For small r, P R  ≈ r2 2σ 2 .     1000 samples 10 000 samples Theoretical  1  0.8  0.6  0.4  0.2    r   p   cid:2 Figure 3.7  0    0  1  2  3  r  4  5  The Rayleigh pdf obtained by simulation.      52   cid:2   Channel and propagation  Rayleigh fading in wireless environments  For wireless communications, the envelope of the received carrier signal is Rayleigh dis- tributed; such a type of fading is thus called Rayleigh fading. This can be caused by multipath with or without the Doppler effect.  In the multipath case, when the dominant signal becomes weaker, such as in the non- LOS case, the received signal is the sum of many components that are reﬂected from the surroundings. These independent scattered signal components have different amplitudes and phases  time delays ; then, the I and Q components of the received signal can be assumed to be independent zero-mean Gaussian processes. This is derived from the cen- tral limit theorem, which states that the sum of a sufﬁcient number of random variables approaches very closely to a normal distribution. When the MS moves, the frequency shift of each reﬂected signal component that arises from the Doppler effect also has an inﬂuence on the fading. Successive drops in amplitudes occur at distances of λ 2 , that is, every time period of λ 2v , where λ is the wavelength of the carrier frequency, and v is the speed of the MS.  Since the I and Q components of the received signal are i.i.d. zero-mean Gaussian  random variables, the phase at any time instant is uniformly distributed  pφ φ  = 1  ,−π ≤ φ < π.  π   3.28   Rayleigh fading occurs very rapidly, and hence it is known as fast fading. It can cause as much as 30 to 50 dB rapid power ﬂuctuations at a scale that is comparable to one wavelength, and is thus referred to as small-scale fading.  The multipath model is commonly modeled as a two-ray model for illustrating Rayleigh  fading. The impulse response is given by [56]  h t  = α1e j θ1 t δ t  + α2e j θ2 t δ t − τ  ,   3.29   where α1 and α2 are independent random variables with a Rayleigh pdf, θ1 and θ2 are two independent random variables with uniform pdf over [0, 2π], and τ is the time delay.  The received signal is composed of multipath components. The different delays of these components lead to a multipath delay spread. If the time differences of these components are signiﬁcant compared to one symbol period, intersymbol interference  ISI  occurs. The multipath delay spread has a spectrum with null magnitudes at frequency intervals of 1 τ , where τ is the time delay. Thus, this type of fading is called frequency-selective fading. When the delay spread is much less than a symbol period, the channel is said to exhibit ﬂat fading.  Combined effect of path loss, shadowing, and Rayleigh fading  The effects of path loss, shadowing, and Rayleigh fading can be combined by adding the average path loss mψdB  characterized by the path-loss model , shadowing, and Rayleigh fading. Thus, we have  Pr Pt  = C0 − 10γ log10  − ψdB − ψ R  dB   dB ,  d d0   3.30       53   cid:2   3.2 Channel fading  Fast fading  Pr  Slow fading  Path loss   cid:2 Figure 3.8  Signal power ﬂuctuation vs. range: The combined effect of path loss  plane earth loss model , slow fading and fast fading.  dc  d  Transmitter  Path 1   d1  d2  Path 2   Receiver  α2 α1   cid:2 Figure 3.9  Geometry of the two-path model for Rayleigh fading.  where C0 is a constant that depends on the antenna and channel characteristics, d0 is a reference distance for the antenna far ﬁeld, γ is the path-loss exponent, ψdB is a zero- mean Gaussian with variance σ 2 dB is the power contribution associated with Rayleigh fading. The overall effect is illustrated in Fig. 3.8.  , which corresponds to shadowing, and ψ R  ψdB  3.2.3 Two-path model of Rayleigh fading  The simple two-path model, shown in Fig. 3.9, can be used for demonstrating Rayleigh fading. The mechanisms for multipath can arise from reﬂection, scattering, reﬂection, or diffraction. The received signal is given by  y t  = a1x  t − τ1  + a2x  t − τ2  ,   3.31  where τ1 = d1 c and τ2 = d2 c are the time delays corresponding to the two paths d1 and d2, c being the speed of light, and the coefﬁcients a1 and a2 measure the reﬂection and propagation losses of the transmitted signal x t , and thus a1, a2 ≤ 1. The two-path channel is a special case of the tapped-delay-line model, the N-tap Rayleigh fading model with N = 2.      54   cid:2   Channel and propagation  Assuming the transmit signal to be a sinusoidal wave x t  = cos 2πfct , the received signal becomes  λ is the wave number.  y t  = a1 cos  2πfct − βd1  + a2 cos  2πfct − βd2  ,  cid:18   where β = 2π If d1 − d2 = mλ, m being a nonzero integer, the sum of the two paths has its maximum  a1 + a2  cos  2πfct − τ1  at the receiver; if d1 − d2 = λ, the sum reaches its minimum  a1 − a2  cos  2πfct − τ1 . The amplitude of the received signal may be different at different receiver locations, but it does not vary at a given location.  m + 1   3.32    cid:17   2  Two-path model with Doppler  When the receiver is moving at a speed of v, the Doppler effect leads to a frequency shift of − v λ if it is mov- ing toward the transmitter. When the receiver is moving away from the transmitter, we have  λ if the receiver is moving away from the transmitter, or v   cid:18    cid:18    cid:17    cid:17   y t  = a1 cos  2π  fc − v cos α1  λ  t − βd1  + a2 cos  2π  fc − v cos α2  λ  t − βd2  ,   cid:17    cid:17    cid:18    cid:18    3.33   where α1 and α2 are the relative angles of the two paths with the moving direction. Since the speed of movement is always very small compared to the speed of light, the Doppler shift is very small. The superposition of two signals at slightly different carriers f1 and f2 vcos α1−cos α2 . This can be leads to a beating envelope with a time interval of more clearly seen by y t  = a1 cos  2πfct − β  vt cos α1 + d1   + a2 cos  2πfct − β  vt cos α2 + d2   .  3.34  Accordingly, if v  cos α1 − cos α2  t +  d1 − d2  = mλ, we get peaks. Thus, the spacing vcos α1−cos α2 . Unlike the time- between the peaks and that between the valleys are both invariant two-path model, the signal at the receiver will oscillate as it moves past each wavelength.  1f1−f2 =  λ  λ  Example 3.5: Given fc = 1 GHz, a1 = a2 = 0.45, d1 = 100 m, d2 = 160 m, α1 = 50 ◦ and α2 = 30 ◦  , the two-path signal, given by  3.34 , is illustrated in Fig. 3.10.  ,  For multiple paths, by assuming that the total power of the multipath components does ai2 = CP, where CP is a constant, not change over the region of observation, that is, and that the phases are uniformly distributed in [0, 2π], the Rayleigh distribution can be derived [46].  N i=1   cid:24       55   cid:2   3.2 Channel fading    t   y  0.5  1  0  −0.5  −1  0   cid:2 Figure 3.10  0.1  0.2  0.3  0.4  0.5  t  The received time-variant two-path signal for Rayleigh fading.  Delay dispersion  Multipath delay spread can be demonstrated by using a two-path model. If the time differ- ence  cid:18 t is signiﬁcant compared to one symbol period, ISI can occur. The delay spread in the time domain corresponds to frequency-selective fading in the frequency domain.  Let us assume that we have two multipaths of signal s t , with time delay τ1 and τ2. The  channel is given by  h τ   = a1δ  τ − τ1  + a2δ  τ − τ2  .  This leads to a spectrum of the received signal r t  to be R  f   = S  f  H  f  ,  where  H  f   = a1e whose magnitude response is given by  −j2πf τ1 + a2e  −j2πf τ2,   cid:21  a12 + a22 + 2a1a2 cos 2πf  cid:18 τ −  cid:18 φ ,  H  f   =   3.38   cid:18 τ = τ2 − τ1 and  cid:18 φ = φ2 − φ1, φ1 and φ2 being the phases of a1 and a2. This leads to dips in the transfer function, when the phase difference is  2n+ 1 180 , n being an integer. The frequency difference between two adjacent notch frequencies is  cid:18 f = 1  cid:18 τ . These fading dips also distort the phase of the signals. For multipath components with different delays, a delay-dispersive channel is thus obtained.  ◦  Selectivity indicates that the value of the signal received is changed by the channel over time or frequency. Dispersion means that the channel is dispersed, or spread out, over time or frequency. Selectivity and dispersion are dual to each other. Selectivity in time causes dispersion in frequency, and selectivity in frequency causes dispersion in time.   3.35    3.36    3.37   3.2.4 Random frequency modulation  When an MS changes its velocity vector to the BS randomly, such a motion gener- ates randomly varying Doppler frequency at the receiver. This is known as random FM.      56   cid:2   Channel and propagation  ,  p  r2   cid:3    cid:20    cid:7   r2 2σ 2  by [58]  + r2 ˙φ2+˙r2 2v2   cid:8  =  Random FM deﬁnes the performance limit of mobile communication systems for high signal-to-noise ratio  SNR .  The joint pdf of the four random variables r, ˙r, φ, ˙φ of a Gaussian process is given  r, ˙r, φ, ˙φ  cid:7  ˙φ  −  2π 2σ 2v2 e  cid:7   cid:2  r, ˙r, φ, ˙φ 1 + σ 2   cid:2   cid:19   cid:8  where σ is the same as that for Rayleigh fading, σ 2 = 1  cid:3  2 E The pdf p  ˙φ  is obtained by integrating p over r, ˙r, φ [58, 66], giving  cid:8  = 1 ˙φ2  cid:19  ˙φ2  cid:20   cid:7  ˙φR  , is inﬁnite. Thus, random FM power can be arbitrarily large unless the bandwidth is restricted. The probability density of random FM conditioned on the received envelope R, p , determines the rms band- width for a given R. The conditional pdf p has a Gaussian distribution with a standard v, and is given by [66] √  From this, the mean square value of random FM, E   cid:7  ˙φR  cid:7  ˙φ, R  cid:8   deviation μ2 = √   cid:19 ˙r2 + r2 ˙θ 2  , and v = 1 2 E   cid:8  = p  = R√   3.39    3.40    cid:7  ˙φR  − R2 ˙φ2 e   3.41    cid:8    cid:8    cid:20   r2  v2  2  p  p  σ  v  2v  .  .  .  2π v  2π v  Thus, for a deep fade in the signal envelope, the frequency deviation due to random FM increases proportionally. A fade depth of 20 dB produces a frequency deviation of 10ωmax, where ωmax is the maximum Doppler frequency in radians s. This makes coherent digital modulation more difﬁcult over fast fading mobile radio channels.  3.2.5 Ricean fading  When a strong stationary path such as a LOS path is introduced into the Rayleigh fading environment, the fading becomes Rice-distributed fading. Ricean fading is suitable for characterizing satellite communications or in some urban environments. Ricean fading is also a small-scale fading. In this case, the probability of deep fades is much smaller than that in the Rayleigh-fading case.  Based on the central limit theorem, the joint pdf of amplitude r and phase φ may be  derived as [46]   cid:19    cid:20   pr,φ r, φ  = r  2π σ 2 e  − r2+A2−2rA cos φ  2σ 2  ,  where A is the amplitude of the dominant component and σ is the same as that for Rayleigh fading, σ 2 = 1 . This joint pdf is not separable, and the pdf of r or φ can be obtained 2 E by integrating over the other quantity. The pdf of the amplitude is a Rice distribution [59]  r2   cid:2    cid:3   pr r  = r σ 2 e  − r2+A2  2σ 2 I0  rA σ 2  ,  0 ≤ r < ∞,   3.42    3.43       where I0 x  is the modiﬁed Bessel function of the ﬁrst kind and zero order, and is deﬁned as  57   cid:2   3.2 Channel fading   cid:14   0  I0 x  = 1 2π  2π  −x cos θ dθ. e  Pr = r2 = 2σ 2 + A2.  The mean square value of r is given by   3.44    3.45   The squared-envelope r2 has a noncentral χ-square distribution with two degrees of freedom [69]. The Rice factor Kr is deﬁned as the ratio of the dominant component to the power in all the other components, Kr = A2 2σ 2 . The Rice distribution approximates the Rayleigh distri- bution as Kr  cid:5  1, and reduces to it at Kr = 0. It approximates the Gaussian distribution with mean value A as Kr  cid:7  1, and reduces to the Gaussian as Kr → ∞. The factor Kr typically shows an exponential decrease with range, and varies from 20 near the BS to zero at a large distance [53].  Example 3.6: The pdfs of the Rice, Rayleigh, and Gaussian distributions are compared in Fig. 3.11. Kr = 0 corresponds to Rayleigh fading, Kr = 40 can be used to approximate the Gaussian distribution.  The dominant component changes the phase distribution from the uniformly random distribution of Rayleigh fading to clustering around the phase of the dominant component. The stronger the dominant component, the closer the resulting phase to the phase of the dominant component. This is similar to a delta function. Flat Ricean fading channel is suitable for characterizing a real satellite link.  Kr = 0, Rayleigh  Kr = 0.1  Kr = A2 2σ2, σ2 = 1  Kr = 1  Kr = 10  Kr = 40    r     p  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0 0   cid:2 Figure 3.11  2  4  6  8  10  12  14  r  Rice distribution for different Rice factor Kr.      58   cid:2   Channel and propagation  3.2.6 Other fading models  Nakagami fading   cid:17    cid:18 m  The Nakagami distribution is another popular empirical fading model [47, 67]   cid:20    cid:19   p r  = 2  3.46   cid:9  m  ,  cid:9  ·  is the Gamma function, and m ≥ 1 2 is the fading ﬁgure. The where σ 2 = 1 2 E received instantaneous power r2 satisﬁes a Gamma distribution. The phase of the signal is uniformly distributed in [0, 2π , which is independent of r.  r2m−1e  r ≥ 0,  m 2σ 2  −m r2 2σ 2 ,  r2  The Nakagami distribution is a general model obtained from experimental data ﬁtting. The Nakagami distribution has a shape very similar to that of the Rice distribution. The shape parameter m controls the severity of fading. When m = 1, its pdf reduces to that of a Rayleigh fading. When m → ∞, it becomes the additive white Gaussian noise  AWGN  channel, that is, there is no fading. When m > 1, the fading is close to Ricean fading, and the Nakagami and Rice distributions can approximate each other with  Kr =  m − 1  + cid:25   m m − 1 , m > 1,   3.47    3.48   The Nakagami distribution has a simple dependence on r, and thus is often used in tractable analysis of fading performance [67]. When the envelope r is assumed to be Nakagami distributed, the squared-envelope r2 has a Gamma distribution [4, 69]. The Nakagami distribution is capable of modeling more severe fading than Rayleigh fading by selecting 1 < m < 1. However, due to the lack of physical basis, the Nakagami distribution 2 is not as popular as the Rayleigh and Ricean fading models in mobile communications.  m =  Kr + 1 2 2Kr + 1  .  Suzuki fading  The Suzuki model [70] is a statistical model that gives the composite distribution due to log-normal shadowing and Rayleigh fading. This model is particularly useful for link performance evaluation of slow moving or stationary MSs, since the receiver has difﬁculty in averaging the effects of fading. It is widely accepted for the signal envelope received in macrocellular mobile channels with no LOS path.  Many other fading channel models are discussed in [67].  3.2.7 Outage probability  Fading channels lead to an oscillating SNR at different locations, and a mobile user will experience rapid variations in SNR, γ . An average SNR can be used to characterize the channel and to compute the BER. For many applications, BER is not the primary concern as long as it is below a threshold. A more meaningful measure is the outage probability,      59   cid:2   3.2 Channel fading  Pout, which is the percentage of time that an acceptable quality of communication is not available. Pout can be calculated by the minimum SNR for the system to work properly. This minimum SNR, γmin, can be calculated from the minimum acceptable BER, Pb,min. In this case  Pout = Pr  γ < γmin  =  pγ  γ  dγ ,   3.49    cid:14  γmin  0  where pγ  γ   is the pdf of γ . For the frequency-ﬂat Rayleigh fading channel, γ = h2 Es  , thus  N0  Pout = 1 − e  − γmin  Es N0 .   3.50   Given a target error rate Pe, the required SNR, γmin, can be calculated, and then inserted  into  3.49  or  3.50 .   cid:17  cid:25    cid:18   Example 3.7: For BPSK signals, the BER for coherent demodulation is given by  refer to  7.55    Pb = Q where the Q-function is given in Appendix A. From this, the target γmin for Pe = 10 −6, can be calculated. The −3, 10 outage probability for different target error rates is plotted in Fig. 3.12. It is seen that for a given BER, a higher quality target  lower Pe  leads to a higher outage probability.  −5, and 10  −4, 10   3.51   2γb  ,  The outage probability Pout of a wireless channel can also be deﬁned by  Pout = cdf rmin  = Pr  r < rmin  ,   3.52      100  10−1  t u o P  10−2    0  Pe = 10−3 Pe = 10−4 Pe = 10−5 Pe = 10−6   cid:2 Figure 3.12  Outage probability for BPSK in the frequency-ﬂat Rayleigh fading channel.  5  10  20  25  30  15 b  dB   γ      60   cid:2   Channel and propagation  where rmin is the minimal detected signal envelope. Given an outage probability, the mean power 2σ 2 can be accordingly calculated. The outage probability can also be deﬁned by the probability that the received power at a distance is below the minimum power that is acceptable.  3.3 Doppler fading  Multipath components lead to delay dispersion, while the Doppler effect leads to frequency dispersion for a multipath propagation. Doppler spread is also known as time-selective spread. Frequency-dispersive channels are known as time-selective fading channels. Sig- nals are distorted in both the cases. Delay dispersion is dominant at high data rates, while frequency dispersion is dominant at low data rates. The two dispersions are equivalent, since the Fourier transform can be applied to move from the time domain to the frequency domain. These distortions cannot be eliminated by just increasing the transmit power, but can be reduced or eliminated by equalization or diversity.  3.3.1 Doppler spectrum  For a moving MS, different multipath components arrive from different directions, and this gives rise to different frequency shifts ν, leading to a broadening of the received spectrum. Assuming a statistical distribution of the multipath component direction θ, pθ  θ , and the antenna pattern G θ , the Doppler spectrum is derived as [46, 56, 62]  ⎧⎨⎩  cid:20 [pθ  θ G θ +pθ  −θ G −θ ]  max−ν2  √  ν2  ,  0  SD ν  =  ν ∈ [−νmax, νmax] otherwise  ,   3.53   where  cid:20  is the mean power of the arriving ﬁeld, and νmax = fcv c is the maximum fre- quency shift due to the Doppler effect, v being the speed of the MS. Note that waves from directions −θ and θ have the same Doppler shift. According to the Clarke or Jakes model, the angle distribution of scattering is assumed to be uniform from all azimuthal directions, that is, pθ  θ  = 1 2π , for a symmetrical antenna like a dipole; this leads to  This spectrum has a U-shape, and is known as the classical Doppler or Jakes spectrum. It can be derived via the Wiener-Khintchin theorem, that is, the Fourier transform of the auto- correlation of the complex envelope of  cid:21   f ; t  of the received signal. The autocorrelation function  ACF  is given by [22, 69]   cid:19   φc  cid:18 t  = E   cid:21 ∗    f ; t  cid:21   f ; t +  cid:18 t    cid:20  =  cid:20 J0  2π νmax cid:18 t  ,   3.54    3.55   SD ν  =   cid:25   π  G θ  cid:20  ν2 max  − ν2  .      61   cid:2   3.3 Doppler fading  νmax = 1 Hz νmax = 10 Hz  2  1.5     ν       D S  1  0.5   cid:2 Figure 3.13  0 −1  −0.5  0  ν νmax  0.5  1  Doppler spectrum for G θ  cid:5  = 1.  where J0 ·  is the zero-order Bessel function of the ﬁrst kind −jx cos θ dθ. e  J0 x  = 1   cid:14  π  π  0   3.56   This leads to a nonuniform spectrum, and singularities at the maximum and mini- mum Doppler frequencies. The frequency dispersion can lead to transmission errors for narrowband systems and OFDM.  Note that the Jakes spectrum is derived from the 2-D isotropic scattering model, and thus is not applicable to microcells that are deployed in dense urban areas, where the streets and buildings along the streets guide the wave within a very narrow angle.  Example 3.8: From  3.54 , by setting G θ  cid:20  = 1, the Doppler spectra for νmax = 1 and 10 Hz are plotted in Fig. 3.13.  Example 3.9: Assume there are 200 random paths with maximum Doppler shift ν = 200 Hz with random moving direction αn and random delay τn. A typical illustration of the received signal envelope is shown in Fig. 3.14. Applying the fast Fourier trans- form  FFT  on the received signal leads to the Doppler power spectrum density, and the result of a typical run is shown in Fig. 3.15. The spectrum is very similar to the theoretical spectrum.  The classical U-shape spectrum cannot specify the peak value and has a ﬁxed spectral width of 2νmax, whereas the measured spectrum reaches a peak near the maximum Doppler frequency and then decays to zero. The extended Clarke’s model introduces ﬂuctuating      62   cid:2   Channel and propagation   cid:2 Figure 3.14  10  20  30  40  50  t  ms   Simulation of Doppler fading with 200 scatters.     B d     e p o l e v n E  20  10  0  −10  −20  −30  0  1.2  1  0.8  0.6  0.4  0.2    f   D S      cid:2 Figure 3.15  0 −400  −200  0  f  Hz   200  400  Simulated Doppler spectrum for 200 scatters.  component phases, and its statistical properties are essential for accurate spectral analysis and channel simulations. The extended Clarke’s model has the ACF [22]  φc  cid:18 t  =  cid:20 e  −B cid:18 t 2J0  2π νmax cid:18 t  ,   3.57   where B is a positive constant with the dimension of frequency, which determines the correlation time scale of the component phase process. As B → 0, i.e., in case of absence of ﬂuctuations in component phases, the exponential term approaches unity and the ACF of the fading approaches that for the Clarke’s model. Estimation of B from the measured data can be obtained by applying statistical information geometric techniques [22].  The power spectrum of the fading process is derived as [22]  SD  f   =  cid:20   π  B   B 2 2 + [2π ν − λ ]2  − λ2  dλ.   3.58    cid:14  νmax  −νmax  1 cid:25   ν2 max      63   cid:2   3.3 Doppler fading  3.3.2 Level crossing rates  From the Doppler spectrum, the occurrence rate of fading dips, known as the envelope level crossing rate  LCR , and the average duration of fades can be derived [39, 46, 62, 69]. LCR is deﬁned as the number of positive-going crossings of a reference level in unit time, while average duration of fades is the average time for the envelope being below a speciﬁed level. Similar to LCR, the zero-crossing rate  ZCR  is deﬁned as the average number of positive-going zero-crossings per second for a signal. For Ricean and Rayleigh fading, these parameters can be derived in closed form [69]. The envelope LCR at level R, LR, can be derived based on the joint pdf of the enve- lope and its slope, p  r, ˙r . For Ricean fading and 2-D isotropic scattering, LR is derived as [69]  2π  Kr + 1 νmaxρe  −Kr− Kr+1 ρ2I0   3.59  where ρ = R , rrms being the rms envelope level, and I0 ·  is the modiﬁed Bessel function of the ﬁrst kind and zero order, which is given by  3.44 . For Rayleigh fading  Kr = 0 , the expression for LR simpliﬁes to  2ρ  rrms  ,  Kr  Kr + 1   LR = cid:25    cid:17    cid:25    cid:18   LR = √  2π νmaxρe  −ρ2.   3.60   Example 3.10: The envelope LCR versus the level ρ is plotted in Fig. 3.16 for the 2-D isotropic scattering environment. It is seen that the fades are shallower for large Kr. It is also seen that at around ρ = 0 dB the envelope LCR is independent of Kr. This feature is exploited for estimation of the MS speed.  100  10−1  10−2  x a m  ν     R L  Kr = 0 1  2  4  8  16  64  10−3  −25  −20  −15  −10 ρ  dB   −5  256  0  5   cid:2 Figure 3.16  Envelope level crossing rate for Ricean fading and 2-D isotropic scattering.      64   cid:2   Channel and propagation  Assuming the received bandpass Ricean fading signal as  x t  = gI t  cos 2πfct − gQ t  sin 2πfct,  and means mI and mQ, the envelope r = cid:4  cid:4 gI t  + jgQ t   cid:17   where gI t  and gQ t  are independent Gaussian random processes with variance σ 2 Kr = gI t  − mI t  and gQ t  − mQ t  for 2-D isotropic scattering is given by [69]   cid:4  cid:4  is Ricean distributed, with    2σ 2 . Thus, the ZCR of the zero-mean Gaussian random processes  + m2   3.61    cid:18   m2 I  Q  LZ = √  2νmax.  The LCR and ZCR can be used to estimate the velocity of an MS. For a bandpass signal under the Ricean fading model, the velocity estimators are robust with respect to the Ricean factor Kr [5, 69]  ˆvZCR ≈ λc  ˆLZCR√  ,  2  ˆLRrms ˆvLCR ≈ λc √ 2πe−1  ,  whereˆ denotes the estimation, and LRrms is LR for R = Rrms. The inﬂuence of Kr and the angle of the specular component θ0 on LZCR is given in [5]. The ZCR velocity estimator is shown to be more robust than the LCR method [5].  Average duration of fades is the average time that the envelope level is below level R. The probability of the envelope level being below R is given by  3.3.3 Average duration of fades   cid:14   Pr α ≤ R  =  Pr α ≤ R  = 1 − Q   cid:14   Q a, b  = 1 −   cid:24   i ti T  ,  2 Kr + 1  ,  0  R  p α dα =  cid:25   cid:25   2Kr, ρ  b  − z2+a2  where ti is the duration of the ith continuous period that is below R, and T is the total period. For the Rice distribution, Pr α ≤ R  can be expressed by [69]  where Q a, b  is the Marcum-Q function deﬁned by   3.66  I0 ·  being the modiﬁed Bessel function of the ﬁrst kind and zero order, which is given by  3.44 .  I0 za dz,  ze  0  2  The average duration of fades is given by  where LR is given by  3.59 . Thus, we have  1 − Q  t =  √ 2π  Kr + 1 νmaxρe−Kr− Kr+1 ρ2I0  2Kr, ρ   cid:8    cid:7  2  Kr + 1  √ 2ρ   cid:8  .  Kr  Kr + 1   ¯t = P α ≤ R   cid:7 √ √  LR  ,   3.62    3.63    3.64    3.65    3.67    3.68       65   cid:2   3.4 WSSUS model  100  10−1  10−2  t  x a m  ν  Kr = 27, 16, 8, 4, 2, 1, 0  10−3  −25  −20  −15  −5  0  5  −10 ρ  dB    cid:2 Figure 3.17  Average envelope fade duration for Ricean fading and 2-D isotropic scattering: νmaxt versus ρ.  For Rayleigh fading  Kr = 0 , it reduces to  t = eρ2 − 1 √ 2π  ρνmax  .   3.69   Example 3.11: The average duration of fades for Ricean fading in the 2-D isotropic scat- tering environment, which is given by  3.68 , is plotted in Fig. 3.17. It is seen that for very deep fades  ρ is very small  each fade lasts a very short time  t is very small , and from Fig. 3.16, that the LCR is very small.  3.4 WSSUS model  Wireless channels are time-variant, with an impulse response h t, τ  , and can be mod- eled by using the theory of linear time-variant systems. Because most wireless channels are slowly time-varying, or quasi-static, this enables the use of many concepts of lin- ear time-invariant  LTI  systems. By performing the Fourier transform to the absolute time t, or the delay τ , or both, we obtain the delay Doppler-spread function S ν, τ  , the time-variant transfer function H t, f  , or the Doppler-variant transfer function B ν, f  , respectively.  The stochastic model of wireless channels is a joint pdf of the complex amplitudes for any τ and t. The ACF is usually used to characterize the complex channel. The ACF of the received signal, y t  = x t  ∗ h t, τ  , for a linear time-variant system is given by   cid:7    cid:14  cid:8  =  Ryy  t, t   cid:14  ∞   cid:14  ∞  −∞  −∞ Rxx   cid:7    cid:14  − τ cid:14  cid:8    cid:7   , τ , τ cid:14  cid:8    cid:14   Rh  t, t  t − τ , t  dτ dτ cid:14   ,   3.70       66   cid:2   where the ACFs are  Channel and propagation   cid:7   Rxx   cid:14  − τ cid:14  cid:8  = E  cid:19   cid:19  , τ , τ cid:14  cid:8  = E  t − τ , t  cid:7    cid:14   t, t  Rh  ∗  x  ∗ h   t − τ  x  cid:7    t, τ  h   cid:14   t   cid:14  − τ cid:14  cid:8  cid:20   cid:7  , τ cid:14  cid:8  cid:20   t  .  ,   3.71    3.72    3.73    3.74    3.75    3.76    3.77   A stochastic process is said to be strictly stationary if all its statistical properties are independent of time. When only the mean is independent of time while the autocorrelation depends on the time difference  cid:18 t = t  cid:14  − t, such a process is said to be a wide sense stationary process. The popular WSSUS  wide sense stationary, uncorrelated scattering  model is based on the dual assumptions: wide sense stationarity and uncorrelated scatters. The assumption of wide sense stationarity states that the ACF of the channel is determined by the difference  cid:18 t, that is,  Thus, the statistical properties of the channel do not change over time, and the signals arriving with different Doppler shifts are uncorrelated :   cid:14   t, t   cid:18 t, τ , τ cid:14  cid:8  , τ , τ cid:14  cid:8  = Rh  cid:7   cid:7  ν − ν cid:14  cid:8   cid:7  ν, τ , τ cid:14  cid:8   cid:7  , τ , τ cid:14  cid:8  = Ps  δ  .  ,  Rh   cid:7   ν, ν cid:14   Rh   cid:7   τ − τ cid:14  cid:8   ,   cid:7    cid:7    cid:14   Rh  t, t  RH   cid:14   Rh  t, t   cid:14   , τ  t, t   cid:7    cid:8   , τ , τ cid:14  cid:8  = Ph  cid:7   cid:14  cid:8  = RH  cid:7   cid:18 t; τ cid:14  cid:8   cid:7  , τ , τ cid:14  cid:8  = Ph  , f , f  t, t   cid:14   δ   cid:14    cid:8   t, t  ,  cid:18 f  .   cid:7   τ cid:14  − τ  δ   cid:8   .  where Ps is the scattering function, giving the Doppler power spectrum for a multipath channel with different path delays τ .  The assumption of uncorrelated scatters means that signals with different delays are  uncorrelated  where Ph is the delay cross-power spectral density. In the frequency domain, we have the time-frequency correlation function RH that depends only on the frequency difference  cid:18 f = f   cid:14  − f  Combining the two properties, the WSSUS model can be characterized by  This kind of stationarity is only valid for a small geographical area. For a large scale channel behavior, the WSSUS model must be examined across consecutive time intervals. This is the quasi-WSSUS model [7], which gives satisfactory results for practical channels. The WSSUS model can be implemented using tapped-delay-line models.  The scattering function Ps τ , ν  gives the average power output of the channel as a function of the time delay τ and the Doppler shift ν. It is a compact characterization of multipath-fading channel. The relationships between the autocorrelation and scattering functions can be characterized by Fig. 3.18.      67   cid:2   3.4 WSSUS model  τRh   ,     Δt  τF  ν  1 − F f− Δ F  1FΔ  −1 f  Δ tF  −1Fν −1 Δ tF FΔ f  HR Δf    ,     Δt  Fν−1  τF FΔt  τ F  t  Δ F  τF  Fν−1  f ν Δ     ,      SP  τ ν   ,      Ps  −1 FΔ f  hP  τ   σ  τ   cid:2 Figure 3.18  Relationships between the ACF and the scattering function. F and F inverse Fourier transforms.  −1 denote the Fourier and   cid:2 Figure 3.19  τ A  τ  τmax  τ  Power delay proﬁle for a typical urban environment.  3.4.1 Delay spread  The delay power spectral density or power delay proﬁle  PDP , Ph τ  , is obtained by integrating the scattering function Ps τ , ν  over the Doppler shift ν.  The PDP can be calculated by  Ph τ   = N cid:26   n=1   cid:14  ∞  −∞  Pnδ τ − τn  =  h t, τ  2dt,   3.78   where Pn = a2 n, an being the amplitude of the nth delay, and the second equality holds if ergodicity holds. First arrival delay τA is the delay of the ﬁrst arriving signal, all the other delays are known as excess delays, and the maximum excess delay τmax is the delay corresponding to a speciﬁed power threshold. A typical PDP for an urban environment is shown in Fig. 3.19.  The average WSSUS channel delay τ and the rms delay spread στ are deﬁned by  τ =   cid:27  ∞  cid:27  ∞  cid:28  cid:29  cid:29  cid:30  cid:27  ∞  cid:27  ∞  τ − τ  2 τ Ph τ  dτ  τ Ph τ  dτ 0 0 Ph τ  dτ  0  ,  τ Ph τ  dτ  0  .  στ =   3.79    3.80       68   cid:2   Channel and propagation  Table 3.2. Typical values of rms delay spreads, στ [62].  Environment  Indoor cells Mobile satellite Open area Suburban area Urban area Hilly area  στ , μs  0.01–0.05 0.04–0.05 < 0.2 < 1 1–3 3–10  Delay spread leads to frequency-selective fading, as the channel function resembles a tapped-delay ﬁlter. A general rule of thumb is that τmax ≈ 5στ . The PDP has been modeled in order to understand the channel behavior and to evaluate the performance of equalizers. There are many measurements of indoor and outdoor chan- nels [13]. The one-sided exponential proﬁle is a suitable model for both indoor and urban channels  Ph τ   = PT  − τ στ , e  τ ≥ 0,  στ   3.81   where PT is the total received power.  When the excess delay spread exceeds the symbol duration by 10% to 20%, an equal- izer may be required. The average delay and the delay spread of a channel diminish with decreasing cell size due to shorter propagation path.  Typical values for the rms delay spread are given in Table 3.2 [62]. Results from the COST-207 models, which were developed and standardized for the GSM system, gives typical rms delay spread as follows[14, 69]:   for typical urban  TU   nonhilly  area, στ = 1.0 μs,   for bad urban  BU   hilly  area, στ = 2.5 μs,   for rural area  RA   nonhilly  area, στ = 0.1 μs, and   for typical hilly terrain  HT  area, στ = 5.0 μs. Typical PDPs are deﬁned for these typical channel environments in [14].  3.4.2 Correlation coefﬁcient  The correlation coefﬁcient of two signals is usually deﬁned with respect to the signal envelopes x and y  ρ = ρxy =   cid:21  cid:7    cid:19   E  x2   cid:20  − E[x]2   cid:19  E[xy] − E[x]E[y] y2   cid:8  cid:7    cid:20  − E[y]2  E   cid:8  .   3.82   For two statistically independent signals, ρ = 0; when ρ is below a threshold such as 0.5, the signals are typically considered effectively as decorrelated.      69   cid:2   3.4 WSSUS model  For a channel with PDP of type  3.81 , assuming a classical Doppler spectrum for all the components, the correlation coefﬁcient of two signals with a temporal separation  cid:18 t and a frequency separation  cid:18 f is given by [39, 46] ρxy  cid:18 t,  cid:18 f   = J2   3.83   0   2π νmax cid:18 t  1 +  2π στ  cid:18 f  2 ,  where J0 x  is the zero-order Bessel function of the ﬁrst kind, deﬁned by  3.56 , and νmax is the maximum Doppler frequency.  Equation  3.83  is derived based on a number of assumptions including the WSSUS model, non-LOS signal, exponential shape of the power delay proﬁle, uniform distribution of incident power, and use of omnidirectional antennas. This equation can also be used for spatial separation, since the latter can be converted into temporal separation for MSs. For a typical urban channel model, the ρ values for 30 kHz  IS-136 , 200 kHz  GSM , and 5 MHz  WCDMA  frequency separation are 0.97, 0.4, and 0.001, respectively.  3.4.3 Channel coherent bandwidth  The channel coherence bandwidth Bc is deﬁned as the maximum frequency difference   cid:18 f  max that limits the correlation coefﬁcient ρ to be smaller than a given threshold, typ- ically 0.7. For instance, using  3.83 , for ρ = 0.5,  cid:18 f takes on its maximum at  cid:18 t = 0, accordingly  Due to the uncertainty relation between the Fourier transform pairs, there is an uncertainty relation between Bc and the rms delay spread στ [46]  Bc =   cid:18 f  max = 1 2π στ  .  Bc ≥ 1 2π στ  .  That is, both Bc and στ can be used to characterize the channel, and they are in inverse proportion; although usually they can be related by the approximation Bc ≈ 1 στ , they cannot be exactly derived from each other.  A wireless channel is said to have frequency coherence if it satisﬁes  H  f   ≈ constant,  fc − f ≤ Bc,  where fc is the center carrier frequency. For narrowband signals, the signal bandwidth B  cid:5  Bc; then, the fading across the entire signal bandwidth is highly correlated. Thus, the fading is roughly equal across the entire signal bandwidth. This is known as ﬂat fading. In this case, for linearly modulated signals, the symbol period Ts ≈ 1 B  cid:7  1 Bc ≈ στ , thus ISI is negligible. On the other hand, if the signal bandwidth B > Bc, the channel amplitudes at frequencies separated by more than Bc are approximately independent. Thus, the channel amplitude varies across the signal band- width B. The channel is thus known as a frequency-selective fading channel. For linearly modulated signals, Ts < στ and thus ISI cannot be neglected. When B is close to Bc, the   3.84    3.85    3.86       70   cid:2   Channel and propagation  Ph    τ  P       Δf   H  F  σt  τ  Bc  Δf   cid:2 Figure 3.20  Power delay proﬁle, frequency-ﬂat fading, and frequency-selective fading. F denotes the Fourier transform.  channel has a behavior between that of ﬂat fading and frequency-selective fading. This is depicted in Fig. 3.20  3.4.4 Doppler spread and channel coherent time  The Doppler power spectral density PB ν  is obtained by integrating the scattering function Ps τ , ν  over the time delay τ . Analogous to the derivation of the average channel delay τ and rms delay spread στ , the average Doppler shift ν and the rms Doppler spread σν can be derived as the ﬁrst- and second-order moments of PB ν . The Doppler spread corresponds to time-selective fading.  The channel coherence time Tc is also deﬁned according to  3.83 . The coherent time measures how fast the channel changes in time: A large coherent time corresponds to a slow channel ﬂuctuation. The coherence time is deﬁned in a manner similar to that of the coherent bandwidth: It is deﬁned as the time delay for which the signal autocorrelation coefﬁcient reduces to 0.7. It also has an uncertainty relationship with the rms Doppler spread σν, although usually the approximation Tc ≈ 1 σν is applied. A channel is said to have temporal coherence if a narrowband  no frequency depen-  dence , ﬁxed  no spatial dependence  channel satisﬁes  h t  ≈ constant,  t0 − t ≤ Tc,   3.87   where t0 is an arbitrary time instant.  Deﬁnitions similar to that of channel coherent bandwidth can be given with respect to the channel coherent time. For example, if the coded symbol duration is much greater than the channel coherent time, the channel is a time-selective channel.  Both Tc and Bc are used to quantize the spread of the signal correlation coefﬁcient  ρ  cid:18 t,  cid:18 f   around the origin, and are given for the classical channel by [6]  Tc = 9  16π νm  , Bc = 1 2π στ   3.88   for a correlation coefﬁcient of 0.5 [51]. The coherent time decides the maximum duration for undistorted symbols.      71   cid:2   3.4 WSSUS model  When Ts > Tc, or equivalently, B < BD, the channel impulse response h t  changes within a signal symbol duration, thus the channel is known as a fast fading channel. On the other hand, if the channel impulse response changes much slower than the symbol rate, that is, Ts  cid:5  Tc or equivalently, B  cid:7  BD, the channel is called a slow fading channel. Thus, a low data rate mobile moving at a high speed has a fast fading channel, while a high data rate mobile moving at a slow speed has a slow fading channel.  For mobile communications, ﬂat slow fading and frequency-selective slow fading are the two common channel models, since fast fading can occur only when the MS is at low data rates and is moving rapidly. Various functions for characterizing stochastic channels and their relationships are given in [40].  3.4.5 Angle spread and coherent distance  The channel model can also include the directional information such as the DoA and DoD of the multipath components into its impulse response, leading to the double-directional impulse response. Analogous to the nondirectional case, a number of power spectrums such as the double directional delay power spectrum, angular delay power spectrum, angular power spectrum, and azimuthal spread can be deﬁned [23]. Such a directional channel model is especially useful for multiple antenna systems.  Angle spread at the receiver is the spread in DoAs of the multipath components at the receive antenna array, while angle spread at the transmitter is the spread in DoDs of the multipath components that ﬁnally arrive at the receiver. Denoting the DoA by θ, the angle power spectrum or power angular proﬁle PA θ  is given by Pnδ  θ − θn  .  PA θ  = N cid:26    3.89   n=1  Analogous to the derivation of the channel delay and delay spread, the mean DoA θ and the rms angle spread σθ can be derived as the ﬁrst- and second-order moments of PA θ . The angle spread leads to space-selective fading. The coherent distance Dc is used to characterize space-selective fading, and it is calculated as the spatial separation when the correlation coefﬁcient reduces to 0.7.  A wireless channel is said to have spatial coherence if for a static narrowband channel  h r  ≈ constant,  r0 − r ≤ Dc,  where r0 is an arbitrary position in space. Spatial incoherence is caused by multipaths from many different directions. These waves create constructive and destructive interference, leading to spatial selectivity.  For receive antennas, the coherent distance is inversely proportional to the angle spread.  An approximate rule of thumb is [4]   3.90    3.91   Dc ≈ λ 5σθ  .      72   cid:2    cid:2 Figure 3.21  Channel and propagation  TX  θ  RX  Scatters around a transmitter.  The Rayleigh fading channel assumes a uniform angle spread, and the coherent distance is given by [4]  Dc ≈ 9λ 16π  .   3.92   Angle spread and coherent distance are particularly important in multiple antenna sys- tems. Dc indicates how far apart the antennas should be spaced in order for the received signals to be statistically independent. Given a target receive antenna, Dc and σθ can also be deﬁned at a transmit antenna array.  Angular spread can be derived from the scattering surrounding the transmitter. Usually the scatters are assumed to be uniformly distributed on a circle around a transmitter so that the multiple paths arrive at the receiver in a very narrow cluster [54]. This is illustrated , with the in Fig. 3.21. The power is concentrated within a small angle spread around 0 ◦ maximum power angular density at 0  ◦  .  In an indoor or a congested urban environment, all the waves are guided along the wall or the buildings along a street; extensive ﬁeld measurements show that the scattering can be modeled by a Laplace distribution [54]   cid:4  cid:4  cid:4  √   cid:4  cid:4  cid:4   − e  2θ σθ  ,  PA θ  = PT√ 2σθ   3.93   where σθ is the angular spread relative to the mean direction of scatter θ. In rural areas, ◦ σ is typically 1  , and in indoor environments it may be tens of degrees [62].  Example 3.12: Assume σθ = 20 ◦ angular spectrum as obtained from  3.93  is shown in Fig. 3.22.  and PT = 1 for an indoor environment. The power  An extension to both the PDP and PAP is the power delay-angular proﬁle, which is a  three-dimensional plot deﬁned by  Pnδ  τ − τn  δ  θ − θn  .   3.94   P τ , θ  = N cid:26   n=1  In a mobile-to-mobile communication channel, the antenna heights of both the transmit- ter and receiver are below the surrounding objects; it is thus likely that both the transmitter and receiver experience rich-scattering effects in the propagation paths. The double-ring scattering model is suitable for analyzing the mobile-to-mobile channel in Rayleigh fading [52] or in Ricean fading [77].      73   cid:2   3.5 Propagation mechanisms    θ   A P  2.5  1.5  2  1  0.5  0 −90   cid:2 Figure 3.22  −60  −30  30  60  90  0  θ  degrees   Power angular spectrum for indoor scattering.  μ1  ε1  μ2  ε2  Reflected  θr θi  Refracted θt  Incident  3.5 Propagation mechanisms   cid:2 Figure 3.23  Reﬂection and refraction: Plane wave incident onto a plane boundary. The paper plane is the scattering plane  Reﬂection, refraction, scattering and diffraction are the four important mechanisms of radio propagation. Reﬂection and refraction occur when a propagating wave impinges on an object that has very large dimensions compared to the wavelength. Scattering occurs when the wave goes through a medium composed of many small objects  in terms of wave- length . Diffraction occurs when the wave path is obstructed by a surface that has sharp edges. All these mechanisms can be analyzed by using Maxwell’s equations.  3.5.1 Reﬂection and refraction  When a plane wave is incident on a plane boundary between two media with different permeabilities μ1, μ2 and permittivities  cid:21 1,  cid:21 2, at an angle θi, the reﬂected and refracted  transmitted  waves, as shown in Fig. 3.23, can be determined by Snell’s law of reﬂection and Snell’s law of refraction, respectively      74   cid:2   Channel and propagation   cid:31  θi = θr, =  cid:21 2μ2  cid:21 1μ1  sin θi sin θt  = n2 n1  ,   3.95    3.96    3.97    3.98    3.99    3.100    3.102   where for media k  k = 1, 2 ,  = √  nk = c vk being the relative permeability,  cid:21 rk =  cid:21 k  μrk cid:21 rk  μ0  −7 henrys m,  cid:21 0 = 8.854 × 10  is the refractive index, μrk = μk the relative permittivity, vk the wave speed, μ0,  cid:21 0 the permeability and permittivity in free space, given by μ0 = 4π × 10 In addition to the direction changes of the incident wave according to Snell’s laws, the amplitudes of the reﬂected and refracted waves can be determined using electromagnetic analysis, and obtained relative to the incident wave amplitude by the Fresnel reﬂection and transmission coefﬁcients R and T. The Fresnel coefﬁcients are different, depending on whether the electric ﬁeld is parallel or normal to the scattering plane. They are given by [62]  −12 farads m.   cid:21 0  = Z2 cos θt − Z1 cos θi Z2 cos θt + Z1 cos θi = Z2 cos θi − Z1 cos θt Z2 cos θi + Z1 cos θt  ,  ,  2Z2 cos θi  Z2 cos θt + Z1 cos θi  ,  R cid:15  = Er cid:15  Ei cid:15  R⊥ = Er⊥ Ei⊥ T cid:15  = Et cid:15  Ei cid:15  T⊥ = Et⊥ Ei⊥  =  =     Z =  jωμ σ + jω cid:21   ,  2Z2 cos θi  Z2 cos θi + Z1 cos θt   3.101  where the subscripts  cid:15  and ⊥ denote the cases of the electric ﬁeld being parallel and normal to the scattering plane, respectively, E is the strength of the electric ﬁeld, the subscripts r and i denote the reﬂected and incident waves, respectively, and Z1 and Z2 are the wave impedances of the two media, and the wave impedance is calculated by  ,  σ being the conductivity.  The Brewster angle is calculated by  θB = tan  −1 n2 n1  .   3.103  At θi = θB, R cid:15  changes its polarization state. When θi < θB, R cid:15  and R⊥ are both negative, and thus reﬂection changes the polarization of the incident wave by a 180 phase change; when θi > θB, there is no phase change for the reﬂected wave. In both the cases, the axis ratio  AR  changes for circularly or elliptically polarized incident waves. Note that the Brewster angle occurs only for vertical polarization.      75   cid:2   3.5 Propagation mechanisms  s t n e i c i f f e o c   l e n s e r F  0.5  1  0  −0.5  −1    0  Rparallel Rperp Tparallel Tperp     θB  Specular direction    cid:2 Figure 3.24  Fresnel coefﬁcients for average ground at 1 GHz with σ = 0.005 S m  −1 and  cid:8 r = 15.  30  θi  60  90   cid:2 Figure 3.25  Scattering on rough surface.  Example 3.13: Figure 3.24 gives an illustration of the Fresnel coefﬁcients for average −1 and  cid:21 r = 15  at 1 GHz. In case of reﬂection from the ground, ground  σ = 0.005 S m  cid:15  corresponds to vertical polarization and ⊥ to horizontal polarization. It is seen that at θi = θB = 75.5 ◦  ◦ , R cid:15  has a 180  phase change.  3.5.2 Scattering  Scattering is an important mechanism of wave propagation, due to rough terrain surface. Scattering theory assumes the roughness of a surface to be random. Different heights of the surface lead to reﬂection  scattering  in different directions, leading to a reduction in the power of the specularly reﬂected ray. When the surface turns rougher, the incident wave is reﬂected from many points on the surface, leading to a broadening of the scattered energy. This is illustrated in Fig. 3.25.  The degree of scattering is dependent on the incident angle as well as the roughness of the surface. The roughness can be characterized by the height of two points at the surface, and the incident waves reﬂected from these points have a relative phase difference   cid:18 φ = 4π   cid:18 h λ  cos θi,   3.104       76   cid:2   Channel and propagation  where  cid:18 h is the difference in the heights at the two points, the wavelength λ characterizes the roughness of the surface, and θi is the angle of incidence. Thus, as θi becomes large, the relative phase difference decreases and the surface becomes relatively ﬂat.  The above criterion is applicable only to a single location. The Rayleigh criterion  ◦ considers a surface as smooth if this phase shift is less than 90  [62]   cid:18 h <  λ  .  8 cos θi  C = 4π σhθi  ,  λ   3.105    3.106    3.107   For a wide area, the Rayleigh criterion gives a statistical characterization of the terrain.  The roughness parameter C is deﬁned by  where σh is the standard deviation of the surface irregularity  height . Typically, the terrain is deemed as smooth if C   10, and quasi-smooth if 0.1 ≤ C ≤ 10. A scattering loss factor can be incorporated into the Fresnel reﬂection coefﬁcients to  account for the energy loss due to scattering [8, 56]   cid:18 2 where I0 ·  is the Bessel function of the ﬁrst kind and order zero.  ρs = e   cid:17  π  σh sin θi  σh sin θi 2  −8  π  I0  8  λ  λ   cid:5    cid:6   ,  3.5.3 Diffraction  Diffraction is caused by discontinuities in a surface on which an electromagnetic wave impinges. It allows radio waves to propagate around the curved surface of the Earth and to reach behind obstructions. Diffraction can be easily understood by using Huygen’s princi- ple. For diffraction analysis, if the wavelength is very small, geometrical optics is exact. For microwave propagation, diffraction analysis can be used to derive a diffraction coefﬁ- cient that estimates the power that can be received in the shadow region behind an obstacle, such as a mountain or a building or a series of mountains or buildings.  The two canonical models for diffraction analysis of a homogeneous plane wave are diffraction by a knife edge or screen and diffraction by a wedge. In these cases, the geomet- rical optics solution leads to a completely incorrect ﬁeld in the shadow region. Geometrical optics has also been extended to include diffraction, yielding the geometrical theory of diffraction.  Knife-edge or half-plane diffraction can be used to model the effect of a surrounding such as a hill. The received ﬁeld is the sum of the direct path and the diffraction path terms. Knife-edge diffraction is illustrated in Fig. 3.26, where d1 and d2 are the distances from the transmitter and the receiver to the top of the edge, respectively, and h1, h2, and h are the heights of the transmitter, receiver, and edge, respectively. The clearance between the knife-edge and the direct path is denoted by l. If l < 0, the direct path is obstructed, and only the diffraction term contributes to the received ﬁeld.      77   cid:2   3.5 Propagation mechanisms  Direct path  Diffraction path  h  1  l  h  Shadow region  h 2   cid:2 Figure 3.26  d  1  d  2  Knife-edge diffraction.   dB ,   3.108   For single knife-edge diffraction, the propagation loss due to diffraction is given by  [56, 62]  Lke = −20 log10  Ei   cid:4  cid:4  cid:4  cid:4  cid:3   cid:2  cid:4  cid:4  cid:4  cid:4  Ed F v  = 1 + j    2  v ≈ l  = −20 log10 F v   cid:14  ∞  v  2  d1 + d2  λd1d2  where Ed is the diffracted ﬁeld, Ei is the incident ﬁeld, and −jπt2 2dt. e  The parameter v, called the Fresnel-Kirchoff diffraction parameter, can be approxi- mated by   3.110  Note that F v  can also be represented using the Fresnel cosine and sine integrals C v  and S v   .   cid:2    cid:3  + C2 v  − C v  + S2 v  − S v   cid:17  π  cid:17  π  cid:18   cid:18    cid:14   x  1 2  ,  S x  =  sin  t2  dt.  2  0  cos  t2  dt,  2  F v  = 1  cid:14  2  C x  =  x  0  where   3.109    3.111    3.112   Example 3.14: By using the standard MATLAB routines for the Fresnel cosine and sine integrals C v  and S v , the knife-edge diffraction attenuation, given by  3.108 , is plotted in Fig. 3.27. The illuminated region corresponds to negative values of v, and the shadow region corresponds to positive values of v.  Diffraction by multiple screens are especially important for wireless communications, but no general exact solution is available. The Bullington method uses a single knife-edge to replace a series of screens, but this method provides very optimistic estimates of the      78   cid:2   Channel and propagation  0  −10  −20  −30  −40     B d       v    e k L −  −50  −4  −2  0 v  2  4   cid:2 Figure 3.27  Knife-edge diffraction path loss Lke v  versus Fresnel diffraction parameter v: v > 0 corresponds to shadow region and v < 0 corresponds to lit region.  received signal strength. A number of other approximate methods, such as the Epstein- Peterson method, Deygout’s method, and the ITU empirical model, are available. These models are described in [46, 62].  3.6 Atmospheric effects  The atmosphere of the Earth is divided into various layers. From the ground to a height of about 90 km, it is the troposphere  0 to about 10 km , stratosphere  about 10 to 45 km , and mesosphere  about 45 to 90 km ; from about 90 to 600 km, it is the ionosphere, which is within the thermosphere of the atmosphere. From about 600 to 10,000 km, it is exosphere. Above 600 km, it can be treated as free space. This is illustrated in Fig. 3.28.  The refractive index n of the Earth’s atmosphere is slightly greater than unity, and at the  Earth surface, it is typically 1.0003. The atmospheric refractivity N is deﬁned as  N =  n − 1  × 106.   3.113   N varies with temperature, pressure, and water vapor pressure, and these quantities vary with both location and height. According to ITU-R Rec. P.453, N varies approximately exponentially within the ﬁrst few tens of kilometers of the Earth’s atmosphere [33, 62]  N = Nse  − h H ,   3.114  where h is the height above the sea level, the surface value Ns ≈ 315, and H = 7.35 km. Variation of the refractive index with height causes the ray paths to be not straight, but tends to curve slightly towards the ground. This can somewhat extend the range of signal propagation on the earth’s surface.      79   cid:2   3.6 Atmospheric effects  10 000 km  Space  Free space  Exosphere  Thermosphere  Ionosphere   Mesosphere  Stratosphere Troposphere  600 km  90 km  45 km  10 km  Earth   cid:2 Figure 3.28  The layer model of the Earth’s atmosphere.  3.6.1 Tropospheric effects  The troposphere contains particles of a wide range of sizes and characteristics, from atmo- spheric gases to raindrops. The resulting propagation loss arises from absorption and scattering. In the troposphere, rain is the major factor for propagation loss. The ionosphere is a region of inhomogeneous and anisotropic magnetized plasma. The ionosphere is more intense during the day than during the night. Ionosphere, rain and ice crystals also result in depolarization.  Gaseous absorption  The atmosphere of the Earth introduces losses as a result of energy absorption by the atmospheric gases such as water vapor  H2O  or molecular oxygen  O2 . The attenuation, γ   f  , is measured in dB km. Attenuation due to gaseous absorption can be estimated based on ITU-R Rec. P.676.  Figure 3.29 shows the speciﬁc attenuation from 1 to 350 GHz at sea-level for dry air and ◦ water vapor with a density of 7.5 g m3 at 15 C. This ﬁgure is plotted based on the equations given in ITU.R Rec. P.676-6. It is seen that the atmospheric gases introduce substantial absorption at high frequencies. Maximum absorption occurs at frequencies that coincide with one of the molecular resonances of water or oxygen. Water vapor  H2O  has resonance frequencies at 22.3, 183.3, and 323.8 GHz, while oxygen  O2  has resonance frequencies at 60.0 and 118.74 GHz. At these frequencies, signiﬁcant absorption is observed.  In the frequency band of 57–64 GHz, there is a signiﬁcant attenuation with a peak at 60 GHz due to the presence of oxygen. At 60 GHz, molecular oxygen can lead to an attenuation of 15 dB km. Thus, this band is actually not suitable for microwave or satel- lite communications. These atmospheric effects must be considered in the link budget analysis.      80   cid:2   Channel and propagation  Water vapor Oxygen total     101  100  10−1  10−2     m k   B d     γ    n o i t a u n e t t a   c i f i c e p S  10−3    100   cid:2 Figure 3.29  ◦ Attenuation due to gaseous absorption: 15  C, water vapor density 7.5 g m3, pressure 1,013 hPa.  101 Frequency f  GHz   102  Rain fading  Attenuation arising from signiﬁcant rain intensity, measured in mm h, becomes consider- able for frequencies above 5 GHz. For network deployment, local meteorological records should be inspected for the rain intensity in mm h to calculate the link budget. Site diversity can be exploited to reduce rain fading, where an additional station at a place not covered by the rain cell provides diversity.  Propagation loss due to rain fading, when the density of the raindrops in a given region  is constant, is given by  L = 4.343αr = γRr   3.115  where r is the distance, γR = 4.343α is the loss for unit length path, and α can be obtained by using theoretical analysis, or more commonly and practically by an empirical model [37]   dB ,  γR = aRb   dB km ,   3.116   where R is the rainfall rate measured in millimeters per hour, and a and b are determined as functions of frequency  in GHz  in the range from 1 to 1000 GHz. The parameters a and b are given as power-law coefﬁcients derived from scattering calculations in ITU-R Rec. P.838 [37].  Figure 3.30 illustrates the relation between attenuation and frequency for some discrete values of rainfall rate, which is plotted based on the equations given in ITU.R Rec. P.838. The effective rain height is determined by the latitute φ of the Earth station, and is given in ITU-R Rec. P.618 [35].  3.6.2 Ionospheric effects  In case of satellite-ground radio communications, the Earth’s ionosphere has a signiﬁcant inﬂuence on the propagation of signals. For frequencies of 1 GHz and above, if the total      81   cid:2   3.6 Atmospheric effects  102  101  100  10−1  10−2  10−3  10−4     m k   B d     γ    n o i t a u n e t t  A  10−5  100  R = 200, 100, 50, 12.5, 2.5, 0.5   cid:2 Figure 3.30  Rain attenuation γ as a function of frequency f  GHz  for various rainfall rates R  mm h .  101  102  Frequency f  GHz   103  electron content  TEC  is as high as 1018 electrons per meter squared, four ionospheric effects, namely, Faraday rotation, propagation delay, dispersion, and scintillation, need to be considered [17, 62]. The ionosphere effects are strongly related to frequency, and more details are given in ITU-R Rec. P.531 [34].  TEC varies in time and space, depending on the solar disturbances and the solar cycle. When a linearly polarized wave enters an ionized medium that is inﬂuenced by an external magnetic ﬁeld, the wave is split into two oppositely rotating circularly polarized waves, with slight differences in velocities and ray paths. At a receiver outside the ionized medium, the resultant linear polarization obtained from recombining the two component waves is different from the original one in the polarization angle. This phenomenon is known as Faraday rotation. This rotation angle is very large for frequencies of 1 GHz and below. This results in serious problems when orthogonal polarizations are used to transmit two separate signals. A simple solution is to use circular polarization, and there is no Faraday rotation in this case. This makes circularly polarized antennas essential.  Faraday rotation is the integral along the path of the product of two quantities: the com- ponent of the Earth’s magnetic ﬁeld along the propagation path, and the local ionospheric electron density [17]. A simple approximation for the Faraday rotation,  cid:23 , in radians, is given by [17]   cid:23  = 1.885f  −2TEC.  The ionosphere also reduces the speed of a radio wave. Relative to the free-space  propagation delay for the same path, the ionosphere causes an additional delay [17]   cid:18 t = 40.3c  −1f  −2TEC  s ,   3.117    3.118   where c is the free-space speed. The GPS actually uses this relation for accurate ranging. From  3.118 , dispersion, deﬁned as the rate of change of the time delay with frequency, is derived as      82   cid:2   Channel and propagation  = −80.6f  −3TEC  s Hz .  dt df  This introduces a phase advance relative to free space   cid:18 φ = 8.44 × 10  −7f  −1TEC  radians   and the phase dispersion is given by  = −8.44 × 10  −7f  −2TEC  radians s .  dφ dt   3.119    3.120    3.121   Scintillation  Scintillation is the variation in the signal amplitude, phase, DoA, and Faraday rotations, caused by spatial irregularities in the refractive indices of the troposphere and the iono- sphere. The turbulence caused by the wind in the troposphere leads to rapid refractive index variations over short distances and over short time intervals. Wind present in the ionosphere causes rapid variations in the local electron density. At visible optical frequen- cies, scintillation is observed as the twinkling of stars. Rain is also a source of tropospheric scintillation.  Scintillation is not an absorptive effect as the mean power of the signal is unchanged. The intensity of the scintillation is measured by its standard deviation. The scintillation intensity can be predicted using a model described in ITU-R Rec. P.618 [35]. This effect is strong for high frequency signals.  Scintillation is easily noticeable in warm, humid climates, and is greatest in summer [62]. It is particularly severe at the time of sunset, when there is a rapid variation in the local electron density. Scintillation is most severe in the equatorial region, and in north and south high-latitude regions [17]. The inﬂuence of scintillation can be reduced by using a wide aperture antenna, because this averages the scintillation across the slightly different paths across the aperture. Spatial diversity can also be exploited to reduce the overall fade depth.  3.7 Channel sounding  There are numerous papers on channel measurements. In [2], analysis of joint statistical properties of azimuth spread, delay spread, and shadowing fading in macrocellular envi- ronments at 1.8 GHz is given, based on measurements in typical urban  TU , bad urban  BU , and suburban  SU  areas, which are according to the deﬁnitions in COST-207 [14]. The azimuth spread σA and the delay spread σD of a channel are deﬁned as the square root of the second central moments of the respective variables θ and τ . Both σA and σD are subject to the log-normal distribution  σA = 10 cid:21 AX+μA,  σD = 10 cid:21 DY+μD,   3.122       μD −6.20 −6.13 −6.08 −5.99 −6.40  cid:19    cid:21 D  0.31 0.28 0.35 0.46 0.22   3.123    3.124    3.125   Table 3.3. Measurements of azimuth spread, delay spread, and shadowing fading in different  83   cid:2   3.7 Channel sounding   cid:20  environments c cid:2 IEEE [2].  μA  0.74 0.77 0.95 0.54 0.84   cid:21 A  0.47 0.37 0.44 0.60 0.31  E [σD]  0.8 μs 0.9 μs 1.2 μs 1.7 μs 0.5 μs  σA   cid:19   E ◦ ◦  8 8 13 ◦ 7 ◦ 8  ◦  Class  TU-32 TU-21 TU-20 BU SU  σs  7.3 dB 8.5 dB 7.9 dB 10.0 dB 6.1 dB   cid:19    cid:20    cid:19   cid:20  where X, Y are zero-mean Gaussian distributed random variables with unit variance, μA = log10  σA  , E  cid:21 D = std The channel gain h can be decomposed as  are the logarithmic means, and  cid:21 A = std  are the logarithmic standard deviations.   cid:20  , μD = E  log10  σD   log10  σD   log10  σA    cid:20    cid:19   where hloss is the deterministic distance-dependent pass loss, and hs is the channel’s shadowing fading loss, which can again be modeled by a log-normal distributed random variable  where Z is a zero-mean Gaussian random variable with unit variance. Thus,  h = hlosshs,  hs = 10σsZ 10,  cid:19    cid:20   σs = std  10 log10  hs   .  According to the measurements performed in [2], the shadowing fading standard deviation σs is in the range of 6–10 dB, with the largest σs in the bad urban environment and the smallest in the suburban environment. This is in agreement with many other publications. A summary from the measurement is given in Table 3.3, wherein TU-32, TU-21, and TU-20 are typical urban environments with BS antenna heights of 31m, 21m, and 20m, respectively.  Channel measurement and modeling campaigns have also been conducted for urban spatial radio channels in macro microcell at 2.154 GHz for a bandwidth of 100 MHz [72], MIMO channels in microcell and picocell at 1.71 2.05 GHz [41], outdoor mobile chan- nels at 5.3 GHz [83], a spatio-temporal channel in a suburb non-LOS microcell [71], a MIMO wireless LAN environment at 5.2 GHz [45], a MIMO outdoor-to-indoor channel at 5.2 GHz [79], a land mobile satellite channel at Ku-band  10–12 GHz , an airport surface area channel in the 5-GHz band with a 50-MHz bandwidth [44, 65], a HAPS channel in built-up areas at 2.0, 3.5, and 5.5 GHz [30], wideband underground mine tunnel channels at 2.4 GHz and 5.8 GHz [9], a double directional UWB channel in a wooden house [27], a nomadic diversity channel at 1.9 GHz with an 80-MHz bandwidth in typical indoor ofﬁce and industrial environments [48], time-varying indoor and outdoor wideband 8× 8 MIMO      84   cid:2   Channel and propagation  channels at 2.55 and 5.2 GHz with receiver movement [76], wideband MIMO mobile- to-mobile  M-to-M  channels at 2.435 GHz for vehicular communication along streets and expressways in a metropolitan area [82], indoor wireless LAN channels at 17 GHz [60] and at 60 GHz [24, 80], an UWB channel [11], an indoor wideband  100 MHz  body-to-body MIMO channel at 5.5 GHz [78], and a UWB cooperative BAN channel [12].  Problems  3.1 For what distances is the two-ray plane earth loss model valid in a macrocell  ht = 50 m and hr = 2 m  and a microcell  ht = 10 m and hr = 2 m ? Consider the frequencies 900 MHz and 1800 MHz. 3.2 Determine the path loss by the Hata model at a frequency of 1 GHz, with ht = 50 m, hr = 2 m, and distance d = 2 km. 3.3 Refer to [15, 28], and ﬁnd the expressions for the COST-WI model. Consider the same data as in Problem 3.2, and determine the path loss for an MS on the street by the COST-WI model. Assume 10 buildings between the BS and the MS, a building separation of 40 m, ◦ 6 storeys per building, 5 m per storey, a street width of 20 m, and a road orientation of 30 with the direct radio path.  3.4 Determine the maximum Doppler shift for a mobile moving at 50 and 100 km h at frequencies of 1 GHz and 2 GHz.  3.5 From the pdf of a Rayleigh channel, derive the mean and mean square values of a Rayleigh fading signal.  3.6 Calculate the LCRs and AFDs for Rayleigh fading signal at levels of 5 dB above and below the mean envelope:  a  f = 1 GHz, v = 50 km h;  b  f = 2 GHz, v = 50 km h;  c  f = 1 GHz, v = 100 km h;  a  f = 2 GHz, v = 100 km h. 3.7 The Doppler power spectrum for the I- and Q-channels of an indoor channel is typically assumed to be uniformly distributed with a maximum Doppler shift of 10 Hz. Assuming that the PDP to be Ph τ   = 1  a  determine the autocorrelation function and then the coherent time of the channel;  b  calculate the rms delay spread and the coherent bandwidth of the channel at T = 2μs. 3.8 Assume that a laptop computer moves at a speed of 20 km h in an IEEE 802.11g wireless LAN operating at 2.45 GHz band. Determine the maximum Doppler shift and the coherent time.  , 0 < τ < T,  1 − τ   cid:7    cid:8   T  T  3.9 Calculate the Brewster angle for a wave impinging on ground of a permittivity of  cid:21 r = 3.9. 3.10 If the received power at 1 km is 1 dBm, determine the received power at 2 km, 5 km, and 20 km from the same transmitter for the path loss models:  a  free space;  b  γ = 3;      85   cid:2   Problems   c  γ = 4;  d  plane earth loss model; and  e  COST-231-Hata. Plot the models over the range of 1 km to 20 km. Assume f = 2 GHz, ht = 50 m, hr = 3 m, Gt = Gr = 1. Comment on the results.  3.11 The average PDP of a channel is given by −6 10 2n2 + 1  P τ   = 2 cid:26   n=0  δ τ − 10  −6n .  What is the local average power in dBm? What is the rms delay spread of the channel? If 16QAM modulation with a bit rate of 1 Mbits s is applied, will the signal undergo ﬂat or frequency-selective fading?  3.12 Assume two propagation paths that are identical except that each experiences an independent log-normal shadowing. A selection diversity is used at the receiver. Derive the pdf of the receiver output. 3.13 The pdf of a random variable X is p x . Let Y = aX3 + b, a < 0. Determine and plot the pdf of Y. Assume X is a Gaussian random variable with zero mean and unit variance. [Hint: pY = ∂Pr Y≤y  3.14 Determine the autocorrelation of the stochastic process x t  = A sin 2πfct + θ , where fc is a constant and θ is the uniformly distributed phase.  . ]  ∂y  3.15 In wireless communication systems, the carrier frequency in the reverse link is usually smaller than the forward link. Explain the reason. 3.16 The scattering function Ps τ , λ  is nonzero and uniform for the region 0 ≤ τ ≤ 2 ms and −0.2 Hz ≤ λ ≤ 0.2 Hz, and is zero otherwise.  a  Derive the PDP of the channel and the Doppler power spectrum.  b  Calculate the multipath spread, Doppler spread, coherent time, and coherent bandwidth of the channel.  c  For a bandwidth of 10 kHz and data transmission at 200 bits s, design a binary commu- nication system with frequency diversity: the modulation type, the number of subchannels and frequency separation, and the signaling interval.  3.17 Refer to [22], and implement a simulation of the extended Clarke’s model by using data generated from the fundamental fading model with component phase ﬂuctu- ations. Assume 200 random paths, B= 100 Hz, νmax = 100 Hz, and a sampling period of 1 ms.  a  Generate the normalized ACF and compare it with the result given by  3.57 .  b  Generate the power spectrum and compare it with the result given by  3.58 .  c  Plot the power spectrum according to  3.58  for B νmax = 0, 0.2, 0.5, and 1. 3.18 Assuming a mobile speed of 60 km h, a carrier frequency of 920 MHz and rms delay spread of 3 μs, what are the coherent time and coherent bandwidth. For IS-95, the coded symbol rate is 19.2 kbits s and the bandwidth is 1.2288 MHz; what type of fading is experienced by the IS-95 channel?      86   cid:2   Channel and propagation  3.19 The channel PDP is given as 0 dB at τ = 0, −6 dB at τ = 2 μs, −12 dB at τ = 4 μs, and −16 dB at τ = 7 μs. Draw the channel PDP. Determine the mean excess delay, rms delay spread, and maximum excess delay of the channel.  3.20 Derive the Brewster angle given by  3.103 .  3.21 A right-hand circularly polarized plane wave is incident on the boundary between dry air and dry earth. Describe the polarization of the reﬂected wave when angle of incidence θi and the Brewster angle θB are related by:  a  θi   θB. For dry air,  cid:21 1 =  cid:21 0, μ1 = μ0, σ1 = 0; for dry earth,  cid:21 2 = 2.53 cid:21 0, μ2 = μ0, σ1 = 0. Plot the Fresnel coefﬁcients.  3.22 A microwave link operating at 5 GHz with a path length of 30 km has a maximum acceptable path loss of 160 dB. The transmit antenna is 25 m above the ground level, and the receive antenna is 15 m above the ground level. A hill 80 m high, located 10 km away from the transmitter, blocks the transmission between the transmitter and the receiver. Determine the total path loss including the free space loss and the knife-edge attenuation.  3.23 A receiver can produce acceptable BERs when the instantaneous SNR is at or above 10 dB. What mean SNR is required in a Rayleigh channel for acceptable BERs for 99% of the time?  3.24 Determine the minimum symbol rate to avoid the effects of Doppler spread in a mobile system operating at 900 MHz with a maximum speed of 120 km h.  References  [1] 3GPP, Technical Speciﬁcation Group Radio Access Network. Spatial Channel Model for Multiple Input Multiple Output  MIMO  Simulations, 3GPP TR 25.996 V6.1.0, technical report, Sep 2003.  [2] A. Algans, K. I. Pedersen, & P. E. Mogensen, Experimental analysis of the joint sta- tistical properties of azimuth spread, delay spread, and shadow fading. IEEE J. Sel. Areas Commun., 20:3  2002 , 523–531.  [3] A. Alomainy, Y. Hao, C. G. Parini, and P. S. Hall, Comparison between two dif- ferent antennas for UWB on-body propagation measurements, IEEE Anten. Wireless Propag. Lett., 4:1  2005 , 31–34.  [4] J. G. Andrews, A. Ghosh, & R. Muhamed, Fundamentals of WiMAX: Understanding  Broadband Wireless Networking  Upper Saddle River, NJ: Prentice Hall, 2007 .  [5] M. D. Austin & G. L. Stuber, Velocity adaptive handoff algorithms for microcellular  systems. IEEE Trans. Veh. Tech., 43:3  1994 , 549–561.  [6] S. Barbarossa & A. Scaglione, Time-varying fading channels. In G. B. Giannakis, Y. Hua, P. Stoica & L. Tong, eds., Signal Processing Advances in Wireless & Mobile Communications: 2, ch.1  Upper Saddle River, NJ: Prentice Hall, 2001 .  [7] P. A. Bello, Characterization of randomly time-variant linear channels. IEEE Trans.  Circ. Syst., 11:4  1963 , 360–393.      87   cid:2   References  [8] L. Boithias, Radio Wave Propagation  New York: McGraw-Hill, 1987 . [9] M. Boutin, A. Benzakour, C. L. Despins & S. Affes, Radio wave characterization and modeling in underground mine tunnels. IEEE Trans. Anten. Propagat., 56:2  2008 , 540–549.  [10] P. Burns, Software Deﬁned Radio for 3G  Boston: Artech House, 2003 . [11] D. Cassioli, M. Z. Win & A. F. Molisch, The ultra-wide bandwith indoor channel: from statistical model to simulations. IEEE J. Sel. Areas Commun., 20:6  2002 , 1247–1257.  [12] Y. Chen, J. Teo, J. C. Y. Lai, E. Gunawan, K. S. Low, C. B. Soh & P. B. Rapajic, Cooperative communications in ultra-wideband wireless body area networks: channel modeling and system diversity analysis. IEEE J. Sel. Areas Commun., 27:1  2009 , 5–16.  [13] J. Chuang, The effects of time delay spread on portable radio communications channels with digital modulation. IEEE J. Sel. Areas Commun., 5:5  1987 , 879–889. [14] COST 207, Proposal on Channel Transfer Functions to be Used in GSM Tests Late  1986, TD 86 51-REV 3  WG1 , European Commission, Brussels, Sep 1986.  [15] COST 231, Digital Mobile Radio Toward Future Generation Systems, Final Report,  European Commission, Brussels, 1999.  [16] S. L. Cotton & S. G. Scanlon, Characterization and modeling of the indoor radio channel at 868 MHz for a mobile bodyworn wireless personal area network, IEEE Anten. Wireless Propagat. Lett., 6:1  2007 , 51–55.  [17] K. Davies & E. K. Smith, Ionospheric effects on satellite land mobile systems. IEEE  Anten. Propagat. Mag., 44:6  2002 , 24–31.  [18] Q. V. Davis & D. J. R. Martin, and R. W. Haining, Microwave radio in mines and  tunnels. In Proc. IEEE VTC, Pittsburgh, PA, May 1984, 31–36.  [19] V. Erceg, L. J. Greenstein, S. Y. Tjandra, S. R. Parkoff, A. Gupta, B. Kulic, A. A. Julius & R. Bianchi, An empirically based pathloss model for wireless channels in suburban environments. IEEE J. Sel. Areas Commun., 17:7  1999 , 1205–1211.  [20] V. Erceg et al, Channel Models for Fixed Wireless Applications, Rev. 4.0,  [21] V. Erceg et al, IEEE P802.11 Wireless LANs: TGn Channel Models, IEEE  IEEE802.16.3c-01 29r4, IEEE, Jul 2001.  802.11-03 940r4, IEEE, May 2004.  [22] S. T. Feng & T. R. Field, Statistical analysis of mobile radio reception: an extension  of Clarke’s model. IEEE Trans. Commun., 56:12  2008 , 2007–2012  [23] B. H. Fleury, First- and second-order characterization of direction dispersion and space selectivity in the radio channel. IEEE Trans. Inf. Theory, 46:6  2000 , 2027–2044.  [24] S. Geng, J. Kivinen, X. Zhao & P. Vainikainen, Millimeter-wave propagation channel characterization for short-range wireless communications. IEEE Trans. Veh. Tech., 58:1  2009 , 3–13.  [25] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [26] P. S. Hall et al, Antennas and propagation for on-body communication systems. IEEE  Anten. Propagat. Mag., 49:3  2007 , 41–58.      88   cid:2   Channel and propagation  [27] K. Haneda, J. Takada & T. Kobayashi, Cluster properties investigated from a series of ultrawideband double directional propagation measurements in home environments. IEEE Trans. Anten. Propagat., 54:12  2006 , 3778–3788.  [28] D. Har, A. W. Watson & A. G. Chadney, Comments on diffraction loss of rooftop- to-street in COST 231 Walﬁsh–Ikegami model. IEEE Trans. Veh. Tech., 48:5  1999 , 1451–1452.  [29] M. Hata, Empirical formula for propagation loss in land mobile radio services. IEEE  Trans. Veh. Tech., 29:3  1980 , 317–325.  [30] J. Holis & P. Pechac, Elevation dependent shadowing model for mobile communica- tions via high altitude platforms in built-up areas. IEEE Trans. Anten. Propagat., 56:4  2008 , 1078–1084  [31] F. Ikegami, T. Takeuchi & S. Yoshida, Theoretical prediction of mean ﬁeld strength for  urban mobile radio. IEEE Trans. Anten. Propagat., 39:3  1991 , 299–302.  [32] ITU-R, Propagation Data and Prediction Methods for the Planning of Short-Range Outdoor Radiocommunication Systems and Radio Local Area Networks in the Frequency Range 300 MHz to 100 GHz, ITU-R Rec. P.1411-4, Geneva, 2007  [33] ITU-R, The Radio Refractive Index: Its Formula and Refractivity Data, ITU-R Rec.  P.453-6, Geneva, 1997.  [34] ITU-R, Ionospheric Propagation Data and Prediction Methods Required for the  Design of Satellite Services and Systems, ITU-R Rec. P.531-8, Geneva, 2005.  [35] ITU-R, Propagation Data and Prediction Methods Required for the Design of Earth-  Space Telecommunication Systems, ITU-R Rec. P.618-9, Geneva, 2007.  [36] ITU-R, Attenuation by Atmospheric Gases, ITU-R Rec. P.676-6, Geneva, 2005. [37] ITU-R, Speciﬁc Attenuation Model for Rain for Use in Prediction Methods, ITU-R  Rec. P.838-3, Geneva, 2005.  [38] ITU-R, Propagation Data and Prediction Models for the Planning of Indoor Radio- communication Systems and Radio Local Area Networks in the Frequency Range 900 MHz to 100 GHz, ITU-R Rec. P.1238, Geneva, 1997.  [39] W. C. Jakes, Jr.  ed. , Microwave Mobile Communications  New York: Wiley,  1974 .  [40] R. Kattenbach, Characterization of Time-variant Indoor Radio Channels by Means their System and Correlation Functions, Doctoral dissertation  in German ,  of University of Kassel, Shaker Verlag, Aachen, 1997, ISBN 3-8265-2872-7.  [41] J. P. Kermoal, L. Schumacher, K. I. Pedersen, P. E. Mogensen & F. Frederiksen, A stochastic MIMO radio channel with experimental validation. IEEE J. Sel. Areas Commun., 20:6  2002 , 1211–1226.  [42] W. C. Y. Lee, Mobile Cellular Telecommunications: Analog and Digital Systems, 2nd  edn  New York: McGraw-Hill, 1995 .  [43] M. Marcus & B. Pattan, Millimeter wave propagation: spectrum management impli-  cations. IEEE Microwave Mag., 6:3  2005 , 54–62.  [44] D. W. Matolak, I. Sen & W. Xiong, The 5-GHz airport surface area channel – part I: measurement and modeling results for large airports. IEEE Trans. Veh. Tech., 57:4  2008 , 2014–2026.      89   cid:2   References  [45] A. F. Molisch, M. Steinbauer, M. Toeltsch, E. Bonek & R. S. Thoma, Capacity of MIMO systems based on measured wireless channels. IEEE J. Sel. Areas Commun., 20:3  2002 , 561–569.  [46] A. F. Molisch, Wireless Communications  Chichester: Wiley-IEEE, 2005 . [47] M. Nakagami, The m-distribution: a general formula of intensity distribution of rapid fading. In W. C. Hoffman, ed., Statistical Methods in Radio Wave Propagation  Oxford: Pergamon Press, 1960 , pp. 3–36.  [48] C. Oestges, D. Vanhoenacker-Janvier & B. Clerckx, Channel characterization of indoor wireless personal area networks. IEEE Trans. Anten. Propagat., 54:11  2006 , 3143–3150.  [49] Y. Okumura, E. Ohmori, T. Kawano & K. Fukuda, Field strength and its variability in VHF and UHF land mobile radio service. Rev. Electr. Commun. Lab, 16  1968 , 825–873.  [50] R. L. Olsen & B. Segal, New techniques for predicting the multipath fading distribu- tion on VHF UHF SHF terrestrial line-of-sight links in Canada. Canadian J. Electr. Comput. Eng., 17:1  1992 , 11–23.  [51] J. F. Ossana, A model for mobile radio fading due to building reﬂections: Theoretical and experimental fading waveform power spectra. Bell Syst. Tech. J., 43:6  1964 , 2935–2971.  [52] C. S. Patel, G. L. Stuber & T. G. Pratt, Simulation of Rayleigh faded mobile-to-mobile  communication channels. In Proc. IEEE VTC, Orlando, FL, Oct 2003, 1: 163–167.  [53] A. Paulraj, R. Nabar & D. Gore, Introduction to Space-Time Wireless Communica-  tions  Cambridge, UK: Cambridge University Press, 2003 .  [54] K. I. Pedersen, P. E. Mogensen & B. H. Fleury, A stochastic model of the temporal and azimuthal dispersion seen at the base station in outdoor propagation environments. IEEE Trans. Veh. Tech., 49:2  2000 , 437–447.  [55] D. M. Pozar, Microwave Engineering, 3nd edn  New York: Wiley, 2005 . [56] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall PTR, 2002 .  [57] D. O. Reudink and M. F. Wazowicz, Some propagation experiments relating foliage loss and diffraction loss at X-band and UHF frequencies. IEEE Trans. Veh. Tech., 22:4  1973 , 1198–1206.  [58] S. O. Rice, Mathematical analysis of random noise. Bell Syst. Tech. J, 23:3  1944 ,  282–332.  27:1  1948 , 109–157.  [59] S. O. Rice, Statistical properties of a sine wave plus random noise. Bell Syst. Tech. J.,  [60] M. L. Rubio, A. Garcia-Armada, R. P. Torres & J. L. Garcia, Channel modelling and characteristic at 17 GHz for indoor broadband WLAN. IEEE J. Sel. Areas Commun., 20:3  2002 , 593–601.  [61] A. A. M. Saleh & R. A. Valenzuela, A statistical model for indoor multipath  propagation. IEEE J. Sel. Areas Commun., 5:2  1987 , 128´lC-137.  [62] S. R. Saunders & A. Aragon-Zavala, Antennas and Propagation for Wireless Commu-  nication Systems, 2nd edn  Chichester, England: Wiley, 2007 .      90   cid:2   Channel and propagation  [63] S. Scalise, H. Ernst & G. Harles, Measurement and modeling of the land mobile satel-  lite channel at Ku-band. IEEE Trans. Veh. Tech., 57:2  2008 , 693–703  [64] S. Y. Seidel, T. Rapport, S. Jain, M. Lord, & R. Singh, Path loss, scattering and mul- tipath delay statistics in four European cities for digital cellular and microcellular radiotelephone. IEEE Trans. Veh. Tech., 40:4  1990 , 721–730.  [65] I. Sen & D. W. Matolak, The 5-GHz airport surface area channel – part II: measure- ment and modeling results for small airports. IEEE Trans. Veh. Tech., 57:4  2008 , 2027–2035.  [66] A. U. H. Sheikh, Wireless Communications: Theory and Techniques  Boston, MA:  [67] M. K. Simon & M.-S. Alouini, Digital Communications over Fading Channels, 2nd  Kluwer, 2004 .  edn  New York: Wiley, 2005 .  [68] Q. H. Spencer, B. D. Jeffs, M. A. Jensen & L. Swindlehurst, Modeling the statistical time and angle of arrival characteristics of an indoor multipath channel. IEEE J. Sel. Areas Commun., 18:3  2000 , 347–360.  [69] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  2001 .  25:7  1977 , 673–680.  [70] H. Suzuki, A statistical model for urban radio propagation. IEEE Trans. Commun.,  [71] J. Takada, J. Fu, H. Zhu & T. Kabayashi, Spatio-temporal channel characterization in a suburban non line-of-sight microcellular environment. IEEE J. Sel. Areas Commun., 20:3  2002 , 532–538.  [72] M. Toeltsch, J. Laurila, K. Kalliola, A. F. Molische, P. Vainikainen & E. Bonek, Sta- tistical characterization of urban spatial radio channels. IEEE J. Sel. Areas Commun., 20:3  2002 , 539–549.  [73] C. A. Tunc, A. Altintas & V. B. Erturk, Examination of existent propagation models over large inhomogeneous terrain proﬁles using fast integral equation solution. IEEE Trans. Anten. Propagat., 53:9  2005 , 3080–3083.  [74] J. Walﬁsch & H. L. Bertoni, A theoretical model of UHF propagation in urban  environments. IEEE Trans. Anten. Propagat., 36:12  1988 , 1788–1796.  [75] E. H. Walker, Penetration of radio signals into buildings in the cellular radio  environment. Bell Syst. Tech. J., 26:9  1983 , 2719–2734.  [76] J. W. Wallace & M. A. Jensen, Time-varying MIMO channels: measurement, analysis,  and modeling. IEEE Trans. Anten. Propagat., 54:11  2006 , 3265–3273.  [77] L.-C. Wang, W.-C. Liu & Y.-H. Cheng, Statistical analysis of a mobile-to-mobile  Rician fading channel model. IEEE Trans. Veh. Tech., 58:1  2009 , 32–38.  [78] Y. Wang, I. B. Bonev, J. O. Nielsen, I. Z. Kovacs & G. F. Pedersen, Characterization of the indoor multiantenna body-to-body radio channel. IEEE Trans. Anten. Propagat., 57:4  2009 , 972–979.  [79] S. Wyne, A. F. Molisch, P. Almers, G. Eriksson, J. Karedal & Fredrik Tufvesson, Outdoor-to-indoor ofﬁce MIMO measurements and analysis at 5.2 GHz. IEEE Trans. Veh. Tech., 57:3  2008 , 1374–1386.  [80] H. Xu, V. Kukshya & T. S. Rappaport, Spatial and temporal characteristics of 60 GHz  indoor channels. IEEE J. Sel. Areas Commun., 20:3  2002 , 620–630.      91   cid:2   References  [81] A. Yagbasan, C. A. Tunc, V. B. Erturk, A. Altintas & R. Mittra, Use of characteristic basis function method for scattering from terrain proﬁles. Turk. J. Electr. Eng., 16:1  2008 , 33–39.  [82] A. G. Zajic, G. L. Stuber, T. G. Pratt & S. T. Nguyen, Wideband MIMO mobile-to- mobile channels: geometry-based statistical modeling with experimental veriﬁcation. IEEE Trans. Veh. Tech., 58:2  2009 , 517–534.  [83] X. Zhao, J. Kivinen, P. Vainikainen & K. Skog, Propagation characteristics for wide- band outdoor mobile communications at 5.3 GHz. IEEE J. Sel. Areas Commun., 20:3  2002 , 507–514.      4  Cellular and multiple-user systems  4.1 The cellular concept  The cellular concept was a major breakthrough in mobile communications, and it ini- tiated the era of modern wireless communications. It helped to solve the problem of spectral congestion and user capacity. For wireless communications, the antennas are typically required to be omnidirectional. The cellular structure divides the geographical area into many cells. A BS equipped with an omnidirectional antenna is installed at the center of each cell. Neighboring cells use different frequency bands to avoid co-channel interference  CCI .  The same frequency bands can be used by different cells that are sufﬁciently far away. This leads to frequency reuse. For a distance D between two cells that use the same fre- quency bands and a radius R of the cell, the relative distance D R between the two cells is the reuse distance. There is no CCI within a cluster of cells, where each cell uses a different frequency spectrum. The number of cells in a cluster is called the cluster size. The cluster size determines the capacity of the cellular system: a smaller cluster size leads to a large capacity.  The cell shape usually takes the form of hexagon, and the overall division of space is like a beehive pattern [16]. This is illustrated in Fig. 4.1 for cluster size 4 and reuse distance D R ≈ 4. This hexagonal cell shape is suitable when the antennas of the BSs are placed on top of buildings with a coverage radius of a few miles, such as in the 1G mobile systems. For small cells with the BS antenna placed closer to the ground, especially in typically urban street grids, diamond cells can more accurately model the contours of constant power [8]. For a given distance between reuse cells, the hexagonal geometry requires the least number of cells.  For any receiver in the cellular system, there is interference from inside as well as from outside its cell. The intracell interference is due to the nonorthogonal channel- ization between users, while the intercell interference is known as CCI. In orthogonal multiple-access techniques such as TDMA or FDMA, there is no intracell interference in ideal operating conditions. In CDMA with nonorthogonal codes, there is intracell as well as intercell interference, but all the interference is suppressed by a factor equal to the processing gain due to the code cross-correlation.      93   cid:2   4.1 The cellular concept   cid:2 Figure 4.1  The cell structure for cluster size 4 and reuse distance D R ≈ 4.  4  1  4  1  3  2  3  2  3  4  1  4  1  4  R  3  D  1  1  4  4  1  3  2  3  2  2  2  3  2  2  3  2  1  4  1  A  A  E  F  i  i  j  j  A  j  D  i  A  i  j  A  j  i  C  B  A  G  j  i  A   cid:2 Figure 4.2  Assignment of hexagonal cells. The cluster size N = 7.  4.1.1 Cell planning  Cell planning in the hexagonal cellular structure is based on the i-j coordinate system, as shown in Fig. 4.2. From the current cell A, move i cells along i axis, and then further j cells along j axis, i, j = 0, 1, 2, . . . From the Pythagorian theorem, we have √ 3R cos 30   cid:18  i2 + j2 + ij  ◦ cid:18 2 = 3R2  √ 3R sin 30  ◦ cid:18 2 +  √ 3R + i  D2 =   4.1    cid:17    cid:17    cid:17   j  j  .      94   cid:2   Cellular and multiple-user systems   cid:21    cid:7   D R =  i2 + ij + j2  3   cid:8  = √  3N.  The reuse distance D R and the cluster size N have such a relation [16]   4.2    4.3   For frequency planning, in order to maximize spectral efﬁciency while satisfying the minimum reuse distance, the cluster size N must satisfy such a relation [18, 19]  N = Acluster Acell  = i2 + ij + j2,  i, j = 0, 1, 2,··· ,  where Acluster and Acell are, respectively, the area of a cluster of hexagonal cells and that of one cell. Thus the cluster size can only be N = 1, 3, 4, 7, 9, 12, 13, 16, 19, 21, 25, 27, 28, 31, 36 . . .  Cell planning is based on  4.2 , and the smallest integer out of the set for N. The distance between the desired BS and interferer, D, is calculated by link budget analysis. Typically, N = 1 for CDMA-based 2G and 3G standards, N = 7 for GSM, N = 4 for PDC, and N = 21 for analog systems such as AMPS and NMT.  Deployment of cell size  Deployment of cell size is dependent on the trafﬁc intensity in erlangs, which can be cal- culated from expected total number of subscribers within an area, their mean access times and the mean duration of each call. For orthogonal systems, such as TDMA or FDMA, the received power Pr is given by  Pr = Ptd  −γ ,   4.4   where Pt is the transmitted power, d is the distance between the BS to an MS, and γ is the path-loss exponent. Within the cell, γ = 2, and outside the cell, γ is selected between 2 to 4.  For a hexagonal cellular structure, the SIR received within a cell is mainly decided by the six ﬁrst-tier BSs of the same frequency. For example, in Fig. 4.1, for cell 2 in the cluster, there are altogether 6 ﬁrst-tier cells using the same frequency. For the worst-case carrier-to-interference power ratio  CIR  calculation, the MS is placed at the corner of a cell. Assuming that all the BSs emit the same power, from geometrical analysis, the SIR received at the MS can be approximated by [19]   cid:7   − 1  2  D R   cid:17    cid:8 −γ +   cid:18 −γ + cid:7    cid:17    cid:8 −γ +  1  D R  + 1  2  D R   cid:18 −γ + cid:7   − 1  2  D R  + 1  D R   cid:8 −γ  .  CIR ≈   4.5   For hexagonal cells, CIR can also be approximated by [8] CIR = a1  a2N γ  2 ,   4.6  where a1 = 0.167 and a2 = 3 for hexagonal cells, and a1 = 0.125 and a2 = 4 for diamond cells. By specifying a target CIR value CIR0, the minimum N can be calculated from  4.6 . For example, GSM requires SIR0 = 7 dB.      95   cid:2   4.1 The cellular concept  The user capacity in each cell Cu is given by  Cu = Nc = B NBs  ,   4.7    4.8    4.9   where Nc is the number of channels assigned to a cell, B is the total system bandwidth, and Bs is the bandwidth of each channel.  Similar analysis is made for nonorthogonal systems such as CDMA. For CDMA  systems, the SIR that is commonly used for uplink with power control is given by [7, 8]  SIR =  1   Nc − 1   1 + λ   ,  ξ 3G  where ξ is a constant characterizing the code cross-correlation that depends on the code properties and other system assumptions and is between 1 and 3, G is the processing gain, and λ is the ratio of the average received power from all intercell interference to that of all intracell interference under perfect intracell power control. Accordingly, by setting Cu = Nc and a target SIR value in  4.8 , the user capacity is derived as  Cu = Nc = 1 +  1  ξ  3G  1 + λ SIR0  .  4.1.2 Increasing capacity of cellular networks  In a cellular system, CCI is a major source of interference. In populous regions, a cell may have many users, and the interferences from these omnidirectional antennas are continually increasing. The cell capacity may not support all these simultaneous users. Cell splitting and sectoring are common techniques employed for increasing the capacity of the cellular system.  The cell-splitting technique subdivides a congested cell into smaller cells, called micro- cells. Each microcell is equipped with a BS that is reassigned a frequency band. Due to the smaller size of the microcell, the antenna has a reduced height and a reduced transmission power so that the receiving power at the new and old cell boundaries are equal to each other. Cell splitting can increase the network capacity by installing more BSs. After a cell is split into microcells, changes in the frequency plan are required to retain the frequency reuse constraint. On the other hand, this also increases the number of handoffs between cells for moving users. The large amount of signaling for handoffs reduces the spectral efﬁciency. To reduce the interference to other cells or limit the radio coverage of the newly formed microcells, antennas are usually deliberately downtilted so that the main radiation beam is towards the ground.  Picocells and femtocells further reduce the size of a microcell. They provide better cov- erage in some locations and enable higher data rates at a signiﬁcantly lower investment than a macrocell microcell BS. The indoor picocell BS is a small device that can be mounted on a wall or ceiling to support users in airports, shopping malls, ofﬁce buildings and other large enterprises. The femtocell BS, also called a home BS, provides coverage within an individual home to support several users. The femtocell BS can be deployed as a 3G access      96   cid:2   Cellular and multiple-user systems  point, since 3G cellular technology suffers from inadequate indoor signal penetration. The cellular BSs are interconnected via an existing access network.  The cell-sectoring technique replaces the single omnidirectional antenna at the BS ◦ each. These directional by several directional antennas, typically three sectors of 120 antennas can be made of patched antenna arrays. Unlike omnidirectional antennas, the directional antennas interfere only with the neighboring cells in their directions. When a cell is sectorized into N sectors, interference power is reduced by roughly a factor of N under heavy loading. Handoff is necessary as MSs move between sectors, and this can be performed in the BS without the intervention of the MSC. However, cell sectoring suf- fers from a considerable loss in trunking inefﬁciency, which becomes a major concern for operation.  A more complex method to increase the system capacity is to use the smart antenna technique. Antenna arrays are used to generate beam patterns towards desired users while rejecting all interfering signals. Due to the excellent interference rejection capability, each BS can cover a wider area. The smart antenna technique achieves a signiﬁcant improvement in system capacity. Smart antennas can be either a switched-beam or an adaptive array system. The switched-beam system continually chooses one pattern from many predeﬁned patterns to steer toward the desired user. This method is incapable of enhancing the desired signal when an interfering signal is close to it, since the beam patterns are predeﬁned. This problem can be solved by using an adaptive array, which creates a beam pattern for each user adaptively by enhancing the desired signal and suppressing all interfering signals. Adaptive antenna array techniques are much more complex for implementation, and will be treated in Chapter 18.  4.1.3 Interference in multiuser systems  Interference is the major limiting factor for the performance of cellular systems. CCI and adjacent channel interference  ACI  are the two major types of interference in cel- lular systems. In a multiuser system such as a CDMA system, the noise can be neglected when compared with interference from other users or sources. Such a system is said to be interference limited. Other interference such as intermodulation interference, intercarrier interference  ICI , and ISI may also arise.  Co-channel interference  In a multi-cell environment with frequency reuse, CCI from different cells always exists. To reduce the CCI, co-channel cells are physically separated by a minimum distance of reuse. Since CCI is from other cells, it usually has a longer delay, a larger angle spread, smaller Kr-factor, and a smaller cross-polarization discrimination. In general, the channel for CCI is close to an i.i.d. channel. In order to mitigate the CCI, multiple antennas can be used at the receiver for CCI cancellation and at the transmitter for CCI avoidance. In the IS-95 CDMA system, the frequency reuse rate is 1, and approximately 40% of the total interference is from the surrounding cells [27]. CCI is also known as multiple-access      97   cid:2   4.1 The cellular concept  interference  MAI  or multiple-user interference  MUI  when it is from users within the same cell, since it arises from the nonorthogonality between multiple accesses, such as in the case of CDMA when nonorthogonal codes are used. In CDMA systems, CCI is typically treated as white noise. The pdf of the total CCI power as well as the signal outage probability is modeled in [23].  Adjacent channel interference  ACI arises from signals which are adjacent in frequency. Due to the imperfect receiver ﬁl- ters, the power in the nearby frequency channel may leak into the passband of the adjacent channel. This problem is especially severe when the receiver is far from the BS but very close to an adjacent channel user. This is referred to as the near–far effect. This also occurs for a BS, when an interfering MS close to the BS transmits on a channel that is close to that being used by a desired MS far from the BS. ACI can be minimized through ﬁltering and optimization of channel assignments. Since each cell has only a fraction of all the channels, the channels within each cell can be separated in frequency.  Intermodulation interference  Intermodulation interference may arise either at the receiver or at the transmitter. Unlike ACI, intermodulation products cannot be removed by simple ﬁltering. Intermodulation products are produced when the desired and interfering signals enter a nonlinear device, such as a mixer or a power ampliﬁer. Intermodulation interference can be reduced by increasing the linearity of the devices and proper frequency allocation.  Intercarrier interference  Doppler spread is caused by different Doppler shifts from different incoming waves at the receiving signal, when the transmitter and or receiver is moving. The Doppler spead fD is given as fD = v λ , where v is the speed of the MS and λ is the wavelength of the carrier frequency fc. fD is typically very small compared to fc. The received carrier frequency is fc + fD if the mobile is moving toward the BS, or fc − fD if moving away from the BS. In narrowband communications, the Doppler spread can account for up to a few percent of the subcarrier space. This may damage the orthogonality among the subcarriers and produce crosstalk, and thus ICI arises.  Intersymbol interference  ISI is due to multipath components of signals. When the time delay of a multipath com- ponent is signiﬁcant compared to a symbol period, ISI occurs. ISI is a common form of interference in wireless communications. It can typically be mitigated by equalization or using OFDM technology.      98   cid:2   Cellular and multiple-user systems  Environmental noise  Interference may also arise due to the radiated power from different neighboring sources such as electric motors and electrical switches. This is generally known as electromagnetic pollution. The mobile radio systems have no control over such emissions. There are some noise models in the literature such as those given in [17].  One public concern about radiated electromagnetic ﬁelds is the possible hazards of radi- ated power to human safety. Currently, it is commonly believed that the damage due to electromagnetic power to humans is the heat effect, as in the case of a microwave oven. The heat is generated from within the body, and may cause damage to the human brain, eyes, and internal organs. For this reason, some safety radiation standards have been deﬁned. The ANSI IEEE standard C95.1-1992 sets the power density limits for the bands from 100 MHz to 300 MHz to 0.2 mW cm2, for frequencies above 15 GHz to 10 mW cm2, and in between these two bands the power density limit increases proportionally in a logarithmic fashion. The difference arises from the fact that low frequencies have strong penetration into the human body, while high frequencies cannot penetrate through the human skin.  In addition to the standards for human safety, FCC has also deﬁned the radiation lim- its for individual wireless standards to minimize their interference with other wireless equipments.  4.1.4 Power control  Power control is a critical aspect for achieving the high capacity of a wireless network. Power control on the downlink leads to less intercell and intracell interference than on the uplink. This is due to the fact that on the downlink, the BS is situated at the center of the cell, and is relatively far from the other cells. In contrast, on the uplink, an MS from the cell boundary has to increase its power to ensure a sufﬁcient received power at the BS, which is at the same level as the received power of those MSs that are close to the BS; this leads to signiﬁcant interference with neighboring cells. Power control helps prolong battery life for MSs. Power control is especially important for the CDMA system, where every user in every cell shares the same frequency band.  Open-loop power control makes the loss in the forward path similar to that in the reverse path. By setting the sum of the transmit and receive powers to a preset value, a reduction in the received signal level leads to a command to increase the transmit power. Closed-loop power control allows the power from the MS to deviate from its nominal value as set by open-loop control. In case of downlink power control, the BS adjusts the transmit power for each trafﬁc channel independently, based on the propagation and interference conditions.  4.1.5 Channel assignment  Channel assignment can be implemented in a ﬁxed, ﬂexible, or dynamic mode. Fixed channel assignment allocates the channel resources statically, and is used in the 1G macro- cellular systems. In the ﬁxed channel assignment scheme, if all the channels in a cell are      99   cid:2   4.1 The cellular concept  occupied, a new call is blocked. To reduce the blocking probability, a cell is allowed to bor- row channels from a neighboring cell, if all of its own channels are occupied, and assign a borrowed channel to a new call; this is known as ﬁxed channel assignment with borrowing. The MSC supervises the borrowing.  Dynamic channel assignment is more suitable for microcellular channel assignment. It allows any cell to use any channel as long as the cochannel reuse constraint is not vio- lated. This reduces the probability of blocking, thus increasing the trunking capacity of the system, since all the channels are accessible to all the cells. Dynamic channel assign- ment requires the MSC to continuously collect real-time data on channel occupancy, trafﬁc distribution, and radio signal strength indications  RSSIs  of all the channels. Thus, it is more expensive to implement. This technique can assign the same channel to an MS that is moving from one cell to another as long as the level of CCI is tolerable, while ﬁxed channel assignment has to implement handoff in this case. It outperforms ﬁxed channel assignment for light nonstationary trafﬁc, but ﬁxed channel assignment is more efﬁcient for heavy trafﬁc.  Flexible channel assignment combines the advantages of both the ﬁxed and dynamic channel assignment schemes. The total number of channels are divided into two categories: Some channels are dedicated for the cells, while others are kept in reserve with the control center which dynamically allocates the channels. Frequency borrowing, which is a vari- ation of the ﬂexible channel assignment, exhibits a blocking probability lower than that achieved in ﬁxed or dynamic channel assignment.  In DECT, dynamic channel selection is employed to improve efﬁciency. This can ele- gantly deal with fast changing shadowing. More discussion on channel assignment is contained in [25].  4.1.6 Handoff  When an MS moves into a new cell during a conversation, the MSC automatically trans- fers the call to a channel of the new cell. Handoff is a fundamental function in cellular communications. Handoff, also known as handover, can be intercell handoff or intracell handoff. Intercell handoff is implemented when an MS traverses a cell boundary, while intracell handoff can be applied within the cell when one channel in the cell is subject to excessive interference. The handoff procedure ﬁrst measures the link quality  i.e., RSSI . If it is below a certain threshold, handoff is initiated. This is followed by radio and net- work resource allocation. Handoffs must be performed as infrequently as possible, and be imperceptible to the users.  To perform handoff, the drop in the measured signal should not be due to instantaneous fading as the MS is moving away from the serving BS. Thus, the power level is measured as an average during a period. A threshold signal-level difference between the powers received from the two BSs is used to initiate the handoff.  In 1G systems, the BSs are in charge of the signal strength measurement, and the RSSI results are reported to the MSC. The MSC decides whether a handoff is necessary. In 2G systems that use TDMA, handoff is mobile-assisted. In mobile-assisted handoff  MAHO ,      100   cid:2   Cellular and multiple-user systems  every MS measures the received power from the surrounding BSs and reports the results to its serving BS. MAHO is much faster than the handoff used in the 1G systems, since the measurements are made by each mobile and the MSC does not need to continuously monitor the RSSIs.  To reduce the probability of forced termination of a call, handoff requests should be given priority. This can be achieved by reserving a few channels exclusively for hand- offs, or by queuing handoff requests. The channel-reservation scheme may reduce the total trafﬁc, but is spectrum-efﬁcient in the dynamic channel assignment strategy. Queuing of handoff requests is possible, since there is a time interval for the received signal to drop from the handoff threshold to call termination due to insufﬁcient signal level.  At the IEEE, a speciﬁcation on media-independent handover services  IEEE 802.21 MIH  is currently being developed to enable handover and interoperability between het- erogeneous network types including both IEEE 802 and non-IEEE 802 networks [10]. IEEE 802.21 provides a framework that allows higher levels to interact with lower layers to provide session continuity without dealing with the speciﬁcs of each technology.  Handoff methods  Handoff can be either hard handoff, or soft handoff, or fast base station switching  FBSS . For hard handoff, an MS is connected to only one BS at a time. There is a short interruption during the transfer from one BS to another. It is simple to implement, but it does not take advantage of the diversity of receiving signals from two or more BSs. Hard handoff is supported in most 1G and 2G standards, and is also supported in WCDMA and WiMAX. Soft handoff is also known as macro diversity handoff  MDHO , since the MS is allowed to simultaneously communicate with more than one BS, and diversity combining is applied at the MS. All the BSs involved in the MDHO of a given MS constitute the diversity set. DECT, IS-95 CDMA, CDMA2000, WCDMA, TD-SCDMA, and HSUPA support the MDHO. MDHO between sectors of the same BS is also supported in WCDMA.  FBSS, also known as fast cell selection, is similar to MDHO in that it maintains a set of BSs, called the active set, but the MS communicates in the uplink and downlink with only one BS at a time, referred to as the anchor BS. When a change of anchor BS is required, the connection is switched between BSs without explicitly performing handoff signaling. The MS simply reports the selected anchor BS to the previous anchor BS. WCDMA  including HSDPA and HSUPA  supports FBSS in its Release 7 published in September 2007. Mobile WiMAX  IEEE 802.16e  supports the mandatory hard handoff, and optionally supports FBSS and MDHO.  Both FBSS and MDHO offer superior performance to hard handoff, but they need to synchronize the BSs in the active or diversity set, and use the same carrier frequency, and share network entry-related information.  Hard handoff  To initiate a hard handoff, H, the average signal difference between the BSs and T, the tem- poral window length over which the signal strength is averaged must be carefully selected.      101   cid:2   4.2 Multiple access techniques  Typically, T corresponds to the time for moving 20 to 40 wavelengths, and H is of the order of the shadow standard deviation [25]. The corner effect usually occurs in urban microcel- lular settings, when the MS turns the corner of a street, and a building blocks the LOS signal component. The corner effect can lead to a sudden drop of the signal strength by 25–30 dB over a distance as small as 10 m [25].  In conventional hard handoff, as used in GSM, when starting a new cell, the old cell is switched off. In order to avoid frequent switching between two BSs at the borders of two cells, the hard switch occurs only when the pilot signal from the second cell is sufﬁciently larger  e.g., 6 dB higher  than that from the original cell. This also reduces the performance at the cell border.  Various implementations of handoff algorithms have been detailed in [25]. Hard handoff is used in all 1G and most 2G standards, such as most of the TDMA cellular systems. Some 3G standards, such as UTRA-TDD, TD-SCDMA, and mobile WiMAX, also employ hard handoff. Soft handoff is introduced in Section 8.3.6.  Mobility management  For mobile communications, the process of identifying and tracking an MS’s attachment position to the network is known as location management. Location management and hand- off management together is known as mobility management. Location management has two processes: location registration  update  and paging. The MS performs location registration by periodically informing the network its location so that the network authenticates the user and updates its location in the database. The network will page all the BSs within the area of the subscriber, when an incoming request for session initiation arrives at the network.  As opposed to location management, handoff management has strict real-time require- ment. Handoff is performed in two steps: handoff detection and handoff execution. Handoff management should minimize handoff failures and also avoid unnecessary handoffs. There is a tradeoff between dropping probability and handoff rate. Handoffs are often given more priority than starting new sessions.  For IP-based wireless communications, IP address of the MS must remain unchanged during the handoff process. This is difﬁcult since a user moves across two BSs that belong to different IP subnets. Mobile IP, deﬁned by RFC 3344, is the IETF solution to this prob- lem. Mobile IP is speciﬁcally designed as an overlay solution to Internet Protocol version 4  IPv4 , and mobility has been considered in IPv6. Mobile IP deﬁnes two addresses for each mobile node: the home address  HoA , which is issued to the mobile node by its home network, and the care-of address  CoA , which is a temporary IP address assigned to the mobile node by the visited network.  4.2 Multiple access techniques  In a multiuser system, the uplink and downlink channels are different in nature. The down- link, also called broadcast channel or forward channel, transmits signals to many receivers      102   cid:2   users, s t  =  cid:24   Cellular and multiple-user systems  from one transmitter. Thus, the transmitted signal is the sum of the signals to each of the K k=1 sk t . Synchronization of all the user signals is easy to realize in the downlink. The transmitter has its constraints on total power and bandwidth. The uplink channel, also known as a multiple access channel or reverse channel, receives signals from many transmitters.  Each communication standard deﬁnes its multiple access technique that allows multi- ple users to efﬁciently share the limited physical resources, usually deﬁned in terms of the bandwidth. No matter what multiple access technique is selected, the objective of a multiuser system is to have a high capacity with sufﬁcient QoS. Voice transmission is −3. For data transmission, the delay-sensitive, but allows a maximum tolerable BER of 10 target BER is 10  −6.  Multiple access techniques used in cellular standards include TDMA, direct-sequence CDMA  DS-CDMA , FDMA, and their combinations. These multiple-access techniques are demand-assignment-based. Strong QoS control is achieved by using a connection- oriented MAC architecture.  In a multiuser system, orthogonal multiple access techniques are used in order to sepa- rate different users. Popular multiple access techniques are TDMA and FDMA that have orthogonal channels, and CDMA that has almost-orthogonal channels. All multiple access techniques that divide the signal space orthogonally, such as TDMA, FDMA, and orthog- onal CDMA, are proved to have the same capacity in AWGN channels [8], since they are all designed to have the same number of orthogonal dimensions for a given bandwidth and duration of time. Note that this is only for the orthogonal case. In dense wireless environ- ments, orthogonality cannot be maintained due to interference from neighboring cells. In ﬂat and frequency-selective fading channels, different multiple access techniques lead to different channel capacities.  4.2.1 Duplexing: FDD versus TDD  Mobile radio systems can be classiﬁed as simplex, half-duplex or full-duplex. Paging sys- tems are simplex systems, where communication is only in one direction. Half-duplex systems allow two-way communication, but use the same channel for both transmission and reception. Thus, at any given instant, a user can only transmit or receive information. An example of half-duplex systems is the walkie-talkie system. Full-duplex, simply called duplex, allows simultaneous transmission and reception. Duplex is the simplest multiple access technique. FDD and TDD are the two duplexing methods.  FDD  In FDD, different frequency bands are used for uplink and downlink transmissions. The frequency band with the higher frequency is used for downlink transmission, while that with the lower frequency for uplink transmission. This is in view of the fact that the lower frequency leads to a lower propagation loss and thus is suitable for MSs. FDD mode is suitable for macrocells and microcells.      103   cid:2   4.2 Multiple access techniques  In order to obtain the channel state information  CSI  at the transmitter, the receiver has to quantize and feedback the channel state to the transmitter. In FDD, the user terminals usually receive a continuous downlink signal; dummy data must be inserted when the trafﬁc is small. The transmission of dummy data wastes spectrum and power. FDD requires two sets of RF transceivers, one for each of the uplink and downlink. FDD has inﬂexibility in trafﬁc allocation, although spectrum usage can be adapted to trafﬁc variations by adding or removing channels. The channels should not be very broad for the reason of spectrum efﬁciency. FDD introduces high hardware cost, since for each carrier frequency an RF circuit is required.  Current 3G mobile communications, such as IS-95, WCDMA, and CDMA2000, and other wireless techniques prefer FDD. FDD is a legacy for voice communication, which has symmetric and predictable trafﬁc.  TDD  In TDD, uplink and downlink transmissions use the same frequency bands, but differ- ent time slots. Since the time intervals are easy to change, TDD can adapt its spectrum resources by arranging different numbers of time slots on the uplink and downlink accord- ing to the actual trafﬁc at each TDD frame. TDD can be used for very broad channels, and this leads to a high frequency diversity. This asymmetric feature is well suited to Internet and broadcasting services. TDD can better manage dense trafﬁc in urban areas than FDD can and is more efﬁcient in pico- to micro-cell sized cases, while FDD works more efﬁciently in macro-cell cases. TDD is only suitable for pico- to micro-cells, since large propagation delays between the MS and BS may lead to overlap of transmitting and receiving time slots. Unlike FDD, dummy data transmission is made unnecessary by introducing pauses in transmission. When the available bandwidth is in noncontiguous blocks, TDD is a desirable choice. TDD leads to lower-cost RF transceivers, which do not require a high isolation for the transmission and reception of multiplexing as needed in FDD transceivers. Thus, the entire RF transceiver can be integrated into a single integrated circuit  IC .  The high ﬂexibility and spectrum efﬁciency of TDD come with a price. It requires burst demodulators, and synchronization for uplink transmissions becomes more difﬁcult since the continuous downlink signal in FDD, that can be used for frequency and clock reference, is not available. Due to the identical radio propagation on the uplink and the downlink, it is easy to perform accurate measurements and the channel impulse responses can be estimated using a Steiner estimator through a training sequence. Furthermore, the strong signals generated by all the nearby mobile transmitters fall into the receive band for TDD, yielding a relatively high PAPR, which requires high-linearity ampliﬁers. TDD introduces a time latency.  TDD is used for uplink and downlink separation in most 2G standards, UTRA-TDD, and TD-SCDMA. It is attractive for future-generation mobile communications and wireless networking. In 802.16, both FDD and TDD are supported. The Korean WiBro supports TDD. In WCDMA, high-speed packet data mode is introduced, and this further decreases the deployment of FDD.      104   cid:2   Cellular and multiple-user systems  4.2.2 FDMA  FDMA divides the total frequency bandwidth into some frequency channels, each being assigned to a single user. Each user accesses its own channel and interference to other users is avoided. For FDMA, frequency synchronization and stability are difﬁcult for narrowband communications such as speech communications, and it is also sensitive to fading. Thus, FDMA is only used for analog communications, wideband systems, or a hybrid with other multiple access techniques.  Frequency guard bands are required for separating each frequency band to compensate for imperfect ﬁlter implementation, ACI, and Doppler spread. The complexity of FDMA systems is lower compared to that of TDMA systems. FDMA is a continuous transmission scheme, and this approach is efﬁcient when the information ﬂow to be transmitted is steady, such as voice signals, but is inefﬁcient with data that are bursty in nature. In FDMA, it is difﬁcult to assign each user multiple channels. In FDMA with FDD, two channels are assigned to each user. FDMA supports both analog and digital transmissions. It was the only access method for the 1G analog FM systems, and is also used in 2G and 3G systems by combining with other multiple access techniques.  It is important to mention the difference between the two terminologies: FDMA and FDD. FDMA is used to separate different users using different frequencies, whereas FDD is used to divide uplink and downlink channels of the same user by using different frequencies. Similar difference applies for TDMA and TDD.  4.2.3 TDMA  TDMA divides the time axis into periodical time frames and time slots, and each slot in a time frame is assigned to a single user to transmit data. A user can send a large amount of data by using the time slots at the same position in multiple frames, so that the receiver can easily collect and assemble the bursty packets.  The need for A D conversion, digital modulation, and synchronization makes TDMA much more complex than FDMA. Synchronization is a major difﬁculty in TDMA, and high synchronization overhead is required. For the downlink, all signals originate from the same transmitter, and synchronization at the receivers may be easier. For the uplink, different users transmit from different channels with different delays, and this may destroy orthogonality in time. Multipath further destroys time division orthogo- nality in both the uplink and downlink channels. Temporal guard intervals are used in the time slots to combat synchronization errors and multipath, and these intervals need to be greater than the channel delay spread. Users of TDMA systems occupy a larger bandwidth compared to the FDMA case; this allows frequency diversity within the bandwidth, and the sensitivity of Doppler effect is lower. But equalizers are required for ISI.  TDMA TDD is a discontinuous transmission scheme. This enables the MS and BS to listen during the idle time slots. This enables the CSI to be obtained at the transmitter without the need for feedback. This feature is very desirable for the precoding of MIMO      105   cid:2   4.2 Multiple access techniques  systems, and MAHO. TDMA systems improve the capacity by a factor of 3 to 6 times as compared to the FDMA-based analog cellular systems [19].  As in the case of FDMA, TDMA is efﬁcient only with steady data trafﬁc. For voice telephony, the ﬁxed channel or time slot allocation can guarantee real-time constant bit rate voice quality. Due to the increased number of users and types of data services, dynamic channel allocation for TDMA and FDMA will introduce delay. TDMA is dominant in wired communications and 2G wireless communications, and also is combined with other multiple access techniques in 3G standards such as UTRA-TDD and TD-SCDMA.  4.2.4 CDMA  Spread spectrum multiple access  SSMA  technology, also known as CDMA, spreads the narrowband user data into a much wider spectrum. A pseudo-noise  PN  sequence is used to convert a narrowband signal to a wideband noise-like signal before transmis- sion. In SSMA, each user shares the same bandwidth and time. The receiver despreads its data by using its unique code that is orthogonal to the codes used by the other users.  SSMA takes the form of either DS-CDMA, frequency-hopping CDMA  FH-CDMA ,  or time-hopping CDMA  TH-CDMA .  DS-CDMA  In DS-CDMA, sometimes simply called CDMA, data of multiple users are spread onto the same spectrum by multiplying with a very large bandwidth PN sequence for each user signal before transmission. DS-CDMA has a soft capacity limit, and is a dynamic chan- nel allocation multiple access technique that has no ﬁxed number of users, as opposed to TDMA and FDMA. The system capacity is determined by the total power of the interfer- ence, and new users joining the network will gracefully degrade the signal quality of all the users.  The large bandwidth introduces inherent frequency diversity. This provides a high time resolution to distinguish the different multipath waves, yielding multipath-diversity gain by applying the rake diversity technique. Thus, DS-CDMA provides better diversity against selective fading by providing more frequency and time diversity, compared to TDMA. In addition, DS-CDMA can operate without timing coordination among users, as opposed to TDMA.  Efﬁcient frequency reuse can be achieved in DS-CDMA, since every cell can use the same frequency and users are separated by their unique codes. The use of the same fre- quency band by all the cells enables soft handoff to make use of macrodiversity. Since all the users share the same channel, the near–far effect will occur, that is, the power of each user received at the BS is not equal. This requires power control at the BS.  The IS-95 and most 3G mobile cellular standards select DS-CDMA as the main multiple  access scheme, where DS-CDMA is combined with FDMA or TDMA.      106   cid:2   Cellular and multiple-user systems  FH-CDMA  In FH-CDMA or FHMA, the carrier frequencies of the users are varied in a pseudoran- dom fashion within a wideband channel. The total wideband channel is divided into many narrowband slots. The user data is broken into uniform sized bursts, which are then trans- mitted on different carriers frequencies  slots  controlled by a PN sequence. FHMA often uses FSK modulation and this enables inexpensive noncoherent detection. Frequency hop- ping provides inherent diversity against frequency selective fading. It is effective to combat interception.  FHSS is used in the baseline IEEE 802.11. FHMA is combined with TDMA in DECT and GSM. FHMA is combined with DS-CDMA to provide DS FHMA in Bluetooth, where the center frequency of a direct-sequence modulated signal is hopped in a pseudorandom fashion. FHSS is more widely used in military communication systems. DS-CDMA and FH-CDMA will be introduced in Chapter 8.  TH-CDMA  TH-CDMA is not as commonly used as DS-CDMA and FH-CDMA. One reason is that it suffers from serious interference if there is a continuous transmission in its coverage area, since the TH system works in an on-and-off fashion in a frame. The TH technique usually works with the FH technique, forming a hybrid TH–FH system. TH-CDMA is the traditional method for UWB communications, and will be introduced in Chapter 20.  4.2.5 OFDMA  OFDM divides the total band into a number of subcarriers. Unlike in FDMA, where each subcarrier is separated by a guard band, OFDM overlaps them. To avoid ICI, OFDM makes the subcarriers orthogonal to each other by precisely controlling their relative frequencies and timing. OFDM can be combined with any of the multiple access techniques such as TDMA, FDMA, or CDMA.  In OFDM, one user uses all the subcarriers at a given time. OFDMA, as the multiple access in OFDM, assigns each user with a distinct subset of the subcarriers dynamically. This yields MAI-free access. OFDMA can be treated as a CDMA system with complex exponential spreading codes. In WiMax, OFDM is used for ﬁxed case  802.16d  and OFDMA for mobile case  802.16e . OFDMA is also used in 3GPP LTE. We will give more introduction to OFDM and OFDMA in Chapter 9.  4.2.6 SDMA  Space division multiple access  SDMA  separates users in a spatial way. The sectorized antenna is the simplest SDMA. SDMA is generally achieved by using directional antennas      107   cid:2   4.2 Multiple access techniques  such as an adaptive antenna array or a switching antenna array. SDMA uses the angu- lar dimension introduced by the directional antenna to channelize the signal space. The antenna array can suitably steer the beams toward the users. A system with N antenna ele- ments can distinguish at most N users. Each user can share the same channel resources such as the frequency and time slot. The multiple access gain of SDMA is inﬂuenced by the relative locations of the users. A tracking algorithm is needed to keep a high carrier-to- interference ratio  CIR . Also, an array of N antennas can create N− 1 nulls in its radiation pattern, and this can effectively reduce interference to the cell.  In practical systems, SDMA is usually implemented using sectorized antennas, and these antennas introduce several orthogonal sectors, in which TDMA or FDMA can be used to further channelize the channels. Due to its limited multiple access capac- ity, SDMA is usually used for improving the spectral efﬁciency by allowing channel reuse within a cell. In the future, smart antennas will likely simultaneously steer the beams in the directions of many users. Smart antenna technology will be dealt with in Chapter 18.  Some of the multiple-access techniques discussed above are illustrated in Fig. 4.3.  user 1  user 2  user 3  user K   a  TDMA  user 1  user 2  user 3  user K   b  FDMA  . . .  . . .  user K . . . user 3 user 2 user 1  . . .  . . .  Time  Frequency   c  CDMA   d  OFDM   e  OFDMA  Time + Frequency  Frequency  Frequency  user 1  users  1  1  2  1  2  2  1  2  . . .  user K   user 1     user 1   f  SDMA  Time + Frequency   cid:2 Figure 4.3  Illustration of some multiple access techniques.      108   cid:2   Cellular and multiple-user systems  4.3 Random multiple access  Demand-assignment-based multiple access is necessary for real-time voice and video com- munications. However, once a channel is assigned, it cannot be used by other users. When data generation is random and has a high PAPR, such as in the case of packet-based wire- less networking, random multiple access, also called packet radio, is most efﬁcient. Packet radio is easy to implement, but has low spectral efﬁciency and may cause delays. Although TDMA and FDMA are more efﬁcient when all users have data to send, wasted frequency or time slots can be up to 50% [2]. That is the reason why CDMA is very successful for voice.  In order to identify the target receiver in packet radio, each packet starts with a header that contains the address or identiﬁcation of the receiver. The header is followed by a data portion with or without error-correction protection. The most popular technique is ALOHA [1] and carrier-sense multiple access  CSMA . Random multiple access combined with a reservation protocol is more efﬁcient when the data length is long.  4.3.1 ALOHA  ALOHA can be either pure or slotted ALOHA. In pure ALOHA, a packet is trans- mitted immediately after it is generated; after a packet is transmitted, the user waits for an acknowledgment from the receiver as to whether the packet has been received without errors. If no acknowledgment is received, the packet is assumed to be lost in a collision. In this case, the user waits for a random time and retransmits the packet. A packet is successfully received only if there is no other transmission during its transmission.  Assuming that all the packets have the same length tp and the average transmission rate of all the transmitters is λp packets per second, for completely random times and different transmitters the probability that n packets are transmitted within time duration t is given by the Poisson’s distribution [18]   cid:7    cid:8 n e  n!  −λpt  .  Pr X t  = n, t  =  λpt  The possible collision time is 2tp, and the possibility that during this period there is zero packet transmitted is thus calculated as Pr X t  = 0  = e −2λptp. The effective channel throughput can be obtained by the normalized channel usage or load R = λptp   4.10    4.11   T = Re  −2R.  The maximum throughput for pure ALOHA is 18.4% at R = 0.5. The slotted ALOHA introduces some coordination by dividing time into time slots, each of which is of the packet length tp. All terminals are allowed to transmit their packets only at the beginning of each slot. The probability that during tp there is zero packet transmitted      109   cid:2   4.3 Random multiple access  Pure ALOHA Slotted ALOHA  0.4  0.35  0.3  0.25  0.2  0.15  0.1  0.05  T   t u p h g u o r h T   cid:2 Figure 4.4  0  0  1  2  Load R  3  4  Throughput of ALOHA.  is calculated as Pr X t  = 0  = e given by  −L, and correspondingly, the effective throughput is  T = Re  −R.   4.12   The maximum throughput for slotted ALOHA is 36.8% at R = 1.  Example 4.1: The throughputs of pure ALOHA and slotted ALOHA are plotted in Fig. 4.4.  ALOHA is usually used in the uplink to signal its presence and request reservations. For example, IEEE 802.15.4a uses ALOHA for channel access; in Wireless USB, the host has a number of device notiﬁcation time slots to permit unassociated devices to request membership in the cluster via slotted ALOHA protocol.  4.3.2 Carrier-sense multiple access  The popular distributed contention method is CSMA. Each node must sense the channel before sending data so as to minimize the chance of collision. Thus, the channel throughput is substantially increased over that of ALOHA. The achievable throughput for CSMA can be as high as 90% under ideal conditions.  CSMA is suitable when all the users can detect the transmissions of one another and the propagation delay is small, and this is the feature of wired LAN. The IEEE 802.3  Ether- net  standard uses CSMA with collision detection  CSMA CD , where channel sensing is performed by sending a few bits  jamming signal  and comparing it with what is sensed on the channel.      110   cid:2   Cellular and multiple-user systems  CSMA with collision avoidance  CSMA CA  is more suitable for the wireless case, since it is more energy-efﬁcient for MSs. CSMA CA attempts to avoid collisions by using explicit packet acknowledgment  ACK  from the receiving station. Collision avoid- ance is implemented by a four-way handshake prior to transmission. CSMA CA uses heuristics, including random backoff, listen-before-talk, and mandated interframe delay periods, to avoid collisions among users on the shared channel. CSMA CA is imple- mented in the IEEE 802.11 standards. Due to the added overhead, CSMA CA is slower than CSMA CD.  Hidden terminal problem  For a centralized wireless network, the BS broadcasts the status of the reverse channel via the forward channel, and thus the probability of collision is signiﬁcantly reduced. For a wireless ad hoc network, carrier sensing is not very effective, as a given user may have difﬁculties in sensing signals transmitted from the other users. Two typical problems existing for carrier sensing are the hidden terminal and the exposed terminal problems, which arise from the fact that carrier sensing is only performed at the transmitter while its effect is determined at the receiver: the absence of complete simultaneity. Also, collision detection is not possible. A wireless transceiver cannot transmit and receive at the same time, since the transmitted signal is always much stronger than the received signal. CSMA assumes the propagation delay between two nodes to be much shorter than the duration of packet. This is usually satisﬁed in land-based systems, but is not the case for satellite communications.  The hidden terminal problem is illustrated in Fig. 4.5. As illustrated, nodes A and B are out of each other’s range, and thus, they cannot hear each other. If node A is transmitting to node C, node B may still sense the channel as idle and starts to transmit; packets from A and B will collide at node C. Thus, nodes A and B are hidden terminals to each other. CSMA CA can largely avoid the hidden terminal problem by using the request-to-send and clear-to-send primitives; this is implemented in the 802.11 MAC. A sending station A transmits a request-to-send and waits for C to reply with clear-to-send. Another strategy is  Collision  A  C  B   cid:2 Figure 4.5  The hidden terminal problem.      111   cid:2   4.3 Random multiple access  A  B  C  D   cid:2 Figure 4.6  The exposed terminal problem.  the idle signal casting multiple access  ISMA , wherein each terminal is informed from the BS of the other terminals’ transmission.  Exposed terminal problem  The exposed terminal problem is shown in Fig. 4.6. Assume that nodes B and C intend to transmit only. When node C transmits to node D, node B can detect the transmission, as node B is within the radio coverage of node C. Thus, the transmission from nodes B and A are blocked, even if they are both idle. To alleviate this, a node must wait a random backoff time between two consecutive new packet transmission times to resolve contention.  Throughput  CSMA can be implemented in one of the three modes based on the method for rescheduling transmissions when a collision occurs, namely nonpersistent CSMA, 1-persistant CSMA, and p-persistent CSMA:   In the nonpersistent CSMA, a user that has a packet to transmit will sense the channel. If the channel is idle, the user transmits a packet; otherwise the user waits a random time delay, and then repeats the process.   In the 1-persistent CSMA, the user senses the channel and transmits its packet with probability 1 if it is idle; otherwise, it will wait until the channel is idle and transmit with probability 1.   The p-persistent CSMA is a generalization of the 1-persistent CSMA to reduce collision. In p-persistent CSMA, upon sensing that the channel is idle, the user transmits its packet with probability p and delays it by τ with probability 1 − p.  A thorough throughput analysis has been given in [13]. An optimum p-persistent CSMA can be achieved by ﬁnding the optimum value of p for each of the throughputs in terms of transmission delay. For small throughput, the 1-persistent  p = 1  is optimal. Slotted CSMA is also possible for ﬁxed length packets.      112   cid:2   Cellular and multiple-user systems  The normalized throughputs for some of the CSMA protocols are given below [12, 13]   Unslotted nonpersistent CSMA ,   4.13    Slotted nonpersistent CSMA ,   4.14   −aR  Re  T = T =  T = R  T = R  2  −aR   cid:8  cid:20   −R 1+2a  e  R 1 + 2a  + e−aR  cid:19   cid:7  aRe  1 + a  − e−aR  cid:8  +  1 + aR e−R 1+a  R 1 + 2a  − cid:7  1 + R + aR 1 + R + aR 1 − e−aR  cid:7   cid:8   cid:7   cid:8  + ae−R 1+a  1 + a − e −aR 1 − e−aR  1 + a   cid:8  + 2aR  cid:7   cid:7   cid:7   1 − e−aR  cid:7   −aR aRe 1 − e−aR − aRe−aR   cid:8  + a  Re−aR + bR  aRe−aR + b  1 − e−aR  −R 1+a  e  −aR  Re   cid:8  + cid:7   T =  T =   Unslotted 1-persistent CSMA ,   4.15    Slotted 1-persistent CSMA ,   4.16    cid:8   2 − e−aR   Unslotted nonpersistent CSMA CD ,   4.17   2 − e−aR − aRe−aR  Slotted nonpersistent CSMA CD ,   4.18    cid:8   where a = τd tp. For CSMA CD, b is the jamming length.  Example 4.2: The throughput for nonpersistent CSMA, as given by  4.13 , is plotted in Fig. 4.7. Maximum throughput is achieved when a = 0. As a → 0, T → R  1 + R .  a = 1, 0.7, 0.5, 0.3, 0.02, 0.005, 0  Increasing α  1  0.8  0.6  0.4  0.2  T    t h g u o r h T   cid:2 Figure 4.7  0  0  2  4  6  Channel traffic R  8  10  Throughput of nonpersistent-CSMA.      113   cid:2   4.3 Random multiple access  CSMA is generally implemented in the time domain. Although it is possible to apply the random access to frequency and code slots, the implementation is very sophisticated. For this reason, CSMA can be viewed as a type of TDMA.  Digital sense multiple access  Digital sense multiple access  DSMA  transmits channel and decode status ﬂags on the forward channel to signify whether the reverse channel is busy and whether the data block that was just received on the reverse channel has been decoded without any errors, respectively. With the information about the reverse channel, DSMA operates in a way similar to slotted CSMA CD. Slotted nonpersistent DSMA has been used in the CDPD network.  DSMA with delayed transmission  DSMA DT  [15] is designed for reverse channel to improve the throughput of DSMA for long round-trip propagation and processing delay, which occurs in outdoor, high-speed environments or when the receiver requires long signal processing time.  4.3.3 Scheduling access  When multiusers share a wireless channel, scheduling must be made for continuous data transmission, since random access leads to frequent collisions. Scheduling access methods are generally distributed contention methods and polling methods. This is deﬁned in the MAC layer of a wireless standard. For high-data-rate services, low latency operation can be achieved in a distributed contention-based MAC at low load; in heavy-load systems this can be accomplished using centralized or distributed round-robin scheduling  polling , which is static TDMA in the context of a packet-based system. Polling can achieve a throughput in excess of 90% over a channel without impairments, though it has the same drawbacks of TDMA.  In WiMAX, an MS can obtain uplink bandwidth by polling. The BS allocates dedi- cated or shared resources periodically to each MS, for it to request bandwidth. Polling can be either unicast or multicast. For multicast polling, a contention access and resolution mechanism for multiple MSs is applied.  ALOHA is still needed in scheduling access, since a predeﬁned scheduling is not avail- able at system startup. Packet-reservation multiple access  PRMA  [9] embodies this random startup by combining slotted ALOHA for bursty data with TDMA scheduling for continuous data. PRMA is used for the reverse channel, while the BS controls the forward channel. The BS broadcasts the information which the MS had successfully broadcast in the previous time slot. When there is a collision on the reverse channel, the BS transmits a negative acknowledgment  NACK .  Although CSMA CA is the mandatory data service, the 802.11 standards support an optional channel reservation scheme based on four-way handshake between the sender and receiver nodes for providing QoS. In WiMedia, each active device is required to send a beacon frame in a selected beacon slot of the superframe. Each active device has a      114   cid:2   Cellular and multiple-user systems  separate beacon slot. All the devices listen for beacons and interpret their content so as to respect declared reservations. The reservations are established via the WiMedia distributed reservation protocol.  4.4 Erlang capacity in uplink  For a given QoS, the capacity of a multiple access network is referred to as the average number of users that can be serviced. QoS can be deﬁned as 100% minus the percentage of blocked call, minus ten times the percentage of lost calls [18]. Cellular systems rely on trunking to accommodate a large number of users in a pool of a limited number of channels. Each user is allocated a channel on a per-call basis. The trunking theory was developed by Erlang in the late 19th century. The unit of trafﬁc density is now called erlang. One erlang represents the trafﬁc intensity of a channel that is completely occupied. A channel occupied half of the time has a trafﬁc of 0.5 erlang.  For a large system, the calls from users are random, and satisfy Poisson’s distribution. Assuming the total call arrival is λ calls per second, the probability of call service time t longer than T is given by  Pr t > T  = e  −μT,   4.19  where the average interval for calls is 1 μ. Deﬁne Ttr = λ μ, measured in erlang; then, Ttr is the average trafﬁc offered in the unit of users  channels .  T > 0,  Two models are usually used to characterize the Erlang capacity: lost call clearing  LCC  and lost call hold  LCH  [27]. In the LCC model, if a new user wants to enter a network with all time- frequency-slots occupied, it can only leave and will then re-enter after a random interval as a new user. This causes a slight increase in λ. The number of total states is thus 1 + Nc, where Nc is the number of available channels. In the LCH model, the user that is not served will repeat its request for service and stay in the network. This leads to a slight increase in the average interval for calls 1 μ, and the number of states will approach inﬁnity. In both the cases, Ttr = λ μ is slightly increased. Analysis of both the models is based on the Markov model [27].  The LCC model can be used to compute the call blocking probability of a time- frequency- slot system by one BS. The probability of call blocking is given by [18, 19, 27]   4.20   4.4.1 Erlang B equation   cid:24 Nc Pblock = TNc  tr  Nc! k=0 Tk  tr k!  .  This is known as the Erlang B equation. The blocking probability during the busiest hour is deﬁned as the grade of service  GoS , which must be estimated by the system designer. The GoS for the AMPS system was designed as 2% blocking [19].      115   cid:2   4.4 Erlang capacity in uplink  100  10−1  k c o l b  r P  10−2  10−3  Nc=1  2  3  4  5  10  20  40  Nc = 80  102  10−4  10−1  100  101  Ttr  erlangs   Block probability of an Erlang B system.   cid:2 Figure 4.8  Example 4.3: The blocking probability for different values of Nc and Ttr, given by  4.20 , is illustrated in Fig. 4.8. Given a blocking probability, the ratio of offered trafﬁc to available channels, Ttr Nc, can be determined using Fig. 4.8. It is seen that for small Nc, this ratio is very low, while for large Nc the ratio is slightly less than unity. For example, given Pblock = 0.001, Ttr Nc = 0.066 if Nc = 3, and Ttr Nc = 0.72 for Nc = 80. Thus for a given Pblock, Ttr increases faster than linearly with Nc, and the difference between the actual increase and the linear increase is known as the trunking gain. Thus, a large pool of channels is more efﬁcient in bandwidth efﬁciency.  The trunking efﬁciency can be deﬁned by the channel usage efﬁciency [25]  ηT = Ttr  1 − Pblock   Nc   4.21   in erlangs   channel.  4.4.2 Erlang C equation  The Erlang C system is based on the LCH model, and gives the probability of a user being on hold when there is no available channel. The blocking probability is the probability of a new call when there are Nc or more users in a system [19] −λ μ  ∞ cid:26   Pdelay = Pr tdelay > t  =  Pk = e   λ μ k k!  ∞ cid:26   cid:18  cid:24 Nc−1  k=Nc  k=0  .  Tk tr k!  k=Nc  =   cid:17   TNc tr Nc!  +  TNc tr Nc!  1 − Ttr  Nc   4.22   This is the Erlang C equation. When Nc is very large, the results of both the Erlang B and C models are very similar.      116   cid:2   Cellular and multiple-user systems  Nc = 1  2  3  4  5  100  10−1  y a l e d r P  10−2  10−3  10−4  10−1  10  20  40  Nc = 80  102  100  101  Ttr  erlangs    cid:2 Figure 4.9  Block probability of an Erlang C system.  The GoS is deﬁned as  Pr tdelay > t  = Pr tdelay > 0  Pr tdelay > ttdelay > 0   = Pr tdelay > 0 e  −  Nc−Ttr t  H  ,  where H is the average duration of a call. The average delay D for all calls is derived as   4.23    4.24    4.25   D = Pr tdelay > 0   H  Nc − Ttr  .  Example 4.4: The blocking probability for different values of Nc and Ttr is illustrated in Fig. 4.9. The result is very close to that of the Erlang B system.  Erlang C model in CDMA systems  The Erlang C equation is more suitable for mobile systems and for non-frequency- time- slot systems such as the CDMA systems. In CDMA systems, Nc is given by   4.26  which is further reduced by a factor 1 − η, η < 1. The quantity η is used to limit the ratio of total interference-plus-noise I0 to noise N0  ,   4.27  Typically, η = 0.25 to 0.1, corresponding to I0 N0 = 6 dB to 10 dB [27]. In CDMA sys- tems, Ttr = λ μ is also reduced by a voice activation factor ρ < 1. The outage probability is given by [27]  <  .  Nc = W  R Eb I0  I0 N0  1 η      117   cid:2   4.5 Protocol design for wireless networks  −ρλ μ  Pout < e   ρλ μ k k! .  k=[Nc 1−η ]  ∞ cid:26    4.28   In case of undesirable power control, an approximation for the outage probability is given in [27]. It is shown that even if the standard deviation of power control is σc = 2.5 dB, the system capacity is reduced by 20%.  The use of ρ as well as the sector gain leads to a capacity gain over frequency- time-slot systems. The ratio of Erlang capacity of the IS-95 CDMA system to that of the time- slot system,  λ μ spread  λ μ slotted, is typically 6 : 1  IS-95 to GSM  or 5 : 1  IS-95 to IS-136 , assuming the BS employs three-sector antennas [27].  4.5 Protocol design for wireless networks  A typical data network such as the internet has ﬁve layers, namely physical, data-link, net- work, transport and application layers of the OSI reference model. Wireless networks can use the same model. Very often, wireless standards have a single MAC layer that has the same functions as the data link layer. For all IEEE 802.x protocols and most other wire- less standards, only the MAC and physical layers are deﬁned. The data are delivered over existing cellular networks such as the GSM network or data communication networks such as the IP network. Unlike wired network protocols where each layer is relatively indepen- dent, many functions in wireless networks, such as power control, multiple antennas, and dynamic resource allocation, may span multiple layers of the protocol stack. For wireless networks, cross-layer design provides signiﬁcant performance gain over a strictly layered structure.  4.5.1 Layered protocol design  Channel structure  The channel structure is composed of logical channels, transport channels, and physical channels. Logical channels are offered by the MAC layer to higher layers. Transport chan- nels are offered by the physical layer to the MAC layer. Physical channels are handled in the physical layer.  A logical channel can be either a control channel or a trafﬁc channel, depending on the type of information transferred on the channel. A transport channel is a physical channel that offers information services to the MAC layer, and it can be either a common or ded- icated channel. The physical channels are deﬁned by code, frequency, and time slot. Rate matching of data that are multiplexed to dedicated and shared channels is done at the phys- ical layer. There are two types of channel mapping: physical to transport, and transport to logical channels.  The control architecture uses paging and access channels for the forward and reverse link control. Paging channels are used by the BS to inform MSs of the system parameters      118   cid:2   Cellular and multiple-user systems  and to alert the MSs of the incoming calls. The systems parameters may include a list of BSs in the neighborhood, MS location, access parameters, and information on usable channels. Access channels are used by MSs to get access to initiate a call, by providing its identiﬁcation and dialed number. The network will then decide whether to allocate a channel for the call. Access procedure is usually based on ALOHA.  Pilot channels, like paging channels, continuously transmit information to allow MSs to acquire the system parameters. It helps the MS to measure the signal strength for comparison and synchronization.  On the reverse link, transmission takes place over two types of channels: access channels and trafﬁc channels. The reverse link is usually deemed to be less reliable than the forward link, as the transmission power of the MS is constrained. For this reason, data on the reverse channel is better protected.  Physical layer design for TDMA systems  In the TDMA system, the packet of a burst is typically of ﬁxed length. Each packet typically contains information of the trafﬁc and control channels. It consists of data bits, a training sequence, and tail bits. The training sequence has a ﬁxed length and a known pattern. The received training sequence is compared with the known training sequence so as to estimate the channel and then reconstruct the rest of the original data bits; this is known as equalization. The training sequence is also used for synchronization. The data bits are then extracted. The packet is assigned in the form of a time slot, and the typical structure of a time slot is shown in Fig. 4.10. Typically, the ﬁrst and last few symbols in a packet are subject to time-domain raised-cosine shaping to prevent abrupt time-domain signal changes. For TDD, the guard section is used to account for the round-trip time delay, τ = 2d c, where d is the distance between the BS and the MS, and c the speed of light in free space. The guard section must be included in the transmit packet of the MS  reverse link  to avoid the overlap of the data from both the BS and the MS. In the forward link, the guard time is not assigned.  For example, in GSM, a time slot for normal burst contains 148 bits. Among the 148 bits, two blocks of 57-bit payload data are separated by a midamble  training sequence  of 26 bits, which is known and used for equalization. At either end of the time slot is 3 tail bits, which are also known and are used to control MLSE-based detection of burst data. A guard period of 8.25 bits are also appended to the end of the time slot. The symbol duration is 3.7 μs. The time slot structure is shown in Fig. 4.11. In GSM, data transmission is in a circuit-switched mode, just like voice transmission. For the GSM system, there are  Sync, training  Signaling  User Data  Guard   cid:2 Figure 4.10  Slot  Packet structure of a time slot.      119   cid:2    cid:2 Figure 4.11  4.5 Protocol design for wireless networks  Tail  3  Control  Control  Tail  Data  57  Midamble  1  26  1  Data  57  Guard  3  8.25  bits  156.25 bits, 576.92 μs  Structure of a normal burst in GSM.  also other kinds of bursts: access burst, S burst for time synchronization, and F burst for frequency synchronization.  In GSM, eight different PN-sequences are designed for midambles in the normal burst, so that different midambles can be used in different cells. These PN sequences have low cross-correlation and speciﬁc autocorrelation functions. The reason for using midamble rather than preamble is to keep the channel estimate to be sufﬁciently accurate at both the beginning and end of the burst, since the channel of GSM is time-varying for speeds of MSs up to 250 km h.  A frame is a basic period in a wireless standard. In the forward link, multiple slots con- stitute a frame. All MSs are synchronized to the frame timing of the BS. For GSM, a frame is comprised of 8 time slots and covers 4.61 ms, 26 frames constitute a superframe cover- ing 6.12 s, which is the period for all channel arrangement modes, and 2,048 superframes constitutes a hyperframe, which covers 3 h and 28 min.  Physical layer design for CDMA systems  In the FDD-based CDMA system, channelization is realized by using different codes. All the channels use the same frequency band. The pilot channel allows the MS to perform timing acquisition from a BS, channel estimation, and signal strength estimation of all neighboring BSs. The pilot channel uses Walsh code 0  all-zeros code  for transmission. The pilot channel is not power controlled, since it is used by all the MSs. It is so important that typically 20% of the total BS power is allocated to the pilot channel.  In the IS-95 CDMA system, the BSs are synchronized based on the GPS. The BS uses the synchronization channel to transmit system information to the MS so that the MS synchronizes itself to the network. This channel is not scrambled. Each frame of the synchronization channel is aligned at the start of the long-code PN-sequence. The syn- chronization channel uses Walsh code 32. Other channels are also used to carry system information.  WCDMA is a FDD-based hybrid TDMA CDMA scheme. Unlike IS-95, transmission in WCDMA is still based on a hierarchical time slot structure very similar to that of GSM. A frame has a duration of 10 ms, which is divided into 15 time slots.  MAC layer design  The MAC layer protocol implements admission control and scheduling. It performs request collection and request scheduling. The request scheduler is used to arbitrate the requests      120   cid:2   Cellular and multiple-user systems  from the participating devices so as to achieve a high bandwidth efﬁciency and also a high QoS to the devices. Due to the conﬂicting requirements of bandwidth efﬁciency and QoS, a tradeoff between them must be made by a scheduling algorithm. A good scheduling algorithm must consider factors such as system throughput, channel quality, fairness, QoS, and admission control of new devices. To guarantee QoS, a central scheduling approach is the preferred solution.  For MAC layer protocol design of the TDMA system, dynamic or ﬁxed frame structure can be used. MAC layer design of the CDMA system should consider the downlink power budget and the uplink interference limit. In MAC layer design, if the ARQ protocol is used, when a packet is received with error, instead of discarding it the MAC layer can save it and combine it with the retransmitted packet as a form of diversity. Type-I and Type-II HARQ can be used for this purpose. Both methods can substantially increase throughput when compared with the simple retransmission [11].  4.5.2 Cross-layer design  The OSI model allows multi-vendor computers to interact and communicate, but QoS is not considered as an issue in the design process. The protocol stack design is highly rigid and strict, and there is no collaboration between the different layers. This may cause problems for real-time applications such as VoIP. The challenges of mobile communication systems cannot be met with a layered design approach.  Cross-layer design is now a new hype in wireless communication systems. As energy management, security and cooperation are cross-layered in nature, cross-layer protocol interactions can improve network efﬁciency and QoS support. Cross-layer design is partic- ularly important for any type of wireless network, since the state of the physical medium can signiﬁcantly vary over time.  A simple cross-layer design requires adaptability in the MAC and PHY layers in response to application services. For multimedia services, the MAC layer needs to dis- tinguish the service type and its associated QoS requirements, and map the service to the corresponding physical layer conﬁguration. HARQ is also a commonly used cross-layer approach, as it involves the interaction of the MAC and physical layers.  Cross-layer design can take an evolutionary  such as for 4G mobile systems  or a rev- olutionary approach  for WSNs . The evolutionary approach is mainly used for cellular communications and wireless networking, since compatibility with existing systems and networks is extremely important. Most existing cross-layer designs are evolutionary, as they need to communicate with the rest of the world, that is, the IP network. The revolu- tionary approach can be applied to speciﬁc applications  such as WSNs  where backward compatibility is not important.  Layer triggers are the most basic implementation of cross-layer design. This method is cheap to implement, and it also maintains compatibility with existing layered structure. Layer triggers are predeﬁned signals that are used to notify special events between proto- cols. A modern implementation of TCP has the ECN-bit in the TCP header, which can be used for transmission rate control [6].      121   cid:2   4.6 Quality of service  The MobileMan reference architecture [5] implements a system-wide cross-layer design in a MANET protocol stack using 802.11. Protocols belonging to different layers cooper- ate by sharing network status, while still maintaining the layer separation in the protocol design. The core component is the network status repository. Whenever a protocol in the stack collects information, it will publish this to the repository, thus making it available for every other protocol.  Cross-layer scheduling can signiﬁcantly enhance multiuser system capacity by using the time-varying nature of the wireless channel, and both the physical layer and the MAC layer are required to jointly adapt to the changing channel [14]. In the physical layer, adap- tation can be achieved by using appropriate forward error correction  FEC  and modulation levels according to the instantaneous CSI. In the MAC layer, users with good CSI can be assigned more opportunity, and thus a higher instantaneous throughput is achieved by using the adaptive physical layer. This, however, leads to the fairness problem. Fairness can be deﬁned as effort fair if the allocation of services to different users is fair, or outcome fair if the actual realized throughput is fair. Many scheduling models including the fairness notion are available in the literature for wireless networks [14].  Cross-layer design requires information exchange between layers. This information can be adapted at each layer. Adaptation at each layer should compensate for variations of the speciﬁc time scale at that layer. Diversity can also be exploited into each layer. Cross- layer design is especially suitable for systems that exploits multiple antennas and AMC techniques.  4.6 Quality of service  End-to-end QoS is a major concern for customers, since they pay for the service. Current 3G and future-generation cellular communications are based on IP technology to deliver data, voice, video, messaging, or multimedia. However, IP was designed for survivability and provides best-effort data, but does not provide QoS. QoS can be more easily realized by polling.  QoS requires mechanisms in both the control plane and the data plane [2]. In the control plane, users and the network are allowed to negotiate and agree on the required QoS spec- iﬁcations so that the network can allocate resources for each service. This is implemented by QoS policy management, signaling, and admission control. The data plane enforces the agreed-on QoS by classifying the incoming packets into several queues and allocating resources to each queue. The classiﬁcation is based on the headers of the incoming packets.  QoS for IP  IP does not provide QoS. Some form of QoS can be provided by transport layer protocols that run over IP, such as TCP and RTP. These transport layer protocols cannot control the end-to-end delay or throughput that is controlled by the network. For this reason, QoS mechanisms must be placed into the network layer. For this reason, the IETF developed a      122   cid:2   Cellular and multiple-user systems  number of protocols for delivering QoS over the IP network, such as the IntServ  integrated services , DiffServ  differential services , and MPLS  multiprotocol label switching .  IntServ employs the resource reservation protocol  RSVP  for signaling end-to-end QoS requirements and making resource reservations. IntServ provides a guaranteed IP QoS, but it has serious limitations such as the attendant scalability problems, and high overhead of signaling and state maintenance. This makes IntServ suitable only for small networks.  DiffServ is a multi-purpose control protocol which uses the TOS-bit in the IP header to identify and mark different types of packets, so as to provide different QoS classes for different types of data. DiffServ depends on aggregate trafﬁc handling, rather than the per- ﬂow trafﬁc handling used in IntServ. DiffServ lacks the degrees of service assurance and granularity offered by IntServ, but it provides good QoS that is scalable and easy to deploy. The DiffServ mechanism is therefore suitable for providing QoS to large IP networks.  MPLS inserts a new ﬁxed-length label between the layer 2 and IP headers of a packet. The label speciﬁes how the packet is treated within the MPLS network. Packets are not routed using IP headers, but are switched using the information in the label. MPLS itself does not provide an end-to-end IP QoS mechanism, but it provides an infrastructure on which IntServ and DiffServ mechanisms can be implemented. However, MPLS breaks the end-to-end principle of the IP.  In WiMAX, the QoS architecture employs the concept of service ﬂow in the MAC layer. Each service ﬂow is associated with a set of QoS parameters, such as latency, jitter through- put, and packet error rate. In WiMAX  IEEE 802.16 , four services are deﬁned to support different types of data ﬂows: [4]   Unsolicited grant service  UGS  for real-time constant bit rate  CBR  trafﬁc such as VoIP.   Real-time polling service  rtPS  for variable-bit-rate trafﬁc such as MPEG video.   Non-real-time polling service  nrtPS  for delay-tolerant data service with a minimum data rate, such as FTP  File Transfer Protocol .   Best-effort service, which does not specify any service related requirements.  IEEE 802.16e includes an additional service known as extended rtPS  ErtPS , which pro- vides a scheduling algorithm that builds on the efﬁciency of both UGS and rtPS. This service supports real-time service ﬂows that generate variable size data packets on a periodic basis. 1xEV-DO supports both user- and application-level QoS.  Resource-allocation techniques  In order to support the various QoS requirements, many resource-allocation algorithms can be applied. These algorithms can take advantage of multiuser diversity and AMC. Resource allocation is usually formulated as a constrained optimization problem, which either maximizes the total data rate with a constraint on the total transmit power or mini- mizes the total transmit power subject to a constraint on user data rate. There are a number of resource-allocation techniques [2]: maximum sum-rate algorithm, maximum fairness algorithm, proportional rate constraints algorithm, and proportional fairness scheduling.      123   cid:2   4.7 User location  The maximum sum-rate algorithm maximizes the sum rate of all users, subject to a total transmit power [29]. A few users that are close to the BS may be allocated all the sys- tem resources, due to their good channels, while other users may never get the resources. The maximum fairness algorithm tries to maximize the minimum user data rate, and this generates equalized data rate for all users [20]. This method has an inﬂexible rate dis- tribution among users, and the total throughput is limited by the user with the worst SINR. The proportional rate constraints algorithm aims to maximize the sum through- put, with the constraint that each user’s data rate is proportional to a set of prespeciﬁed parameters [24]. This method is more suitable when different users require different data rates.  Unlike the other three algorithms which attempt to instantaneously achieve their respec- tive objectives, proportional fairness scheduling achieves its objective over time [26]. In this case, in addition to throughput and fairness, latency can also be traded for additional ﬂexibility to scheduling. Proportional fairness scheduling takes advantage of multiuser diversity while providing comparable long-term throughput for all users. Proportional fairness scheduling has been widely used in packet data systems, such as HSDPA and 1xEV-DO.  4.7 User location  User location or positioning offers important services for the users, and it also signiﬁcantly increases the performance of the cellular network. Also, wireless user location is important for public safety, since a large portion of all emergency 911  E-911  calls originates from mobile phones. For this reason, the FCC issued, in 1996, an order that mandates all wire- less service providers to deliver accurate location in case of E-911 calls. Wireless E-911 services require a location accuracy to within 100 m for 67 percent of the cases. However, user location is challenging due to the adverse wireless channel. In 4G wireless networks, the location of users is required to be determined. IEEE 802.16m supports E-911. Location is also an option for IEEE 802.15.4 and 802.15.4a.  Principles of basic location techniques  Basic location techniques are RSSI positioning, DoA positioning, time-of-arrival  ToA  positioning, and time-difference-of-arrival  TDoA  positioning [21]. These techniques are illustrated in Fig. 4.12. They are all network-based techniques. For all the cases, multipath propagation may inﬂuence the location accuracy.  RSS positioning is attractive, as the implementation complexity is low; but this approach is traditionally treated as a coarse positioning method due to signal fading caused by multipath propagation. RSSI measurement can be accurate in dense sensor networks [28]. The DoA positioning technique determines the position of an MS using triangulation. This is illustrated in Fig. 4.12a. The intersection of two directional lines determines a unique position. Thus, a pair of BSs is required for location. The estimation of DoA      124   cid:2   Cellular and multiple-user systems  Station 3  Station 1  Station 3  Station 1  Station 2  Station 1  Station 2   cid:2 Figure 4.12  Three location techniques.  a  DoA positioning.  b  ToA positioning.  c  TDoA positioning.   a    b   Station 2   c   requires directional antennas or antenna arrays, thus it is difﬁcult to estimate the DoA at the MS. The method does not require synchronization at the receiver, but requires cali- bration of antennas. In addition, the method does not perform well in indoor environments due to multipath propagation.  The ToA positioning technique determines the position of the MS as the intersection of three circles, as illustrated in Fig. 4.12b. The ranging is based on the propagation time of the radio wave. This technique requires the synchronization of the transmitter and receiver. The Cramer-Rao lower bound  CRLB  of a ToA estimate is given by [3]  τ ≥ σ 2  1  ,  8π 2B2γ   4.29   where σ 2 τ is the variance of the ToA estimate, B is the bandwidth of the received signal, and γ is the bit SNR  Eb N0 . Since the impact of the bandwidth is quadratic, but the impact of the SNR is linear, spread-spectrum and UWB are good choices for accurate ranging. The GPS is based on spread-spectrum technology for timing accuracy.  ToA positioning is a low-complexity, accurate measurement method based on energy detection. However, it requires a precise time synchronization among the nodes. ToA esti- mation is made on the basis of the symbol rate samples that are obtained after a square-law device. ToA positioning is used in the GPS system, where the circles are replaced by spheres in space and a fourth sphere is required to solve the receiver-clock bias in the 3D case. This bias arises from the unsynchronized clocks between the receiver and the satellite. ToA positioning has been standardized within IEEE 802.15.4a.  The TDoA positioning technique determines the position of the MS by using trilater- ation. This is illustrated in Fig. 4.12c. It uses time differences rather than absolute time measurements. The difference between the time instants that the transmitted signal is received at the two BSs is converted to a difference between the distance from the trans- mitter to one of the two BSs and that from the transmitter to the other BS. The distance difference is used to deﬁne a hyperbolic curve, with the two BSs as the two foci. Two hyper- bolas determine the location, and thereby two pairs  at least three  of BSs are required. The TDoA technique eliminates the requirement of time synchronization. Pulsed-UWB signals have a ﬁne time resolution, and this makes pulsed-UWB technology a prominent choice for indoor positioning using ToA TDoA estimation. Location is enabled for the IR-UWB mode of IEEE 802.15.4a.      125   cid:2   4.7 User location  Types of location systems  When multiple network BSs are involved in wireless user location, the method is known as network-based wireless location. The BSs measure the signals transmitted from an MS and relay them to a central site for estimation of the MS location. In this technique, the MS is not involved in the location-ﬁnding process and thus, no modiﬁcation to the existing handset is required.  When the MS determines its location from signals received from some BSs or from the GPS, the technique is called mobile-based location. This requires the integration of a location estimation module such as a GPS receiver into the MS. The cell-ID solution is faster for deployment, but has a low accuracy. Mobile-based location mainly depends on satellite-based positioning techniques. The satellite-based solution is very accurate, but is not reliable in urban or in-building environments, as the receiver cannot see four satellites in its LOS. It is also expensive to deploy. Mobile and network-based techniques can be combined to provide a more robust estimate of the location in a single process. An overview of wireless location techniques and challenges can be found in [22].  The US GPS is a real-time, worldwide, satellite-based positioning system. GPS has become the standard location and navigation system. GPS positioning accuracy now exceeds that of most other positioning systems. It does not need calibration as microwave equipments do. GPS provides a precise and standard positioning service. The Euro- pean Galileo, and the Russian GLONASS  Global Navigation Satellite System  are satellite-based positioning systems to rival with GPS. The Galileo system is still in devel- opment, but promises a higher accuracy than GPS. The principle of satellite positioning is the same as the network-based techniques, where a satellite corresponds to a BS for positioning.  The operating frequency of a location system determines the operating range and accu- racy. In general, the higher the operating frequency, the better the positioning accuracy and the shorter the range. Microwave and UWB location systems in the super high frequency  SHF, 3–30 GHz  range are most commonly used over the range of 100 meters, with an accuracy of up to 1 cm.  A wideband system can achieve a higher location accuracy than a narrowband system. In the time-based approach, the absolute resolution of location,  cid:21 , is related to the signal bandwidth B by   cid:21  = c B  ,   4.30   where c is the speed of light. For an UWB system, the bandwidth is usually in excess of 3 GHz, thus the location accuracy is of the order of 1 cm. The large bandwidth helps to resolve multipath and interference, but due to the high attenuation associated with the high-frequency portion of the signal, the range is typically limited to 100 meters. UWB- based location is especially attractive [21], and it can be used for ad hoc networking, smart homes and ofﬁces, inventory control, sensor networks, smart highways, and manufacturing automation.  In the indoor radio channel, it is difﬁcult to accurately measure the DoA, carrier signal phase of arrival  PoA  and RSSI; thus, indoor positioning systems mainly use ToA based      126   cid:2   Cellular and multiple-user systems  techniques. The UWB system is a means of measuring accurate ToA for indoor geolocation applications. Due to the high attenuation for high frequencies, the frequency band used for a UWB system is typically within 2–3 GHz. IEEE 802.15.4a is based on UWB technology, and can provide high-precision location. Indoor localization has given risen to a multitude of applications in warehousing, supply-chain management, health care, public safety, and military.  The DSSS wideband signal is also used in ranging systems. A transmitter transmits a signal spread by a known PN sequence, and the receiver cross-correlates the received signal with a locally generated PN sequence using a sliding correlator. The distance is determined from the arrival time of the ﬁrst correlation peak.  Problems  4.1 Given a total bandwidth for cellular operator as 12.5 MHz. If each voice channel needs a bandwidth of 30 kHz, what is the total number of simplex channels per cluster and per cell in a 7-cell cluster? 4.2 Derive Equation  4.5 . Evaluate the C I ratio for N = 7 and γ = 3. 4.3 Consider a cellular system with hexagonal cells of radius R = 2 km. If the minimum distance between cell centers that use the same frequency is D = 10 km, ﬁnd the reuse factor N and the number of cells per cluster. For a total of 1000 channels, determine the number of channels assigned to each cell.  4.4 If a user makes 10 calls per day with an average call duration of 6 minutes, what is the trafﬁc due to this caller?  4.5 If there are 400 seizures  connected calls  and 20 blocked calls during the busiest hours, what is the GoS?  4.6 Consider a CDMA system with perfect power control within a cell. Assuming a target SIR of 10 dB, a processing gain of 100, the nonorthogonal spreading code with ξ = 2 and equal average power from inside and outside of the cell, ﬁnd the user capacity of the system.  4.7 Determine the propagation delay for the case of a channel data rate of 19.2 kbits s and packet length of 256 bits. If a LOS radio link exists for any user which is at most 10 km away from the BS, what is the best choice for the number of bits per packet if slotted ALOHA is used?  4.8 In a pure ALOHA system, the channel bit rate is 2400 bits s. Suppose each user trans- mits a 60-bit message every minute on the average.  a  Determine the maximum number of terminals that can use the channel.  b  What is the corresponding result in the case of slotted ALOHA?      127   cid:2   Problems  4.9 For a pure ALOHA system operating with a throughput of T = 0.15 and packets generated with a Poisson’s distributed arrival rate, determine  a  the value of the load R and  b  the average number of attempted transmissions for sending a packet.  4.10 Consider a pure ALOHA system with a transmission rate of 1 Mbit s. Compute the load R and throughput T for a system with 200 bit packets and an average transmission rate of λp = 500 packets per second. What is the effective data rate? 4.11 The maximum calls per hour in a cell is 5000 and the average call holding time is 140 seconds.  a  Find the offered load for a GoS of 2%.  b  How many service channels are required for handling the load?  4.12 How many users can be supported by 50 channels at a GoS of 2%? Assume the average call holding time is 120 seconds and the average busy hour call per user is 1 call per hour.  4.13 A trunk accumulated 0.5 erlang of usage while 6 calls were carried in an hour without overﬂow. What is the average holding time per call?  4.14 A wireless LAN operates at a data rate of 10 Mbits s, and the packets are of length 500 bits. The maximum propagation τ = 0.5 μs. Calculate the normalized throughput using  a  an unslotted nonpersistent,  b  a slotted persistent,  c  a unslotted 1-persistent, and  d  a slotted 1-persistent CSMA protocol. Remark on the results.  4.15 Calculate the capacity and spectral efﬁciency of a single sector DS-CDMA system if the total bandwidth is 10 MHz, the bandwidth efﬁciency is 0.9, the frequency reuse efﬁciency is 0.5, the capacity degradation factor is 0.8, the voice activity factor is 0.38, the data rate is 9.6 kbits s, and Eb N0 = 8.9 dB. 4.16 The GSM system transmits at 270.8 kbits s to support 8 users per frame. If each user occupies one time slot per frame, what is the raw data rate for each user? In each time slot, guard and other overheads consume a rate of 10.1 kbits s. What is the user trafﬁc efﬁciency?  4.17 A cell in a blocked call delayed cellular system has 8 channels. Assume that the probability of a delayed call is 5%, each user has a load of 0.10 erlang, and λ = 0.75 call per busy hour. Determine the maximum number of users that the cell can support. Determine the probability that a delayed call needs to wait for more than 20 seconds.  4.18 In a pure ALOHA system, the average packet arrival rate is assumed to be 103 packets s. The transmission rate is 10 Mbits s, and each packet has 1500 bits. What is the normalized throughput of the system? At what packet length is the throughput maximized?  4.19 What is the ratio of the cluster sizes needed for two systems with 9 dB and 15 dB C I requirements?      128   cid:2   Cellular and multiple-user systems  References  [1] N. Abramson, The ALOHA system – another alternative for computer communica- tions. In Proc. Amer. Federation Inf. Proc. Soc. Fall Joint Comput. Conf., Nov 1970, 281–285.  [2] J. G. Andrews, A. Ghosh & R. Muhamed, Fundamentals of WiMAX: Understanding  Broadband Wireless Networking  Upper Saddle River, NJ: Prentice Hall, 2007 .  [3] W. C. Chung and D. S. Ha, An accurate ultra wideband  UWB  ranging for precision  asset location. In Proc. IEEE UWBST, Reston, VA, Nov 2003, 389–393.  [4] C. Cicconetti, L. Lenzini & E. Mingozzi, Quality of service support in IEEE 802.16  networks. IEEE Network, 20:2  2006 , 50–55.  [5] M. Conti, G. Maselli, G. Turi & S. Giordano, Cross-layering in mobile ad hoc network  design. IEEE Computer, 37:2  2004 , 48–51.  [6] S. Floyd, TCP and explicit congestion notiﬁcation. ACM Comp. Commun. Rev., 24:5  [7] K. S. Gilhousen, I. M. Jacobs, R. Padovani, A. J. Viterbi, L. A. Weaver, Jr. & C. E. Wheatley, III, On the capacity of a cellular CDMA system. IEEE Trans. Veh. Tech., 40:2  1991 , 303–312.  [8] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University   1994 , 10–23.  Press, 2005 .  [9] D. J. Goodman, R. A. Valenzuela, K. T. Gayliard & B. Ramamurthi, Packet reserva- tion multiple access for local wireless communications. IEEE Trans. Commun., 37:8  1989 , 885–890.  [10] IEEE 802.21 WG, Draft IEEE Standard for Local and Metropolitan Area Net- works: Media Independent Handover Services, IEEE LAN MAN Draft IEEE P802.21 D11.0, May 2008.  [11] S. Kallel, Analysis of memory and incremental redundancy ARQ schemes over a  nonstationary channel. IEEE Trans. Commun., 40:9  1992 , 1474–1480.  [12] G. E. Keiser, Local Area Networks  New York: McGraw-Hill, 1989 . [13] L. Kleinroch & F. A. Tobagi, Packet switching in radio channels: part I – carrier sense multiple-access modes and their throughput-delay characteristics. IEEE Trans. Commun., 23:12  1975 , 1400–1416.  [14] V. K. N. Lau & Y.-K. R. Kwok, Channel Adaptive Technologies and Cross Layer Designs for Wireless Systems with Multiple Antennas: Theory and Applications  New Jersey: Wiley, 2006 .  [15] K. K. Leung , J.-M. Ho & H. Chien, A new digital sense multiple access  DSMA  protocol for high-speed wireless networks. In Proc. IEEE PIMRC, Boston, MA, Sep 1998, 3, 1360–1366.  [16] V. H. MacDonald, The cellular concept. Bell Syst. Tech. J., 58:1  1979 , 15–41. [17] D. Middleton, Statistical-physical models of electromagnetic interference. IEEE  Trans. Electromagnetic Compatibility, 19:3  1977 , 106–127.  [18] A. F. Molisch, Wireless Communications  Chichester, UK: Wiley-IEEE, 2005 .      129   cid:2   References  [19] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall, 2002 .  [20] W. Rhee & J. M. Ciofﬁ, Increase in capacity of multiuser OFDM system using dynamic subchannel allocation. In Proc. IEEE VTC, Tokyo, Japan, May 2000, 1085–1089.  [21] Z. Sahinoglu, S. Gezici & I. Guvenc, Ultra-wideband Positioning Systems   Cambridge, UK: Cambridge University Press, 2008 .  [22] A. H. Sayed, A. Tarighat & N. Khajehnouri, Network-based wireless location. IEEE  Signal Process. Mag., 22:4  2005 , 24–40.  [23] A. U. H. Sheikh, Wireless Communications: Theory and Techniques  Boston, MA:  [24] Z. Shen, J. G. Andrews & B. L. Evans, Adaptive resource allocation for mul- tiuser OFDM with constraint fairness. IEEE Trans. Wireless Commun., 4:6  2005 , 2726–2737.  [25] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  [26] P. Viswanath, D. N. C. Tse & R. Laroia, Opportunistic beamforming using dumb  antennas. IEEE Trans. Inf. Theory, 48:6  2002 , 1277–1294.  [27] A. J. Viterbi, Principles of Spread Spectrum Communication  Reading, MA: Addison-  [28] R. Zemek, D. Anzai, S. Hara, K. Yanagihara & K. Kitayama, RSSI-based localization without a prior knowledge of channel model parameters. Int J. Wireless Inf. Networks, 15:3 4  2008 , 128–136.  [29] Y. J. Zhang & K. B. Letaief, Multiuser adaptive subcarrier-and-bit allocation with adaptive cell selection for OFDM systems. IEEE Trans. Wireless Commun., 3:4  2004 , 1566–1575.  Kluwer, 2004 .  2001 .  Wesley, 1995 .      5  Diversity  5.1 Diversity methods  Two channels with different frequencies, polarizations, or physical locations experience fading independently of each other. By combining two or more such channels, fading can be reduced. This is called diversity. Diversity ensures that the same information reaches the receiver from statistically independent channels. There are two types of diversity: microdi- versity that mitigates the effect of multipath fading, and macrodiversity that mitigates the effect of shadowing.  For a fading channel, if we use two well-separated antennas, the probability of both the antennas being in a fading dip is low. Diversity is most efﬁcient when multiple diversity channels carry independently fading copies of the same signal. This leads to a joint pdf being the product of the marginal pdfs for the channels. Correlation between the fading of the channels reduces the effectiveness of diversity, and correlation is characterized by the correlation coefﬁcient, as discussed in Section 3.4.2. Note that for an AWGN channel, diversity does not improve performance.  Common diversity methods for dealing with small-scale fading are spatial diversity  multiple antennas with space separation , temporal diversity  time division , frequency diversity  frequency division , angular diversity  multiple antennas using different antenna patterns , and polarization diversity  multiple antennas with different polarizations . Macrodiveristy is usually implemented by combining signals received by multiple BSs, repeaters or access points, and the coordination between them is part of the networking protocols.  Spatial diversity  Equation  3.83  is valid based on an assumption of using omnidirectional antennas and uniform incident power. For an antenna array using omnidirectional antennas, such as in the MS case, the correlation between adjacent antenna elements can be calculated by  3.83 . In this case, f2 − f1 = 0, and vτ = d is the distance between the two antennas.  Example 5.1: The correlation coefﬁcient between two antenna elements is plotted in Fig. 5.1. At around d = 0.2λ, the correlation coefﬁcient ρxy = 0.5. At d = 0.38λ, ρxy = 0. As a rule of thumb, for uniform incident directions, the spacing of antenna is usually taken as approximately 0.5λ.      131   cid:2   5.1 Diversity methods  1  0.8  0.6  0.4  0.2  y x  ρ   cid:2 Figure 5.1  0  0  1  2 d λ  3  4  Correlation coefﬁcient of two antennas.  This model is invalid for cellular BSs, since the interacting objects surrounding MSs make the uniform incident power assumption invalid. To obtain sufﬁcient decorrelation, one has to increase the antenna spacing.  Temporal diversity  Signals that are received at different time instants are uncorrelated. In order to identify a time-variant channel with a band-limited Doppler spectrum, similar to the sampling the- orem for identifying a signal with a band-limited spectrum, the temporal sampling rate should be at least twice the maximum Doppler frequency νmax  fmin = 1 τmax  = 2νmax.   5.1   This criterion ensures the identiﬁability of the channel. For temporal diversity with suf- ﬁcient decorrelation, the minimum time separation must be greater than τmax. Temporal diversity can be converted into space diversity.  Temporal diversity is usually implemented by using FEC with interleaving, and ARQ. Multipath diversity is also a type of temporal diversity, collecting and combining signal multipath components to obtain a stronger signal. Transmission with adaptive modulation, which requires the knowledge of the channel, is also a kind of temporal diversity.  Frequency diversity  In this case, the same signal is transmitted at multiple frequencies, which are separated by at least the coherent bandwidth of the channel. This can again be analyzed by using  3.83 , where the numerator is unity since vt = 0. For a correlation coefﬁcient smaller than 0.5,  cid:18 f ≥ 1 . Frequency diversity is rarely implemented this way for the sake of frequency  2π σt      132   cid:2   Diversity  efﬁciency. Instead, the information is spread onto a wide frequency band to combat fading, and this is embodied in TDMA, frequency hopping, CDMA, and OFDM.  Angular diversity  Angular diversity, also known as pattern diversity, uses multiple antennas at the same loca- tion, each having a different pattern, so that multipath components from different DoAs are attenuated differently. These antennas should be placed by minimizing mutual coupling, which changes the beam patterns of all the antennas. Angular diversity is usually com- bined with spatial diversity. Smart antennas with steerable or ﬁxed multiple narrow beams are now used in wireless systems.  Mutual coupling changes the individual antenna patterns, but it is insigniﬁcant unless the antennas are located very close to one another. Mutual coupling may result in a higher spa- tial correlation between the antenna signals by reradiation of the received power, leading to a reduction in the capacity.  Polarization diversity  Horizontally- and vertically-polarized multipath components have different pro-pagation over a wireless channel. Fading of signals with different polarizations is statistically inde- pendent. A scattering environment tends to depolarize a signal. Thus, receiving the signal using two different polarized antennas provides diversity. Two cross-polarized anten- nas with no spacing between them can provide diversity. Cross-polarized systems are of interest since they are able to double the antenna numbers using half the spacing for co-polarized antennas. Polarization diversity can achieve a diversity gain as high as that of space diversity alone in reasonable scattering areas [44], and thus it is being deployed in more and more BSs now. The sum of the multipaths is determined by their relative phases and their polarizations. This may lead to prolonged deep fades, and to avoid this problem, a fast polarization-hopping diversity scheme was proposed in [53].  Macrodiversity  Macrdiversity, or large-scale space diversity, also achieves high capacity by receiving and or transmitting the same signal through multiple BSs. It is an effective method for combating shadowing. Soft handoff in CDMA systems is a well-known implementation of macrodiversity. At any instant, the BS with the best quality is chosen to serve the MS, and the local-mean power criterion is usually used since the branch selection cannot be so fast compared to the rapidly varying instantaneous signal power. In TDMA systems, hard handoff has to be used due to the nonuniversal frequency reuse; however, the use of dynamic channel assignment techniques can help TDMA beneﬁt from the macrodiversity by implementing soft handoff.      133   cid:2   5.2 Combining multiple signals  Cooperative diversity  Cooperative diversity is an effective and promising method to combat fading in wire- less channels in a mobile ad hoc network or a cellular network. Users or nodes in a wireless network share their resources and transmit cooperatively, and these users or nodes collectively function like an antenna array, thus providing diversity. For exam- ple, combining the signals transmitted from the direct and relay links provides a kind of diversity.  5.2 Combining multiple signals  Diversity is an effective method for combating fading by improving SNR. In cellular sys- tems, diversity can also be used to reduce CCI. Diversity has a considerable impact on other aspects of wireless transmission, such as reducing the impact of random FM noise, which is produced as a result of channel fading for angle modulation.  As the receiver has multiple independent fading copies of the same signal, it has to com- bine these signals to improve the quality of the detected signal. Diversity can be exploited in two ways: selection diversity that selects and processes the best signal copy and dis- cards all other copies, and combining diversity that combines all copies of the signal and processes the combined signal. Combining diversity produces a better performance, but has a much more complex receiver than selection diversity has. Combining diversity is processed at the baseband. All the diversity techniques can also be implemented in digital systems.  For multiple antennas, the gain is due to diversity gain and beamforming gain. Diver- sity gain is the gain due to the fact that the received copies at multiple antennas have little probability of being in a fading dip simultaneously; this corresponds to selection diversity. Beamforming gain corresponds to combining diversity which averages over noises at dif- ferent antennas. For selection diversity, only one RF chain is required, while for combining diversity multiple RF chains are required.  Combining diversity exploits the information of all received signal copies. Combin- ing can be based on maximum ratio combining  MRC  or equal gain combining  EGC . For highly time-varying channels, the phase estimation is difﬁcult. Unlike MRC and EGC, square-law combining achieves diversity without the need for phase estimation. Square-law combining of orthogonally modulated signals, such as FSK or DS-CDMA signals that are widely used for noncoherent demodulation, is a method for exploiting diversity.  Diversity and channel coding can both improve the average probability of a detection error as well as the outage probability. Assuming maximum-likelihood  ML  detection and MRC, at high SNR, the error probability for a fading channel can be expressed by  Pe ∝ γ −Gd  ,  Gc   5.2       134   cid:2   Diversity  slope = −1     B d      R E B    slope = −Gd  Gc   cid:2 Figure 5.2  SNR  dB   Inﬂuence of diversity and coding gains on BER.  where Gc is the coding gain, γ is the symbol SNR, and Gd is the diversity order. Gc and Gd inﬂuence the bit error probability  BEP , also called bit error rate  BER ,1 in different ways, as shown in Fig. 5.2 on a log–log scale. In the ﬁgure, the line with slope −1 corre- sponds to Gd = 1, that is, there is no diversity gain. The coding gain Gc shifts the BER curve to the left.  From  5.2 , the diversity gain or order can accordingly be deﬁned as  Gd = − lim γ→∞  log2 Pe  γ    .  log2 γ   5.3   5.2.1 Selection diversity  Selection diversity is based on the largest instantaneous power, also known as RSSI.  Outage probability   cid:7    cid:19    cid:20    cid:8  = Nr!  The pdf of the selected signal is the product of the pdfs of each diversity branch  pγmax γ   = p  γ1, γ2,··· , γNr  max  < γ  p  γi < γ   ,   5.4    cid:20   cid:19  where γi is the instantaneous SNR on the ith diversity branch, and Nr is the number of diversity branches. For Rayleigh fading, the average SNR on the ith branch is γ i = E , γi the SNR distribution is exponential p  γi  = 1 −γi γ i, and the outage probability is e  cid:17  given by   cid:18   i=1  Nr!   cid:14  γ0  1 − e  −γ0 γ i  .   5.5   γ i  p  γi  dγ = Nr!  i=1  Pout  γ0  =  0  i=1  1 BEP and BER are equivalent words in this book.      135   cid:2   5.2 Combining multiple signals  If the average SNR is the same for all branches γ i = γ , the outage probability of the  selection combiner is given by  Differentiating Pout γ0  with respect to γ0 leads to the distribution for γmax  Pout  γ0  = Pr  γmax < γ0  =   cid:17   − γ 1 − e  γ  γ  pγmax γ   = Nr  cid:14  ∞  γmax =  0  γ pγmax γ  dγ = γ   cid:18 Nr  .  −γ0 γ  − γ γ . e  1 − e   cid:17   cid:18 Nr−1 Nr cid:26   1 i  .  i=1   5.6    5.7    5.8   From this, the average SNR is derived as  Thus, the average SNR gain and array gain increase with Nr, the largest gain being achieved when switching from no diversity to two-branch diversity. The array gain diminishes as Nrincreases.  Example 5.2: The outage probability for selection diversity, given by  5.6 , is plotted in Fig. 5.3.  The BER with slow fading can be derived by averaging the BER on the AWGN channel  over the pdf of the selected SNR, γmax Pb =   cid:14  ∞   5.9  Typically, when the average received branch symbol SNR γ  cid:7  1, Pb is proportional to 1 γ Nr .  Pb γ  pγmax γ  dγ .  0  100  10−1  t u o P  10−2  10−3  8  16  Nr = 64  10−4  −10  32  0  Nr = 1  2  3  4   cid:2 Figure 5.3  Outage probability of selection diversity in Rayleigh fading channels.  10 avg γ γ  20 0  dB   30  40      136   cid:2   Diversity  For selection diversity in Rayleigh fading channels, exact closed-form expressions for the average crossing rate of the combined signal have been given in [54] for the inphase ZCR, inphase rate of maxima, phase ZCR, and the instantaneous frequency ZCR of the output of the selection combiner.  Selection criteria  The RSSI-based selection diversity is only valid when the BER is determined by noise. When CCI is high, the high RSSI may be due to strong interference and thus the RSSI criterion is not suitable. The BER-based selection diversity is more suitable for all cases.  The BER-based selection diversity uses a training sequence, and demodulates the signal at each receive antenna and selects the antenna with the best BER. To evaluate all the Nr diversity branches, one needs Nr RF chains or needs to repeat the training sequence Nr times. In the latter case, one demodulator is not suitable for a fast changing channel. Due to the limited length of the training sequence, the calculated BER is not accurate, and a longer training sequence can improve the BER accuracy, but leads to a loss in the spectral efﬁciency.  Inﬂuence of correlation branches  When there is some degree of correlation between the received signals, the effectiveness of diversity will be reduced. In this case, the outage probability Pout  γ0  can be derived using the joint pdf of the varying γi of the Nr different branches. For two-branch diversity, the correlated multiplicative fading processes on the two branches are assumed to be jointly Gaussian, with complex cross-covariance ρ. The normalized covariance between branches is closely approximated by   cid:4  cid:4 ρ2   cid:4  cid:4 .  For a threshold level γ0, the outage probability Pout is derived as [34]   cid:12  − γ0 γ 1 Q b,ρa  − e   cid:17    cid:18   − γ0 1−ρ2  + 1 γ 2  1 γ 1  I0   cid:8  ,  b =  2γ0 1 − ρ2   cid:13   ,   cid:7   − γ0 γ 2 Q a,ρb   cid:8  cid:25  2ργ0 1 − ρ2    cid:7   γ 1γ 2   cid:8   2γ0 1 − ρ2  Pout = 1 − e + e   a =  cid:14  ∞  γ 1   cid:7   y  γ 2   cid:14   0   5.10    5.11    5.12   Q x, y  =  − x2+z2 e  2  I0 xz zdz = 1 −  b  − x2+z2 e  2  I0 xz zdz.  Under normal operating conditions, γ 1 = γ 2. In this case, as ρ increases, the diversity gain decreases [34]. Even at ρ = 0.95, a diversity gain of 4.2 dB is realized at an out- age probability of 1%. As the imbalance between γ 1 and γ 2 increases, the diversity gain degrades as compared to the case of γ 1 = γ 2 for a given ρ.  where  and      137   cid:2   When γ0  cid:5  γ 1, γ 2, the outage probability can be approximated by [37]  5.2 Combining multiple signals   cid:7    cid:8  .  Pout ≈  γ 2 0 1 − ρ2  γ 1γ 2   5.13    5.14    5.15    5.16    5.17    5.18   hn τ   = αnδ τ  ,  γMRC = Nr cid:26   γn.  n=1  γ MRC = Nrγ ,  5.2.2 Maximum ratio combining  MRC is an optimum combination strategy for a slow and ﬂat-fading channel with AWGN as the only disturbance. Each channel is a time-invariant ﬁlter with the impulse response  where αn is the instantaneous attenuation of the nth diversity branch. By selecting the antenna weight wMRC = α∗ n, the signals are phase-corrected and weighted by the amplitude, and the combined output SNR is the sum of the branch SNRs  Thus, the received SNR continuously grows as the number of antennas is increased. The average combined SNR is given by  where γ is the average SNR on each branch. Therefore, the SNR grows linearly with the diversity order.  Outage probability  Assuming each branch to have equal average branch SNR γ and to be uncorrelated, the distribution of γ is a χ 2 distribution with 2Nr degrees of freedom, mean Nrγ , and variance 2Nrγ , given by [14, 20, 34, 38, 41]  The corresponding outage probability for a given threshold γ0 is given by  γ0 γ  k−1  k − 1 !  Pout = Pr  γ < γ0  =  pγ  γ  dγ = 1 − e  −γ0 γ  .  0  −γ  γ γ Nr  Nr − 1  !  pγ  γ   = γ Nr−1e  cid:14  γ0  ,  γ ≥ 0. Nr cid:26   k=1  Example 5.3: The outage probability of MRC in Rayleigh fading is plotted in Fig. 5.4. Comparison with Fig. 5.3 indicates that the performance of MRC is much better than that of selection diversity. The diversity order is embodied from the slope of the BER curve or outage probability curve versus average SNR on a log-log scale. A comparison of Figs. 5.4 and 5.3 shows that MRC is 2 dB more effective than selection diversity.      138   cid:2   Diversity  100  10−1  t u o P  10−2  10−3  8  16  32  64  10−4  −20  −10  0  Nr = 1  2  34  10 γavg  γ  0  dB   20  30  40   cid:2 Figure 5.4  Outage probability of MRC in Rayleigh fading channels.  Ergodic error probability  The ergodic error probability can be derived in a fashion similar to that in  5.9 . Since MRC is a coherent detection technique, it is only suitable for signals that can be coherently detected. The ergodic error probability Ps for Rayleigh fading is given by  7.167 , when the transmit power is uniformly distributed onto all diversity paths. Equation  7.167  is reproduced below [20]   cid:12    cid:14   Ps = a  b  0   cid:14  π  2  0  Nr sin2 θ  Nr sin2 θ + cγs  cid:12   Nr sin2 θ Nr sin2 θ + γs  Ps = 1  π   cid:13 Nr   cid:13 Nr  dθ,  dθ.   5.19    5.20   where the values of the parameters a, b, c depend on the modulation method. For BPSK signals, the BER for equally distributed branches is given by  Example 5.4: The ergodic BER of MRC for Rayleigh fading, as given by  5.20 , is plotted in Fig. 5.5. It is seen that as Nr → ∞, the performance approaches that of an AWGN channel.  Ergodic capacity  The ergodic capacity of a diversity system can also be obtained in case of MRC. Assuming that the signal is transmitted over Nr independent channels with coefﬁcients hm and that the signal power is equally distributed among these channels, the instantaneous capacity after MRC is   cid:13   C γ   = log2  hm2 Es NrN0  = log2 1 + γ  .   5.21    cid:12  1 + Nr cid:26   m=1      139   cid:2   5.2 Combining multiple signals  Nr = 1  Rayleigh  2  4  Nr =  ∞ Gaussian  168 128  5  10  20  25  30  15 γb  dB    cid:2 Figure 5.5  BER of BPSK over Rayleigh fading channels with diversity degree Nr using MRC.  b P  100  10−2  10−4  10−6 0   cid:14  ∞  0  The pdf pγ  γ   is given by  5.17  with γ = Es N0 The ergodic capacity is obtained by averaging C γ   with respect to pγ  γ    for nondissipative channels with σ 2 H  Nr  = 1.  C =  log2 1 + γ    γ Nr−1  NNr r   Nr − 1  !  Es N0 Nr  − γ Nr e  Es N0 dγ .   5.22   This result can be evaluated numerically.   cid:12    cid:12   Example 5.5: The ergodic capacity, given by  5.22 , is plotted in Fig. 5.6. It is seen that C for different values of Nr runs between the two curves for the AWGN and the Rayleigh channels, which correspond to Nr = ∞ and Nr = 1, respectively. The result for the Rayleigh channel can also be calculated by setting Nr = 1 or by using the closed-form  cid:13  solution given by  14.76 , which is reproduced below [20] · expint  cid:14  ∞  cid:2   The result for the AWGN channel is calculated by  14.54 , which is also reproduced below  C = log2 e · exp  expint x  =  σ 2 HEs N0  σ 2 HEs N0  −t e t  where   5.23    5.24    cid:13    cid:3   dt.  1  1  x  ,  CAWGN = log2  1 + Es N0   5.25  The largest gains are obtained for the transition from Nr = 1 to Nr = 2. Calculation of numerical integration must be very carefully performed, or numerical instability may occur.  .      140   cid:2   Diversity  Rayleigh Nr = 2 Nr = 3 Nr = 4 Nr = 10 AWGN  4.5  3.5  4  3  2  1  2.5  1.5    z H   s   s t i b         C y t i c a p a c   c i d o g r E   cid:2 Figure 5.6  The ergodic capacity for the Nrth-order MRC diversity system over Rayleigh fading channels.  0.5  0  2  4  γ  6  8  10  Outage capacity  The outage probability Pout and the outage capacity Cout can be obtained from each other. The outage probability Pout can be deﬁned by  Pout = Pr  C γ   < Cout  =  pγ  γ  dγ ,   5.26    cid:14  γmin  0  where the minimum SNR γmin can be calculated from Cout, and pγ  γ   is the pdf of γ . For the AWGN channel, log2  1 + γmin  = Cout, thus γmin = 2Cout − 1.  By inserting pγ  γ   into  5.26 , we have  Pout =  1   Nr − 1  !  0  γ Nr−1e  −γ dγ .   5.27   The relations of Pout, Cout, Es N0 and Nr can be numerically evaluated from  5.27 .   cid:14  2Cout−1  Es  NrN0   Example 5.6: Given Es N0 = 10 dB, the relation of Pout versus Cout is plotted in Fig. 5.7. As Es N0 increases, the curves shift to the right. Given Pout, the relation of Cout versus SNR can also be obtained.  For MRC scheme with independent but unbalanced branches in Nakagami-m fading, the pdf of the SNR at the combiner output, Pout and the ergodic error probability have been obtained in [1]. In [16], closed-form expressions for the LCR and the ACF are derived for MRC with independent but unbalanced branches, and Rayleigh fading.  Inﬂuence of correlation branches  Assuming that two branches are correlated with a correlation coefﬁcient ρ and each branch has an equal average branch SNR γ , the outage probability with MRC is given by [17]      141   cid:2   5.2 Combining multiple signals  t u o P  1  0.8  0.6  0.4  0.2  0  0  100  10−2  10−4  t u o P  Nr = 1  2  4 8 Nr = 16 4 Cout  2  6  8   cid:2 Figure 5.7  Outage probability as a function of outage capacity of ﬂat-fading channels with Gaussian input, for different diversity degree Nr.  ρ = 0 ρ = 0.3 ρ = 0.5 ρ = 0.7 ρ = 0.8 ρ = 0.9 ρ = 1   cid:2 Figure 5.8  10−6  −30  −25  −20  −10  −5  0  −15  γ γ γavg  dB   The outage probability for correlated branches with MRC.   cid:22    cid:23   Pout = Pr  γ1, γ2 < γ0  = 1 − 1 2ρ   1 + ρ e  − γ0 γ  1+ρ  −  1 − ρ e  − γ0  γ  1−ρ   ,   5.28   where γ1, γ2 are the instantaneous SNRs on the two branches.  Example 5.7: The outage probability  5.28  is plotted in Fig. 5.8. It is seen that the diver- sity gain is still very high when ρ = 0.9. Usually it is assumed that almost full diversity gain is obtained when ρ = 0.7. This is the reason ρ = 0.7 is speciﬁed for deﬁning the coherent time, bandwidth, and angle.  In the case when all the channels have the same average power σH = 1 and the correlation between any pair of diversity branches is ρ, the correlation matrix is given by      142   cid:2   Diversity  b P  10−1  10−2  10−3  10−4  10−5  10−6  100  ρ = 1.0 ρ = 0.9 ρ = 0.7 ρ = 0.5 ρ = 0.3 ρ = 0.1 ρ = 0      cid:2 Figure 5.9  BER of BPSK over Rayleigh fading channels with diversity degree Nr using MRC, correlation coefﬁcient ρ at Es N0  = 10 dB.  101  102  103  Nr  ⎡⎢⎢⎢⎣ 1 ρ ··· ρ  ··· ρ ... ... ... ρ ρ ··· 1  1 ...  ρ  ⎤⎥⎥⎥⎦ .   cid:23 HH = σH   5.29   The correlation matrix has  Nr − 1 -fold eigenvalues λ1 = λ2 = ··· = λNr−1 = σ 2 H 1−ρ , H [1 + ρ  Nr − 1 ]; these correspond to the average powers of the various = σ 2 and λNr channels [20, 38]. For BPSK signals in ﬂat Rayleigh fading channels, from  5.20 , with  cid:13   cid:12  γl = λl and σH = 1, the ergodic error probability is given as  cid:14  π   cid:13 Nr−1 cid:12   Es N0  Ps = 1  π  2  0  Nr sin2 θ  Nr sin2 θ +  1 − ρ  Es  N0  Nr sin2 θ  Nr sin2 θ + [1 + ρ  Nr − 1 ] Es  N0  dθ.   5.30   = 10 dB, the ergodic error probability for correlated branches Example 5.8: Assuming Es N0 with MRC, given by  5.30 , is plotted in Fig. 5.9. It is seen that correlation reduces the effective diversity degree for a given diversity order Nr. For ρ = 1, there is no diversity gain at all.  The BER performance of MRC in Nakagami fading is analyzed for coherent and non- coherent FSK in [7], and the results are extended to include coherent PSK and DPSK. The effect of correlation is also considered for the dual diversity case [7]. In [29], perfor- mance metrics of MRC in correlated Nakagami fading, such as Pout, the average symbol error probability  SEP , also called symbol error rate  SER 2, for coherent multichannel  2 SEP and SER are equivalent words in this book.      143   cid:2   5.2 Combining multiple signals  reception, and the diversity gain, are calculated with arbitrary fading parameters and arbitrary average powers.  H-S MRC  The tradeoff between the selection diversity and MRC is the hybrid selection scheme, called the hybrid selection maximum ratio combining  H-S MRC , which selects the best L out of Nr signals and processes them. The main feature of the H-S MRC scheme is the reduction of the number of RF chains.  The performance of the H-S MRC diversity system over Rayleigh and Nakagami-m channels is analyzed in [12, 48]. Exact expressions for the SEP for coherent detection of MPSK and MQAM with H-S MRC in multipath-fading channels are given in [48]. It has been shown that H-S MRC, even with L  cid:5  Nr, can achieve performance close to that of Nr-branch MRC [48]. For a H-S MRC diversity system that has independent Nak- agami fading on the diversity branches with unequal fading parameters and unequal SNRs, closed-form expressions for Pout, the channel capacity, and the average SEP for a general class of M-ary modulation schemes  including MPSK, MQAM, BFSK, and MSK  with coherent detection have been derived in [12].  5.2.3 Equal gain combining  MRC needs the knowledge of the channel on each branch. EGC is a simpler technique that cophases signals on all the branches and combines them with equal weights. EGC is useful for constant amplitude signals such as MPSK that has equal energy symbols.  After cophasing and combining, the envelope of the composite signal is  αEGC = Nr cid:26   cid:12  Nr cid:26   k=1  αk   cid:13 2  √  γn  n=1   5.31    5.32    5.33   and the SNR of the EGC output is given by γEGC = 1 Nr  cid:22   γEGC = γ  1 +  Nr − 1   .   cid:23   π 4  .  γEGC generally does not have a closed-form pdf nor a closed-form cdf.  With Rayleigh fading, if the branches experience uncorrelated fading, we have [41]  Thus, the performance of EGC is always worse than that of MRC, but is quite close to that of MRC, with a power penalty of 1.05 dB.  When applied to unequal energy constellations, EGC requires to compute the opti- mal bias, which depends on the measurement on each branch. Calculation of the bias for MPAM and MQAM constellations has been proposed in [26]. Similar to H-S MRC, H-S EGC is obtained as the hybrid of selection combing and EGC [24]. The      144   cid:2   Diversity  H-S EGC receiver proposed in [24] allows diversity for nonconstant modulus modulation formats.   5.34    5.35    5.36   The outage probability for EGC is similar to, but slightly worse than, that for MRC. The distribution of γ at low values of γ is given by [10, 34]  Outage probability  p γ   = 2Nr−1  2Nr − 1  !  1   Nr k=1  Zk ZT   cid:12       cid:12   Nr k=1 p γ   = 2Nr−1NNr  2Nr − 1  !  cid:14  γ0  r   cid:13   ,  γ k   cid:13  cid:12   Nr k=1  γ Nr−1   cid:17   cid:18 Nr  cid:13  γ Nr−1   1 Nr  Nr k=1  γ k  where Zk is the noise power on branch k, and ZT is the total noise power.  To maximize the performance of EGC, one can minimize p γ   for small γ ,  5.34 , with , that is, all the branches have  respect to γ . This yields the condition of equal noise power level. Under this assumption, p γ   becomes [34]  =  Zk ZT  and the outage probability is given by [34]  Pout = Pr  γ < γ0  =  p γ  dγ =  2Nr Nr  2Nr  !  0  For low outage, if Nr  cid:7  1, EGC requires 1.34 dB more power than MRC does [34].   cid:12    cid:13   .  0   γ Nr Nr k=1  γ k  Inﬂuence of correlated branches  2  1 + √ρ cid:8  γ − cid:7  √ρ 1 + √ρ cid:8   In the case of two branches that are correlated with a complex correlation coefﬁcient ρ, the outage probability for EGC is approximated by [22, 37] − 2aγ0  − 2bγ0   cid:7   1 − √ρ cid:8   e  e  γ  Pout = Pr  γ1, γ2 ≤ γ0  = 1 +  ,   5.37    cid:7   a =  1 − √ρ cid:8  ,  where γ1, γ2 are the instantaneous SNRs on the two branches, γ0 is the speciﬁed outage SNR, γ is the average SNR on each of the branches, b = and g2 = 1.16 for ρ < 1 and g2 = 1 for ρ = 1. Expressions have been derived in [4] for the LCR and the average duration of fades in the case of two-branch predetection selection diversity, EGC and MRC with correlated Rayleigh fading signals.   5.38    cid:7   g2  g2  2  2  Dual-branch diversity combining over log-normal channels has been analyzed in [8, 38] for MRC, selection diversity and switch diversity, allowing for the possibility of average power unbalance and correlation between the two branches.      145   cid:2   5.2 Combining multiple signals  5.2.4 Switch diversity  Selection diversity requires a dedicated receiver on each branch to continuously monitor the branch SNR. Switch diversity, or threshold combining, is a simple selection diver- sity method. Selection diversity uses only one receiver to scan each of the branches in a sequential order, and outputs the ﬁrst signal whose SNR is above a given threshold γT. Whenever the signal on the branch in use is below γT, switching continues until an acceptable signal level is found. This is also known as switching diversity with feed- back [17]. To reduce the noise arising from rapid switching, the switch-and-stay strategy is usually used: the combiner switches to another branch whenever the signal on the branch in use falls below a selected threshold, regardless of the signal level on the other branches.  In FM analog mobile radio systems, switching between antennas creates noise in the signal. Thus, the switching rate must be limited, leading to a limited protection against fading. In digital radio systems, switching yields loss of phase coherence in the signal. This is not a problem for FSK and DPSK modulation: Such systems are not affected by the switching rate, achieving a higher degree of protection against fading. The BER per- formance of switched diversity with feedback for DPSK mobile radio has been analyzed in [49].  Switch diversity is a degenerate form of selection diversity. Switch diversity provides most of the gain in the region immediately above the threshold level. The optimum thresh- old should be set slightly above the lowest acceptable SNR. The outage probability for two branches with switch diversity has been given in [37]. The performance of switch diversity is between that of no diversity and selection diversity. The optimal selection of the thresh- old is γT = γ0, and this leads to the same outage probability as the selection diversity [14, 38].  5.2.5 Optimum combining  The preceding combining techniques are based on maximizing the signal power at the combiner output. MRC is optimum only when there is no interference. In case of CCI, optimum combining can be derived by maximizing the output signal-to-interference-plus- noise ratio  SINR  of the combiner.  The received signal consists of the desired signal, noise, and NI interfering signals  If the transmitted average power of the desired signal sd t  is normalized to unity, we can write  x = xd + n + NI cid:26  x = hdsd t  + n + NI cid:26   i=1  xi.  xi,  i=1   5.39    5.40   where hd is the complex channel attenuation vector of the Nr diversity branches.      146   cid:2   The weight vector that maximizes the output SINR is derived as [50, 51]  where RI, the correlation matrix of the received noise-plus-interference contained in the multiple received signal copies, is given by  Diversity  wopt = RIh  ∗ d,   cid:19   n I + NI cid:26   k=1  ∗ kxT x k  ,  E   cid:20   RI = σ 2  opthdhH γ = wH wopt d wH optRIwopt  .   5.41    5.42    5.43   σ 2 n being the noise power. This solution is known as the Wiener solution. The output SINR is given by  The pdf of the combiner output is given in [11, 37]. More combining algorithms will be introduced in Chapter 18, when we discuss beamforming.  Performance of various diversity combiners with CCI  The performance of a diversity system in reducing interference has been derived in [17, 36] for the cases of Rayleigh or Ricean distributed desired signal and Rayleigh distributed interfering signals. The pdfs and cdfs of the SINR for both cases are given in [36], when MRC is applied. Assuming equal-power interference sources, analytical expressions are derived for the pdf of the output SINR, Pout, and the average BER with MRC for an arbitrary number of interference sources in [36] for BPSK modulation.  For ﬂat-fading channels, simpliﬁed closed-form expressions for the pdf of the output SINR and the outage probability  i.e., the cdf of the output SINR  with MRC in case of CCI is given in [13]. In [5], closed-form expressions for pdf and cdf of the output SINR in case of CCI are derived, when there is a channel estimation error. For perfect channel estimation, the pdf of the output SINR reduces to that given in [13].  Closed-form expressions for Pout when using MRC with CCI are available for Rayleigh fading [27] and for Nakagami fading [30]. An exact closed-form expression for the aver- age BER of coherent BPSK using MRC with correlated branches in the presence of CCI and Rayleigh fading is derived in [55]. In addition, theoretical analysis has been made for hybrid selection MRC diversity in the presence of the Rayleigh desired signal with differ- ent CCI models in [15, 23], and expressions for the pdf of the instantaneous SINR, as well as average BER and Pout for some special modulation schemes given.  The performance of EGC, selection combining, switching diversity schemes with CCI have also been investigated in the literature. In [2], closed-form expressions for Pout in Nakagami fading with CCI are derived for EGC, selection combining, and switched diver- sity schemes. In [2], average BEPs of MPSK using both dual-branch EGC and dual-branch selection combining are derived in a Ricean or Nakagami fading channel with Rayleigh fading CCI. In [40], the Pout’s of EGC and selection combining are compared in a Rayleigh fading channel with CCI. In [39], the average BEPs of EGC and selection combining for      147   cid:2   5.2 Combining multiple signals  band-limited BPSK systems in Nakagami fading with CCI are derived. The average output SINR of EGC in a correlated Nakagami fading channel with CCI is obtained in closed form in [31]. Outage and average SEP performance of EGC in a Nakagami fading channel with Rayleigh fading CCI are analyzed in [32].  Performance of optimum combining with CCI  For optimum combining, a closed-form expression is given for one interferer in [50]. In [52], a closed-form expression for the upper bound on the BER with optimum combining is given for any number of antennas Nr and interferers NI, with coherent detection of BPSK and QAM signals, and differential detection of DPSK. Bounds on the performance gain of optimum combining over MRC are also derived, and these bounds are asymptotically tight with decreasing BER.  In [45], a performance analysis of optimum combining in the presence of NI equal power interferers and noise has been made, subject to independent ﬂat Rayleigh fading channels, when NI < Nr. An approximate expression of the pdf of the output SINR γ has been derived analytically, and then applied to obtain the closed-form cdf of the SINR  outage probability  as  Pout = Pr  γ ≤ γ0  =   cid:3 k  bk  k=0 γ0 1+Nrγ I      1 + Nrγ I   cid:2  −Nrγ I NI−1 cid:26  ⎤⎥⎦  cid:18 m ⎡⎢⎣1 − e  − γ0 γ s  n cid:26   m=0  γ s m!   cid:8 n cn   cid:17    cid:18 m  ⎤⎥⎦  ⎫⎪⎬⎪⎭ ,  γ0 γ s m!  k = 0, 1,··· , NI − 1,  n = 0, 1, . . . , Nr − NI − 1  − γ0 1+Nr γ I    ×  ⎡⎢⎣1 − e − cid:7   1 + Nrγ I  γ s   cid:7   m=0   cid:8 NI−1  cid:7 −Nrγ I  cid:8 Nr−1 1 + Nrγ I  cid:17  k cid:26   cid:8  Nr−NI−1 cid:26   cid:7 −Nrγ I  cid:8  ,  cid:8  ak, NI!  n=0  n=1,n cid:18 =k+1   cid:7  bk = ak  cid:7   cid:8  k Nr−1 cn = NI−1 cid:26   cid:7   cid:8   cid:7   NI − 1  !  k n k Nr−1  k NI−1  k=0   5.44    5.45    5.46   ak =  −1 NI−1+k   Nr − n  ,  k = 0, 1,··· , NI − 1.   5.47   γ s is the average input SNR for the desired user and γ I is the average interference-to-noise ratio  INR  for any interferer. All interferers have equal power so that the average SINR is given by  where  with      148   cid:2   Diversity  γ =  γ s  1 + NIγ I  .   5.48   In [45], closed-form expressions for the BER of coherent BPSK, DPSK, and FSK modulations have been derived for NI < Nr. Optimum combining of NI equal-power interferers  NI ≥ Nr  with BPSK modulation in a ﬂat Rayleigh-fading environment is analyzed in [35]. The pdf of the output SINR of optimum combining has a Hotelling T2 distribution, and closed-form expressions for the outage probability and BER are derived. In [36], the results obtained for optimum combin- ing and Rayleigh fading in [35] are extended to the case when the desired signal is subject to Ricean fading, for NI ≥ Nr. The performance has been studied for several channel mod- els of the desired signal: Rayleigh, Rice, and nonfading. In all cases, the interference is assumed to be subject to independent and identically distributed  i.i.d.  Rayleigh fading. Exact analysis of optimum combining is performed in [28] when either the desired user or the interferers undergo Ricean fading.  In [42], the pdf of the output SINR of the optimum combining technique has been examined. When NI > Nr, the outage probability of optimum combining with NI equal- power interferers is upper and lower bounded by the MRC performance [13] with NI and NI − Nr + 1 interferers, respectively. In [21], a closed-form expression of the exact BER has been derived for optimum com- bining with BPSK and Rayleigh fading, in the presence of NI equal power interferences. It is shown that for large SNR, the BER of a system with Nr diversity branches and NI interferences  NI < Nr  is equivalent to a system with  Nr − NI  diversity branches, but no interference [21, 51].  Optimum combining gives the best error performance only with perfect channel esti- mation. Optimized diversity combining is introduced in [25] that results from pilot-based ML channel estimation applied to a correlated ﬂat Rayleigh fading channel in the presence of CCI and additive noise. Optimized diversity combining can perform signiﬁcantly better than optimum combining with imperfect channel estimates.  5.3 Transmit diversity  Transmit diversity is dual to receive diversity, when the knowledge of the complex channel gain is available. For a transmit diversity system with Nt transmit antennas and one receive antenna, when the receiver CSI is available and the transmit antennas are subject to an average total energy constraint Es, the received SNR can be combined by using an analysis similar to that for receiver MRC, and the combined SNR is given by  γMRC = Nt cid:26   γi.  i=1   5.49   At high SNR, both transmit and receive MRC achieve full diversity order. Similar analysis can be done for EGC and selection diversity.      149   cid:2   5.3 Transmit diversity  The transmitter CSI can be obtained by feedback from the receiver. The receiver esti- mates the channel using a pilot transmitted from the transmitter and then feeds back it to the transmitter. In TDMA, the BS can use transmission from the MS to estimate the channel, and then transmit based on this information. This is because in time division the forward and reverse links are reciprocal.  5.3.1 Open-loop transmit diversity   cid:6   y = HAs + n,  cid:5   cid:17  cid:4  cid:4  cid:4 h2  cid:4  cid:4  cid:4  +  h1 ∗ h 2  1  2  When there is no transmitter CSI, transmit diversity gain can be obtained by using Alam- outi’s space-time diversity scheme [6]. Alamouti’s scheme is for two-antenna transmit diversity. The method works over two symbol periods, during which the channel is assumed constant. During the ﬁrst symbol period, two different symbols s1 and s2, each having an energy Es 2, are transmitted from antennas 1 and 2, respectively. During the second sym- bol period, symbols −s ∗ ∗ 1 are, respectively, transmitted from antennas 1 and 2, again 2 and s each having an energy Es 2. For the two-symbol period, the received symbol is given by  where the output y =  cid:7   ∗ 2  y1, y   n1, n2 T, and the channel matrix   cid:8 T, the transmitted symbols s =  s1, s2 T, the AWGN n =   5.50   HA =  h2 −h1 Deﬁning a zero-forcing receiver z =  z1, z2 T = HH A y, we can estimate s from s + ˜n,   cid:4  cid:4  cid:4 h2   cid:4  cid:4  cid:4  cid:18   z =  .   5.51    5.52   where ˜n = HH A n. Thus, each component of z corresponds to one transmitted symbol, and a diversity order of 2 is achieved. Alamouti’s scheme can be general-ized to multiple anten- nas. The Alamouti transmit diversity scheme is known as the Alamouti code or transmitter beamforming, which is dual to receiver beamforming in a smart antenna system. The 2×1 Alamouti code achieves the same diversity order and data rate as a 1×2 receive diversity with MRC, but with a 3 dB power penalty, due to the redundant transmission at the transmitter. For receiver MRC diversity, the received SNR linearly increases with the diversity order Nr. Due to the transmit power penalty, the received SNR does not always increase. The Alamouti code has been extended to the orthogonal space-time block code  OSTBC  for Nt > 2. For a single receive antenna, when an OSTBC is employed, the received SNR is given by   cid:22    cid:23   γtd = γ Nt  hi2 → γ E  h12  ,  Nt cid:26   i=1   5.53   where the law of large numbers is applied for large Nt. This result shows that the received SNR for transmit diversity approaches the average SNR as Nt increases. More details on the Alamouti code and OSTBCs are given in Chapter 19.      150   cid:2   Diversity  5.3.2 Closed-loop transmit diversity  When the channel information is available at the transmitter by reciprocity or feedback from the receiver, closed-form transmit diversity can be implemented. Transmit selection diversity is a simple, but most effective transmit diversity [49]. Transmit selection diversity  cid:14  < Nt antennas that have the best channels for transmission. selects from Nt antennas N This can signiﬁcantly reduce the hardware cost and complexity. The use of fewer trans- mit antennas for transmitting the same signal also reduces the spatial interference. Like selection diversity, transmit selection diversity achieves a full diversity order of Nt at the transmitter side.  When a single transmit antenna is selected, the power penalty relative to receive MRC diversity that is observed in the case of OSTBCs does not occur. In the case of i.i.d. Rayleigh fading, the average SNR of a single transmit antenna in an Nt × 1 system is given by [9]  Nt cid:26   i=1  1 i  ,  γtsd = γ   5.54   which is identical to  5.8 . Although full diversity is obtained, the average SNR γ is lower than that achieved with all the transmit antennas using beamforming.   cid:14    cid:14   The feedback required for transmit selection diversity is also very low, since only active transmit antennas, only  the indices of the required antennas are fed back. For N N  log2 Nt bits per channel coherent time is required to send to the transmitter. Another kind of closed-loop transmit diversity is linear diversity precoding, where the data rate is unchanged but is used to improve the link diversity. Linear diversity precoding is a special case of linear beamforming. Linear precoding will be introduced in Chapter 19. Compared to OSTBCs, linear precoding achieves a higher SNR than the open-loop STBCs, by a factor up to Nt [9].  5.4 Multiuser diversity  Multiuser diversity [19] takes advantage of the fact that different users have channels that fade independently. By transmitting only to users with the best channels, the system capac- ity as well as performance can be improved. Single-user diversity uses a point-to-point link consisting of multiple independent channels whose outputs are combined, while in mul- tiuser diversity the multiple channels are for different users and selection diversity is used to select the user with the best channel to increases the mean SNR. Multiuser diversity leads to a signiﬁcant improvement in throughput when there is a large number of users.  Transmission scheduling that employs multiuser diversity based on the channel condi- tions of users is known as opportunistic scheduling. In addition to increasing the system throughput, opportunistic scheduling also improves BER performance, since transmission is only to users with the largest SNRs. In i.i.d. Rayleigh fading channels, this maximum      151   cid:2   5.4 Multiuser diversity  SNR has a gain of ln K, when the number of users, K, is large [46]. Multiuser diversity has been supported by 1xEV-DO and WiMAX to improve the overall system diversity.  However, opportunistic scheduling leads to problems of fairness and delay. The user with the best channel may occupy the system resources all the time, while other users with poor channels may never get system resources. Proportional fairness scheduling [46] helps to solve the fairness and delay problems in the downlink. Proportional fair scheduling is the baseline scheduling technique for the TDMA-based downlink of 1xEV-DO for packet data transmission.  Opportunistic scheduling requires CSI at the BS. Strategies with one-bit feedback per user can capture the double-logarithmic capacity growth of full-CSI systems, i.e., log log K, for ﬂat Rayleigh-fading channels [33]. The one-bit feedback technique is extended for sub- channel user selection under both correlated and uncorrelated subchannel conditions. With one-bit feedback, most of the sum-rate capacity of the full-CSI system can be achieved, and it is possible to maintain proportional fairness without any loss of throughput [33]. The results have also been extended to frequency-selective channels via a simple joint user subchannel selection strategy.  5.4.1 Pdf and cdf  For Nu users with independent ﬂat Rayleigh fading channels, the user SNRs γi = hi2 Es N0 are χ 2 distributed with two degrees of freedom. The pdf pγmax γ   of the strongest channel γmax = max given by  , can be derived. First,  γ1, γ2, . . . , γNu  the cdf is   cid:7   Pγmax γ   = Pr  γmax < γ   = Pr  γi < γ  Pγi γ  ,   5.55    cid:7    cid:8  = Nu!  i=1  where the last equality is obtained for independent processes γi. The pdf can be obtained as the derivative of the cdf with respective to γ , thus  pγmax γ   = dPγmax γ    dγ  Pγi γ  .   5.56    cid:8   cid:4  cid:4 i = 1, 2, . . . , NNu Nu! = Nu cid:26  Nu!  j=1, j cid:18 =i  pγi γ     cid:17   i=1  γi . Thus,   cid:18   .  − γ For ﬂat-fading channels, Pγi γ   = 1 − e  pγmax γ   = Nu cid:26   − γ γi  − γ e γi  i=1  1 γ i  1 − e  cid:18 Nu−1 For i.i.d. channels, all γ i = γ , we have the pdf and cdf as  cid:18 Nu  pγmax γ   = Nu  − γ 1 − e  j=1, j cid:18 =i  − γ e   cid:17    cid:17   γ  γ  γ  ,  Pγmax γ   =  − γ 1 − e  γ  .   5.57    5.58    5.59       152   cid:2   1  0.8  0.6  0.4  0.2  f d p  Diversity  1  0.8  0.6  0.4  0.2  f d c  Nu = 1  2  4 8 Nu = 16  Nu = 1  2 4 8 Nu = 16  0 −15  −10  −5  5  10  15  0 −15  −10  −5  0  γ  dB   0  γ  dB   5  10  15   cid:2 Figure 5.10  The pdf pγmax  γ   and cdf Pγmax  γ   of the strongest channel.  Example 5.9: The pdf and cdf for a multiuser diversity system with Nu = 1, 2, 4, 8, and 16 i.i.d. channels are plotted in Fig. 5.10. It is seen that as Nu increases, the outage probability  cdf  decreases.  The ergodic capacity C with respect to Es N0 and the outage probability with respect to the sum rate can also be derived based on the pdf and cdf for the multiuser diversity case, and can be evaluated using numerical integration. C increases with Nu.  5.4.2 Multiuser diversity versus classical diversity  Like the classical diversity techniques, multiuser diversity is also used to combat the adverse fading channel by exploiting independently faded signal paths. For multiuser diver- sity, the independently faded signals are from different users in the network. However, the objective of classical diversity is to improve the reliability of point-point communi- cation, while multiuser diversity aims to improve the total downlink throughput of the network.  The classical diversity techniques were designed to counteract fading. In contrast, multiuser diversity improves system performance by exploiting fading. In a fading envi- ronment, a user that has a channel strength much greater than the average level exists with a high probability; this strong channel is then fully utilized.  To exploit multiuser diversity, the BS needs to have access to channel quality measure- ments and the ability to schedule transmission among the users based on the instantaneous channel quality. Practical implementation of multiuser diversity may face the following problems [43, 47]:   Fairness and delay. For example, a user who is close to the BS always has a better average SNR and is noise-limited; such a user beneﬁts from multiuser diversity, but other users have high delay. There are some schedulers that exploit multiuser diversity while considering fairness [43].      153   cid:2   Problems    Error and feedback delay in channel measurement. The measurement error is usually small since the pilot signal in the downlink is shared by many users and is strong. Feed- back delay has a more signiﬁcant inﬂuence on the channel estimation error. A short feedback delay can be achieved by increasing the feedback frequency, which, however, increases the system overload. Some techniques for reducing the feedback delay have been studied in [43].   Slow and small channel ﬂuctuations such as in the LOS path or in a little-scattering environment. In this case, a technique called opportunistic beamforming that uses dumb antennas at the BS can be exploited to induce faster and larger ﬂuctuations [46].  Opportunistic beamforming  In the opportunistic beamforming scheme, multiple antennas are deployed at the BS to induce fast and large channel ﬂuctuations. The beamforming weights can be simply gen- erated in a pseudorandom fashion [46]. It can substantially improve the system capacity in a slow fading environment. Opportunistic beamforming can also signiﬁcantly increase the dynamic range of the ﬂuctuations in a Ricean environment, and thus give a performance gain, particularly when the Kr-factor is large [43, 46]. Opportunistic beamforming requires no knowledge of the individual channel gains, neither at the users or at the transmitter. It relies on the multiuser diversity scheduling, which requires feedback of the overall SNR of each user. However, in an independent fast Rayleigh fading environment, the opportunistic beamforming technique does not provide any performance gain [43, 46].  In a slowly fading environment with many users in the system, opportunistic beam- forming with multiuser diversity scheduling has a performance similar to that of transmit beamforming, but outperforms the space-time coding case. In a multicell environment, opportunistic beamforming has a dual beneﬁt of opportunistic nulling in an interference- limited cellular system; this has the potential of converting a user from a low SINR, interference-limited channel to a high SINR, noise-limited channel [43, 46, 47].  Adaptive opportunistic beamforming is proposed in [18] for Ricean fading channels, wherein the beamforming weights are generated based on the estimation of the users’ DoAs. With the same pilot overhead in the downlink and the same feedback overhead in the uplink, the improved scheme considerably outperforms original opportunistic beam- forming [46] in both slow and fast-fading environments. This improvement becomes more pronounced when the number of users is small or the number of antennas is large.  Problems  5.1 Assume three branch diversity in a Rayleigh fading channel. Given an average SNR of 10 dB, determine the probability that the SNR is below 5 dB. What is the result for a single receiver case.  5.2 Give a high-SNR approximation to the outage probability for the parallel channel with L i.i.d. Rayleigh fading branches.      154   cid:2   Diversity  5.3 In a three-branch selection diversity, the mean SNR of each branch is randomly varying with a uniform distribution over 4 dB. Derive an expression for the outage probability.  5.4 Determine the time separation required for two signals to achieve time diversity in a Rayleigh channel at 1800 MHz with a mobile speed of 60 km h.  h, y = √ 5.5 Two independent branches are used to transmit a BPSK signal over an AWGN channel γ hx + n, where the channel h is a random variable with pdf ph h  = 0.2δ h − 1  + 0.8δ h − 4 , the noise term n is of zero mean and a variance of 1 2, h and x are normalized, and γ is the SNR. Assuming the CSI is available at the receiver, what is the error probability for:  a  Equal-gain combining.  b  Maximal-ratio combining.  c  Selection combining. 5.6 Write a MATLAB program to evaluate  5.44 . Plot Pout as a function of γ , for γI = 1, γ0 = 6 dB, NI = 5 and Nr = 8.  References  [1] V. A. Aalo, T. Piboongungon & G. P. Efthymoglou, Another look at the performance of MRC schemes in Nakagami-m fading channels with arbitrary parameters. IEEE Trans. Commun., 53:12  2005 , 2002–2005.  [2] A. A. Abu-Dayya & N. C. Beaulieu, Outage probabilities of diversity cellular systems with cochannel interference in Nakagami fading. IEEE Trans. Veh. Tech., 41:4  1992 , 343–355.  [3] A. A. Abu-Dayya & N. C. Beaulieu, Diversity MPSK receivers in cochannel  interference. IEEE Trans. Veh. Tech., 48:6  1999 , 1959–1965.  [4] F. Adachi, M. T. Feeney & J. D. Parsons, Effect of correlated fading on level crossing rates and average fade duration with pre-detection diversity reception. IEE Proc. Pt. F, 135:1  1988 , 11–17.  [5] Y. Akyildiz & B. D. Rao, Maximum ratio combining performance with imper- fect channel estimates. In Proc. IEEE ICASSP, Orlando, FL, May 2002, 3, 2485–2488.  [6] S. M. Alamouti, A simple transmit diversity technique for wireless communications.  IEEE J. Sel. Areas Commun., 16:8  1998 , 1451–1458.  [7] E. K. Al-Hussaini & A. A. M. Al-Bassiouni, Performance of MRC diversity sys- tems for the detection of signals with Nakagami fading. IEEE Trans. Commun., 33:12  1985 , 1315–1319.  [8] M.-S. Alouini & M. K. Simon, Dual-branch diversity over correlated log-normal  fading channels. IEEE Trans. Commun., 50:12  2002 , 1946–1959.  [9] J. G. Andrews, A. Ghosh & R. Muhamed, Fundamentals of WiMAX: Understanding  Broadband Wireless Networking  Upper Saddle River, NJ: Prentice Hall, 2007 .  [10] B. B. Barrow, Diversity combination of fading signals with unequal mean strengths.  IRE Trans. Commun. Syst., 11:1  1963 , 73–78.      155   cid:2   References  [11] V. M. Bogachev & I. G. Kiselev, Optimum combining of signals in space diversity  reception. Telecommun. Radio Eng., 34 35:10  1980 , 83–85. [12] J. Cheng & T. Berger, Capacity and performance  for hybrid selection maximal-ratio combining in Nakagami fading parameters and branch powers. In Proc. IEEE ICC, Anchorage, AK, May 2003, 5, 3031–3035.  fading with unequal  analysis  [13] J. Cui & A. U. H. Sheih, Outage probability of cellular radio systems using maximal ratio combining in the presence of multiple interferers. IEEE Trans. Commun., 47:8  1999 , 1121–1124.  [14] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [15] K. A. Hamdi & L. Pap, Exact BER analysis of binary and quaternary PSK with gen- eralized selection diversity in cochannel interference. IEEE Trans. Veh. Tech., 56:4  2007 , 1849–1856.  [16] P. Ivanis, D. Drajic, & B. Vucetic, The second order statistics of maximal ratio  combining with unbalanced branches. IEEE Commun. Lett., 12:7  2008 , 508–510. [17] W. C. Jakes, Jr., ed., Microwave Mobile Communications  New York: Wiley, 1974 . [18] I.-M. Kim, Z. Yi, D. Kim & W. Chung, Improved opportunistic beamforming in  Ricean fading channels. IEEE Trans. Commun., 54:2  2006 , 199–211.  [19] R. Knopp & P. Humblet, Information capacity and power control in single-cell  multiuser communications. In Proc. IEEE ICC, Seattle, WA, Jun 1995, 331–335.  [20] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [21] D. Lao & A. M. Haimovich, Exact closed-form performance analysis of optimum combining with multiple cochannel interferers and Rayleigh fading. IEEE Trans. Commun., 51:6  2003 , 995–1003.  [22] W. C. Y. Lee, Mobile radio performance for two-branch equal-gain combining receiver with correlated signals at the land site. IEEE Trans. Veh. Tech., 27:4  1978 , 239–243.  [23] C. M. Lo & W. H. Lam, Performance of generalized selection combining for mobile radio communications with mixed cochannel interferers. IEEE Trans. Veh. Tech., 51:1  2002 , 114–121.  [24] Y. Ma & J. Jin, Uniﬁed performance analysis of hybrid-selection equal-gain combin-  ing. IEEE Trans. Veh. Tech., 56:4  2007 , 1866–1873.  [25] R. K. Mallik, Optimized diversity combining with imperfect channel estimation. IEEE  Trans. Inf. Theory, 52:3  2006 , 1176–1184.  [26] R. K. Mallik & G. K. Karagiannidis, Equal-gain combining with unequal energy  constellations. IEEE Trans. Wireless Commun., 6:3  2007 , 1125–1132.  [27] J. P. P. Martin & J. M. Romero-Jerez, Outage probability with MRC in presence of multiple interferers under Rayleigh fading channels. Electron. Lett., 40:14  2004 , 888–889.  [28] M. R. McKay, A. Zanella, I. B. Collings & M. Chiani, Error probability and SINR analysis of optimum combining in Rician fading. IEEE Trans. Commun., 57:3  2009 , 676–687.      156   cid:2   Diversity  [29] J. Reig, Performance of maximal ratio combiners over correlated Nakagami-m fad- ing channels with arbitrary fading parameters. IEEE Trans. Wireless Commun., 7:5  2008 , 1441–1444.  [30] J. M. Romero-Jerez, J. P. P. Martin & A. J. Goldsmith, Outage probability of MRC with arbitrary power cochannel interferers in Nakagami fading. IEEE Trans. Commun., 55:7  2007 , 1283–1286.  [31] N. C. Sagias, G. K. Karagiannidis, D. A. Zogas, G. S. Tombras & S. A. Kot- sopoulos, Average output SINR of equal-gain diversity in correlated Nakagami-m fading with cochannel interference. IEEE Trans. Wireless Commun., 4:4  2005 , 1407–1411.  [32] N. C. Sagias, Closed-form analysis of equal-gain diversity in wireless radio networks.  IEEE Trans. Veh. Tech., 56:1  2007 , 173–182.  [33] S. Sanayei & A. Nosratinia, Opportunistic downlink transmission with limited  feedback. IEEE Trans. Inf. Theory, 53:11  2007 , 4363–4372.  [34] M. Schwartz, W. R. Bennet & S. Stein, Communication Systems and Techniques  New  York: McGraw-Hill, 1966 .  [35] A. Shah & A. M. Haimovich, Performance analysis of optimum combining in wire- less communications with Rayleigh fading and cochannel interference. IEEE Trans. Commun., 46:4  1998 , 473–479.  [36] A. Shah & A. M. Haimovich, Performance analysis of maximal ratio combining and comparison with optimum combining for mobile radio communications with cochannel interference. IEEE Trans. Veh. Tech., 49:4  2000 , 1454–1463.  [37] A. U. H. Sheikh, Wireless Communications: Theory and Techniques  Boston, MA:  [38] M. K. Simon & M.-S. Alouini, Digital Communications over Fading Channels, 2nd  Kluwer, 2004 .  edn  New York: Wiley, 2005 .  [39] K. Sivanesan & N. C. Beaulieu, Exact BER analysis of bandlimited BPSK with EGC and SC diversity in cochannel interference and Nakagami fading. IEEE Commun. Lett., 8:10  2004 , 623–625.  [40] Y. Song, S. D. Blostein & J. Cheng, Outage probability comparisons for diversity sys- tems with cochannel interference in Rayleigh fading. IEEE Trans. Wireless Commun., 4:4  2005 , 1279–1284.  [41] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer  Academic Publishers, 2001 .  [42] Y. Tokgoz, B. D. Rao, M. Wengler, & B. Judson, Performance analysis of optimum combining in antenna array systems with multiple interferers in ﬂat Rayleigh fading. IEEE Trans. Commun., 52:7  2004 , 1047–1050.  [43] D. Tse & P. Viswanath, Fundamentals of Wireless Communications  Cambridge, UK:  Cambridge University Press, 2005 .  [44] A. M. D. Turkmani, A. A. Arowojolu, P. A. Jefford & C. J. Kellett, An experimental evaluation of the performance of two-branch space and polarization diversity schemes at 1800 MHz. IEEE Trans. Veh. Tech., 44:2  1995 , 318–326.  [45] E. Villier, Performance analysis of optimum combining with multiple interferers in  ﬂat Rayleigh fading. IEEE Trans. Commun., 47:10  1999 , 1503–1510.      157   cid:2   References  [46] P. Viswanath, D. N. C. Tse, & R. Laroia, Opportunistic beamforming using dumb  antennas. IEEE Trans. Inf. Theory, 48:6  2002 , 1277–1294.  [47] P. Viswanath, Opportunistic communication: a system view. In H. Bolcskei, D. Gesbert, C. B. Papadias & A.-J. van der Veen, eds., Space-Time Wireless Systems: From Array Processing to MIMO Communications  Cambridge, UK: Cambridge University Press, 2006 , pp. 426–442.  [48] M. Z. Win & J. H. Winters, Virtual branch analysis of symbol error probability for hybrid selection maximal-ratio combining. IEEE Trans. Commun., 49:11  2001 , 1926–1934.  [49] J. H. Winters, Switched diversity with feedback for DPSK mobile radio systems. IEEE  Trans. Veh. Tech., 32:1  1983 , 134–150.  [50] J. H. Winters, Optimum combining in digital mobile radio with cochannel interfer-  ence. IEEE J. Sel. Areas Commun., 2:4  1984 , 528–539.  [51] J. H. Winters, J. Salz, and R. D. Gitlin, The impact of antenna diversity on the capacity of wireless communication systems. IEEE Trans. Commun., 42:2–4  1994 , 1740– 1750.  [52] J. H. Winters & J. Salz, Upper bounds on the bit-error rate of optimum combining in  wireless systems. IEEE Trans. Commun., 46:12  1998 , 1619–1624.  [53] K. T. Wong, S. L. A Chan & R. P. Torres, Fast-polarization-hopping transmission diversity to mitigate prolonged deep fades in indoor wireless communications. IEEE Anten. Propagat. Mag., 48:3  2006 , 20–27.  [54] H. Zhang & A. Abdi, On the average crossing rates in selection diversity. IEEE Trans.  Wireless Commun., 6:2  2007 , 448–451  [55] X. Zhang & N. C. Beaulieu, A closed-form BER expression for BPSK using MRC in correlated CCI and Rayleigh fading. IEEE Trans. Commun., 55:12  2007 , 2249–2252.      6  Channel estimation and equalization  6.1 Channel estimation  Traditionally, receivers rely on the transmitter-assisted training sequences to extract the desired reference signal for multiuser channel estimation and equalization. There has also been substantial research done in blind channel estimation and equalization, where no training sequence is used.  One of the most popular parameter estimation methods is the maximum-likelihood  ML   method. Consider a slowly time-varying  frequency-selective  channel model  r m  =  h k s m − k  + n m ,   6.1    cid:26   k  where r m  is a vector obtained by stacking p consecutive received samples in the mth symbol duration, w m  is the corresponding p-dimensional AWGN vector at the receiver, and s m − k  is the input at time m − k. Assume that the channel has a ﬁnite impulse  response of order L. For N symbols, we have r = cid:7   rT N − 1 , . . . , rT 0    cid:8 T and   6.2  where S is a block Hankel matrix of size Np× L+1 p, h is the vector of channel parameters, and w is the stacked AWGN vector:  r = Sh + n  S =  ...  ⎛⎜⎝ s N − 1 Ip ⎛⎜⎝ h 0   s 0 Ip  h =  s N − L − 1 Ip  s N − 2 Ip s −1 Ip  ...  ··· ... ···  s −L Ip  ...  ⎞⎟⎠ ,  ⎛⎜⎝ n N − 1   n =  ⎞⎟⎠ ,  ⎞⎟⎠ ,  ... h L  with Ip being the p × p identity matrix. For training-based channel estimation, the input vector s is the known training symbols, and the corresponding observation r is also known at the receiver. The ML estimation solution is given by  ... n 0    6.4    6.3    6.5   ˆh = arg min   cid:15 r − Sh cid:15 2 = S†r,  h      159   cid:2   6.1 Channel estimation   6.6    6.7    6.8    6.9   where S† is the pseudo-inverse of S. This is also the classical linear least squares estima- tor. This method realizes the minimum mean squared error  MMSE  among all unbiased estimators and achieves the CRLB.  The frequency of channel estimation is determined by the Doppler spread of the channel  νmax. The pilot spacing M should satisfy the Nyquist sampling rate  M ≤  1  ,  2νmaxT  where T is the symbol period.  6.1.1 Adaptive channel estimation  The least mean squares  LMS  algorithm, proposed by Widrow et al [36], is the most popular adaptation technique. The LMS algorithm is a gradient-based search algorithm. It minimizes the mean square error between the desired signal d t  and the model ﬁlter output y t  = wT t x t , that is   cid:22    cid:23   w = arg min E   cid:15 d t  − y t  cid:15 2  ,  where w is the weighting vector, and x is the input delay line. This yields the LMS algorithm [7]  w t + 1  = w t  + 2μe t x t ,  where the step size μ should be selected in a range that guarantees convergence, and e is the error deﬁned by  e t  = d t  − wT t x t .  The algorithm can be initialized by setting x 0  = w 0  = 0. The LMS algorithm is the most widely used one in adaptive ﬁltering. It has low com- putational complexity, unbiased convergence to the Wiener solution, and stable behavior when implemented with ﬁnite-precision arithmetic, but the convergence speed is relatively low. For rapidly time-varying channels, a fast-convergent algorithm such as the recursive least-squares  RLS  or Kalman ﬁltering is needed to avoid numerical instability. The RLS algorithm solves the least squares problem in a recursive form. It has a rate of conver- gence that is typically an order of magnitude faster than the LMS algorithm. This is, however, at the price of a large computational complexity. More details of these adap- tive algorithms are given in Section 13.5. Various adaptation techniques are discussed in [7, 16].  Channel estimation using a training sequence reduces the spectrum efﬁciency. For example, the GSM uses a training sequence of 26 bits in every 148-bit frame. Training- sequence-based channel estimation is used practically in all the wireless standards, since the blind methods have many complexity and stability problems.      160   cid:2   Channel estimation and equalization  6.1.2 Blind channel estimation  Blind techniques for channel estimation utilize qualitative information about the channel and the input. No explicit training signal is used, and the receiver estimates the channel from the signals received during the normal data transmission. Blind techniques typically employ the signal properties such as cyclostationarity, ﬁnite alphabet, and constant mod- ulus. But, they usually suffer from convergence problems. Semiblind techniques combine the merits of both the training-based and blind techniques, and are more promising.  The blind estimation of a channel as well as its input signal is an unidentiﬁable prob- lem. This makes the conventional CRLB inapplicable. By incorporating some forms of constraint to make the problem identiﬁable, some CRLBs have been derived. Various blind channel estimators can be compared based on tight performance bounds.  The blind channel identiﬁcation problem consists of estimating the channel H and the input signal s t  from N samples of y t . For a single-input multiple-output  SIMO  channel  y t  = L−1 cid:26   cid:20   k=0  hks t − k  + n t  = Hs t  + n t ,  t = 1, 2, . . . ,   6.10    cid:19  where y t  is the Nr × 1 output signal, hk is the channel impulse response vector at the kth time tap, L is the channel length, s t  is the input signal and n t  is AWGN. H = , and s t  =  s t , s t − 1 , . . . , s t − L − 1  T. By stacking all the N h0, h1,··· , hL−1 samples of y t  into an MN × 1 vector y, a Toepliz form is obtained. From this equation, it is clear that the identiﬁcation of H and s is not possible unless another constraint is exercised.  Blind channel estimation has to rely on the known statistics of the transmitted signals. The signal properties that can be used for blind equalization include constant modulus  envelope , statistical properties like cyclostationarity, and ﬁnite symbol alphabet. There are also some training-based semiblind channel estimation algorithms that exploit the advantages of both the training-based and the blind approaches [34, 35].  6.2 Channel equalization  Channel equalizers are used to reduce the ISI arising from the delay spread or band- limitation of the channel by adjusting the pulse shape so that it does not interfere with the neighboring pulses. Equalization is a MIPS  million instructions per second -intensive function in cellular phone receivers. Major equalization techniques are linear equalization [21], decision-feedback equalization  DFE , and Viterbi maximum-likelihood sequence estimation  MLSE  [31]. Adaptive equalization is especially useful in TDMA systems. These receivers for frequency-selective channels can be easily extended to multiple antenna cases [26]. Channel equalization was ﬁrst used in echo cancellation in telephone networks.      161   cid:2   6.2 Channel equalization  For all these algorithms, a training sequence is transmitted over the channel to aid the receiver to calculate the channel impulse response H, which is used for equalization. Clas- sical channel equalization methods such as the linear equalizer and the DFE are based on training sequences. There are some blind algorithms, which avoid the use of training sequences.  Adaptive equalizers are typically implemented by using a transversal ﬁlter with a tap-spacing of the symbol interval T. The symbol-spaced equalizers are more sensitive to the sampling instant. The fractionally-spaced equalizer uses tap-spacing less than T [13]. The fractionally-spaced equalizer is equivalent to a symbol-spaced equalizer pre- ceded by a matched ﬁlter [30]. Since an exact matched ﬁlter is usually difﬁcult to obtain, the fractional-spaced equalizer is very attractive. In real systems, the output of a matched ﬁlter is usually oversampled so as to extract the timing information and to mitigate the inﬂuence of timing errors. Thus a T 2-spaced transversal ﬁlter can be easily implemented [30], and this provides a better accuracy than the symbol-spaced equalizers.  6.2.1 Optimum sequence detection  For frequency-selective channels, the optimum sequence detection is to maximize the a-posteriori probability Pr xr , that is, the probability that x is transmitted given the received r. Applying Bayes’ rule, we have  Pr xr  = prx r   Pr x  pr r   .  MAP sequence detection   6.11    6.12   The maximum a-posteriori  MAP  sequence detector is obtained as prx r Pr x ,  Pr xr  = arg max x∈X L  ˆx = arg max x∈X L  where L is the sequence length, and X = {Xi} is a ﬁnite alphabet of symbols.  Maximum-likelihood sequence estimation  The a priori probability Pr x  is typically known for communications systems, since the symbols are usually uniformly distributed. In this case, the MAP detector is equivalent to the maximum likelihood sequence detector  ˆx = arg max x∈X L  Pr xr  = arg max x∈X L  prx r .   6.13   The Viterbi algorithm is an efﬁcient algorithm for this purpose [31]. The Viterbi algorithm minimizes the error probability when detecting sequences.      162   cid:2   Channel estimation and equalization  Symbol-by-symbol MAP detector  The optimum symbol-by-symbol MAP detector [1] minimizes the symbol error probability  SEP    cid:7    cid:8  = arg max  Xj∈X   cid:26   Pr xr   x∈X L, x k =Xj  ˆx k  = arg max  Xj∈X Pr  x k  = Xjr  cid:26   = arg max Xj∈X   6.14  The above equation differs from  6.12  in that all sequences x with x k  = Xj contribute to the decision.  x∈X L, x k =Xj  prx r Pr x .  Symbol-by-symbol maximum-likelihood detection  A symbol-by-symbol ML detector can also be obtained as  ˆx k  = arg max  Xj∈X prx k =Xj r  = arg max Xj∈X  prx r .   6.15    cid:26   x∈X K, x k =Xj  For memoryless channels like AWGN or ﬂat-fading channels, the detection can be based on the current symbol rather than the whole sequence; then, the ML detector reduces to  ˆx k  = arg max  Xj∈X prXj r k  .   6.16   The time index k can be dropped.  detection techniques.  In addition, there are also multiple-symbol ML [6] and multiple-symbol MAP [18]  6.2.2 Linear equalizers  A linear equalizer is usually implemented with a ﬁnite impulse response  FIR  transversal ﬁlter that consists of a delay line of 2K + 1 τ -second taps, as shown in Fig. 6.1. The tap weights are adapted to improve the shape of the system impulse response so as to match the unequalized channel.  x  t   w−K  τ  w−1  τ  w0  τ  w1  τ  wK  Adaptation  c t    cid:2 Figure 6.1  The transversal FIR ﬁlter for linear equalization.      163   cid:2   6.2 Channel equalization  A complex transmit symbol sequence {ci} is sent over a dispersive, noisy channel, and a sequence {xi} is received. The sequence {xi} is used as input to the equalizer. The output of the equalizer is given as  5  4ˆci  wix t − iτ  .   6.17  should be as close to {ci} as possible. Thus, the linear equalizer has a  The estimate transfer function of the form  i=−K  ˆc t  = K cid:26  Heq z  = K cid:26   i=−K  −i.  wiz   6.18   Usually, the ISI caused by the channel distortion is limited to a ﬁnite number of sym- bols on both sides of the desired symbol. The time delay τ between adjacent taps may be selected as the symbol interval T, yielding a symbol-spaced equalizer. When τ is selected to be less than T, typically τ = T 2, we get a fractionally spaced equalizer. Linear equalizers result in noise enhancement. They perform well in the wired line case, but perform very poorly in the wireless case. This is due to the deep spectrum nulls in the passband in the wireless channel.  Zero-forcing equalizer  If the channel is ISI distorted by Hc  f  , the linear equalizer removes the ISI distortion by −1   f  . Thus, the combination of channel and equalizer leads applying channel inversion, H c to a completely ﬂat transfer function. This is an ideal equalizer, also know as zero-forcing  ZF  equalizer, since it forces the ISI to zero at the sampling instants t = kT, k = 0, 1,··· . As a result, the output of the ZF equalizer is simply  zk = ck + nk,  k = 0, 1, . . .   6.19   where ck is the desired symbol and nk is the additive noise. The ZF equalizer enhances the noise of the channel, at frequencies where the transfer function of the channel attains small values, since it performs channel inversion. For the  2K + 1 -tap equalizer, the value of K should satisfy 2K + 1 ≥ L so that the equalizer spans the length of the ISI, where L is the number of signal samples spanned by the ISI. From  6.17 , by applying the ZF condition to each sample at t = mT  wix mT − iτ   =  1, m = 0 0, m = ±1,··· ,±K.   6.20  This is a set of 2K+ 1 linear equations for the coefﬁcients wi of the ZF equalizer. In matrix form  i=−K  c mT  = K cid:26    cid:15    6.21  where Xij = x iT − jτ  , i, j = −K,−K + 1,··· , K, w =  w−K,··· , wK  T, c =  0,··· , 0, 1, 0,··· , 0 T. Thus, we have the ZF solution  Xw = c,  w = X  −1c.   6.22       164   cid:2   Channel estimation and equalization  x t , σ 2 = 0 c t , σ 2 = 0 x t , σ 2 = 10−4 c t , σ 2 = 10−4  1.2  1  0.8  0.6  0.4  0.2  0  e d u t i l p m A   cid:2 Figure 6.2  −0.2  −20  −10  0 t  T  10  20  The distorted pulse and the equalized pulse.  Example 6.1: Assume the input to the ZF equalizer is given by  x t  =  2  1 + et  2T  ,  where T is the symbol period. The pulse is sampled at the rate 2 T. Assume that the noise at the receiver, n t , is zero-mean AWGN with variance σ 2. The results of a 5-tap ZF equalizer  K = 2  are shown in Fig. 6.2 for σ 2 = 0 and σ 2 = 10 −4 is from a random run. It is seen that the ISI is substantially eliminated by equalization for σ 2 = 0. Note that the performance of the ZF equalizer degrades rapidly if we introduce noise into the model.  −4. The result for σ 2 = 10  MMSE equalizer  Although the ZF equalizer eliminates the ISI, noise enhancement makes the BER per- formance undesirable. A better choice is the MMSE equalizer. In the MMSE equalizer, the equalizer ﬁlter parameters are updated by minimizing the mean squared error  MSE  criterion,   6.23  where ˆck = zk is the equalizer output. By this means, the ISI is removed as much as possible.  ,   cid:23    cid:4  cid:4 2   cid:22  cid:4  cid:4 ck − ˆck  cid:8 −1 pT,  min J = E  wopt = cid:7    cid:20    cid:19   6.24  where w =  w−L,··· , wL T, the correlation matrix of the received signal Rxx = E   cid:19  um =  x mT + Kτ  , x mT −  −K + 1 τ ,··· , x mT − Kτ   T .  , p = E  ∗ umc m  umuH m   6.25   , and  RT xx   cid:20   The optimum MMSE solution is given by      165   cid:2   Thus  6.2 Channel equalization  Rxx =  1  XTX + σ 2 0 I,  with σ 2  0 being the variance of the noise at the receiver.  The components of Rxx and p are given by  2K + 1  cid:19  x mT − iτ  x Rxx i, j  = Rxx i − j  = E  cid:19  x mT − iτ  c p i  = E  ∗   mT − jτ    cid:20  ∗ m   cid:20  + δijσ 2  0 ,   6.28  for i, j = −K,−K + 1,··· , 0,··· , K, where E[·] is over all values of m, and δij is the Krocknecker delta function. Usually, E[·] is implemented by averaging over samples 1 to K.  This solution is known as the Wiener solution. The MMSE is given by   6.26    6.27   Jmin = 1 − pR −1 xx pT.  Adaptive equalizers   6.29    6.30   6.31   Solving  6.22  or  6.24  requires a complexity of the order of  2K+1 3 complex operations on each iteration  each symbol period T  due to the matrix inversion operation. This is the reason why the LMS, RLS, or Kalman ﬁltering algorithm is usually used for adaptation [27].  In either the ZF or the MMSE equalizer case, we need to solve a set of linear equations for each sample. In practice, a simple iterative procedure can be applied so that for each input sample, only one iteration is performed. This can be derived by deﬁning an MSE from the set of linear equations, and then applying steepest descent to the MSE. One can also apply RLS or the conjugate-gradient method.  The adaptive implementation of the MMSE equalizer using the LMS method is given by  wk+1 = wk + μekx ∗ k,  ek = ck − ˆck,  where the step size μ should be selected to ensure stability and a fast convergence [7].  Example 6.2: Consider a channel  h = [0.1811,−0.2716, 0.0453, 0.9054, 0.2263, 0.0453,−0.1358].  For a bitstream of 1000 bits, and σ = 0.1, simulation of an adaptive 7-tap MMSE equalizer using the LMS algorithm is illustrated in Fig. 6.3. The MSE obtained is the average of 1000 independent runs. It is seen that μ = 0.02 achieves a good tradeoff of stability and convergence speed.      166   cid:2   Channel estimation and equalization  E S M  0.2  0.18  0.16  0.14  0.12  0.1  0.08  0.06  0.04  μ = 0.04  μ = 0.02  μ = 0.01   cid:2 Figure 6.3   cid:2 Figure 6.4  0  200  400  600  800  1000  Iterations  Simulation of the adaptive MMSE equalizer using different step sizes.  ni  ci  H  z   +  HE z   ci  Structure of a decision feedback equalizer.  D  z   ˆx  kT0  = N−1 cid:26   Given an input of sampled signal sequences, sin  kT0 , the equalizer is a time-varying, N-tap FIR ﬁlter, and the output of the equalizer ˆx  kT0  is given by convolution  wi  kT0  sin   k − i T0  .  i=0   6.32  The output ˆx  kT0  is compared with the training signal x  kT0 , and the error signal is used to adjust the ﬁlter weight values for the next instant, wi   k + 1 T0 . The adaptive algorithm is switched off at the end of the training sequences. The trained equalizer can then work for the transmitted data. For mobile systems, the channel is time- varying, and the decision-directed operation can continue adapting to the channel for the transmitted data [8]. The adaptive algorithm is still working, but the training sequence is replaced by the output of the decision circuits.  6.2.3 Decision-feedback equalizers  The DFE is a nonlinear equalizer that uses a feedforward ﬁlter and a feedback ﬁlter. The DFE performs better than linear equalizers in channels with severe amplitude distortion, and thus is widely used in wireless communications. The feedback ﬁlter subtracts the ISI due to the earlier pulses from the current pulse  postcursor ISI . The structure of a DFE is shown in Fig. 6.4.      167   cid:2   6.2 Channel equalization  The DFE consists of a feedforward ﬁlter HE z , which is a conventional linear equal- izer, and a feedback ﬁlter D z . The impact of the received symbol to future samples can be computed and then subtracted from the received signal. Since the ISI is com- puted using the signal after hard decision, the additive noise from the feedback signal is eliminated, leading to a smaller error probability than that in the case of a linear equalizer.  Due to the use of the feedback ﬁlter, the DFE performs much better than the linear equalizer for the same number of taps. However, it may suffer from error propagation, and the difﬁculty in analyzing the stochastic nonlinear dynamic system that governs the error propagation causes the DFE to be not as widely used as the linear equalizer. Error propagation is negligible for small BER, which can often be achieved via coding. Error propagation makes DFEs more sensitive to channel estimation errors. DFEs can be implemented as an MMSE-DFE or a ZF-DFE. The SNR of the ZF-DFE is simply SNRZF−DFE = σ 2 , where σc is the deviation of c k . The MMSE-DFE targets at minimizing the MSE by achieving a balance between the noise enhancement and the residual ISI. Since the postcursor ISI does not contribute to noise enhancement, the objec- tive is to minimize the sum of the noise and the average precursor ISI. For the ZF-DFE, all the precursor ISI is eliminated, and the postcursor ISI is subtracted by the feedback branch.  c σ 2 n  DFE with Gaussian distributed input symbols is considered as the canonical receiver structure due to its simple structure and optimality. The ZF-DFE achieves a capacity very close to the Shannon capacity of the channel, and asymptotically approximates the channel capacity for large SNR [10]. The unbiased MMSE-DFE is optimum since it achieves the channel capacity for all SNRs [3, 10]. However, these results are based on the assumption of correct decisions. Unfortunately, DFE suffers from error propagation, which degrades the performance, especially at low SNR. Channel coding is the common method for approaching the channel capacity, but it cannot be applied in DFE in a straight forward manner. This is because DFE requires zero-delay decisions, while channel decoding is typically based on a block or a sequence of symbols.  6.2.4 MLSE equalizer  The MLSE equalizer achieves a much better performance than DFEs do, but with a much higher complexity. The linear equalizers and DFEs provide hard decision as to which sym- bol has been transmitted. Unlike the linear equalizers and DFEs that adjust the received signal via ﬁltering to remove the distortion, the MLSE determines the sequence of symbols that has most likely been transmitted. This is very similar to the decoding of convolutional codes.  The output signal of the time-discrete channel, or the received signal at the receiver, can  be written as  ri = L cid:26   n=0  hnci−n + ni,   6.33       168   cid:2   Channel estimation and equalization  where L is the length of the channel h, and ni is AWGN with variance σ 2 n . For a sequence of N received symbols, the joint pdf of the vector of received symbols r, conditioned on the data vector c and impulse response vector h, is given by  p rc, h  =   6.34  For a given h, the MLSE of c maximizes p rc, h ; this corresponds to the minimization of  2σ 2 n  hnci−n   cid:7   1 2π σ 2 n  ⎛⎝− 1  cid:8 N 2 exp  cid:4  cid:4  cid:4  cid:4  cid:4 ri − L cid:26  N cid:26   n=0  i=1   cid:4  cid:4  cid:4  cid:4  cid:4 ri − L cid:26  N cid:26   cid:4  cid:4  cid:4  cid:4  cid:4 2  n=0  i=1  .  hnci−n  ⎞⎠ .   cid:4  cid:4  cid:4  cid:4  cid:4 2   6.35   An exhaustive search for c is the most straightforward but also the most computationally complex method. The Viterbi algorithm is the one that is used in practice [31]. It was originally proposed for ML decoding of convolutional codes. The similarity between an ISI channel and a convolutional encoder was recognized by Forney, and hence he applied the Viterbi algorithm to channel equalization [12].  MLSE estimators offer the best BER performance among all the equalizers. However, MLSE has a computational complexity that increases exponentially with the length of the impulse response of the channel, and the size of signal constellation. This makes it impractical for systems with a large constellation and or a long channel impulse response. A sequential decoding algorithm for decoding convolutional codes can be use instead, especially for a long encoder constraint length and a moderate-to-high SNR [19]. This sequential sequence estimation has been applied to signal detection in ISI channels [20].  The Viterbi equalizer estimates the data without changing the distorted sequence. The lattice sequence estimator [24] and the sphere decoding algorithm [9, 15] were developed for the near-ML detection of a lattice-type modulation, such as MPAM and MQAM, trans- mitted over a linear channel, with a signiﬁcantly reduced complexity. The method limits the search among possible candidates to those located within a sphere centered on the received vector. ML detection can be formulated as an integer LS problem, and can be solved at considerable complexity reduction by using fast algorithms [15] of sphere decod- ing [9]. Turbo equalization is an iterative equalization and decoding technique for coded data transmission over ISI channels.  There is a fundamental link between orthogonality deﬁciency of the channel matrix, od H , and the performance of the linear equalizers [22]. When od H  is strictly upper- bounded by unity, linear equalizers collect the same diversity order as ML equalizers do, and the outage capacity loss relative to ML equalizers is constant with respect to SNR. Based on these results, hybrid equalizers can be designed. Hybrid equalizers can trade off between performance and complexity by tuning od H .  6.2.5 Viterbi algorithm  b∗ =  cid:7    cid:8   MLSE operates on the received signal r t , 0 ≤ t ≤ τ to produce an estimate sequence of the transmitted symbol sequence b =  b1, b2, . . . , bN   with the  ∗ ∗ 1, . . . , b b N      169   cid:2   6.2 Channel equalization  minimum error probability. This can be represented by the maximization of a pdf in the form  r t , 0 ≤ t ≤ τb1 = ˆb1, b2 = ˆb2,··· , bN = ˆbN  .  max p   6.36    cid:23    cid:22   This is the deﬁnition for MAP detection, and it is equivalent to MLSE detection for equiprobable sequences. MLSE detection determines the total distances of all possible paths through the trellis, for all possible input sequences, and selects the path with the smallest metric. For a symbol of m possible values, the brute force method uses mN calculations.  The Viterbi algorithm [31, 32] solves the MLSE problem optimally but using a com- plexity that linearly increases with N rather than exponentially. In the case of equalization, the Viterbi algorithm is often referred to as a Viterbi equalizer. ∗ The ML decoder chooses an estimate sequence b likelihood function log P rb . For a discrete memoryless channel,  of b, which maximizes the log-   6.37  The log-likelihood log P rb  is called the metric associated with path b, and is denoted M rb . The terms log P  ribi  are called branch metrics, denoted M  ribi . Thus,  i=1  log P  ribi  .  log P rb  = N cid:26  M rb  = N cid:26  Mj rb  = j cid:26   i=1  i=1  M  ribi  .  M  ribi  .  The partial path metric for the ﬁrst j branches of a path is deﬁned as   6.38    6.39   From the trellis diagram, at a node of two routes, we can exclude the one with the smaller sum of measurements. By deﬁning the state measurement of node i at time j, Mi j , as the maximum among all the sums of all branch measurements to this node  state , we have  Mi j + 1  = max  Mi cid:14  j  + mi cid:14 ,i, Mi cid:14  cid:14  j  + mi cid:14  cid:14 ,i   cid:14  cid:14    6.40   cid:14  are the nodes allowed to transfer to node i in one symbol period, and mi cid:14 ,i where i and mi cid:14  cid:14 ,i are the branch measurements of the two transfer branches. Equation  6.40  is usually called the Viterbi algorithm.  and i  ,   cid:20    cid:19   For discrete memoryless channel, the Viterbi algorithm is implemented as follows  [19]:   Step 1. Set the time instant j = K, K being the constraint length. Calculate the partial metric Mj for the single path entering each state. Store the path with the largest metric, called the survivor, and its metric for each state.   Step 2. Set j = j + 1. Calculate Mj for all the paths entering each state i by adding the branch metric entering state i to the metric of the connecting survivor at time j − 1,      170   cid:2   Channel estimation and equalization  Mi cid:14  j − 1 . For each state i, store the survivor and its metric, and eliminate all the other paths.   Step 3. Repeat Step 2, until j ≥ N + K, where N is the length of the input sequence. The Viterbi algorithm always ﬁnds the maximum likelihood path through the trellis. The algorithm starts with the all-zero state of the trellis at time j = 0, with the initial cumulative path metrics M for all states being zero.  The basic operation reduces the maximum number of routes from 2N to only 4N com- putations, for binary sequences. At each state in each layer of the trellis diagram, an add-compare-select  ACS  operation is required. To implement the Viterbi algorithm, two sets of registers are needed: registers for storing the states of the routes Mi j  and for storing the selection at each node. The Viterbi algorithm must keep records of 2N K−1  surviving paths and their corresponding metrics. For this reason, when the Viterbi algorithm is used for decoding of convolutional codes, the number of computations as well as the memory requirement makes convolutional codes feasible only for small N and K. Commercially available Viterbi equalizer decoder chips are typically limited to 64 states. These can be used for equalization for pulses that each smear over K = 7 bit intervals. In IS-95, the constraint length K = 9 is selected. Hardware implementation of the Viterbi algorithm has been discussed in many publications [14, 17].  The Viterbi algorithm was originally proposed for decoding convolutional codes using MLSE [31]. The channel memory which introduces ISI is analogous to the encoder mem- ory in a convolutional code [12], thus it is also used for the equalization and detection of digital signals. It is generally applicable to detection of a discrete-time ﬁnite-state Markov process immersed in additive memoryless noise. The trellis diagram is used for characteriz- ing a ﬁnite state machine. The Viterbi algorithm is well suited for estimating the most likely input sequence to the ﬁnite state machine, thus implementing equalization and detection simultaneously in case of ISI distortion. The Viterbi algorithm is a technique for ﬁnding the shortest route through a graph. More description of the Viterbi algorithm is given in Chapter 15.  6.2.6 Frequency-domain equalizers  Compared with the conventional time-domain equalization, frequency-domain equaliza- tion  FDE  exhibits a substantially low complexity that grows with the number of symbols of dispersion [33]. Also, adaptive algorithms generally converge faster and are more stable in the frequency domain [28]. FDE is an effective technique for high-data-rate wireless communication systems suffering from very long ISI.  FDE for single-carrier systems  SC-FDE  shares some common elements with OFDM. Compared to OFDM, FDE offers similar performance and complexity for broadband wire- less systems [5], but it is more robust without heavy interleaving and error-correction coding and is less sensitive to nonlinear distortion and carrier synchronization difﬁculties [5], thereby allowing for the use of low-cost power ampliﬁers. The SC-FDE system is shown in Fig. 6.5. At the transmitter, a cyclic preﬁx is peri- odically added to the baseband data sequence {x n } and modulated onto a single-carrier      171   cid:2   x  n   Cyclic prefix  insertion  Transmitter   cid:2 Figure 6.5  6.2 Channel equalization  Channel  FFT  Equalizer  IFFT  Detection  x  n   Cyclic prefix removal  Channel estimation  Receiver  FDE  Simpliﬁed block diagram of an SC-FDE system.  frequency for transmission across the time-varying and frequency-selective fading chan- nel. At the receiver, the cyclic preﬁx is removed. The FFT is utilized to convert the time-domain data signal into frequency-domain signal. Then, frequency-domain channel estimation and equalization are applied to mitigate ISI. The IFFT is applied to convert the equalized frequency-domain signal into a time-domain signal for detection and estimation. Like OFDM, FDE applies the processing in the frequency domain and uses cyclic preﬁx. OFDM will be introduced in Chapter 9.  Single-carrier FDMA  SC-FDMA  [25] is a multiple-access scheme based on SC-FDE. It has similar performance and similar overall complexity to OFDM. SC-FDMA has the inherent characteristics of a low PAPR. This is the reason why SC-FDMA is preferred over OFDM in the uplink communications in 3GPP LTE, where lower PAPR greatly enhances the transmit power efﬁciency of MSs. For subchannel allocation, SC-FDMA can be implemented by sub-band [25] and interleaved approaches [29] for allocating resources to users.  Single-carrier systems generally require knowledge of the channel and the variance of the additive noise process for channel equalization. Training blocks are utilized to estimate the channel transfer function for the blocks. The channel transfer functions for the data blocks are estimated by interpolating the channel transfer functions of the training blocks at the current and the next frames. Adaptive SC-FDE systems with explicit channel and noise-power estimation have been considered in [4, 23, 37].  A single-carrier frequency-domain DFE, which employs a frequency-domain feedfor- ward ﬁlter and a short time-domain feedback ﬁlter, is described in [2]. It signiﬁcantly outperforms a linear FDE, and yields a capacity very close to that of OFDM, with a computational complexity similar to that of OFDM.  6.2.7 Blind equalizers  As in the case of blind channel estimation discussed earlier, blind adaptive equalization exploits known statistical properties of the transmitted signal for estimation of both the channel and the data. The constant modulus algorithm is the well-known blind adaptation algorithm. This principle is applicable for blind channel estimation, blind equalization, blind source separation and blind beamforming in the wireless communication ﬁeld. For      172   cid:2   Channel estimation and equalization  constant envelope signals such as FM and M-ary PSK  MPSK  signals, the amplitude of the signal is the same, and thus such a constant-modulus cost function can be deﬁned by   cid:22    cid:23   JCM = E   1 − yn 2   6.41   or by a similar function. The approximation of JCM is formed from the equalizer output yn, and no training signal is required for estimation.  Blind equalization algorithms can also be derived from high-order statistics of the sig- nals. For example, the entropy of the received symbols is smaller than that in case of no ISI, since ISI introduces dependence; thus, maximizing the joint entropy of the equal- izer outputs removes the ISI. Blind adaptive equalization algorithms are typically based on implicit high-order statistics criteria or the constant modulus criteria. Generally, blind equalization algorithms have convergence and complexity problems, making them rarely used in industry.  6.2.8 Precoding  Channel equalization can also be implemented at the transmitter side. Linear preequal- ization at the transmitter has exactly the same performance as linear equalization at the receiver does. Precoding is done in a nonlinear way. Similar to the evolution from the ZF linear equalizer to the DFE, precoding replaces the linear ﬁlter by a nonlinear feedback structure to avoid power enhancement. Since equalization is implemented at the transmit- ter, error propagation that occurs in the case of the DFE is avoided. Precoding is applicable only if the channel H z  is known at the transmitter. Tomlinson-Harashima precoding and ﬂexible precoding are the two fundamental channel precoding techniques. More exposition of precoding is given in [11]. Flexible precoding, also known as distribution-preserving precoding, is employed in ITU V.34 voiced-band modem standard. Flexible precoding can be viewed as being derived from linear equalization at the receiver.  The nonlinear device used in precoding is a modulo operation. There is a precoding loss as the transmit power penalty. Tomlinson-Harashima precoding converts the ISI channel H z  into a memoryless AWGN channel. Flexible precoding may cause error propagation, and for this reason Tomlinson-Harashima precoding is preferable for high rate transmission such as DSL. Implementation of Tomlinson-Harashima precoding is also very simple.  Signal shaping is intended to decrease average transmit power. The constellation expan- sion also causes an increase in the peak power of the transmit signal [11]. Precoding and signal shaping are combined in V.34 and V.90.  6.3 Pulse shaping  Filters for transmitters and receivers have different requirements. The transmitter ﬁlter band-limits the signal spectrum to the Nyquist bandwidth B, while the receiver ﬁlter must have high stopband attenuation to reject the out-of-band noise. The cascade of the      173   cid:2   6.3 Pulse shaping  transmitter and receiver ﬁlters must satisfy the Nyquist criterion so as to avoid ISI. This is called Nyquist ﬁltering. Pulse shaping reduces sidelobe energy associated with a rectan- gular pulse. It is targeted at shaping the transmitted pulses to allow transmission at a rate close to 2B symbols s  Nyquist rate .  An ISI-free signal is any signal that passes through zero at all but one of sampling  instants. This is known as the Nyquist criterion   cid:15   p kT  =  k = 0 k  cid:18 = 0.  1, 0,  That is, p t  has a zero crossing at every T seconds. Note that in this section T is the sampling period.  In the frequency domain, the folded spectrum P cid:27   f   of pk t  must satisfy [27]   cid:18   ∞ cid:26    cid:17   P  n=−∞  P cid:27   f   = 1 T  f + n T  = 1,  from which one can design pulses in the frequency domain that yield zero ISI.  The sinc function is an ISI-free signal, and it has a desired rectangular frequency response called the desired Nyquist ﬁlter. The sinc pulse is, however, physically unreal- izable. Also, in the time domain, the signal decays slowly, at a rate of 1 t.   6.42    6.43   6.3.1 Raised-cosine ﬁltering  The raised-cosine pulse shaping function is a popular subset of the Nyquist ﬁlter family that satisﬁes the Nyquist criterion for an ISI-free baseband impulse response. In the frequency domain, the raised-cosine ﬁlter is deﬁned by  ⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩   cid:22   cid:22   1 2 1, 1 2 0,   cid:17   cid:17    cid:18  cid:23   cid:18  cid:23   a  1 + cos π 1 + cos π  a  f T − 1−α  , −f2 < f < −f1  2  2  f T + 1−α  ,   f ≤ f1 f1 < f ≤ f2 otherwise  Rα  f   =  ,   6.44   where α ∈  0, 1] is the roll-off factor, f1 = 1−α The pulse p t  in the time domain corresponds to Rα  f   is given by  2T and f2 = 1+α 2T .  p t  = sin πt T  πt T  cos απt T  1 − 4 αt T 2 .   6.45   The raised-cosine pulse decays as a function of 1 t3.  Example 6.3: The frequency- and time-domain representations of the raised-cosine func- tion are shown in Figs. 6.6 and 6.7, respectively. The impulse response of a raised-cosine ﬁlter is similar to the sinc pulse but with sidelobe that decreases with increasing α.      174   cid:2   Channel estimation and equalization   cid:2 Figure 6.6  The raised-cosine ﬁlter in the frequency domain.  −1  −0.5  0.5  1  α = 0 α = 0.3 α = 0.5 α = 1  0 f T  α = 0 α = 0.3 α = 0.5 α = 1       f    α R  1  0.8  0.6  0.4  0.2  0  1  0.8  0.6  0.4  0.2  0    t      p  −0.2  −5   cid:2 Figure 6.7  The raised-cosine ﬁlter in the time domain.  0 t  T  5  In practice, the raised-cosine ﬁlter is usually applied to shape rectangular pulses to  generate ISI-free signals. The pulse shaping ﬁlter is designed as  H  f   = Rα  f   sinc Tf  ,   6.46   where sinc Tf   is the frequency response of a rectangular pulses with width T.  Example 6.4: The frequency response of the pulse shaping ﬁlter, given by  6.46 , is plotted in Fig. 6.8.  When a Nyquist ﬁlter is raised-cosine pulse shaped, the combined ﬁlter is an anti-ISI ﬁlter for a rectangular pulse shape, which has a sinc spectrum. This effectively increases the      175   cid:2   6.3 Pulse shaping       f         f  H  0.8  1.6  1.2  0.4  0  α = 0 α = 0.3 α = 0.5 α = 1  0 f T   cid:2 Figure 6.8  Amplitude response of the raised-cosine ﬁltered rectangular pulse.  −1  −0.5  0.5  1  system bandwidth from that of the Nyquist ﬁlter, 1 T . This requires some additional bandwidth for realizable anti-ISI ﬁltering. This is suitable for a large channel space. An increase in α can reduce the PAPR of the transmitted signal in a SC-FDMA system [25], leading to reduced requirement on the linearity of the transmitter power ampliﬁer.  T , to 1+α  6.3.2 Root-raised-cosine ﬁltering  Commonly, the transmitter and receiver ﬁlters have the form of HT  f   = Rβ HR  f   = R1−β  α  f   and   f   to satisfy the Nyquist criterion, where β is selected to optimize the  α  performance. This is given by the relation  where HN and Hch are the Nyquist and channel frequency responses, respectively.  From  6.47 , if HT  f   and HR  f   are related by  HN  f   = HT  f  Hch  f  HR  f  ,  T  f   = HR  f  , ∗  H  Equation  6.48  satisﬁes the requirement for matched ﬁltering, except for the linear phase factor. By a careful selection of HT and HR, the system can satisfy the Nyquist and matched ﬁltering criteria simultaneously. A popular selection is  HT  f   = HR  f   = cid:25   Rα  f  .  This function is known as the root-raised-cosine function. It has better spectral properties than the raised-cosine function, but decays less rapidly in the time domain. In practical implementation, the transmitter and receiver ﬁlters also include a term to compensate the channel distortion.   6.47    6.48    6.49       176   cid:2   The impulse response for the root-raised-cosine ﬁlter is given as  Channel estimation and equalization   cid:17    cid:18   cid:5  + 4αt 1 −   cid:17   T cos  4αt T   cid:17   cid:6   cid:18 2   1−α πt  T  πt T   cid:18   .   1+α πt  T  p t  = sin   6.50   Raised-cosine pulse shaping and root-raised-cosine ﬁltering are widely used in wireless communications for avoiding ISI. In most practical communication systems, the matched ﬁlter must be used in the receiver since it is the optimum. Thus root-raised-cosine ﬁl- tering is typically used at both the transmitter and the receiver. Root-raised-cosine pulse ﬁltering is employed in IS-95, WCDMA, and TD-SCDMA with α = 0.22, in IS-54 136 with α = 0.35, in IEEE 802.16 with α = 0.25, in ZigBee with α = 1, in Bluetooth with α = 0.4, and in PACS with α = 0.5.  Problems  6.1 Consider a wireless channel with three multipath components −j4πf Ts. Neglecting the thermal noise, the nth received sample is given by r n  = 0.8c n  − 0.5c n − 1  − 0.3c n − 2 ,  H  f   = 0.8 − 0.5e  −j2πf Ts − 0.3e  where c n  is the nth transmitted symbol. Design a ZF equalizer to compensate for the linear distortion caused by the channel.  6.2 Suppose that the sample values of the channel response are  [x −5 , x −4 , x −3 , x −2 , x −1 , x 0 , x 1 , x 2 , x 3 , x 4 , x 5 ] = [0.01,−0.02, 0.03,−0.15, 0.2, 1,−0.1, 0.12,−0.06, 0.04, 0.005].   a  Calculate the ZF equalizer coefﬁcients.  b  Set K = 2. Verify whether the values of [c −2 , c −1 , c 0 , c 1 , c 2 ] = [0, 0, 1, 0, 0].  c  What are the values for c −3  and c 3 ? 6.3 Let the pulse shaping function g t  = sinc t Ts . Find the matched ﬁlter for g t . [Hint:  −t .] ∗ g 6.4 Show that the impulse response of a root raised cosine ﬁlter is given as  4αt T  cos[π 1 + α t T] + sin[π 1 − α t T]   cid:20    cid:19    πt T   1 −  4αt T 2  .  x t  = 1√ T  Plot the impulse response.  6.5 Show that a pulse having the raised-cosine spectrum satisﬁes the Nyquist criterion for any value of the roll-off factor α.      177   cid:2   References  6.6 4PAM is used for transmitting at a bit rate of 9600 bits s on a channel with frequency response  C  f   =  1   1 + j  f  2400  2 ,   f ≤ 2400  and C  f   = 0 otherwise. The noise is zero-mean AWGN with PSD N0 2 W Hz. Determine the magnitude responses of the optimum transmitting and receiver ﬁlters.  6.7 For a telephone channel in the frequency range 300 Hz to 3000 Hz,  a  select a power- efﬁcient constellation to achieve a data rate of 9600 bits s.  b  Assuming an ideal channel, if root-raised-cosine pulse is used as the transmitter pulse, select the roll-off factor. 6.8 A channel has an impulse response h τ   = 1 − 0.2τ . Derive an expression for the coefﬁcients of a T-space ZF equalizer.  6.9 Write a computer program to design:  a  the ZF equalizer and  b  the MMSE equalizer. Test the program using some speciﬁc channel conditions.  6.10 Write a computer program to plot the impulse responses of the raised-cosine and root-raised-cosine ﬁlter. Plot for the cases of α = 0, 0.22, 0.5, and 1.  References  [1] K. Abend & B. D. Fritchman, Statistical detection for communication channels with  intersymbol interference. Proc. IEEE, 58:5  1970 , 779–785.  [2] N. Benvenuto & S. Tomasin, On the comparison between OFDM and single carrier modulation with a DFE using a frequency-domain feedforward ﬁlter. IEEE Trans. Commun., 50:6  2002 , 947–955.  [3] J. M. Ciofﬁ, G. P. Dudevoir, M. V. Eyuboglu & G. D. Forney, Jr., MMSE decision- feedback equalizers and coding – part I: equalization results. IEEE Trans. Commun., 43:10  1995 , 2582–2594.  [4] J. Coon, M. Sandell, M. Beach & J. McGeehan, Channel and noise variance esti- mation and tracking algorithms for unique-word based singlecarrier systems. IEEE Trans. Wireless Commun., 5:6  2006 , 1488–1496.  [5] A. Czylwik, Comparison between adaptive OFDM and single carrier modulation with frequency domain equalization. In Proc. IEEE VTC, Phoenix, AZ, May 1997, 2, 865–869.  [6] D. Divsalar & M. K. Simon, Multiple-symbol differential detection of MPSK. IEEE  Trans. Commun., 38:3  1990 , 300–308.  [7] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [8] K.-L. Du & M. N. S. Swamy, An adaptive space-time multiuser detection algorithm  for CDMA systems. In Proc. IEEE WiCOM, Wuhan, China, Sep 2006, 1–5.      178   cid:2   Channel estimation and equalization  [9] U. Fincke & M. Pohst, Improved methods for calculating vectors of short length in a lattice, including a complexity analysis. Math. of Computation, 44  1985 , 463–471. [10] R. F. H. Fischer, C. Windpassinger, A. Lampe & J. B. Huber, MIMO precoding for decentralized receivers. In Proc. IEEE ISIT, Lausanne, Switzerland, June-Jul 2002, 496.  [11] R. F. H. Fischer, Precoding and Signal Shaping for Digital Transmission  New York:  Wiley-IEEE Press, 2002 .  [12] G. D. Forney, Jr., Maximum likelihood sequence estimation of digital sequence in the presence of intersymbol interference. IEEE Trans. Inf. Theory, 18:3  1972 , 363–378. [13] R. D. Gitlin and S. B. Weinstein, Fractionally-spaced equalization: an improved  digital transversal equalizer. Bell Syst. Tech. J., 60:2  1981 , 275–296.  [14] M. Guo, M. O. Ahmad, M. N. S. Swamy & C. Wang, FPGA design and implementa- tion of a low-power systolic array-based adaptive Viterbi decoder. IEEE Trans. Circ. Syst. I, 52:2  2005 , 350–365.  [15] B. Hassibi & H. Vikalo, On the expected complexity of sphere decoding. In Proc. Asilomar Conf. Signals Systems Computers, Paciﬁc Grove, CA, Nov 2001, 2, 1051–1055.  [16] S. Haykin, Adaptive Filter Theory, 4th edn  Upper Saddle River, NJ: Prentice Hall,  2002 .  [17] Y. Jiang, Y. Tang, Y. Wang & M. N. S. Swamy, A trace-back-free Viterbi decoder using a new survival path management algorithm. In Proc. IEEE ISCAS, Phoenix, AZ, May 2002, 1, 261–264.  [18] B. Li, W. Tong & P. Ho, Multiple-symbol detection for orthogonal modulation in  CDMA system. IEEE Trans. Veh. Tech., 50:1  2001 , 321–325.  [19] J. Lin & D. J. Costello, Jr., Error Control Coding: Fundamentals and Applications   Englewood Cliffs, NJ: Prentice Hall, 1983 .  [20] E. M. Long & A. M. Bush, Decision-aided sequential sequence estimation for intersymbol interference channels. In Proc. IEEE ICC, Boston, MA, Jun 1989, 26.1.1–26.1.5.  [21] R. W. Lucky, Techniques for adaptive equalization of digital communication systems.  Bell Syst. Tech. J., 45:2  1966 , 255–286.  [22] X. Ma & W. Zhang, Fundamental limits of linear equalizers: diversity, capacity, and  complexity. IEEE Trans. Inf. Theory, 54:8  2008 , 3442–3456.  [23] M. Morelli, L. Sanguinetti & U.Mengali, Channel estimation for adaptive frequency-  domain equalization. IEEE Trans. Wireless Commun., 4:5  2005 , 2508–2518.  [24] W. H. Mow, Maximum likelihood sequence estimation from the lattice viewpoint.  IEEE Trans. Inf. Theory, 40:5  1994 , 1591–1600.  [25] H. G. Myung, J. Lim & D. J. Goodman, Peak-to-average power ratio of single car- rier FDMA signals with pulse shaping. In Proc. IEEE PIMRC, Helsinki, Finland, Sep 2006, 1–5.  [26] A. Paulraj, R. Nabar & D. Gore, Introduction to Space–Time Wireless Communica-  tions  Cambridge, UK: Cambridge University Press, 2003 .  [27] J. G. Proakis & M. Salehi, Digital Communications, 5th edn  New York: McGraw-  Hill, 2008 .      179   cid:2   References  [28] J. J. Shynk, Frequency-domain and multirate adaptive ﬁltering. IEEE Signal Process.  Mag., 9:1  1992 , 14–35.  [29] U. Sorger, I. De Broeck & M. Schnell, Interleaved FDMA – a new spreading-spectrum  multiple-access scheme. In Proc. IEEE ICC, Atlanta, GA, Jun 1998, 1013–1017.  [30] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  [31] A. J. Viterbi, Error bounds for convolutional codes and an asymptotically optimum  decoding algorithm. IEEE Trans. Inf. Theory, 13:2  1967 , 260–269.  [32] A. J. Viterbi, Principles of Spread Spectrum Communication  Reading, MA: Addison-  2001 .  Wesley, 1995 .  [33] T. Walzman & M. Schwartz, Automatic equalization using the discrete frequency  domain. IEEE. Trans. Inf. Theory, 19:1  1973 , 59–68.  [34] F. Wan, W.-P. Zhu & M. N. S. Swamy, A semiblind channel estimation approach for  MIMO-OFDM systems. IEEE Trans. Signal Process., 56:7  2008 , 2821–2834.  [35] F. Wan, W.-P. Zhu & M. N. S. Swamy, Frequency-domain semi-blind channel estimation for MIMO-OFDM Systems. Submitted to IEEE Trans. Wireless Commun. [36] B. Widrow, J. M. McCool, M. G. Larimore, and J. C. R. Johnson, Adaptive switching  circuits. In Proc. IRE WESCON Conv., Los Angeles, CA, 1960, 96–104.  [37] Y. R. Zheng & C. Xiao, Channel estimation for frequency-domain equalization of single-carrier broadband wireless communications. IEEE Trans. Veh. Tech., 58:2  2009 , 815–823.      7  Modulation and detection  7.1 Analog modulation  Before we start to deal with digital modulation, we ﬁrst brieﬂy introduce analog modula- tion. Given a carrier waveform  x t  = a cos ωt + φ ,   7.1   a message can be modulated on the amplitude, frequency, phase, or a combination of these, leading to various modulation techniques. Analog modulation, such as amplitude modula- tion  AM , phase modulation  PM , or frequency modulation  FM , is only used in analog wireless communication systems.  7.1.1 Amplitude modulation  xAM t  = A [1 + mxBB t ] cos ωct,  For a baseband signal xBB t , the conventional AM generates a waveform of the type  where m is the modulation index, and ωc = 2πfc is the angle frequency of the carrier. The spectrum of the modulated signal is obtained by taking the Fourier transform of the   cid:19    cid:20  m  XBB   f − fc  + XBB   f + fc   + δ   f − fc  + δ   f + fc   .  signal xAM t   XAM  f   = A 2  Double-sideband  DSB  AM deﬁnes the modulated waveform as  xDSB-AM t  = AxBB t  cos ωct.  The spectrum of the modulated signal is given by  XDSB-AM  f   = A 2  XBB   f − fc  + A 2  XBB   f + fc  .  The spectra of conventional AM and DSB-AM are illustrated in Fig. 7.1. Both tech- niques have the same bandwidth of the modulated signal, which is twice that of the baseband bandwidth  BAM = 2BBB.   7.2    7.3    7.4    7.5    7.6       181   cid:2    cid:2 Figure 7.1  Spectra of the conventional AM and the DSB-AM.  7.1 Analog modulation  XBB  f    −BBB  f  BBB  XAM  f    XDSB−AM  f    0  0  0  fc  fc  −fc  −fc  f  f  0.01  0.02  0.03  0.04  0.05  0.01  0.02  0.03  0.04  0.05  B B x  M A x  M A − B S D x  −2  0  −2  0  2  0  2  0  2  0  −2  0   cid:2 Figure 7.2  0.01  0.02  0.03  0.04  0.05  t  Modulated waveforms of conventional AM and DSB-AM.  There is a spectral line at fc for the conventional AM, and this corresponds to a sinu- soidal component at fc. This component does not transmit any information, leading to a lower power efﬁciency, compared to DSB-AM. For this reason, conventional AM is some- times termed DSB-large carrier  DSB-LC , while DSB-AM is termed DSB-small carrier  DSB-SC . However, the presence of this component makes 1 + mxBB t  always positive, resulting in easy demodulation when applying cheap envelope detection. Single-sideband  SSB  AM is obtained by ﬁltering out one of the sidebands.  Example 7.1: Given a digital-like waveform and the AM parameters m = 0.5, A = 1, and fc = 200, the amplitude modulated waveforms of the conventional AM and the DSB-AM are shown in Fig. 7.2.  AM signals can be demodulated using a coherent demodulator. Demodulation that uses an LO identical in frequency and phase to the modulator LO is referred to as synchronous or      182   cid:2   Modulation and detection  coherent demodulation. Coherent SSB- and DSB-AM demodulators have the same SNR performance, while coherent conventional AM has a smaller output SNR performance. For signals using conventional AM, demodulation can also be done by using an enve- lope detector, and such a method is known as noncoherent demodulation. The noncoherent demodulator is comparable to the coherent demodulator in terms of the output SNR for large input SNR, but introduces signiﬁcant degradation for small input SNR.  AM is mainly used in broadcast radios and sound modulation in television, and ﬁnds limited application in other wireless systems, since the modulated amplitude is more susceptible to noise and a highly linear power ampliﬁer is required in the transmitter.  7.1.2 Phase modulation and frequency modulation  Both PM and FM methods are angle modulation schemes, and they are nonlinear modu- lation schemes. The phase-modulated and frequency-modulated signals are, respectively, deﬁned by  xPM t  = A cos [ωct + mxBB t ] ,   cid:5    cid:14    cid:6   xFM t  = A cos  ωct + m  t  −∞ xBB t dt  ,   7.7    7.8   where m is the phase or frequency modulation index.  Example 7.2: For the same message given in Example 7.1 and the modulation parameters: A = 1, fc = 200, and mFM = 1000 or mPM = 10, the waveforms of the FM and PM signals are plotted in Fig. 7.3.  B B x  M F x  M P x  −2  0  −1  0  2  0  1  0  1  0  −1  0  0.01  0.02  0.03  0.04  0.05  0.01  0.02  0.03  0.04  0.05   cid:2 Figure 7.3  0.01  0.02  0.03  0.04  0.05  t  Modulated waveforms of FM and PM.      183   cid:2   7.2 Introduction to digital modulation  FM is more widely used than PM. This is due to the fact that frequency modulation and demodulation are simple to implement. In reality, any circuit having a transfer function that is sensitive to frequency can be used as a frequency demodulator. For example, a highpass ﬁlter can actually convert an FM signal to an AM signal, whose amplitude corresponds to the frequency of the FM signal.  For implementation of FM, the baseband signal that bears information is passed through a pre-emphasis ﬁlter to emphasize weaker higher frequency signal components before it is passed to either a direct or indirect FM modulator. This is because the discriminator’s output noise PSD, which is proportional to the square of the frequency [15], has a much more adverse inﬂuence on the higher frequency components of the information-bearing signal. At the receiver, the emphasized components are de-emphasized. More details on analog FM may be found in [32].  The nonlinear dependence of PM or FM signals upon the baseband signal makes the bandwidth of the modulated signal inﬁnite. Thus, the effective bandwidth of the signal, BFM or BPM, can be deﬁned as that containing 98% of the signal power, and this bandwidth is given by Carson’s rule   7.9  where β = mAm ωm, when xBB t  = Am cos ωmt. The parameter β is also called modulation index. Accordingly,  BFM, BPM ≈ 2 β + 1 BBB,  The SNR of the FM radio can be much better than the AM radio, but needs more channel  bandwidth. The output SNRs of FM and AM are related by [27]  xFM t  = A cos  ωct + β sin ωmt  .   cid:8    cid:7   2 + m2 2m2  SNRFM = 3  β2SNRAM,   7.10    7.11   where m is the AM modulation index. Thus, the output SNR of FM increases in square law, when its bandwidth increases linearly.  PM and FM are more important than AM, since they are also used in the analysis of oscillators and frequency synthesizers. FM ﬁnds applications in two-way voice radio, and is used in most 1G mobile communication systems. Demodulation of FM signals can be performed by using a discriminator and an envelope detector.  7.2 Introduction to digital modulation  Digital modulation techniques are more important for modern wireless systems. Compared to analog systems, digital systems achieve better spectral efﬁciency, have better noise and fade-rejecting capability, and require lower transmit power. In addition, error correction and encryption can be easy to implement in digital systems. As in analog systems, the amplitude, frequency, and phase of a carrier A cos ωt + φ  are used to modulate digital symbols, and accordingly the three basic classes of digital      184   cid:2   Modulation and detection  modulation techniques are amplitude-shift keying  ASK , frequency-shift keying  FSK , and phase-shift keying  PSK . Another important class of digital modulation technique is quadrature amplitude modulation  QAM , which employs both the amplitude and phase for modulation. These modulation techniques are widely used in various standards for wireless communications.  In recent wireless standards, multiple modulation techniques are used, in an adaptive manner. The modulation parameters such as the modulation level, symbol rate, or coding rate of the channel coding are adaptively adjusted according to the channel and trafﬁc. Adaptive modulation can be preassigned or be dependent on the measurement of the chan- nel and trafﬁc. Adaptive modulation is embodied in all 3G 4G and some recent wireless network standards.  7.2.1 Signal space diagram  Digital signal symbols are represented by different states in the signal space diagram, known as the constellation diagram. The shape of the constellation is related to the modulation method. Typically, the constellation takes form of squares or circles, for sim- ple demodulation. It is interesting to note that rectangular and hexagonal constellations have a better power efﬁciency than the corresponding square and circular constella- tions associated with M-ary QAM  MQAM  and M-ary PSK  MPSK , with a saving of 1.3 dB in power [11]. This gain in power, however, leads to increased complexity in constellation. This method is usually not used, since coding provides much better performance.  The carrier modulated waveform can be expressed in the complex envelope form   cid:22    cid:23   sBP t  =  cid:19   sLP t e j 2πfct  ,  sLP t  = sLP, I t  + jsLP, Q t   where  is the complex baseband signal, and sBP t  is the upconverted bandpass signal, which is the physically existing signal. In quadrature form, the bandpass waveform is expressed by  sBP t  = sLP, I t  cos 2πfct − sLP, Q t  sin 2πfct.  In digital modulation, the bandpass signal is transmitted at each baud interval as a member of a ﬁnite set of ﬁnite energy waveforms, {sBP,0 t , sBP,1 t , ··· , sBP, M−1 t }. The baseband counterpart is denoted by {sLP,0 t , sLP,1 t , ··· , sLP, M−1 t }. Each complex waveform sLP, m can be projected onto a set of N orthogonal basis functions, yielding a signal vector representation  sLP, m, 0, sLP, m, 1,··· , sLP, m, N−1  .   7.15   sLP, m = cid:7    cid:8   The N orthogonal basis functions can be obtained from the M signals by using the Gram- Schmidt orthogonalization [9].   7.12    7.13    7.14       185   cid:2   The energy in the waveform sBP, m t  is given by  7.2 Introduction to digital modulation  Em =6   cid:14  ∞ 882 = 7 =88sBP, m 882 . 88sLP, m  sBP, m, sBP, m   cid:14  ∞  ≈ 1 2  LP, m t dt = 1  2  −∞ s2  −∞ s2  BP, m t dt  The approximation is applicable when the bandwidth of the baseband signal BBB is much less than fc.  The squared Euclidean distance between two symbols sBP, i t  and sBP, j t  is given by   7.16    7.17   d2 ij  2  882  88sLP, i − sLP, j  882 = 1 =88sBP, i − sBP, j  cid:14  ∞  cid:19   cid:20 2 dt  cid:21  = si t  − sj t  −∞ + Esj  cid:19  ρij , = Esi 7 6  cid:4  cid:4 sBP, i 88 = sBP, isBP, j 88sBP, i cid:15  ·  cid:15 sBP, j  cid:4  cid:4  · sBP, j  cid:12  6  cid:13  7 8888sLP, j 88sLP, m 88  sBP, i, sBP, j  sLP, i, sLP, j  =  cid:19   − 2  EsiEsj  .   cid:19  ρij  =  where ρij is the correlation coefﬁcient between the two symbols   7.18  For antipodal binary signals, ρ12 = −1 and dij reaches its maximum. For orthogonal signals ρ12 = 0.  7.2.2 Demodulation and detection  The optimum receiver of any modulation alphabet represented in a signal space diagram is a correlator, or a matched ﬁlter, matched to all the possible transmit waveforms. The coherent receiver compensates for phase rotation due to the channel by means of carrier recovery. By adjusting the magnitude of the channel attenuation, in the absence of noise, the received signal r is equal to the transmitted signal s. The ideal detector is known as the MAP detector. For the assumption of equiprobable symbols, the MAP detector is identical to the ML detector.  When carrier recovery is difﬁcult, differential detection becomes an attractive alterna- tive. The receiver needs just to compare the phases and or amplitudes of two subsequent symbols. In order to implement differential detection, the transmitted signals need to be differentially encoded. When the carrier phase is completely unknown, noncoherent detec- tion such as envelope detection can be used. Generally, coherent detection provides the best bit error probability  BEP  performance, and is discussed here. The block diagrams of MPSK, M-ary pulse amplitude modulation  MPAM  and QAM demodulators can be found in [28].      186   cid:2   Modulation and detection  For M-ary signaling, it is typically assumed that the symbol energy is equally divided among all bits and that Gray encoding is used. Based on these assumptions, when coherent ML detection is employed, the bit SNR and the symbol SNR are related by   7.19    7.20    7.22    7.23    7.24   and the BEP and the symbol error probability  SEP  are related by  γb ≈ γs log2 M  Pb ≈ Ps log2 M  .  The bit SNR and symbol SNR are deﬁned by γb = Eb N0  ,  γs = Es N0   7.21  where the average bit energy Eb is calculated by Eb = PRTb, PR being the average received power and Tb the bit period. The noise power spectrum N0 is constant, measured in watts Hz.  ,  Coherent maximum-likelihood detection  Consider a channel of the form  y = Hx + e  where the vector e has components that are zero-mean complex AWGN variables with variance σ 2, and H is known at the receiver. Thus, y is a complex Gaussian random vector with mean Hx and covariance matrix σ 2I.  The conditional pdf  or likelihood function  of y, conditioned on x, can be written as  where n is the dimension of y. Given y, x can be estimated by maximizing the likelihood function. This is equivalent to the minimization of the ML metric  p yx  = 1  π nσ 2n e  − 1 σ 2   cid:15 y−Hx cid:15 2  ,  ˆx = arg min   cid:15 y − Hx cid:15 2.  x  7.2.3 Error probability in the Gaussian channel  The error probability is determined by the decision zone of each symbol in the constellation diagram, and can be analyzed by using the ML receiver structure.  From the fundamental theory of detection and estimation of signals in noise, for a Gaussian channel, the probability of symbol si being misjudged as symbol sj is given by [28, 39]   cid:7   Pr  si, sj  ⎛⎝    cid:8  = Q  ⎞⎠ = 1  erfc  2     ⎛⎝ 1  2  d2 ij N0  ⎞⎠ ,  d2 ij 2N0   7.25       187   cid:2   7.2 Introduction to digital modulation  where dij is the Euclidean distance between the two symbols, and N0 is the noise power. The Q-function is related to the complementary error function, erfc x , by  refer to Appendix A    cid:17 √   cid:18   2x  .  erfc x  = 2Q  The Q-function is upper-bounded by the Chernoff bound  For binary signals, all symbols have the same energy Es, and we have  −t2 2.  cid:7   1 −  cid:19  cid:7    cid:8  cid:8  cid:3   ρij  .  Q t  ≤ e  cid:2  cid:21   cid:8    cid:8  = Q  cid:7 √  γs  Pr  si, sj   cid:7   cid:8  = Q   cid:7   For binary orthogonal signals such as the binary FSK  BFSK , minimum shift keying  MSK  and binary pulse position modulation  PPM , we have Pr . For antipodal signaling, Pr  si, sj  γs  .  si, sj  2γs   cid:7    7.28    cid:8  = Q   cid:7 √   cid:8    7.26    7.27   The union bound  M cid:26   M cid:26    cid:2    cid:3   Given M equally likely symbols such as MPSK, the union bound on the SEP Ps is given by  Ps ≤ 1 M   7.29  Deﬁning the minimum distance of the constellation as dmin = min  dik , the above bound can be simpliﬁed with a looser bound  k=1, k cid:18 =i  i=1  Q  .  The nearest-neighbor approximation to Ps is given by the probability of error associated with constellations at the minimum distance dmin scaled by Mdmin, the number of neighbors at this distance [13]  The nearest-neighbor approximation is less than the loose bound, and also slightly less than the union bound. At high SNR, it is quite close to the exact probability of symbol error. For an M-ary modulation, a symbol contains log2 M bits. The log2 M possible bits should be designed to map to symbol si, i = 1, . . . , M, in such a way that a decoding error is associated with an adjacent decision region, leading to only one bit error. This mapping scheme is known as the Gray coding. In this case, the error probability of a symbol being its nearest neighbors is very low. Thus, we have the BEP as  Pb ≈ Ps log2 M  .   7.30    7.31    7.32   dik√ 2N0   cid:3   .   cid:3   .   cid:2    cid:2   Ps ≤  M − 1 Q  dmin√ 2N0  Ps ≈ MdminQ  dmin√ 2N0      188   cid:2   Modulation and detection  7.3 Baseband modulation  Baseband modulation represents digital sequences by pulse waveforms that are suitable for baseband transmission. Baseband modulation waveforms are also called line codes or PCM codes.  7.3.1 Line codes  Basic classes of line codes are nonreturn-to-zero  NRZ , return-to-zero  RZ , pseu- doternary, and biphase. NRZ and RZ codes can be subdivided into unipolar and bipolar. Many more complex substitution codes and block codes are also available, and they are described in [39].  The different line codes are used for different applications. Selection of line code is  based on the following requirements on performance [39]:   Adequate timing information in the received data sequence. For this purpose, line codes with higher transition density are preferable.   A spectrum suitable for the channel. The PSD of the line code should have small bandwidth compared with the channel bandwidth to avoid the occurrence of ISI.   Narrow bandwidth.   Low error probability.   Error detection capability.   Bit sequence independence  transparency . Attributes of the code are independent of the source statistics.   Differential coding. Differential coded sequences are immune from polarity inversion. Some line codes have differential coding inherent in them.  Among NRZ codes, the NRZ-L  NRZ-level  waveform is the most common waveform in digital logic. It uses a level of A for 1, and a level of −A or 0 for 0  depending on bipolar or unipolar . NRZ-M  NRZ-mark  and NRZ-S  NRZ-space  are two differentially encoded NRZ codes. In telecommunications, NRZ codes are limited to short-haul links due to the lack of the timing information. RZ codes have more transitions in the waveform that render easy timing, but this introduces a wider bandwidth. Pseudoternary codes use three levels ± A and 0. The AMI  alternative mark inversion  codes in this class are often called bipolar codes in telecommunications. They are imple- mented as AMI-RZ and AMI-NRZ. Other codes in this class are the dicode NRZ and dicode RZ. Dicodes and AMI codes are related by differential coding.  Biphase codes use half-period pulses with differential phases. The Bi- cid:23 -L  biphase- level  format is better known as the Manchester code. Some biphase codes, such as Bi- cid:23 -L, Bi- cid:23 -M  biphase-mark , Bi- cid:23 -S  biphase-space , typically ensure at least one transition in a bit duration, thus providing adequate timing information to the demodulator. The conditioned Bi- cid:23 -L code, as a differentially encoded Bi- cid:23 -L, is immune from polarity inversion in the circuit. The delay modulation code, also called the Miller code, is also a      189   cid:2   7.3 Baseband modulation  biphase code. The Manchester code is speciﬁed for the IEEE 802.3 standard  Ethernet  for baseband coaxial cable, and differential Manchester has been speciﬁed in the IEEE 802.5 standard for token ring, using baseband coaxial cable or twisted pair.  PSDs  ∞ cid:26   k=−∞  s t  =  akg t − kT ,  Most of the digital modulated baseband signals can be written in the form  where ak’s are random data bits, g t  is the pulse shape in [0, T], and T is the bit duration. For NRZ codes, g t  = A, 0 ≤ t ≤ T, and 0 otherwise, A being the signal amplitude; for RZ codes, g t  = A, 0 ≤ t ≤ T 2, and 0 otherwise. In the unipolar case, ak = 1 for binary 1, and 0 for binary 0; in the bipolar case, ak = 1 for binary 1, and −1 for binary 0.  For wide sense stationary signals, the PSD can be calculated by taking the Fourier trans- form of the autocorrelation R τ  , using the Wiener-Khinchine theorem. For cyclostationary signals, R τ   is the time average of the time-dependent R t, τ   in a period. The derivation of the PSD is based on the stochastic mode of the bit sequences. For uncorrelated data sequences {ak}, the PSD is derived as [39]  9  :   cid:23 s = G  f  2  T  + m2  aRb  σ 2 a  δ   f − nRb   ,  ∞ cid:26   n=−∞  where Rb = 1 T is the bit rate, G  f   is the Fourier transform of g t , and σ 2 the variance and mean of {ak}. The fractional out-of-band power is deﬁned as B−B  cid:23 s  f  df −∞  cid:23 s  f  df  .   7.34   a and ma are  This can be obtained by numerical integration.  The PSD of s t  is derived, for NRZ codes, as [39]   cid:23 s  f   = A2T 4  cid:23 s  f   = A2T  δ  f     unipolar NRZ ,   bipolar NRZ .   cid:27   cid:27  ∞  cid:3 2 + A2  cid:3 2  Pob B  = 1 −  cid:2   cid:2   sin πf T  πf T sin πf T  4  πf T   7.33    7.35    7.36    7.37   These PSD expressions are valid for NRZ-L, NRZ-M, and NRZ-S codes, since the statistics properties of their sequences are the same.  For unitary average symbol energy, A = √  2 in both the cases. The two PSDs have the  same shape, but the unipolar case has an impulse at dc.  The PSDs of all the basic line codes are given in [39]. The bandwidths of some of the line codes are also given in [39], and they are listed in Table 7.1, where Bnull stands for the null bandwidth, B90% for the 90% energy bandwidth, and B99% for the 99% energy      190   cid:2   Modulation and detection  Table 7.1. Bandwidths of basic line codes.  Bnull  1.0Rb 1.0Rb 2.0Rb 2.0Rb 1.0Rb 1.0Rb 2.0Rb  BEPs  Line codes  bipolar NRZ -L,-M,-S  unipolar NRZ -L,-M,-S  bipolar RZ unipolar RZ AMI-RZ, dicode RZ AMI-NRZ, dicode NRZ Bi- cid:23  -L,-M, -S   B90%  0.85Rb 0.54Rb 1.7Rb 1.6Rb 1.71Rb 1.53Rb 3.05Rb  B99%  10Rb 5Rb 22Rb 22Rb 20Rb 15Rb 29Rb  bandwidth. The NRZ code has a narrow bandwidth  Bnull = Rb . The RZ code increases the density of transitions for ease of timing recovery, but leads to a doubling of the bandwidth.  The BEPs of line codes transmitted through an AWGN channel can be obtained for opti- mum detection. The BEPs for the basic line codes can be derived from  7.28 . The results for some line codes are given as [39]   bipolar NRZ-L, bipolar-RZ, Bi- cid:23 -L ,   bipolar NRZ-M -S, conditioned Bi- cid:23 -L ,   unipolar NRZ-L, unipolar-RZ, Bi- cid:23 -M -S ,   7.38    7.39    7.40    cid:18   cid:18    cid:17  cid:25   cid:17  cid:25  Pb = Q  cid:7 √ Pb ≈ 2Q Pb = Q  γb  2γb   cid:8   2γb  where γb = Eb  .  N0  Example 7.3: The BEPs for different line codes, given by  7.38 – 7.40 , are plotted in Fig. 7.4.  7.3.2 Pulse time modulation  Pulse time modulation is a type of baseband modulation scheme that is in between being pure analog or pure digital. It uses a constant amplitude. Pulse time modulation generates a sequence of pulses with a spectrum around the sampling frequency and its harmonics. Pop- ular pulse time modulation schemes are pulse-width modulation  PWM  and PPM. They have ﬁxed symbol intervals, and this enables much easier multiplexing and demultiplex- ing in the time domain. A PWM or PPM signal can be generated by uniform sampling or natural sampling.      191   cid:2   7.4 Pulse amplitude modulation  unipolar NRZ−L or RZ,  Bi−Φ−M −S  100  10−2  10−4  10−6  0  NRZ−M −S,  conditioned Bi−Φ−L  b P  NRZ−L, polar RZ, Bi−Φ−L   cid:2 Figure 7.4  2  4  8  10  12  6  γ  b  dB   BEPs of some line codes.  PCM code, as will be discussed in Chapter 12, is also a baseband coding scheme. It is widely used in source coding. PCM codes can be either NRZ or RZ. The digital PPM denotes a PCM code of k bits by a narrow pulse at one of the 2k positions for a symbol period T in the time domain, leading to a bandwidth expansion of 2k k. Compared to PCM, digital PPM can achieve a 5–11 dB improvement in sensitivity, but requires more transmission bandwidth [39]. PPM is usually implemented differentially as differential PPM to avoid the difﬁculties in synchronization. PPM is an M-ary modulation technique that can be detected noncoherently.  PPM is inherently sensitive to multipath interference, and for this reason, it is mainly used in optical or UWB wireless communications, where there is no or very little multipath interference. The 16PPM and 4PPM are used in the infrared physical mode of the baseline IEEE 802.11 standard. They are also used in the ISO 15693 standard for contactless Smart card, and the EPC standard for RFID.  7.4 Pulse amplitude modulation  Pulse amplitude modulation  PAM  can be in the baseband or in the passband. M-ary amplitude-shift keying  MASK  is MPAM in the passband case  with a carrier . NRZ and RZ line codes are baseband binary PAM. All information is encoded into the signal amplitude.  MPAM is one-dimensional linear modulation. For passband MPAM, that is, for MASK,  the transmitted signal over one symbol period is given by  si t  = Aig t  cos  2πfct  ,  0 ≤ t ≤ T,   7.41       192   cid:2    cid:2 Figure 7.5  Modulation and detection  00  s1  01  s2  0  11  s3  10  s4  I  The constellation of 4PAM. The information bits are Gray-encoded.  where Ai =  2i − 1 − M d, i = 1, 2,··· , M  for bipolar MPAM  or Ai =  i − 1 d  for unipolar MPAM , and g t  is a real-valued pulse shaping function. The bandpass MPAM signal is a DSB-SC AM signal.  The MPASK signals have energies   cid:14    cid:14   Ei =  T  i  t dt = 1 s2  A2 i  2  0  T  g2 t dt = 1 2  0  A2 mEg,   7.42   1  2 Eg, i = 1, 2, . . . , M. For the rectanglular pulse g t  =  where Eg denotes the energy in the pulse g t . On a signal constellation diagram, si = Ai T , Eg = 2, we have si = Ai. The signal constellation {si} is one-dimensional, and the case of 4PAM is illustrated in Fig. 7.5.  2  For baseband MPAM, the cosine factor in  7.41  is dropped, that is, the transmitted   cid:21    cid:21   signal over one symbol period is given by  si t  = Aig t ,  0 ≤ t ≤ T.   7.43  On-off keying  OOK  is a unipolar MASK with M = 2. Like AM, ASK can be demodu- lated coherently or by using an envelope detector. For binary digital modulation, given the same probability of error, coherent FSK and coherent ASK requires the same power, which is 3 dB higher than that required for coherent PSK. Noncoherent detection techniques such as envelope detection lead to worse BEP performance than their respective coherent ver- sion. ASK has a high sensitivity to amplitude noise, and thus is less popular than PSK and FSK in wireless communications.  PSD  The PSD of MPAM contains two terms, the ﬁrst being a continuous term and the second a discrete term with spectral lines at uniform frequency intervals of 1 T. When the ampli- tudes are symmetrically distributed around zero, their mean mA is zero, resulting in the second term being zero, and the discrete spectral lines disappear. Thus, for bipolar MASK there are no spectral lines, while for unipolar MASK there are spectral lines.  The PSD for the symmetrical bipolar MPAM  not necessarily uniform spaced  is  given by   cid:23 ˜s  f   = σ 2  A  G  f  2 T  ,   7.44   where G  f   is the Fourier transform of g t . Note that  cid:23 ˜s  f   is the PSD of the complex envelope of the signal.      193   cid:2   7.4 Pulse amplitude modulation   cid:2    cid:3 2  ,   cid:23 ˜s  f   = σ 2 AT  sin πf T   πf T  When g t  is a rectangular pulse of unit amplitude, the PSD of the symmetrical bipolar  MASK is given by  which has the same shape as that of MPSK. σ 2 If mA  cid:18 = 0, as in unipolar MPAM, and g t  is a rectangular pulse, the PSD is given by  A is the variance of Ai.   cid:2    cid:3 2 + m2  δ  f  .  A   cid:23 ˜s  f   = σ 2 AT  sin πf T   πf T  There is a spectral line at dc. For the unipolar uniform MASK, mA =  M−1 A the corresponding passband PSD is given by  2  . For MASK,   cid:19  which has a spectral line at fc and −fc.   cid:23 s  f   = 1 2   cid:20    cid:23 ˜s   f − fc  +  cid:23 ˜s  −f − fc   ,   7.45    7.46    7.47   Error probability  A bipolar MASK can only be demodulated coherently, since the sign of the signal cannot be differentiated by noncoherent demodulation. A unipolar MASK can be demodulated either coherently or noncoherently. The optimum receiver is a matched ﬁlter followed by an amplitude detector. To differentiate the demodulated amplitudes, a threshold detector with M − 1 thresholds is used. For coherent detection of bipolar MASK signals, carrier recovery can be based on a squaring loop or Costas loop. Noncoherent detection uses an envelope detector, followed by a threshold detector.  The probability of symbol error for MPAM with equal amplitude spacings, when subject  to coherent detection, is given by [39]  Ps = 2 M − 1    cid:18 2 2N0 where  cid:18  is the amplitude spacing,  cid:18  = Ai − Ai−1 = 2d. Each symbol conveys log2 M bits. Assuming equally likely symbols, the average energy   7.48   M  Q  ⎛⎝   ⎞⎠ ,  is given by  M cid:26   i=1  A2 i .  Es = 1 M   7.49   From  7.48  and  7.49 , the probabilities of symbol error for MASK with symmetrical uniformly-spaced bipolar and unipolar amplitude distribution, when subject to coherent detection, are derived as      194   cid:2   Modulation and detection   cid:13    cid:12  cid:31   cid:12  cid:31   Ps = 2 M − 1  Ps = 2 M − 1   M  Q  Q  M   cid:13   6γs M2 − 1 3γs  2M2 − 3M + 1   coherent bipolar MASK ,   7.50    coherent unipolar MASK ,   7.51   ≈ γb log2 M. The bipolar case is has an SNR advantage over the unipolar  where γs = Es case, by 3 to 6 dB, with an asymptotic ratio of 6 dB. Thus, for coherent detection, bipolar MASK is preferred.  N0  Noncoherent demodulation of unipolar MASK introduces a small performance degrada- −5. For large M, this degradation is negligible.  cid:18  cid:23    cid:22   tion, which is less than 1 dB for a BEP of 10 The error rate is derived as [39] Ps = 1 M where  2 BM γs +  2M − 3 Q − 1 e  BMγs   cid:17  cid:25    noncoherent unipolar MASK ,   7.52   BM =  3  2M2 − 3M + 1  .   7.53   MASK has the same PSD as MPSK for the same symbol rate and pulse shape. This implies that they have the same bandwidth. The uniform bipolar MASK is inferior to MPSK in terms of error probability by 3.98 to 5.17 dB for M ≥ 4.  Example 7.4: The SEPs of the uniformly spaced MASK, for the cases of bipolar, coher- ent demodulation, given by  7.50 ; unipolar, coherent demodulation,  7.51 ; and unipolar, noncoherent demodulation  7.52 , are plotted in Fig. 7.6.  100  10−2  s  P  bipolar coherent unipolar coherent unipolar noncoherent  10−4  M = 2  4  8  16  32   cid:2 Figure 7.6  10−6  5  10  15  25  30  35  20  γb  dB   SEPs of uniformly spaced MASK.      195   cid:2   7.5 Phase shift keying  7.5 Phase shift keying  PSK is a modulation technique that conveys data by changing or modulating the phase of a reference signal called the carrier wave. The demodulator determines the phase of the received signal and maps it back to the symbol it represents. The receiver compares the phase of the received signal to a reference signal, hence this system is termed coherent. PSK has a constant envelope, and this relaxes the requirements on the transmitter power ampliﬁer. PSK is more bandwidth efﬁcient than FSK, and more power efﬁcient than ASK and FSK.  When the phase is differentially encoded, the demodulator then determines the changes in the phase of the received signal rather than the phase itself. This is differential phase- shift keying  DPSK . DPSK can be signiﬁcantly simpler to implement than PSK since the demodulator does not need a copy of the reference signal to determine the exact phase of the received signal, thus it is a non-coherent scheme. In return, it produces a higher BEP at demodulation. When the communication channel introduces an arbitrary phase shift, the demodulator is unable to discriminate the constellation points; in this case, the data is often differentially encoded prior to modulation. PSK and DPSK are illustrated in Fig. 7.7, by QPSK and DQPSK. Note that their phase or differential phase is Gray coded.  7.5.1 Binary phase shift keying  In BPSK, the carrier signal has a constant amplitude but its phase is switched between two values, which are separated by π, to represent 0 and 1, respectively. Typically, the two phases are 0 and π, and the signals are represented by  s1, s2 t  = ±A cos 2πfct,  kT ≤ t ≤  k + 1 T,   7.54   for 1 and 0, respectively. The signals are called antipodal, and they have a correlation coefﬁcient ρ12 = −1, leading to the minimum BEP for a given γb = Eb N0. BPSK is a binary antipodal ASK.  Demodulation of BPSK can be coherent. The coherent detector can be in the form of either a correlator or a matched ﬁlter. A reference signal must be used in the receiver, which  Q  QPSK  Q  DQPSK  00  I  01  11  10  01  00  11  I  10   cid:2 Figure 7.7  Signal constellation diagrams of QPSK and DQPSK.      196   cid:2   Modulation and detection  must be synchronous to the received signal in frequency and phase. A carrier recovery circuit can be used. At passband, a correlator is typically used, since a matched ﬁlter with h t  = cos 2πfc T − t  is difﬁcult to implement.  In an uncoded AWGN channel, for coherent demodulation, BPSK has the BEP as a function of γb  2γb   coherent BPSK .   7.55   BEP   cid:17  cid:25    cid:18   Pb = Q  PSD   cid:2    cid:3 2  The PSD of the baseband BPSK signal is given as   cid:23 ˜s  f   = A2T  sin πf T   7.56  The null bandwidth Bnull = 2Rb, B90% ≈ 1.7Rb, and B99% ≈ 20Rb, Rb being the data bit rate.   BPSK .  πf T  BPSK signals have a mainlobe at the carrier frequency and many sidelobes in the power spectrum. The use of raised cosine ﬁltering can increase the spectral roll-off, and thus the spectral efﬁciency. This also makes the signal to no longer have a constant envelope. The raised cosine ﬁltering method is applicable to QPSK.  Differential BPSK  Differentially encoded BPSK  DEBPSK  signals can be coherently demodulated or differ- entially demodulated. The PSD of the DEBPSK signal is the same as that of BPSK. The modulator and demodulator structures for various BPSK and DEBPSK schemes are given in [39].  For DEBPSK signals that use differential demodulation, the scheme is called differential BPSK  DBPSK . DBPSK does not use any coherent reference signal for demodulation, but uses the previous symbol as the reference for demodulating the current symbol. This leads to a suboptimum receiver.  When DBPSK uses differential coherent demodulation, which requires a reference sig- nal but does not require phase synchronization, we get the optimum DBPSK. The BEP of the optimum DBPSK is given by [39] Pb = 1 −γb e 2   optimum DBPSK .   7.57   The suboptimum receiver is used in practice as the DBPSK receiver. The performance of the suboptimum receiver is given in [25]. Its error performance is slightly inferior to that of the optimum case, with a loss smaller than 2 dB. When an ideal narrow-band IF ﬁlter      197   cid:2   7.5 Phase shift keying  with a bandwidth of W = 0.57 T is placed before the correlator, the best performance is achieved with a loss of 1 dB [25, 39]  Pb = 1 2  −0.8γb e   suboptimum DBPSK .   7.58   The DEBPSK signal can also be demodulated coherently, and this scheme is known as DEBPSK. It is the same as coherent BPSK, but uses differential encoding to eliminate phase ambiguity in the carrier recovery circuit for coherent PSK. The corresponding BEP is given as [39]   cid:18  cid:22    cid:17  cid:25    cid:18  cid:23   1 − Q  2γb  2γb   DEBPSK .   7.59    cid:17  cid:25   cid:8   2γb   cid:7 √ Pb = 2Q  , which is two times the BEP of coherent BPSK without  For large SNR, Pb ≈ 2Q differential encoding.  Example 7.5: The BEPs of the coherent BPSK, coherent DEBPSK, optimum DPSK and suboptimum DBPSK schemes are plotted in Fig. 7.8.  7.5.2 M-ary phase shift keying  The reason for using MPSK is to increase the bandwidth efﬁciency of PSK. For MPSK, the modulated signal is deﬁned as  si t  = Ag t  cos  2πfct + φi  , i g t  cos 2πfct + sQ  = A cos φig t  cos 2πfct + A sin φig t  sin 2πfct = sI  0 ≤ t ≤ T,  i g t  sin 2πfct,  i = 0, 1,··· , M − 1   7.60   Optipum DBPSK  Suboptimum DBPSK  100  10−2  10−4  10−6  0  b P  Coherent BPSK  Coherent DEBPSK   cid:2 Figure 7.8  2  4  8  10  12  6  γ  dB   BEPs of BPSK and differential BPSKs.      198   cid:2   Modulation and detection   cid:21  M , A = √  where φi = 2πi given by g t  = conditions  Es, sI i  = A cos φi, sQ  = A sin φi, and g t  is a pulse shaping function T , 0 ≤ t ≤ T, or by another function, which satisﬁes the orthonormal  2  i   cid:14   cid:14   0  0  T  T  g2 t  cos2  2πfct  dt = 1, g2 t  cos  2πfct  sin  2πfct  dt = 0.  The carrier frequency fc is selected as an integer multiple of the symbol rate, thus the signal initial phase in any symbol interval is one of the M phases, φi.  On the signal constellation diagram, the minimum distance between two constellation  points is given by   cid:17  π   cid:18   .  M  dmin = 2A sin  The constellations of Gray coded QPSK and 8PSK are shown in Fig. 7.9. For MPSK, there are M points uniformly distributed on a unit circle, each point representing a possible value of the symbol. The symbol uses Gray code such that adjacent signal points differ by only one bit. Using Gray coding, a symbol error is most likely to cause a single bit error. The Gray encoder, as baseband signal generator, outputs cos φ and sin φ, where φ is the phase of the signal. When M ≥ 4, the MPSK signals are two-dimensional and can be written as  si t  = s I  i cos 2πfct − sQ  i sin 2πfct.   7.64   The quadrature modulator can be implemented as shown in Fig. 7.10.   7.61    7.62    7.63   Q  01  s1  Q s0  00  s2  s0  I s0 s3  11  10  I  011  s3  001  s  4  010 s2  Q  s1  110  s5 000  s6  100  s0  s7  111  I  101  MPSK constellations.  a  QPSK.  b  8PSK.  T = nTb   cid:2 Figure 7.9  bitstream  S P  converter  Baseband  signal  generator  sI  sQ  fc  90   Σ  MPSK signal   cid:2 Figure 7.10  MPSK modulator.      199   cid:2   7.5 Phase shift keying  r  t   CR  cos2πfct  90   −sin2πfct  I tan−1              k  Q k r  r  θk  Find smallest θi  θ  − θ  k  i   k+1  kT  T dt  T +1  dt  k  kT  I rk  Q rk   cid:2 Figure 7.11  Coherent MPSK demodulator. CR denotes coherent reference.  Coherent MPSK demodulation uses two correlators, and a carrier recovery circuit is  used to get the reference signal. At the receiver, the received signal is  r t  = s t  + n t ,   7.65   where n t  is the AWGN channel noise. The structure of coherent MPSK demodulator is shown in Fig. 7.11.  For coherent demodulation, the SEP is the probability of ˆφi being outside its decision  region, which is an angle of 2π M. The formulas cannot be given in a closed form for M > 4, and numerical integration has to be used for obtaining the SEP. The result in integration form is given in [39].  For large SNR, the SEP can be approximated by  SEP   cid:18    cid:17  cid:25   Ps ≈ 2Q  2γs sin  π M   coherent MPSK .   7.66   This corresponds to the nearest-neighbor approximation to Ps. For MPSK, each constella- tion point has two nearest neighbors at distance dmin.  Example 7.6: The SEP of MPSK, given by  7.66 , is plotted in Fig. 7.12 for M = 2, 4, 8, 16, and 32.  Gray coding is usually used for signal assignment in MPSK. For two adjacent signals in the constellation, the n-tuple symbols have only one differing bit. For Gray-encoded MPSK, the BEP under the Gaussian condition is approximately  Pb ≈ Ps n  = Ps log2 M   7.67  −3. For low SNR, a more accurate BEP expression for Gray-coded for M > 2 and Ps < 10 coherent MPSK is given in [19]. Since the exact BEP expression for M = 2 and 4 are available, here we give its form for M ≥ 8      200   cid:2   Modulation and detection  100  10−2  s  P  10−4  M = 2  4  8  16  32   cid:2 Figure 7.12  10−6  0  5  20  25  10  15  γb  dB   SEP of MPSK.   cid:12    M 4 cid:26   i=1  Q   cid:13   .  Pb ≈ 2  log2 M  2Eb log2 M  sin  N0   2i − 1 π  M   7.68   The approximation given by  7.66  and  7.67  corresponds to a lower bound, while  7.68  is an upper bound. The expression using the ﬁrst two terms in  7.68  gives the best approximation of MPSK for M ≥ 8.  PSD   cid:2    cid:3 2  It is well-known that the PSD of a bandpass signal is just the shift version of the PSD of the baseband signal or complex envelope. The PSD of the complex envelope of the MPSK signal is derived as [39]   cid:23 ˜s  f   = A2nTb  sin πfnTb  πfnTb   MPSK ,   7.69   where n = log2 M and the bit duration Tb = T n. For unit bit energy Eb = 1, we have A = √ 2 and Tb = 1. The PSD of MPSK is the same as that of BPSK in terms of symbol  rate, but in terms of bit rate it is n times narrower than that of BPSK.  Since the minimum passband required for transmission of the symbols is 1 T, the max-  imum bandwidth efﬁciency is Rb T = log2 M. Hence, the bandwidth efﬁciency increases  with M.  Example 7.7: The PSD of MPSK is plotted in Fig. 7.13 for M = 2, 4, 8, 16, and 32. The null bandwidth Bnull = 2Rs n, B90% ≈ 1.7Rs n, B99% ≈ 20Rs n. MPSK signals have a mainlobe at the carrier frequency and many sidelobes in the power spectrum. The use of raised cosine ﬁltering can increase the spectral rolloff, and thus the spectral efﬁciency. This also makes the envelope of the signal no longer constant.      201   cid:2   7.5 Phase shift keying  32  4816  M = 2  10  0     B d         f      Φ       −20   cid:2 Figure 7.13  −40  0  0.5  1.5  2  1 Tb f  PSD of MPSK.  Differential MPSK  Differential MPSK  DMPSK  is referred to as differentially encoded and differentially coherently demodulated MPSK. The differentially coherent demodulation is a noncoher- ent scheme, since phase coherent reference signals are not needed. This scheme is used in case of random phase in the received signal. Like DEBPSK, when the differentially encoded MPSK signal is coherently demodulated, we get differentially encoded MPSK  DEMPSK , which is used to eliminate phase ambiguity in the carrier recovery process. The modulator uses the MPSK modulator, preceded by two differential encoders, one on each channel, before the carrier multiplier. The DMPSK and DEMPSK demodulators are given in [39]. The DEMPSK demodulator is in fact the coherent MPSK, followed by a differential decoder. The PSD for differentially encoded MPSK signals is the same as that of MPSK for an equally likely original bitstream. The SEP for DMPSK is in an integral form [39]   7.70  For M = 2, it reduces to  7.57 . For other M values, it has to be numerically evaluated. For large SNR, it can be approximated by  −π 2  dx.  Ps = sin π M 2π  cid:2  cid:25   M cos x  M cos x  −γs 1−cos π e 1 − cos π  cid:3    cid:14  π 2   optimum DMPSK .   7.71   Ps ≈ 2Q  2γs sin  π√ 2M  This result is asymptotically 3 dB inferior in SNR to the SEP of the MPSK, which is given by  7.66  for M ≥ 4. The SEP for DEMPSK is also given in integral form [39]. For M = 2, it reduces to  7.59 . For M = 4, it reduces to [39] Ps = 4Q   cid:8  cid:20 2 + 8   cid:8  cid:20 3 − 4   cid:8  − 8   DEQPSK .   cid:8  cid:20 4   cid:7 √   cid:7 √   cid:7 √   cid:7 √   7.72    cid:19    cid:19    cid:19   γs  γs  γs  γs  Q  Q  Q      202   cid:2   Modulation and detection  The last three terms can be ignored for large SNR, and the SEP is about twice that of coherent QPSK. In fact, for large SNR  Ps ≈ 2PMPSK  s   DEMPSK ,   7.73   where PMPSK  s  is the SEP for MPSK. This corresponds to 0.5 dB or less degradation in SNR.  Applications  MPSK has a maximum spectral efﬁciency of log2 M bits s Hz. The popular MPSK schemes uses M = 2, 4, and 8. 8PSK is usually the highest-order PSK constellation deployed. For more than 8 phases, the BEP becomes too high, and in this case, better, though more complex, QAM modulation can be used. 8PSK is used by EDGE. Since 8PSK has a BEP performance close to  0.5 dB better than  that of 16QAM but its data rate is only 3 4 that of 16QAM, 16QAM is more frequently used than 8PSK. 8PSK is used in DVB-S S2 T.  MPSK and its variants are widely used in various wireless communication standards. For example, QPSK and its variants are used in IS-95, CDMA2000, WCDMA, TD-SCDMA, WiMedia, satellite communication systems, and DBS. In IEEE 802.11b, DBPSK, DQPSK, and QPSK are used, depending on the data rate required. Likewise, in IEEE 802.11g, BPSK, QPSK, 16QAM, and 64QAM are used. Bluetooth uses π 4-DQPSK and 8DPSK in its version 2, and uses GMSK in version 1. ZigBee uses DBPSK at 868 915 MHz, but uses OQPSK and 16QAM at 2.4 GHz. 8PSK is used in EDGE, UWC-136, TD-SCDMA. In EDGE, 8PSK is used in a way analogous to π 4-DQPSK, by inserting a π 8 phase rotation at each symbol transmission to eliminate zero crossings. 3GPP LTE uses QPSK, 16QAM and 64QAM. In 802.16 standards family, QPSK and 16QAM are mandatory, and 64QAM is optional. DQPSK is used in DAB.  High-order modulations like MPSK and MQAM require more power for a given error performance. MQAM also has a strict requirement on the power ampliﬁer, thus it is typically not used in MSs.  7.5.3 Quaternary phase shift keying  QPSK is an MPSK scheme with M = 4, and it is the most popular MPSK scheme. QPSK increases the bandwidth efﬁciency by a factor of two when compared to BPSK, while hav- ing the same BEP performance. Other MPSK schemes increase the bandwidth efﬁciency, but yield BEP degradation. QPSK modulation is used in CDMA-based systems, IS-54 136, UWC-136, PWT, PDC, PHS, DVB-S S2 T, LMDS, and satellite systems.  The QPSK signal can be deﬁned by Ikg t  cos 2πfct − A√ 2  s t  = A√ 2   7.74  where Ik = ±1 and Qk = ±1 corresponds to the odd- and even-numbered bits, with mapping 1 → +1 and 0 → −1.  Qkg t  sin 2πfct,  kT ≤ t ≤  k + 1 T,      203   cid:2    cid:2 Figure 7.14  r  t     CR  cos2π t f c  90   −sin2  π  fc  t  P S  bitstream  7.5 Phase shift keying  I r k  1   k+1 T dt kT  0  0  Qr k  1   k+1 T dt kT  QPSK demodulation.  For QPSK, the bitstream is ﬁrst reshufﬂed into the symbol stream, each symbol having two bits. The symbol rate is only half the bit rate. Each symbol can have one of four values, which are modulated to one of the four positions in the constellation diagram.  The modulator and demodulator for MPSK are applicable to QPSK. Due to the special property of the QPSK constellation, a simple demodulator can be used. Coherent detection requires a pilot-signal-assisted fading compensation for demodulation. The QPSK correla- tion receiver is illustrated in Fig. 7.14. The I- and Q-channel signals can be demodulated separately as two individual BPSK signals. A parallel-to-serial  P S  converter is used to combine the two sequences into one. The received symbol is decided by the QPSK decision table.  The QPSK signal can be treated as two independent BPSK signals along the in-phase and quadature directions. For the AWGN channel, from Fig. 7.14, the two channels are independent and the average BEP for each channel is the same. The exact BEP is derived from the detection theory as   cid:17  cid:25    cid:18   Pb = Q  2γb   coherent QPSK .   7.75   It is the same as that of BPSK, given by  7.55  and  7.139 , under both the AWGN and ﬂat Rayleigh conditions.  A symbol represents two bits from the I- and Q-channels. The SEP is given as  Ps = 1 − Pr  both bits are correct    cid:7 √  = 1 −  1 − Pb 2 = 2Q Q   cid:8  − cid:19    cid:7 √   cid:8  cid:20 2 .  γs   7.76  By using γs = 2γb and Pb ≈ Ps 2 for Gray encoding, and the union bound and the nearest- √ neighbor approximation, an approximate formula for Pb is also derived, Pb ≈ Q  2γb , which is coincidently the same as the exact form  7.75 . Thus, QPSK achieves twice the data rate as BPSK, with the same bandwidth and BEP performance.  γs  Like all DEMPSK schemes, differentially encoded QPSK  DEQPSK  has a BEP that is twice as large as that for coherent QPSK under both the AWGN and ﬂat Rayleigh fading conditions. For the AWGN channel Pb = 2PQPSK   cid:17  cid:25    DEQPSK ,  = 2Q   7.77    cid:18   2γb  b      204   cid:2   Modulation and detection  because a symbol error leads to errors of two consecutive phase transitions. In DEQPSK, information dibits are represented by the phase difference  cid:18 φi from symbol to symbol. A possible phase assignment is given by 00 → 0, 01 → π 2, 10 → −π 2, and 11 → π. For DQPSK, the BEP can be derived from  7.71  as   cid:2  cid:25    cid:3   Pb ≈ Q  4γb sin  π  √  4  2   optimum DQPSK ,   7.78   which is 2 to 3 dB inferior to coherent QPSK. Like DBPSK, a suboptimum demodulator using the previous symbol as reference is available, and the BEP is given as [39]  Pb ≈ e  −0.59γb   suboptimum DQPSK .   7.79   At high SNR it is inferior to the optimum DQPSK by less than 1 dB. DQPSK is used in IEEE 802.11 and 802.11b.  QPSK is nominally a constant envelope format, but it has deep amplitude dips at bit tran- ◦ phase shift between symbols, which causes the trajectories sitions. This is due to the 180 in the I-Q diagram to pass through the origin for these transitions. A number of variants of QPSK are described below.  Quadrature quadrature PSK  Q2PSK  [30] has a nonconstant envelope. It uses four basis signals, as opposed to two for QPSK. Q2PSK has the same BEP as QPSK and MSK in an AWGN channel, but with a doubled bandwidth efﬁciency. The structure of the demodulator is very similar to that of MSK. A constant-envelope version of Q2PSK can be obtained by a simple coding scheme that adds a fourth bit for every three information bits, leading to a code rate of 3 4. There is still an increase of 50% in bandwidth efﬁciency over MSK.  Offset QPSK  OQPSK delays the Q-channel signal  even bitstream  by half a symbol period, prior to carrier multiplication. s t  = A√ 2  I t g t  cos 2πfct − A√ 2  sin 2πfct, −∞ < t < ∞,  7.80   t − T 2  t − T 2  Q  g   cid:3    cid:2    cid:2    cid:3   The OQPSK signal has a symbol period of T 2. At the symbol boundary, only one of the two bits in an  Ik, Qk  pair may change sign, but not both. Thus, it avoids 180 phase transitions by doubling the phase switching rate. Phase changes can only be 0 and ±90 ◦ . This leads to less out-of-band interference due to band-limiting and ampliﬁer nonlinearity, as compared to QPSK. Also, the reduced amplitude variation allows the use of a more power-efﬁcient, less linear RF power ampliﬁer. The PSD and BEP of OQPSK are the same as those of QPSK.  ◦  Consequently, if a bandpass ﬁlter is used to control spillover  as used in satellite trans- mitters , a much smaller envelope variation  due to the FM-to-AM conversion effect  is achieved. IS-95 uses QPSK for the forward link and OQPSK for the reverse link. OQPSK is also used for satellite communications.      205   cid:2   7.5 Phase shift keying  π 4−  QPSK  Q  01  11  10  I  11  01  00  00  10  Q  π 4−DQPSK  01  10  I  00  11   cid:2 Figure 7.15  Constellations of π 4-QPSK and π 4-DQPSK.  π 4-QPSK  The π 4-QPSK modulation alternatively selects the modulated signal points from two QPSK constellations that have a phase difference of π 4, as shown in Fig. 7.15, where the dotted constellations are used for t = 2mT, m = 0, 1,··· , and the circled con- stellations for t =  2m + 1 T. This method leads to a phase transition for every symbol, and thus enables a receiver to perform timing recovery and synchronization. The phase changes  cid:18 φk are conﬁned to odd multiples of π 4, and information is carried by  cid:18 φk.  Since information is carried by  cid:18 φk, π 4-QPSK is a form of differentially encoded QPSK, but differs from the DEQPSK in the differential coding rules. It can be differen- tially demodulated. Differential coherent demodulation can reduce the adverse effect of the fading channel. π 4-QPSK can also be demodulated by coherent demodulation and FM- discriminator detection. Coherent demodulation provides a BEP performance of 2 to 3 dB better than the other schemes do [18, 39]. The coherent detector can be the same as that for QPSK, but it is followed by differential decoding. The coherently demodulated π 4-QPSK has the same BEP as that of DEQPSK   cid:17  cid:25    cid:18   Pb ≈ Q  2γb   coherent π 4-QPSK ,   7.81   and noncoherently demodulated π 4-QPSK has the same BEP as that of DQPSK.  The 3π 8-8PSK modulation scheme used in EDGE exploits an idea similar to that in π 4-QPSK. It has a 16-point constellation, which is formed from two 8-point mappings, offset by a phase of 3π 8radians. This avoids symbol-to-symbol transitions through the origin, and thus lowers the PAPR compared to the normal 8PSK.  π 4-DQPSK  The π 4-DQPSK modulation combines differential encoding with π 4-QPSK. The con- stellation of π 4-DQPSK modulation is also shown in Fig. 7.15. For each symbol, the modulated signal has a phase shift which is that of the previous symbol plus a nonzero phase shift. The nonzero phase shift has four states, corresponding to the four possi- ble values of a symbol. The transitions between subsequent signal constellations never      206   cid:2   Modulation and detection  pass through the origin, leading to much smaller ﬂuctuations of the envelope than that of QPSK.  π 4-DQPSK can be differentially demodulated. For π 4-DQPSK with Gray coding, the  BEP is quite complicated [29, 35]  where I0 is the zero-order modiﬁed Bessel function of the ﬁrst kind, which is given by  3.44 ,  Pb = Q a, b  − 1 2  cid:3   cid:2       cid:7    cid:8   ,  − 1  2  a2+b2  I0 ab e      cid:2   a =  2γb  1 − 1√ 2  ,  b =  2γb  1 + 1√ 2   cid:3   ,   7.82    7.83   and Q a, b  is the Marcum Q function, deﬁned by  3.66 .  With coherent demodulation, π 4-DQPSK has the same BEP performance as DQPSK. It produces better results than OQPSK in the presence of multipath fading. π 4-DQPSK modulation, like QPSK, is used in CDMA-based systems, IS-54 136, UWC-136, PWT, PDC, PHS, LMDS, and satellite systems.  Example 7.8: The modulated signals of the BPSK, QPSK, OQPSK, and 8PSK modula- tion schemes are plotted in Fig. 7.16. Here, A = 1 and fc = 2.  Example 7.9: The BEPs of all the popular PSK schemes discussed above are plotted in Fig. 7.17.    t   b  1 0.5 0  K S P B  K S P Q  K S P Q O  K S P 8  1 0 −1  1 0 −1  1 0 −1  1 0 −1  0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4  4  5  5  5  5  5  6  6  6  6  6 t Tb  7  7  7  7  7  8  8  8  8  8  9  9  9  9  9  10  11  12  10  11  12  10  11  12  10  11  12  10  11  12  Modulated BPSK, QPSK, OQPSK, and 8PSK signals.   cid:2 Figure 7.16      207   cid:2   7.6 Frequency shift keying  100  10−2  10−4  10−6  0  suboptimum DQPSK  suboptimum DBPSK    optimum DQPSK,        π 4−DQPSK  coherent 8PSK  optimum DBPSK  s  P  coherent DEBPSK  DEQPSK, π 4−DEQPSK  coherent BPSK, QPSK, OQPSK  6  γ  b  dB   2  4  8  10  12  14   cid:2 Figure 7.17  BEPs of some popular PSK schemes.  7.6 Frequency shift keying  FSK is another constant-envelope modulation technique. FSK modulates the digital sig- nal using predetermined output frequency. FSK is appropriate for channels that lack phase stability, while phase estimation is necessary for coherent detection used in linear modulation methods such as PAM, PSK, and QAM. Since the frequency modulation tech- nique is nonlinear, it tends to occupy a higher bandwidth than the amplitude and phase modulations do.  7.6.1 Binary frequency shift keying  For BFSK, the instantaneous frequency is usually shifted between two discrete values, f1 = fc −  cid:18 f and f2 = fc +  cid:18 f . A positive frequency deviation from the operating fre- quency is represented by 1, and a negative frequency deviation is represented by 0. That is, the modulated waveform is cos 2πf1t for 0 and cos 2πf2t for 1. The BFSK signal is represented by  s1 t  = Ag t  cos  2πf1t + φ1  , s2 t  = Ag t  cos  2πf2t + φ2  ,  kT ≤ t <  k + 1 T, kT ≤ t <  k + 1 T,  where the rectangular window g t  = √ Eb = A2T 2. In order to implement coherent FSK that uses coherent detection, it is required that φ1 = φ2 at t = 0 and that f1 and f2 are suitably selected so as to make s1 t  and s2 t  orthogonal   7.85  2 T is deﬁned in kT ≤ t <  k + 1 T, and   7.84       208   cid:2   This corresponds to [39]  4T where n and m are integers. Thus we have  Modulation and detection   k+1 T  s1 t s2 t dt = 0.   cid:14   kT  f1 = n − m  ,  f2 = n + m  ,  4T  f2 − f1 = 2 cid:18 f = m 2T  ,  fc = n 2T  .   7.86    7.87    7.88   That is, the nominal carrier frequency fc must be an integer multiple of 1 2T for orthogonality. A coherent FSK signal may have discontinuous phase at bit boundaries. For φ1 = φ2, when f2 − f1 = k T , the phase continuity is maintained at bit transi- tions. For k = 1, the FSK is called Sunde’s FSK. MSK is a particular form of FSK that has the minimum separation for orthogonality, namely 1 2T, as well as continuous phase.  Example 7.10: The modulated signals of Sunde’s FSK and coherent FSK with discontin- uous phase are plotted in Fig. 7.18. For Sunde’s FSK, bit 1 corresponds to f2 = 2 T, while bit 0 corresponds to f1 = 1 T. For coherent FSK with discontinuous phase, f2 = 6 4T, f1 = 3 4T.  PSD  Unlike QPSK, which has a continuous power spectrum with main lobe at fc and many side- lobes around it, the power spectrum of FSK, in addition to the continuous power spectrum, has also spectral lines added at some frequencies.  0  1  2  3  4  5  6  7  8  9  10  1  2  3  4  5  6  7  8  9  10    t   b  1 0.5 0      t   s   , e d n u S    t   s   , t n e r e h o C  1  0  1  0  −1  0  −1  0   cid:2 Figure 7.18  FSK signals: Sunde’s FSK and coherent FSK with discontinuous phase.  1  2  3  4  6  7  8  9  10  5 t      209   cid:2   7.6 Frequency shift keying  0     B d       f    Φ  −20  −40   cid:2 Figure 7.19  −60  0  2  4  6  T f  PSD of Sunde’s FSK.  The PSD of a passband signal can be derived from the baseband signal based on  7.47 . For Sunde’s FSK, the I- and Q-channel are independent of each other, and thus the PSD of the complex envelope is the PSDs of the two components  cid:23 ˜s  f   =  cid:23 I  f   +  cid:23 Q  f  .  cid:12   cid:3  The complete baseband PSD of the BFSK is given as [39] + T   cid:20  cid:13 2   cid:3  cid:6    7.89   + δ   cid:2    cid:2    7.90    cid:5    cid:19   δ  ,   cid:23 ˜s  f   = A2 4  f − 1 2T  2A cos πTf   1 −  2Tf  2 π  f + 1 2T  where A = √  2 for a unity signal energy in one side.  Example 7.11: The one-sided PSD is illustrated in Fig. 7.19. A spectrum line occurs at fT = 0.5. For passband spectrum, the spectrum lines occur at f = fc ± 1 2T , which are the two frequencies of the BFSK. From the ﬁgure, the null bandwidth is Bnull = 1.5Rb, thus the null-to-null bandwidth at fc is 3Rb. The two-sided bandwidths at fc are B90% ≈ 1.23Rb and B99% ≈ 2.12Rb. The transmission bandwidth is usually set as B = 2Rb.  A coherent FSK signal can be coherently or noncoherently detected. For coherent demod- ulation, two LOs that operate at f1 and f2 are required. For Sunde’s FSK, the BEP performance for any two equally likely binary signals can be derived from  7.28 , where ρ12 = 0  orthogonal  and Es = Eb. The BEP for coherent detection is given by   7.91   BEP  Pb = Q   √ γb .  The result is 3 dB inferior to that of coherent BPSK.      210   cid:2   Modulation and detection  A noncoherent FSK signal can only be demodulated by noncoherent demodulation. Information of an FSK signal is conveyed at zero-crossing points during each bit period, and a limiter is used for demodulation. The output of a limiter contains only two states, zero and one. Noncoherent demodulation can be implemented with the correlator-squarer structure. For each fi, i = 1, 2, the I and Q signals at the correlator output are squared and summed, and the maximum sum corresponds to the detected frequency. Noncoherent demodulation using envelope detection is more common, since the LOs are not needed and it requires only about 1 dB more power than coherent FSK demodulation under the Gaussian condition for Pb ≤ 10 −4. For this reason, practical FSK systems never use coherent demodulation. The method uses two bandpass ﬁlters to convert the FSK sig- nal into two ASK signals, which are then demodulated with an envelope or rectiﬁer detector.  For orthogonal, equiprobable, equal-energy, noncoherent BFSK signals, the BEP is  given by [31, 39]  Pb = 1 2  − γb 2 . e   7.92   For orthogonality between noncoherent FSK signals, the minimum frequency separation is 1 T, in contrast to 1 2T for coherent FSK [39]. Thus, more bandwidth is required for noncoherent FSK at the same symbol rate.  Example 7.12: The BEPs for coherently and noncoherently demodulated FSK are plotted in Fig. 7.20. Noncoherent demodulation typically requires 1 dB more power than coherent modulation.  100  10−2  10−4  b P  Nocoherent BFSK  Coherent BFSK   cid:2 Figure 7.20  10−6  0  2  4  6 8 γ b  dB   10  12  14  BEPs of FSK using coherent and noncoherent demodulation.      211   cid:2   7.6 Frequency shift keying  7.6.2 M-ary frequency shift keying  For M-ary FSK  MFSK  modulation, M different frequencies, usually equally spaced, are used. The modulated MFSK signal is deﬁned by   cid:20  for i = 1, 2, . . . , M, where αi = 2i − 1 − M and g t  = √  2π   fc + αi cid:18 fc  t + φi  si t  = Ag t  cos   cid:19   ,  kT ≤ t <  k + 1 T 2 T.   7.93   When all φi’s are the same, the signal is coherent and the demodulation can be coher- ent or noncoherent. Otherwise, the signal is noncoherent and demodulation must be noncoherent. Like BFSK, for orthongonality of the signals, the frequency separations between any two of them must be m 2T for the coherent case and m T for the noncoherent case, m ≥ 1. Typically, a uniform frequency separation between adjacent frequencies is used for MFSK. The PSD of MFSK is very complex, and is plotted in [1, 39]. GFSK and 4-level GFSK, which are obtained by preﬁltering the BFSK and 4FSK signals by a lowpass Gaussian ﬁlter, are used in the baseline IEEE 802.11 standard. GFSK are also used in DECT, CT2, Bluetooth, and paging. FSK is used in AMPS as well as most 1G mobile systems.  A simple way to generate MFSK signals is to use M oscillators operating at the M fre- quencies, and switch between them at each symbol period. This usually leads to phase discontinuity at the switching times due to the phase offsets between oscillators. This dis- continuity in phase leads to a broadening of spectrum. To eliminate the phase discontinuity, the continuous phase FSK  CPFSK  modulation technique is usually used.  SEP  The principles for demodulation of BFSK are applicable to MFSK. The modulators and demodulators for BFSK can be easily extended to MFSK, and their structures are given in [39]. The coherent MFSK demodulator can use the general form of detector for M- ary equiprobable, equal-energy signals with known phases. It consists of a bank of M correlators or matched ﬁlters. The orthogonal MFSK waveforms have a constellation of M M-dimensional orthogonal vectors si, i = 1,··· , M, whose ith element is Es and all other elements are zero. The basis function for si is  √  2 T cos 2π   fc +  i − 1  cid:18 f   t.   7.94   ψi = cid:25   For coherent detection, the SEP derivation for MFSK is more complex for M > 2. The SEP can be estimated by  7.30 . If the signal set is equal-energy and orthogonal, the  distances between any two signals are the same, d = √  cid:8   cid:7 √ .  7.95  For M = 2, it is an exact representation, while for Ps ≤ 10 −3 it is a good approximation. For MFSK, noncoherent receivers are easier and cheaper to implement than coherent receivers. The square-law detector is a noncoherent detector for M-ary orthogonal signals. It takes the correlator-squarer or matched-ﬁlter-squarer form. The matched-ﬁlter envelope  Ps ≤  M − 1 Q  2Es, thus we have  γs      212   cid:2   Modulation and detection  detector is also used. The conventional frequency discriminator is even simpler for MFSK demodulation. For matched-ﬁlter envelope-demodulated orthogonal MFSK, the SEP is given by [33, 39]  Ps = M−1 cid:26   m=1   cid:2    cid:3    −1 m+1  M − 1 M  −mγs m+1 ,  e  1 m + 1  is the binomial coefﬁcient. For BFSK  M = 2 , the expression reduces  where to  7.92 . The ﬁrst term in the summation provides an upper bound as  M−1 M   cid:7    cid:8   For equal-energy, equiprobable, and orthogonal MFSK, the probability of bit error is  Ps ≤ M − 1  2  −γs 2.  e  Pb =  M  2 M − 1   Ps.  derived as [35, 39]  For large M, Pb ≈ 1  2 Ps.   7.96    7.97    7.98   Example 7.13: The SEPs for noncoherent demodulation are plotted in Fig. 7.21. From the ﬁgure, it is seen that for given BEP an increase in M leads to a reduction in the bit SNR. This is different from the cases of MPSK and MQAM. Because all the M signals are orthogonal, the power efﬁciency increases, but the bandwidth efﬁciency decreases, as M increases. The orthogonal property of MFSK motivates the OFDM scheme as a means of providing power-efﬁcient modulation.  100  10−2  10−4  s P  M = 2  4  8  16  32  64  10−6  0  2  4  6 γ  8 b  dB   10  12  14   cid:2 Figure 7.21  SEP of MFSK using noncoherent demodulation. The dotted lines correspond to upper bound.      213   cid:2   7.6 Frequency shift keying  1  0   cid:2 Figure 7.22  State diagram of MSK modulation.  7.6.3 Minimum shift keying  MSK or minimum frequency-shift keying can be viewed as OQPSK plus half-sinusoidal pulse shaping. MSK encodes each bit as a half sinusoid. The MSK signal can be deﬁned as sin 2πfct, −∞ < t ≤ ∞,  7.99   cos 2πfct + AQ t  sin  s t  = AI t + T  cos  2T  2T   cid:17  πt   cid:18    cid:17  πt   cid:18   where T, as in OQPSK, is the bit period, as composed to the symbol period for QPSK. The symbol duration for MSK and OQPSK is a one-bit period, while that for QPSK is a two-bit period. The state diagram of MSK is the same as that of OQPSK, and is shown in Fig. 7.22. The MSK signal is shown to be a special FSK signal with two frequencies f−, f+ = fc ± 1 4T [39]. The frequency separation is  cid:18 f = 1 2T , which is the minimum separation for two FSK signals to be orthogonal; hence the name minimum shift keying. MSK carrier phase is continuous at bit transitions. MSK is a particularly spectrally efﬁcient form of coherent CPFSK. It is a CPFSK scheme with a modulation index h = 0.5. When the MSK signal is realized in this manner, it is called fast frequency shift keying  FFSK .  MSK can also be implemented in a serial fashion. In this case, the precise synchroniza- tion and balancing for the Q-channel is no longer needed, and this is especially suitable for high bit rates. Many MSK-type schemes have been proposed to improve the bandwidth efﬁciency of MSK. They can be continuous phase modulation with constant envelope, or based on pulse shaping in the Q-channel such as the sinusoidal FSK and many other symbol-shaping pulses. These are given in detail in [39]. These shaping schemes can gen- erally have better spectral sidelobe roll-offs, but have a wider main lobe than the MSK spectrum and that of conventional PSK.  MSK has the advantage of not introducing any ISI. As a binary modulation scheme, the spectral efﬁciency of MSK is still very low. MSK is used in NASA’s Advanced Communication Technology Satellite  ACTS  system.  Example 7.14: The modulated signal of MSK modulation is plotted in Fig. 7.23. Here, A = 1 and fc = 2.      214   cid:2   Modulation and detection  1  2  3  4  5  6  7  8  9  10 11 12   cid:2 Figure 7.23  1  2  3  4  5  7  8  9  10 11 12  6 t Tb  Modulated MSK signal.  MSK  BPSK  0  0  1  1  0    t   b  K S M  −1  0  0  −20  −40  −60  −80  0  QPSK  OQPSK     B d       f    Φ   cid:2 Figure 7.24  PSDs of MSK, BPSK, QPSK, and OQPSK.  0.5  1  2  2.5  3  1.5 Tb f  PSD  The PSD for MSK is given as [39]   cid:23 ˜s  f   =  cid:23 I  f   +  cid:23 Q  f   = 16A2T  π 2  cos 2πTf   1 −  4Tf  2   7.100    cid:5    cid:6 2  .  Example 7.15: The PSDs of MSK, QPSK or OQPSK, and BPSK are plotted in Fig. 7.24. For MSK, the null bandwidth Bnull is 0.75Rb, as compared to 1.0Rb for BPSK and 0.5Rb for QPSK or OQPSK. The bandwidths containing 90% of the power, B90%, are 0.76Rb for MSK, 0.8Rb for QPSK or OQPSK, and 1.7Rb for BPSK, respectively. For MSK, B99% ≈ 1.2Rb, while the corresponding values are 10Rb for QPSK or OQPSK, and 20Rb for BPSK.      215   cid:2   7.6 Frequency shift keying  Unlike FSK, which has spectral lines at certain frequencies, MSK does not have. The power spectrum decreases faster than that of OQPSK, QPSK, and FSK, leading to less out- of-band energy. Thus, MSK provides an advantage over other schemes in case of a more stringent in-band power speciﬁcation.  Since MSK can be viewed as a form of OQPSK, it has the same BEP as OQPSK, QPSK and BPSK for coherent detection. This is only valid for the inﬁnite bandwidth case. How- ever, from the PSDs, the BEP performance of QPSK or OQPSK would be better than that of MSK, when the system bandwidth is below 0.75Rb, since the in-band power for MSK is lower.  Demodulation  The MSK signal can be demodulated by using the same techniques as for FSK  since MSK is a type of FSK . It can also be demodulated as a continuous phase modulation  CPM  scheme with trellis demodulation using the Viterbi algorithm  since MSK is a CPFSK scheme  [39].  Coherent demodulation of MSK is very similar to that of QPSK. The BEP is  derived as   cid:17  cid:25    cid:18   Pb = Q  2γb   coherent MSK ,   7.101   which is the same as that of BPSK, QPSK, and OQPSK. Since MSK is a type of FSK, it can also be demodulated noncoherently with about 1 dB loss in power efﬁ- ciency. To ensure the orthogonality between the two channels, it is necessary to have fc = n 4T , n = 2, 3,··· [39]. However, for the typical case fc  cid:7  1 T, and even if it is not a multiple of 1  4T , orthogonality is almost retained. The MSK signal has no discrete spectral line that can be used for synchronization. By passing through a squarer, strong discrete spectral lines are generated at 2f− and 2f+. There phase ambiguity in carrier recovery due to the squaring operation. One solution is a 180 is to differentially encode the data stream before modulation.  ◦  7.6.4 Gaussian minimum shift keying  The power spectrum of MSK has a wide mainlobe. GMSK is obtained by narrowing the mainlobe of MSK signals using a premodulation Gaussian lowpass ﬁlter, that is, using Gaussian instead of sinusoidal pulse shaping [22]. The transfer function of the Gaussian ﬁlter is given by  H  f   = e  − 2 ln 2f 2 B2 b  ,   7.102   where Bb is the 3-dB bandwidth of the baseband shaping ﬁlter. Thus, smaller Bb corre- sponds to a higher frequency efﬁciency. The impulse response of the Gaussian ﬁlter is given by [28]      216   cid:2   Modulation and detection  BbT = ∞  MSK   1.0  0.7  0.5  0.16 0.2  0.25  0.3  0.4  0  –20  –40  –60  –80    b d         Y T I S N E D L A R T C E P S  –100  –120  0   cid:2 Figure 7.25  2.5  1.0  0.5 2.0 NORMALIZED FREQUENCY :   f – fc T PSD of GMSK. c cid:2 IEEE, 1981.  [22], Fig. 2 .  1.5   cid:12    cid:7    cid:13    cid:8    cid:12   g t  = Q  t − T √ 2πBb ln 2  2  − Q  √ 2πBb   cid:13    cid:8   ,   cid:7   t + T ln 2  2   7.103   which can be approximated by a Gaussian response.  Since the Gaussian ﬁlter does not satisfy the Nyquist criterion for ISI cancellation, reduc- ing the spectral occupancy introduces ISI. ISI increases as Bb decreases. This reduces the BEP performance of MSK. The ﬁlter parameter is speciﬁed by the normalized bandwidth BbT. A decrease in BbT narrows the power spectrum, but leads to an increase in ISI and also a degradation in power efﬁciency. At 99.99% bandwidth, the power degradation fac- tor β with respect to MSK due to premodulation ﬁlter is 0.76 for BbT = 0.20, 0.84 for BbT = 0.25, 0.89 for BbT = 0.30, and 0.97 for BbT = 0.5. GMSK signals have a phase that changes linearly with time. The PSD of GMSK is simulated in [22]. For BbT = ∞, it reduces to MSK. A smaller BbT leads to a tighter PSD. The spectrum with BbT = 0.25 is quite tight, and is usually used. The PSD of GMSK is plotted in Fig. 7.25. We have B90% = 0.52Rb, B99% = 0.79Rb for BbT = 0.2, B90% = 0.57Rb, B99% = 0.86Rb for BbT = 0.25, and B90% = 0.69Rb, B99% = 1.04Rb for BbT = 0.5. A Costas loop demodulator is implemented in [22]. For GMSK, the measured BER can  be approximated by [22]   cid:17  cid:25    cid:18   Pb ≈ Q  2αγb   GMSK ,   7.104       217   cid:2   7.6 Frequency shift keying  where α is the degradation factor due to the Gaussian ﬁlter, α = 0.68 for GMSK with BbT = 0.25, α = 0.85 for simple MSK  BbT → ∞ . With coherent detection in the AWGN channel, theoretically α = 1 for MSK. GMSK increases the spectral efﬁciency of MSK. Like MSK, GMSK signals can also be demodulated by using coherent detection, differential detection, and frequency discrimi- nator techniques. Coherent detection generally gives the best result. Differential detection does not suffer from the threshold effect and cancels the phase distortion between adja- cent symbols. Like MSK, GMSK is a constant-envelope modulation scheme that achieves a high power-efﬁciency MS using a class C ampliﬁer.  The GMSK modulator consists of a bit stufﬁng system, a differential encoder, a Gaus- sian lowpass ﬁlter and an FM modulator. The bit stufﬁng system repeats each bit once to eliminate small and ambiguous phase change sequence patterns and to provide a sym- metric detection. The differential encoder encodes information bits using the carrier phase differences. GMSK is used in the GSM, GRPS, EDGE, and CDPD systems. In the GSM system, BbT is selected as 0.3. In CDPD, BbT = 0.5. GFSK is similar to GMSK, but it utilizes a Gaussian ﬁlter to smooth positive negative frequency deviations of FSK. GFSK is used in DECT and CT2. In DECT, BbT = 0.5, and in CT2 BbT = 0.3. Although GMSK is a good choice for voice modulation, it is not desirable for data modulation. This is because a much lower BER is required for data, which limits the value α and consequently reduces the spectral efﬁciency of GMSK for data.  7.6.5 Continuous phase modulation  CPM is a constant amplitude modulation scheme that is jointly power and bandwidth efﬁ- cient. With suitable design, CPM may achieve higher bandwidth efﬁciency than QPSK and higher-order MPSK. Although high-order QAM can outperform MPSK in terms of power or bandwidth efﬁciency, their nonconstant envelope imposes strict restrictions on power ampliﬁers. The constant-amplitude property of CPM makes it desirable in certain cases. The MSK and GMSK are two practical CPM schemes.  The CPM signal is deﬁned as [3]  s t  = A cos  2πfct +  cid:23  t, a   , −∞ < t < ∞,   7.105  where A is a constant, a = {ak} is the transmitted M-ary symbol sequence, which takes values ±1, ±3, . . ., ± M − 1 , and  ∞ cid:26   k=−∞  akq t − kT    cid:23  t, a  = 2πh  cid:14   q t  =  t  −∞ g τ  dτ   7.106    7.107   with      218   cid:2   Modulation and detection  The term g t  is the frequency shape pulse, which has a smooth pulse shape over 0 ≤ t ≤ LT, but is zero outside, and h is the modulation index. If L ≤ 1, g t  is a full-response pulse shape, and it is a partial-response pulse shape if L > 1.  In order to develop a practical maximum-likelihood CPM detector, h should be chosen as a rational number to make a ﬁnite number of phase states. There is memory in the received signal for L > 1, and this enables the use of the Viterbi algorithm for partial response CPM [4]. When the CPM signal state at t = kT is deﬁned by sk =  θk, ak−1, ak−2, . . . , ak−L+1 , where  cid:23  t, a  is decomposed into the sum of the cumulate phase θk and the instant phase θ  t, ak , the total number of signal states is pML−1, for p phase states. With the Viterbi algorithm, the number of paths to be searched is only the number of states, pML−1.  When g t  is a rectangular pulse of a length of L symbols [3, 39]     g t  =  1 2LT , 0,  0 ≤ t ≤ LT otherwise  .   7.108   We get CPFSK for L = 1. If further M = 2 and h = 1 2, we get MSK. A CPM signal with integer h has discrete frequency components in PSD, enabling car- rier and symbol timing in CPM receivers [39]. Many modulation schemes are given in [39]. Demodulation is mainly based on the optimum ML detection, even though other demodulators are also used. MSK-type demodulators work well for binary CPM wth h = 1 2. Differential receivers and discriminator receivers are also used for binary partial response CPM.  Synchronization is a difﬁcult problem for the CPM technique. Today, synchroniza- tion methods such as the MSK-type synchronizer, square loop and fourth-power loop synchronizers are in practical use for some binary CPM with h = 1 2 such as GMSK. The multi-h CPM is a special CPM where h is cyclically changed for successive symbol intervals. This leads to an increase in the minimum Euclidean distance and an improvement in the error performance, when compared to CPM. Its modulator and demodulator are very similar to that of CPM but with slight modiﬁcations. More detail on CPM and multi-h CPM is addressed in [39].  7.7 Quadrature amplitude modulation  QAM is a modulation scheme which communicates data by changing  modulating  the ◦ . amplitude of two sinusoidal carrier waves, which are out of phase with each other by 90 Unlike MPAM or MPSK, which has one degree of freedom for encoding the information, MQAM encodes information in both the amplitude and the phase of the transmitted signal. Thus, MQAM is more spectrally efﬁcient by encoding more bits per symbol for a given average energy.  Unlike MPSK, where all the M signals are distributed on a unit circle with equidistance, the output signals generated by the rectangular MQAM modulator are distributed on an orthogonal grid on the constellation diagram. The M symbols are gray-encoded.      219   cid:2   7.7 Quadrature amplitude modulation  4  8  12  16  20  24    t   b  0.5  1  0  0  M A Q 6 1  1 0.5 0 −0.5 −1   cid:2 Figure 7.26  0  4  8  16  20  24  12 t  Tb  Modulated 16QAM signal.  The modulated signal is given by  ;  si t  =  cid:19   = cid:19   < cos  2πfct  − cid:19    cid:20   Aie j φig t e j 2πfct   cid:20   Ai cos φig t    7.109  for kT ≤ t ≤  k + 1 T, i = 1, 2,··· M. For the rectangular window, the energy in symbol si t  is Esi  i T 2. The modulated signal can be written as  Ai sin φig t   sin  2πfct   = A2  si t  = Iig t  cos  2πfct  − Qig t  sin  2πfct  ,  where  Ii = si,1 = Ai cos φi, Qi = si,2 = Ai sin φi.   7.110    7.111   Example 7.16: The modulated signal of 16QAM modulation is plotted in Fig. 7.26. Here, the bit period Tb = 1 and fc = 2, and the waveform is normalized.  MQAM constellations  The constellation diagram of MQAM can be speciﬁed in any combination of Ai and θi. Three types of QAM constellations are popular, namely type-I, type-II and type-III con- stellations. The type-I  star  constellation places a ﬁxed number of signal points uniformly on each of the N concentrated rings, where N is the number of amplitude levels. This is also known as star-QAM. The points on the inner ring are very close in distance, and are thus most affected by errors. The type-II constellation improves the error performance of type-I, by decreasing the number of points on the inner circles, and making the distance between two adjacent points on the outer circles to be approximately equal to that on the inner cir- cles. The type-III  square  constellation has a very small performance improvement over      220   cid:2   Modulation and detection  Q  Q  101  111  1101  1100  1110  1111  100  110  1001  1000  1010  1011  I  I  000  010  0001  0000  0010  0011  001  011  0101  0100  0110  0111   cid:2 Figure 7.27  star 8QAM  square 16QAM  Constellations of Gray coded star 8QAM and square 16QAM.  Q  M = 256  M = 128  M = 64  M = 32 M = 16  M = 8  M = 4  I   cid:2 Figure 7.28  Square QAM constellations.  type-II constellation, but its implementation is much simpler. For this reason, the type-III constellation is most widely used. A type-I 8QAM and a type-III 16QAM are shown in Fig. 7.27.  Square MQAM is the most popular QAM scheme. It usually takes the form of a square constellation such as 4QAM, 16QAM, 64QAM, and 256QAM. 4QAM is the same as QPSK. These constellations are more often used, due to the relative ease of their circuit implementation. Square MQAM implementation for 32QAM, 128QAM, and 512QAM is also possible. The square QAM has a maximum possible minimum Euclidean distance dmin among its phasors  constellation states , for a given average symbol power. It is most appropriate for the AWGN channel. The square QAM constellations are shown in Fig. 7.28      221   cid:2   7.7 Quadrature amplitude modulation  for M = 4, 16, 32, 64, 256, 512. Two rectangular constellations for M = 8 are also shown in the ﬁgure.  Star MQAM may also be used due to its relatively simple detector and lower PAPR [14]. Star MQAM can be treated as multi-level MPSK, each level having a different amplitude. Although it is not optimum in terms of dmin under the constraint of average phasor power, it allows the use of efﬁcient differential encoding and decoding methods. This makes it suitable for fading channels. The method of differential coding for star QAM is determined depending on the purpose: based on either avoiding carrier recovery or enabling differential detection of signals.  Good constellation mappings may be hard to ﬁnd for MQAM signals, especially for irregular constellation shapes. It may be also hard to ﬁnd a Gray code mapping where all the symbols differ from their adjacent symbols by exactly one bit.  Application  An MQAM system requires a smaller minimum carrier-to-noise power ratio than an MPSK system does. A higher level of encoding requires a higher minimum carrier-to-noise power ratio  CNR or C N . Gray codes are used to map binary symbols to phasor states in the constellation.  MQAM modulation is most widely used in various wireless systems. Lower-order QAM schemes have better cell overlap control and good tolerance to distortion, but lower spectral efﬁciency. Higher-order QAM schemes provide higher data rates at the cost of stricter C N requirements, smaller coverage radii for the same availability, and hardware complexity, and more severe cell-to-cell interference. For satellite communication systems, QPSK is usually used in the uplink direction at a lower frequency channel, and MQAM is used in the downlink direction at a higher frequency band.  Due to the high spectral efﬁciency, MQAM are widely used in broadband wireless and satellite multimedia communication systems, such as DVB. In IEEE 802.11n, the 256QAM modulation is used in order to achieve a data rate in excess of 600 Mbits s. In WiMax, adaptive modulation is applied, higher-order modulation being used for MSs that are closer to the BS. In LTE, QPSK, 16QAM, and 64QAM are used in the downlink. MQAM is also used in DVB-S C T.  For symmetrical constellations, the means of Ik and Qk are zero, but the variances depend on the constellation shape  PSD   cid:22    cid:23   I2 k   cid:17    cid:22    cid:23   = E  cid:18   = E  σ 2 I  ,  σ 2 Q  Q2 k  .   cid:23 ˜s  f   = P  f  2  T  + σ 2  Q  σ 2 I  = 2Pavg Ep  P  f  2,   7.112    7.113   The PSD for QAM is derived by [39]      222   cid:2   Modulation and detection  where P  f   is the spectrum of the signal pulse shape g t , Pavg is the average power of the signal, and Ep is the pulse energy of g t  in [0, T]. From this, we can see that the PSD shape of QAM is independent of its constellation, but decided by g t .  For the rectangular pulse, the PSD is derived as  It has the same shape as the PSD of MPSK. For square MQAM  M = 4n, n = 1, 2, . . .    cid:23 ˜s  f   = 2 3  E0 M − 1   sin πf nTb  πf nTb  ,  where E0 is the energy of the signal with the lowest amplitude.   7.114    7.115    cid:2    cid:3 2  avgT   cid:23 ˜s  f   = A2 = A2  avgnTb   cid:2   sin πf T  πf T sin πf nTb  πf nTb  .   cid:3 2  cid:3 2   cid:2   SEP  The QAM modulator and demodulator are based on the same quadrature modulator and demodulator used for MPSK. Coherent detection is used, and a pilot-signal-aided fading compensation technique is required. For square MQAM, the r1k and r2k can be detected separately by two multi-threshold detectors to generate Ik and Qk.  The received MQAM signal can be demodulated by ﬁrst correlating with two phase- shifted basis functions cos 2πfct and sin 2πfct. The correlator outputs are then sampled and passed to the detector. Detection is based on the minimum distance between the received amplitudes of I and Q and the set of standard amplitudes of I and Q for modulation.  Clock synchronization for MQAM is the same as that for MPSK. Carrier synchroniza- tion is required for square QAM constellation, but it is not required for star QAM if differential encoding is used. Differential coding is needed for square QAM to resolve the phase ambiguity in carrier recovery. This is because all square QAM schemes have 4-fold symmetry, and the four-time loop for carrier recovery may introduce a phase ambi- guity of π 2. This is similar to the M-fold symmetry for MPSK. Differential coding can be designed to remove the symmetrical ambiguity, but it violates the Gray code rule, lead- ing to an increase in BER. For K-bit square QAM, only the ﬁrst two bits are differentially encoded, while other bits are Gray coded in each quadrant. This same rule applies for other constellations. For star QAM, the use of differential coding can eliminate carrier recovery. MQAM modulation with a square constellation of size M = 2k with k even, such as M = 4, 16, 64, 256, can be treated as two independent MPAM systems with constellation √ M over the I and Q signal components, each having half the total MQAM system size energy. Thus, the probability of symbol error for MQAM can be derived as   cid:17    cid:18 2 = 2P√  Ps = 1 −  1 − P√  M  − P2√  M,  M   7.116       223   cid:2   7.7 Quadrature amplitude modulation  M is the SEP for each branch, that is, an  where P√ average power of the QAM signal. At high SNR √ M − 1  √ M  Ps ≈ 2P√  = 4   Q  M   cid:12  cid:31    cid:13   3γs M − 1  ,  √ M-ary PAM with one-half of the  where γs is the average symbol SNR. For square QAM with M = 2k for k odd, it has a rectangular constellation, and there √ M-ary PAM system. Each constellation point may have two, three, or is no equivalent four nearest neighbors. The inner points have four nearest neighbors, while the outer points have two or three. The distance dmin = 2d. The nearest-neighbor approximation to Ps can be derived, using four nearest neighbors Ps ≈ 4Q   cid:12  cid:31    7.118    cid:13   .  For nonrectangular constellations, the solution  7.118  is an upper bound on Ps. The  nearest-neighbor approximation for nonrectangular constellation is given by [13]  3γs M − 1  cid:2   dmin√ 2N0   cid:3   ,  Ps ≈ MdminQ  where Mdmin is the largest number of nearest neighbors for any constellation point.  For Gray coded QAM, the BEP is calculated by Pb ≈ Ps log2 M    cid:7    cid:2    cid:3  √ 2 cid:26   M  ⎛⎝ 2i − 1   Pb ≈ 4  Q  3  .  1 − 1√ M  log2 M   cid:8  log2 M M − 1  i=1  ⎞⎠  square QAM .  γb  The BEP of Gray coded coherent square QAM can be more accurately computed by [19]  The ﬁrst two terms in the summation give a very accurate result. If all terms are included, then it is an upper bound, while the ﬁrst term corresponds the lower bound. The approxi- mation becomes exact for M = 4. A comparison between Ps of MPSK and that of MQAM clearly shows that when M ≥ 8, every doubling of M leads to an asymptotic 3 dB increase in power saving over MPSK.   7.117    7.119    7.120    7.121   Example 7.17: The BEPs of QAM using the accurate expression for M = 4 and the two-term approximation for M ≥ 8 are plotted in Fig. 7.29.  In [6], exact closed-form expressions for the BEP of the coherent demodulation of Gray coded MPAM, square MQAM, rectangular I × J-ary QAM have been derived, under the AWGN channel. A general, numerically efﬁcient algorithmic method for the      224   cid:2   Modulation and detection  s P  100  10−2  10−4  10−6  0  M = 4  8 16  32  64 128 256   cid:2 Figure 7.29  5  10  15  20  25  γ  b  dB   BEP of square QAM.  exact evaluation of the BEP SEP in arbitrary 2-D constellations with arbitrary labeling  bits-to-symbol mapping  and arbitrary signaling has been proposed in [36].  For MQAM demodulation, the channel amplitude is used to scale the decision region so as to obtain the correct transmitted symbol, and this scaling is known as automatic gain control  AGC . The channel gain is typically estimated at the receiver using pilot symbols.  For both MPSK and MQAM, the maximum  ISI free  spectral efﬁciency is ηs = log2 M  bits s Hz. MPSK leads to constant-envelope signals. MQAM has a large PAPR in the resulting signal, and a linear ampliﬁer is required.  More details on various modulation techniques and their PSDs are given in [35, 39].  7.8 Bandwidth efﬁciencies of M-ary modulation  For M-ary modulation, the bit rate is related to the symbol rate by  Rb =  log2 M Rs.  For MPSK modulation, the modulated signal has a null-to-null bandwidth of 2Rs Hz, that is   7.122    7.123   Bnull-to-null = 2Rs = 2Rb log2 M   Hz .  The same results are obtained for MQAM and DMPSK. Thus, the bandwidth efﬁciencies  bits s Hz  for MPSK, DMPSK, and MQAM are given by  η =  Rb  = 1 2  Bnull-to-null   7.124  For coherent MFSK, the minimum spacing between two tones is  cid:18 f = 1  2Ts  = Rs 2. For M tones, the bandwidth is  M− 1 Rs 2. There is an allowance of Rs Hz at either end of   MPSK, DMPSK, MQAM .  log2 M  bits s Hz       225   cid:2   7.9 Matched ﬁltering  the band to get the null. Thus, the total bandwidth is  M+3 Rs 2. The bandwidth efﬁciency for coherent MFSK is given by η = 2 log2 M M + 3   coherent MFSK .   bits s Hz    7.125   The bandwidth efﬁciency for noncoherent MFSK is given by  η = log2 M 2M   bits s Hz    noncoherent MFSK .   7.126   7.9 Matched ﬁltering  Matched ﬁltering is an optimum ﬁltering technique that results in the maximum SNR at the receiver decision instants. For the AWGN channel, the matched ﬁltering criterion can be represented by [21, 28]  H  f   = kX  ∗  −jωT0,    f  e   7.127   where H  f   is frequency response of the pulse shaping ﬁlter, k is a scaling factor, X  f   is the voltage spectrum of the pulse, ∗ is the conjugation operator, and T0 is the duration of the pulse. The delay term is used for causality. As H  f   = kX  f  , the magnitude response of the matched ﬁlter is identical to the transmitted signal spectrum. On the other hand, the phase of H  f   is the negative of the phase of X  f   shifted by ωT0.  Matched ﬁltering makes use of the coherent property of the pulse frequency components,  while the noise components are incoherent.  The matched ﬁltering criterion  7.127  can be transformed into the time domain by using  the inverse Fourier transform  h t  = kx  ∗  T0 − t  .   7.128   Since the impulse response of the matched ﬁlter is a time-reversed copy of the expected pulse, the output is the autocorrelation of either the input pulse or impulse response of the matched ﬁlter  y t  = kRxx τ   = kRhh τ  ,   7.129  where τ = T0 − t, and x t  = s t  + n t , s t  being the transmitted pulse and n t  white noise with double-sided PSD N0 2. The matched ﬁlter is thus also called a correlation receiver. The matched ﬁlter output at the sampling instant t = T0 is identical to the output of the signal correlator.  For digital communications, the variable delay τ is unnecessary, since the timing is usually known and also only the peak value of the correlation function, Rxs 0 , is important. The output of the correlator reaches the maximum at the end of the pulse of period T0. The s2 t dt = Es, Es being the normalized symbol energy. matched ﬁlter output is given by The decision instant SNR is given by   cid:27   T0 0  S N  = 2Es N0  .   7.130       226   cid:2    cid:2 Figure 7.30  Modulation and detection  kT0  dt    −1   k T 0  0kT  Rxs  0   x  t   s   t  Signal correlator in digital communications.  g T−t   Sampler  Carrier phase  recovery  r  t    φ  90   Timing recovery  s I i  s Q i  mi  Decision  logic  T  g T−t   Sampler   cid:2 Figure 7.31  Receiver with carrier phase and timing recovery. T is the sampling period.  This SNR value depends only on pulse energy and the input noise power spectral density, but independent of pulse shape. The signal correlator is shown in Fig. 7.30.  A single matched ﬁlter can only detect one state of digital symbol. For reception of an M-ary signal, M parallel correlators are used, each having a reference pulse corresponding to one of the M symbol states. The outputs of all the M correlators are compared, and the one with the maximum value corresponds to the detected symbols.  7.10 Synchronization  For digital demodulation and detection, synchronization of symbol timing and estimation of the carrier frequency and phase are very challenging tasks. Symbol timing is necessary for estimating the received symbol and is used for driving the sampling devices at the demodulators. Carrier frequency and phase are used in all coherent demodulators. Due to the complex channel, synchronization of timing and carrier phase is most difﬁcult. In case of multipath components, the receiver is usually synchronized to the strongest multipath component or the ﬁrst arriving multipath component that exceeds a power threshold.  The carrier phase and timing recovery structure for the amplitude and phase demodulator is shown in Fig. 7.31. Carrier phase and symbol timing can be jointly estimated by using the ML method. They can also be detected separately by assuming the other to be known. Synchronization at the receiver has several layers: carrier synchronization; symbol tim- ing recovery; slot, frame, and superframe synchronization. Synchronization is typically accomplished through initial acquisition, tracking, and reacquisition. Acquisition is a hypothesis-testing problem that determines the interval in which the optimum estimation lies, while tracking ﬁne-tunes the estimation to the exact value.      227   cid:2   7.10 Synchronization  For cellular communication systems, BSs use precise rubidium clocks or GPS signals as frequency references, while MSs use quartz oscillators. The BS periodically transmits a high-precision frequency reference, and the MS can adjust its local oscillator using this reference. Time synchronization information is also transmitted from the BS to the MS.  7.10.1 Carrier synchronization  Carrier frequency offsets are caused by drifts of LOs at the transmitters and receivers, and or the Doppler shift. Carrier synchronization is necessary for coherent demodula- tion, where the phase of the received signal must be known so that the LO is exactly synchronized to the carrier, both in frequency and phase. This is practically very difﬁcult. Carrier synchronization can be achieved by sending a pilot tone, which has a strong spectral line at the carrier frequency. This spectral line enables the receiver to easily lock onto it and generate a local coherent carrier. Carrier synchronization can also be achieved by using a carrier recovery circuit which extracts the phase and frequency of the received signal to generate a clean reference signal. Carrier synchronization is implemented by some variant of PLL such as a Costas loop.  Carrier phase recovery   cid:14    cid:17   Assuming a known timing, the ML phase estimation ˆφ for an unmodulated carrier plus  cid:18  noise, r t  = A cos  2πfct + φ  + n t , is given by [13] 2πfct + ˆφ   7.131  where T0 is a ﬁnite time interval T0 ≥ T. This solution is accomplished by using a PLL that satisﬁes  7.131 , as shown in Fig. 7.32. In the ﬁgure, if z t  = 0, then ˆφ is the ML estimate of φ. If z t   cid:18 = 0, then the VCO adjusts its phase ˆφ.  dt = 0,  r t  sin  T0  For a modulated carrier, there are decision-directed and non-decision-directed parameter estimation methods. The data decision structure can remove the data decision from the modulation of the received signal, and the resulting unmodulated carrier is then passed to the above PLL for phase recovery. A non-decision-directed loop structure can use a squaring or Mth-power loop, or a Costas loop. The Mth-power loop takes the Mth-power of the signal, ﬁlters out the frequency Mfc by a bandpass ﬁlter, and the output is sent to a PLL. The Costas loop is very similar to a PLL. The decision-directed PLL is superior  r  t   .      dt  T0  z t   +φ sin 2            πfc  VCO  Phase-locked loop for carrier phase recovery.   cid:2 Figure 7.32      228   cid:2   Modulation and detection  in performance to both the Costas loop [8] and the squaring  or Mth-power  loop, when −2. More discussion on carrier phase recovery is the demodulation error rates are below 10 given in [28].  Carrier frequency synchronization  The LO can be synchronized with an incoming carrier wave by either using a pilot carrier transmitted along with the incoming carrier wave, or using a carrier-recovery circuit. The pilot carrier has the same phase and frequency as the modulated signal, and can be used to phase-lock the LO. Carrier-recovery circuits are typically based on PLLs.  The carrier-recovery loop and the timing synchronizer are ideally locked to the carrier of the LOS or the minimum-delay multipath component, which has the largest amplitude. In practice, the synchronizer typically locks to the ﬁrst found component above a threshold to avoid the complex search process.  For PSK signals such as BPSK or QPSK signals, there is no spectral line at the carrier frequency. A nonlinear device is used to generate such a spectral line. A Mth-power loop or a Costas loop can be used for this purpose. For MPSK, the Mth-power loop can produce a spectral line at Mfc. A PLL tracks and locks onto the frequency and phase of this Mfc component. A divided-by-M device produces the desired carrier at fc and almost the same phase of the received signal. For a BPSK signal m t  cos  2πfct + φ , m t  = ±1, a simple squarer, which uses a diode, bandpass ﬁltering, and a divide-by-two circuit, generates an LO signal synchronized to the input signal, cos  2πfct + φ . Mixing the LO with the input signal yields the demodulated m t . Thus, for BPSK signals, the PLL is not necessary. The Mth-power device is difﬁcult in circuit implementation, especially at high frequencies. The Costas loop avoids this device, but it requires a good balance between the I- and Q- channels. The performance of the Mth-power loop and the Costas loop implementation are the same [12].  For QAM, carrier recovery is typically realized by using the fourth-power loop or by decision-directed carrier recovery  DDCR . DDCR is suitable for ﬁxed-link QAM systems, while the fourth-power loop is more suitable for digital radio in fading channels, since it does not depend on data decisions. The fourth-power device generates a spectral line at 4fc. DDCR can be used for any constellation, but it has a BER threshold: below this threshold, its performance is extremely good; otherwise, the decision is not reliable.  Frequency synchronization is typically realized using automatic frequency control  AFC . It is often feedback-based and the algorithm requires the PLL operation suitable for DSP implementation. The received signal constellation rotation is corrected as phase error. By monitoring the phase error in the signal constellation, phase correction can be conducted by an analog component with a digital control signal or by using a DSP.  7.10.2 Symbol timing recovery  Symbol timing recovery or clock synchronization ensures the received signal is sampled as close as possible to the optimal sampling point for detection. The clock signal is recovered      229   cid:2   7.10 Synchronization  I r   t   g −t         d dτ  Sampler  I ks       dz      dτ  τ     k  τ  VCC  Σ  k   cid:2 Figure 7.33  Decision-directed timing estimator.  from the demodulated waveform. Digital interpolation is usually used to ﬁnd the value of the signal at the optimal sampling point from two or more neighboring samples.  Usually the spectrum of the received waveform does not contain a discrete compo- nent at the clock frequency, due to distortion of the transmission link and noise. But a periodic component at the clock frequency exists in the squared waveform for digital sig- nals. Timing estimation can be performed on either the in-phase or quadrature branch. The timing estimator can be either a decision-directed estimator or a non-decision-directed estimator.  Assuming a known carrier phase φ, the ML estimation of the timing delay τ can be derived. The ML estimation of τ is required to satisfy [13, 28]  ML estimation  sI k   d dτ  zk τ   = 0,   cid:26   k   cid:14   T0  zk τ   =  r t g t − kT − τ  dt.   7.132    7.133   where sI k  is the amplitude of the in-phase component of the symbol transmitted over the kth symbol period, and  For decision-directed estimation, the estimator is as shown in Fig. 7.33. The voltage- controlled clock  VCC  has an input as the LHS of  7.132  and an output of timing estimator ˆτ . The feedback loop ensures that the input will become zero and in this case the output is the ML estimation of τ . In the ﬁgure, the in-phase equivalent lowpass received  signal is rI t  = sI t; τ   + nI t , and sI t; τ   = cid:24   k sI k g t − kT − τ  .  Early-late gate synchronizer  A well-known non-decision-directed timing estimation method is the early-late gate syn- chronizer [13, 28]. It exploits the symmetry of autocorrelation and the fact that the maximum of the autocorrelation is at τ = 0. It is applied to the output of the matched ﬁlter or correlator. Bit timing is established by adaptive timing based on an error signal generated by, for example, early-late gate integrators. The architecture of the early-late gate synchronizer is shown in Fig. 7.34. The loop adjusts the timing of the VCO square wave so that it is in perfect synchronization with the demodulated signal m t . Timing      230   cid:2    cid:2 Figure 7.34  Modulation and detection  Late gate integrator  R1  Absolute  value  R1  e  Σ  −  +  m  t   VCO  LPF  R2  Early gate integrator  Absolute  value  R2  Early-late gate timing estimator.  recovery estimates the timing offsets before sampling. The early-late gate is used in IS-95 [38].  Timing recovery is conventionally performed using a decision-directed PLL. Con- ventionally timing recovery is an independent step relative to equalization and channel decoding. This timing recovery approach fails at low SNR. Iterative timing recovery per- forms timing recovery multiple times while interacting with the decoder, to enable reliable operation at very low SNR, with a marginal increase in complexity when compared to the conventional timing recovery [5]. The eye diagram is a useful tool for accessing the distor- tion of a digital signal. The vertical eye opening is an indication of the amount of noise that can be tolerated without causing an incorrect decision. The eye diagram can be obtained by triggering the oscilloscope with the recovered symbol timing clock signal and displaying the symbol stream using a sweep time for 2 or 3 symbol periods.  The ﬁlter and square timing recovery technique [24] is a simple and well-known one. It exploits the cyclostationary property for timing estimation. It is based on an explicit spectral line regeneration using a nonlinear device. In [41], this symbol timing recovery technique is reﬁned by implementing interpolation.  Frame timing  Frame timing can be accomplished by using training symbols at the beginning of a data frame, and frame synchronization is performed by repetitively correlating the received training sequence with its replica known at the receiver until a peak is identiﬁed. The receiver can then adjust its timing based on the time at the peak. Frame timing can be tracked by the same operation. In case of frequency offset, the received signal should be correlated with the frequency-shifted original training sequence. For estimation of slot timing, a primary synchronization sequence is included at the beginning of the transmit- ted data. The signal at the ADC output is ﬁltered by a correlator matched to the primary synchronization sequence.  Some BSs provide the synchronization channel for MSs to achieve slot and frame syn- chronization. Synchronization is searched by performing correlations for at least a frame boundary. Also the location of each time slot corresponds to a strong peak.      231   cid:2   7.12 Error probability in fading channels  7.11 Differential modulation  Differential modulation is a noncoherent technique. The differential scheme does not require channel knowledge, but incurs 3 dB loss in the required SNR when compared to its coherent counterpart.  The differential scheme is traditionally used for PSK-modulated symbols s n . But the idea is applicable to other modulation schemes. The transmitted symbol x n  is obtained by  x n  = x n − 1 s n ,  n ≥ 0  and x −1  = 1. After transmission over a ﬂat-fading channel h, the received signal at the receiver is  given by  y n  = √  γ hx n  + w n ,  where γ is the average symbol SNR, and w n  is white Gaussian noise with mean 0 and variance 1.  Assuming the channel h is time-invariant for at least two symbol periods, we have  y n  = √  γ hx n − 1 s n  + w n   = [y n − 1  − w n − 1 ]s n  + w n  = y n − 1 s n  + v n ,  where v n  = w n  − w n − 1 s n . Assuming s n  = 1, we obtain that v n  is Gaussian with mean zero and variance 2. The ML demodulation of s n  from  7.136  gives  ˆs n  = arg min s n ∈S   cid:15 y n  − y n − 1 s n  cid:15 2.  This does not require any information of the channel h. From  7.136 , the SNR at the output of the differential decoder is derived as   7.134    7.135    7.136    7.137    7.138   γdiff = h2γ  .  2  The 3 dB loss in SNR compared to the coherent ML decoding is due to the fact that the noise variance is increased from 1 for w n  to 2 for v n .  7.12 Error probability in fading channels  Thus far, the error probabilities given for different modulation schemes are for the AWGN channel. This section gives the corresponding error probabilities in fading channels.      232   cid:2   Modulation and detection  7.12.1 Flat Rayleigh fading channel   cid:14  ∞  Wireless channels with relatively small bandwidth are typically characterized as the Rayleigh-fading channel. The Rayleigh fading leads to a signiﬁcant degradation in BEP performance compared to the Gaussian channel, since the Rayleigh fading decreases the SNR. In the Gaussian channel, the BEP decreases exponentially with the SNR, while in the Rayleigh fading channel it decreases linearly with the average SNR. Diversity, spread spectrum, and OFDM are the three techniques to overcome fading.  The BEP of Rayleigh fading can be derived as  =  PRayleigh b  Pb  γbr  pr r dr, where pr r  is the Rayleigh pdf, given by  3.25 , and γb = Eb is the mean bit SNR, σ being a parameter of the Rayleigh pdf. The SEP of the Rayleigh fading channel can be derived similarly.  = 2σ 2Eb N0   7.139   N0  0  The SEP for Rayleigh fading can also be derived from  7.25 . First, at each instant, the amplitude of the received signal, r, satisﬁes the Rayleigh distribution. Deﬁne the received power as Pinst = r2, and then the mean power is P = 2σ 2. Since dPinst = 2rdr, the pdf of the received power pPinst Pinst  can be derived. By scaling Pinst by 1 N0, the pdf of the symbol SNR γs, pγs γ  , is derived as  − γ γ s , e  pγs γ   = 1 γ s  cid:14  ∞  PRayleigh s  =  0  where γ s = Es  N0  is the mean symbol SNR. The SEP of the Rayleigh fading channel is ﬁnally  obtained by averaging over the distribution of the symbol SNR  pγs γ  Ps γ  dγ ,   7.141   where Ps γ   is the SEP in the AWGN channel. This procedure is also valid for Ricean fading and other amplitude distributions.  In the AWGN channel, many coherent demodulation methods have an approximate or  exact value for Ps of the form   cid:7 √   cid:8   Ps γb  ≈ c1Q  c2γb  .  Corresponding to  7.142 , the SEP in the Rayleigh fading channel can be derived by  Another general form for Ps in the AWGN channel is Ps γb  ≈ c1e −c2γb,    where c1 and c2 are constants.  substituting  7.142   in  7.141 :   cid:13   PRayleigh s  = c1 2  c2γ b 2 + c2γ b  .   cid:12  1 −  At high γ b, PRayleigh  s  ≈ c1 2c2γ b  .   7.140    7.142    7.143    7.144       233   cid:2   7.12 Error probability in fading channels  b P  100  10−2  10−4  10−6  0  BPSK, QPSK OQPSK, MSK  in Rayleigh  BPSK, QPSK OQPSK, MSK  in AWGN  15 b  dB   γ  5  10  20  25  30   cid:2 Figure 7.35  BEPs of BPSK, QPSK, OQPSK, and MSK in the AWGN and ﬂat Rayleigh fading channels.  Also, corresponding to  7.143 , the SEP in the Rayleigh fading channel can be obtained  by substituting  7.143  in  7.141 :  PRayleigh s  =  c1  1 + c2γ b  .   7.145   At high γ b, PRayleigh  s  ≈ c1 c2γ b  .  Example 7.18: The BEPs for BPSK  also QPSK, OQPSK, and MSK  in the AWGN and −5 the Rayleigh fading channels are plotted in Fig. 7.35. It is shown that at the BEP of 10 AWGN channel requires a bit SNR γb of 10 dB, while the ﬂat Rayleigh fading channel requires 44 dB; this means a loss of 34 dB. To increase the BEP performance, one can increase the transmitting power by 34 dB. Proper coding techniques can have a coding gain of 34 dB, and thus are power efﬁcient; this is achieved at the price of reduced data rate.  Based on the two error probability representations given by  7.144  and  7.145 , BEPs in the Rayleigh fading channel can be obtained. Some values of c1 and c2 are listed in Table 7.2.  Closed-form results for MPSK, DMPSK, and MQAM  For MPSK, a closed-form expression for the ﬂat Rayleigh fading channel is given by [10, 33]   cid:5    cid:17    cid:18  cid:6   PRayleigh s  = M − 1  − α  M  + 1  π  1 2  −1  tan  α cot  π M   MPSK, Rayleigh ,   7.146       234   cid:2   Modulation and detection  Table 7.2. List of c1 and c2 for different modulation schemes under a ﬂat Rayleigh  fading channel.  c1  1  1 2 2  1 2 1  log2 M  log2 M  2  4  2  log2 M 1 1 2  Modulation  coherent BPSK, QPSK,  OOPSK, MSK optimum DBPSK  DEBPSK, DEQPSK,  π 4-QPSK  suboptimum DBPSK  optimum DQPSK,  π 4-DQPSK MPSK  M > 4   DEMPSK  optimum DMPSK  coherent BFSK  noncoherent orthogonal  BFSK  coherent GMSK MQAM  M = 2k for k even  a α = 0.68 for BTs = 0.25  BEP  AWGN  BEP  Rayleigh    7.142    7.144   c2  2  1  2  0.8  1.112  2 log2 M sin2 π M 2 log2 M sin2 π M 2 log2 M sin2 π√ 1 1 2  2M   7.143    7.142    7.143    7.142    7.142    7.142    7.142    7.142    7.143    7.142    7.142    7.145    7.144    7.145    7.144    7.144    7.144    7.144    7.144    7.145    7.144 a [22]   7.144   1 √ M−1  √ 4  M log2 M  2α 3 log2 M M−1   cid:8  .   cid:28  cid:29  cid:29  cid:30  γ s sin2  cid:7  1 + γ s sin2  cid:2   π M   cid:8    cid:7   cid:3   π M  1 π  arctan  ξ ρz  ρz  − 1   cid:6   α =   cid:5   ρα,  ρz = γ  cid:31  1 + γ 1 − ρz2 + tan2   cid:17  π   cid:18   .  M  ξ ρz  =  where  where  For DMPSK, a closed-form SEP formula for fast Rayleigh channels is derived  as [40]  Ps = M − 1  M  + ρz tan π M   ξ ρz    DMPSK, fast Rayleigh ,   7.147    7.148    7.149    7.150       235   cid:2   7.12 Error probability in fading channels  ρα denotes the correlation between αk and αk−1, αk being the received signal phase difference. When M = 2, it reduces to Ps = 1 2  1 − γ 1 + γ  ρα   7.151    cid:2    cid:3   ,  which is the same as that give in [33] As γ → ∞, ρz → ρα, Ps reveals the presence of an error ﬂoor for DMPSK on fast fading channels. On slow fading channels, ρα = 1, and thus Ps → 0, indicating the error ﬂoor vanishes. For slow fading, ρα = 1, we have from  7.148   cid:8  × Ps = M − 1   cid:8   cid:7  1 + 2γ + γ 2 sin2  π − arccos   cid:18  cid:3  cid:6    cid:17  π   cid:28  cid:29  cid:29  cid:30   1 + γ  γ 2 sin2  − 1   cid:2    cid:5    cid:7   cos  π M  M  M  π  γ  ,  π M   7.152   which is identical to the result given in [10].  Based on the exact instantaneous BEP expression given in [6], an exact closed- form BEP formula for coherently detected MQAM with Gray code bit mapping in the Rayleigh fading channel is derived in [7]. To simplify the formula, tight invertible lower and upper bounds on the BEP are derived. Using these bounds, tight lower and upper bounds on the BEP-based outage probability are also obtained in a log-normal shadowing environment.  In addition, the SEP performance of coherent MPSK in a situation where the phase error, quadrature error, and I Q mismatch problems take place all concurrently over an AWGN and arbitrary fading channel has been investigated in [26].  7.12.2 Flat Ricean fading channel  The SEP for the Ricean fading channel can also be computed from  7.141 , but pγs γ   for Ricean fading is used. Closed-form BEP expressions are derived for optimum DBPSK and noncoherent BFSK [39]   cid:8  e  cid:7  Kr + 1 Kr + 1 + γ b Kr + 1 2  Kr + 1  + γ b  2  − Kr γ b Kr+1+γ b  − Kr γ b e  2 Kr+1 +γ b  Pb = Pb =   optimum DBPSK ,   7.153    noncoherent BFSK .   7.154   For other modulation schemes, numerical integration has to be used for calculating the BEP performance in the Ricean channel. The BEP performance in the Ricean fading channel lies between that in the AWGN and Rayleigh fading channels. For Kr → 1, it reduces to Rayleigh fading, while for Kr → ∞, we obtain the AWGN channel.      236   cid:2   Modulation and detection  b P  100  10−2  10−4  10−6  0  optimum DBPSK  Kr = 0, Rayleigh  4  8  Ricean  Kr = ∞, AWGN  12  16  20  γ  15 b  dB   5  10  20  25  30   cid:2 Figure 7.36  BEPs of the optimum DBPSK in the AWGN, Rayleigh fading, and Ricean fading channels.  Example 7.19: The BEPs for the optimum DBPSK are plotted in Fig. 7.36 in case of the AWGN, Rayleigh fading, and Ricean fading channels.  7.12.3 Alternative form of the Q-function  The Q-function is most fundamental for BEP calculation. Its integration limit that runs to inﬁnity makes its calculation very difﬁcult. Recently, the following representation of the Q-function has been introduced and it makes the computation much more efﬁcient [13, 21, 33]:  Q x  = 1  π  − x2 e  2 sin2 θ dθ,  x > 0.   7.155   By using this new Q-function, one can very easily calculate the BEP or SEP related to the Q-function. The alternative Q-function makes the derivation of closed-form BEP or SEP, or its numerical calculation much easier.  The SEP in fading channels can be written in a generic form [21]  Ps γ   =  −γ f2 θ  dθ.  f1 θ e   7.156   The alternative form of Q-function is more useful for calculating the BEP or SEP in fading channels.  The SEPs of MPSK, MASK, and MQAM, given in terms of Q-function can be calculated  by using the alternative Q-function representation [17]  Ps = a  b  − cγs e  sin2 θ dθ,   7.157    cid:14  π 2  0   cid:14  θ2  θ1   cid:14   0      237   cid:2   where  7.12 Error probability in fading channels  ,  M − 1 √ M M − 1√  ,  M  π  a = 2 a = 4 a = 1  π  π  ,  ,  b = π 2 b = π 2 b = π  , M − 1 M  ,  3  c = M2 − 1 c = 3 2 M − 1  c = sin2 π M    MASK ,   7.158    MQAM ,   7.159    MPSK .   7.160   7.12.4 Error probability using moment-generating functions   cid:14  θ2  θ1  The average SEP can be expressed as  Mγ = cid:27  ∞  0 pγ  γ  esγ dγ .  For the Rayleigh distribution  Ps =  f1 θ Mγ  −f2 θ   dθ,  where the moment-genrating function Mγ  s  is the Laplace transform of pγ  γ  , that is,  For the Rice distribution  The average  ergodic  error probability in fading for modulation with Ps in the AWGN  channel, which is given by  7.142 , can be calculated by  Mγ  s  = 1 1 − sγ  .  Krsγ  1+Kr−sγ .   cid:3   dθ.  Ps = αM  e  π  Mγs  Mγ  s  = 1 + Kr 1 + Kr − sγ  cid:14  π 2  cid:14  Ps = a  cid:3    cid:2  −βM  cid:2  −c  cid:3   cid:5   cid:14   sin2 θ   cid:2  −c  Mγs  0  0  b  b  dθ = a  Mγs  2 sin2 θ  sin2 θ  0  dθ.   cid:2  −c  sin2 θ   cid:3  cid:6 Nr  From  7.157 , the exact average probability of error for M-ary linear modulation in  fading is given by  For statistically independent diversity branches, we have [17]   cid:14   Nr!  l=1  b  0  Ps = a  Mγs,l  dθ,   7.166   The ergodic error probability in the Rayleigh fading channel can thus be obtained by  where Nr is the diversity order.  inserting the MGF  7.162  into  7.166    cid:12    cid:14    cid:13 Nr  Ps = a  b  0  Nr sin2 θ  Nr sin2 θ + cγs  dθ   7.167    7.161    7.162    7.163    7.164    7.165       238   cid:2   Modulation and detection  when the transmit power is uniformly distributed onto all diversity paths. For Ricean fading, the MGF  7.163  is inserted into  7.166 .  The MGFs for many distributions are given in [33].  7.13 Error probabilities due to delay spread and frequency  dispersion  Frequency-selective fading leads to ISI, while Doppler gives rise to spectrum broadening, which leads to ACI. Doppler spread has a signiﬁcant inﬂuence on the BEP performance of modulation techniques that use differential detection. BEPs due to delay spread  frequency- selected fading  or frequency dispersion  Doppler spread  cannot be reduced by increasing the transmit power, thus they are called error ﬂoors. For low-data-rate systems such as sen- −2. sor networks or paging, the Doppler shift can lead to an error ﬂoor of an order of up to 10 Generally, for high-data-rate wireless communications such as mobile communications and −4, which is very wireless LAN, error due to frequency dispersion is of the order of up to 10 small compared with that arising from noise.  Error probability due to frequency dispersion  For DPSK in fast Ricean fading, where the channel decorrelates over a bit period, the BEP is given by [13, 33]   cid:2    cid:3   Pb = 1 2  1 + Kr + γ b 1 − ρc   1 + Kr + γ b  − Kr γ b 1+Kr+γ b , e   7.168    cid:25   P0  S  f   =  where Kr is the fading parameter of Ricean distribution, and ρc is the channel correlation coefﬁcient after a bit period Tb. For the uniform scattering Doppler spectrum model, from Section 3.3.1, the Doppler power spectrum is   f < νmax,  ,  − f 2  π  ν2 max   7.169  then ρc = φc T  φc 0  = J0 2π νmaxT . For the rectangular Doppler power spectrum model, S  f   = P0 2νmax,  f < νmax, then ρc = sinc 2νmaxT .  cid:3  For Rayleigh fading, Kr = 0, from  7.168 , we have 1 + γ b  1 − ρc    cid:2   Pb = 1 2  1 + γ b  .  The irreducible error ﬂoor for DPSK is obtained by limiting γ b → ∞ in  7.168    7.170    7.171   Pb,ﬂoor =  1 − ρc e −Kr  .  2      239   cid:2   7.14 Error probability in fading channels with diversity reception  The irreducible bit error ﬂoor for DQPSK in fast Ricean fading is derived as [13, 16]     ⎛⎝1 −  √  ρc  1 −  ρc   √ 2 2 2 2  ⎞⎠ e  −    √ 2−1 Kr √ 2−ρc  ,  Pb,ﬂoor = 1 2   7.172   where ρc is the channel correlation coefﬁcient after a symbol time T.  For the uniform scattering model and Rayleigh fading, the irreducible error for DPSK is  obtained from  7.171  as  Pb,ﬂoor = 1 2  [1 − J0  2π νmaxTb ] ≈ 0.5  π νmaxTb 2 .   7.173   For small νmaxTb, the BEP is generally given by   7.174  where K is a constant. Note that the error ﬂoor decreases as the data rate R = 1 Tb increases. For MSK, K = π 2 2.  PDoppler b  = K  νmaxTb 2 ,  Error probability due to delay dispersion  For delay dispersion, ISI inﬂuences a signiﬁcant percentage of each symbol. For Rayleigh fading, when the maximum excess delay of the channel is much smaller than the symbol duration, the error ﬂoor due to delay dispersion is given by [21]   cid:2    cid:3 2  ,  στ Tb  Pb,ﬂoor = K   7.175   where στ is the rms delay spread of the channel, given by  3.80 , and K is a constant, which depends on the system implementation. For differentially detected MSK, K = 4 9 [21]. The error ﬂoor due to delay dispersion is typically more signiﬁcant than that due to frequency dispersion for high data rates.  7.14 Error probability in fading channels with diversity reception  The average SEP in a ﬂat-fading channel is derived by the distribution of the SNR  pγ  γ  Ps γ  dγ .   7.176   For BPSK signals in the Rayleigh fading channel, the SEP for Nr diversity branches with  MRC is given by [28] Ps =   cid:2   1 − μ 2   cid:3  cid:2    cid:3 k  ,  1 + μ 2  Nr − 1 + k  k   7.177    cid:14  ∞  0  Ps =  cid:3 Nr Nr−1 cid:26    cid:2   k=0      240   cid:2   Modulation and detection  where    γ s 1 + γ s  cid:3 Nr  cid:2  For large γ s, the SEP is well approximated by [28]  μ =   cid:2   .   cid:3   .  2Nr − 1  Nr  Ps =  1 4γ s   7.178    7.179    7.180   Thus, the BEP decreases with the Nrth power of the average SNR. For a MIMO system of Nt transmitting antennas and Nr receiving antennas, there are altogether NtNr diversity branches, and thus Nr in the above equation is replaced by NtNr.  For the AWGN channel, consider the error probability of the form  where α = 1 diversity branches, we have the error probability for both cases [31, 32]  2 for noncoherent FSK and α = 1 for differential coherent PSK. For Nr  −αγs, e  Ps = 1 2 Nr!  1  k=1  Pb = 1 2  cid:7    Nr!  cid:18 Nr √  cid:17  k + αγ s Nr − 1  Nr k=1   cid:17   1 + αγ s,k  cid:8   cid:18  Nr! 1 + αγ s,k  cid:2  cid:31   cid:3   k=1  Nr 2  2  1  π  2  Ps = Q  αγs 2  ,  Pb = 1 2  Pb =   MRC ,   7.181    Selection diversity ,   7.182    EGC .   7.183   For coherent FSK and coherent PSK in the AWGN channel, we have  2 for coherent FSK and α = 1 for coherent PSK. For Nr diversity branches,  where α = 1 the average error probability is derived from  7.176 , by taking p γ   obtained from  5.17 . There is no convenient closed-form solution. In the case of all branches being equal in strength γ s, we have [31]   cid:17    cid:18   Nr − 1 Nr!  2  !  .  Ps = 1 √ 2  1  π   αγ s Nr  The error probability of discriminator detected FSK that uses two branch diversity is also given in [2, 32] for MRC and selection diversity.  By using the moment-generating function and the trigonomic form of the Q-function,  the average SEP of an MRC diversity system can be derived as [21]   cid:14  θ2  θ1   cid:19   Ps =  dθf1 θ   Mγs   −f2 θ     cid:20 Nr .   7.184    7.185    7.186       241   cid:2   For BPSK in Rayleigh fading, the SEP is alternatively given by [21]  Problems   cid:12    cid:14  π 2   cid:13 Nr  Ps = 1  π  0  sin2 θ sin2 θ + γ s  dθ.   7.187   Diversity can also improve the SEP performance of frequency-selective and time- selective fading channels. Generally, the SEP with diversity is approximately the Nrth power of the BEP without diversity.  The BEP of BPSK for MRC in a Rayleigh fading channel can be extended to the SEP of MPSK in a Rayleigh fading channel in a straightforward manner [37]. MRC receivers using BPSK and MPSK modulation in spatially correlated Rayleigh fading channels have been analyzed in [34], and closed-form expressions for error probabilities of these modu- lations with MRC derived. Exact average SEP expressions for arbitrary M-ary rectangular QAM, when used along with MRC receive diversity over independent but not necessarily identically distributed Nakagami fading channels, are derived in [20].  Asymptotic BEP and SEP expressions are derived in [23] for coherent MRC with MPAM, MPSK and MQAM modulation, differential EGC with DMPSK, and square law combining with BFSK, in correlated Ricean fading and nonCGaussian noise  including interference . Compared to BPSK with MRC, BFSK with square law combining has an asymptotic performance loss of 6 dB independent of the type of noise and Nr. The asymp- totic performance loss of differential EGC compared to MRC is always 3 dB for AWGN, but depending on Nr it may be larger or smaller than 3 dB for non-Gaussian noise.  Problems  7.1 For baseband data transmission, if N0 = 10 mV, what is the maximum data rate for Ps = 10 7.2 A sine wave is used for the PSK and QPSK signaling schemes, respectively. The −5 s. If the received signal is s t  = 0.01 sin 2π106t + θ  volts duration of a symbol is 10 and the measured noise power at the receiver is 10  −7 W Hz and the signal amplitude A = 20 −5?  −7 watts, calculate Eb N0.  7.3 Consider the sequence 1001 1110 0001.  a  Differentially encode it and obtain the differentially encoded sequence b.  b  Biphase-modulate b by a sinusoidal carrier of arbitrary phase, and plot the modulated signal.  c  Draw the block diagram of the demodulator.  d  Show how the demodulator generates the original sequence.  7.4 Generate the message 0010011001 through MSK transmitter and receiver. Sketch the waveforms at the input and output. 7.5 Given MPSK modulation with M = 2, 4, 8, and 16, calculate the bit SNR Eb N0 required for BEPs of 10  −6, 10  −5, 10  −7.      242   cid:2   Modulation and detection  7.6 Calculate the bit rate that can be supported by a 4 kHz channel for modulation:  a  BPSK,  b  QPSK,  c  8PSK,  d  16QAM,  e  coherent BFSK,  f  coherent 4FSK,  g  noncoherent BFSK,  h  noncoherent 8FSK. If N0 = 10 −7 W Hz, ﬁnd the carrier power required for each modulation to support Pb = 10 −5.  Hint: The carrier power Pc = A2 7.7 For BPSK and MSK, compare their bandwidths that contain 90% power with their null-to-null bandwidths.  = EbRb.   2  7.8 Consider PSK modulation with a carrier component 2πf0t + d t  cos  xc t  = A sin  −1 a  ,  where d t  = +1 or −1 with bit intervals of Tb. Assuming the total power is PT, show that the powers in the modulation and carrier components are, respectively, given as   cid:22    cid:23   Pc = a2PT, Pm =  1 − a2 PT.  7.9 Compare binary ASK, BPSK, and BFSK in terms of the transmission bandwidth for a constant data rate. The required bandwidth can be taken as the null-to-null bandwidth. 7.10 For Pb = 10 −5, what is the dB increase in Eb N0 required for DPSK, 16QAM in slow Rayleigh fading over the nonfading cases.  7.11 Plot the BEP for M-ary noncoherent FSK, DMPSK, MPSK, and MQAM in Rayleigh fading.  7.12 Use numerical integration to evaluate the BEP for MQAM in Ricean fading.  7.13 Plot g t  given by  7.103 , for different values of BbT between 0 and 1. The horizontal axis is t T and the vertical axis is g t T. 7.14 A matched ﬁlter has the frequency response H  f   = 1−e . Determine the cor- responding impulse response h t . What is the signal waveform to which this ﬁlter is matched?  −j2πfT j2πf  = 10  7.15 Assume BPSK is used for transmitting information over an AWGN channel with a PSD of N0 2 A2Tb, where Tb is the bit −6 2 interval and A is the signal amplitude. Determine A to achieve an error probability of 10 when the data rate is 100 kbits s.  −9 W Hz. The transmitted signal energy Eb = 1  7.16 A PCM encoded speech signal uses 8 bits per sample, sampling at 8 kHz. The PCM data is then transmitted over an AWGN channel via 8PAM. Determine the bandwidth required for transmission.  7.17 Consider the three 8QAM constellations, shown in Fig. 7.37. The minimum distance between adjacent points is 2A, and all the signal points are equally probable. Determine the average transmitted power for each constellation. Which constellation is more power efﬁcient?  7.18 Show that a π 4-DQPSK signal can be demodulated by using an FM discriminator.      243   cid:2   References   cid:2 Figure 7.37   a    b    c   Figure for Problem 7.17.  7.19 Given a binary sequence 110010100101, plot the MSK modulated waveform as well as its I and Q components.  the GMSK modulated waveform for bit sequence 11010001, assuming  7.20 Plot BbTb = 0.3. 7.21 The BEPs for BPSK, MSK, and QPSK are the same. What are the differences in terms of bandwidth efﬁciency?  7.22 Gray encoding ensures that only one bit changes when the decimal number changes by one unit. For a binary representation of a decimal number b1b2 . . . bn, b1 being the MSB, write a program to convert it into a Gray code g1g2 . . . gn, according to such a relation [9]: g1 = b1, and gn = bn⊕bn−1, where ⊕ denotes modulo-2 addition. Tabulate the conversion for decimal numbers 0 through 31.  7.23 Refer to [7], ﬁnd the closed-form BEP expressions for MQAM with Gray code bit mapping in the Rayleigh fading channel in equation  6 , and the upper bound  10  and lower bound  12 . Plot the BEP formulas as a function of average SNR for M = 4, 16, 64, 256.  References  [1] R. R. Anderson & J. Salz, Spectra of digital FM. Bell Syst. Tech. J., 44:6  1965 ,  1165–1189.  [2] H. W. Arnold & W. F. Bodtmann, Switched-diversity FSK in frequency selective  Rayleigh fading. IEEE J. Sel. Areas Commun., 2:4  1984 , 540–547.  [3] T. Aulin & C.-E. Sundberg, Continuous phase modulation – part I: full response  signaling. IEEE Trans. Commun., 29:3  1981 , 196–209.  [4] T. Aulin, N. Rydbeck & C.-E. Sundberg, Continuous phase modulation – part II:  partial response signaling. IEEE Trans. Commun., 29:3  1981 , 210–225.  [5] J. R. Barry, A. Kavcic, S. W. McLaughlin, A. Nayak & W. Zeng, Iterative timing recovery: methods for implementing timing recovery in cooperation with iterative error-control decoding. IEEE Signal Process. Mag., 21:1  2004 , 89–102.  [6] K. Cho & D. Yoon, On the general BER expression of one- and two-dimensional  amplitude modulations. IEEE Trans. Commun., 50:7  2002 , 1074–1080.  [7] A. Conti, M. Z. Win & M. Chiani, Invertible bounds for M-QAM in Rayleigh fading.  IEEE Trans. Wireless Commun., 4:5  2005 , 1994–2000.      244   cid:2   Modulation and detection  [8] J. P. Costas, Synchronous communications. Proc. IRE, 44:12  1956 , 1713–1718. [9] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework  [10] N. Ekanayake, Performance of M-ary PSK signals in slow Rayleigh fading channels.   London: Springer, 2006 .  Electron. Lett., 26:10  1990 , 618–619.  [11] G. D. Forney, Jr. & L. F. Wei, Multidimensional constellations – part I: introduction, ﬁgures of merit, and generalized cross constellations. IEEE J. Sel. Areas Commun., 7:6  1989 , 877–892.  [12] F. M. Gardner, Phaselock Techniques, 2nd edn  New York: Wiley, 1979 . [13] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [14] L. Hanzo, M. Munster, B. J. Choi & T. Keller, OFDM and MC-CDMA for Broadband Multi-User Communications, WLANs and Broadcasting  New York: Wiley-IEEE, 2003 .  [15] W. C. Jakes, Jr., ed., Microwave Mobile Communications  New York: Wiley, 1974 . [16] P. Y. Kam, Tight bounds on the bit-error probabilities of 2DPSK and 4DPSK in  nonselective Rician fading. IEEE Trans. Commun., 46:7  1998 , 860–862.  [17] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [18] C.-L. Liu & K. Feher, π 4-QPSK modems for satellite sound data broadcast systems.  IEEE Trans. Broadcast., 37:1  1991 , 1–8.  [19] J. Lu, K. B. Letaief, J. C.-I. Chuang & M. L. Liou, M-PSK and M-QAM BER com- putation using signal-space concepts. IEEE Trans. Commun., 47:2  1999 , 181–184. [20] A. Maaref & S. Aissa, Exact error probability analysis of rectangular QAM for single- and multichannel reception in Nakagami-m fading channels. IEEE Trans. Commun., 57:1  2009 , 214–221.  [21] A. F. Molisch, Wireless Communications  Chichester, UK: Wiley-IEEE, 2005 . [22] K. Murota & K. Hirade, GMSK modulation for digital mobile telephony. IEEE Trans.  Commun., 29:7  1981 , 1044–1050.  [23] A. Nezampour, A. Nasri, R. Schober & Y. Ma, Asymptotic BEP and SEP of quadratic diversity combining receivers in correlated Ricean fading, non-Gaussian noise, and interference. IEEE Trans. Commun., 57:4  2009 , 1039–1049.  [24] M. Oerder & H. Meyr, Digital ﬁlter and square timing recovery. IEEE Trans.  [25] J. H. Park, Jr., On binary DPSK detection. IEEE Trans. Commun., 26:4  1978 ,  Commun., 36:5  1988 , 605–612.  484–486.  [26] S. Park & S. H. Cho, SEP performance of coherent MPSK over fading channels in the presence of phase quadrature error and I-Q gain mismatch. IEEE Trans. Commun., 53:7  2005 , 1088–1091.  [27] D. M. Pozar, Microwave and RF Wireless Systems  New York: Wiley, 2001 . [28] J. G. Proakis & M. Salehi, Digital Communications, 5th edn  New York: McGraw-  Hill, 2008 .  [29] J. G. Proakis & D. G. Manolakis, Digital Signal Processing: Principle, Algorithms,  and Applications, 4th edn  Upper Saddle River, NJ: Pearson Prentice Hall, 2007 .      245   cid:2   References  [30] D. Saha & T. G. Birdsall, Quadature-quadrature phase-shift keying. IEEE Trans.  [31] M. Schwartz, W. R. Bennet, & S. Stein, Communication Systems and Techniques  [32] A. U. H. Sheikh, Wireless Communications: Theory and Techniques  Boston, MA:  [33] M. K. Simon & M.-S. Alouini, Digital Communications over Fading Channels, 2nd  Commun., 37:5  1989 , 437–448.   New York: McGraw-Hill, 1966 .  Kluwer, 2004 .  edn  New York: Wiley, 2005 .  [34] D. B. Smith & T. D. Abhayapala, Maximal ratio combining performance analysis in  practical Rayleigh fading channels. IEE Proc.-Commun., 153:5  2006 , 755–761.  [35] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  2001 .  [36] L. Szczecinski, S. Aissa, C. Gonzalez, & M. Bacic, Exact evaluation of bit- and symbol-error rates for arbitrary 2-D modulation and nonuniform signaling in AWGN channel. IEEE Trans. Commun., 54:6  2006 , 1049–1056.  [37] V. V. Veeravalli, On performance analysis for signaling on correlated fading channels.  IEEE Trans. Commun., 49:11  2001 , 1879-C1883.  [38] A. J. Viterbi, Principles of Spread Spectrum Communication  Reading, MA: Addison-  Wesley, 1995 .  2006 .  [39] F. Xiong, Digital Modulation Techniques, 2nd edn  Boston, MA: Artech House,  [40] Q. T. Zhang & X. W. Cui, A closed-form expression for the symbol-error rate of M-ary  DPSK in fast Rayleigh fading. IEEE Trans. Commun., 53:7  2005 , 1085–1087.  [41] W.-P. Zhu, Y. Yan, M. O. Ahmad & M. N. S. Swamy, Feedforward symbol timing recovery technique using two samples per symbol. IEEE Trans. Circ. Syst. I, 52:11  2005 , 2490–2500.      8  Spread spectrum communications  8.1 Introduction  Spread spectrum communications was originally used in the military for the purpose of interference rejection and enciphering. In digital cellular communications, spread spec- trum modulation is used as a multiple-access technique. Spectrum spreading is mainly performed by one of the following three schemes.   Direct sequence  DS : Data is spread and the carrier frequency is ﬁxed.   Frequency hopping  FH : Data is directly modulated and the carrier frequency is spread by channel hopping.   Time hopping  TH : Signal transmission is randomized in time. The ﬁrst two schemes are known as spectral spreading, and are introduced in this chap- ter. Time hopping is known as temporal spreading, and will be introduced in Chapter 20. Spectrum spreading provides frequency diversity, low PSD of the transmitted signal, and reduced band-limited interference, while temporal spreading has the advantage of time diversity, low instantaneous power of the transmitted signals, and reduced impulse interference.  CDMA is a spread spectrum modulation technology in which all users occupy the same time and frequency, and they can be separated by their speciﬁc codes. For DS-CDMA sys- tems, at the BS, the baseband bitstream for each MS is ﬁrst mapped onto M-ary symbols such as QPSK symbols; each of the I and Q signals is then spread by multiplying a spread- ing code and then a scrambling code. The spread signals for all MSs are then ampliﬁed to their respective power, summed, modulated to the speciﬁed band, and then transmit- ted. Each MS receives the summed signal, but extracts its own bitstream by demodulating, descrambling, and despreading the sum signal using its unique scrambling and spreading codes. In a spread spectrum system, bandwidth spreading and user separation are done using different codes: spreading codes and scrambling codes.  CDMA technology uses a set of binary CDMA codes that are orthogonal or almost orthogonal to one another. Each single pulse of the code waveform is called a chip, and it has a duration of Tc. Assuming that each chip has a rectangular pulse shape, the corre- sponding frequency response is a sinc function; thus, the bandwidth between the two zero points of the main lobe is 1 Tc, and this can be deﬁned as the bandwidth of the trans- mit signal. The number of chips in one symbol is often referred to as the processing gain or spreading factor Gp = T Tc, T being the symbol period; thus, the processing gain is the ratio of the spread bandwidth of the transmitted data to the data rate, and spreading      247   cid:2   8.1 Introduction  increases the bandwidth by a factor Gp. In addition, the processing gain allows the removal of up to Gp − 1 interfering signals of other users. Scrambling multiplies the bitstream of a physical channel by a user-speciﬁc PN sequence. This effectively prevents the data from being eavesdropped. Scrambling also changes the dc components of the bitstreams to zero, since the PN sequence is of zero mean. At the receive end, the received scrambled bitstream can be descrambled by using the same PN sequence. Scrambling is also used for wireless systems other than spread spectrum systems.  The use of spread spectrum modulation has a number of advantages such as resistance to eavesdropping, resistance to multipath fading, interference rejection and multiple access capabilities. As opposed to TDMA and FDMA, in CDMA all the cells can use the same frequency. The capacity can be increased by adding some cells without modifying the frequency scheme in existing cells.  CDMA cellular systems employ universal frequency reuse. Any technique that reduces multiple-access interference leads to a capacity gain. For voice communications, voice activity detection and speech coding can reduce MAI, and this leads to a signiﬁcant capacity increase over TDMA systems.  PSD of the DS-CDMA signal  The power spectrum of an inﬁnite random sequence of data d t  with rate R = 1 T bits s is given by  The power spectrum of the spreading sequence p t  is the same as that of the spread sequence d t p t , and is given by  SD f   = T  sin πfT  πfT   cid:2    cid:2   .   cid:3 2  cid:3 2  Sss f   = 1 fc  sin πf  fc  πf  fc  ,   8.1    8.2      SD f  Sss f   100  10−1    f      S  10−2  10−3  10−4    −6   cid:2 Figure 8.1  −4  −2 −1  1  2  4  6  0 fT   Power spectrums of narrowband and CDMA signals.      248   cid:2   Spread spectrum communications  where fc = Gp T = GpR. Thus, a narrowband waveform is spread over a wider bandwidth.  Example 8.1: Given Gp = 4, the PSDs of a narrowband signal and the corresponding DS- CDMA signal can be calculated by  8.1  and  8.2 . They are plotted in Fig. 8.1. Clearly, the bandwidth of the DS-CDMA signal is four times that of the narrowband signal.  8.2 Spreading sequences  8.2.1 Properties of spreading sequences  A spreading sequence, c = {ck}, is a periodic deterministic sequence with a period N. The duration for each ck is the chip period Tc. The spreading sequence is used to generate a spreading waveform by applying a real chip amplitude shaping function that has a peak amplitude of unity. Given a symbol duration T, the chip duration Tc should be selected so that T is an integer multiple of Tc, and the processing gain or spreading factor Gp = T Tc. When Gp = N, the code is a short code, and each data symbol is spread by a full period of the spreading sequence. When Gp  cid:5  N, the code is called a long code, and each data symbol is spread by a portion of the spreading sequence. In the following, the use of short code is assumed, and for this reason Gp is usually replaced by N.  The length of a code is the period of the code, GpTc. Putting it another way, there are Gp chips in a code. Two codes, ci and cj, are said to be orthogonal if their cross-correlation function  CCF  over the period is equal to zero:  CCF i, j  =  GpTc  ci t cj t dt = 0,  for all i  cid:18 = j.   8.3    cid:14   0  Orthogonality allows multiple information streams to be multiplexed for transmission.  De-spreading is a process of data recovery from the composite spread spectrum signal by applying the same CDMA code that is used for spreading. In order to obtain the original data by correlation, the autocorrelation function  ACF  of the spreading sequence should be a Dirac delta function. For a spreading sequence p t , the desirable ACF at time iTc is given by   cid:15   ACF i  =  i = 0 otherwise  .  Gp, 0,   8.4   For nonorthogonal spreading sequences, the receiver achieves a ﬁnite interference suppres- sion by a factor ACF CCF.  For spread spectrum systems that use long codes, accordingly, partial period ACF and CCF can be deﬁned over a portion  Gp chips  of the long codes; partial period ACF and CCF are dependent on the delay and the starting point of the subsequence. The partial period correlations are difﬁcult to analyze, and are usually treated statistically.      249   cid:2   8.2 Spreading sequences  Selection of the spreading code is based on three factors: autocorrelation, cross-  correlation, and the number of codes.   Good autocorrelation property helps to despread the original code perfectly, and to mit- igate the ISI. It is also useful for synchronization and reduction of interchip interference in a rake receiver.   Desirable cross-correlation property is that all the codes are orthogonal to one another so that all the other users’ information is demodulated as noise at the receiver. For unsyn- chronized systems, orthogonality must be guaranteed between the codes with arbitrary delays.   The number of codes is also important since all the users in a cell and its surrounding cells must have different codes to identify them. A large number of codes can support more users.  For the uplink of CDMA systems, the popular spreading sequences are the m-sequence, Gold sequence, and Kasami sequence. These sequences have a good cross-correlation property between their time-shifted versions. The m-sequence has a good ACF property, and also has 2m − 1 codes. The Gold sequence is obtained by combining a subset of m-sequence, and has 2m + 1 codes. The Kasami sequence can have a great number of codes. For the downlink, the Walsh-Hadamard codes can be used, since signals of different users can be synchronized before transmission.  Among popular spreading sequences, the m-sequence, Gold code, and Kasami code have nonzero off-peak autocorrelations and crosscorrelations; the Walsh code and the orthogonal Gold code are orthogonal only in the case of perfect synchronization, but have nonzero off-peak autocorrelations and cross-correlations in the asynchronous case. The Barker sequences are specially designed sequences that have almost ideal aperiodic ACFs. Complementary codes are a kind of orthogonal codes.  There are also some codes with good autocorrelation properties [11]. These codes are useful as reference signals for synchronization, channel estimation, or channel sounding. For example, the Zadoff-Chu sequence is used as uplink reference signal in LTE.  8.2.2 Pseudo-noise sequences  PN sequences can be used as codes. Although different PN sequences of a given length are not completely orthogonal to one another, they can be easily generated by a PN code gen- erator. PN sequences are typically generated using a maximal length shift register  MLSR , hence the generated PN sequence is also called MLSR sequence or m-sequence. The MLSR sequence generator is shown in Fig. 8.2. At each time instant, the register right-shifts its content by one bit. The output sequence an is given by  an = c1an−1 + c2an−2 + ··· + cran−r = r cid:26   cian−i,   8.5   i=1  where c1, . . . , cr are connection weights with 1 for connection and 0 for no connection, and all ai’s are the bits in the register. The addition is a modulo-2 addition. For an m-stage shift register, the period of the generated sequence is at most 2m − 1.      250   cid:2   Spread spectrum communications  an−1  an−2  c1  c2  an−r  cr   cid:2 Figure 8.2  an  MLSR sequence generator.  The m-sequence always has an odd length N = 2m − 1. It satisﬁes the three properties of a random sequence or a large PN-sequence [22, 63]:   Balance of 1 and 0: Out of the length 2m − 1, 2m−1 bits are 1 and 2m−1 − 1 bits are 0, since the case of all zero bits is eliminated;   Run-length property: The probability of n continuous 0 or 1 is 1 2n, for n ≤ m − 1, and 1 2m−1 for n = m;   Shift property: If the sequence is shifted by any nonzero number of elements, the result- ing sequence has half of its elements the same as in the original sequence and half different from the original sequence.  In addition, the m-sequence has the shift-and-add property: If we shift a sequence of length 2m − 1 by r bits, r < 2m − 1, we obtain an m-sequence with a different initial vector. The modulo-2 addition of the original and the shifted m-sequences leads to a new m-sequence. The m-sequence is a type of cyclic code, and it is generated and characterized by a generator polynomial, and can be analyzed by using the algebraic coding theory. The m- sequence of period N has an autocorrelation property that is very close to the desirable case   cid:15    8.6  where k is any integer. The normalized ACF i  = ACF i  ACF 0  is very close to the delta function δ i  for large N. Thus m-sequences are ideal for minimizing the ISI effect. Their cross-correlation is very small. For the m-sequence, the suppression factor ACF CCF = N. The power spectrum of the m-sequence is derived by taking the Fourier transform of the  ,  ACF i  =  i = kN i  cid:18 = kN  N, −1,  ACF of the waveform a t . It is derived as     Sa f   =  N+1 N2 sinc2  fTc  , 1 N2 ,  f = i f = 0  NTc  , i  cid:18 = 0  .   8.7   The ACF and PSD for the m-sequence are plotted in Fig. 8.3. Usually, the length of the m-sequence is selected as N = T Tc, so that the spreading code is a short spreading code since the repetition of the autocorrelation leads to a peak every symbol period. These short-periodic peaks yield signiﬁcant ISI from multipath components in the ﬁrst few symbols after the desired symbol. This can be avoided by using a long spreading code, where N  cid:7  T Tc. When a long spreading code is used, the demodulation      251   cid:2   8.2 Spreading sequences  Table 8.1. Properties of m-sequences. Adapted from [53] c cid:2 1980, IEEE.  N = 2m − 1  Number of m-sequences  ACF  5 9 11 23 41 95 113 383 287 1407 ≥ 703 ≥ 5631 ≥ 2047 ≥ 4095  t n   5 9 9 17 17 33 33 65 65 129 129 257 257 513  m  3 4 5 6 7 8 9 10 11 12 13 14 15 16  7 15 31 63 127 255 511 1023 2047 4095 8191 16383 32767 65535  2 2 6 6 18 16 48 60 176 144 630 756 1800 2048  0.2  0.15    f      a S  0.1  0.05  8  6  4  2  0  F C A  −2  −3 −2  cid:2 Figure 8.3  −1  0  i   N  1  2  3  −2  −1  0  1  2  3  0 −3  i   N ACF and PSD for an m-sequence waveform, N = 7.  is taken over a partial period T = GpTc  cid:5  NTc, where Gp is the processing gain. This partial-period autocorrelation can roughly attenuate ISI by a factor of Gp [20]. For each m, there exist a pair of m-sequences with three-valued CCFs, −1, −t m , t m  − 2, where   cid:15   t m  =  2 m+1  2 + 1, 2 m+2  2 + 1,  for m odd for m even  .   8.8   Such a pair of m-sequences is called a preferred pair of m-sequences. In other cases, the CCF peak is higher.  Table 8.1 lists some properties of m-sequences. The number of m-sequences for an MLSR of length m is given in [56]. This number is much smaller compared to its sequence      252   cid:2   Spread spectrum communications  length, and cannot provide a sufﬁcient number of codes for CDMA systems. Also, the maximum cross-correlation levels are too large. Thus, m-sequences are not used alone in CDMA applications. The shift-register connections for generating m-sequences with m = 2 to 34 are listed in [15, 49].  8.2.3 Gold sequences  The Gold code [19] is generated by using the preferred pairs of m-sequences by a process of all possible cyclically shifted modulo-2 additions of the preferred pair. The m-sequence family has one such unique preferred pair for each sequence length; the preferred pairs have good correlation properties. Due to the use of the preferred pair, both the autocorrelations and cross-correlations of Gold codes take on the values {−1,−t m , t m  − 2}, where t m  is given by  8.8  [24]. Gold codes have lower peak cross-correlations than m-sequences, but have worse autocorrelation properties than m-sequences. The family of the 2m−1 derived sequences plus the preferred pair are collectively known as Gold codes; there are all together 2m + 1 Gold codes of code length 2m − 1, for two m-sequences of order m. Like the m-sequence, all the 2m+1 Gold codes are balanced, with 2m−1 ones and 2m−1 − 1 zeros. The autocorrelation property of the spreading codes can effectively eliminate ISI. In [2], minimum autocorrelation spreading codes were designed for this purpose. The Gold code has been extensively used in spread-spectrum communication systems, such as in IS-95, WCDMA, and UTRA-TDD standards as the scrambling code, and in satellite systems such as the GPS and NASA’s Tracking and Data Relay Satellite System  TDRSS .  Orthogonal Gold codes  The cross-correlation of the Gold codes is −1 for many code offsets. By attaching an additional 0 to the original Gold codes, the cross-correlation can turn to 0. A total of 2r orthogonal Gold codes can be obtained by zero-padding from a preferred pair of two r- stage MLSRs.  Orthogonal Gold codes have the same cross-correlation property as the Walsh codes of the same length, but have better characteristics in terms of autocorrelation. The orthogonal Gold code is desirable when the code’s auto-correlations must be low to avoid falsely registering the main peak of the autocorrelation function [24]. Orthogonal Gold codes of length 256 chips have been used in WCDMA for fast cell search.  8.2.4 Kasami sequences  The Kasami sequences [29] have properties similar to the preferred pairs of m-sequences and are also derived from m-sequences in a fashion similar to the generation of the Gold sequences. Consider two m-sequences of periods 2m − 1 and 2m 2 − 1 that are gener- ated from two preferred polynomials p1 x  and p2 x , which are of order m and m 2,      253   cid:2   8.2 Spreading sequences  respectively. The set of Kasami sequences is generated by using the long sequence and the sum of the long sequence with all 2m 2 − 1 cyclic shifts of the short sequence. Thus, the number of Kasami sequences is 2m 2, each with a period of 2m − 1. This is the small set of Kasami sequences. The small set has 2m 2 binary sequences of 2m − 1 for m even. For the small set, Kasami codes achieve the Welch lower bound for autocorrelation and cross-correlation for any set of 2m 2 sequences of length 2m − 1 [20, 24, 56]. The off-peak autocorrelation and cross-correlation of the Kasami sequences are also three-valued {−1,−t m , t m −2}, with  8.9   t m  = 2m 2 + 1.  The large set of Kasami sequences includes both the small set of Kasami sequences and a set of Gold sequences as its subsets. The autocorrelation and cross-correlation properties of the large Kasami set are inferior to those of the small Kasami set, but the large set has a large number of sequences. In WCDMA, the uplink short scrambling code is a complex code c = cI + jcQ, where cI and cQ are two different codes from the extended very large Kasami set of length 256. The uplink long scrambling code is based on the Gold sequence, and the downlink scrambling code uses the Gold sequence.  8.2.5 Walsh sequences  ⎡⎢⎢⎣ Bn  ···  Bn  ⎤⎥⎥⎦ .  ... ··· ...  Bn ···  Bn  Bn+1 =  The Walsh codes, also known as the Walsh-Hadamard codes, are generated by rearranging the Hadamard codes; they are orthogonal to one another. The K-bit Walsh codes can be generated recursively by using   8.10   The recursion starts from B0 = 0 or 1. Each row of the matrix can be used as a code. Thus, the length as well as the number of codes can be 2, 4, ··· , 2K. The Walsh code has a length of 2K. The correlation of two Walsh codes is nonzero only if the two codes are the same. The Walsh-Hadamard codes can be generated by using a Walsh-Hadamard sequence generator [63]. DS-CDMA with Walsh codes can support at most N = T Tc users. Walsh codes have perfect orthogonality. Unlike the aforementioned codes, which still have good orthogonality properties between their delay versions, the orthogonality of Walsh codes are destroyed by delay dispersion. In a multipath environment, even though the users are synchronous, multipath destroys the synchronism of the channel. Thus, when Walsh codes are used in a multipath channel, there will be interference between users. Equalization of the spreading codes can mitigate this interference.  A drawback of the Walsh code is that the codewords have poor autocorrelation prop- erties. By multiplying the Walsh codes with a scrambling code, better autocorrelation properties are achieved and the mutual orthogonal property is retained.      254   cid:2   Spread spectrum communications  In the downlink, Walsh codes are usually used so that different users can be separated completely. However, the number of Walsh codes is so limited that it is not enough for assignment to all the users in the cell as well as in the neighboring cells. This problem can be mitigated by multiplying the Walsh codes by a scrambling code, since the resulting code sequences are also orthogonal. In cellular networks, each BS uses a different scrambling code cs k  for cell identiﬁcation. Each user has a code that is obtained as a Walsh code cw u  k  multiplied by the scrambling code in its cell  cu k  = cw  u  k cs k .   8.11   In this case, the new code maintains orthogonality for synchronous signals and suppresses asynchronous signals like a random code. Walsh codes multiplied by different scram- bling codes appear to be noise to each other. This method is used in IS-95, WCDMA, and CDMA2000. The ﬁrst sequence in the Walsh code set is the all-zeros sequence. It gives the highest possible autocorrelation ACF n  = N − n, where N is the length of the sequence and n is the number of bit shifts. For this reason, the all-zero sequence is usually used as the pilot sequence.  8.2.6 Orthogonal variable spreading factor sequences  The orthogonal variable spreading factor  OVSF  codes are derived from the Walsh codes. These codes are of different lengths, and they are used for spreading when different users require different data rates.  The procedure for generating OVSF codes is shown by the graph of Fig. 8.4. At each  node of the tree, a code wk n  of length n generates two new codes by the rule  wk n  →  w2k−1 2n  = [wk n , wk n ] = [wk n ,−wk n ] w2k 2n   .   8.12    cid:15   The variable spreading factor is used for rate-matching.  The OVSF code is used in WCDMA with spreading factors of 4–512, and in TD- SCDMA with spreading factors of 1–16  1,2,4,8,16 . In WCDMA, downlink transmission  w1 2  =  1,1   w1 1  = 1  w2 2  =  1,−1   w1 4  =  1,1,1,1   w2 4  =  1,1,−1,−1   w3 4  =  1,−1,1,−1   w4 4  =  1,−1,−1,1   Graph for OVSF code generation.   cid:2 Figure 8.4      255   cid:2   8.2 Spreading sequences  at the peak data rate requires three channelization codes with a spreading factor of 4; that is, three-fourths of the code resources is allocated to a single user. In the uplink, an MS transmitting with the peak data rate is seen as a large interference, but does not affect the code resource availability of other intracell users. The OVSF code is also used in HSUPA. The multi-rate orthogonal Gold code that is generated by combining a Walsh code  generator and an orthogonal Gold code generator can also be used [24].  8.2.7 Barker sequences  A Barker sequence is a binary sequence whose off-peak values of its ACF are 1, 0, or −1. All the known Barker sequences  excluding their negations and reversals  are:  + + − + − ++ and + − −− + + + − + + + + − − + − + + + − − − + − − + − + + + + + − − + + − + − +  length 3 length 4 length 5 length 7 length 11 length 13  where a + sign stands for the positive pulse and a − sign for the negative pulse. The length-11 and length-13 Barker sequences have the best autocorrelation properties among all the binary codes [21]. Barker sequences are commonly used for word synchronization in paging systems, and the length-11 Barker sequence is also used in IEEE 802.11. In general, any sequence whose aperiodic autocorrelation reaches the lower bound, ACF = 1, is called a Barker sequence. The longest known quadriphase Barker sequence is of length 15 [21]. Polyphase Barker sequences up to length 36 have been reported in [16, 42, 43]. Quasi-Barker sequences achieve the peak aperiodic autocorrelation sidelobe level ACF = 1 only within a certain window centered at the mainlobe. Quasi-Barker sequences exist for all lengths. The best quasi-Barker sequences of a given length are those that achieve the largest window and can thus tolerate the highest degree of mis-synchronization. By exhaustive search, all the best biphase and quadriphase quasi-Barker sequences, with maximum window sizes, of lengths up to 36 and 21, respectively, are listed in [26].  8.2.8 Complementary codes  The Golay complementary sequences are sequence pairs for which the sum of the autocor- relation functions is zero for all nonzero delay shifts [17, 18]. The complementary codes used for CCK also have the property that the sum of their aperiodic ACFs are zero for all nonzero delays [56]. The orthogonal complementary codes  OCCs  [57] are orthogonal in both the synchronous and asynchronous cases, thus offering MAI-free operation. The OCCs can hardly be used in real systems due to the very small set size: Only G1 3 users can be supported for a processing gain of Gp. In comparison, the Walsh codes and OVSF  p      256   cid:2   Spread spectrum communications  codes are not truly orthogonal codes, since they possess very high out-of-phase ACFs and CCFs.  Unlike traditional CDMA codes that use a single code, the orthogonality of the OCC is based on a ﬂock of element codes. That is, each user is assigned a ﬂock of element codes as its signature code in an OCC-based CDMA system. The OCC is a truly perfect orthogonal code, since it provides zero out-of-phase ACFs and zero CCFs. These ACF and CCF properties make the rake receiver and power control unnecessary.  The OCC was considered in [7] for MC-CDMA  multi-carrier CDMA  based commu- nication systems. It has also found application in the TD-LAS  Large-Area-Synchronous  CDMA system [9, 34], which has been approved by 3GPP2 as an enhanced standard. In the TD-LAS CDMA system, pair-wise OCCs, called loosely synchronized  LS  codes, have been used as spreading codes of the users. The LAS code family is obtained by com- bining the LS code with a large area  LA  code. The ACFs of all LAS codes are ideal, and there exists an interference-free window  IFW  or a zero-correlation zone  ZCZ  in the CCFs of the access codes around the origin. The use of LAS code family achieves an intracell-interference-free cellular quasi-synchronous  QS -CDMA system with low intercell interference. The TD-LAS CDMA system is still at the developing stage. A systematic construction of many families of generalized LS codes has been proposed in [58].  CDMA systems implemented based on the OCCs have a number of advantages over the  current 3G CDMA systems [8]:   OCC-based CDMA is suitable for bursty trafﬁc. For detecting bits at the edges of a packet or frame, OCC-based DS-CDMA can yield zero partial CCFs.   In WCDMA, UTRA-TDD, and TD-SCDMA, the rate change can be made only in powers of two due to the application of the OVSF code. In OCC-based CDMA, the transmission rates can be continuously adjusted by simply shifting more than one chip  at most N chips  between two consecutive off-stacking  OS  bits. If N chips are shifted, OS spreading reduces to DS spreading, yielding the lowest data rate.   OS spreading also helps support asymmetrical transmission in the uplink and downlink by simply adjusting relative offset chips between two neighboring spreading modulated bits.   The same processing gain is applicable to all different transmission rates. For CDMA- based 3G systems that use the OVSF code, a slower transmission rate corresponds to a higher processing gain.  8.3 Direct-sequence spread spectrum  The spread spectrum scheme described thus far is DS-CDMA. It is widely used in cellular standards. In DS-CDMA, each user u is assigned a unique spreading code cu. The load of the system is deﬁned as the ratio between the number of active users K and the spreading factor N      257   cid:2   8.3 Direct-sequence spread spectrum    t   b    t   c    t   c   t   b  1  0  1  0  1  0  −1  0  −1  0  −1  0  0.5  0.5  0.5  1  1  1  1.5  1.5  1.5 t  2  2  2  2.5  2.5  2.5  3  3  3   cid:2 Figure 8.5  Spread waveform of a bitstream for a DS-CDMA system with BPSK modulation. The top ﬁgure is the bitstream, the middle ﬁgure is the spreading sequence, and the bottom ﬁgure is the spread sequence.  β = K . N When β = 1 the system is said to be fully loaded.   8.13   Example 8.2: For the data stream of each user, each symbol is ﬁrst spread by a spreading sequence of length Gp. Given a bitstream with BPSK modulation and Gp = 5, the spread waveform is plotted in Fig. 8.5.  8.3.1 DS-CDMA model  Uplink  When K active users transmit their information asynchronously over a common AWGN channel, the received signal at a single antenna of the BS can be modeled by  Aibi j ci  t − jT − τi  + n t ,   8.14   r t  = K cid:26   ∞ cid:26   i=1  j=−∞  where Ai is the received amplitude of the ith user, bi j  is the transmitted symbol of the ith user in jT ≤ t ≤  j + 1 T, T is the symbol period, ci t  is the signature waveform of the ith user, τi is the delay of the ith user, and n t  is AWGN with zero mean and a double-sided PSD of σ 2 W Hz.  Equation  8.14  corresponds to the case of baseband transmission. In cellular systems, the ﬁrst term on the RHS needs to be upconverted to the carrier frequency fc by multi- plying it by cos  2πfct  before transmission. At the receiver, the received signal is ﬁrst      258   cid:2   Spread spectrum communications  Data  symbols  Chip  waveform modulator  Bandpass  filter  Transmitted  signal  Spreading sequence  generator  cos 2πfc          cid:2 Figure 8.6  Functional block diagram of the DS-CDMA transmitter at the MS.  downconverted by multiplying it by cos  2πfct + φ , where φ is matched to the carrier phase arising from channel delay. The functional block diagram of the DS-CDMA trans- mitter at the MS is shown in Fig. 8.6. After the sum signal is received at the BS, it is ﬁrst downconverted to the baseband, and each user’s bitstream is then extracted from the sum baseband signal by correlating with the user-speciﬁc scrambling and spreading codes and demodulation. When all τi, i = 1, . . . , K, are the same, that is, all users’ signals arrive at the BS at the same time, we get a synchronous CDMA system. In this case, we can take τi = 0. The signature waveforms have the properties  for t  ∈ [0, T],  ci t  = 0,  cid:14   T  i dt = 1 c2  0   8.15    8.16   for all i. Assuming that short codes  N = Gp  are used, the signature waveform can be represented by  where Pc t  is a rectangular chip waveform of duration Tc = T N, that is, Pc t  = 1    cid:20    8.17  √ Tc, is the normalized spreading  ci t  = N−1 cid:26  for t ∈ [0, Tc], and 0 otherwise. Thus, ci = cid:19  denoted by g t . For rectangular pulses, g t  = √  sequence assigned to the ith user.  k=0  period.  ci,kPc  t − kTc  ,  ci,0, . . . , ci,N−1  Pulse shaping is usually applied to the spread sequence. The pulse shaping function is 2 T, 0 ≤ t ≤ T, T being the symbol  Downlink  The functional block diagram of the DS-CDMA receiver at the MS is depicted in Fig. 8.7. The received signal at the MS is the sum signal transmitted by the BS, which has the same form as in  8.14 . The sum signal is ﬁrst downconverted to the baseband, then descrambled and despread using the scrambling and spreading codes of that speciﬁc MS, and is ﬁnally demodulated to generate the bitstream for the MS.      259   cid:2   8.3 Direct-sequence spread spectrum  Bandpass  filter  Received  signal  Carrier synch.  cos 2πfc + φ   Synchronization  Spreading sequence generator  Chip synch.  Demodulator  Data  symbols  Symbol synch.   cid:2 Figure 8.7  Functional block diagram of the DS-CDMA receiver at the MS.  By using a chip matched ﬁlter and sampling at the chip rate, the received signal during the jth symbol interval, jT ≤ t ≤  j + 1 T, is given by the discrete-time N-dimensional vector  Aibi j ci + n j ,   8.18   r j  = K cid:26   i=1  where r j  and n j  are N-vectors whose kth entries are obtained by integrating r t  over the kth chip period. So far, we have assumed that the short spreading sequence  Gp = N  is used in the DS- CDMA model, that is, the period of each periodic spreading sequence is the same as the symbol interval. In IS-95 and CDMA2000, the period of the spreading sequence is larger than the symbol interval  N > Gp , and such long spreading sequences are aperiodic. In this case, modiﬁcations to  8.14  and  8.17  are necessary. The matched ﬁlter is applied to the baseband signal obtained by despreading, ˆx t , and the symbols are obtained as   cid:14   0  ˆbl =  T  ˆx t  ∗ g  ∗   −t dt.  SNR = cid:4  cid:4 h l    cid:4  cid:4 2 Es  ,  N0   8.19    8.20   For single-user cellular systems with ﬂat-fading channels, the SNR is the same as that  for the narrowband case  where l corresponds to the symbol index. Spread spectrum gives no advantage in this case [32]. The spread bandwidth usually leads to a frequency-selective behavior of the mobile channel. The rake receiver is used to overcome the frequency-selective fading.  8.3.2 Conventional receiver  The conventional single-user CDMA receiver at the BS uses a bank of matched ﬁlters that are matched to the user spreading waveforms. For each user, the received signal is descrambled using a different PN code, then correlated with its spreading code, and ﬁnally sampled at the symbol rate.      260   cid:2   Spread spectrum communications  The received signal for a symbol period can be expressed in the matrix form  r = SAb + n,   8.21  where r is an N-dimensional vector, S contains all signatures, S = [cl c2 . . . cK], A = diag  A1, A2, . . . , AK  , b =  b1, b2, . . . , bK  T, and n is the noise vector. For the synchronous CDMA channel, the output of the matched ﬁlter is given by   8.22  where y is a K-dimensional vector, y =  y1, y2, . . . , yK  T. The matched ﬁlter output for user u is given by  y = SHr = SHSAb + SHn,  cid:14   yu = cH  u r =  T  0  r t cu t dt,  u = 1, . . . , K.  For orthogonal codes, SHS = IK×K, thus  8.22  reduces to  y = SHr = Ab + SHn.  A decision of the symbols can be made based on this equation. For BPSK modulation, decision can be made by using the signum function. For an M-ary constellation, due to the Pb, where P is the power of all the  received signals. The decision is just the same as the demodulation of the constellation.  PIK×K, and y ≈ √  application of power control, A = √ where the crosscorrelation matrix R = SHS = cid:19   For nonorthogonal codes,  8.22  can be expressed by  cid:20  y = RAb + n1,  cid:14  Rij  is given by   8.25    8.23    8.24    8.26   Rij =  T  0  ci t cj t dt,  and n1 = SHn. A decision on the user data can then be made based on yk. This matched ﬁlter structure is simple, but the performance is highly dependent on the power of each user and the cross-correlations between the code waveforms with random delays. In frequency-selective fading channels, the conventional receiver is simply a rake receiver.  8.3.3 Rake receiver  Multipath signals cause signiﬁcant ISI in TDMA systems, and a time-domain ﬁlter called an equalizer is usually used to minimize the ISI. Unlike in other systems, in DS-CDMA systems the multipath signals can be employed to advantage by using the rake receiver [48]. Only when the multipaths can be differentiated can they be made use of by the rake receiver. Spectrum spreading facilitates the situation by making the multipath copies resolvable. As long as the relative time delay between two multipaths is greater than Tc, each multipath is separable. According to the delay and addition property of PN-sequences,      261   cid:2   8.3 Direct-sequence spread spectrum  the different delayed versions of the signal are almost noncoherent. Multipath delays can be obtained by searching the pilot sequences.  With coherent demodulation, an increase in the number of independent Rayleigh multi- paths L leads to a better performance. For multipaths of ﬁxed amplitudes and phases, the desirable performance bound is the same as that for the case of a single component, assum- ing that the energy of the single component and the total energy of all the multipaths are the same [63]. In this case, the rake receiver, like the matched ﬁlter, combines the transmitter ﬁlter and the multipath channel.  Analysis indicates that as the number of Rayleigh multipaths increases, the performance of the system approaches that of nonfading propagation [63]. This is the advantage of diversity.  Structure of rake receiver  A rake receiver consists of a bank of correlators  matched ﬁlters , each synchronized with a different multipath of time delay τ . The outputs of these correlators are then weighted and combined. Thus, a rake receiver is actually a tapped delay line ﬁlter, and is also a diversity receiver. A BS typically deploys a four-ﬁnger rake receiver: According to the ITU Pedestrian-A channel model, only four multipath components carry energy. When a path has a delay τi relative to the delay the rake ﬁnger is tuned to, the rake receiver with nonideal spreading sequences suffers from interpath or interchip interference.  The MRC strategy can theoretically obtain the optimum weights for the rake receiver. This requires that each resolvable multipath component is assigned a rake ﬁnger. Given τmax to be the maximum delay of the channel, τmax Tc taps are required, where each mul- tipath component is assumed to be at an integer multiple of a chip period. In outdoor environments, the number of taps may be very large, and for the reason of implementation, we have to select a subset of the resolvable multipaths before applying MRC. The principle of the rake receiver is shown in Fig. 8.8. In the ﬁgure, c t  is the spreading code, bl is the symbol transmitted over the symbol period [lT,  l + 1 T], and bm is the symbol transmitted over the symbol time [lT − mTc,  l + 1 T − mTc], which is assumed to be constant.  l  r      t  MRC  b l  0 b l  b  1 l  M b l      c t  c             t −T c  Matched  filter  Matched  filter  Matched  filter  c                t − MT c   cid:2 Figure 8.8  Principle of the rake receiver.      262   cid:2   Spread spectrum communications  DDC output  I  Q  MRC  I  Q  Correlator  I  Q  Fine finger tracking  Code  generation   Channel   estimation  Phase rotation  Delay  equalization  I  Q  I  Q  N  Rake finger 1   cid:2 Figure 8.9  Implementation of the rake receiver. DDC stands for digital down-converter.  Path searcher  The architecture for implementing a rake receiver is shown in Fig. 8.9. Oversampled baseband I and Q signals are fed to each ﬁnger from a digital down-converter output, and also fed to the path searcher. The path searcher despreads the received data by using correlations with different time delays of the code. The range of time delays is decided by the radius of the cell plus allowed delay spread. The peaks in the correlation correspond to strong multipath signals. A peak detection threshold is set for selecting the suitable peaks. For each peak, its associated time delay is forwarded to a ﬁnger for further processing. This timing information is used for code generation and code synchronization at the rake and also allows the rake to lock on a multipath. The path searcher is usually computationally more expensive than the rake.  The incoming data is multiplied by the despreading code, and this result is integrated to produce symbols. The data is processed at the oversampling rate, and this leads to phase rotation in the symbol data. Phase rotation can be removed by using phase data from the channel estimation that is based on the pilot information. The ﬁnger then tracks any small change in the time delay of the path with the feedback loop controlled by the ﬁne ﬁnger tracking function. I and Q signals are generated from the correlator periodically on 1 4 chip earlier or later of the code assigned by the path searcher. The early and late correlations are examined so as to correct the timing of the path. Finally, a rake combiner, usually using the MRC strategy, is used to combine the active outputs so as to maximize the SNR.  The rake receiver achieves the optimum performance when there is no ISI. That is, the maximum delay τmax must be smaller than T. When there is ISI, an equalizer can be applied to the rake receiver output, which is sampled at intervals T. The combination of rake receiver and equalizer can also be replaced by a chip-based equalizer, which is opti- mum but most complex for implementation. When smart antenna technology is combined with the rake receiver for a CDMA system, we get a space-time processing system [10, 36]. Two CDMA beamforming rake receiver schemes are given and compared in [5, 36].  IS-95, WCDMA and CDMA2000 use the rake receiver, but not multiuser detection  MUD . This is because the spreading factor is too large and the computational load grows      263   cid:2   8.3 Direct-sequence spread spectrum  exponentially with the spreading factor for MUD. MUD is applied in TD-SCDMA, since the maximum spreading factor is 16 and thus the computational complexity is tractable. A typical TD-SCDMA system uses a circular array with eight antennas.  8.3.4 Synchronization in CDMA  For CDMA systems such as IS-95, it is reasonable to achieve time synchronization before accurate phase and frequency are obtained. In principle, matched ﬁltering or cross- correlation is the optimum method for initial synchronization. The timing acquisition process is based on the autocorrelation of the spreading sequence. Since all periodic spread- ing sequences have an autocorrelation that peaks at zero delay, the synchronizer adjusts its estimate of the delay to maximize the autocorrelation output of the integrator. A sharp autocorrelation function facilitates ﬁne synchronization.  The sliding correlator is usually implemented in discrete time intervals of 1  2 Tc; it corre- lates the received signal with the known synchronization sequence, over the time interval of NTc, until the correlator output exceeds a threshold. When timing acquisition is achieved with τ = 0, to account for frequency error  cid:18 f , the signal error is scaled by a factor, which is approximated by [63]   cid:5   D  cid:18 f   =  sin πN cid:18 fTc   πN cid:18 fTc   cid:6 2  ,   8.27   where N is the spreading factor. This signal deteriorating factor is small when N cid:18 fTc is small.  After timing acquisition achieves a timing error of a small fraction of Tc, timing tracking must be applied to further reduce the error to zero. This is achieved by using the delay- locked loop  DLL , which is very similar to the early-late gate circuitry. Once timing is accurately obtained, phase and frequency can be accurately estimated by using the PLL technique.  The pilot sequence is very important for CDMA systems. It is a nonmodulated signal.  The pilot signal is shared by all the users, and it has a strong power.  8.3.5 Power control  Power control is necessary to reduce CCI, and is implemented in most cellular standards in some form. The DS-CDMA system has the problem of the near–far effect, which mandates implementation of power control to limit the amplitudes of user signals so as to maintain orthogonality and system capacity. Power control can also reduce the interference to other systems, and reduce the power consumption at mobile terminals. Power control is a critical aspect of CDMA-based cellular systems.  Before an MS establishes a connection with the BS, it cannot be power-controlled by the BS. The initial transmission power of the MS is estimated from its nominal power, its current power, and the received power from the BS. Power control can take an open-loop      264   cid:2   Spread spectrum communications  or closed-loop form. Open-loop power control can compensate for slow-varying and log- normal shadowing effects, whereas closed-loop power control can compensate for power ﬂuctuations arising from fast Rayleigh fading, which is frequency-dependent and occurs over every half-wavelength.  In open-loop power control, the sum of the downlink and uplink powers  in dB  is main- tained constant. Open-loop control is based on AGC, but the powers of different MSs can differ by several dB at the BS. Power control is based on the SIR Eb I0 measured at the BS. For IS-95, Eb I0 measured at the BS should be in the range of 3 to 7 dB [63]. The BS transmits power control instructions to the MS to increase or decrease its power. Eb I0 in dB is normally distributed with a large standard deviation in case of a fading channel. A closed-loop power control is necessary to help reduce the standard deviation to typically within 1.5 to 2.5 dB [63].  Power control is performed via the uplink and downlink transmissions of power control instructions over the trafﬁc channel. These power control bits are usually not error- protected so as to avoid delays due to decoding. Power control is more stringent on the uplink than on the downlink. The MS has to report the quality of the downlink to the BS. In the case of closed-loop power control during soft handoff, the MS receives from two or more BSs power-control instructions that may be conﬂicting. The rule for handling this is to power down the MS if any of the BSs commands to power down and to power up the mobile only when all the BSs command to power up.  For downlink power control, open-loop control is sufﬁcient, as power control in the downlink does not affect the functioning of the system. Uplink power control is rather crude, usually ±6 dB around its nominal value for IS-95. In IS-95, fast closed-loop power control is applied to the reverse link at a rate of one instruction per frame. Open and fast closed-loop power control schemes are supported in both the reverse and forward links in CDMA2000, WCDMA, UTRA-TDD, and TD- SCDMA, with a speed of up to 800 Hz, 1,500 Hz, 100 Hz, and 200 Hz, respectively. In GSM, power control loops run at 2 Hz. WiMAX also supports closed-loop power control for the uplink, but leaves the downlink power control to the manufacturer.  8.3.6 Soft handoff  In CDMA systems, all the BSs use the same frequency. Thus, an MS can transmit to and receive from two or more BSs. The received signals from multiple BSs constitute multipaths, and can be used to improve the performance.  Soft handoff is an important feature of CDMA systems, and it also has signiﬁcant impact on power control. Unlike hard handoff used in GSM, an MS receives and transmits signals from and to two or more BSs. Signals coming from different BSs have different delays, and these signals can be combined by using a rake receiver. Due to the use of diversity, soft handoff signiﬁcantly increases the performance while the MS is on the border of two cells. Soft handoff can improve coverage by a factor of 2 to 2.5 in cell area, thus lead- ing to a reduction in the number of BSs by this factor [62]. The reverse channel capacity is also increased by a factor greater than 2 [62]. However, the MS must use the Walsh      265   cid:2   8.4 Multiuser detection  codes in the multiple BSs at the same time. It also requires a lot of signaling during handoff.  To implement soft handoff, each cell or sector transmits in the downlink simultaneously its speciﬁc pilot signal and its user signals. For synchronous CDMA, all BSs use the same pilot code and they are distinguished by using different phase shifts of the same pilot, while for asynchronous CDMA, each BS is assigned a distinct scrambling code. The pilot PN- sequence signal can be added to the user signals, or it is multiplied with each of the user signals. All the pilot PN sequences can use the same m-sequence but with different initial vectors. The pilot signals are used by MSs for handoff implementation.  When the searcher ﬁnds a new, sufﬁciently strong pilot signal, the MS reports to its original BS. The BS then reports this to the switching center, and the switching center instructs the new BS to transmit and receive signals from the MS. The MS communicates with two BSs at the same time, with the same information. The rake receiver at the MS combines the signals from the two BSs, just as in the case of processing multipaths with different time delays.  Soft handoff improves the system performance, but at a cost of consuming more spec- trum resources. Soft handoff can help increase the capacity of a heavily loaded cell by making use of the neighboring cells. For a given outage probability Pout, the transmit power should be above a threshold γ dB; for soft handoff, the required threshold is 6 to 8 dB, which is several dB less than that needed for hard handoff [63]. This leads to an increase in the cell size by a factor of two or more. Thus, soft handoff supports a larger capacity than hard handoff does.  During soft handoff, the second BS must transmit the same information as the ﬁrst BS does. When the power of the second BS received at the MS is 6 dB less than that from the ﬁrst BS, the second BS is activated. This ﬁrst BS continues to communicate with the MS, until its power received at the MS is 6 dB less than that from the second BS. Thus, during soft handoff, there is more interference caused to the other users.  In IS-95 or CDMA2000, each BS transmits the same PN-sequence as a pilot signal, but with an offset of 64 chips from each other. The pilot signal is a PN sequence of 32,768 chips, or 26.7 ms. This can be used to estimate the signal strengths of all the surrounding BSs. WCDMA supports soft, interfrequency, and inter-RAT handoffs, where RAT stands for radio access technology, such as GSM, CDMA2000, or UTRA-TDD.  TD-SCDMA employs baton handover, which takes advantage of both hard and soft handoffs. Baton handover, which is similar to the procedure of handing over a baton in a relay, depends on the user positioning capability provided by TD-SCDMA BSs using smart antenna technology.  8.4 Multiuser detection  8.4.1 Introduction  In the conventional CDMA system, MAI and multipath fading  ISI  are mitigated by rig- orous power control in conjunction with single-user rake receivers. The rake detector [48]      266   cid:2   Spread spectrum communications  effectively combats multipath fading by coherently combining resolvable multipath repli- cas of the desired signal; but it is based on the assumption of path resolvability, which is not always true. The rake structure is not ﬂexible for multiuser solution. The rake receiver also does not make use of the inherent diversity of the spread spectrum. MAI is caused by cochannel signals that are not orthogonal to the desired signal, and is reduced by strict power control. Power control instructions also consume frequency spectrum and the performance is unsatisfactory.  In a multiple-access channel such as a CDMA channel, MUD, also known as multi- user equalization or joint detection, can be applied to detect the data of the users. MUD improves the data detection process by exploiting the cross-correlation among the signals to be demodulated. By using MUD, receivers can effectively reduce the inﬂuence of the near–far effect, i.e., MAI or CCI, as well as ISI due to multipath delays [10]. When using MUD in CDMA systems, interference signals are not treated as noise, instead their spread- ing codes are used to mitigate MAI. MUD has become a key technique to overcome the effects of MAI and multipath fading, thus substantially increasing the capacity of CDMA systems.  MUD is typically not used on downlink channels, since downlink channels are syn- chronous and all interference is typically eliminated by using orthogonal codes. Also, the power consumption and complexity of MUD make it impractical for its implementation in MSs.  MUD achieves a BER performance that greatly exceeds that of the conventional correlator-based receiver. The optimum MUD receiver [59] is an MLSE receiver, which is based on the ML or MAP criterion. The Viterbi algorithm is a well-known, efﬁcient MLSE algorithm. The complexity of such algorithms grows exponentially with the number of users.  Many low complexity MUD algorithms, such as the linear MUD and iterative MUD algorithms, are available. The linear MUD algorithm applies a linear transformation to the matched ﬁlter outputs to reduce the MAI effects on between them. The decorrelating and MMSE detectors are two popular MUD algorithms. The matched ﬁlter detector is a sim- ple example of the linear MUD algorithm. The serial interference cancellation  SIC  and parallel interference cancellation  PIC  algorithms are two simple, nonlinear MUD tech- niques. The turbo MUD technique is a nonlinear, iterative MUD algorithm, and it is used in the context of the convolutionally encoded multiple-access channel. It uses soft decision strategies to reduce the probability of error propagation. The turbo MUD algorithm can approach the performance of the MLSE MUD algorithm.  For IS-95A networks, the voice capacity per cell is about 20 to 25 users. CDMA2000 1x increases it to 35 to 40 users. In 3G standards, such as CDMA2000 and WCMDA, MUD has been speciﬁed as an option. This option will not be activated by most mobile commu- nications operators due to its complexity. In UTRA-TDD, each slot allows up to 8 codes for multiple access, while in TD-SCDMA each slot allows up to 16 codes; this requires a relatively small spreading factor. Since the computational complexity increases at least linearly with the spreading factor, MUD is supported easily in the two TDD modes. Only TD-SCDMA applies MUD as a mandatory part, and in the TD-SCDMA system the max- imum spreading factor is 16. In UTRA-TDD and TD-SCDMA, smart antenna technology with MUD was developed based on the algorithm given in [4].      267   cid:2   8.4 Multiuser detection  8.4.2 Optimum multiuser detector  The optimum multiuser detector performs joint MAP detection for all users based on the received sequence r. Mathematically, ˆb MAP = arg min b∈BK   8.28  where B is the symbol set, and the second equality is obtained by applying Bayes’s rule. The hypothesis ˆb is generally uniformly distributed, thus Pr b  is known at the receiver.  Pr bS, r  = arg max b∈BK  prb,S r  Pr b ,  In this case, joint MAP detection is equivalent to joint ML detection  ˆb  ML = arg max b∈BK  prb,S r .  The conditional pdf in  8.29  is a multivariable Gaussian function. By taking its natural  logarithm, the optimum MAP or ML detection algorithm is ﬁnally obtained as  ˆb = arg min b∈BK = arg min b∈BK = arg min b∈BK = arg max b∈BK  :2  9  cid:15 r − SAb cid:15 2  cid:14   r t  − K cid:26   T  0  k=1  bkAkck t   dt   cid:15 r cid:15 2 − 2rHSAb + bH SA H SA b 2rHSAb − bHARAb.   8.29    8.30   Note that the search space is the entire K-dimensional complex space, rather than a ﬁnite alphabet. Since b consists of discrete values, an exhaustive search is necessary. The complexity grows exponentially with the number of users and the length of the sequence. In general, the optimum MUD receiver for bit sequence consists of a bank of single-user correlators followed by a Viterbi algorithm, and the algorithm has a complexity per binary , K being the number of users. The optimum detector is based on the decision of O conventional matched ﬁlter detector, but the discrete decision device for each of the users is replaced by the joint Viterbi algorithm. This is illustrated in Fig. 8.10.   cid:8    cid:7   2K  Suboptimal MUD algorithms based on the genetic algorithm have also been given [12, 66]. The genetic algorithm-based MUD algorithm will be more practical when the  Matched filter bank  r    t  cos 2πfc+φ1   cos 2πfc+φK   MF  c    t1  MF  c    K t  Sampler  Sampler  b1  bK  Viterbi algorithm   cid:2 Figure 8.10  Optimum MUD detector based on MLSE.      268   cid:2   Spread spectrum communications  parallel hardware for the genetic algorithm is available. Nevertheless, the genetic algo- rithm provides a benchmark when the exact solution is computationally intractable. The optimum MUD can be resolved using the collective computational behavior of such neural networks as the Hopﬁeld network [30] or the cellular neural network [6]. Many subopti- mal algorithms have been proposed based on the criterion  8.30  using various optimization techniques such as the gradient descent and the genetic algorithm [25].  8.4.3 Linear multiuser detection  Linear MUD is very similar to linear equalization, and concepts like ZF and Wiener ﬁltering are usually used.  Decorrelation receiver  ˜b = arg min b∈BK   cid:15 r − SAb cid:15 2.  − SHr + SHSA˜b = 0.  The decorrelation receiver [37] is the ZF version of the multiuser detector. It searches the unconstrained vector b ∈ BK that minimizes the ML objective function [32]   8.31   to zero   8.32    8.33    8.35   By setting the derivative of the squared Euclidean distance with respect to ˜bH and applying the Wirtinger calculus ∂˜b ∂˜bH = 0  see Appendix B  , we have  From this, the ZF solution ˜bZF is obtained. For K ≤ N, S generally consists of linear  independent columns. The correlation R has a full rank and its inverse exists. Thus, the symbols can be estimated by  ˜bZF = A  −1R  −1y = b + A  −1R  −1SHn,  where   8.34  is the output of the receiver after despreading. For K > N, R−1 has to be replaced by the pseudoinverse R†.  The ﬁnal output is obtained by a hard decision,  y = SHr  cid:18    cid:17 ˜b  ˆb = Q  .  where Q is the quantization function.  Like the ZF equalizer, the decorrelation receiver leads to noise enhancement, which is determined by the conditioning of the correlation matrix, especially for high load β. In order to compute the optimal cross-correlation matrix, knowledge of all the user parameters is required. The noise covariance matrix is given by   cid:5  cid:17 ˜bZF − b   cid:18  cid:17 ˜bZF − b   cid:6    cid:18 H   cid:23 ZF = E  = σ 2 n R  −1,   8.36   where σ 2  n is the variance of n. For K > N, R−1 is replaced by pseudoinverse R†.      269   cid:2   For BPSK or QPSK modulation, the BER performance for the kth user is given by [59]  8.4 Multiuser detection  ⎛⎝   cid:21  cid:7    cid:8   kk  Ak R−1  σn  ⎞⎠ .  Pb,k = Q   8.37   MMSE receiver   cid:22    cid:23   .  b − ˆb2  is minimized [38]  Similarly to the MMSE equalizer, the MMSE MUD receiver targets at a balance between interference suppression and noise enhancement. The objective function to minimize is the MSE E  W = arg min W∈CK×N  For the linear MMSE MUD receiver, a linear transform W is applied such that the MSE   cid:23   cid:15 b − Wy cid:15 2 , where C denotes the complex space and W is a N × K matrix. Again, by setting the partial derivative of the squared Euclidean distance with respect to W to zero and considering the Wirtinger calculus ∂WH ∂W = 0, we have the well-known  cid:18 −1 Wiener solution. The ﬁnal result is given as [1]   8.38    cid:17    cid:22   E  WMMSE = A −1  R + σ 2 n A  −2  .   8.39   From this, the MMSE receiver can be treated as a tradeoff between the matched ﬁlter and → 0, the second term in the inverse is reduced, and a decorrelator decorrelator: If σ 2 → ∞, R is negligible, and a matched ﬁlter is n is obtained; at the other extreme, for σ 2 n obtained.   cid:22   The derived MMSE solution is given by   cid:23 −1 The estimate symbol vector ˆb is decided by quantizing ˜b.  cid:2  cid:17   R + σ 2 n A  cid:23   ˜b = A −1  cid:22   The MMSE is given by  −2  y.   8.40    cid:3    cid:18 −1  JMMSE = min W∈CK×N  E   cid:15 b − Wy cid:15 2  = trace  I + σ 2  n ARA  .   8.41   The total signal distortion for the MMSE receiver is much lower than that for the decor- relation receiver. The MMSE receiver exhibits an excellent performance, but it requires training data. Both the decorrelating detector and the linear MMSE detector achieve the optimal near-far resistance.  8.4.4 Serial parallel interference cancellation  The linear ZF and MMSE MUD receivers have a complexity that grows cubically with the system size in view of the need for the calculation of the matrix inverse of M,      270   cid:2   Spread spectrum communications   cid:15   M =  R R + σ 2  n A−2   ZF   MMSE    8.42  The calculation of M−1 is basically via the solution of a set of linear equations. The set of linear equations can be solved iteratively, and this yields the linear SIC and PIC algorithms. Linear SIC and PIC are decision-driven MUD algorithms.  .  Linear SIC  Application of the Gauss-Seidel algorithm to the set of linear equations leads to the SIC technique. The algorithm always converges for the Hermitian positive deﬁnite matrix M [23]. This is satisﬁed for CDMA systems.  The SIC receiver is a suboptimum but practical multiuser receiver [31]. SIC just detects users in the order of their signal strength. The signal of each user is subtracted from the total signal, based on which the next user is detected. Thus, the SIC receiver is a decision- feedback receiver. The SIC receiver is illustrated in Fig. 8.11.  In each stage of the SIC receiver, a conventional matched ﬁlter detector and an interfer- ence canceller are included. The ﬁrst stage estimates and removes the strongest user signal. The user signals should be detected from the strongest to weakest power to reduce error propagation. Sorting also leads to a faster convergence.  The SIC receiver simply performs a hard decision upon the kth user’s correlator as the  initial data estimate ˆbk, n, which is the estimate of bk, n, the kth user’s original transmitted data at time nTb. The estimate ˆbk, n is multiplied by its respective synchronized spreading  sequence and carrier signal to produce a replica of the original signal, which is passed through a transversal ﬁlter that emulates channel hk t . The CCI replica of each user is subtracted from the original received signal r 1  t  = r t  to produce the desired received signal of the user with the second largest power, denoted user m, and we obtain r 2  t . The signal r 2  t  is passed to a second set of correlators to estimate the data bits bm, n, of user m. A cascade of such CCI canceller and data decision stages will lead to a better BER performance.  y k  max  kb  r 1  t      cos 2 πfc+φ   Σ  r 2  t      Despreader  Despreader  Despreader  1  2  K  Rake  receiver 1  Rake  receiver 2  Rake  receiver K  y 1  y 2  yK  Channel  filter  Spreader  k  cos 2 πfc+φ   One stage of an SIC receiver.   cid:2 Figure 8.11      271   cid:2   8.4 Multiuser detection   cid:7    cid:8   The direct implementation of matrix inversion leads to a complexity of O  , while the iterative implementation has a complexity of O nK2 , where n is the number of itera- tions. As long as n < K, the iterative implementation always leads to a reduction in the computational cost.  K3  At each iteration, interference cancellation is implemented for all the K users. Because of the cascade structure, to reduce the bit delay, we need to limit the number of stages. Only a few of the strongest users are removed at these stages, and the ﬁnal out- put is input to a conventional matched ﬁlter detector to extract the remaining signals. The order of cancellation is based on the ranking of the power of the matched ﬁlter outputs.  The SIC receiver provides a BER performance that is much better than that of the con- ventional matched ﬁlter detector, especially for the near-far problem [33]. The SIC receiver suffers from error propagation, and this degradation can be improved by power control. In the adaptive SIC receiver, the interference canceller is adjusted by the LMS algorithm. This yields a more accurate amplitude estimate than the SIC receiver yields, and hence a much lower BER. The SIC technique can theoretically achieve the Shannon capacity, and practical SIC implementations can approach this capacity [61].  Linear PIC  Application of the Jacobi algorithm for solving the set of linear equations [23] leads to the linear PIC algorithm. The PIC receiver cancels all the users simultaneously. The method ﬁrst makes decisions for all the users based on the received total signal, and obtains ˆb0 k, k = 1, 2, . . . , K. These decoded user signals are then respread. For a given user k, all the other K − 1 users’ respread signals are treated as interferers, and are subtracted from the total signal. The remnant signal is then subject to the same pro- cedure, until the decision no longer changes or the prespeciﬁed number of iterations is reached.  The PIC receiver has a lower latency, but has a performance degradation due to the near- far effect. The convergence of the PIC depends highly on the eigenvalue distribution of M [32]. The convergence property is generally poor.  8.4.5 Combination of linear MUD and nonlinear SIC  The Bell Laboratories layered space-time  BLAST  scheme [13, 14], originally proposed for multiple-antenna systems, can be directly applied to CDMA systems, since both systems have a similar architecture  r = Sb + n.   8.43   For CDMA systems, this equation is obtained when strict power control is applied. The method ﬁrst uses a linear MUD stage to suppress the interference prior to the nonlinear SIC stage.      272   cid:2   Spread spectrum communications  At the ﬁrst step, the linear ﬁlter w1 is applied to suppress the interference of user 1. w1 is drawn as the ﬁrst column of W 1  = WZF or WMMSE, and   cid:18  ˜b1 = wH 1 r.   cid:17 ˜b1  .  ˜r2 = r − s1  ˆb1,  ˜b2 = wH  2  ˜r2.  The symbol is then obtained as ˆb1 = Q  By implementing interference cancellation, we have  where s1 is the ﬁrst column of S. The residual ˜r2 is then processed by a second ﬁlter w2, which is the ﬁrst column of W 2 , W 2  being the ZF or MMSE ﬁlter obtained by removing s1 from S. To suppress the interference of the second user, we have  This procedure is repeated until all the users have been detected. To avoid matrix inversions, QL decomposition can be applied [32].  The ML space-time multiuser detectors for ﬂat-fading channels and multipath fading channels are presented in [40] and [44]. Space-time MMSE multiuser detectors have been proposed in [10, 45]. MUD for CDMA systems has been extended to antenna arrays, and several space-time MUD algorithms are described in [64].  8.5 Bit error probability and system capacity  8.5.1 BER performance  The DS-CDMA system is an interference-limited system, where the noise is negligible compared with the interference from all the other users. By using the standard Gaussian approximation, the MAI is assumed to be a Gaussian random variable. For a synchronous K-user system with N chips in each symbol, in the downlink, the SIR at an MS receiver is given by [56]  If noise is considered, the SINR is accordingly given by  .  SIR = N K − 1  cid:2   + K − 1  N  N0 Es   cid:3 −1  .  SINR =  In the uplink, signals from different users travel through different channels, and this leads to the near-far effect, where different users have different powers at the BS receiver.   8.44    8.45    8.46    8.47    8.48       273   cid:2   8.5 Bit error probability and system capacity  Assuming random spreading codes with N chips per symbol, random start time, and random carrier, the average SINR for asynchronous users is given by [20, 50, 56]  For the interference-limited system, the SIR is given by   cid:2   SINR =  + K − 1  3N  N0 Es   cid:3 −1  .  SIR = 3N K − 1  .  The above equations for both the uplink and the downlink are known as the standard Gaussian approximations to SINR and SIR.  The calculated SIR can be used to replace γb in the error probability equations. For  example, the BER for asynchronous DS-CDMA with BPSK modulation is given by   cid:12  cid:31    cid:7 √   cid:8  = Q  γb   cid:13   3N K − 1  .  Pb = Q  The standard Gaussian approximation underestimates the BER performance when the number of simultaneous users K is small or the processing gain N is large. For practical systems, the SIR for nonrandom spreading codes can be approximated by  SIR =  3N  ψ K − 1   ,  where ψ is a constant, whose value depends on the system assumptions. For PN sequences, ψ = 2 or 3, depending on the system assumptions [20]. The improved Gaussian approximation proposed in [41] is much more accurate than the standard Gaussian approximation, but its complexity is too high. A simple but approxi- mate Gaussian approximation is given in [28], and the result is very close to that of the improved Gaussian approximation[41]. For BPSK signals, the BER performance for the AWGN channel is given by [28]   cid:12  cid:31    cid:13   Pb ≈ 2 3  Q  3N K − 1  + 1 6  Q  + 1 6  Q   cid:21   cid:21   ⎛⎝ ⎛⎝  cid:2   ⎞⎠ ⎞⎠ ,  3σ  3σ   cid:6   N   K − 1 N 3 + √  K − 1 N 3 − √  N   cid:3    cid:5   σ 2 =  K − 1   N2 +  23 360  + K − 2  36  1 20   N − 1   .  where  This result is very accurate for all values of K and N.   8.49    8.50    8.51    8.52    8.53    8.54       274   cid:2   Spread spectrum communications  b  P  100  10−2  10−4  10−6     Standard Gaussian Simple Gaussian  N= 7  15  31  63  10 1  K  N = 127     10 2   cid:2 Figure 8.12  BER performance for different K and N: Standard Gaussian approximation vs. simple improved Gaussian approximation.  Example 8.3: Based on the standard Gaussian approximation and the simple improved Gaussian approximation to the SIR, the BERs for the asynchronous CDMA system with BPSK modulation are given by  8.52  and  8.53 , respectively. These results are plotted in Fig. 8.12. It is seen than the standard Gaussian approximation is accurate for large K, but underestimates the BER performance for small K.  From the above equations, we can solve for the total number of active users for a given Pb or SINR. For speech communications, the voice activity occupies only about 3 8 of the call duration. Cell sectorization and smart antenna technology can be used to reduce the interference. All these can be used to increase the cell capacity. In a cel- lular network, interference from other cells should also be considered into the capacity analysis.  8.5.2 Uplink capacity  The uplink capacity in a cell depends on the user SNRs and the system matrix S. For an asynchronous CDMA system with strict power control, signals from other K − 1 users appear as interference at the kth user receiver. The sum capacity for K active users is derived as [1]  RCDMA = KRk ≈ 1.44B  bits s ,   8.55   where B is the signal bandwidth and Rk is the Shannon capacity of the kth user. Thus, the sum capacity does not increase with K.      275   cid:2   8.5 Bit error probability and system capacity  For the synchronous link with the individual codes being orthogonal to one another, when strict power control is implemented, the sum capacity of the K users is given by [1, 49]   cid:2    cid:3   Rk ≤ B log2  1 + KP BN0  K cid:26   k=1   bits s ,   8.56   where P is the average power of each user’s signal. Thus, the sum capacity of the CDMA system increases with K, as is the case for FDMA and TDMA.  In a cell, the average capacity per user is given by   8.57    8.58    8.59   where C is the average capacity of the cell.  The spectral efﬁciency is deﬁned as the average number of information bits transmitted  per chip  Cu = C K   bits s ,  η = C N  = βCu   bits s Hz ,  where β is deﬁned by  8.13 . Note that as the bandwidth of a DS-CDMA signal is approx- imately equal to the reciprocal of the chip duration, 1 bit chip is equivalent to 1 bit s Hz. If the code rate supported by each user is Rc bits symbol, the spectral efﬁciency is given by  η = KRc N  = βRc   bits s Hz .  For an M-ary modulation scheme, Rc = log2 M bits symbol.  In the case of orthogonal spreading codes that are used for synchronous CDMA trans- mission in ﬂat-fading channels, no MAI exists; thus, there are K independent, parallel data streams. Each stream has a capacity Cu determined by its SNR only. The spectral efﬁciency η linearly increases with β up to β = 1 for a ﬁxed SNR. However, for β > 1, the so-called Welch-bounded sequence has to be used to keep η constant at its value at β = 1 [60]. The spectral efﬁciencies for the cases of random spreading codes with different receivers in AWGN multiple-access channels, such as the single-user matched ﬁlter, the decorrelator  ZF , the MMSE receiver, and the optimum MUD receiver, are given in [60]. The results for spectral efﬁciency are shown in Fig. 8.13 for Eb N0 = 10 dB and K → ∞. The spectral efﬁciencies achievable by an optimum joint decoder with no spreading and with orthogonal codes for K ≤ N are also plotted for comparison. It is seen that the capacity of the MMSE receiver is always higher than that of the single-user matched ﬁlter and ZF receivers, but is lower than that of the optimum MUD receiver and the receiver with orthogonal codes. The ZF receiver typically approximates the performance of the MMSE and the optimum MUD receiver for small β. As load increases, η reaches an optimum, and then decreases dramatically and drops to zero below β = 1.      276   cid:2   Spread spectrum communications  y c n e i c i f f e   l a r t c e p S    p i h c   r e p   s t i b    2.5  1.5  3  2  1  0  0.5  No spreading  Orthogonal  Optimal  Decorrelator  MMSE  0.25  0.5  0.75  1.25  1.5  1.75  2  1 K N  Matched filter   cid:2 Figure 8.13  The uplink spectral efﬁciencies of DS-CDMA for different receivers for Eb N0 = 10 dB and K → ∞. c cid:2 IEEE 1999.  [60], Fig. 1 .  8.6 Other DSSS techniques  In addition to DS-CDMA, there are some other DSSS techniques, such as single- carrier cyclic preﬁx assisted CDMA  CP-CDMA  [3], multicarrier CDMA  MC-CDMA  [65], block-spreading CDMA  BS-CDMA  [46], and interleave division multiple access  IDMA  [39, 47].  Single-carrier CP-CDMA is used for broadband cellular systems [3]. It is a block-based transmission scheme, where a cyclic preﬁx is inserted to each data block. This alleviates the inter-block interference if the cyclic preﬁx length is larger than the maximum delay spread of the channel. The use of a cyclic preﬁx transforms the linear convolution into circular convolution, so that FFT-based linear equalizers can be used to recover the trans- mitted symbols for each user in frequency-selective fading channels.  MC-CDMA, which will be introduced in Section 9.13, combines DS-CDMA with OFDM [65]. Unlike the single-carrier CP-CDMA system that transmits the data block directly, the MC-CDMA system transmits the IFFT version of the data block. Due to the insertion of a cyclic preﬁx, FFT-based linear receivers are also applicable for MC-CDMA systems.  A block-spreading CDMA  BS-CDMA  system produces a signiﬁcantly improved mul- tiuser performance without using complex MUD techniques for uplink transmission [46]. Code orthogonality is easily maintained when channel variation across the consecutive blocks is negligible in a block-based high-speed transmission, leading to MAI-free trans- mission in a slow fading channel. The system uses FDE at the receiver to combat ISI over frequency-selective fading channels. Despreading is implemented prior to equalization, reducing the frequency domain process to a symbol-wise operation.  Interleave division multiple access  IDMA [39, 47] may be considered as a special DS-CDMA scheme. In a DS-CDMA sys- tem, the bitstream is ﬁrst channel-encoded, interleaved, and then spread for each user, and      277   cid:2   8.7 DSSS and DS-CDMA in wireless standards  the spreader is user-speciﬁc. In contrast, in IDMA, spreading is placed prior to interleaving, and the interleaver is user-speciﬁc. The different users are distinguished by their unique chip interleavers. In IDMA, FEC and spreading can be combined in a single encoder, which is the same for all users; as a consequence, very low-rate encoding is used, and the spreader may be used to simplify the overall encoder. The combined use of low-rate channel coding and chip-level interleaving allows IDMA for simple soft-input soft-output  SISO  iterative decoding techniques with low-complexity MUD. Like multicode CDMA, the data rate can be controlled by the number of signature sequences assigned given a predeﬁned target BER.  IDMA with a sufﬁciently large number of superimposed codewords, with optimum power allocation, and in conjunction with a suitable receiver is capacity-achieving [27]. Single-carrier IDMA realizes time diversity, where chip interleaving is capable of increas- ing the achievable time-diversity in time-selective channels, and joint coding and spreading design.  The MMSE-ﬁltered PIC strategy is used as a low-complexity SISO MUD [47]. Due to low-rate coding and chip-level processing, rather than spreading and bit-level processing in DS-CDMA, for each transmitted symbol, the interference for one chip is independent from that for another chip due to the chip-interleaver, and thus correlation between users is virtually eliminated. Hence, the optimal ﬁltering after interference cancellation is sim- ply the summation of the log-likelihood-ratio  LLR  values for all the chips, and matrix inversion is avoided, resulting in a low-complexity implementation that grows linearly with the number of users. This is achieved at a price of more memory for interleaver sizes.  IDMA has been generalized to the multicarrier case. In the multicarrier interleave- division-multiplexing  IDM -aided IDMA  MC-IDM-IDMA  [67], each user transmits multiple streams differentiated by stream-speciﬁc chip interleavers. This concept is similar to the multicode scheme employed in the HSPA system.  Possible applications include 4G cellular standards, wireless LANs, ad-hoc networks  [55], and UWB systems [35]. Channel coding is introduced in Chapter 15.  8.7 DSSS and DS-CDMA in wireless standards  DSSS, as well as its multiuser version DS-CDMA, is the most popular spread spectrum technology. DS-CDMA is widely used in CDMA-based 2G and 3G mobile communica- tions standards including IS-95, CDMA2000, WCDMA, UTRA-TDD, and TD-SCDMA. Both IS-95 and CDMA2000 use synchronous DS-CDMA architecture. Each BS has a code clock obtained from combining the PN short code and long code generators by spreading. A BS code clock is synchronized by loading the shift registers with the start bits.  DSSS is also widely used in wireless networking. The baseline IEEE 802.11 supports both FHSS and DSSS. In the DSSS mode of the baseline IEEE 802.11, each data bit is spread by an 11-chip Barker sequence, and the data stream is spread over an 11 MHz band. DBPSK and DQPSK are used for the data rates of 1 Mbit s and 2 Mbits s, respectively.      278   cid:2   Spread spectrum communications  IEEE 802.11b uses eight-chip CCK, which is an extension of DSSS modulation. IEEE 802.15.4  ZigBee  also uses DSSS modulation using PN chip sequences.  DS-CDMA is usually combined with FDMA or TDMA. In the combined DS- CDMA FDMA system, the total bandwidth is divided into multiple sub-bands, and DS-CDMA is the multiple access method employed in each sub-band. This approach is used in IS-95 and WCDMA. When DS-CDMA is combined with TDMA, each user is assigned one timeslot. Users in different cells are distinguished by different spreading codes. This eliminates the near-far effect. Such an idea is embodied in UTRA-TDD.  IS-95  In the downlink, IS-95 uses 64 Walsh codes for each band, each code being designated as a channel. Each channel in the same band must use a unique code, while the same code can be used in different bands. Among the 64 codes: W0, W1, ··· , W63, some are used for forward channel broadcasting, such as W0 for the pilot channel, W1 to W7 for the paging channels and W32 for the synchronization channel, while all the remaining codes plus some unused paging codes are assigned to users as their unique identiﬁcations and also for trafﬁc.  The pilot channel sends all zeros  W0 code . It serves as the beacon signal that deﬁnes the radius of the cell, and the signal level is 4 to 6 dB higher than all other channels. The pilot channel is also used as a timing or demodulation reference at the MS receiver, and also for signal measurement during handoffs. The sync channel is used by the MS to acquire initial time synchronization. The paging channels are used by the BS to page an idle MS in the case of an incoming call, or carry control messages for call setup. The MS is listening on a paging channel when it is idle.  The uplink does not have pilot and synchronization channels for synchronization, thus the Walsh code cannot be used on the uplink and instead a long PN code of a length of 242 − 1 chips are used for channelization. In order to provide isolation among BSs or sectors, each BS or sector is assigned a unique short PN code with a length of 215 − 1 = 32767 chips, which is superimposed on top of a Walsh code; that is, each downlink channel including the pilot channel is ﬁrst spread by its Walsh code, and then spread by a quadrature pair of short PN sequences, PNI and PNQ. The same pair of short PN sequences for the pilot channel are used in all BSs, but each BS in the network is assigned a signature generated by phase offset in steps of 64 chips of the pilot PN sequence pair.  CDMA2000  CDMA2000 reuses several IS-95 common channels and adds several new forward common channels. The pilot channel must be receivable at all locations in a cell, since it is used for synchronization, multipath channel estimation, coherent detection, frequency correction, as well as handover decisions. IS-95 uses BPSK prespreading, and ﬁxed 64-bit Walsh codes. In CDMA2000, Walsh codes from 4 chips to 256 chips are used for variable information rates.      279   cid:2   8.7 DSSS and DS-CDMA in wireless standards  S P  bitstream  j  sc  I + jQ  s   cid:2 Figure 8.14  Spreading for WCDMA downlink channels.  I  Q  ch1c cch2  WCDMA  WCDMA also uses the Walsh codes. They are used to multiplex users on the downlink and to identify MSs on the uplink. Each complex-valued downlink physical channel except the synchronization channel is split into I and Q parts which are spread by using different codes. This is shown in Fig. 8.14.  WCDMA uses two types of codes: channelization codes for spreading and scrambling codes for multiple access. The channelization codes are OVSF codes, whose code length is 4–256 for the uplink and 4–512 for the downlink. After channelization using a code, scram- bling is applied to the result. The scrambling code cs is only for identiﬁcation purposes  for separating users on the uplink and for identifying BSs on the downlink , while the chan- nelization code is used in the downlink to separate different intracell users. Separation of intercell users is implemented by using the scrambling code in the downlink.  The scrambling code is a complex-valued code, which is derived from two real-valued codes. It can be a long or a short code. The short scrambling code is derived from the very large Kasami code of length 256, while the long code is derived from the Gold code of length 225 − 1. The long code is truncated to a length of one frame  10 ms . For the uplink, both the short and long scrambling codes can be used. In case MUD is implemented in the BS, the short code is recommended for complexity reasons; otherwise, the long code should be used, since it provides a better whitening of interference. For the downlink, only the long code is used.  Multirate CDMA systems  In multirate CDMA systems, such as WCDMA, UTRA-TDD, and TD-SCDMA, multirate is realized by changing the spreading factor N, which is implemented by using the OVSF code. Since the chip rate 1 Tc is constant and T = NTc, decreasing N leads to a higher data rate. However, a large spreading factor corresponds to a good capability for interference suppression. Thus, low spreading users require either a higher power level, or very few interferers in a cell, or a sophisticated detection technique. The use of the OVSF code is inﬂexible for rate-matching for multimedia applications, since the spreading factor must be made a power of two.  The multicode technique is another solution for multirate transmission. This method assigns more spreading codes to a subscriber that requires a high data rate. This method consumes more spreading codes, but can perform like a conventional single-rate CDMA      280   cid:2   Spread spectrum communications  system. The multicode technique is used in CDMA2000 and also in WCDMA. Multicode transmission is also allowed in UTRA-TDD. CDMA2000 also uses repetition and punc- turing to achieve multirate. In HSDPA, AMC is used instead, and the method ﬁxes the spreading factor to N = 16. The principal drawback of the multicode technique is that the transmitted signals may have a high PAPR. In [54], constant-amplitude codes are designed to reduce the PAPR in multicode systems to the favorable value 1.  Remarks on spread spectrum technologies  DS-CDMA is now the mainstream technology for 3G mobile communications. It is effec- tive for multiplexing a large number of variable-rate users in a cellular environment. Although DSSS is used for WCDMA and CDMA2000, CDMA is not an appropriate tech- nology for high data rates. As 3G evolves toward higher rates, notably in HSDPA HSUPA, 3GPP LTE, and 1xEV-DO, CDMA technology is actually losing its position. In HSDPA and 1xEV-DO, very small spreading factors are used and dynamical TDMA scheduling is employed based on channel conditions and latency. In 3GPP LTE, OFDM technology is applied.  CDMA technology is suitable for low-data-rate communications, such as voice, where many users are multiplexed to yield a high overall system capacity. For high-data-rate systems, each user must be assigned multiple codes, introducing considerable self- interference. For this reason, OFDM technology is widely used in high-data-rate wireless communications. We will introduce OFDM technology in Chapter 9.  8.8 Frequency-hopping spread spectrum  FHSS, or code-controlled multifrequency-FSK modulation, is another type of spectrum spreading technique. Unlike DS-CDMA which occupies the whole frequency band, FHSS uses only one among a set of narrow channels and hops through all of them in a predeter- mined spreading sequence at each predeﬁned time interval. In the FHSS system, as in the DSSS system, the processing gain Gp is also deﬁned as the ratio of the spread bandwidth of the transmitted signal to the data rate. The principle of FHSS is shown in Fig. 8.15, where B is the spread bandwidth, and N = Gp is the period of the code. At the transmitter, the modulated signal is mixed with the synthesizer output pattern to produce the FH signal. For an angle-modulation scheme, the transmitted signal for the kth hop is given by  s t  =  2Pavg cos  2πfit + φ t  + φk  ,   k − 1 Th ≤ t ≤ kTh,   8.60    cid:21   where Pavg is the average power, fi is the carrier frequency for the kth hop, φ t  is a con- tinuous phase term, φk is a random phase angle for the kth hop, and Th is the interval of each hop.      281   cid:2   8.8 Frequency-hopping spread spectrum  f  B   cid:2 Figure 8.15  NTc  Principle of FHSS.  t  Data stream  Transmitter  Modulator  FH signal  Channel  Receiver  Dehopped  signal  Demodulator  Symbols  Bandpass  filter  Code  generator  Frequency synthesizer  Frequency synthesizer  Code  generator  Synchr.   cid:2 Figure 8.16  The transceiver of the FHSS system.  At the receiver, the mixing operation removes the frequency-hopping pattern from the received signal, and the dehopped signal is obtained. The architecture of an FHSS system is depicted in Fig. 8.16.  FH can be either slow FH or fast FH. The time spent in one frequency is called dwell time or hop interval, Th. Fast FH changes the carrier frequency several times during one symbol period, the chip period Tc = Ts k for some integer k. Thus, each symbol is spread over a large bandwidth, and there is frequency diversity on each symbol that combats fading or interference. Fast FH is not widely used in commercial wireless systems, and its market share is supplanted by the DS-CDMA technology. Slow FH transmits one or multiple symbols over each frequency, Tc = kTs for some integer k. Slow FH is usually used with TDMA so that each time slot is transmitted on a carrier frequency according to a hopping scheme. Slow FH is used in GSM, DECT, HomeRF, Bluetooth, and the baseline IEEE 802.11. In Bluetooth, the full-duplex signal implements FH at up to 1,600 hops per second amongst 79 frequencies at 1-MHz intervals. FH is more commonly used in military systems to avoid jammers. 3GPP LTE achieves frequency diversity also by FH.  For FHSS, MFSK is the commonly used modulation method. FH MFSK is often detected using a noncoherent technique, due to the difﬁculty in rapid carrier synchroniza- tion as the carrier frequency is hopped. Beacon frames that contain the pattern and time can be used for synchronization between the receiver and the transmitter. In the FH scheme      282   cid:2   Spread spectrum communications  of the baseline 802.11, two-level GFSK and four-level GFSK modulation are used for the data rates of 1 Mbit s and 2 Mbits s, respectively.  For FHSS systems using BFSK modulation, if no two users utilize the same frequency band at the same time, the error probability for BFSK is given by  In the case of two users transmitting on the same frequency band, a collision occurs. The error probability of the collided band should be 0.5, and thus the overall error probability is given by  where Pc is the probability of collision.  chronously, the probability of collision is  Given M frequency slots and K users, when all the users are assumed to hop syn-  8.8.1 Error performance of FHSS  Slow frequency hopping  P0 = 1 2  − γb 2 . e  Pe = P0  1 − Pc  + 1 2  Pc,  ,  M   cid:2  1 − 1  cid:2  M   cid:3 K−1 ≈ K − 1  cid:3  1 − K − 1  cid:2   + K − 1  cid:3  cid:6 K−1  2M  M   cid:5   1 − 1 M  1 + 1 Nb  ,  .  Pc = 1 −  Pe = 1 2  − γb e  2  Pc = 1 −  where the approximation is made for large M. Inserting Pc into  8.62 , we have  For γb → ∞, Pe = K−1 2M , which demonstrates an irreducible error rate due to MAI. In the case of asynchronous hopping, the probability of collision is given by [52]  where Nb is the number of bits per hop. Obviously, Pc in the asynchronous case is higher than that in the synchronous case. The error probability Pe can be correspondingly obtained by  8.62 .  The error probability of slow FH MFSK on the AWGN channel with non-coherent  square-law detection is given by  7.96 .  For BFSK modulation, if fast FH is used, that is, each bit corresponds to Nh hops, the error rate probability for an FH system is approximated by [8]  Fast frequency hopping   cid:3    cid:2   Pe = Nh cid:26   n=r  Nh r   1 − Pe0 Nh−n ,  Pn e0   8.61    8.62    8.63    8.64    8.65    8.66       283   cid:2   8.8 Frequency-hopping spread spectrum  where Pe0 is the error probability of a single jamming trial, which is J N, J being the number of jammers and N the number of channels, and r is the number of wrong chip decisions necessary to cause a bit error. Pe0 can be calculated from  8.62 . A fast FH system offers a performance much better than that of a slow FH system, but at the cost of complexity. For a three-hops-per-bit FH system, if at least r = 2 frequencies are correct, the decision is a correct bit per symbol, thus Pe ≈ 3P2 e0, which is much better than that in the case of one hop per bit, namely, Pe = Pe0.   1 − Pe0  ≈ 3P2  e0  8.8.2 FHSS versus DSSS  Both DSSS and FHSS have no impact on the performance in the AWGN channel, but they can improve the performance in the Rayleigh fading channel and in the case of narrowband interference. Between FHSS and DSSS, the nature of interference reduction differs: DSSS results in a reduced-power interference on the entire band all the time, while FHSS has a full power interferer on a narrowband channel over a chip period. Thus, coding with interleaving is needed for FHSS, and a collision in one or two frequencies can be recovered by coding.  Implementation of FHSS is inexpensive. FHSS is superior to DSSS in terms of immu- nity to interference. In case of a strong interference in a segment of the band, the FHSS transmitter will use the remaining band effectively with a decrease in the throughput. FH leads to a whitening of the received signal and an averaging over all the frequencies. When different users use different FH sequences, the FH technique can also be used as a multiple- access technique. Some spectral regions with steady interference can be omitted from the hopset, and this is a process called spectral notching. In contrast, a single interferer with sufﬁcient power can stop communication of a whole DSSS system. Interference from a narrowband jammer in DSSS systems can be alleviated by adaptive ﬁltering [51]. FHSS has the technical constraints of producing fast frequency synthesizers, especially in the case of fast hopping.  Implementation of DSSS requires synchronization and tracking of the phase of the received signal, which is typically difﬁcult in the presence of fast fading. Due to their complexity, DSSS systems consume more power than FSSS systems. Transmission time in DSSS is shorter than that in FHSS, since no frequency changing is necessary. DSSS achieves a higher processing gain and is more widely used in high rate systems.  Multiuser FHSS, also referred to as FH-CDMA or FH-SSMA, is implemented by assign- ing each user a unique spreading code sequence for hop pattern generation. FH-CDMA is typically used in uplinks, and for military purposes. FH-CDMA typically supports a smaller number of users than DS-CDMA. The near-far effect is also an issue for FSK- based FHSS systems: A near transmitter has sidelobes that may extend to the band of the desired signal. Choosing CPFSK can generate an inherently narrow signal spectrum. Thus, the advantage of FH-CDMA over DS-CDMA is its robustness to the near-far effect: hopping can mitigate performance degradation caused by strong interferers [20]. FHSS and FH-CDMA are used in some low-rate systems. For example, FH-CDMA is the core multiple-access technology in Bluetooth, and FHSS is employed in GSM.      284   cid:2   Spread spectrum communications  Problems  8.1 An FHSS system using 8FSK employs 500 different frequencies. Determine the processing gain. 8.2 In IS-95, assume K = 30 users share a channel of 1.25 Mhz. Each user has a chip rate of 1.2288 Mchips s and a baseband data rate of 13 kbits s, and the PN code lengths are 32,678 chips. If each user is provided with a maximum Eb N0 of 7.8 dB, determine the bit error probability for a user, and the processing gain of IS-95. 8.3 A CDMA system has a bandwidth of W = 1.6 Mhz, supports a data rate of R = 12.5 kbits s, and the minimum acceptable Eb Nb = 8.9 dB. Determine the maximum number of users that can be supported by a single cell:  a  with omnidirectional BS antennas and no voice activity detection.  b  with three-sectors at the BS and voice activity is detected as α = 3 8. 8.4 Given a code length  processing gain  of 255 and the desired bit error probability −4 for a conventional receiver, how many equal-power users can be supported at of 10 Eb N0 = 20 dB? 8.5 Plot the power spectrum of an m-sequence with chip duration Tc and period NTc.  8.6 A preferred pair of m-sequences of length 31 is given as  b1 = 1010111011000111110011010010000 b2 = 1011010100011101111100100110000  Verify that the pair satisﬁes the three-valued cross-correlation for preferred pairs of m- sequences. Demonstrate that a Gold code of length 31 achieves the permitted values of cross correlations. Verify that it is true for b1 + Db2 and b1 + D3b2, where D is the delay operator. 8.7 Consider the m-sequence generated using the primitive polynomial g D  = 1 + D2 + D5. Show that the properties for m-sequences are satisﬁed. 8.8 Plot the ACF and the power spectrum for the m-sequence speciﬁed by g D  = 1 + D2 + D3 + D4 + D5. The shift-register clock rate is 10 kHz. 8.9 A rate-1 3 convolutional code with dfree = 8 is used to encode a data sequence at a rate of 1000 bits s. BPSK modulation is employed. The DSSS has a chip rate of 10 Mchips s.  a  Determine the coding gain.  b  Determine the processing gain.  c  Deter- mine the jamming margin for Eb J0 = 10 dB, where J0 is the spectral density of the combined interference.  8.10 A DSSS BPSK signal has a processing gain of 100. Determine the jamming margin against a continuous-tone jammer for an error probability of 10  −4.      285   cid:2   References  8.11 Write a MATLAB program for constructing Gold code sequences for length n = 2m − 1, m = 3 to 9. Verify their cross-correlation peak values by searching all the Gold codes. For example, the parity polynomials for a pair of preferred sequence for constructing Gold code of length n = 7 are given as h1 D  = D3 + D + 1 and h2 D  = D3 + D2 + 1. Find from the literature all the pairs of preferred sequence for m = 3 to 9. 8.12 A DS BPSK system employs an LFSR of length 15 to generate PN sequences. What is the processing gain? If the required bit error probability is 105, what is the maximum interference?  8.13 In the IS-95 system, the conventional single-user CDMA receiver is used. For a bandwidth of 1.25 MHz and a user data rate of 9.6 kbits s, what is the maximum number of voice users that can be accommodated?  8.14 An IS-95 mobile transmits with a power of 24 dBm. If the BS wishes the MS to transmit with a power of 18 dBm, how long does it take for the change? [Hint: Power control frequency is 800 Hz and the step is 1 dB.]  8.15 For the DS-CDMA system in the AWGN multiple-access channel, the spectral efﬁciencies for the different receivers are given in [60]. Write a MATLAB program to reproduce Fig. 8.13. 8.16 A slow FH BPSK system with noncoherent detection operates at Eb J0 = 15, the hopping bandwidth is 2GHz, and the bit rate is 100 bits s. What is the processing gain of the system?  8.17 For a slow FH, 16FSK system, if each hop lasts over 6 symbols, what is the processing gain?  8.18 For a fast FH, 16FSK system, if each 16FSK symbol experiences 5 hops, what is the processing gain?  8.19 For an FH, MFSK wireless LAN system, an m-sequence is generated by a 20 stage LFSR. Each state of the register corresponds to a hopping frequency. The minimum hop- ping step is 200 Hz. The register clock rate is 2 kHz. 4FSK modulation is applied and the data rate is 2.4 kbits s. Determine the hopping bandwidth, the chip rate, the processing gain, and chips per symbol.  References  [1] M. A. Abu-Rgheff, Introduction to CDMA Wireless Communications  Oxford, UK:  Academic Press, 2007 .  [2] A. I. Amayreh & A. K. Farraj, Minimum autocorrelation spreading codes. Wireless  Pers. Commun., 40:1  2007 , 107–115.  [3] K. L. Baum, T. A. Thomas, F. W. Vook & V. Nangia, Cyclic-preﬁx CDMA: an improved transmission method for broadband DS-CDMA cellular systems. In Proc. IEEE WCNC, Orlando, FL, Mar 2002, 1, 183–188.      286   cid:2   Spread spectrum communications  [4] J. J. Blanz, A. Papathanassiou, M. Haardt, I. Furio & P. W. Baier, Smart antennas for combined DOA and joint channel estimation in time-slotted CDMA mobile radio systems with joint detection. IEEE Trans. Veh. Tech., 49:2  2000 , 293–306.  [5] P. Burns, Software Deﬁned Radio for 3G  Boston: Artech House, 2003 . [6] D. C.-H. Chen, B. J. Sheu & W. C. Young, A CDMA communication detector with robust near-far resistance using paralleled array processors. IEEE Trans. Circ. Syst. Video Tech., 7:4  1997 , 654–662.  [7] H.-H. Chen, J. F. Yeh & N. Seuhiro, A multi-carrier CDMA architecture based on orthogonal complementary codes for new generations of wideband wireless communications. IEEE Commun. Mag., 39:10  2001 , 126–135.  [8] H.-H. Chen & M. Guizani, Next Generation Wireless Systems and Networks   Chichester, UK: Wiley, 2006 .  [9] CWTS-SWG2 LAS-CDMA, Physical layer aspects of TD-LAS high speed packet  technology, LAS TR 25.951, v1.0.0, Jul 2001.  [10] K.-L. Du & M. N. S. Swamy, An adaptive space-time multiuser detection algorithm  for CDMA systems. In Proc. IEEE WiCOM, Wuhan, China, Sep 2006, 1–5.  [11] K.-L. Du & W. H. Mow, Search for long low-autocorrelation binary sequences by  evolutionary algorithms. Submitted to IEEE Trans. Aerospace Electron. Syst.  [12] C. Ergun & K. Hacioglu, Multiuser detection using a genetic algorithm in CDMA  communications systems. IEEE Trans. Commun., 48:8  2000 , 1374–1383.  [13] G. J. Foschini & M. J. Gans, Layered space-time architecture for wireless communi- cation in a fading environment when using multiple antennas. Bell Labs Tech. J., 1:2  1996 , 41–59.  [14] G. J. Foschini & M. J. Gans, On limits of wireless communications in a fading environment when using multiple antennas. Wireless Pers. Commun., 6:3  1998 , 311–335.  [15] G. D. Forney, Jr., Coding and its application in space communications. IEEE  [16] M. Friese, Polyphase Barker sequences up to length 36. IEEE Trans. Inf. Theory, 42:4  [17] R. L. Frank, Polyphase complementary codes. IEEE Trans. Inf. Theory, 26:6  1980 ,  [18] M. J. E. Golay, Complementary series. IRE Trans. Inf. Theory, 7:2  1961 , 82–87. [19] R. Gold, Optimum binary sequences for spread-spectrum multiplexing. IEEE Trans.  Spectrum, 7:6  1970 , 47–58.   1996 , 1248–1250.  641–647.  Inf. Theory, 13:4  1967 , 619–621.  Press, 2005 .  Theory, ll:4  1965 , 533–537.  [20] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  [21] S. W. Golomb and R. A. Scholtz, Generalized Barker sequences. IEEE Trans. Inf.  [22] S. W. Golomb, Shift Register Sequences  San Francisco, CA: Holden-Day, 1967 . [23] G. Golub & C. van Loan, Matrix Computations, 3rd edn  Baltimore, MD: John  Hopkins University Press, 1996 .  [24] L. Hanzo, M. Munster, B. J. Choi & T. Keller, OFDM and MC-CDMA for Broadband Multi-User Communications, WLANs and Broadcasting  New York: Wiley-IEEE, 2003 .      287   cid:2   References  [25] F. Hasegawa, J. Luo, K. R. Pattipati, P. Willett & D. Pham, Speed and accuracy com- parison of techniques for multiuser detection in synchronous CDMA. IEEE Trans. Commun., 52:4  2004 , 540–545.  [26] K. M. Ho & W. H. Mow, Searching for the best biphase and quadriphase quasi-Barker  sequences. In Proc. IEEE ICCCAS, Chengdu, China, Jun 2004, 1, 43–47.  [27] P. A. Hoeher & H. Schoeneich, Interleave-division multiple access from a multiuser theory point of view. In Proc. Int. Symp. Turbo Codes Appl., Munich, Germany, Apr 2006.  [28] J. M. Holtzman, A simple, accurate method to calculate spread-spectrum multiple-  access error probabilities. IEEE Trans. Commun., 40:3  1992 , 461–464.  [29] T. Kasami, Weight distribution of Bose-Chaudhuri-Hocquenghem codes.  In R. C. Bose and T. A. Dowling, eds., Combinatorial Mathematics and its Applications  Chapel Hill, NC: University of North Carolina Press, 1967 , pp. 335–357.  [30] G. I. Kechriotis & E. S. Manolako, Hopﬁeld neural network implementation of the optimal CDMA multiuser detector. IEEE Trans. Neural Netw., 7:1  1996 , 131–141. [31] R. Kohno, Interference cancellation and multiuser detection. In M. Shaﬁ, S. Ogose & T. Hattori, eds., Wireless Communications in the 21st Century  New York: IEEE Press, 2002 .  [32] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [33] K.-C. Lai, R. Chandrasekaran, R. E. Cagley & J. J. Shynk, Multistage interference cancellation algorithms for DS CDMA signals. In G. B. Giannakis, Y. Hua, P. Stoica, L. Tong, eds., Signal Processing in Wireless & Mobile Communications: Trends in Single- and Multi-user Systems, 2  Upper Saddle River, NJ: Prentice Hall, 2001 , pp. 267–314.  [34] D. B. Li, The perspectives of large area synchronous CDMA technology for the  fourth-generation mobile radio. IEEE Commun. Mag., 41:3  2003 , 114´lC-118.  [35] K. Li, X. Wang, G. Yue & L. Ping, A low-rate code-spread and chip-interleaved time-  hopping UWB system. IEEE J. Sel. Areas Commun., 24:4  2006 , 864–870.  [36] J. Liberti & T. Rappaport, Smart Antenna for Wireless Communications  Englewood  Cliffs, NJ: Prentice Hall, 1999 .  [37] R. Lupas & S. Verdu, Linear multi-user detectors for synchronous code-division  multiple-access channels. IEEE Trans. Inf. Theory, 35:1  1989 , 123–136.  [38] U. Madhow & M. L. Honig, MMSE interference suppression for direct sequence  spread-spectrum CDMA. IEEE Trans. Commun., 42:12  1994 , 3178–3188.  [39] R. Mahadevappa & J. G. Proakis, Mitigating multiple access interference and inter- symbol interference in uncoded CDMA systems with chip-level interleaving. IEEE Trans. Wireless Commun., 1:4  2002 , 781–792.  [40] S. Y. Miller & S. C. Schwartz, Integrated spatial-temporal detectors for asyn- chronous Gaussian multiple-access channels. IEEE Trans. Commun., 43:2–4  1995 , 396–411.  [41] R. K. Morrow, Jr. & J. S. Lehnert, Bit-to-bit error dependence in slotted DS SSMA packet systems with random signature sequences. IEEE Trans. Commun., 37:10  1989 , 1052–1061.      288   cid:2   Spread spectrum communications  [42] W. H. Mow, Best quadriphase codes up to length 24. Electron. Lett., 29:10  1993 ,  923–925.  [43] W. H. Mow & S.-Y. R. Li, Aperiodic autocorrelation and crosscorrelation of  polyphase sequences. IEEE Trans. Inf. Theory, 43:3  1997 , 1000–1007.  [44] M. Nagatsuka & R. Kohno, A spatially and temporally optimal multiuser receiver using an antenna array for DS CDMA. IEICE Trans. Commun., E78-B:11  1995 , 1489–1497.  [45] C. B. Papadias & H. Huang, Linear space-time multiuser detection for multipath  CDMA channels. IEEE J. Sel. Areas Commun., 19:2  2001 , 254–265.  [46] X. Peng, A. S. Madhukumar, F. Chin & T. T. Tjhung, Block spreading CDMA sys- tem: a simpliﬁed scheme using despreading before equalisation for broadband uplink transmission. IET commun., 3:4  2009 , 666–676.  [47] L. Ping, L. Liu, K. Wu & W. K. Leung, Interleave division multiple access. IEEE  Trans. Wireless Commun., 5:4  2006 , 938–947.  [48] R. Price & P. E. Green, Jr, A communication technique for multipath channels. Proc.  [49] J. G. Proakis & M. Salehi, Digital Communications, 5th edn  New York: McGraw-  IRE, 46:3  1958 , 555–570.  Hill, 2008 .  [50] M. B. Pursley, Performance evaluation for phase-coded spread-spectrum multiple- access communication – part I: system analysis. IEEE Trans. Commun., 25:8  1977 , 795–759.  [51] K. D. Rao, M. N. S. Swamy & E. I. Plotkin, A nonlinear adaptive ﬁlter for nar- rowband interference mitigation in spread spectrum systems. Signal Process., 85:3  2005 , 625–635.  [52] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall, 2002 .  [53] S. V. Sarwate & M. B. Pursley, Crosscorrelation properties of pseudrandom and  related sequences. Proc. IEEE, 68:5  1980 , 593–613.  [54] K.-U. Schmidt, Quaternary constant-amplitude codes for multicode CDMA. IEEE  Trans. Inf. Theory, 55:4  2009 , 1824–1832.  [55] H. Schoeneich & P. A. Hoeher, Adaptive interleave-division multiple access – a poten- tial air interference for 4G bearer services and wireless LANs. In Proc. IEEE IFIP WOCN, Muscat, Oman, Jun 2004, 179–182.  [56] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  2001 .  34:1  1988 , 143–46.  [57] N. Suehiro & M. Hatori, N-Shift cross-orthogonal sequence. IEEE Trans. Inf. Theory,  [58] X. Tang & W. H. Mow, Design of spreading codes for quasi-synchronous CDMA with intercell interference. IEEE J. Sel. Areas Commun., 24:1  2006 , 84–93.  [59] S. Verdu, Multiuser Detection  Cambridge, UK: Cambridge University Press,  1998 .  [60] S. Verdu & S. Shamai, Spectral efﬁciency of CDMA with random spreading. IEEE  Trans. Inf. Theory, 45:2  1999 , 622–640.      289   cid:2   References  [61] A. J. Viterbi, Very low rate convolutional codes for maximum theoretical perfor- mance of spread-spectrum multiple-access channels. IEEE J. Sel. Areas Commun., 8:4  1990 , 641–649.  [62] A. J. Viterbi, A. M. Viterbi, K. Gilhousen & E. Zehavi, Soft handoff extends CDMA cell coverage and increases reverse channel capacity. IEEE J. Sel. Areas Commun., 12:8  1994 , 1281–1288.  [63] A. J. Viterbi1995, Principles of Spread Spectrum Communication  Reading, MA:  Addison-Wesley, 1995 .  [64] X. Wang & H. V. Poor, Space-time multiuser detection in multipath CDMA channels.  IEEE Trans. Signal Process., 47:9  1999 , 2356–2374.  [65] N. Yee, J.-P. Linnartz & G. Fettweis, Multicarrier CDMA in indoor wireless radio  networks. In Proc. IEEE PIMRC, Yokohama, Japan, Sep 1993, 109–113.  [66] K. Yen & L. Hanzo, Genetic-algorithm-assisted multiuser detection in asynchronous  CDMA communications. IEEE Trans. Veh. Tech., 53:5  2004 , 1413–1422.  [67] R. Zhang & L. Hanzo, Three Design Aspects of Multicarrier Interleave Division  Multiple Access. IEEE Trans. Veh. Tech., 57:6  2008 , 3607–3617.      9  Orthogonal frequency division multiplexing  9.1 Introduction  OFDM, also known as simultaneous MFSK, has been widely implemented in high-speed digital communications in delay-dispersive environments. It is a multicarrier modulation  MCM  technique. OFDM was ﬁrst proposed by Chang in 1966 [11]. Chang proposed the principle of transmitting messages simultaneously over multiple carriers in a linear band- limited channel without ISI and ICI. The initial version of OFDM employed a large number of oscillators and coherent demodulators. In 1971, DFT was applied to the modulation and demodulation process by Weinstein and Ebert [81]. In 1980, Peled and Ruiz introduced the notion of cyclic preﬁx to maintain frequency orthogonality over the dispersive chan- nel [60]. The ﬁrst commercial OFDM-based wireless system is the ETSI DAB standard proposed in 1995.  A wide variety of wired and wireless communication standards are based on the OFDM  or MCM technology. Examples are   digital broadcasting systems such as DAB, DVB-T  Terrestrial DVB , and DVB-H;   home networking such as digital subscriber line  xDSL  technologies;   wireless LAN standards such as HyperLAN 2 and IEEE 802.11a g n;   wireless MANs such as IEEE 802.16a e  WiMAX , ETSI HiperACESS, IEEE 802.20  mobile-Fi , WiBro, and HiperMAN2;   wireless WANs such as 3GPP LTE and 3GPP2 UMB;   powerline communications such as HomePlug;   wireless PANs such as UWB radios  IEEE 802.15.3a 3c 4a . It is commonly deemed that OFDM is a major modulation technique for beyond-3G wireless multimedia communications.  Features of OFDM technology  In OFDM technology, the multiple carriers are called subcarriers, and the frequency band occupied by the signal carried by a subcarrier is called a sub-band. OFDM achieves orthogonality in both the time and frequency domains.  The most attractive feature of OFDM is its robustness against multipath fading, but with a low complexity; that is, it can reliably transmit data over time-dispersive or frequency- selective channels without the need of a complex time-domain channel equalizer. OFDM can be efﬁciently implemented using FFT.      291   cid:2   9.2 Principle of OFDM  Other advantages of OFDM are listed as follows.   OFDM achieves robustness against narrowband interference, since narrowband interfer- ence only affects a small fraction of the subcarriers.   Frequency diversity can be exploited by coding and interleaving across subcarriers in the frequency domain.   Different modulation formats and data rates can be implemented on different subcarriers depending on the channel quality of individual sub-bands.   OFDM enables bandwidth-on-demand technology and higher spectral efﬁciency.   Contiguous bandwidth for operation is not required.  However,  the high PAPR of the OFDM signal places a strict requirement on power ampliﬁers. For this reason, 3GPP LTE employs SC-FDMA for transmission to reduce the strict requirement on power ampliﬁers in MSs. Also, multicarrier sys- tems are inherently more susceptible to frequency offset and phase noise; thus, fre- quency jitter and Doppler shift between the transmitter and receiver cause inter- carrier interference  ICI , which becomes a challenge in case of medium or high mobility.  9.2 Principle of OFDM  For high-speed communications, the multipath characteristics of the environment cause the channel to be frequency-selective. In the OFDM system, a frequency-selective channel is equally divided into N frequency-ﬂat subchannels. Speciﬁcally, the N subcarriers are assumed to be at the frequencies fn = nW N, n = 0, 1, . . . , N − 1, where W is the total bandwidth that is available, and usually W = N T. These subcarriers are orthogonal: Their inter-carrier spacing is equivalent to the inverse of the symbol duration, 1 T, and the spectral peak of each subcarrier must coincide with the zero-crossings of all the other subcarriers. For PAM modulation with rect- angular pulse shape, mutual orthogonality of the subcarriers is easily seen from the relation  e j2πfkte  −j2πfntdt = δnk.   9.1    cid:14   iT   i+1 T  Example 9.1: Given an OFDM signal using 7 subcarriers, the spectrum of each modulated subcarrier is a sinc function due to the rectangular pulse shape in the time domain. The frequency spectrum of the subcarriers is shown in Fig. 9.1a. The power spectrum of the OFDM signal is shown in Fig. 9.1b. The ﬁrst spectrum sidelobes are only about 17.3 dB below the passband level. By using other windows for pulse shaping, the sidelobes can be suppressed, but this introduces ACI.      292   cid:2   Orthogonal frequency division multiplexing  m u r t c e p s   e d u t i l p m A  1  0.8  0.6  0.4  0.2  0  −0.2     B d      m u r t c e p s   y c n e u q e r F  0 −5 −10 −15 −20 −25 −30 −35 −40  −10  −5  5  10  −10  −5  5  10  0 fTs  a   0 fTs  b    cid:2 Figure 9.1  Spectrum of OFDM.  a  Amplitude spectrum of each carrier.  b  Power spectrum of the OFDM signal.   9.2    9.3   OFDM leads to an equation of the same form as that of IFFT operation. Assuming that the complex symbol to be transmitted on the ith subcarrier at instant k is di,k, the transmitted signal is given by  ∞ cid:26   k=−∞  ∞ cid:26   N−1 cid:26   k=−∞  i=0  s t  =  sk t  =  di,kgi t − kT ,  where gi t  is a normailzed, frequency-shifted rectangular pulse 0 ≤ t ≤ T,  e j2πfit,  gi t  = 1√ T  and 0 otherwise. The complex symbol di,k can be obtained by ASK, PSK, or QAM. Without loss of generality, for symbol k = 0, if the symbol is sampled at tu = uT N, u = 0, 1, . . . , N − 1, we have su = 1√ T  u = 0, . . . , N − 1.  di,0e j2πiu N,  N−1 cid:26    9.4   i=0  The is exactly the IFFT of the transmitted symbols. Thus, these modulations can be performed by using IFFT.  At the receiver, demodulation can be implemented by multiplying the received signal −j2πfit and integrating over a symbol duration. on each carrier fi, that is, di,kgi t , by e FFT can be used for this purpose. Spectral overlapping among subcarriers can be sep- arated at the receiver due to the orthogonality property of the subcarriers. This makes the implementation much simpler than the traditional implementation that uses multiple oscillators.  For the baseband OFDM signal, the zero-to-null bandwidth is N T, thus the sampling frequency should be at least 2N T to avoid aliasing. When implemented using IFFT, only N samples are available for a symbol period T. Thus, N zeros can be padded to increase the number of samples to 2N, and 2N-point IFFT can then be used to generate the OFDM      293   cid:2   9.3 OFDM transceivers  signal. Those subcarriers with zero data are known as dummy or virtual subcarriers. This oversampling strategy can be implemented by padding L  even  zeros, half of them before and half after the data sequence. For example, in IEEE 802.11a, the signal samples are generated by 64-point IFFT, among which 12 points correspond to virtual subcarriers. The virtual subcarriers create separation between the repetitions of the PSD. At the receiver, N-point FFT is used to demodulate the signal.  9.3 OFDM transceivers  OFDM splits the bitstream into multiple parallel bitstreams of reduced bit rate, modulates them using an M-ary modulation, and then transmits each of them on a separate subcar- rier. The amplitude spectrum of each modulated subcarrier using PSK or QAM has a sinc shape. At the peak spectrum response of each subcarrier, the spectral responses of all other subcarriers are identically zero. This is shown in Fig. 9.1a. This improves the spectral efﬁciency. The use of narrowband ﬂat-fading subchannels can effectively resist frequency selective fading.  Each modulated subcarrier in the OFDM signal can be an MPSK, MASK, or MQAM signal. Thus, the OFDM signal can be obtained ﬁrst by 1:N serial-to-parallel  S P  con- version and then by converting each of the N bitstreams to one of the N subcarriers fi. Their sum is then upconverted to the RF band. For each subcarrier, there is a complete modulator, which typically consists of a subcarrier oscillator, one  for MASK  or two  for MQAM and MPSK  multipliers, and an adder. A phase shifter is also required for MQAM and MPSK. For passband modulation, a mixer and a bandpass ﬁlter are required for upconversion.  The receiver consists of a downconverter to translate the signal to the baseband. The baseband OFDM signal is then demodulated by a bank of N demodulators at N subcarrier frequencies, one for each of the subcarriers. The subcarrier demodulator can be a stan- dard MPSK, MASK, or MQAM demodulator, which consists of oscillators, multipliers, integrators, and threshold detectors.  The basic implementation of the OFDM transceiver is rarely used in practical systems, since for large N the implementation is too complex and thus is impractical. Almost all modern OFDM systems use the DFT-based digital implementation. The block diagram of the OFDM system is shown in Fig. 9.2.  b0 b1  S P  d0 d1  PSK Mod.  bitstream  bN − 1  dN − 1  Transmitter  s  IFFT  Cyclic prefix insertion  Channel  FFT  Demod  P S  bitstream  s  Cyclic prefix removal  d0  d1  dN – 1 Receiver  b0 b1  bN – 1   cid:2 Figure 9.2  The OFDM system.      294   cid:2   Orthogonal frequency division multiplexing  The input high-speed bitstream is ﬁrst converted into N parallel low-speed bitstreams. N is selected as a power of two, since it is used as the FFT block size. Each low-speed bitstream is then converted into symbols, and M-ary modulated to its subchannel with  the modulated data sequence dn = dIn  + jdQn, n = 0, 1, . . . , N − 1. All the N modulated  subchannel data are fed to an IFFT algorithm or circuit to generate an OFDM signal. MPSK modulation is usually used, since it produces a constant amplitude signal, thus reducing problems with amplitude ﬂuctuations due to fading. IFFT is used to ﬁnd the time waveform for the spectrum. A cyclic preﬁx is then appended to the OFDM signal, and serves as guard time.  OFDM demodulation reverses the process of OFDM modulation. At the receiver, the received signal is ﬁltered using a wide bandpass ﬁlter. An orthogonal detector is applied to downconvert the signal to the IF band. The cyclic preﬁx is ﬁrst removed. An FFT circuit is then used to obtain the Fourier coefﬁcients of the signal ˆdn, n = 0, 1, . . . , N − 1, in the observation period [kTs, kTs + T], where T is the symbol dura- tion, and Ts = Tg + T is the extended OFDM symbol duration, Tg being the guard interval. By comparing bi k  and ˆbi k , i = 0, 1, . . . , N − 1,  the BER performance can be calculated. OFDM transmission preserves the orthogonality among the subchan- nels, and the BER performance is thus decided by the modulation scheme in each subchannel.  9.4 Cyclic preﬁx  The frequency-selective channel is divided into frequency-ﬂat fading channels, and this substantially eliminates ISI. However, delay dispersion can lead to appreciable errors even when στ  T < 1, and also leads to a loss of orthogonality between the subcarriers and thus to ICI. The cyclic preﬁx is a kind of guard interval that effectively eliminates the effects of delay dispersion. The OFDM data frame is cyclically extended with the last L symbols of the frame, which corresponds to the maximum channel delay τmax. This can effectively eliminate ISI and interframe interference. An empty guard interval can avoid ISI, but not ICI. When the cyclic preﬁx is used in the guard interval, ICI can also be avoided.  Due to the orthogonality of the subchannels, individual subchannels can be separated by using an FFT circuit at the receiver if there is neither ISI nor ICI. Channel equalization is easily accomplished by using a complex scale factor for each subchannel. Multipath fading may cause each subchannel to spread the power into the adjacent channels. Distortion arising from ISI and ICI can be reduced by increasing the number of subcarriers. This, however, leads to carrier instability against Doppler and a large FFT size. OFDM inserts a guard time, usually selected as two to four times the expected delay spread, to eliminate ISI, but the guard time reduces the data throughput. To reduce ICI, OFDM symbols are cyclically extended into the guard interval to ensure that an OFDM symbol has an integer number of cycles in the DFT intervals.      295   cid:2   9.4 Cyclic preﬁx  sk  −Ncp  −1  0  N−1  k   cid:2 Figure 9.3  Cyclic preﬁx is the repetition of the last part of the symbol to be transmitted.  Assume that a cyclic preﬁx is prepended to the normal OFDM symbol, τmax ≤ Tcp. The cyclic preﬁx spans the duration from −Tcp < t < 0, and the normal OFDM symbol from 0 < t < T. The cyclic preﬁx is a copy of the last part of the trans- mitted symbol. For a carrier spacing W N, the symbol period T = N W. The number of samples of the symbol is N, and the number of the samples in the cyclic preﬁx is Ncp = NTcp T. This is shown in Fig. 9.3. Cyclic preﬁx can recover the orthogonality of the subcarriers. Usually, cyclic preﬁx occupies 10% of symbol duration. At the receiver side, for each received block, the cyclic preﬁx is ﬁrst removed, and the remainder is fed to FFT.  With the cyclic preﬁx, the transmitted OFDM signal can be represented by  s k  =   cid:15  x t  = N−1 cid:26   ifft  d0, d1, . . . , dN−1  , s N + k ,  k = 0, 1, . . . , N − 1 k = −Ncp, . . . ,−1  ,   cid:2    cid:3   s k w  k=−Ncp  t − k N  T  , − Ncp N  T ≤ t ≤ T,   9.5    9.6   where w t  is the time-domain window function, such as a rectangular window or the raised cosine function.  Example 9.2: Given a randomly generated bitstream, we use OFDM modulation with N = 128 and Ncp = 13, and the modulation on each subcarrier is BPSK with amplitude A = 1. The modulated OFDM signal is plotted in Fig. 9.4, for a period of Ts = T + Tcp, where the rectangular window is used.  The use of cyclic preﬁx, although elegant and simple, reduces the spectral efﬁciency and introduces a power penalty. Both the rate loss and the power loss are a fraction Ncp N+Ncp . The length of the cyclic preﬁx Ncp is determined by the channel length τmax. The efﬁciency can be improved by increasing the number of subcarriers N. This, however, increases the total symbol duration N + Ng, which may be critical for time varying channels, since the channel must remain constant during one symbol period, otherwise the orthogonality      296   cid:2   Orthogonal frequency division multiplexing  0.2  0.15    n   x  0.1  0.05   cid:2 Figure 9.4  Modulated OFDM signal x n  for a BPSK bitstream, N = 128 and Ncp = 13.  0 −20  0  20  40  80  100  120  140  60 n  between subcarriers will be lost. The wasted power in the cyclic preﬁx causes interference to neighboring users.  Zero-padded OFDM  Most OFDM systems are based on the traditional cyclic-preﬁx OFDM  CP-OFDM  mod- ulation scheme. An alternative is zero-padded OFDM, which replaces this time-domain redundancy by null samples [55]. This solution relies on a larger FFT demodulator, and has the merit of guaranteeing symbol recovery irrespective of the channel null locations for coherent modulation. It enables semiblind pilot-based channel estimation with improved tracking capability of channel variations. The price paid is somewhat increased receiver complexity. In terms of power ampliﬁer-induced clipping effects, zero-padded OFDM introduces slightly more nonlinear distortions, and therefore, needs slightly increased power backoff than CP-OFDM.  In the MB-OFDM technology, which was standardized by the WiMedia Alliance for UWB operation, the cyclic preﬁx is just a zero preﬁx of null data to avoid the transmitter power penalty. At the receiver, the tail of the transmitted symbols is duplicated to the position of the cyclic preﬁx to recreate the same effect as a cyclic preﬁx. Although the zero- preﬁx scheme avoids the power penalty, additional noise from the received tail symbols is added into the signal, raising the noise power to N+Ncp σ 2 n , whereas in the cyclic preﬁx scheme, the tail is ignored. For this reason, most OFDM-based standards employ the cyclic preﬁx scheme.  N  By capitalizing on the advantages of zero-padded OFDM, the pseudorandom-postﬁx OFDM replaces the null samples inserted between each OFDM modulated block by a known vector weighted by a pseudorandom scalar sequence to replace the guard interval contents of CP-OFDM [52]. Unlike cyclic-preﬁx and zero-padded OFDM modulators, the receiver can exploit pseudorandomly weighted postﬁx sequences for channel estimation, and thus, the pilot overhead is avoided. The method has the ability to estimate and track the channel variations semi-blindly using the ﬁrst-order statistics of the received signal.      297   cid:2   9.5 Spectrum of OFDM  Case study: IEEE 802.11a and WiMAX  IEEE 802.11a uses a 20-MHz channel spacing in the 5-GHz unlicensed band. IEEE 802.11g is virtually identical to IEEE 802.11a, but operates on the unlicensed 2.4-GHz ISM band. IEEE 802.11a uses OFDM with 64 subcarriers for each 20-MHz channel, thus 64-point IFFT is used to create an OFDM symbol. Among the 64 subcarriers, the inner 52 subcarriers are user-modulated and transmitted, and the outer 12 subcarriers are null- carriers for ACI reduction. The 52 useful tones are indexed from −26 to 26, without a DC component. Among the 52 tones, the 4 tones indexed −21, −7, 7, 21 are used for pilot tones, and they are BPSK-modulated by a PN sequence; the other 48 tones are used for data transmission. The power in the pilot subcarriers is higher so as to allow reliable channel tracking even at low SNR. The cyclic preﬁx consists of Ncp = 16 samples, thus the total number of samples in an OFDM symbol is 80, corresponding to a duration of Ts = 80Tsample = 4μs, where Tsample =1  20 MHz =0.05 μs is the sampling period. The symbol rate is Rs = 1 Ts = 0.25 Msymbols s. Depending the channel state, rate adaptation is achieved by selecting the modulation as BPSK, QPSK, 16QAM, or 64QAM, and or choosing the rate of convolu- tional codes to be 1 2, 2 3, or 3 4. This leads to different data rates ranging from 6 Mbits s to 54 Mbits s. For example, for the combination of 64QAM and Rc = 3 4, the data rate is log2 64 bits symbol × 0.25 Msymbols s × 3 4 × 48 = 54 Mbits s.  For ﬁxed WiMAX  IEEE 802.16d , 256 subcarriers are used, which are composed of 192 data subcarriers for data, 8 pilot subcarriers for various estimation purposes, and 56 null subcarriers for guard bands. The DC subcarrier is nulled to avoid DC offset. The null subcarrier is the center of the signal frequency band. For mobile WiMAX  IEEE 802.16e , OFDMA technology is used; it has a scalability supported by four different FFT sizes, 128, 512, 1024, and 2048. In OFDM, one user can use all the subcarriers at any given time, while in OFDMA multiple users are assigned subsets of subcarriers.  9.5 Spectrum of OFDM  For the baseband OFDM signal, fi must be integer multiples of 1 2T, and the minimum frequency separation between subcarriers is 1 T  refer to FSK . The frequency subcarriers are f0+iRs, i = 0, 1,··· , N−1, where Rs = 1 T is the symbol rate. For ease of analysis, f0 is usually set to zero; but in practical use, the zero frequency subcarrier is unused to avoid the dc component, as in IEEE 802.11a.  The PSD of the OFDM signal is derived from the assumption of random data. It is just the superposition of the PSDs of all the sub-band signals. For the OFDM signals that use MASK, QAM with symmetrical constellation, and MPSK modulation, their PSDs have the same shape. The normalized PSD at the positive frequency part is given by   cid:23 ˜s f   = N−1 cid:26    cid:23 ˜si f   = N−1 cid:26   i=0  i=0   cid:2    cid:3 2  sin π  f − fi  T π  f − fi  T  f ≥ 0.  ,   9.7       298   cid:2   Orthogonal frequency division multiplexing  ,  2T  For unipolar MASK, a discrete part is added to the above spectrum. The null-bandwidth of the total PSD is N T = NRs, and the null-to-null bandwidth is 2NRs. As N → ∞, we get a steep spectrum cut-off at f    NRs  → 1. Bandpass OFDM is typically scheduled as fi = fc − N − 1 + i T  i = 0, 1, . . . , N − 1.  2T to fc + N−1  That is, the subcarriers are uniformly distributed in the range fc − N−1 2T , with a symmetry about the nominal carrier frequency fc. This can be obtained by upconvert- ing the baseband OFDM signal with a frequency shift of fc − N−1 2T . The total PSD for the positive frequency part is also given by  9.7 , but with a frequency shift of fc − N−1 2T . The null-to-null bandwidth is  N + 1 Rs. As N → ∞, we get a steep cut-off in the spectrum. For both the baseband and passband OFDM, the spectrums exhibit a steep cut-off as N → ∞. For this reason, bandpass OFDM achieves the Nyquist rate, since the normalized bandpass frequency  f − fc     NRs  → 1, as N → ∞. The same rule applies for the zero-to-null band of the baseband OFDM. This corresponds to a spectral efﬁciency of 2 bauds Hz, which is the theoretically highest Shannon bandwidth efﬁciency.   9.8   Under a Rayleigh-fading channel, the overall capacity for each OFDM block is a ran- dom variable; in case of large N and ﬁnite power, the distribution of the instantaneous capacity is shown to be approximately Gaussian [15]. In the limit as N → ∞, the capac- ity approaches a constant value equal to the capacity of the inﬁnite-bandwidth Gaussian channel [15].  For baseband OFDM, the subcarriers are required to be orthogonal. The subcarriers at the RF band are not required to be orthogonal to one another, because demodulation is performed at the baseband after downconverting from the RF band. Thus, fc need not to be an integer multiple of 1  2T , as required for fi in baseband OFDM.  Spectrum shaping  In practical wireless standards, the spectrum of the transmitted OFDM signal must be sub- ject to a spectral mask to avoid interference to adjacent bands. This requires the reduction of the sidelobes of the spectrum of the OFDM signal. Reducing the spectrum sidelobes can be implemented by windowing or pulse shaping.  The raised cosine function is commonly used for pulse shaping. It can eliminate ISI by introducing a roll-off segment at each side of the window, leading to a total pulse length of  1 + α Ts, where α is the roll-off factor and Ts is the extended symbol period. This introduces overlapping between adjacent symbols.  In OFDM, a cyclic extension is employed. The last length-Tg portion of the symbol is duplicated, and is then added to the symbol as a preﬁx. Thus, the extended symbol period is given by  Ts = T + Tg,   9.9   where Tg is the guard time.      299   cid:2   9.5 Spectrum of OFDM  prefix  Tg  postfix β Ts  T   cid:2 Figure 9.5  Pulse shaping of OFDM symbols. Cyclic extension is also shown.  Ts = T + Tg     B d       f    Φ  0  −10  −20  −30  −40  −50  −60  −70  −80  −40  −30  −20  −10  0    cid:2 Figure 9.6  PSD of the OFDM signal speciﬁed in the IEEE 802.11a standard.  no pulse shaping pulse shaped  f − fc  MHz   Similarly, since the total pulse length  1 + α Ts is longer than the extended symbol duration Ts, the ﬁrst length-αTs portion of the symbol is duplicated and added as a postﬁx to the extended symbol to deal with overlapping. This is shown in Fig. 9.5. This accounts for the overlapping period by αTs.  In OFDM, pulse shaping is performed on each carrier. Unlike the case in Sec- tion 6.3.1, where raised cosine ﬁltering is applied in the frequency domain, here the raised cosine function is applied along the time domain. The raised-cosine time- window and its spectrum are dual they can be obtained by applying the transformation t → f and 1 T → T. Thus, the spec- trum  Fourier transform  of the raised cosine time-window function can be derived as [89]  to  6.44  and  6.45 , respectively;  The overall PSD of the pulse-shaped OFDM signal is thus given by  W f   = Ts cos  πf αTs  1 −  2f αTs 2  sin  πfTs   .  πfTs   cid:23 w f   = N−1 cid:26   i=0  W  f − fi 2 .   9.10    9.11       300   cid:2   Orthogonal frequency division multiplexing  Example 9.3: In IEEE 802.11a, a raised-cosine ﬁlter with α = 0.025 is used to shape the PSD of the 64-channel QAM-OFDM to a 40-dB attenuation at 30 MHz from the nominal carrier frequency fc. The channel separation is 1  3.2μs  = 0.3125 MHz. With a 0.8 μs guard interval, Ts = 4μs. The PSD of the IEEE 802.11a OFDM signal is plotted in Fig. 9.6, where the PSD with no pulse shaping is also plotted for comparison. With the raised cosine pulse shaping, the speciﬁcation of 40-dB attenuation at 30 MHz away from the carrier frequency can be realized.  9.6 Fading mitigation in OFDM  For the OFDM system in a frequency-ﬂat slow fading channel, if the rms excess delay στ is much less than the symbol period, the multipath signals received are not resolvable and a single-path signal with a fading envelope and random phase is formed. This type of fading does not introduce any ISI and ICI, and all the subcarriers experience the same complex fading factor h.  The performance of OFDM will degrade in a fading channel other than the frequency- ﬂat slow fading channel. Frequency-selective slow fading is characterized by multiple resolvable signal paths in the channel. Fading and multipath will incur both ISI and ICI. Frequency-ﬂat fast fading arises from Doppler shift, and the multiplicative fading factor varies in a symbol period. Doppler shift introduces ICI, leading to an error ﬂoor in the BEP performance. For frequency-selective fast fading, both ISI and ICI occur, and the error ﬂoor in the BEP performance is also present.  The most important measure for fading mitigation in OFDM is through channel estimation and equalization. Other techniques for fading mitigation include differen- tial modulation, and diversity schemes such as the widely used coded OFDM and MIMO-OFDM.  As in single-carrier systems, differential demodulation and detection can be used for OFDM in fading channels where carrier synchronization for coherent demodula- tion is difﬁcult to accomplish. For OFDM, differential encoding and detection can be performed in the time domain or in the frequency domain. Time-domain differential encoding and detection are performed on consecutive symbols for each subcarrier, and in the frequency-domain counterparts to consecutive subcarriers for each symbol period. To prevent fast fading that generates large phase noise and an increase in BEP, in the time-domain case, the symbol rate should be greater than the Doppler frequency spread νmax; likewise, in the frequency-domain case, the subcarrier spacing should be much smaller than the channel coherent bandwidth 1 στ . The SNR in differential detection is 3 dB inferior to that with ideal coherent detection, but practical coherent detection also introduces some loss in SNR due to channel estimation accuracy and power loss in pilots. Thus, differential detection is typically 1 to 2 dB inferior in SNR to coherent detection [89].      301   cid:2   9.7 Channel estimation  ISI and ICI in the OFDM system can be completely eliminated by using cyclic preﬁx. However, an uncoded OFDM system does not have any frequency diversity, and each subcarrier can be in a fading dip. To reduce BEP, some form of diversity, such as coding, must be used to improve the BEP. When coding is applied, the bitstream can be ﬁrst coded by using turbo convolutional code or Reed-Solomon  RS  code, followed by interleaving. In the MIMO-OFDM system, space-time trellis coding  STTC  or space-time block coding  STBC  can be further applied. MIMO and channel coding are, respectively, described in Chapters 19 and 15.  To mitigate fading in OFDM, conventional equalization can be used on each subcarrier, but it also enhances the noise power. Precoding [68] uses the same idea as equalization, but the fading is inverted at the transmitter rather than at the receiver, thus noise power remains N0BN, where BN is the bandwidth of each subchannel. Precoding is common in wireline multicarrier systems such as DSL. However, in the wireless case, due to a Rayleigh fading channel, the power for channel inversion will approach inﬁnity; also, precoding requires subchannel ﬂat-fading gains at the transmitter, which is difﬁcult to obtain in a rapidly fading channel.  Adaptive loading, where power and data rate on each subchannel are adapted to maximize the total rate of the system by using adaptive modulation, can also be used to mitigate fading. Like precoding, the subchannel fading at the transmitter is required.  9.7 Channel estimation  Channel estimation and equalization are necessary for combating the performance degrada- tion caused by fading. This requires estimation of the channel. Channel estimation is based on the assumption of perfect synchronization, thus it is a part of the coherent detection. Channel estimation is usually performed jointly with carrier and timing synchronization. It can be pilot-assisted or decision-directed.  The pilot-assisted method uses the pilot symbols sparsely distributed across the time slots as well as the subcarriers. Estimation of the channel for each subcarrier at each symbol period is performed by two-dimensional interpolation. At the beginning, preambles that contain one or two preamble OFDM symbols are sent prior to the user data symbols for the purpose of synchronization and initial channel estimation. Pilot symbols are then inserted according to a known pattern among the subcarriers in order to track the time-varying channel to maintain accurate channel estimates.  Decision-directed channel estimation uses the previously demodulated symbols. The decision-directed method is not as reliable as the pilot-assisted method and it suffers from error propagation, but it uses less bandwidth. It is capable of tracking fast fading, while the pilot-assisted method with sparsely inserted pilots is not able to do so. The decision- directed method can use the same least squares  LS  or linear MMSE algorithm as the pilot-assisted method does, but the input to the algorithm is the previously demodulated symbols [27].      302   cid:2   Orthogonal frequency division multiplexing  The pilot-assisted and decision-directed methods can be combined to combat the shortcomings of the two methods. After the channel is estimated, the symbols can be detected by using a ZF or MMSE detector.  Due to shaping of the transmit spectrum, practical OFDM systems are usually not fully loaded. The subcarriers that are set to null are referred to as virtual carriers. Cyclic preﬁx and or virtual carriers have been employed in subspace-based blind channel estimation techniques [41, 54], and semiblind techniques that also take advantage of the training data [54]. In the following, we introduce pilot-based channel estimation.  9.7.1 Pilot arrangement for channel estimation  The pilot-assisted method requires an arrangement of the pilots. Figure 9.7 illustrates three types of pilot arrangement, namely block-type, comb-type and scattered-type. In the block-type pilot arrangement, one speciﬁc symbol full of pilot subcarriers is trans- mitted periodically. The block-type pilot arrangement is suitable for estimation of slow fading channels, and it has been used in the IEEE 802.16e-2005 OFDM mode standard. In the comb-type arrangement, a number of subcarriers are reserved for pilot signals, which are transmitted continuously. The comb-type pilot arrangement can be used for equaliza- tion when the channel changes in one OFDM block. Np pilots are uniformly inserted into x k  on each carrier. The comb-type arrangement requires interpolation of the channel. For fast fading channels, the comb-type arrangement leads to better channel estimation. The scattered-type is not periodical, and the number of pilots and their positions can be changed dynamically according to the channel.  Based on the Nyquist theorem, the maximum sampling distance along the time axis is  derived as [57]   cid:17    cid:18   Nt ≤  1  2νmaxTs  =  2  1 1 + Ncp  N  ,  νmax   9.12   f  f  f  t   a   t   b   t   c    cid:2 Figure 9.7  Pilot Arrangement.  a  Block-type.  b  Comb-type.  c  Scattered-type. A “×” represents a pilot.      303   cid:2   9.7 Channel estimation   cid:17    cid:18   where νmax is the maximum Doppler spread, and Ts is the extended OFDM symbol duration, Ts = By duality between the Fourier transform and the inverse Fourier transform  see  1 + Ncp  T.  N  Chapter 13 , in the frequency domain the sampling theorem requires that [51, 57]  Nf ≤ 1 στ  cid:18 f  = N Ncp  ,   9.13   where Nf is the sampling distance along the frequency axis,  cid:18 f is the subcarrier spacing,  cid:18 f = 1 T, and στ is the multipath spread of the channel.  9.7.2 Pilot-assisted channel estimation  Operation of OFDM requires knowledge of the channel. For frequency-selective ﬂat fad- ing, the channel impulse response for the nth subchannel at time k is hn,k. Also, since channel estimation is based on the pilot symbols, the data on each subchannel is known. Based on this, an LS estimate of the channel is given by  ˆhLS  n,k  = rn,k dn,k  ,   9.14    9.15  =  ˆh  LS k  where dn,k is the known symbol on subchannel n at time k, and rn,k is the received value on subchannel n at time k. The LS estimator has a coarse estimate, but it is simple.  Assuming AWGN with variance σ 2  n on each subchannel, the linear MMSE or Wiener  estimate is given by [51]   cid:17   ˆh  MMSE k  = Rhh   cid:18 −1 ˆh  LS k ,   cid:18 T  LS k   cid:17 ˆhLS where ˆh 1,k, ˆhLS hk = cid:7   time k.  2,k, . . . , ˆhLS  N,k  is obtained by stacking all  time k, , and Rhh is the autocovariance matrix of the channel gains  the N LS estimates at  Rhh = E   cid:8 T. For the wide sense stationary channel, Rhh is independent of  hkhH k   9.16   ,  h1,k, h2,k,··· , hN,k  Rhh + σ 2IN×N  cid:20   cid:19    cid:7    cid:8   The method is accurate, but the complexity is O  complex multiplications, which is very high for large N. This method is used for initial acquisition of the channel. To reduce the complexity, the structure of OFDM can be used and Rhh can be eigen-decomposed,  N2  Rhh = U cid:8 UH,   9.17  where the dimension of the space is approximately Ncp + 1, and the transforms U and UH are, respectively, DFT and IDFT.  After the channel is estimated, the ﬁnal estimate of the data symbol at time k is given by  a one-tap equalizer  ˆdn,k = rn,kˆhn,k  ,   9.18       304   cid:2   Orthogonal frequency division multiplexing  where the subscript n runs for the subcarriers, and k corresponds to the time instant. The channel is assumed to be constant for a period of one symbol.  After the channel is acquired, it also needs to be tracked by using pilot symbols scattered into the OFDM time-frequency grid, spaced by Nf subcarriers and Nt OFDM symbols. At the pilot positions, the channel is estimated by the LS or MMSE estimation, while at other positions the channel can be estimated by interpolation.  Case study: LTE  In LTE, data symbols are mapped to resource blocks based on CSI at the transmitter. The uplink frame is the same for both FDD and TDD. Each frame is 10 ms long and is divided into 10 subframes. In TDD mode, each subframe is allocated to either the downlink or uplink. Each subframe is divided into two time slots. A slot consists of seven DFT-spread OFDM symbols with cyclic preﬁx of a normal length or six symbols with cyclic preﬁx of an extended length.  A resource block is deﬁned for one slot, and contains 12 adjacent subcarriers spaced by 15 kHz, or 180 kHz. A resource block in uplink TDD mode is illustrated in Fig. 9.8. Every fourth symbol is a pilot symbol for channel estimation at the receiver, while the others are data symbols. The symbols are time multiplexed, occupying the entire transmission bandwidth of 180 kHz. The pilot symbol is chosen as a Zadoff-Chu sequence, and different Zadoff-Chu sequences are assigned to resource blocks of different cells.  Channel sounding is also required in the uplink. For uplink, channel sounding is achieved by reserving blocks within the same subframe for this purpose. The blocks con- taining sounding signals occupy a bandwidth of multiple resource blocks, and these blocks of different users share either the time, frequency, or code domain. Different Zadoff-Chu sequences are assigned to different users.  0.5 ms  Data symbol  Pilot symbol  Sounding symbol  0.5 ms  180 kHz  180 kHz  Multiple resource blocks   cid:2 Figure 9.8  Symbols within a resource block of LTE in uplink TDD mode.  a  A regular resource block.  b  A resource block with a sounding symbol.   a    b       305   cid:2   9.8 Peak-to-average power ratio  9.8 Peak-to-average power ratio  The OFDM signal consists of many independently modulated subcarriers, which may lead to a large PAPR for some OFDM symbols. When N signals have the same phase, they produce a peak power, which is N times the average power.  9.8.1 Peak factor: deﬁnition and impact  The PAPR or peak factor is deﬁned by   cid:20  .  cid:19 x t 2 PAPR = maxt x t 2  E   9.19   For constant amplitude signals, PAPR=0 dB, for a sine wave PAPR=3 dB.  For OFDM systems, in order to reduce the overhead of the cyclic preﬁx, the number of subcarriers N should be as large as possible. However, for N subcarriers the maximum possible PAPR is N, although the possibility of PAPR being N is very low. The maximum PAPRs for MQAM-OFDM and MPSK-OFDM signals are derived in [89]. For the square MQAM with M = 2k for k even, the PAPR is given as  √ M − 1  PAPR = 3N  √ M + 1   MQAM-OFDM .   9.20   For MPSK,  PAPR = N  MPSK-OFDM .   9.21   The probability of maximum PAPR happening is very low. For system design, the statis- tical distribution of the instantaneous PAPR is more important. For large N, the IFFT output x n , 0 ≤ n ≤ N − 1, is zero-mean complex Gaussian, since the central limit theorem is applicable to the IFFT expression. In this case, the OFDM signal has an envelope that is Rayleigh distributed with variance σ 2, and a phase of uniform distribution. The probability of the PAPR exceeding a threshold P0 = σ 2   σ 2 is given by [77, 89]  Pr  PAPR > P0  = 1 − cid:7   0  1 − e  −P0   cid:8 αN ,   9.22  where α = 1 for N ≥ 512, and α = 2.8 for N ≤ 256. The result is quite accurate for N ≥ 128.  Example 9.4: The probability of the PAPR exceeding P0 is plotted in Fig. 9.9, for N=64, 128, . . ., 2048. It is seen that the probability of PAPR being greater than a moderate P0 decreases rapidly.      306   cid:2   Orthogonal frequency division multiplexing  100           0 P > R P A P       r P  10−2  10−4  Increasing N  N = 64, 128, 256, 512, 1024, 2048  10−6  4  6  8  10  12  14  P0  dB   The probability of the PAPR being greater than P0.   cid:2 Figure 9.9  The high PAPR becomes a critical challenge to RF power ampliﬁer design. In order to operate in the linear region to avoid distortion, the peak must be within this region. This can be realized by reducing the average power of the input signal, known as input back-off, which also results in a proportional output back-off. Back-off reduces the power efﬁciency of the power ampliﬁer, which may limit the battery life for MSs. Back-off also reduces the coverage range. For a given average power requirement, high PAPR requires power ampliﬁers with a large linear region, and this increases the cost of the power ampliﬁers. In addition, high PAPR corresponds to a large dynamic range of the signal, and thus requires high resolution for both the DACs at the transmitter and the ADCs at the receiver.  Thus, OFDM requires high-power ampliﬁers, with a wide linear range, and hence, class A ampliﬁers are required. If a cheaper nonlinear ampliﬁer is used, the distortions intro- duced destroy orthogonality between the subcarriers, and also lead to more out-of-band emissions.  9.8.2 Peak factor reduction techniques  The PAPR can be reduced by amplitude clipping or companding, by using a PAPR reduc- tion code [82], by phase adjustments [6, 53], or by precoding [70]. PAPR reduction techniques are reviewed in [31], and criteria for selecting a PAPR reduction technique are also given. Here, we only mention some basic ideas.  From Fig. 9.9, it is seen that large peaks are rare to happen. Thus, clipping the high peaks would not introduce too much performance degradation. Clipping is the simplest and most widely used PAPR reduction technique. Amplitude clipping introduces out-of-band emission  spectral growth  and in-band distortion, and hence multiplicative and additive time-domain modiﬁcations of the OFDM signal have been proposed to alter the amplitude of the time-domain OFDM samples rather than clipping [33]. The companding technique      307   cid:2   9.8 Peak-to-average power ratio   cid:7    cid:8   for PAPR reduction uses the μ-law to compress the signal amplitude [78]. The spectral regrowth and in-band distortion arising from clipping can also be improved by an iterative process of clipping and ﬁltering [4].  Channel codes are employed not only as a means of error control but also simultaneously as a sequence restrictor so as to select only low peak OFDM symbols from a set of block codes for transmission. The Golay complementary sequences [30] are particularly suitable for PAPR reduction [82]. The polyphase Golay complementary sequences [26] are suit- able for MPSK-OFDM, since all the elements in the sequence have the same amplitude. The peak factor of x t  that employs any Golay complementary sequence for the complex , is bounded by 3 dB, that is, it symbols on all the subcarriers, achieves a maximum PAPR of 2 [63]. A systematic method for encoding an arbitrary data sequence into a Golay complementary sequence is given in [20]. Coding for PAPR reduc- tion has a large overhead, thus reducing the data throughput. Iterative channel codes such as turbo codes [1] and LDPC codes have also been used for this purpose [18].  dn,k, n = 0, 1, . . . , N − 1  4  5  jφk,l  The phase adjustment method multiplies the complex symbol, dn,k, to be transmitted , where φk,l is a predeﬁned phase selected as the lth at the nth subcarrier by exp value of L possible discrete phase values for symbol k. The ensemble of the phase adjust- ments is known to both the transmitter and the receiver. By minimizing the PAPR, the value of l can be derived. This approach cannot guarantee a given maximum peak factor. In the partial transmit sequence  PTS  technique [53], an input data block of N symbols is partitioned into disjoint sub-blocks. The subcarriers in each sub-block are weighted by a phase factor for that sub-block. The phase factors are selected such that the PAPR of the combined signal is minimized. In the selected mapping  SLM  technique [6], the transmit- ter generates a set of modiﬁed data blocks, all representing the same original data block, and selects the most favorable ones for transmission. Speciﬁcally, each data block is multi- plied component-wise by different phase sequences. Exploiting the fact that the modulation symbols belong to a given constellation and that the multiple signals generated by the PTS or SLM processes are widely different in a Hamming distance sense, the simpliﬁed ML decoder for SLM and PTS proposed in [36] operates without side information. Compared to the QAM constellation, the hexagonal constellation has more regularly-spaced signal points in a given area. These extra degrees of freedom can be exploited to eliminate data rate loss due to the side information in the PTS and SLM techniques [32]. The techniques proposed in [32] achieve almost identical PAPR reduction and SEP performance as those of the techniques in [36], but with signiﬁcantly reduced complexity at the receiver.  dn,k, n = 0, 1, . . . , N − 1  There are a number of special sequences that can be used to encode the information so sequences as to reduce amplitude variations. Such codes include the Shapiro-Rudon sequences, Golay codes, m-sequences, Newman phases, and Schroeder phases [33]. According to the com- parison made in [33], the Newman phases show the lowest peak factor among a number of techniques.  or to adjust the phase  4 φk,l, l = 0, 1, . . . , L − 1  5  4  5  Precoding-based PAPR reduction is implemented by multiplying each data block by the same precoding matrix prior to OFDM modulation and transmission [70]. Precod- ing avoids block-based optimization, and this method is data-independent. A properly selected precoding matrix distributes the power of each modulated symbol over the OFDM      308   cid:2   Orthogonal frequency division multiplexing  block, and this makes the PAPR of OFDM modulated signals very close to that of single- carrier signals. This method works with an arbitrary number of subcarriers and any type of baseband modulation used.  Constant envelope OFDM  CE-OFDM  [74] transforms the OFDM signal, by way of phase modulation, to a 0-dB constant-envelope signal, thus eliminating the PAPR problem. At the receiver, phase demodulation is applied ahead of the conventional OFDM demod- ulator. The BEP performance of CE-OFDM is analyzed in AWGN and fading channels in [74]. CE-OFDM achieves good performance in dense multipath with the use of cyclic preﬁx transmission in conjunction with a frequency domain equalizer.  9.8.3 Amplitude clipping or companding  Peak factor can be reduced by modifying the time-domain signal when its amplitude exceeds a limit. The transfer function for amplitude clipping for a baseband multi-carrier signal x t  is given by  ⎧⎨⎩−l,  x t , l,  y t  =  x ≤ −l x < l x ≥ l  ,  where l is the absolute level of clipping.  Error probability due to in-band distortion  The in-band distortion has been modeled based on the Bussgang theorem in [19, 58]. The clipped output can be modeled as  ˜x n  = αx n  + d n ,  n = 0, 1, . . . , N − 1,  where the distortion d n  is uncorrelated with x n , and the attenuation factor α is given by  with the clipping level β being deﬁned as  −β2 +  α = 1 − e l cid:21   cid:19 x n 2  β =  E  √  π β 2  erfc β ,   cid:20  = l√  ,  Ex   9.23    9.24    9.25    9.26   with Ex being the average input power of the OFDM signal before clipping. The attenuation factor α   8 dB. In this case, the uncorrelated distortion can be approximated by the clipped-off signal c n  = ˜x n  − x n . The variance of the distortion is given by [19] 1 − e  −β2 − α2   9.27    cid:18    cid:17   = Ex  .  σ 2 d      309   cid:2   9.8 Peak-to-average power ratio  Assuming that the distortion is Gaussian, the signal-to-noise-plus-distortion ratio  SNDR  of an OFDM symbol is given by  SNDR = α2Ex + N N0  σ 2 d  2  ,   9.28   where N0 2 is the variance of the channel noise on a single carrier. Substituting this SNDR into the BEP equation of an M-ary modulation, we get the BEP for the modulation. The BEP exhibits an irreducible ﬂoor as N0 → 0 or Eb N0 → ∞. The BEP for an OFDM system can be calculated as the average BEP on a single carrier.  Example 9.5: For MQAM with average power Ex = EbN log2 M, the SNDR can be  calculated using  9.28 . From  7.117 , the BEP can be approximated by replacing γ by SNDR  Pb ≈ 4  1 − 1√ M   9.29  For 64QAM modulation, the BEP is plotted in Fig. 9.10, for β =1.4, 1.6, 1.8, 2.0, 2.2, 2.6, and ∞. The irreducible ﬂoor is clearly demonstrated for large Eb N0.  log2 M  Q  .  3SNDR M − 1   cid:3    cid:12  cid:31    cid:13    cid:2   Error probability due to clipping  The probabilities of error due to clipping vary across subcarriers, and the overall prob- ability is dominated by that of the lower subcarriers. A bound on the BEP ﬂoor caused  100  10−2  10−6  b P  10−4  β = 1.4 1.6  1.8  2.0  0  5  10  20  25  30  2.2  2.6  ∞ 15 b dB   γ   cid:2 Figure 9.10  The BEP for a clipped OFDM signal in the AWGN channel for a single carrier and 64QAM modulation.      310   cid:2   Orthogonal frequency division multiplexing  by clipping in a multi-carrier system is given in [5] under the assumption of the absence of noise and other channel impairments. Assuming that each subcarrier carries a square- QAM constellation of L2 points, with the same power for all the subcarriers, the overall probability of symbol error is upper bounded for a clipping by [5]  Ps = 8N L − 1   √ 3L  − β2 e  2 Q  3πβ2 L2 − 1  8  ⎛⎜⎝  ⎡⎣   cid:21   ⎛⎜⎝  ⎡⎣   cid:21    cid:7    cid:7   ⎤⎦1 3  ⎞⎟⎠ .   cid:8   ⎤⎦1 3  ⎞⎟⎠ .   cid:8   Ps = 8N L − 1   L  Q β Q  3πβ2 L2 − 1  8  This bound is obtained for continuous-time signals, where the clipping events satisfy the Poison probability. For practical transceivers operating with discrete-time values, the clip- ping probability has a corresponding discrete-time value. Based on this, a more tight error bound is obtained as [5]   9.30    9.31   Example 9.6: The SEP of the OFDM system caused by clipping, given by  9.31 , is plotted in Fig. 9.11 for QPSK  4QAM , 16QAM, 64QAM and 256QAM.  There is also an additive Gaussian noise model for SEP analysis [49]. In [5], it was pointed out that the additive Gaussian model achieves an SEP that is substantially lower than that from the above model, and the result of the above model is very close to that from simulation [5]. Thus, the OFDM signal is relatively insensitive to clipping at the transmitter.  100  10−2  N       s  P  10−4  10−6  256QAM  16QAM  64QAM  QPSK  3 4 Clip level, β  1  2  5  6   cid:2 Figure 9.11  The SEP due to amplitude clipping, for QPSK  4QAM , 16QAM, 64QAM and 256QAM.      311   cid:2   9.8 Peak-to-average power ratio  The SEP  9.31  is derived when there exists clipping only. In practice, we are more interested in the SEP at the OFDM receiver, where there exist noise and fading. In case of channel noise and fading together with clipping at the receiver, the SEP performance degrades signiﬁcantly. Noise can reduce the effective distance between the constellation points, thus increasing the SEP.  A noiseless, slowly varying Rayleigh fading channel can be modeled by the pdf [5]  pz z  = π 2  −πz2 4, ze  z > 0,  where the mean is normalized to unity. Assuming that the channel is known and is con- stant over one OFDM symbol duration, an upper bound on the error probability is derived as [5]   cid:14  ∞  Ps = 4π  N L − 1   L  0  −πz2 4Q βz Q ze  ⎛⎜⎝  ⎡⎣ 3πβ2z2  cid:21   cid:7   L2 − 1  8  ⎤⎦1 3  ⎞⎟⎠ dz.   cid:8   This bound is tight for lower subcarriers of the multi-carrier signal.   9.32    9.33   Example 9.7: The SEP for a Rayleigh fading channel with clipping at the OFDM receiver, as given by  9.33 , is plotted in Fig. 9.12 numerically, for QPSK  4QAM , 16QAM, 64QAM and 256QAM.  100  10−1  N       s  P  10−2  10−3  64QAM  256QAM  16QAM  QPSK  1  2  5  6  3 4 Clip level, β   cid:2 Figure 9.12  The SEP due to amplitude clipping in a slow, ﬂat Rayleigh fading channel, for QPSK  4QAM , 16QAM, 64QAM and 256QAM.      312   cid:2   Orthogonal frequency division multiplexing  9.9 Intercarrier interference  Cyclic preﬁx ensures orthogonality between the subcarriers in a delay-dispersive  frequency-selective  environment, thus eliminating ICI due to frequency selectivity. How- ever, the frequency-dispersive  time selective  channel due to the Doppler effect also creates ICI. It also leads to random frequency modulation, leading to errors. For a large symbol duration, a small Doppler shift can cause a considerable ICI. Another source that introduces ICI is due to errors in the local oscillators.  To eliminate ICI, we need to optimally select the carrier spacing and OFDM symbol length. A short symbol duration T causes a smaller Doppler-induced ICI, but it must be above a minimum value for the reason of spectral efﬁciency: The cyclic preﬁx, determined by the τmax, should occupy 10% of the symbol duration.  In OFDM, the rectangular time-domain signal has a sinc shape in the frequency domain, which decays slowly in the frequency domain. The slope of the sinc function is large when its value is close to zero, and as a result, a small Doppler shift causes a large ICI. By suitably selecting a pulse shape whose spectrum has a large mainlobe and small sidelobes, ICI due to the Doppler effect can be decreased; this, however, leads to a slower decay in the time domain, and thus to errors induced by the delay spread. FDE techniques such as ZF and MMSE equalizers can also be used to reduce ICI.  For large N, the central limit theorem can be applied and the ICI can be treated as a Gaussian variable. Based on this, the autocorrelation of the ICI for 2-D isotropic scattering can be derived [72]. The variance of the ICI caused by the Doppler shift is derived as [72, 89]   cid:13   φcc 0  = Eav T  − Eav TN2   N − i J0  2π νmaxTi   ,   9.34    cid:12  N + 2  N−1 cid:26   i=1  where Eav is the average symbol energy, T is the symbol period, J0 is the Bessel function of the ﬁrst kind and zero order, and νmax is the maximum Doppler frequency. It is seen that the variance of the ICI is independent of the signal constellation. The SIR of the OFDM signal is given by  SIR = Eav T φcc 0   .   9.35   Example 9.8: The SIR as a function of νmaxT, as given by  9.35 , is plotted in Fig. 9.13 for N = 64 to 2048. It is seen that SIR decreases with the increase of νmax and N.  From Fig. 9.13, it is seen that there is an SIR ﬂoor, as νmaxT increases. Thus, ICI results in an error ﬂoor, which can be estimated by substituting SIR given by  9.35  for the average SNR γ in the BEP expression for the data modulation technique on each subcarrier. The theoretical BEP result is very close to that obtained from random simulations.      313   cid:2   9.9 Intercarrier interference     B d      R I S  70  60  50  40  30  20  10  0  0  100  10−2  10−4  b P  N = 64  128  256  512  1024  N=2048  2048  1024  512   cid:2 Figure 9.13  0.2  0.4  0.6  0.8  1  νmaxT  x10−3  Inﬂuence of ICI on SIR.   cid:2 Figure 9.14  10−6  10−1  100  101 νmax  The error ﬂoor of QPSK due to ICI.  256  128  N = 64  102  103   cid:7 √   cid:8   Example 9.9: For QPSK, the BEP is given by Pb = Q . By substituting SIR given by  9.35  for γ , the corresponding BEP due to ICI is obtained. Given a bit rate of Rb = 10 Mbits s, the BEP against the Doppler frequency νmax is plotted in Fig. 9.14 for N = 64, 128, 256, 512, 1028, and 2048. Bit error ﬂoor is clearly demonstrated in the ﬁgure.  γ  For a particular fading channel such as the Rayleigh fading channel, we have γb = α2γb, α being the fading amplitude, and the average SEP is derived by  7.141  with γs being replaced by SIR. The same expression for the error ﬂoor in the BEP performance is applicable for both the frequency-ﬂat fast fading and the frequency-selective fast fading channels.      314   cid:2   Orthogonal frequency division multiplexing  Standard OFDM systems using a guard-time interval or cyclic preﬁx combat ISI, but provide no protection against ICI. This drawback has led to the introduction of pulse- shaping OFDM systems [71].  A universal bound on the ICI power, PICI, is given in [42] based on the Doppler spectrum  PICI ≤  2πfDT 2  ,  12   9.36   where fD is the maximum Doppler spread and T is the OFDM symbol duration. Upper and lower bounds on PICI of OFDM in a Gaussian scattering channel  e.g., with a Gaussian DoA pdf p θ    are also given in [40] is a function of fDT, the frequency offset, and the mobile moving direction. It is found in [40] that the Gaussian scattering channel can be best described as the classical Doppler spectrum model.  9.10 Synchronization  Time and frequency synchronization between the transmitter and receiver is of critical importance to OFDM systems. Multicarriers make OFDM susceptible to time and fre- quency synchronization errors, i.e., phase noise and frequency offset. Frequency jitter and Doppler shift cause ICI and time-varying phase shift. Sample timing errors could destroy the orthogonality among the subcarriers, leading to an increase in the BEP, or at least intro- ducing to the signal symbol a phase shift, which is linearly proportional to the subcarrier frequency.  9.10.1 Inﬂuence of frequency offset  In the OFDM system, frequency offset is introduced by mismatch between the trans- mit and receive sampling clocks and misalignment between the reference frequencies of the transmitter and receiver. Frequency offset causes ICI due to the rotation of the sig- nal constellation on each subcarrier, in turn causing a loss in SNR. The SNR loss is due to the amplitude loss, since the desired subcarrier is no longer sampled at the peak of the equivalent sinc function of the DFT. As a consequence, the adjacent subcarri- ers cause interference as they are not sampled at their zero crossings. This can be seen from Fig. 9.1a.  The degradation caused by the sampling frequency offset can be expressed in terms of  the SNR loss as [61]   cid:2   γ  k  δf fs   cid:13    cid:3 2  cid:3    cid:12   cid:2  1 + π 2 3 1 + π 2 3  γ  kt cid:18  2   dB ,  LSNR ≈ 10 log10 = 10 log10   9.37    9.38       315   cid:2   9.10 Synchronization   cid:14  cid:14    cid:14   is the real channel SNR, fs = N T, T being the where k is the subcarrier index, γ = Es symbol period, δf is the sampling frequency offset between the receiver and the transmitter, and t cid:18  is the normalized sampling error given by  cid:14  cid:14  − T T cid:14   t cid:18  = T   9.39   N0   cid:14   ,  and T  being the sampling periods at the transmitter and receiver, respectively. This T approximation is quite accurate except for the smallest and highest carrier indexes. Thus, when the number of subcarriers and the sampling error t cid:18  are small so that kt cid:18   cid:5  1, the degradation can be ignored.  The overall effect of the carrier frequency offset  CFO  on SNR is analyzed in [61], and is given by  9.37 ; for small frequency offset δf , the SNR loss is approximated by [62]  LSNR ≈ 10 3 ln 10   cid:14    πT  kδf  2γ   dB ,  where T   cid:14   is the sampling period at the receiver. The maximum LSNR is at k = N.  Frequency error reduces the useful signal amplitude at the frequency-domain sampling point by a factor of sinc δf   cid:18 f  , where δf   cid:18 f is the normalized frequency synchronization error, and  cid:18 f is the frequency difference between two adjacent subcarriers [33]. Assuming that the effects of the frequency error can be approximated by white Gaussian noise with variance σ 2  ICI, the equivalent SNR is given by [33] δf  cid:18 f   cid:17   + σ 2   cid:18  8888sinc  a  σ 2 a   γ  ,   cid:2   γ  cid:14  = sinc σ 2 ICI N 2 cid:26   i=−N 2−1,i cid:18 =0   cid:3 88882  .  i + δf  cid:18 f  = σ 2  a  σ 2 ICI  where σ 2  a is the average symbol power. The ICI variance can be expressed by [33]   9.40    9.41    9.42   Example 9.10: The ICI variance versus the normalized frequency synchronization error is plotted in Fig. 9.15, for N = 16, 64, 2048. It is shown that the ICI noise variance virtually has no change for N > 64.  Example 9.11: Based on the equivalent SNR given by  9.41 , the BEP performance for QPSK modulation of subcarriers is plotted in Fig. 9.16, for different values of δf   cid:18 f . As δf   cid:18 f increases, a bit error ﬂoor is clearly demonstrated.  In the presence of the frequency offset that considers the Doppler effect, the effective  SNR for each subcarrier p is derived as [66]      316   cid:2   Orthogonal frequency division multiplexing   cid:2 Figure 9.15  ICI variance σ 2  ICI as a function of the normalized frequency shift δf  cid:12 f.  0.2  0.4  0.6  0.8  1  δf Δf  2a  σ      I  C  I  2 σ  1  0.8  0.6  0.4  0.2  0  0  b P  100  10−2  10−4  10−6  0  N = 16 N = 64 N = 2048  δf Δf=0 δf Δf=0.03 δf Δf=0.05 δf Δf=0.1 δf Δf=0.15 δf Δf=0.2   cid:2 Figure 9.16  Inﬂuence of frequency synchronization error δf  cid:12 f on the BEP over the AWGN channel for QPSK signals.  5  10  20  25  30  15 γ  dB   γ  p  =   cid:24   s  p σ 2 σ 2  H p   n∈Na,n cid:18 =p  s  p σ 2 σ 2  H p    cid:4  cid:4  cid:4 μN  cid:4  cid:4  cid:4 μN  cid:17    cid:17   δf  cid:18 f   cid:18  cid:4  cid:4  cid:4 2  δf  cid:18 f  + pβ + n 1 + β  − p   cid:18  cid:4  cid:4  cid:4 2 + σ 2  w  ,   9.43   where σ 2 subchannel p, σ 2  H p  is the variance of the subchannel Hp, σ 2  s  p  is the variance of the symbols on  w is the variance of the noise at subchannel p,  μN θ  = 1 N  e j2πnθ N = 1 N  sin π θ   sin π θ N   e jπ θ N−1  N,   9.44   N−1 cid:26   n=0      317   cid:2   9.10 Synchronization  β = v c denotes the relative Doppler shift, v being the velocity component along the radial direction, and the frequency offset  = foff 1 + β   =  1 + β fc − fLO   cid:18 f   cid:18 f  δf  cid:18 f   9.45   denotes the normalized shift of the carrier, foff being the frequency offset at the transmitter, fLO the frequency of the LO at the receiver. Na is the set of active subcarriers Na ⊂ {−N 2 + 1, . . . , N 2}. The parameters δf  cid:18 f , β, and symbols can be estimated by using the ML approach [66].  Error performance of OFDM systems with CFO has also been analyzed in the literature [7, 21]. In [21], exact closed-form BEP SEP expressions have been derived for an OFDM system with BPSK QPSK modulation and CFO in AWGN, frequency-ﬂat and frequency- selective Rayleigh fading channels. An exact BEP expression for an OFDM system with windowing reception has been derived in [7].  9.10.2 Phase noise effects on OFDM  Phase noise effects introduced by the LO in any receiver can only be mitigated by improv- ing the performance of the oscillator itself. Phase noise can be interpreted as a parasitic phase modulation in the oscillator’s signal. Two different kinds of effects that are intro- duced by phase noise into the OFDM signal are common phase error and ICI [3]. When there is a timing error or a carrier phase offset, phase rotation will occur. The phase noise is the sum of the common phase error and the carrier phase noise. The common phase error is the same for all subcarriers, and can be corrected by some kind of phase rotation. Carrier phase noise is caused by the imperfection of the transmitter and receiver oscillators. The ICI resembles Gaussian noise.  When the ratio of the phase noise bandwidth Bφ to the OFDM inter-carrier spacing  cid:18 f , Bφ  cid:18 f is small, the common phase error dominates over the ICI. This error can be cor- rected together with the channel effects by channel estimation, and the SEP is substantially reduced after the correction. As this ratio approaches unity, the ICI increases and the cor- rection capabilities decrease. When this ratio is greater than unity, it cannot be corrected since the ICI dominates the phase noise. SNR degradation caused by the phase noise is the same for both the OFDM and single- carrier systems. For small phase noise variance  σ 2  cid:5  1 , the SNR degradation is given by [3, 50]   cid:3    cid:18 γ = 10 log10  1 + σ 2 Es N0   dB ,   9.46   where the variance σ 2 can be calculated based on the phase-noise pdf and is given by   cid:2   cid:14   σ 2 =  b  2N0p  0  C  df ,   9.47   with N0p being the PSD of the phase noise and C the related carrier power. The frequency b is due to the band-limited phase noise or ﬁltering in the receiver.      318   cid:2   Orthogonal frequency division multiplexing   cid:19  The inﬂuence of carrier phase noise on system performance has also been analyzed in [62]. The carrier phase noise is modeled as the Wiener process θ t  with E[θ t ] = 0 and  θ  t + t0  − θ  t0  2 E of the Lorentzian power spectral density of the free-running carrier generator. For small impairments, the degradation in SNR can be approximated by [62]   cid:20  = 4πβt, where β, in hertz, is the single-sided 3-dB line width  γ  4πN   dB , where γ = Es N0, and W is the bandwidth of the OFDM signal. Although the SNR degradation caused by the phase noise is independent of the number of subcarriers in the OFDM signal and the phase noise bandwidth, the situation is different for correcting the common phase error by any phase correction scheme that takes advantage of the pilot-based correction mechanism.   9.48    cid:2    cid:3   β W  D ≈ 11 6 ln 10  9.10.3 Inﬂuence of timing offset  Since the bandwidth of the phase noise spectrum is wider than the subcarrier spacing, this leads to energy spillage into other subchannels and thus ICI. When there is a timing error, the FFT window at the receiver spans samples from two consecutive OFDM symbols, leading to an inter-OFDM symbol interference. Assuming that the Fourier transform of f  t  is F ω , the time-shift version of f  t , f  t−τ  , −jωτ F ω . Thus, a misalignment τ of the FFT window at the has the Fourier transform e receiver leads to a phase error of 2π  cid:18 f τ between two adjacent subcarriers. The phase error introduced has a considerable inﬂuence on the BEP performance of the OFDM sys- tem, especially in case of coherent detection. In order to use coherent detection, a phase correction mechanism has to be employed. As long as the timing offset τ satisﬁes 0 ≤ τ ≤ τmax − Tg, where τmax is the maximum channel delay spread and Tg = Tcp is the guard time, it still introduces ICI due to the loss of orthogonality and thus a degradation in performance. In this case, the timing offset can be included into the channel estimation. If τ is not within this window, ISI occurs even if the phase shift is accounted for. The ICI loss can be approximated by [2, 59]   cid:12    cid:2    cid:13    cid:3 2  ICI ≈ 10 log10  2  τ Ts   dB .   9.49   From this, we see that timing synchronization is not a critical problem as long as the induced phase change is corrected, since typically τ  cid:5  Ts.  9.10.4 Implementation of synchronization  Synchronization is usually implemented in two steps: acquisition  coarse synchronization  phase and tracking  ﬁne synchronization  phase, to achieve a minimal computational load and a minimal information overhead. Coarse timing and frequency acquisition relies on      319   cid:2   9.10 Synchronization  pilot symbols or pilot tones embedded into the OFDM symbols, while ﬁne timing and frequency tracking exploits the cyclic extension of the OFDM signal. For TDMA-based OFDM systems, frame synchronization between a BS and an MS also needs to be main- tained. This added redundancy can be further used for frequency synchronization as well as FFT window alignment.  Initially a frame synchronization circuit is used to detect the frame starting point, which is usually achieved by correlating the incoming signal with a known preamble. This cir- cuit can also be used for initial gain control. Since timing offset only introduces a phase rotation, which linearly increases with the order of the subcarrier and does not violate orthogonality of the symbols, it can be compensated after FFT. Frequency offset inﬂu- ences the orthogonality, and must be corrected before applying FFT. This requires a fast coarse acquisition, and the PLL technique is not viable for this purpose. In stead, a pilot sequence is usually transmitted. Synchronization of the OFDM system can be performed in the following steps:   Coarse timing recovery frame synchronization;   Coarse frequency offset correction;   Fine frequency correction  after FFT ;   Fine timing correction  after FFT .  Timing offset and CFO detections can be implemented by using the correlation, ML, and MMSE approaches.  Synchronization using pilot symbols  Synchronization using pilot symbols is reliable and widely used in communications, although it has a small bandwidth overhead. This method can be used to synchronize frame  packet or slot  timing, symbol timing, and to estimate CFO at the initial stage of synchronization.  In [69], Schmidl and Cox proposed a synchronization scheme that uses a two-symbol training sequence. The ﬁrst training symbol consists of two identical halves in the time domain. Correlation between the two halves is used for frame and symbol timing. The second training symbol is composed of two PN sequences, one on the odd frequencies for estimating the subchannels and the other on the even frequencies to determine the frequency offset. The second training symbol is used for ﬁne frequency estimation. The selection of a particular PN sequence does not have much inﬂuence on the performance of the synchronization, but the PN sequence should be selected so as to make it easy to implement or to have a low PAPR.  In [16], the two pilot symbols modulated by two PN sequences in [69] are replaced by a single pilot symbol modulated by an m-sequence. This improved version reduces the overhead and maximizes the pilot symbol SNR at the receiver. The method can also estimate the subsample timing offset. However, its use of a matched ﬁlter leads to higher complexity. The Schmidl-Cox Scheme has been used for synchronization in IEEE 802.11a.      320   cid:2   Orthogonal frequency division multiplexing  Timing synchronization  A positive offset in timing synchronization causes ISI between two successive OFDM symbols. Thus, the estimated start sample should be shifted several samples, although the shift decreases tolerance to multipath fading. For the ﬁrst training symbol u t , at time t in the ﬁrst half, we have u t  = u t + T 2 , thus,  ∗   t r t + T 2  = u t 2eπT cid:18 f+θ t+T 2 −θ t  ≈ u t 2eπT cid:18 f ,  r   9.50   where r t  is the received signal, θ t  is the phase shift caused by the channel to all the samples, T is the symbol period, and  cid:18 f is the CFO; for a slow-fading channel, θ t  is slowly changing. It is seen that the inﬂuence of the channel is negligible, but the frequency offset introduces a phase of πT cid:18 f . Timing synchronization can be achieved by cross-correlation. Frame symbol timing synchronization can be based on  9.50 . Assuming that there are L = N 2 samples in one-half of the ﬁrst training symbol, the correlation between the samples in the two halves is deﬁned by  R d  = L−1 cid:26   m=0  ∗ d+mrd+m+L,  r  where d is the time index of the ﬁrst sample in a window of 2L samples. At the start of a frame R d  has a peak.  Sampling clock offset is the misalignment between the DAC clock at the transmitter and the ADC clock at the receiver. The distortion arising from sampling frequency offset linearly increases with the index of the subcarrier. Sampling clock offset also introduces ISI. A sampling clock offset estimation method is given in [87].  Carrier synchronization  In the Schmidl-Cox scheme [69], at the receiver, the two identical halves in the ﬁrst training symbol remain identical but there is a phase difference between them, which is caused by the CFO. Thus, the ﬁrst training symbol is also used for coarse frequency offset estimation. In  9.50 , the CFO introduces a phase of φ = πT cid:18 f in the correlation between two samples T 2 apart in the ﬁrst training symbol. Since R d  is a sum of these correlations, the phase shift of R d  introduced by the CFO is also φ. If φ ≤ π, the CFO can be estimated by  Otherwise, an additional frequency offset 2i T, for integer i, exists due to the periodic nature of the phase:   9.51    9.52    9.53   = cid:18 f =  cid:18  R d   .  πT  = cid:18 f =  cid:18  R d   πT  + 2i T  .      321   cid:2   9.10 Synchronization  symbol. The estimated CFO with respect to the subcarrier spacing is ˆ cid:21  == cid:18 f T, where 1 T  This additional frequency offset can be further determined by using the second training  is the subcarrier spacing.  Carrier frequency offset estimation using one symbol with two identical halves can be modiﬁed into using two consecutive symbols carrying identical information [87]. Accordingly,  9.52  can be written as  ˆ cid:21  == cid:18 f T = 1  2π   cid:12  N−1 cid:26   m=0   cid:13   ∗ d+mrd+m+N  r  ,  where rd+m and rd+m+N are the two consecutive OFDM symbols, and d is the time index of the ﬁrst sample in a window of 2N samples.  Compensation of the frequency offset is performed by multiplying each distorted sample by a complex factor, αm, where m is the index of the sample. In the case of two identical half symbols, α = e −j2π  cid:21  N. To save computation time, αm can be recursively computed by using αm = ααm−1 or using a lookup table.  −jπ= cid:18 f T L = e  Synchronization by correlating the cyclic extension  Both frequency- and time-domain synchronization can be simultaneously obtained by using the cyclic preﬁx by means of correlation [33, 34, 75]. In fact, most timing recov- ery methods for OFDM rely on correlation. The scheme is used for ﬁne frequency and timing corrections after FFT. Assuming that the CFO is  cid:18 f =  cid:21  T, the downconverted output will be s t e j2π  cid:21 t T. If the signal is sampled at N times the symbol rate, the received signal samples in the AWGN channel are given by  r k  = s  k − τ0  e j2π  cid:21  k−τ0  N + n k ,  where τ0 is the timing offset in the samples. For 2N + Ncp consecutive samples, where N + Ncp samples correspond to a complete symbol with Ncp samples for the cyclic preﬁx. Assuming that the samples in the cyclic preﬁx are indexed as  the samples with indexes  I =4 I cid:14  =4   cid:7   cid:19   5  ,  5  τ0, τ0 + 1,··· , τ0 + Ncp − 1  τ0 + N,··· , τ0 + N + Ncp − 1  cid:8   ⎧⎨⎩ σ 2   cid:20  =  + σ 2 n , m = 0 −j2π  cid:21 , m = N s σ 2 s e 0,  otherwise  E  r k r  ∗   k + m   are replicas of the cyclic preﬁx. All received samples in the observation interval are identiﬁed as r 1 , . . . , r  2N + Ncp  .  By correlating the samples in the cyclic preﬁx and their replicas, we have [75]   9.54    9.55    9.56    9.57    9.58       cid:18   322   cid:2   Orthogonal frequency division multiplexing  s and σ 2  , where σ 2 n are the signal power and the noise power, respectively. , the correlation is zero. The correlation given in  9.58  can be used for  for k ∈ I ∪ I cid:14  For k  ∈ I ∪ I cid:14  estimation of the timing offset and the frequency offset. The peak of the correlation  9.58  can be used to estimate the timing offset, and the correlation for m = N can be used for estimating the frequency offset. More precise esti- mation of the timing offset and the frequency offset is given by the joint ML estimation of τ0 and  cid:21  [39, 75].  Another approach for synchronizing the frame position and the carrier frequency using the cyclic preﬁx correlation has been proposed in [34]. The implementation can be sim- pliﬁed by only using the sign bits of the in-phase and the quadrature components of the received OFDM signal for frame synchronization and frequency offset compensation.  The cyclic preﬁx correlation technique does not introduce any spectrum overhead, and it is actually a blind technique. However, it has some disadvantages. The peak of the corre- lation output varies from symbol to symbol, due to the randomness of the data. For small N, the sidelobes of the correlation output are comparable to the peaks. The method is only valid for ﬁnding symbol timing, but cannot detect the start of a frame, such as the start of a data packet.  Other synchronization schemes  Other schemes for OFDM synchronization are also available in the literature. In the DVB standard, a null symbol is used as the ﬁrst OFDM symbol in the time frame and the receiver detects it by monitoring the symbol energy [23]. This method is only valid for continuous transmission systems, since in other cases there is no difference between the null symbol and the idle period between signal bursts. Pilot designs for consistent frequency-offset estimation of OFDM systems in frequency-selective fading channels are treated in [43].  Virtual carriers have been exploited for blind CFO estimation [45]. The optimal virtual carrier placement that minimizes the CRLB of the CFO estimation is achieved by placing the virtual carriers with even spacing across the whole OFDM symbol [28]. This placement also maximizes the SNR and minimizes the theoretical MSE of the CFO estimation [86].  9.11 OFDM-based multiple access  OFDM is usually used as a modulation format for a single user, where all the subcarri- ers are used by a single user. For the purpose of multiple access, different users can be assigned different subcarriers, and each user can have multiple subcarriers. This strategy makes subcarrier administration very difﬁcult, and orthogonality between users does not obtain.  More often, OFDM is combined with TDMA or packet radio. Each user occupies the full band during a time slot or a packet transmission. This strategy is used in IEEE 802.11a. OFDM can also be combined with FDMA, where each user is assigned a subset of adjacent subcarriers, and bands of different users are separated by frequency guard.      323   cid:2   9.11 OFDM-based multiple access  In OFDMA, users share subcarriers and time slots. Thus, OFDMA is actually a hybrid of FDMA and TDMA. Different users within the same cell use different tones, and thus do not interfere other users. OFDM and CDMA can be combined into MC-CDMA, where spreading can be either in the time or the frequency domain.  OFDMA  OFDMA has the advantages of the single-user OFDM that we discussed earlier. In addi- tion, it is a ﬂexible multiple-access technique for many users with wide variation in data rates and QoS requirements. OFDMA has a reduced PAPR as compared to OFDM, since each MS uses only a small fraction of all the subcarriers. Lower data rates and bursty data can be transmitted more efﬁciently than single-user OFDM, TDMA, or CSMA.  OFDMA systems are sensitive to multipath fading. Different subchannels experience different fading. For those strongly attenuated subchannels, error correction has to be introduced, and this leads to a reduced spectral efﬁciency. MC-CDMA can better solve this problem. OFDMA requires overheads in both directions: the transmitter requires CSI from the receivers, and the receivers also need the information of their subcarrier assignment.  The OFDMA approach allows for increased multiuser diversity and adaptive modula- tion, which can boost the capacity. Multiuser diversity is obtained by adaptive subcarrier allocation so that data are sent to one or a subset of users with good channel conditions. Adaptive modulation transmits as high a data rate as possible for a good channel and at a lower rate for poor channels.  OFDMA can be implemented using fast hopping across all tones in a predetermined pseudorandom pattern, making it an SS technology. This adds the advantages of FH sys- tems in cellular deployment. OFDMA is at least three times more efﬁcient than CDMA at the physical layer [12]. Compared to CDMA and TDMA, OFDMA takes advantage of the granularity of OFDM in its control layer design, resulting in efﬁcient MAC and link layers for data. OFDMA eliminates some of the disadvantages of CDMA, such as the difﬁculty of adding capacity via microcells and the use of ﬁxed bandwidth size. OFDMA is used in the mobile WiMAX  IEEE 802.16e .  In [84], an algorithm that combines subcarrier, bit, and power allocations for OFDMA has been proposed to minimize the overall transmit power for given transmission rates and QoS requirements of the users by using instantaneous CSI. This approach allows all the subcarriers to be used more effectively, because a subcarrier will be left unused only if it is in deep fade to all users and all users transmit in all the time slots.  When the number of subcarriers is high, OFDMA has the disadvantage of high PAPR, sensitivity to CFO, and high complexity at MSs. Based on a layered FFT structure, quadrature OFDMA  Q-OFDMA  [92] achieves the same guard-interval overhead and same bandwidth occupation as OFDMA systems, but with reduced PAPR and improved CFO robustness and frequency diversity. It also achieves low-complexity downlink receivers.      324   cid:2   Orthogonal frequency division multiplexing  9.12 Performance of OFDM systems  The performance of the OFDM system in the AWGN channel is identical to that of a serial modem, since AWGN in the time domain corresponds to AWGN of the same average power in the frequency domain and the OFDM subcarriers are orthogonal. The opti- mum receiver for OFDM consists of a bank of correlators, one for each subcarrier. The error probability for each subcarrier is independent of the other subcarriers due to the orthogonal nature. The overall error probability can be obtained from the error probabil- ity of each subcarrier. For OFDM systems using a ﬁxed signal constellation in all the subcarriers, the total BEP is dominated by the subchannels that have the worst perfor- mance. The overall capacity of the OFDM system is the sum of the individual subchannel capacities.  The error performance of OFDM systems in various fading channels has been investi- gated in the literature. In [80], the SEP performance of MQAM and BPSK OFDM systems over frequency-selective Rayleigh-fading channels with Doppler spread is analyzed. The SEP performance for the MQAM OFDM systems over frequency-selective fast Ricean fading with Doppler spread is analyzed in [91]. A closed-form expression for the BEP of DMPSK OFDM systems in frequency-selective slow fast Rayleigh Ricean fading channels with diversity reception has been derived in [48]. In [22], the SEP of OFDM systems in slow Nakagami-m fading channels is given in closed form, and the analysis extended to a system using MRC diversity reception.  Water ﬁlling or bit loading  Multipath incurs frequency-selective fading. The distribution of the SNR at any frequency follows a Rayleigh distribution. The performance of the OFDM system over a stationary channel can be optimized by maximizing the overall bit rate for a given error probabil- ity, or by minimizing the error probability for a given bit rate. When the total power is constrained and the symbol rate is set to a target value, each subchannel is usually assigned the same error probability to achieve the minimum overall error probability. This approach has been shown to be suboptimum [83]. The optimum solution is derived by applying constraint on the SEP of each subchannel to the target value, rather than the BEP. This ﬁnally leads to the well-known water-ﬁlling solution. For the more common case of minimization of the BEP for a ﬁxed bit rate under a transmitter-power con- straint, the BEP must be below some target value. There are some algorithms to solve this problem [14].  In OFDM, bit loading harnesses the channel knowledge. At frequencies with high SNR, higher-order modulation is used, while at frequencies with low SNR, lower-order modula- tion is employed or no information is sent at all. Bit loading can be based on maximizing the total rate subject to total-transmitted-power constraint, or minimizing the total trans- mitted power subject to the total-rate constraint. Bit loading approaches the water-ﬁlling solution for transmit-spectrum allocation in order to achieve the channel capacity. It is      325   cid:2   9.12 Performance of OFDM systems  noted in [15] that the use of OFDM with equal power allocated on all subcarriers does not lead to any capacity reduction for large N and ﬁnite power.  Bit-loading algorithms can be classiﬁed into three categories: incremental allocation [35], channel-capacity approximation-based allocation [13, 56], and BEP expression- based allocation [25]. Incremental allocation starts from an all-zero allocation, and an additional bit incremental energy until either the total power or the aggregate BEP constraints are violated [35]. In [13, 56], the channel-capacity approximation is used for computing the bit allocation across all subcarriers. In [25], closed-form error-probability expressions are used for bit and power allocation on the subcarriers with a speciﬁed error-rate constraint.  is allocated to the subcarrier requiring the smallest  Comparison with single-carrier techniques   cid:7    cid:8   B2Tm  Since OFDM is implemented with FFT IFFT, it has a complexity of O  TmB log B , as for a standard time-domain equalizer, where B ≈ 1 T is the opposed to O bandwidth or the data rate, T being the symbol period, and Tm the delay spread. A typ- ical wireless environment experiences delay spread of up to 800 ns. For a data rate of 10 Mbits s, this covers several symbols if a single carrier is used. An equalizer such as a DFE can be used, but there must be a sufﬁcient number of taps. The equalizer coefﬁcients must be trained for each packet, leading to a large overhead. OFDM is most suitable for high-speed transmission at say, 60 GHz.  Recently, SC-FDE have been shown to have similar performance and complexity com- pared to the OFDM technique, but have a number of advantages over OFDM [17]  refer to Section 6.2.6 . It may become an alternative to OFDM in future-generation wireless systems.  Spread spectrum and OFDM represent  two opposite approaches to combating frequency-selective channels. The DS-CDMA system spreads the bandwidth, and then uses the rake receiver for multipath separation. Due to imperfect separation, path crosstalk remains. In contrast, OFDM converts a frequency-selective channel into many ﬂat-fading channels, enabling very simple receivers. Compared with DS-CDMA, OFDM has the advantages of computational efﬁciency, no near-far problem since no correlation is used, and fast synchronization. These are achieved at the expense of an SNR loss due to the guard interval. The SNR is changed by a factor δ = 1 − Ncp N + Ncp   9.59   =  1  1 + Ncp  ,  N  where Ncp is the number of samples in the cyclic preﬁx and N is the number of subchannels. This SNR loss can be reduced by decreasing the ratio Ncp N. In addition, the narrowband subcarriers generate ﬂat-fading conditions, thus no frequency diversity can be exploited. The combination of the two approaches has been explored for future mobile radio systems [33, 38, 90].      326   cid:2   Orthogonal frequency division multiplexing  9.13 Multi-carrier CDMA  Recently, the MC-CDMA system, as a combination of OFDM and CDMA, has received attention for feasibility of an air interface for 4G mobile communications [33]. MC- CDMA effectively mitigates multipath interference and also provides multiple-access capability.  Unlike DS-CDMA that applies spreading sequences in the time domain, MC-CDMA applies spreading sequences in the frequency domain, mapping a different chip to a different OFDM subcarrier. MC-CDMA transmits a data symbol on all the subcarriers simultaneously. The overall MC-CDMA transmitter can be implemented by a DS-CDMA spreader followed by an OFDM transmitter. A code symbol is ﬁrst mapped to a vec- tor by using an N-dimensional spreading sequence, N being the number of subcarriers. By performing symbol spreading on the ith symbol for user j, dj,i, we have the spread symbols  ˜dj,i = dj,icj,  where K is the number of users, and cj = cid:7   cid:17 ˜d1,i, . . . , ˜dK,i  cid:7  sj,i t  = N−1 cid:26   , the sequence   cid:8   is the code vector of the jth user, cj,k being the kth chip of the spreading sequence of the jth user. All the code vectors cj are orthogonal, and the Walsh codes are especially suitable as the spreading codes. Instead of d1,i,··· , dK,i The transmitted signal of the ith symbol of the jth user, sj,i t , is denoted by [33, 90]  is then OFDM-modulated.   cid:18    cid:8  j = 1, . . . , K, cj,0, . . . , cj,N−1  dj,icj,ke2π  f0+kfd tp t − iT ,   9.60    9.61   k=0  where f0 is the frequency of the lowest subcarrier, fd is the subcarrier separation, and p t  is the rectangular pulse with value 1 for t ∈ [0, T] and 0 otherwise. When fd = 1 T, the transmitted signal can be generated using IFFT. When each user transmits M bits during a signaling interval, this leads to a spreading factor or processing gain G = N M. When the number of users K = G, we get a fully loaded system, and the MAI dominates the system perfor- mance, which becomes poor. The fully loaded MC-CDMA system usually uses Walsh codes.  At the receiver, the signal is ﬁrst OFDM-demodulated; the output is the convolution . By using the jth user’s  cid:14  j,i, can be obtained. By using a ZF or  of the channel and the spread symbol sequence spreading sequence, the ith symbol of the jth user, d MMSE equalizer, the unspread symbols d1,i, . . . , dK,i The ith received symbol at the kth carrier is given as  can be obtained.   cid:18    cid:17 ˜d1,i, . . . , ˜dK,i  cid:8   Hkdj,icj,k + nk,i,   9.62    cid:7  rk,i = K−1 cid:26   j=0  where Hk is the frequency response of the kth subcarrier, and nk,i is the corresponding noise sample.      327   cid:2   9.13 Multi-carrier CDMA  For the jth user, the ﬁnal decision variable dj,i is given by  dj,i = N−1 cid:26   k=0  cj,kgkrk,i,   9.63   where the gain gk is given by the reciprocal of the estimated channel transfer factor of subcarrier k. To maintain orthogonality between different users, FDE must be performed on the received subcarrier symbols. BEP analysis has been performed over both the Rayleigh and Ricean fading channels for various equalization methods in [90].  MC-CDMA also has the PAPR problem. Spreading usually has no signiﬁcant impact on PAPR [51]. The average transmitted power is proportional to the number of simultane- ously used spreading codes [33]. MUD can also be implemented in MC-CDMA. Various multicarrier-based CDMA systems are described in [79].  Multicode MC-CDMA using MMSE combining provides a performance superior to that of OFDM for the same data rate and the same bandwidth [37]. The best performance is achieved by using the largest possible spreading factor, that is, the number of subcarriers, since by spreading the same data symbol over all subcarriers, frequency diversity can be maximally exploited by using MMSE combining [37].  Spreading codes for MC-CDMA  For MC-CDMA, the Walsh code and the orthogonal Gold code can be used. Complex orthogonal sequences such as the family of Frank codes and Zadoff-Chu codes have also been applied for MC-CDMA [64]. Compared to the orthogonal Gold code and the Walsh code, the Frank code and the Zadoff-Chu code have lower off-peak autocorrela- tion, which helps peak factor reduction and reliable code-acquisition for synchronization [33]. The family of Zadoff-Chu codes is shown to be similar to the set of Newman phases and Schroeder phases [33]. Both the Frank code and the Zadoff-Chu code have perfect periodic autocorrelations. The Zadoff-Chu code achieves the lowest peak factor among the four spreading sequences. The all-zero sequence of the Walsh code yields the highest possible autocorrelation, and hence yields the highest possible peak factor of N.  These spreading codes are used when all users occupy the same set of subcarriers. When different MSs are assigned nonoverlapping sets of subcarriers, we need only one spread- ing sequence, and any of the sequence that can produce a low power factor, such as the Newman phases, can be used.  Many results for CDMA systems such as the SIC receiver and the MMSE receiver can  be modiﬁed and applied to MC-CDMA [29].  Fourier code  The columns of a Fourier matrix can be considered as orthogonal spreading codes. The spreading code for user k is ck =  ck,0, ck,1, . . . , ck,L T, and the chip ck,l = e −j2πlk L. If Fourier spreading is applied in MC-CDMA systems, the FFT operation is canceled by the      328   cid:2   Orthogonal frequency division multiplexing  IFFT for the OFDM operation if they are of the same size [8]. This yields an SC-FDE system with cyclic preﬁx. The Fourier code leads to an equal or lower PAPR, compared with the Walsh code [9]. The Fourier code is applied in DFT-spread OFDM, which is used for the uplink of LTE.  The Zadoff-Chu code is deﬁned as     Zadoff-Chu code  ck,l =  e j2πk ql+l2 2  L e j2πk ql+l l+1  2  L   for L even   for L odd    9.64  where q is any integer and k is prime with L. For L prime, a set of L − 1 sequences is obtained. The Zadoff-Chu code has an optimum periodic ACF and a low constant- magnitude periodic CCF. When used for MC-CDMA, the PAPR bounds for MC-CDMA uplink signals are 2 for the Zadoff-Chu code, ≤ 4 for the Golay code, ≤ 2L for the Walsh code, and ≤ 2 t m  − 1 − t m +2    for the Gold code, where t m  is given by  8.8  [24].  L  Comparison with other techniques  The main advantage of MC-CDMA over other OFDM-based multiple access techniques is the inherent frequency diversity provided by MC-CDMA. This advantage is at the cost of higher MAI.  In DS-CDMA, the rake receiver is used to exploit the multipath diversity, but the num- ber of ﬁngers  diversity order  is limited by the complexity. In comparison, MC-CDMA can easily achieve a high diversity order by transmitting the same information on several subcarriers.  The maximum achieved order of frequency diversity is limited by [33, 65]  L ≈ W Bc   9.65   where W is the total bandwidth of the channel and Bc is its coherent bandwidth. Spread- ing over more than L subcarriers leads to no more increase in terms of diversity gain, but a rapid increase in MAI, which causes a decrease in the overall performance of the system.  In a single-cell scenario, MC-CDMA achieves frequency diversity when there is no CSI at the transmitter, while OFDMA achieves a higher capacity by exploiting mul- tiuser diversity over the frequency domain with CSI at the transmitter [47]. In a multi-cell multiuser downlink scenario, OFDMA and MC-CDMA have been compared in terms of system ergodic capacity and system goodput in [10]. For high-speed data communications, OFDMA outperforms MC-CDMA; the achievable goodput of OFDMA can sometimes be even higher than the ergodic capacity of MC-CDMA. For voice users, MC-CDMA shows noticeably higher goodput than the OFDMA. These results are also applicable for the MIMO case [10, 47].      329   cid:2   9.14 Other OFDM-associated schemes  9.14 Other OFDM-associated schemes  Multi-carrier DS-CDMA and multi-tone CDMA  In addition to MC-CDMA, there are some other schemes for combining OFDM and CDMA, such as multi-carrier DS-CDMA  MC-DS-CDMA  and multi-tone CDMA  MT- CDMA  [33]. In MC-CDMA, at the transmitter the bitstream having a bit rate of 1 T is ﬁrst spread, yielding a bit rate of N T; then by assigning it to the N subcarriers, the bitstream on each subcarrier is reduced to 1 T again.  MC-DS-CDMA is very similar to MC-CDMA. In MC-DS-CDMA,  the bit rate Rb is ﬁrst reduced by a factor of N before being assigned to N carriers, each of the bitstreams is then spread by a factor of G, before applying MCM. To main- tain orthogonality between subcarriers, MC-DS-CDMA has the subcarrier separation fd = RbG N. MT-CDMA [76] is similar to MC-DS-CDMA in data mapping and spreading, but it uses spreading codes which are approximately Nc times longer than that used in MC- DS-CDMA; thus, the processing gain of MT-CDMA is Nc times that of MC-DS-CDMA. Orthogonality between subcarriers is not maintained in MT-CDMA.  Non-FFT-based OFDM  The widely adopted OFDM schemes are all FFT-based. Other non-FFT-based schemes such as the wavelet-transform-based OFDM  wavelet OFDM  and the DCT-based OFDM have also been proposed recently. MCM is very similar to sub-band coding. Like sub-band coding, many MCM schemes that use this idea, such as wavelet-based fractal modulation [85], wavelet packet modulation [44], wavelet PAM [46], and overlapped discrete wavelet multitone [67], have been proposed. In addition, the MASK-OFDM can be efﬁciently implemented by DCT [88].  Transform-domain communication system  The transform-domain communication system  TDCS  [73] is a recent technique that syn- thesizes a smart adaptive waveform to avoid interference at the transmitter rather than at the receiver. TDCS avoids existing users and jammers by notching or removing their bands prior to generating the time-domain fundamental modulation waveform by using IFFT. Like MC-CDMA, TDCS also achieves multiple access using PN sequences. Like OFDM and MC-CDMA, TDCS is also FFT-based.  Generalized multi-carrier System  In order to retain high orthogonality between subcarriers as well as high spectral efﬁciency, the OFDM technology is usually used at low mobility  low Doppler spread  and a small time delay spread. In case of high mobility of the MS, where the Doppler shift and time      330   cid:2   Orthogonal frequency division multiplexing  delay spread are high, the generalized multi-carrier  GMC  scheme can be applied, since no assumption of orthogonality between subcarriers is made and each carrier signal can be transmitted on a non-ﬂat-fading channel. GMC is a nonothogonal multicarrier transmission technology with a relatively high complexity.  Problems  9.1 IEEE 802.16e is designed to allow a delay spread of up to στ = 20 μs and the maximum speed of v = 125 km h. In the OFDMA mode, the subcarrier spac- ing is designed to be  cid:18 f = 11.16 kHz, and the OFDM symbol duration is 100 μs. Determine the maximum frequency-domain spacing and time-domain spacing for the pilots. 9.2 For an OFDM system with N = 4 subcarriers, if the CP has a length of Ng = 2 and the wireless channel has a length of L = 3, the received signal is given by  r n  = 0.8c n  − 0.5c n − 1  − 0.3c n − 2 .  Two blocks of binary data symbols are fed to the IDFT unit, c0 = [1,−1,−1, 1]T and c1 = [−1,−1,−1, 1]T. Show the estimated symbols at the receiver. Assume the channel is known to the receiver. Compare this result with that of Problem 6.1.  9.3 Consider a signal with a bandwidth of 1 MHz and a data rate of 1 Mbit s. The wireless channel has a delay spread of 10 μs.  a  Design an OFDM system for this purpose. Give the number of subchannels, the modu- lation, and the data rate on each subchannel.  b  If raised cosine pulse with the roll-off factor α = 1 is used, and the subcarriers are separated by the minimum bandwidth necessary for retaining orthogonality, redesign the OFDM system.  c  For case  b , assuming the SNR on each subchannel is 15 dB, ﬁnd the maxi- mum constellation size for MQAM modulation that can be transmitted over each sub- −4, as well as the corresponding data rate of the channel with a target BEP of 10 system.  9.4 Find the data rate of an IEEE 802.11a system, if 16 out of the available 48 sub- channels are BPSK-modulated with a rate-1 2 channel code and the remaining are 16QAM-modulated with a rate-3 4 channel code.  9.5 Evaluate the cost of the cyclic preﬁx in OFDM in terms of  a  extra channel bandwidth, and  b  extra signal energy. 9.6 Given β = 1 150, N = 256, δ = 0, σ 2 −3. Using  9.43 , plot the SNR degradation versus the subcarrier index n, for various esti- mated values of β, that is, for different values of ˆβ β. Compare your plot with Fig. 3  H n  = 1, σ 2  w = 10  = 1, σ 2  s  in [66].      331   cid:2   References  References  [1] M. Al-Akaidi & O. Daoud, Reducing the peak-to-average power ratio using turbo  coding. IEE Proc. Commun., 153:6  2006 , 818–821.  [2] J. G. Andrews, A. Ghosh, & R. Muhamed, Fundamentals of WiMAX: Understanding  Broadband Wireless Networking  Upper Saddle River, NJ: Prentice Hall, 2007 .  [3] A. G. Armada, Understanding the effects of phase noise in orthogonal frequency divi-  sion multiplexing  OFDM . IEEE Trans. Broadcast., 47:2  2001 , 153–159.  [4] J. Armstrong, Peak-to-average power reduction for OFDM by repeated clipping and  frequency domain ﬁltering. Electron. Lett., 38:8  2002 , 246–247.  [5] A. R. S. Bahai, M. Singh, A. J. Goldsmith & B. R. Saltzberg, A new approach for evaluating clipping distortion in multicarrier systems. IEEE J. Sel. Areas Commun., 20:5  2002 , 1037–1046.  [6] R. W. Bauml, R. F. H. Fisher & J. B. Huber, Reducing the peak-to-average power ratio of multicarrier modulation by selected mapping. Electron. Lett., 32:22  1996 , 2056–2057.  [7] N. C. Beaulieu and P. Tan, On the effects of receiver windowing on OFDM perfor- mance in the presence of carrier frequency offset. IEEE Trans. Wireless Commun., 6:1  2007 , 202–209.  [8] K. Bruninghaus & H. Rohling, On the duality of multi-carrier spread spectrum and single-carrier transmission. In Proc. Int. Workshop Multi-Carrier Spread Spectrum  MC-SS , Oberpfaffenhofen, Germany, Apr 1997, 187–194.  [9] A. Bury & J. Lindner, Comparison of amplitude distributions for Hadamard spread- ing and Fourier spreading in multi-carrier code division multiplexing. In Proc. IEEE GLOBECOM, San Francisco, CA, Nov Dec 2000, 857–860.  [10] P. W. C. Chan, E. S. Lo, V. K. N. Lau, R. S. Cheng, K. B. Letaief, R. D. Murch & W. H. Mow, Performance comparison of downlink multiuser MIMO-OFDMA and MIMO-MC-CDMA with transmit side information – multi-cell analysis. IEEE Trans. Wireless Commun., 6:6  2007 , 2193–2203.  [11] R. W. Chang, Synthesis of band-limited orthogonal signals for multichannel data  transmission. Bell Syst. Tech. J., 45  1966 , 1775–1796.  [12] H.-H. Chen & M. Guizani, Next Generation Wireless Systems and Networks  Chich-  ester, UK: Wiley, 2006 .  [13] P. S. Chow, J. M. Ciofﬁ & J. A. C. Bingham, A practical discrete multitone transceiver loading algorithm for data transmission over spectrally shaped channels. IEEE Trans. Commun., 43:2–4  1995 , 773–775.  [14] J. M. Ciofﬁ, G. P. Dudevoir, M. V. Eyuboglu & G. D. Forney, Jr., MMSE decision- feedback equalizers and coding – part I: equalization results. IEEE Trans. Commun., 43:10  1995 , 2582–2594.  [15] A. Clark, P. J. Smith & D. P. Taylor, Instantaneous capacity of OFDM on Rayleigh-  fading channels. IEEE Trans. Inf. Theory, 53:1  2007 , 355–361.      332   cid:2   Orthogonal frequency division multiplexing  [16] A. Coulson, Maximum likelihood synchronization for OFDM using a pilot symbol: algorithms; analysis. IEEE J. Sel. Areas Commun., 19:12  2001 , 2486–2494; 2495– 2503.  [17] A. Czylwik, Comparison between adaptive OFDM and single carrier modulation with frequency domain equalization. In Proc. IEEE VTC, Phoenix, AZ, May 1997, 2, 865– 869.  [18] O. Daoud & O. Alani, Reducing the PAPR by utilisation of the LDPC code. IET  Commun., 3:4  2009 , 520–529.  [19] D. Dardari, V. Tralli & A. Vaccari, A theoretical characterization of nonlinear distor-  tion effects in OFDM systems. IEEE Trans. Commun., 48:10  2000 , 1755–1764.  [20] J. Davis & J. Jedwab, Peak-to-mean power control in OFDM, Golay complementary  sequences, and Reed-Muller codes. IEEE Trans. Inf. Theory, 45:7  1999 , 2397–2417.  [21] P. Dharmawansa, N. Rajatheva & H. Minn, An exact error probability analysis of  OFDM systems with frequency offset. IEEE Trans. Commun., 57:1  2009 , 26–31.  [22] Z. Du, J. Cheng & N. C. Beaulieu, Accurate error-rate performance analysis of OFDM on frequency-selective Nakagami-m fading channels. IEEE Trans. Commun., 54:2  2006 , 319–328.  [23] K. Fazel, S. Kaiser, P. Robertson & M. J. Ruf, A concept of digital terrestrial television  broadcasting. Wireless Pers. Commun., 2:1 2  1995 , 9–27.  [24] K. Fazel & S. Kaiser, Multi-Carrier and Spread Spectrum Systems: From OFDM and  MC-CDMA to LTE and WiMAX, 2nd edn  Chichester, UK: Wiley, 2008 .  [25] R. Fischer, A new loading algorithm for discrete multitone modulation. In Proc. IEEE  GLOBECOM, London, UK, Mar 1996, 724–728.  [26] R. L. Frank, Polyphase complementary codes. IEEE Trans. Inf. Theory, 26:6  1980 ,  641–647.  [27] P. K. Frenger & N. A. B. Svensson, Decision-directed coherent detection in multi- carrier systems on Rayleigh fading channels. IEEE Trans. Veh. Tech., 49:2  1999 , 490–498.  [28] M. Ghogho, A. Swami & G. Giannakis, Optimized null-subcarrier selection for CFO estimation in OFDM over frequency-selective fading channels. In Proc. IEEE GLOBECOM, San Antonio, TX, Nov. 2001, 1, 202–206.  [29] S. Glisic, Advanced Wireless Communications: 4G Technologies, 2nd edn  Chich-  ester, UK: Wiley-IEEE, 2007 .  [30] M. J. E. Golay, Complementary series. IRE Trans. Inf. Theory, 7:2  1961 , 82–87. [31] S. H. Han & J. H. Lee, An overview of peak-to-average power ratio reduction techniques for multicarrier transmission. IEEE Wireless Commun., 12:2  2005 , 56–65.  [32] S. H. Han, J. M. Ciofﬁ & J. H. Lee, On the use of hexagonal constellation for peak-to- average power ratio reduction of an OFDM signal. IEEE Trans. Wireless Commun., 7:3  2008 , 781–786.  [33] L. Hanzo, M. Munster, B. J. Choi & T. Keller, OFDM and MC-CDMA for Broadband Multi-User Communications, WLANs and Broadcasting  New York: Wiley-IEEE, 2003 .      333   cid:2   References  [34] M.-H. Hsieh & C.-H. Wei, A low-complexity frame synchronization and frequency offset compensation scheme for OFDM systems over fading channels. IEEE Trans. Veh. Tech., 48:5  1999 , 1596–1609.  [35] D. Hughes-Hartogs, Ensemble Modem Structure for Imperfect Transmission Media, U.S. Patents Nos. 4,679,227, Jul 1987; 4,731,816, Mar 1988; and 4,833,796, May 1989.  [36] A. D. S. Jayalath & C. Tellambura, SLM and PTS peak-power reduction of OFDM signals without side information. IEEE Trans. Wireless Commun., 4:5  2005 , 2006– 2013.  [37] R. Kimura & E. Adachi, Comparison of OFDM and multicode MC-CDMA in  frequency selective fading channel. Electron. Lett., 39:3  2003 , 317–318.  [38] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [39] N. Lashkarian & S. Kiaei, Class of cyclic-based estimators for frequency-offset  estimation of OFDM systems. IEEE Trans. Commun., 48:12  2000 , 2139–2149.  [40] K. N. Le, Bounds on inter-carrier interference power of OFDM in a Gaussian  scattering channel. Wireless Pers. Commun., 47:3  2008 , 355-C362.  [41] C. Li & S. Roy, Subspace-based blind channel estimation for OFDM by exploiting  virtual carriers. IEEE Trans. Wireless Commun., 2:1  2003 , 141–150.  [42] Y. Li & L. J. Cimini, Bounds on the interchannel interference of OFDM in time-  varying impairments. IEEE Trans. Commun., 49:3  2001 , 401–404.  [43] Y. Li, H. Minn, N. Al-Dhahir & A. R. Calderbank, Pilot designs for consistent frequency-offset estimation in OFDM systems. IEEE Trans. Commun., 55:5  2007 , 864–877.  [44] A. R. Lindsey, Wavelet packet modulation for orthogonally transmultiplexed commu-  nication. IEEE Trans. Signal Process., 45:5  1997 , 1336–1339.  [45] H. Liu & U. Tureli, A high-efﬁciency carrier estimator for OFDM communications.  [46] J. N. Livingston & C. Tung, Bandwidth efﬁcient PAM signaling using wavelets. IEEE  IEEE Commun. Lett., 2:4  1998 , 104–106.  Trans. Commun., 44:12  1996 , 1629–1631.  [47] E. S. Lo, P. W. C. Chan, V. K. N. Lau, R. S. Cheng, K. B. Letaief, R. D. Murch & W. H. Mow, Adaptive resource allocation and capacity comparison of downlink multiuser MIMO-MC-CDMA and MIMO-OFDMA. IEEE Trans. Wireless Commun., 6:3  2007 , 1083–1093.  [48] J. Lu, T. T. Tihung, F. Adachi & C. L. Huang, BER performance of OFDMCMDPSK system in frequency-selective Rician fading with diversity reception. IEEE Trans. Veh. Tech., 49:4  2000 , 1216–1225.  [49] D. J. G. Mestdagh, P. Spruyt & B. Biran, Analysis of clipping effect in DMT-based  ADSL systems. In Proc. IEEE ICC, New Orleans, LA, May 1994, 293–300.  [50] M. Moeneclaey, The effect of synchronization errors on the performance of orthogo- nal frequency-division multiplexed  OFDM  systems. In Proc. COST 254  Emergent Techniques for Communication Terminals , Toulouse, France, Jul 1997, Paper 5.1.  [51] A. F. Molisch, Wireless Communications  Chichester, UK: Wiley-IEEE, 2005 .      334   cid:2   Orthogonal frequency division multiplexing  [52] M. Muck, M. de Courville, and P. Duhamel, A pseudorandom postﬁx OFDM modu- lator – semi-blind channel estimation and equalization. IEEE Trans. Signal Process., 54:3  2006 , 1005–1017.  [53] S. H. Muller & J. B. Huber, OFDM with reduce peak-to-average power ratio by optimum combination of partial transmit sequences. Electron. Lett., 33:5  1997 , 368–369.  [54] B. Muquet, M. de Courville & P. Duhamel, Subspace-based blind and semi-blind channel estimation for OFDM systems. IEEE Trans. Signal Process., 50:7  2002 , 1699–1712.  [55] B. Muquet, Z. Wang, G. B. Giannakis, M. de Courville & P. Duhamel, Cyclic preﬁx- ing or zero padding for wireless multicarrier transmissions? IEEE Trans. Commun., 50:12  2002 , 2136–2148.  [56] S. Nader-Esfahani & M. Afrasiabi, Simple bit loading algorithm for OFDM-based  systems. IET Commun., 1:3  2007 , 312–316.  [57] R. Nilsson, O. Edfors, M. Sandell & P. O. Borjesson, An Analysis of two-dimensional pilot-symbol assisted modulation for OFDM. In Proc. IEEE ICPWC, Bombay, India, Dec 1997, 71–74.  [58] H. Ochiai & H. Imai, Performance analysis of deliberately clipped OFDM signals.  IEEE Trans. Commun., 50:1  2002 , 89–101.  [59] J. M. Paez-Borrallo, Multicarrier vs. monocarrier modulation techniques: An intro-  duction to OFDM. In Proc. Berkeley Wireless Research Center Retreat, Jan 2000.  [60] A. Peled & A. Ruiz, Frequency domain data transmission using reduced compu- tational complexity algorithms. In Proc. IEEE ICASSP, Denver, CO, Jun 1980, 964–967.  [61] T. Pollet, P. Spruyt & M. Moeneclaey, The BER performance of OFDM systems using non-synchronized sampling. In Proc. IEEE Globecom, San Francisco, CA, Nov–Dec 1994, 1, 253–257.  [62] T. Pollet, M. van Bladel & M. Moeneclaey, BER sensitivity of OFDM systems to car- rier frequency offset and Wiener phase noise. IEEE Trans. Commun., 43:2–4  1995 , 191–193.  [63] B. M. Popovic, Synthesis of power efﬁcient multitone signals with ﬂat amplitude  spectrum. IEEE Trans. Commun., 39:7  1991 , 1031–1033.  [64] B. M. Popovic, Spreading sequences for multicarrier CDMA systems. IEEE Trans.  Commun., 47:6  1999 , 918–926.  [65] J. G. Proakis & D. G. Manolakis, Digital Signal Processing: Principle, Algorithms,  and Applications, 4th edn  Upper Saddle River, NJ: Pearson Prentice Hall, 2007 .  [66] A.-B. Salberg & A. Swami, Doppler and frequency-offset synchronization in wide-  band OFDM. IEEE Trans. Wireless Commun., 4:6  2005 , 2870–2881.  [67] S. Sandberg & M. Tzannes, Overlapped discrete multitone modulation for high speed copper wire communications. IEEE J. Sel. Areas Commun., 13:9  1995 , 1571–1585. [68] A. Scaglione, G. B. Giannakis & S. Barbarossa, Redundant ﬁlterbank precoders and equalizers – I: uniﬁcation and optimal designs; II: blind channel estimation, synchronization, and direct equalization. IEEE Trans. Signal Process., 47:7  1999 , 1988–2006; 2007–2022.      335   cid:2   References  [69] T. M. Schmidl & D. C. Cox, Robust frequency and timing synchronization for OFDM.  IEEE Trans. Commun., 45:12  1997 , 1613–1621.  [70] S. B. Slimane, Reducing the peak-to-average power ratio of OFDM signals through  precoding. IEEE Trans. Veh. Tech., 56:2  2007 , 686–695.  [71] T. Strohmer & S. Beaver, Optimal OFDM design for time-frequency dispersive  channels. IEEE Trans. Commun., 51:7  2003 , 1111–1122.  [72] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  2001 .  [73] P. J. Swackhammer, M. A. Temple & R. A. Raines, Performance simulation of a transform domain communication system for multiple access applications. In Proc. IEEE MILCOM, Atlantic City, NJ, Oct–Nov 1999, 2, 1055–1059.  [74] S. C. Thompson, A. U. Ahmed, J. G. Proakis, J. R. Zeidler & M. J. Geile, Constant  envelope OFDM. IEEE Trans. Commun. 56:8  2008 , 1300–1312.  [75] J.-J. van de Beek, M. Sandell & P. Borjesson, ML estimation of time and frequency  offset in OFDM systems. IEEE Trans. Signal Process., 45:7  1997 , 1800–1805.  [76] L. Vandendorpe, Multitone direct sequence CDMA system in an indoor wireless envi- ronment. In Proc. IEEE Symp. Commun. Veh. Technol., Delft, Netherlands, Oct 1993, 4.1.1–4.1.8.  [77] R. van Nee & A. de Wild, Reducing the peak-to-average power ratio of OFDM. In  Proc. IEEE VTC, Ottawa, Canada, May 1996, 3, 2072–2076.  [78] X. Wang, T. T. Tjhung & C. S. Ng, Reduction of peak-to-average power ratio of OFDM system using a companding technique. IEEE Trans. Broadcast., 45:3  1999 , 303–307.  [79] Z. Wang & G. B. Giannakis, Block spreading for multipath-resilient generalized multi-carrier CDMA. In G. B. Giannakis, Y. Hua, P. Stoica & L. Tong, eds., Signal Processing in Wireless & Mobile Communications: Trends in Single- and Multi-user Systems, 2  Upper Saddle River, NJ: Prentice Hall, 2001 , pp. 223–266.  [80] T. R. Wang, J. G. Proakis, E. Masry & J. R. Zeidler, Performance degradation of OFDM systems due to Doppler spreading. IEEE Trans. Wireless Commun., 5:6  2006 , 1422–1432.  [81] S. Weinstein & P. Ebert, Data transmission by frequency division multiplexing using  the discrete Fourier transform. IEEE Trans. Commun., 19:10  1971 , 628–634.  [82] T. A. Wilkinson & A. E. Jones, Minimisation of the peak-to-mean envelope power ratio of multicarrier transmission schemes by block coding. In Proc. IEEE VTC, Chicago, IL, Jul 1995, 2, 825–29  [83] T. J. Willink & P. H. Wittke, Optimization and performance evaluation of multicarrier  transmission. IEEE Trans. Inf. Theory, 43:2  1997 , 426–440.  [84] C. Y. Wong, R. S. Cheng, K. B. Letaief & R. D. Murch, Multiuser OFDM with adap- tive subcarrier, bit, and power allocation. IEEE J. Sel. Areas Commun., 17:10  1999 , 1747–1758.  [85] G. W. Wornell & A. V. Oppenheim, Wavelet based representations for a class of self- similar signals with application to fractal modulation. IEEE Trans. Inf. Theory, 38:2  1992 , 785–800.      336   cid:2   Orthogonal frequency division multiplexing  [86] Y. Wu, S. Attallah & J. W. M. Bergmans, On the optimality of the null subcarrier placement for blind carrier offset estimation in OFDM systems. IEEE Trans. Veh. Tech., 58:4  2009 , 2109–2115.  [87] W. Xiang, T. Pratt & X. Wang, A software radio testbed for two-transmitter two- receiver space-time coding OFDM wireless LAN. IEEE Commun. Mag., 42:6  2004 , S20–S28.  [88] F. Xiong, M-ary amplitude shift keying OFDM system. IEEE Trans. Commun., 51:10   2003 , 1638–1642.  2006 .  [89] F. Xiong, Digital Modulation Techniques, 2nd edn  Boston, MA: Artech House,  [90] N. Yee, J.-P. Linnartz & G. Fettweis, Multicarrier CDMA in indoor wireless radio  networks. In Proc. IEEE PIMRC, Yokohama, Japan, Sep 1993, 109–113.  [91] R. Y. Yen, H.-Y. Liu & W. K. Tsai, QAM symbol error rate in OFDM systems over frequency-selective fast Ricean-fading channels. IEEE Trans. Veh. Tech., 57:2  2008 , 1322–1325.  [92] J. A. Zhang, L. Luo & Z. Shi, Quadrature OFDMA systems based on layered FFT  structure. IEEE Trans. Commun., 57:3  2009 , 850–860.      10  Antennas  10.1 Maxwell’s equations  Maxwell’s equations are a set of four fundamental equations that govern all electromag- netic  EM  phenomena [28]. Maxwell’s equations can be in differential or integral form. In differential form, the four basic laws are given as  ∇ × E = − ∂B ∂t + J ∇ × H = ∂D ∂t ∇ · D = ρ ∇ · B = 0   Faraday’s law    Maxwell-Ampere law    Gauss’s electric law   Gauss’s magnetic law   where E is electric ﬁeld intensity  volts m2 , D electric ﬂux density  coulombs m2 , H mag- netic ﬁeld intensity  amperes m , B magnetic ﬂux density  webers m2 , J electric current density  amperes m2 , and ρ electric charge density  coulombs m3 .  Among the four Maxwell’s equations, any one can be derived from the other three by  using the equation of continuity  ∇ · J = − ∂ρ ∂t  There are three constitutive relations   Equation of continuity    10.5    10.1    10.2    10.3   10.4    10.6    10.7    10.8   D =  cid:21 E B = μH J = σ E  where  cid:21 , μ, and σ are, respectively, the permittivity  farads m , permeability  henrys m , and conductivity  siemens m  of the medium. These parameters are tensors in anisotropic media and scalars in isotropic media.  The three independent equations in Maxwell’s equations and the three constitutive  relations make all the six variables in Maxwell’s equations solvable.  Maxwell’s equations in time-harmonic form are obtained by setting the ﬁeld quantities as harmonically oscillating functions with a single frequency ω. Using the complex phasor notation, e jωt,  10.1 ,  10.2 , and  10.5  can be written in a simpliﬁed form as      338   cid:2   Antennas  ∇ × E = −jωB ∇ × H = jωD + J ∇ · J = −jωρ   10.9    10.10    10.11   The time-domain solution can be derived by using the Fourier transform.  In order to solve Maxwell’s equations, a number of boundary conditions must be spec- iﬁed to make the solution unique. For a second-order partial differential equation  PDE , the boundary conditions can be either the Dirichlet boundary condition  a value of the function φ is speciﬁed , a Neumann boundary condition  a value of the normal derivative, ∂φ ∂n , is speciﬁed , or a mixed boundary condition  a linear combination of a Dirichlet and a Neumann boundary condition .  10.2 Introduction to computational electromagnetics  Computational electromagnetics solves Maxwell’s equations subject to a set of bound- ary conditions associated with the domains by using numerical techniques. They are now fundamental for antenna and microwave RF design.  Three methods are widely used in computational electromagnetics, namely, the method of moments  MoM , the ﬁnite difference time domain  FDTD  method, and the ﬁnite element method  FEM . These methods are known as full-wave computational electro- magnetics methods. The full-wave methods approximate Maxwell’s equations numerically, without making any physical approximations. There are powerful commercial computer codes for all these methods.  The ﬁrst step for all the three methods is to discretize the domain and this process is known as meshing; this subdivides the domain into many elements. As a rule of thumb, each wavelength is segmented into ten segments in each geometrical dimension to maintain sufﬁcient accuracy. For the FDTD method, Maxwell’s equations are then converted into difference equations within each element, iteration goes on in each element for each time instant and the result is passed to neighboring elements. No linear algebra is required. For the MoM and the FEM, the second step is to select the interpolation function, known as the shape function, which relates the spatial variation of the unknowns within each element. This is followed by constructing the equation for each element and assembling them to form a system of equations. Finally, the system of linear equations is solved by using a direct solver such as Gaussian elimination or forward and backward substitution based on LU-factorization, or by using a recursive solver such as the conjugate-gradient method [12].  for  the three methods  A good introductory text  In addition to full-wave methods, asymptotic techniques, such as physical optics, geometrical optics, and the uniform theory of diffraction  UTD , are based on high- frequency approximation to Maxwell’s equations, and thus the validity increases with frequency.  is by Davidson [10].      339   cid:2   10.2 Introduction to computational electromagnetics  10.2.1 Method of moments  The MoM was ﬁrst introduced by Harrington into computational electromagnetics [18]. This method is also known as the boundary element method  BEM , where only the surface is meshed. The MoM is the most popular computational electromagnetics method for antenna engineering. It is also widely used in RF computational electromagnetics. The MoM is based on the integral form of Maxwell’s equations, and has been traditionally applied in the frequency domain.  The Numerical Electromagnetic Code – Method of Moments, widely known as NEC-2, is a powerful program for antenna modeling, that is available in the public domain. NEC-2 has no graphic abilities. There are some commercial codes incorporating all the functional- ity of NEC-2, but with better graphical functions and other enhancements. Some examples of the MoM codes are FEKO, Advanced Design System  ADS , Momentum, Zeland’s IE3D, SuperNEC, Ansoft’s Ensemble, and Sonnet Software’s EM; these codes can be used by inputting the geometry of the antenna.  The MoM uses an integral equation method to solve for the current density on the surface of the conductors. Once the current density on the surface of the antenna is known, the radiation pattern, directivity and gain can be computed using the far-ﬁeld model. Input impedance, voltage standing-wave ratio  VSWR  and scattering parameters can also be calculated. It is suitable for simulation of wire antennas and printed antennas.  The MoM is very efﬁcient for modeling structures that consist entirely of perfectly or highly conducting radiators or scatterers, when compared to the FEM or the FDTD method. Since it is a boundary element method, the boundary conditions are built into the MoM formulation, while for the FEM and the FDTD methods the boundary conditions must be explicitly imposed. The MoM includes the radiation condition automatically, and this makes it especially suitable for radiation or scattering problems.  The MoM is difﬁcult to implement for arbitrary geometry and three-dimensional  3-D  structures that use nonhomogeneous, magnetodielectric, or anisotropic materials. These complex cases and more general Maxwell’s equations can be solved using the FDTD method or the FEM, which is computationally more demanding.  10.2.2 Finite difference time-domain method  The FDTD method is derived from the differential form of Maxwell’s equations. In differ- ence methods, the derivatives are approximated by ﬁnite differences. The FDTD method directly approximates the differential operators in Maxwell’s curl equations on a grid on time and space by using Yee’s ﬁnite difference scheme [50]. The FDTD method is currently the most popular method for electrodynamic problems in computational electromagnetics. A comprehensive study of the FDTD method is given in [40].  The FDTD method may introduce numerical dispersion, that is, the phase velocity vp and the wave  group  speed vg are different. This can be minimized by selecting a time-step at the Courant limit, i.e.,  cid:18 t =  cid:18 z c, where c is the speed of the wave propagation, and the spatial step size  cid:18 z is no more than one-tenth of the minimum      340   cid:2   Antennas  wavelength  corresponding to the maximum frequency . The frequency dispersion is frequency dependent, and worsens rapidly when the frequency is above a certain value.  Implementation of the FDTD method does not lead to complex matrix computation. In contrast, the MoM and the FEM lead to a large system of linear equations. For FEM, the coefﬁcient matrix is sparse, while the MoM generates a full matrix. The FDTD method pro- vides a very simple implementation of a full-wave solver, and much less work is required as compared to an MoM or FEM implementation.  For 3D FDTD, halving the mesh size leads to an increase in run time by a factor of 16, and doubling the frequency leads to an increase in run time by a factor of 32 to 45 [10]. Memory also becomes a serious issue in 3D FDTD.  Unlike the MoM and the FEM that operate in the frequency domain, the FDTD method operates in the time domain; as a result, by using a wideband source the FDTD method can compute a wideband response in one run, while the MoM and the FEM have to recompute the system response for each frequency. The result from the FDTD method is more suitable for computer visualization of the ﬁeld dynamics. The Fourier transform is used to yield a frequency response. Thus, the FDTD method is preferable for wideband systems.  When a suitable absorbing boundary condition  ABC  is available, the FDTD method can also be applied to antennas. The perfectly matched layer  PML -based ABC is a very accurate mesh truncation technique [6], and is integrated into the software package, Microwave Studio.  Commercial software packages for the FDTD method include Remcon’s XFDTD, and Sonnet Software and CST’s joint product, Microwave Studio. XFDTD is an implemen- tation of the standard FDTD. Microwave Studio is a transient solver that uses the ﬁnite integration technique; The ﬁnite integration technique can be rewritten as a standard FDTD method for Cartesian grids. Zeland  now a part of Mentor Graphics  also provides Fidelity as a FDTD simulator.  10.2.3 Finite element method  The FEM is a general method for solving partial differential equations, subject to cer- tain boundary conditions, and is very useful in providing solutions to engineering and physical problems. The FEM can be formulated via the conventional Ritz variational method or Galerkin’s weighted residual method. Both methods start from the partial dif- ferential form of Maxwell’s equations. The former ﬁnds a variational functional whose minimum corresponds to the solution, while the latter introduces a weighted residual and solves the weighting functions. In most applications, both methods lead to identical equations.  The FEM is traditionally formulated in the frequency domain. The FDTD method typ- ically employs a rectangular, staggered grid, while the FEM allows elements of arbitrary geometry. This provides the FEM with more geometrical modeling ﬂexibility by using tri- angular elements for two dimensions and tetrahedral elements for three dimensions. As with the FDTD, the FEM does not include the radiation condition. For open regions, as in      341   cid:2   10.3 Antenna fundamentals  radiation or scattering problems, one has to employ an artiﬁcial absorbing region within the mesh or a hybridization with the MoM to terminate the mesh.  The FEM is especially suitable for volumetric conﬁguration with complex geometries and inhomogeneous material or material with frequency-dependent properties. The FEM can also couple electromagnetic solutions with mechanical or thermal solutions. The FEM is much more complex to implement than the FDTD method, but is more accurate than the FDTD. However, for electromagnetic eigenvalue problems, the standard FEM introduces spurious modes, while this does not occur in the FDTD.  Both the FEM and FDTD methods are theoretically capable of solving any problem, but they are computationally too expensive for problems that are more suitable for the MoM. For all the three methods, the mesh has to become ﬁner for an increasing frequency, and all these methods scale badly with frequency. Some fast methods try to replace the traditional direct matrix solution algorithms with iterative solvers.  Several commercial software packages are available for ﬁnite element analysis of elec- tromagnetic problems. Ansoft’s High-Frequency Structure Simulators  HFSS  is the most popular. Ansys provides FEMLAB, and Agilent also provides its HFSS. There are a number of excellent texts on the FEM, including the one by Jin [20].  10.3 Antenna fundamentals  An antenna is a device that converts a guided wave into a free-space wave, or vice versa. It connects the energy of electrons and the energy of photons. Radiation is produced by accel- erated or decelerated charge. Maxwell’s equations constitute the theoretical foundation for antenna and microwave design.  The transmission between a transmit and a receive antenna is illustrated in Fig. 10.1.  The link can be characterized by the Friis transmission formula [13]  Pr Pt  = AetAer r2λ2 ,   10.12   where Pr  in watts  is the received power, Pt  in watts  is the transmitted power, Aet  in m2  is the effective aperture of the transmit antenna, Aer  in m2  is the effective aperture of the receive antenna, r  in m  is the distance between the antennas, and λ  in m  is the wavelength.  Transmit antenna  Aet  Transmitter  r  Receive antenna  Aer  Receiver  Transmission between two antennas.   cid:2 Figure 10.1      342   cid:2   Antennas  10.3.1 Radiation patterns  The radiation pattern of an antenna is a three-dimensional quantity associated with its spherical coordinates θ and φ. The radiation pattern is also a reception pattern due to antenna reciprocity. The radiation pattern can be characterized by using its normalized ﬁeld pattern or its normalized power pattern.  The normalized power pattern is deﬁned by  where S θ, φ  is the power per unit area, measured in watts m2, or the amplitude of the Poynting vector,  Pn θ, φ  = S θ, φ  S θ, φ max  ,  S θ, φ  = E2  θ  θ, φ  + E2  φ θ, φ   Z0   10.13    10.14   and Z0 = E H = 376.7 ohms is the intrinsic impedance of free space. A radiation pattern has its main lobe and minor lobes. The half-power beamwidth  HPBW , or 3-dB beamwidth, and the beamwidth between the ﬁrst nulls  FNBW  are important pattern parameters. A typical beampattern and its parameters are illustrated in Fig. 10.2. According to the principle of reciprocity, the pattern of an antenna is the same for both reception and transmission.  Beam area   cid:14    cid:14  π  The beam solid angle or beam area,  cid:20 A, of an antenna is deﬁned by   cid:20 A =  2π  Pn θ, φ 2 sin θ dθdφ.   10.15  The pattern can usually be separated as Pn θ, φ  = Pe θ Pa φ , where Pe θ  and Pa φ  are elevation and azimuth patterns, respectively.  cid:20 A can be approximated by using  0  0   cid:20 A ≈ θHPφHP,   10.16   Minor lobes  Minor lobes  Back lobe  Side lobes  Side lobes  Back lobe  Pn  Major lobe  HPBW  FNBW  0  −π  −π 2  π 2  π  θ   cid:2 Figure 10.2  Antenna radiation pattern.      343   cid:2   10.3 Antenna fundamentals  where θHP and φHP are the HPBWs in the two principal planes, and minor lobes are neglected.  Radiation intensity  The power radiated from an antenna per unit solid angle is referred to as the radiation intensity U, measured in watts radian2. Accordingly, the normalized power pattern can be deﬁned by  Pn θ, φ  = U θ, φ  U θ, φ max   10.17   Unlike the deﬁnition given in  10.13 , where the amplitude of the Poynting vector varies with the distance from the antenna, the radiation intensity is independent of the distance, assuming the case of far ﬁeld of the antenna.  10.3.2 Antenna ﬁeld zones  The ﬁeld of an antenna is usually divided into two regions, the near ﬁeld or Fresnel zone, and the far ﬁeld or Fraunhofer zone. The boundary between the two regions is selected as  R0 = 2  L2 λ   10.18   where L is the largest dimension of the antenna. The antenna ﬁeld zones are shown in Fig. 10.3.  In the far or Fraunhofer ﬁeld, the radiation is close to a transverse electromagnetic  TEM  wave radiating radially outward, and the energy drops at a rate of 1 r2, where r is the distance from the antenna. The power pattern is independent of the distance. In the near or Fresnel region, the power ﬂow is not radial and the power pattern is dependent on the distance; the energy drops as 1 r3. There is oscillating energy ﬂow as well as radially outward energy ﬂow. The outﬂow is the radiated power, while the oscillating ﬂow is reac- tive energy that is trapped in the vicinity of the antenna. The near-ﬁeld or far-ﬁeld patterns can be measured in an anechoic chamber.  L  R0  Fraunhofer region  Antenna region  Fresnel region   cid:2 Figure 10.3  Antenna ﬁeld zones.      344   cid:2   Antennas  10.3.3 Antenna gain and directivity  At the far ﬁeld, the ﬁeld E and the power density W, measured in watts m2, are related by  10.14   For an isotropic antenna, the power density at a distance R in the far-ﬁeld is given by  where Prad is the radiated power. Correspondingly, the radiation intensity U is given by  W = S θ, φ  = E2 Z0  .  Wiso = Prad 4πR2 ,  Uiso = Prad 4π  .  The gain of a transmit antenna in the direction  θ, φ  can be deﬁned as the ratio of the  radiation intensity to that for a lossless isotropic antenna G θ, φ  = U θ, φ  PT   4π   ,  where PT is the output power when the antenna is matched to its feed.  Directivity D corresponds to the case when there is loss in the hypothetical isotropic  antenna, and is deﬁned by  D = P θ, φ max P θ, φ av  = U θ, φ  Prad  4π   .  D = 4π  cid:20 A  .  The unit of D is usually dBi, denoting decibels over isotropic. Directivity can also be deﬁned by  A speciﬁed directivity parameter is a primary goal for many antenna structures.  Directivity and gain are thus related by   10.25  where η cid:20  = Prad PT ≤ 1 is the ohmic or radiation efﬁciency of the antenna, and is given by  G θ, φ  = η cid:20 D θ, φ ,  RL being a loss resistance and Rrad the radiation resistance of the antenna. RL always exists due to conductance loss, and is a function of frequency.  The spatial resolution of an antenna can be deﬁned as half the beamwidth between the ﬁrst nulls, FNBW 2. Usually, this value is approximately equal to HPBW. The number of point sources of radiation uniformly distributed over the sky that can be resolved by an antenna is given by  η cid:20  = Rrad  Rrad + RL  ,  N = 4π  cid:20 A  = D.   10.19    10.20    10.21    10.22    10.23    10.24    10.26    10.27       345   cid:2   10.3 Antenna fundamentals  The impedance presented by an antenna to a transmission line can be represented by a 2-terminal network with an equivalent impedance Z. This impedance is called the ter- minal or driving point impedance. If the antenna is isolated and lossless, the terminal impedance is the same as the self-impedance of the antenna, which contains a self- resistance  radiation resistance  and a self-reactance. The self-impedance is the same for both reception and transmission. According to the reciprocity theorem for anten- nas, the antenna impedance for both transmitting and receiving operation modes is the same.  10.3.4 Effective area and effective height  For a receive antenna, its effective area or aperture Ae, measured in m2, is deﬁned as the ratio of the received power P to the power density W of the planar wave  where the plane wave is assumed to have the same polarization as that of the antenna. D and Ae are related by  All antennas have an effective aperture, which can be calculated using this equation.  For an aperture antenna such as a horn antenna or a parabolic reﬂector antenna, the effec- tive aperture Ae is less than its physical aperture Ap due to the nonuniform ﬁeld response in the aperture antenna. The aperture efﬁciency,  cid:21  = Ae Ap, is usually 50 to 80% for horn and parabolic reﬂector antennas. Large dipole and patch arrays can achieve a higher aperture efﬁciency.  Another parameter related to the aperture is the effective height he, measured in meters. It is deﬁned as the ratio of the induced voltage to an incident ﬁeld E of the same polarization  The effective height is useful for characterizing transmitting tower-type antennas. Ae and he are related by  Ae = P W  ,  D = 4π  Ae λ2 .  he = V E  .  Ae = h2 eZ0 4Rrad  .  The quality factor, Q, of an antenna is deﬁned by [25]  Q = energy stored per second energy lost per second  =  X  Rrad + RL  = fc B  ,  where fc is the center frequency and B is the bandwidth. Increasing Rrad or RL reduces Q, and thus increases the bandwidth.   10.28    10.29    10.30    10.31    10.32       346   cid:2   Antennas  10.3.5 Antenna temperature  The noise received as electromagnetic radiation by an antenna as well as the thermal noise in the antenna itself can be modeled by a noise temperature or temperature of the antenna’s radiation resistance. For a receive antenna, the equivalent noise temperature, measured in kelvins  K , is deﬁned by  Tant = TA + Tth = GN f   kB  ,   10.33   where the antenna temperature TA is due to the electromagnetic radiation and Tth is the ther- mal noise in the antenna. The equivalent noise is assumed to be white with the one-sided noise power spectral density  PSD  GN  f  , measured in watts  Hz, and kB is Boltzmann’s constant kB = 1.38 × 10 −23 J K. TA is determined by Ts, the temperature or brightness temperature of the sky or source that the antenna points toward, and can be calculated by   10.34  where d cid:20  = sin θdθdφ. Note that the cosmic background noise is independent of frequency and is 2.7 K everywhere in the sky. Radio noise is treated in ITU-R Rec. P.372.  Ts θ, φ Pn θ, φ d cid:20 ,  0  0  The overall noise temperature of a radio receiver is given by  Tsys = Tant + Te,   10.35   where Te is the equivalent input noise temperature of the receiver.   cid:14    cid:14   2π  2π  TA = 1  cid:20 A  10.3.6 Polarization  Polarization of an electromagnetic wave is referred to as the orientation of the electric ﬁeld vector, E. For a wave traveling along the z-direction, if E is along the x- or y-direction only, the wave is linearly polarized in the x- or y-direction. In general, the electric ﬁeld has both x- and y-components, and the wave is referred to as elliptically polarized:  E = ˆxEx sin ωt − βz  + ˆyEy sin ωt − βz + φ ,   10.36   ◦  , or right-hand circular polarization  RHCP  if φ = −90  where β = 2π λ is the wave number and ω is the angular frequency. The elliptical polariza- tion is characterized by axial ratio, the ratio of the major to minor axes of the polarization ellipse. When Ex = Ey, the wave is circularly polarized; it is left-hand circular polarization  LHCP  if φ = 90 An antenna is blind to a wave of opposite polarization. Most cosmic radio sources are unpolarized, and any polarized antennas can receive only half of the available power [25]. Dipoles generate a linearly polarized wave, and end-ﬁre antennas such as axial-mode heli- cal antennas generate circular polarization. Circular polarization can also be generated by a pair of crossed λ 2 dipoles that have equal currents with quadrature phases; transmission is along the direction that is perpendicular to the antenna plane. The circular polarizations are opposite in the two axial directions.  ◦  .      347   cid:2   10.3 Antenna fundamentals  The receive voltage is proportional to the dot-product of the electric ﬁeld and the polarization vector of the receive antenna. The received power has a polarization loss factor   cid:21 pol = ei · er2 ,   10.37   where ei is the unit electric ﬁeld vector of the incident wave and er is the unit polarization √ vector of the received antenna. For this reason, a linearly polarized antenna can only receive half the power of a circularly polarized signal reaching it, since ei =  ˆx + ˆy   2 and er = ˆy, making  cid:21 pol = 0.5. Similarly, an LHCP antenna is completely mismatched to an RHCP wave, and a horizontally polarized antenna is completely mismatched to a vertically polarized wave.  Cross-polarization discrimination  A radiation pattern can be expressed as  E = Eθ  θ, φ ˆθ + Eφ θ, φ ˆφ,   10.38   where Eθ  θ, φ  and Eφ θ, φ  are the amplitudes of the electric ﬁeld vector in the elevation and azimuth directions, respectively.  In wireless communications, the interactions of environment not only attenuate the transmitted signals, but also depolarize them. Cross-polarization discrimination  XPD  is deﬁned as the power ratio of the copolarization and cross-polarization components of the mean incident wave. A higher XPD corresponds to less energy coupled in the cross- polarized channel. XPD can be deﬁned for the two cases: azimuth transmission  χθ   and elevation transmission  χφ    cid:19 Eθ θ2  cid:20   cid:22  cid:4  cid:4 Eθ φ  cid:23  , χφ = E  cid:4  cid:4 2  E   cid:22  cid:4  cid:4 Eφφ  cid:22  cid:4  cid:4 Eφθ   cid:23   cid:23  ,   cid:4  cid:4 2  cid:4  cid:4 2  χθ = E E   10.39   where Eθ φ denotes the received φ-polarized electric ﬁeld of the transmitted θ-polarized electric ﬁeld. Similar explanations apply for Eθ θ , Eφφ, and Eφθ . XPD can be approximated by a Gaussian distribution [44].  10.3.7 Receiving and transmitting power efﬁciency  Transmit and receive antennas can be characterized by their equivalent circuits, as shown in Fig. 10.4. The antenna is modeled by a network ZA = RA + jXA. The impedance at the generator or receiver side is assumed to be purely resistant. The antenna impedance ZA can be impedance matched to a lossless transmission line of the characteristic impedance Z0 = RA by using a stub tuner  refer to Section 11.5 . The input impedance of antennas can be analyzed by using a network analyzer.  In the transmitting case, the radiation power via the antenna is given by  Prad =  Rrad  Rrad + RL + Rt  Pt,   10.40       348   cid:2   Antennas  I  E  E  α  R  r  V  Load  t  P R  t  Generator  Z0 = RA  −j X A  −j X  A  R  t  P  t  Z A  Z  A  Pr  Rr   cid:2 Figure 10.4   a  Transmit   b  Receive  The equivalent circuits for  a  a transmit and  b  a receive antenna. Note that the transmission line segment is composed of two parts. One part is used for impedance matching, and it can be treated as an impedance of −jXA. The other part is a lossless transmission line of characteristic impedance Z0 = RA.  where Rrad is radiation resistance of the antenna, RL is the loss resistance of the antenna, RA = Rrad + RL, Pt is the transmitted power, and Rt is the resistance of the transmitter  generator . When RL and Rt are negligible, Prad is close to Pt and the radiating efﬁciency approaches 100%.  The maximum power delivered to the antenna occurs when the conjugate matching  occurs  where Rt is the resistance of the transmitter. The power supplied by the transmitter during conjugate matching is given by [5]  RA = Rrad + RL = Rt,  Pt =  V2 g  4  Rrad + RL   ,  where Vg is the voltage amplitude of the generator. Half of this power is dissipated as heat in the internal resistance Rt and the other half is delivered to the antenna. In the receiving case, in case of perfect match, the receiver impedance Rr should be equal to the antenna radiation resistance RA, that is, Rr = RA. In this case, the power received by the receiver is  Pr =  Rr  Rr + RA  PR = 0.5PR,  where PR is the power collected by the antenna. Thus, at best, 50% of the total power collected by the antenna is transferred to the receiver, while the other half is scattered [25].   10.41    10.42    10.43       349   cid:2   10.4 Antennas for wireless communications  10.4 Antennas for wireless communications  Antennas are used to radiate electromagnetic energy by using an oscillating current distri- bution. An antenna can be either a resonant or a nonresonant antenna. A resonant antenna uses resonance to increase the radiating current. A resonant antenna radiates almost all the radio signal fed to it, if working at a resonant frequency; otherwise, a large portion of the fed signal is not radiated. This makes resonant frequency only suitable for narrowband use. Conventional wired antennas and patch antennas are resonant antennas.  A nonresonant antenna, also called frequency-independent antenna, has approximately constant input impedance and radiation characteristics over a wide range of frequency. The dimensions of a nonresonant antenna are decided by its lower and higher frequency limits. A nonresonant antenna can be designed as a wideband antenna such as a log-periodic dipole antenna or a spiral antenna, but its size is usually very large.  Wired antennas, such as dipole and monopole antennas, and patch antennas are most widely used in wireless communications. The dipole has a favorable radiation pattern, but has a relatively large size and needs a differential feed. The microstrip-patch antenna is inexpensive, lightweight, and easy to manufacture. The performance of microstrip printed-dipole arrays are compared to that of arrays of free-standing dipoles in a MIMO channel in [30, 43]. The effects of parameters such as the dielectric thickness and the permittivity on the MIMO performance of the printed-dipole array are analyzed as well in [43]. The rectangular patch has attractive radiation characteristics and has a good polarization, thus it is most commonly used. These antennas typically have small bandwidth.  Aperture antennas are also used for wireless communications. The parabolic reﬂector is usually employed for satellite communications, and the horn antenna and the corner reﬂector can be used as sector antennas in a BS. The helical antenna is also widely used for satellite and space communications.  For antenna design, the important parameters are the directivity and gain, bandwidth, and input impedance. Impedance matching between the antenna and the coaxial cables with a 50-ohms impedance is necessary to improve the VSWR or power reﬂection. Most commercial antennas have a VSWR of 1.5:1 or less, and the corresponding reﬂected power is 4% of the incoming power.  10.4.1 Antennas for base stations  For cellular BSs, the coverage area must be large. This requires the radiation pattern to be omnidirectional in the horizontal  azimuthal  plane. The directivity can be increased by decreasing the beamwidth in the vertical  elevation  plane. Dipoles, monopoles, or folded dipoles can be used for this purpose. For cellular and point-to-multipoint communications using BSs with multiple sectors, the beamwidth of each antenna can be adjusted to its sector, and directional antennas such as Yagi or corner reﬂectors can be applied. Dead spots arise due to the presence of nulls in the radiation pattern. Dead spots lead to call      350   cid:2   Antennas  drops, and should be avoided. The nulls in the antenna pattern may increase the number of handoffs, resulting in increased management overhead of the system.  The vertical beamwidth may vary depending on coverage. This beam may be tilted downward so that the main beam is toward its coverage area to reduce interference to neighboring cells. Depending on the radiation characteristics, bandwidth as well as instal- lation, the type of antennas used for BSs may be dipoles, monopoles, patch arrays, corner reﬂectors, or aperture antennas such as horn antennas.  For indoor use such as wireless LAN, a leaky line, which is a coaxial cable with a leaky outer conductor, can be used as the radiation antenna. The leaky-wave antenna is a kind of traveling-wave antenna. Parabolic reﬂectors are widely used in satellite communications and broadcasting systems. The parabolic reﬂector is very effective for enhancing the gain of the antenna, and the antenna is installed at the focus of the reﬂector.  Diversity can effectively increase the system capacity. Space diversity uses multiple antennas, and polarization diversity makes use of the low correlation between oppo- sitely polarized electric ﬁeld components. Diversity based on multiple antennas can be easily implemented in BSs, since there is no size restriction as in the MS case. Cross- polarized antennas are also widely used in cellular BS installations as it reduces spacing needs and tower loads. With the use of MIMO technology in the next-generation wire- less communications, cross-polarization will become an approach to exploit diversity in both BSs and MSs. 3GPP 3GPP2 have deﬁned a cross-polarized channel model for MIMO systems [1].  10.4.2 Antennas for mobile stations  The antennas for MSs should have generally an omnidirectional antenna pattern, because the signal arrives in a continuously changing random direction and the MS is changing its orientation.  For MSs, a vertical polarized antenna such as a vertical dipole or monopole antenna made of a ﬂexible antenna element, called whip antenna, is usually desirable. Such an antenna is subject to size restriction, and it is required to have adequate bandwidth and high efﬁciency. A retractable whip antenna is usually used in mobile handsets. Such a whip antenna can be treated as a monopole with the phone chassis as the ground. The length of the whip can be either λ 4 or 3λ 8. The use of 3λ 8 is to shift the current maximum away from the user and also to reduce the current on the chassis. In order to reduce the size, a dipole or monopole antenna can be embedded in a dielectric medium. In this case, the size  cid:21 r, where  cid:21 r is the relative permittivity of the dielectric. can be reduced by a factor of 1  A normal-mode helical antenna can be used in combination with a whip antenna. When the whip antenna is retracted, the helical antenna becomes the major receive antenna. Dual band can be easily achieved in one helical antenna by using two pitch angles. A helical antenna can be modeled as an array of loop antennas. It has an elliptical polarization, which approximates a circular polarization when the number of turns is large.  √  The sleeve antenna [21] avoids the big ground plane in the monopole by using a coax feed line that passes through a metallic sleeve without direct contact. The sleeve      351   cid:2   10.5 Dipole antennas  is used as a choke to prevent the antenna current from leaking into the outer surface of the coaxial cable. The sleeve moves the virtual antenna feed up the monopole. The bandwidth increases because the current at the feed point remains nearly constant over a wide frequency range. The overall length of the sleeve and the monopole is λ 4. It is inexpensive, compact, and widely used in MSs such as vehicles.  Antennas can also be installed inside MSs. Planar antennas using length λ 4 microstrip are usually mounted on the chassis. The microstrip can meander to adapt to the size restric- tion. Such internal antennas may have reduced sensitivity and allow reduced transmission power. Planar antennas of inverted-F shape can be used when dual-band is required [31]. By electrically tuning the frequency using a PIN diode, a dual-band planar inverted-F antenna is capable of operating in several frequency bands, covering the 850, 900, 1800, 1900 and 2000 MHz frequency bands that are used for GSM, PCS, and UMTS systems, with a total efﬁciency over 40% [24]. Design of the various antennas mentioned in this section is given in [25].  Electro-textiles are conductive fabrics that interpolate conductive metal polymer threads with normal fabric threads. These fabrics can be integrated into clothing and they are wash- able, durable and ﬂexible. Antennas made of electro-textile materials are now available for distributed body-worn electronics in wireless BANs [23, 32].  Minimization of antennas  MSs are restricted by size. Thus the antennas attached to them must be very small, but with acceptable performance. Reducing the size of an antenna will inﬂuence its bandwidth, gain, efﬁciency, and polarization purity, and also inﬂuence its feeding, since the transmission depends on the wavelength.  In order to use multiple antennas in MSs, measures must be taken to mitigate the inﬂu- ence of mutual coupling. Fractal geometry can be used for miniaturizing antennas. Fractals have no characteristic size, and they are composed of many copies of themselves at differ- ent scales. The fractal contours can add electrical length in less volume [16]. Increasing the fractal dimension of the antenna leads to a higher degree of miniaturization. Fractal antennas are more effective in decreasing mutual coupling for antenna arrays, since for the same center-to-center spacing, the fractal antennas have a larger edge-to-edge separation. Fractals have been used for miniaturization of antennas and for designing multiband, wide- band or even ultra wideband  UWB  antennas [45]. Fractal elements and arrays are also ideal candidates for use in reconﬁgurable systems.  10.5 Dipole antennas  The Hertzian electric dipole, often called short dipole, is a pair of electric charges, which vary sinusoidally with time but have equal magnitude with opposite signs, at the two ends of an electrically short length. On the short length of the dipole, the current is uniformly distributed.      352   cid:2   Antennas  The Hertzian dipole cannot efﬁciently radiate energy due to the need of a high voltage to generate large current. A small horizontal loop antenna may be treated as the mag- netic counterpart of a short vertical dipole: They have the same far-ﬁeld patterns, but with opposite polarization [25].  For a Hertzian dipole of length  cid:18 l along the z-axis, the E- and H-ﬁelds are given by [25]   cid:2    cid:3   Er = Z0  I0 cid:18 l cos θ  2πr2   cid:2   e  −βr,  cid:3   1 + 1 jβr − 1  βr 2  1 + 1 jβr  −βr, e  Eθ = jZ0  βI0 cid:18 l sin θ   10.45  and Eφ = 0, Hφ = Eθ  Z0, Hr = Hθ = 0, where Z0 = 120π is the space impedance and I0 is the constant current on the wire.  4πr   10.44   The radiation resistance Rrad, in ohms, is given by   cid:18 l λ   cid:2   cid:3 2  cid:3 2 = 789  .   cid:2   Rrad = 2π 3  cid:2    cid:18 l λ   cid:3 2  .   cid:18 l λ  D = 3 2  sin2 θ.  In free space η = 120π ohm, and thus Rr = 80π 2  For the radiator to be efﬁcient, its length must be comparable to the wavelength. This explains why radiation is not considered in low-frequency circuit design.  The directivity is given by  The commonly used antennas are the wire, or thin-wire, antennas. The λ 2 dipole antenna, as shown in Fig. 10.5, is a centrally fed element with a sinusoidally varying current.  A slot antenna is complementary to a dipole or a strip, if the dipole or the strip is cut from a metal sheet, leaving the slot. They have the same pattern, but with E and H interchanged. This is shown in Fig. 10.6. Radiation occurs from both sides of the sheet.   10.46    10.47    10.48   Transmission  line  I0  I0   cid:2 Figure 10.5  The λ 2 dipole antenna.      353   cid:2   10.5 Dipole antennas  F  F λ 2  F  F  λ 2   cid:2 Figure 10.6  A λ 2 slot antenna which is a slot cut from an inﬁnite ﬂat sheet, and a complementary λ 2 dipole antenna.  10.5.1 Wire dipole antennas  For the thin-wire linear dipole, the current distribution on the wire is close to sinusoidal, if the wire diameter is less than λ 100. The current distribution is a standing wave that is generated from the forward traveling wave and reﬂected wave of equal amplitude from the distal end of the wire. When the total length is equal to one half of a wavelength, the antenna is at resonance.  For the thin-wire linear dipole, the current on the wire can be approximated by  The current is zero at the ends, z The far ﬁeld is given by [25]  Radiation pattern   cid:5    cid:2   2π λ  − z   cid:14   l 2   cid:3  cid:6   .   cid:14   I z    = Imax sin  cid:14  = ±l 2.  cid:5   cos[ βL cos θ  2] − cos βL 2   Hφ = j [I0] 2πr  sin θ Eθ = Z0Hφ,   cid:6   ,  where L is the length of the dipole, r is the distance from the center of the dipole to the far-ﬁeld point, [I0] = I0e jω[t− r c ], I0 being the amplitude of the sinusoidal current on the wire, β = 2π λ is the wave number, and Z0 = 120π is the space impedance. The radiation pattern is a function of θ only, and the radiation pattern is omnidirectional in the azimuthal plane. If half the length of a dipole is λ 4, that is, L = λ 2, we get the basic λ 2-dipole:  P θ  = cos2  π  2 cos θ   cid:8   .   cid:7   sin2 θ ◦  ◦ The 3-dB beamwidth is 78 is 1.64 or 2.15 dB.  , as compared to 90  for the short dipole. The directivity  gain    10.49    10.50    10.51    10.52       354   cid:2   Antennas  150  180  120  90    1  60  λ  0.5  λ 2   a   0.5 0 −0.5 1  0.5  30  0  −1  −0.5  0  −0.5  0  0.5  −1  1   b    cid:2 Figure 10.7   a  Dipole patterns for the half-wave  λ 2  and full-wave  λ  dipoles.  b  The 3-D pattern for the λ 2 dipole.  Example 10.1: The normalized patterns of the dipole antennas for L = λ 2  half-wave  and L = λ  full-wave  are plotted in Fig. 10.7a, at any azimuthal angle φ. Note that the elevation angle θ is deﬁned over [0, π]. The beamwidths between half-power points are ◦ for the λ 2 and λ antennas, respectively. A 3-D view of the pattern for the 78 λ 2 dipole is plotted in Fig. 10.7b.  ◦ and 47.8  Radiation resistance  The radiation resistance can be calculated by equating the radiated power, which is calcu- lated by integrating the Poynting vector over a large sphere, to a power delivered to the radiation resistance at the maximum current  cid:2    cid:14  cid:14   cid:4  cid:4 Hφ   cid:14  cid:14  P =  cid:2    cid:4  cid:4 2 ds =   cid:18 2   cid:31    10.53    cid:17   √  μ  2  Rrad,  I0   S · ds = 1 2   cid:21   where Rrad is the radiation resistance at the current maximum point I0, which is the center of the antenna or at the terminals of the transmission line for the λ 2-dipole.  The radiation resistance is equal to the self-resistance. For the λ 2-dipole, the radiation resistance Rrad is 73.2 ohms. A general result for the self-resistance of dipole of any length, R11 = Rrad, is given in [25]. The terminal impedance also has an inductive reactance and the impedance is given by  Z = 73.2 + j42.5   ohms .   10.54   Since the phase velocity of the radio wave along the wire is slightly less than the free-space velocity, the wavelength is slightly less than that in free space. By short- ening the antenna by a few percent to 0.475λ, the reactance is reduced to zero, and thus the antenna is resonant. In this case, the radiation or terminal resistance is about 67 ohms.      355   cid:2   10.5 Dipole antennas  The λ 2-dipole has a terminal  resistance of 73.2 ohms, while the connecting transmission lines have a different impedance. For example, the coaxial cable has an impedance of 50 ohms, while a 2-wire line has a characteristic impedance of 300 to 600 ohms. An impedance transformer is required to match the impedance. The dipole so arranged has a vertical polarization. A vertical electric ﬁeld will induce a maximum voltage at the antenna output V = Vmax, while a horizontal electric ﬁeld will induce zero voltage at the antenna output. At an angle of α, the induced voltage is given by   10.55   V = Vmax cos α.  10.5.2 Baluns  When a dipole is fed at the center by a coaxial line, as illustrated in Fig. 10.8 a net current  I3  is induced on the outside of the coaxial cable. This current is not shielded and will radiate.  For feeding the dipole antenna, a two-wire line can be used to support the dipole so as to prevent the current from ﬂowing to the surface of the outer conductor of the coaxial cable. This prevents the entire coaxial cable from becoming a radiating antenna. Such a structure is called a balun, which is an acronym for balanced-to-unbalanced transformer. A balun changes a single-ended signal  signal referenced to ground , such as an unbal- anced coaxial line, to a balanced signal with equal potentials but of opposite polarity. The balanced output can be treated as two separated ports with anti-phase signals. The balun connects the dipole  with a balanced structure  and the coaxial cable  with an unbalanced structure .  In addition to application in antenna feeding networks, baluns are also used in mixers and frequency multipliers. The balun functions as an impedance transformer. It can also be used as an antiphase power splitter. There are many balun structures in the literature. The planar version of the Marchand balun is very attractive for its planar structure and wideband performance [35]. A balun may have a limited bandwidth.  The feed network is used for power distribution between the transmitter and the antenna as well as impedance matching. Proper impedance matching makes the reﬂection coef- ﬁcients and VSWR to be within the speciﬁed levels. In the receiver case, a balun is not necessary if the SNR is adequate.   cid:2 Figure 10.8  The currents in the coaxial line when feeding a dipole antenna.  I3  I2  I1      356   cid:2   Antennas  I0  V0  +  −  +  −  I0  V0 2  Ground plane   cid:2 Figure 10.9  Monopole vs Dipole.  10.5.3 Wire monopoles  The monopole is a variant of the dipole that uses the ground plane to provide the other half of the antenna. It has half the architecture of the dipole and as such, its self-impedance is half that of the dipole. For the monopole of length λ 4, its self-impedance is Z = 36.6 + j21.2 ohms. Comparison of a dipole and a monopole is shown in Fig. 10.9.  A monopole has twice the directivity of its dipole counterpart. A popular monopole antenna is the quarter-wave  λ 4  monopole. For the λ 4 monopole, the directivity is 3.28 or 5.15 dBi. To produce the same ﬁeld strength as a dipole, a monopole above the ground needs only half the power. While at the receiver side, the gain of a monopole is only half that of the dipole.  The monopole antenna is unbalanced, and thus avoids the use of a balun. Both the dipole  and monopole antennas are widely used in wireless communications.  10.6 Patch antennas  Patch antennas are also widely used in wireless communications. They can be used in MSs for cellular communications, in MSs and BSs for wireless networking, and also for beamforming at the BSs for satellite communications. Printed microstrip antennas have very little manufacturing cost, and they can be made as resonant-slot antennas to better control polarization.  Patch antennas are commonly a rectangular metal patch on a thin layer of dielec- tric above a ground plane. A patch antenna of length L, width W, and thickness t is shown in Fig. 10.10. Feeding is at the center of one side of the patch. This produces lin- early polarized radiation with a maximum broadside to the patch. Feeding typically uses either a coaxial probe or a microstrip line. When fed by a microstrip line, a quarterwave transformer can be used for impedance matching between the patch and the microstrip line.      357   cid:2   10.6 Patch antennas  Feed point  W  L  t  Dielectric substrate  Ground plane   cid:2 Figure 10.10  Patch antenna. The feed line can be coax feed or transmission line.  10.6.1 Microstrip antennas  Analysis and design of microstrip patch antennas can be based on the simple but approx- imate transmission-line model [7], or on the accurate but computationally complex cavity model [5, 27]. Both methods provide physical insight. In the transmission-line model, the microstrip radiator element is viewed as a transmission-line resonator with no transverse ﬁeld variations, and the radiation occurs mainly from the fringing ﬁelds; the patch can be modeled as two slots that are separated by the length of the resonator. In the cavity model, the region between the patch and the ground plane is treated as a cavity that is enclosed by magnetic walls around the periphery and electric walls at the top and bottom. The far-ﬁeld radiation is calculated from the equivalent magnetic current around the periphery. More complex numerical methods include the MoM [29] and FDTD methods. The result based on the transmission-line model is introduced here. The patch can be modeled by n = W t parallel-plate microstrip transmission lines of length L. The thickness t is usually a few percent of wavelength in the dielectric. The microstrip characteristic impedance Zc is given by [25]  Zc =  √  Z0  n + 2    cid:21 r  =   cid:7    cid:8 √  ,   cid:21 r  Z0 + 2  W t   10.56   where two microstrip transmission lines are added to account for the fringing effect, and Z0 = 377 ohms is the free-space impedance. The resonant length L is critical, and is usually a few percent less than λ 2, where λ is the wavelength in the dielectric, λ = λ0  Radiation from the patch can be modeled by two radiating slots, one at the left and the other at the right of the pad [25]. The slots are of length W and width of a few λ 100. If W = λ, the input impedance is calculated as Rin ≈ 50 ohms. When W is smaller, Rin increases in proportion to the reduction. The radiation pattern can be obtained by combining that of two in-phase slot dipoles. The radiation pattern of the patch is broad, with a typical directivity D ≈ 4 or 6 dBi.  √   cid:21 r.      358   cid:2   Antennas   cid:2    cid:3 2  Rr = 90   cid:21 2 r   cid:21 r − 1  L W  The radiation resistance of a resonant λ 2 patch is given by [25]   ohms ,   10.57   and Xr = 0. For VSWR< 2 and small t λ0, the bandwidth is empirically given by [25]  BW = 3.77    cid:21 r − 1    cid:21 2 r  W L  t λ0  ,   10.58   which is a linear function of t. However, t must be small, since a large t will lead to larger surface waves, more fringing leakage, and smaller directivity. Thus, the microstrip antenna has an inherently narrow bandwidth of only a couple of percent. An increase in W leads to an increase in bandwidth. However, W should be less than λ to prevent excitation of higher- order modes. A commonly used substrate for microstrip antennas is ﬁberglass-reinforced synthetic substrate, with  cid:21 r typically between 2.1 and 2.6, and low dielectric loss  tan δ within 0.0006 and 0.002  [26].  10.6.2 Broadband microstrip antennas  Regularly shaped microstrip antennas are featured by narrow bandwidth, lower gain, and lower power-handling capability. By use of thick substrates with a low dielectric constant, the bandwidth can be improved to 5% to 10%. Bandwidth can be enhanced by modify- ing the shape of the patches, by using stacked  multilayer  or co-planar parasitic patches, or by using impedance-matching networks. Many bandwidth-enhancement techniques for microstrip antennas have been reviewed in [26].  Among various shape-modifying techniques, the technique of adding a U-shaped slot or using an L-shaped probe can provide bandwidths in excess of 30% [37, 47]. The U-slot patch antenna consists of a probe-fed rectangular patch with a U-shaped slot, which is cut symmetrically around the center of the patch; this antenna has an average gain of 7 dBi, and the L-probe-fed rectangular patch achieves an average gain of 7.5 dBi [37]. With the use of L-slot, L-shaped feed line and truncated corner, a wideband circularly-polarized slot antenna achieves a gain of around 6–7.5 dBi [47].  The bandwidth is usually deﬁned as the frequency range over which VSWR is less than  2 or 1.5. The bandwidth of a microstrip antenna is related to its quality factor Q by [26]  BW = VSWR − 1  √ VSWR  Q  .   10.59   The planar monopole antenna provides extremely wideband impedance characteristics. An array of planar monopoles can be used for wideband beamforming.  A reconﬁgurable microstrip antenna can adjust its operating frequency, radiation pat- terns, and polarization. It has a compact size. The patch antenna with switchable slot  PASS  is a reconﬁgurable slot-loaded patch antenna that inserts a switch in the center of the slot to control its conﬁguration. The switch can be a PIN diode or a micro- electromechanical system  MEMS -based switch. PASS has been design for dual-band      359   cid:2   10.7 Polarization-agile antennas  wireless LAN or GPS applications [46]. Frequency-reconﬁgurable antenna structures that incorporate switches, such as RF MEMS and PIN diodes, for frequency selection are desirable for mobile multiradio platforms [48].  10.7 Polarization-agile antennas  Polarization is a key parameter in antenna design. Polarization-agile antennas [14] are those antennas whose polarization can be dynamically changed at different times. Polarization- agile antennas can make use of polarization diversity in wireless communications to mitigate multipath fading. Different polarizations can be used for frequency-reuse radio transceivers, where the two orthogonal polarizations are used, one for transmitting and the other for receiving. Polarization-agile antennas can also be used in MIMO systems.  ◦  ◦ , 180  A circularly-polarized microstrip antenna can be implemented by exciting two orthogo- nal modes with equal magnitude. A simple polarization-agile antenna can be implemented by using a switchable phase shifter, as shown in Fig. 10.11. By controlling the phase differ- ence between φ1 and φ2, four types of polarization, i.e., two opposite linear polarizations and two opposite circular polarizations, can be achieved. A square microstrip antenna, which is fed at the four middle points of the edges with equal amplitude but phases 0, ◦ , results in an excellent axis ratio  AR  in the entire VSWR band- 90 width [26]. A similar result is obtained for circular microstrip antennas. A square-patch antenna with a slot along the diagonal direction can realize circular polarization with a single feed [26, 46]. A square-patch antenna embedded with a pair of L-type slits can switch its polarization between linear and circular polarization by using PIN diodes [39]. By using switches such as PIN diodes or RF MEMS, the polarization can be conﬁgured. Some RF MEMS-switch controlled pixel-patch antennas are capable of both polarization and frequency reconﬁguration.  , and 270  Wave polarizers can be used to convert between a linearly polarized wave and an elliptically or circularly polarized wave. A polarizer can be designed by using several conductive-strip or dielectric slab gratings. By suitably selecting grating separation and rotation angles or the depth of the slabs, a very small pattern distortion and insertion  y  z  E  x  Port 2  φ2  Phase shifter  φ1  Port 1   cid:2 Figure 10.11  Polarization-agile antenna using switchable phase shifter.      360   cid:2   Antennas  loss can be achieved. A polarization cascade matrix gives the reﬂection and transmission properties between the incident wave and the output linearly polarized wave. For each grating, the elliptically polarized wave is represented by two orthogonal linearly polarized waves. Each grating slab will retard the phase of an electric component by an angle, and thus change the polarization. The theory underlying this is given in [19]. A parasitic axial- mode helix can also be used as a polarizer to transform linearly polarized radiation to a circularly polarized wave [25].  10.8 Antenna arrays  Antenna arrays are usually used to provide desired radiation patterns. In a phased array, the phase of each element can be varied so as to adjust the radiation pattern. The elements can be antennas of the same type. This is illustrated in Fig. 10.12. All the branches are fed by a common feed. The feed cables for all the branches are made to be of equal length by using the corporate structure. Otherwise, the cables introduce different phase delays, which, in addition to the desired phase changes, must be compensated by phase shifters. Each antenna element is usually assigned with equal feed power by using power splitters, and phase shifters and attenuators are then connected to each element to adjust its phase and amplitude independently.  Three types of antenna arrays are usually used: uniform linear arrays, uniform pla- nar arrays and uniform circular arrays, where all the antenna elements are identical. An important parameter for antenna arrays is the array factor, also known as the beamforming gain.  The application of antenna arrays in smart antenna or MIMO systems is different from that of the conventional phased arrays. In a phased array, all the elements may have a common feed, whereas each element in a smart antenna or MIMO system has a sepa- rate feed whose current and phase can be adjusted independently. For application in smart antenna systems, uniform linear arrays or uniform planar arrays are conventionally used.  φ 1  φ 2  A1  A2  φ  3  A3  φ  4  A4   cid:2 Figure 10.12  Phased array with phase shifters and attenuators. The array has a corporate structure.  Feedline      361   cid:2   10.8 Antenna arrays  Uniform circular arrays are presently gaining more popularity due to their compact size and symmetry [11]. Uniform linear arrays have ambiguity in a differentiating the elevation angles θ and −θ. In practice, the ﬁeld of view of a uniform linear array is restricted to 120 ◦ , or a loss in spatial resolution will occur. For BSs that require omnidirectional antenna cov- erage, multiple uniform linear arrays along different sectors can be used. However, uniform circular arrays provide a better solution. Uniform circular arrays are usually composed of monopoles. Uniform planar arrays are more complex for implementation in smart antenna or MIMO systems.  For use in BSs, multiple patch antennas can be used as a phased array by suitably design- ing the feeding system so that it has a desired beam pattern. These patch arrays can be placed on a planar board or on a cylinder. Printed patch array antennas are popular due to their ease of manufacture using microstrip lines, which are etched on one side of a PCB. A multilayer PCB is usually used so as to accommodate the connections and circuitry. Patch arrays are also used to replace the parabolic dishes for satellite and space communica- tions. Although the microstrip element is inherently narrowband, log-periodic patch arrays achieve broadband ratios of up to 4 to 1 with moderate gain.  Parasitic array antennas  In conventional array antennas or antenna arrays, all antenna elements are active. For dig- ital beamforming, each antenna element is connected to its own RF circuit branch and ADC. This leads to a signiﬁcant increase in the dc power and cost. A switched parasitic antenna offers characteristics similar to an array antenna with several ﬁxed beams, but uses only one RF branch. Due to the compact size and low cost, it is suitable for small wireless devices [33].  A switched parasitic antenna can be designed as an array of λ 2-dipoles, composed of one central active element and two co-linear parasitic elements. The two parasitic elements may be either open- or short-circuited by using PIN diodes and digital control signals [33]. The electronically steerable parasitic array radiator  ESPAR  antenna is a low-power- consumption, compact, smart antenna [38]. The inter-element spacing can be as small as 0.05λ [41]. The ESPAR antenna is a reactively controlled directive-array antenna, in which only the central element is actively fed and connected to the RF port while all the surrounding elements are parasitic. By tuning the load reactance of parasitic elements, beam steering is achieved. The load reactances are implemented using reversely biased varactor diodes. ESPAR is especially suitable for low-power-consumption, low-cost MSs.  10.8.1 Array factor  For the uniform linear array, when the elements have identical amplitude, but progressive phase shift α across the array, the array factor is given by  AF = Na cid:26   n=1  e j n−1 ψ = sin Naψ 2  Na sin ψ 2   ,   10.60       362   cid:2   Antennas  where Na is the number of array elements, d is the inter-element spacing, and  ψ = 2π  d cos θ + α,  λ   10.61   with θ being the elevation angle and λ the wavelength. The array factor can be designed by suitably selecting α. In fact, both the amplitude and phase of the antenna elements can be adjusted to control the array factor. The array factors for the uniform planar array and the uniform circular array for identical amplitude and progressive phase shift of antenna elements are derived in [5].  A distributed antenna is a phased array that is composed of multiple identical antenna elements with currents of the same amplitude and phase. A distributed antenna provides a better power efﬁciency than a single antenna for the same total delivered power [11]. This also introduces reliability.  Beampattern design for antenna arrays requires the pattern to satisfy some speciﬁca- tions, and some optimization techniques are used to select the optimum amplitude and phase at each antenna element. For example, a uniform linear array with amplitudes of Dolph-Tchebysheff distribution and uniform phase difference between adjacent elements can generate optimum patterns for a speciﬁed sidelobe level with all sidelobes of the same level [25].  10.8.2 Mutual coupling and spatial correlation  For smart antenna or MIMO systems, the capacity offered by multiple antennas may not be realized when the antenna elements are highly correlated. Physical limitations on the MSs force multiple antennas to be spaced closely. The spatial correlation coefﬁcient ρ is deﬁned to measure the relationship between the signals of two antennas as [42]   cid:27  cid:27   ρ =  2π 0  ∗ 1 θ, φ E2 θ, φ P θ, φ  sin θdθdφ  0 E  ∗ 1 θ, φ E1 θ, φ P θ, φ  sin θdθdφ E  ∗ 2 θ, φ E2 θ, φ P θ, φ  sin θdθdφ  ,  E   cid:27  cid:27    cid:4  cid:4  cid:4  cid:27    cid:27  π   cid:4  cid:4  cid:4 2  ∗   10.62  where Ei, i = 1, 2, is the electric ﬁeld of antenna i when all other antennas are matched, P ·  denotes conjugation. Mutual coupling is the distribution of DoA  θ, φ , and superscript and antenna spacing can change Ei, and hence, the spatial correlation. Mutual coupling from other antenna elements or nearby conducting objects modify the induced current on an antenna element; thus, many parameters of the antennas including spatial correla- tion are modiﬁed. Mutual coupling as well as spatial correlation is mostly inﬂuenced by the spacing between antennas. To reduce the inﬂuence of mutual coupling, the distance between antenna elements needs to be at least half a wavelength, and a spacing of one half-wavelength is usually recommended.  Mutual coupling introduces mutual impedance that changes the radiation property of each antenna. For two identical thin-wire linear dipoles that are placed side by side, the mutual impedance is given in [25]. For the special case of the antenna length L = n λ 2 for n odd, the mutual resistance and mutual reactance, measured in ohms, are given by [25]      363   cid:2   ;   cid:22   cid:22   10.8 Antenna arrays   cid:17  cid:25  d2 + L2 + L  cid:17  cid:25    cid:18  cid:23  − Ci  cid:18  cid:23    cid:22   cid:22   β  2Ci βd  − Ci ;  R21 = 30 X21 = −30 where d is the distance between the two parallel antennas, Ci and Si are the cosine and sine integrals,  2Si βd  − Si  d2 + L2 + L  cid:14   − Si   10.64    10.63   β  β  β  ,  ,  Ci x  = γ + ln x  +  cos t − 1  x  Si x  =   10.65  with γ = 0.577 being Euler’s constant, R21 and X21 the mutual resistance and mutual reactance on antenna 2 caused by antenna 1, and  dt,  dt,  0  0  t  t   cid:18  cid:23 <  cid:18  cid:23 <   cid:17  cid:25  d2 + L2 − L  cid:17  cid:25  d2 + L2 − L  cid:14   x  sin t  Z21 = R21 + jX21 = Z12 = R12 + jX12.   10.66   Mutual impedances between two thin-wire dipoles of various conﬁgurations are also given in [25].  Example 10.2: The mutual resistance and reactance as a function of the distance between the two antennas, given by  10.63  and  10.64  are plotted in Fig. 10.13 for λ 2 dipoles. It is seen that the total resistance for each antenna, R11 − R21, is signiﬁcantly lower than the self resistance R11 when the distance is below 0.4λ. This leads to considerable loss in radiation efﬁciency, since the antenna current must be large for radiating the power, and the antenna loss resistance consumes a considerable amount of energy. When the spacing is λ 2, the mutual resistance R21 is −12.7 ohms, and this value oscillates around 0, and takes small values when the spacing is close to a multiple of λ 2.  R21 X21  80  60  40  20  0    s  m h o     e c n a d e p m  I  −20  −40  0   cid:2 Figure 10.13 Mutual resistance R21 and reactance  X21  of two parallel side-by-side λ 2-dipoles versus the  distance between the two antennas, d.  1  2  3  4  5  d λ      364   cid:2   Antennas  When the antenna patterns are dissimilar, the correlation is small. Orthogonal patterns can be obtained by a suitable selection of angle, space, or polarization diversity. In this case, small spacings can be used. Dissimilar patterns can also be obtained using different types of antennas. Spatial correlation reduces the number of independent channels in a MIMO system, and thus signiﬁcantly diminishes the capacity of a MIMO system.  10.9 Wideband antennas  FBW = f2 − f1  The useful bandwidth of an antenna is decided by both its pattern and impedance charac- teristics. Assuming the VSWR is within the desired range, the fractional bandwidth  FBW  of an antenna can be deﬁned as   10.67  where f1 and f2, f1 < f2, are the frequency limits, and f0 =   f1 + f2   2 is the center frequency. For narrowband communications, FBW is usually less than 5%; for wideband antennas, FBW can be up to 25%; for UWB antennas, it is between 25 and 200%. The bandwidth can also be deﬁned as f2 :1. When the impedance varies more rapidly than the f1 pattern, the bandwidth is usually small and can be deﬁned as Q at f0.  f0  In contrast to the dipole, which is a resonant, high-Q antenna with its input impedance changing rapidly with frequency, broadband antennas are nonresonant low-Q radiators whose input impedance remains essentially constant over a wide frequency range. Wide- band antennas require the phase center and VSWR to be constant across the whole bandwidth of operation.  10.9.1 Implementation of wideband antennas  Rumsey’s principle indicates that the impedance and pattern of an antenna are frequency- independent if the antenna shape is speciﬁed in terms of the angle only. This requires an architecture of inﬁnite size. By suitable truncation of the architecture, these antennas can provide the broadband property. Examples are the biconical dipole antenna, the biconi- cal vee antenna, the ﬂat-plane bow-tie dipole antenna, the axial-mode helical antenna, the planar log-spiral antenna, the self-complementary toothed log-periodic antenna, and the log-periodic dipole array. Little energy is reﬂected from the open end of the antenna, thus the input impedance remains essentially constant over a wide bandwidth. The biconical dipole, the log-spiral antenna, and the bow-tie dipole provide omnidirectional radiations.  Conical monopoles can achieve impedance bandwidth, which is dependent on the radius of the cylindrical stub and increases with increased radius. Tapering the transition for the feed probe is often employed in wideband elements, such as biconical dipoles and con- ical monopoles. A cheap alternative to the cones is to use a planar element to replace      365   cid:2   10.9 Wideband antennas  the cylindrical stub, leading to a planar monopole. Square planar monopoles of different size typically have an impedance bandwidth of 80% [4]. Such planar monopole anten- nas are especially suitable for multiband and UWB systems. A signiﬁcant increase in impedance bandwidth can be achieved by trimming the square edge near the ground plane, yielding an asymmetrical or symmetrical pentagonal monopole. An increase in the bevel angle can increase the upper-edge frequency and thus, the impedance bandwidth. The use of a shorting post can reduce the lower-edge frequency by introducing an extra mode [4]. The planar antenna can be replaced by a wire grid to reduce the inﬂuence of wind.  For multiband SDR, multiband antennas must be used. This requires the use of a wideband antenna. Tunable microstrip antennas provide an alternative to large bandwidth antennas. Tunable microstrip antennas can be designed by changing the length of the small stub attached to the regularly shaped microstrip antennas [26]. For a rectangular microstrip antenna, a stub can be placed along one of its edges. When the length of the stub is small, tunability is achieved. However, when the length is comparable to λ 4, dual-band properties are exhibited. For a rectangular microstrip antenna, the TM10 and TM30 modes have the radiation patterns in the broadside direction with the same polar- ization at both the resonant frequencies, and thus these modes can be used for dual-band operation.  The aperture-coupled microstrip-patch antenna is a low-cost solution for BSs. This design provides dual linear polarization, thus allowing polarization diversity. The planar structure can be simulated accurately by using the MoM. Spiral antennas have the charac- teristics of broad bandwidth and circular polarization. They can be implemented as wires, microstrips, or slots.  Broadband reconﬁgurable antennas  Broadband reconﬁgurable antennas are especially desirable for SDRs. The bandwidth can be adjusted over a wide range of frequency, when its environment or application is changed, by reconﬁguring the system structure using switches. The switches can be made using RF MEMS technology, since it allows for lower resistance and excellent efﬁciency as compared to electrical switches [9, 34].  The self-structuring antenna [9] consists of a number of wires or patches intercon- nected by controllable switches. These switches are used to alter the electrical shape of the antenna. The self-structuring antenna is capable of selecting its state from one of 2n discrete electrical conﬁgurations for n switches. The self-structuring antenna is composed of an antenna template, controllable switches, a sensor system for measuring important quantities such as signal strength, VSWR and input impedance, an efﬁcient binary search algorithm, and a microprocessor controller. The binary search algorithm can be based on the genetic algorithm or simulated annealing [12] so that it can ﬁnd a suboptimal conﬁgu- ration in a short time. The self-structuring antenna can be used as a wideband antenna or as a no-design antenna. In [34], a design that is able to electronically change the operating frequency of a rectangular ring slot antenna by adjusting the MEMS switches to change the circumference of the ring is described.      366   cid:2   Antennas  10.9.2 Ultra wideband antennas  UWB antennas are quite different from conventional narrowband antennas. FCC speciﬁes the 3.1 to 10.6 GHz band for UWB communications. Due to the intended applications in consumer electronics, UWB antennas should be of small size, efﬁcient, omnidirectional in pattern, and have low distortion, and large bandwidth. The phase center and VSWR of UWB antennas are required to be constant across the whole bandwidth of operation.  Conventional resonant antennas are not suitable for UWB applications, since they can only radiate waves at the resonant frequency. A nonresonant antenna is usually electrically large. It is dispersive for UWB pulses by radiating different frequency components from different parts of the antenna, leading to extended and distorted waveforms. Also, special care must be taken to make it efﬁcient. Thus it is also not suitable for UWB systems. UWB systems transmit very low power pulses, and antennas are signiﬁcant pulse-shaping ﬁlters; for UWB systems, any distortion in the frequency domain increases the complexity for detection at the receiver.  For UWB pulse signals, also called digital waves, the radiation from an antenna is sig- niﬁcantly different from that of continuous wave narrowband signals. Since UWB systems are typically used for indoor environments, the near-ﬁeld radiation must be considered. For fast transient radiation, the frequency-domain model fails due to the near-ﬁeld dispersion. The biconical and bowtie monopoles dipoles are usually used for UWB applications [25]. Broadband planar monopole antennas are particularly attractive for use as UWB antennas due to ease of fabrication.  A number of antennas can be used as impulse antennas under certain conditions [15]. The conical antenna, when used as a receive antenna, generates its output as the integral of the incident electric ﬁeld. A monopole antenna is used as a simpler version of the conical antenna, and thus also has an integral effect for the voltage wave from the driving point or for the received electric ﬁeld. The D-dot probe antenna is an extremely short monopole antenna, and its output is the derivative of the incident electric ﬁeld. A TEM horn antenna, when used as a transmit antenna, generates the radiated electric ﬁeld as the derivative of the input driving-point voltage.  Planar UWB antennas  Planar monopole and dipole antennas are well-suited for UWB systems, since they are compact and easy to fabricate. They can generate a very large impedance bandwidth and near constant group delays if designed appropriately [8]. They can be viewed as a microstrip antenna on a very thick substrate  very large t  with  cid:21 r = 1  suspended in air . For a rectangular planar monopole, as shown in Fig. 10.14, the impedance bandwidth depends mainly on the width W of the plate, the diameter d of the feeding probe, and the length p of the probe. When the frequency is above 1 GHz, the SMA connector is gener- ally used for feeding the antenna, and thus d = 0.12 cm. The lower edge frequency of the antenna is then given by [26]  fL =  7.2  L + r + p   GHz ,   10.68       367   cid:2   Problems  W  L  p   cid:2 Figure 10.14  Planar rectangular monopole.  where the height L of the monopole antenna, the equivalent radius r corresponding to an equivalent cylindrical monopole antenna, r = W 2π , and the feed probe length p are all in centimeters.  A planar circular or elliptical monopole antenna can generate a larger bandwidth than other planar monopole antennas can [3]. It can be designed to include the whole UWB band very easily [3, 17]. For example, when the radius of a circular monopole is 2.5 cm and the feed probe length p = 0.1 cm, the bandwidth for VSWR≤ 2 is from 1.17 GHz to 12 GHz, corresponding to a bandwidth ratio of 1:10.2 [26].  The antenna impedance of a narrowband antenna is an intrinsic property of the antenna. In contrast, the impedance of a UWB antenna is not an intrinsic property, but a design choice. For instance, a planar elliptical dipole yields an excellent match to 50 ohms [36], but a planar elliptical monopole also offers a good match to 50 ohms [3]. Impedance of these antennas can be adjusted by varying the gap between the dipole elements and by varying the gap between a monopole element and the ground plane.  When UWB systems share the frequency bands with existing wireless standards, band- stop ﬁltering is required to prevent interference. This is normally done by a conventional ﬁlter in the RF receiver front end. UWB antennas can also be designed with a band-notch characteristic to aid narrowband signal rejection. This can be realized by modifying the planar monopoles by adding internal or external slot structures [22, 51].  Many UWB antennas that cover the entire UWB band of 3.1–10.6 GHz are available in the literature [2, 23, 49]. In [2], planar monopole UWB antennas of elliptical and circular shape have been fabricated using simple design formulas. These antennas have near-omnidirectional characteristics and a radiation efﬁciency of more than 90%. A pla- nar dipole UWB antenna of bow-tie shape has been designed in [49]. Planar UWB textile antennas have been designed for wireless BAN applications in [23].  Problems  10.1 From Maxell’s equations, derive the wave equations for E and H as  ∇2E + ω2 cid:21 μ  1 − j  E = 0, ∇2H + ω2 cid:21 μ  1 − j  H = 0.  σ  ω cid:21    cid:17    cid:18   σ  ω cid:21    cid:17    cid:18       368   cid:2   Antennas  In space, the conductivity is very small, σ  cid:5  ω cid:21 . [Hint: Use the vector identity ∇×∇×E = ∇ ∇ · E  − ∇2E. ] 10.2 Find the far-ﬁeld distance for an antenna with maximum dimension of 1 m, operating at 2 GHz.  10.3 If the BS transmits with a power of 50 W via a unity-gain antenna at 2 GHz, ﬁnd the received power in dBm at a free space distance of 100 m. Assume the receive antenna has a unity gain. What is the received power at a free-space distance of 10 km?  10.4 Prove that the directivity of a half-wave dipole is equal to 1.64.  .  10.5 A half-wave dipole radiates a power of 100 W in free space at a frequency of 900 MHz. Calculate the electric and magnetic ﬁeld strengths at a point r = 100 m, θ = 60 ◦ , and φ = 30 ◦ 10.6 Eight half-wave dipoles are arranged side-by-side along a circle of radius a = λ 2. Calculate the open-circuit voltage on any antenna element, when all the antennas are fed with current I0 cos ωt. 10.7 A radio transmitter on the Moon is operated at f = 2.8 GHz with a transmit power of PT = 2 W. The gain of the antenna is GT = 1000. A receiver is located on the Earth, and the propagation delay from the Moon to the Earth is 1.27 s. For a detection threshold P0 = 10 −14 W, what is the gain of the receive antenna GR? What is the area of the receive antenna?  10.8 Derive the directivity of the half-wave dipole to be   cid:7    cid:4  cid:4  cid:4  cid:4  cid:4  cos   cid:8    cid:4  cid:4  cid:4  cid:4  cid:4 2  .  D θ  = 1.64  π  2 cos θ sin θ  10.9 An elliptically polarized wave is traveling along the z direction in free space. It has components in volts m as  Ex = 2 sin ωt − βz , Ey = 5 sin ωt − βz + 45 ◦   .  What is the average power density conveyed by the wave? What is the axial ratio of the wave? Is it a left-circularly polarized or right-circularly polarized wave?  10.10 Find the maximum effective aperture of a microwave antenna with a directivity of 50.  10.11 Two isotropic sources have equal amplitude and opposite phase. They are separated by a distance of 2λ. Plot the far-ﬁeld power pattern. If the two sources are two half-wave dipoles conﬁgured side by side, plot the far-ﬁeld power pattern. 10.12 An antenna has a uniform ﬁeld E = 1 V m  rms  at a distance of 100 m for 30 θ ≤ 45 ◦  rms . Calculate the directivity, effective aperture, and radiation resistance.  ◦ ≤ , and E = 0 elsewhere. The antenna terminal current is 2 A  ◦ ≤ φ ≤ 60 ◦  and 0      369   cid:2   References  10.13 An antenna system is composed of two quarter-wave monopoles above a perfect ground. The two quarter-wave monopoles are separated by a quarter-wavelength. The two ◦ out of phase. The antenna system antennas are fed currents of equal amplitudes but 90 radiates a power of 1 kW. Determine the magnitude and phase of the required driving-point voltages for the two antennas.  10.14 An omnidirectional antenna is 10 m above the Earth surface. What is the distance to the horizon it can cover? Assume a smooth Earth and a medium refractivity. [Hint:  d = √  2Rh.]  10.15 An isotropic antenna is radiating in free space. At a distance of 100 m, the total electric ﬁeld is measured to be 2 V m. Determine the power density and the radiated power.  10.16 The radiation intensity of an antenna is given by U θ, φ  = cos4 θ sin2φ  for 0 ≤ θ ≤ π 2 and 0 ≤ φ ≤ 2π, and is zero elsewhere. Find  a  the directivity and  b  the HPBW in the elevation plane. 10.17 A half-wave dipole is connected to a generator with impedance of 50 + j25. The dipole has a loss resistance of 2 ohms. The peak voltage of the generator is 5 V, and the radiation resistance of the dipole is 73 + j43.5 ohms. Find  a  the power supplied by the source,  b  the power radiated by the antenna, and  c  the radiation efﬁciency. 10.18 A 4-cm long dipole carries a phasor current I0 = 10e j45 ◦ A. If the wavelength is 10 cm, ﬁnd the E- and H-ﬁelds at a distance of r = 1 m and θ = 30 ◦ 10.19 Verify that the directivity of a Hertzian dipole is given by  10.48 .  .  10.20 Design a microstrip patch antenna operating at 2.4 GHz. The substrate is Duroid 5880   cid:21 r = 2.2  with a thickness of 0.04 in.  References  [1] 3GPP, Spatial Channel Model for Multiple Input Multiple Output MIMO Simulations,  TR 25.996, ver. 6.1.0, Sep 2003.  [2] A. M. Abbosh & M. E. Bialkowski, Design of ultrawideband planar monopole anten- nas of circular and elliptical shape. IEEE Trans. Anten. Propagat., 56:1  2008 , 17–23.  [3] N. P. Agarwall, G. Kumar & K. P. Ray, Wide-band planar monopole antennas. IEEE  Trans. Anten. Propagat., 46:2  1998 , 294–295.  [4] M. J. Ammann & Z. N. Chen, Wideband monopole antennas for multi-band wireless  systems. IEEE Anten. Propagat. Mag., 45:2  2003 , 146–150.  [5] C. A. Balanis, Antenna Theory: Analysis and Design, 2nd edn  New York: Wiley,  1997 .      370   cid:2   Antennas  [6] J.-P. Berenger, A perfectly matched layer for the absorption of electromagnetic waves.  J. Comput. Physics, 114:2  1994 , 185–200.  [7] K. R. Carver & J. W. Mink, Microstrip antenna technology. IEEE Trans. Anten.  Propagat., 29:1  1981 , 2–24.  [8] Z. N. Chen, M. J. Ammann, X. Qing, X. H. Wu, T. S. P. See & A. Cai, Planar antennas.  IEEE Microwave Mag., 7:6  2006 , 63–73.  [9] C. M. Coleman, E. J. Rothwell, J. E. Ross & L. L. Nagy, Self-structuring antennas.  IEEE Anten. Propagat. Mag., 44:3  2002 , 11–22.  [10] D. B. Davidson, Computational Electromagnetics for RF and Microwave Engineering   Cambridge, UK: Cambridge University Press, 2005 .  [11] K.-L. Du, Pattern analysis of uniform circular array. IEEE Trans. Anten. Propagat.,  52:4  2004 , 1125–1129.   London: Springer, 2006 .  [12] K.-L. Du and M. N. S. Swamy, Neural Networks in a Softcomputing Framework  [13] H. T. Friis, A note on a simple transmission formula. Proc. IRE, 34:5  1946 , 254–256. [14] S. Gao, A. Sambell & S. S. Zhong, Polarization-agile antennas. IEEE Anten. Propa-  gat. Mag., 48:3  2006 , 28–37.  [15] M. Ghavami, L.B. Michael & R. Kohno, Ultra Wideband: Signals and Systems in  Communication Engineering, 2nd edn  Chichester, UK: Wiley, 2007 .  [16] J. P. Gianvittorio & Y. Rahmat-Samii, Fractal antennas: a novel antenna minia- turization technique, and applications. IEEE Anten. Propagat. Mag., 44:1  2002 , 20–36.  [17] M. Hammoud, P. Poey & F. Colombel, Matching the input impedance of a broadband  disc monopole. Electron. Lett., 29:4  1993 , 406–407.  [18] R. F. Harrington, Field Computation by Moment Methods  New York: Macmillan,  1968 .  2002 .  [19] N. Hill & S. Cornbleet, Microwave transmission through a series of inclined gratings.  Proc. IEE, 120:4  1973 , 407–412.  [20] J. Jin, The Finite Element Method in Electromagnetics, 2nd edn  New York: Wiley,  [21] H. Jasik, ed., Antenna Engineering Handbook  New York: McGraw-Hill, 1961 . [22] A. Kerkhoff and H. Ling, A parametric study of band-notched UWB planar monopole  antennas. In Proc. IEEE AP-S Int. Symp., Monterey, CA, Jun 2004, 2, 1768–1771.  [23] M. Klemm & G. Troester, Textile UWB antennas for wireless body area networks.  IEEE Trans. Anten. Propagat., 54:11  2006 , 3192–3197.  [24] M. Komulainen, M. Berg, H. Jantunen, E. T. Salonen & C. Free, A frequency tuning method for a planar inverted-F antenna. IEEE Trans. Anten. Propagat., 56:4  2008 , 944–950.  [25] J. D. Kraus & R. J. Marhefka, Antennas: For All Applications, 3rd edn  New York:  McGraw-Hill, 2002 .  House, 2003 .  [26] G. Kumar & K. P. Ray, Broadband Microstrip Antennas  Norwood, MA: Artech  [27] Y. T. Lo, D. Solomon, & W. F. Richards, Theory and experiment on microstrip  antennas. IEEE Trans. Anten. Propagat., 27:2  1979 , 137–145.      371   cid:2   References  [28] J. C. Maxwell, A Treatise on Electricity and Magnetism  Oxford, UK: Clarendon  Press, 1873; New York: Dover, 1954 .  [29] E. H. Newman & P. Tulyathan, Analysis of microstrip antennas using method of  moments. IEEE Trans. Anten. Propagat., 29:1  1981 , 47–53.  [30] U. Olgun, C. A. Tunc, D. Aktas, V. B. Erturk & A. Altintas, Particle swarm optimiza- tion of dipole arrays for superior MIMO capacity. Microwave Opt. Tech. Lett., 51:2  2009 , 333–337.  [31] J. Ollikainen, O. Kivekas, A Toropainen, and P. Vainikainen, Internal dual-band patch antenna for mobile phones. In Proc. Millenium Conf. Anten. Propagat.  AP2000 , Davos, Switzerland, Apr 2000, paper no. 1111 .  [32] Y. Ouyang & W. J. Chappell, High frequency properties of electro-textiles for wearable antenna applications. IEEE Trans. Anten. Propagat., 56:2  2008 , 381–389. [33] S. L. Preston, D. V. Thiel, J. W. Lu, S. G. O’Keefe & T. S. Bird, Electronic beam  steering using switched parasitic patch elements. Electron. Lett., 33:1  1997 , 7–8.  [34] R. J. Richards & H. J. De Los Santos, MEMS for RF microwave wireless applications:  the next wave. Microwave J., 44:3  2001 , 20–41  [35] I. D. Robertson & S. Lucyszyn, ed., RFIC and MMIC Design and Technology   London, UK: IEE Press, 2001 .  [36] H. Schantz, Planar elliptical element ultra-wideband dipole antennas. In Proc. IEEE  A-S Int. Symp., San Antonio, TX, Jun 2002, 3, 44–47.  [37] A. K. Shackelford, K.-F. Lee & K. M. Luk, Design of small-size wide-bandwidth  microstrip-patch antennas. IEEE Anten. Propagat. Mag., 45:1  2003 , 75–83.  [38] C. Sun, A. Hirata, T. Ohira & N. C. Karmakar, Fast Beamforming of electronically steerable parasitic array radiator antennas: theory and experiment. IEEE Trans. Anten. Propagat., 52:7  2004 , 1819–1832.  [39] Y. J. Sung, Reconﬁgurable patch antenna for polarization diversity. IEEE Trans.  Anten. Propagat., 56:9  2008 , 3053–3054.  [40] A. Taﬂove & S. C. Hagness, Computational Electrodynamics: the Finite Difference  Time Domain Method, 3rd edn  Boston, MA: Artech House, 2005 .  [41] M. Taromaru & T. Ohira, Electronically steerable parasitic array radiator antenna: principle, control theory and its applications. In Proc. General Assembly of URSI, New Delhi, India, Oct 2005, Paper no. C02.1.  [42] K. Tsunekawa & K. Kagoshima, Analysis of a correlation coefﬁcient of built-in diver- sity antennas for a portable telephone. In Proc. IEEE AP-S Int. Symp., Dallas, TX, May 1990, vol 1, 543–46.  [43] C. A. Tunc, D. Aktas, V. B. Erturk & A. Altintas, Capacity of printed dipole arrays in  MIMO channel. IEEE Ant. Propagat. Mag., 50:5  2008 , 190–198.  [44] R. G. Vaughan, Polarization diversity in mobile communications. IEEE Trans. Veh.  Tech., 39:3  1990 , 177–186.  [45] D. H. Werner & S. Ganguly, An overview of fractal antenna engineering research.  IEEE Anten. Propagat. Mag., 45:1  2003 , 38–57.  [46] F. Yang & Y. Rahmat-Samii, Patch antennas with switchable slots  PASS  in wireless communications: concepts, designs, and applications. IEEE Anten. Propagat. Mag., 47:2  2005 , 13–29.      372   cid:2   Antennas  [47] S.-L. S. Yang, A. A. Kishk & K.-F. Lee, Wideband circularly polarized antenna with  L-shaped slot. IEEE Trans. Anten. Propagat., 56:6  2008 , 1780–1783.  [48] S. Yang, C. Zhang, H. K. Pan, A. E. Fathy & V. K. Nair, Frequency-reconﬁgurable  antennas for multiradio wireless platforms. IEEE Microwave Mag., 10:1  2009 , 66–83.  [49] K. Y. Yazdandoost & R. Kohno, Ultra wideband antenna. IEEE Commun. Mag., 42:6   2004 , S29–S32.  [50] K. Yee, Numerical solution of initial boundary value problems involving Maxwell’s  equations in isotropic media. IEEE Trans. Anten. Propagat., 14:3  1966 , 302–307.  [51] H. Yoon, H. Kim, K. Chang, Y. J. Yoon & Y. H. Kim, A study on the UWB antenna with band-rejection characteristic. In Proc. IEEE AP-S Int. Symp., Monterey, CA, Jun 2004, 2, 1784–1787.      11  RF and microwave subsystems  11.1 Introduction  The term microwaves is used to describe electromagnetic waves with frequencies from 300 MHz to 300 GHz, corresponding to wavelengths in free space from 1 m to 1mm. Within the microwave range, from 30 GHz to 300 GHz the wavelengths are between 1 mm and 10 mm, and hence these waves are known as millimeter waves. Below 300 MHz the spectrum of electromagnetic waves is known as the radio frequency  RF  spectrum, while above the microwave spectrum are the infrared, visible optical, ultra- violet, and x-ray spectrums. Wireless communications uses only the electromagnetic waves in the range of the microwave and RF spectrums. In the wireless communica- tions literature, the term RF is often used to represent the entire RF and microwave spectrums.  11.1.1 Receiver performance requirements  The requirements on RF receivers are typically more demanding than those on transmitters. In addition to the requirements on gain and noise ﬁgure, the receiver must have:   A good sensitivity to the minimum power at the antenna for a given BER require- ment. For example, the GSM standard requires a reception dynamic range from −102 dBm to −15 dBm, IEEE 802.11g requires a reception range of −92 dBm to −20 dBm, for WCDMA it is −117 to −25 dBm  before spreading , for CDMA2000 it is −117 dBm to −30 dBm, and for WideMedia it is −80.8 dBm MHz  or −72.4 dBm MHz at highest speed  to -41.25 dBm MHz. For multiple data rates, a higher data rate requires a higher sensitivity, since it requires a larger SNR. The AWGN sensitivity is computed by  Sensitivity = NFR + SNR + margin  where NFR denotes the noise ﬁgure of the receiver. The high sensitivity demands a high gain, as high as 100 to 120 dB, to restore the received signal to its original baseband level. The total gain should be distributed over the RF, IF, and baseband stages for reasons of stability and cost. The receiver sensitivity of WCDMA is −106 dBm with a nominal receiver noise ﬁgure of 9 dB, therefore the required signal power before despreading is −117 dBm.      374   cid:2   RF and microwave subsystems  Table 11.1. Radio speciﬁcations for GSM WCDMA Wi-Fi WiMAX [45].  WiMAX  802.16  Wi-Fi  802.11b  WCDMA  GSM  2.412–2.484 GHz 2.010–2.025 GHz 890–915 MHz  Frequency band  Channel spacing Channel bandwidth Sensitivity Maximum input signal −20 dBm Input noise Required SNR  2–11 GHz 10–66 GHz 1.25–28 MHz 25 MHz 1.25–28 MHz 20 MHz  −93.2 to −80  −76 dBm +10log BW  −10 dBm −116 to −103 dBm −104 dBm 9.8–23 dB  14 dB  1.900–1.910 GHz 5 MHz 3.84 MHz −117 dBm −25 dBm −111 dBm 7.2 dB  200 kHz 200 kHz −102 dBm −15 dBm −124 dBm 9 dB    A wide dynamic range for handling interference in the channel.   A good adjacent channel selectivity for receiving the wanted signal while reject- ing interference present on an adjacent channel. The minimum adjacent chan- nel leakage power ratio for WCDMA is greater than 33 and 43 dB for adjacent channel frequency relative to assigned channel frequency at ±5 and ±10 MHz, respectively.   A good blocking ability to maintain performance of a wanted signal in the presence of an interferer.   A desirable intermodulation rejection ability to reject interfering signals arising from intermodulation with the wanted signal.   A good isolation from the transmitter to prevent saturation of the receiver in a duplex system. The isolation is required to be not less than 100 dB. For a half-duplex system, the transmitter and receiver are not operating simultaneously and a transmit receive switch can be used. For a full-duplex system, both transmitter and receiver operate simultaneously but on different frequency bands; duplexing is achieved using bandpass ﬁlters.  The radio speciﬁcations of GSM WCDMA Wi-Fi WiMAX are summarized in Table 11.1 for GSM power class II, WCDMA TDD mode, IEEE 802.11b, and IEEE 802.16 [45].  For RF transmitters, it is generally required to have a tight occupied bandwidth, low out-of-band emissions, low spurious emissions, and the ability to inhibit intermodulation.  11.1.2 Architecture of RF subsystems  The architecture of radio tranceivers has been discussed in Section 1.4. The RF front- end or subsystem is critical to the performance of the whole radio transceiver. Also, the emission of the RF front-end must strictly comply with the electromagnetic interference and electromagnetic compatibility requirements that are speciﬁed by FCC for a wireless standard.      375   cid:2   11.2 RF system analysis  A typical RF subsystem architecture for SDRs has been shown in Fig. 1.3. On the receive path, the received RF signal is ﬁrst subject to a bandpass ﬁlter and LNA before it is trans- formed to the IF signal. Conversely, on the transmit path, the IF signal is transformed to RF signal and then ampliﬁed with the power ampliﬁer. Depending on implementation, there may be more than one IF stage. For a wideband system, all the RF components, such as the mixers, preampliﬁers, and LNAs, are required to be of wideband nature, and these com- ponents can be used for multiband RF front-ends. The ﬁlters have to accommodate for the widest bandwidth among the multiple radio standards.  Oscillators are necessary for frequency conversion, and PLLs are used for generating sta- ble oscillators. For phased-array antennas, phase shifters are essential components. Phase shifters can be fabricated by using PIN diodes, ﬁeld-effect transistor  FET  switches or MEMS switches. Attenuators and ampliﬁers may be used in phased arrays and automatic gain control  AGC . Baluns are required in many microwave components, such as balanced mixers, push-pull ampliﬁers, multipliers, and phase shifters, to improve the performance and reduce the cost of the RF module. The transmit receive switch, which is used to con- nect the antenna to form a transmit or receive train, can be implemented using a circulator. We will introduce all the important RF or microwave components that constitute a RF subsystem in this chapter.  Discrete gallium arsenide  GaAs  transistors traditionally dominate gigahertz  GHz - band RF circuits. These require signiﬁcant area and have large power consumption. More and more RF designs are now based on CMOS technologies. Some wireless transceivers implement system-on-chip  SOC  technology. The system-on-package  SOP  scheme allows combination of CMOS monolithic microwave integrated circuits  MMICs  with low-temperature coﬁred ceramic  LTCC  multilayer passive components, which are then integrated in an LTCC substrate. Integrating high-quality passive components on ceramic substrates signiﬁcantly increases the output power.  RF Globalnet1 is a leading online trade publication for the RF microwave design indus- try. Its vast product directory contains detailed information on all kinds of RF microwave and antenna products, services, and test equipment.  11.2 RF system analysis  Before we proceed, we ﬁrst give the deﬁnition of power spectral density  PSD , also called spectral density or spectrum, Sx  f  , of a random signal x t . PSD is a measure of how much power a signal carries in a unit bandwidth  Hz , centered around frequency f . The value of Sx  f   can be measured by applying a bandpass ﬁlter of 1-Hz bandwidth to the frequency f and then averaging the output power over a sufﬁciently long time  Sx  f   = lim T→∞  XT  f  2  ,  T  1 http:  www.rfglobalnet.com   11.1       376   cid:2   RF and microwave subsystems  where XT  f   is the Fourier transform of x t  in a period [0, T],  XT  f   =  T  −j2πftdt.  x t e   11.2    cid:14   0  11.2.1 Noise  Noise is one of the most important considerations in communication system design. For analog systems, thermal noise is generated by the thermal agitation of the electrons inside a conductor in equilibrium. Noise is additive for cascaded analog systems, thus each pro- cessing block of an RF subsystem must be allocated a reasonable gain and noise ﬁgure to reduce the noise of the whole subsystem.  For analog systems, the most common noises are thermal noise, shot noise, and ﬂicker noise. For digital systems, the major noise is the quantization noise arising from A D conversion. Overﬂow and rounding errors can also be treated as noise.  Thermal noise  Vn = √  4kTBR.  N = kBTB,  Thermal noise, also called Johnson noise, is a consequence of Brownian motion of free charge carriers, usually electrons, in a resistive medium. For a resistor R at temperature T, the random motion in the resistor leads to small random voltage ﬂuctuations at the terminals of the resistor. The rms voltage is given by the Rayleigh-Jean approximation [36, 37]   11.3   A Thevenin equivalent circuit for a noisy resistor can be used, and the noise power of thermal noise of the channel, measured in watts, is given by Nyquist’s formula   11.4  where kB is Boltzmann’s constant 1.381 × 10 −23 watts Hz K, T is the noise temperature in kelvins  K , and B is the bandwidth of the channel. In decibels referencing to milliwatts  dBm , kB = −198.6 dBm Hz K. The thermal noise power at room temperature  T = 290 K  is given by  N = −174 + 10 log10 B    dBm .   11.5   Thermal noise is independent of frequency, thus it is referred to as white noise.  The two-sided PSD of thermal noise is deﬁned as = kBT 2  Sn  f   = N 2B   11.6  where N0 = kBT is in watts Hz. This is the conventional deﬁnition used for communication systems, over the frequency range from −B to B Hz. The one-sided PSD Sn  f   = N0, since noise is only deﬁned over 0 to B Hz. The probability density function  pdf  of white noise is zero-mean Gaussian. In reality, Sn  f   is ﬂat for only  f < 100 GHz, and dropping beyond this frequency, leading to a ﬁnite total noise power of the resistor, N [37].  = N0 2  ,      377   cid:2   11.2 RF system analysis  Shot noise  Shot noise occurs only when there is a direct current ﬂow and a potential barrier over which the charge carriers hop. Some potential barriers are the junction of a PN diode, the emitter- base junction of a bipolar transistor, and the cathode of a vacuum tube. Shot noise is also a Gaussian white process, with a PSD  = 2qI,  I2 n   11.7   where q is the charge of an electron and I the average current. Due to the requirement for a potential barrier, shot noise only exists in nonlinear devices. In a bipolar transistor, both the base and collector currents are sources of shot noise, while in FETs only the dc gate leakage current produces shot noise.  Flicker noise  Flicker, or 1 f or pink, noise is the most mysterious type of noise. Flicker noise is ubiq- uitous, but no universal mechanism is identiﬁed yet for the ﬂicker noise. Thus, it can only be characterized by empirical parameters. Flicker noise occurs in most active devices. Flicker noise power is concentrated, with a PSD of approximately 1 f characteristic at low frequencies, usually below a few kilohertz, and has a ﬂat, weak spectrum above a few kilohertz.  Flicker noise may arise from random trapping of charge in bulk material, at junction interfaces and at the surface of the substrate as in the FET. Note that the ﬂicker noise also has a Gaussian pdf, but its PSD is not white but proportional to 1 f . Due to the nonlinarity of active devices, the 1 f -shaped spectrum may be translated into the RF range. Flicker noise is also exhibited in forward-biased junctions, as in the case of bipolar transistors.  For a three-terminal active device, the broadband noise performance can be split into three zones, as illustrated in Fig. 11.1. The ﬂicker noise typically occurs up to about 1 kHz for bipolar technologies, but above 10 MHz for FET technologies. When frequency is very large, the device capacitance leads to an increase in the noise, known as the capacitance- coupled noise.  Flicker noise also shows up in resistors, where it is usually called excess noise. A resistor is found to exhibit ﬂicker noise only when dc current follows through it, with the noise  Noise power  1 f noise  1 f corner frequency  Thermal + shot noise  Capacitance coupled noise  Frequency   cid:2 Figure 11.1  The noise power density spectrum of a transistor.      378   cid:2   RF and microwave subsystems  increasing with the current [27]. The common carbon composition resistors exhibit the most signiﬁcant ﬂicker noise, while metal ﬁlm and wirewound resistors have the least ﬂicker noise.  In a practical system such as in a low noise system, thermal noise is dominant, and thus physical cooling can effectively improve its noise performance. Noise power can be represented by using an equivalent thermal noise temperature Te = N kBB kelvins  K ; shot and ﬂicker noises can be treated in a similar way.  11.2.2 Noise ﬁgure  Noise ﬁgure measures the amount of noise added by a device. It is deﬁned by the ratio of the input SNR to the output SNR of a functional block, or more often by the ratio of the output noise to the input noise  F = SNRi SNRo  = No Ni  .   11.8   For practical devices, F > 1, i.e., F > 0 dB. The two deﬁnitions are equivalent, since the output signal So = GSi, and No = G  Ni + Ne , where Ne is the device noise as an equivalent input noise to the device. Thus No in the right-hand side of the equation is replaced by Ni + Ne. This deﬁnition is usually called noise factor, and noise ﬁgure is given by 10 log10 F, in decibels. Noise ﬁgure is typically speciﬁed for all devices and systems at an input noise temper- ature of T = 290 K for fair comparison. In this case, No is calculated by No = 290kBB. An equivalent input noise temperature Te can be used to characterize the system noise, and thus the noise ﬁgure can be calculated by  F = No Ni  = kB  T + Te  B  kBTB  = 1 + Te 290  .  Or an equivalent noise temperature can be calculated by  Te = 290 F − 1    K .  For a typical LNA, F is 3.0 dB, corresponding to Te = 290 K. For passive, lossy devices such as transmission lines, attenuators, or mixers, their gains T,  Gl are less than unity. The lossy device has an equivalent noise temperature and the noise ﬁgure is given by [36]  − 1  1 Gl   cid:18    cid:17    11.11  When the transmission line is at room temperature 290 K, F = 1 Gl and thus a 3-dB attenuator has a noise ﬁgure of 3 dB.  .  F = 1 +  − 1  1 Gl  T 290  The total noise ﬁgure of a cascaded system is calculated by using the Friis noise formula   cid:2    cid:3   [36, 37]  Ftot = F1 + F2 − 1  G1  + F3 − 1  G1G2  + ··· +  Fn − 1  G1G2 ··· Gn−1  ,   11.12    11.9    11.10       379   cid:2   11.2 RF system analysis  where Fi and Gi are the noise ﬁgure and gain of the ith element in the cascaded chain. Alternatively, the overall equivalent noise Te can be obtained by [36] G1G2 ··· Gn−1  Te = Te1 + Te2 G1  + Te3 G1G2  + ··· +   11.13   Ten  ,  where Tei is the equivalent noise temperature of the ith element. Thus the ﬁrst few devices have a more signiﬁcant effect on the noise power. The ﬁrst element in the chain should therefore have a low noise factor and a high gain. For example, if the bandpass ﬁlter pre- ceding an LNA has a loss of 2 dB, it corresponds to a noise ﬁgure F1 = 2 dB. If the LNA has a noise ﬁgure F2 = 3 dB, the overall noise ﬁgure becomes F1F2 = 5 dB. Thus, the in-band loss for the bandpass ﬁlter is most critical for the system performance.  11.2.3 Link budget analysis  The carrier-to-noise ratio  CNR  deﬁnes the ratio of the signal power to the noise power over a channel. CNR can be regarded as a ﬁgure of merit of a communication system. For a wireless communication system, CNR can be calculated by using the link equation  where PERP is the effective radiated power from the transmit antenna, LP is the propagation loss, GR is the gain of the receive antenna, and N is the noise power. PERP is calculated by  CNR = PERPLPGR  ,  N  PERP = PtLCTGT   11.14    11.15   where Pt is the output power at the transmitter power ampliﬁer, LCT is the loss of the connecting cable between the power ampliﬁer and the transmit antenna, and GT is the gain of the transmit antenna. N is attributed to thermal noise and is given by  11.4 . The carrier- to-interference ratio  CIR  is deﬁned as the ratio of the signal power to the noise power plus interfering power.  For an RF subsystem, each analog RF functional block along the link leads to a loss or a gain to the overall power. For wireless system design, it is important to give a system link budget from the point after DAC in the transmit subsystem to the point before ADC in the receive subsystem. This is illustrated by Fig. 11.2. In the ﬁgure, the gain or loss at each functional block is given, and the noise ﬁgure of each block at the receiver is also given.  GUC Up  convert  GPA  PA  DAC  P1   cid:2 Figure 11.2  GAT  LCT  Pt  LP  GAR  LCR  Pr  FLNA GLNA LNA  RF system link budget analysis.  FDC GDC Down convert  ADC  P2      380   cid:2   RF and microwave subsystems  In decibels, we can get the following three equations for Pt = P1 + GUC + GPA,  Pr = Pt − LCT + GAT − LP + GAR − LCR,  P2 = Pr + GLNA + GDC.   11.16    11.17    11.18   The cumulative noise effect must also be considered in the receive subsystem, and this can be based on the noise ﬁgure. In cellular RF design, one usually performs noise ﬁgure analysis for the receive subsystem only. This is because the thermal noise from the transmit subsystem is signiﬁcantly attenuated by the propagation, and the ambient thermal noise surrounding the receive antenna is much higher than the attenuated transmit noise. Many standards such as GSM and 802.11g require an overall noise ﬁgure of around 10 dB, and WideMedia requires a noise ﬁgure 6.6 dB. For 3G standards, a noise ﬁgure of 5 dB is recommended.  11.3 Transmission lines  11.3.1 Fundamental theory  A transmission line is a distributed parameter network, as shown in Fig. 11.3. It is usually represented by a two-wire line.  The voltage V z  and current I z  at any point z on the line are related by the transmission line equations, which under sinusoidal steady state conditions, are given in the phasor form  = − R + jωL I z ,  = − G + jωC V z ,  dV z   dz  dI z  dz   11.19    11.20   where R  ohms m  and L  henrys m  are, respectively, the series resistance and induc- tance per unit length for both conductors, and G  siemens m  and C  farads m  are shunt conductance and capacitance per unit length, respectively.  + V   z −     zZ in     z  I  Z0, β  l  Γ  + V L −  0  IL  ZL  z   cid:2 Figure 11.3  Transmission line terminated with load.      381   cid:2   11.3 Transmission lines  Traveling wave solutions to the wave equations  11.19  and  11.20  can be found as  V z  = V −γ z + V − + o eγ z, o e −γ z + I I z  = I − + o eγ z, o e  γ = α + jβ = cid:25   where   R + jωL  G + jωC    11.23  is the complex propagation constant, with α being the attenuation coefﬁcient and β = + + 2π λ the wave number, V o are the voltage and current amplitudes of the incident o and I wave along +z direction, V − o are the voltage amplitude and current amplitudes of the reﬂected wave along −z direction, and Z0 is the characteristic impedance of the transmission line and is deﬁned by  − o and I  It can be shown that     Z0 =  R + jωL G + jωC  .  + Z0 = V o + I o  = −V − o − o  I  .   11.21    11.22    11.24    11.25   It should be pointed that the distributed parameters R, L and G are not constant, but are frequency-dependent due to the skin effect – the current mainly ﬂows near the surface of the conductor. Usually, the transmission line is assumed to be lossless or with low loss, that is, R = G = 0. Accordingly, we have Z0 = LC, and the phase velocity vp = ω  C , γ = jβ = jω  = 1√   cid:21   √  L  .  β  LC  Reﬂection coefﬁcient  Consider a lossless transmission line terminated by a load ZL, as shown in Fig. 11.3. Since ZL is at z = 0, we have V 0  = ZLI 0 . The voltage reﬂection coefﬁcient  cid:9  is deﬁned as the ratio of the amplitude of the reﬂected voltage wave to that of the incident voltage wave, and it can be derived as  −  cid:9  = V o + V o  = ZL − Z0 ZL + Z0  .   11.26  In order to obtain  cid:9  = 0, ZL = Z0. In this case, the load is said to be matched to the line, and there is no reﬂection of the incident wave. For a short circuit  ZL = 0 ,  cid:9  = −1, while for an open circuit  ZL = ∞ ,  cid:9  = 1.  cid:9  is the reﬂection coefﬁcient at the load  z = 0 , i.e.,  cid:9  =  cid:9  0 . It can be generalized to any point z:  −  cid:9  z  = V o ejβz + o e−jβz V  =  cid:9  0 e2jβz.   11.27       382   cid:2   RF and microwave subsystems  Return loss   cid:4  cid:4 2   cid:17    cid:4  cid:4 V  + o Z0   cid:18   1 −  cid:9 2  .  Pav = 1 2  The average power ﬂow is constant at any point on the line and is given by   11.28   This result is obtained by assuming that the generator is matched so that there is no rere- ﬂection of the reﬂected wave from the generator side. This is also the power delivered to the load.  The return loss  RL  is deﬁned as the power loss for reﬂected power due to the load  RL = −20 log10  cid:9    11.29  For a matched load   cid:9  = 0 , the return loss is ∞. When  cid:9  = 1, all incident power is reﬂected, and thus the return loss is 0 dB.   dB .  wave on the line; the voltage amplitude is given by  When the load is matched to the line, the amplitude of the voltage at any point z on the line  is a constant V z  =  cid:4  cid:4 V  + o  Voltage standing wave ratio   cid:4  cid:4 . In case of an unmatched load, reﬂection leads to a standing V z  = cid:4  cid:4 V   cid:4  cid:4  cid:4 1 +  cid:9 ej θ+2βz    cid:4  cid:4  cid:4  ,   cid:4  cid:4  ·  + o   11.30  where θ is the phase of  cid:9 ,  cid:9  =  cid:9 ejθ . The amplitude V z  takes its maximum and mini- mum values, V z max and V z min, at ej θ+2βz  = 1 and −1, respectively. The mismatch of the line can be measured by the standing wave ratio, more frequently known as voltage standing wave ratio  VSWR , deﬁned by  VSWR = V z max V z min  = 1 +  cid:9  1 −  cid:9  .   11.31  Thus, VSWR≥ 1. For matched load, VSWR= 1. For a short or open circuit,  cid:9  = −1 or 1, thus VSWR=∞.  Input impedance  The input impedance seen in the direction of the load is derived by −2jβl  Zin = V −l  I −l   = 1 +  cid:9  −l  1 −  cid:9  −l   Z0 = 1 +  cid:9 e  1 −  cid:9 e−2jβl Z0.  Inserting  11.26  into  11.32 , we have Zin = Z0  ZL + jZ0 tan βl Z0 + jZL tan βl  .   11.32    11.33       383   cid:2   11.3 Transmission lines  From  11.33 , the following points can be reached:   For a short circuit  ZL = 0 ,  Zin = jZ0 tan βl   11.34    11.35    11.36    11.37   which is purely imaginary, periodic in z with a period of λ 2, and can take any value between −j∞ and j∞.   For an open circuit  ZL = ∞ ,  Zin = −jZ0 cot βl  which is also purely imaginary, periodic in z with a period of λ 2.   For l = λ 2 or l = nλ 2, n = 1, 2, . . .  Zin = ZL. This indicates that a λ 2 line does not change the load impedance.   For l = λ 4 or l = λ 4 + nλ 2, n = 0, 1, 2, . . . Zin = Z2 0 ZL  .  This result is very important for impedance transformation and matching. The quarter- wavelength line is known as a quarter-wave transformer.  Insertion loss  Consider the case of a lossless transmission line of characteristic impedance Z0 feeding a line of characteristic impedance Z1. If the latter is terminated in a load of impedance Z1 or is of inﬁnite length, there is no reﬂection from its load, and Zin seen from the feedline is Z1. The reﬂection coefﬁcient is thus given by   11.38  At the intersection z = 0, the incident wave is transmitted to the load line, and also reﬂected −jβz, to the feedline. The wave on the load line is outgoing with an amplitude of TV z > 0, where T is the transmission coefﬁcient. At z = 0,  + o e  .   cid:9  = Z1 − Z0 Z1 + Z0  T = 1 +  cid:9 .  Insertion loss  IL  is deﬁned by   11.39    11.40   IL = −20 log10 T   dB .  Smith chart  The Smith chart is the most widely used graphical aid for solving transmission line prob- lems. The Smith chart is a polar plot of the voltage reﬂection coefﬁcient  cid:9  [36]. Any passively realizable reﬂection coefﬁcient is a unique point on the Smith chart. The Smith chart can be used to convert between the reﬂection coefﬁcients and normalized impedances  or admittances , using the impedance  or admittance  circles.      384   cid:2   RF and microwave subsystems  Twin−line  Rectangular waveguide  Stripline   cid:2 Figure 11.4  Coaxial cable  Circular waveguide  Microstrip  Structures of some transmission lines and waveguides.  11.3.2 Types of transmission line  Practical transmission lines and waveguides are twin-line, coaxial cable, stripline, microstrip, rectangular waveguide, and circular waveguide, and they are shown in Fig. 11.4. They typically operate in TEM mode, that is, Ez = Hz = 0. For transmis- sion lines in TEM mode, there is a one-to-one correspondence between electric ﬁeld and voltage, and between magnetic ﬁeld and current.  Coaxial cables have very high bandwidth and power-handling capacity, while planar transmission lines are compact and easily integrated with active devices. The characteristic impedances of these transmission lines can be found in [36]. For example, the characteristic impedance of a coaxial cable is given by   cid:2    cid:3   Z0 = η 2π  ln  b a   11.41   and η = √  where a is the radius of the inner conductor, b is the inner radius of the outer conductor, μ  cid:21  is the intrinsic impedance of the medium. μ and  cid:21  are, respectively, the  permittivity and permeability of the material ﬁlling the space between the conductors.  The microstrip line is the most important type of transmission line. The grounded metalized surface covers only one side of the dielectric substrate, and this causes the electromagnetic wave along the microstrip line to be not a pure TEM; but the TEM approx- imation is sufﬁciently accurate as long as the height of the dielectric substrate is very small relative to the wavelength. The analytical result for the effective dielectric constant  cid:21 e r and the characteristic impedance Z0 of a lossless microstrip line is given as [17, 19, 36]: For W h ≤ 1:  9 cid:2   =  cid:21 r + 1  +  cid:21 r − 1  2  2   cid:21 e r  1 + 12  :   cid:3 2  ,  1 − W h   cid:2   cid:3 −0.5 + 0.04  cid:3   8h W  + 0.25  W h  .  h W   cid:2   Z0 = 60√  ln   cid:21 e r   11.42    11.43       385   cid:2   For W h ≥ 1:  11.4 Microwave network analysis   cid:2    cid:3 −0.5   cid:21 e r  =  cid:21 r + 1  cid:5   2  +  cid:21 r − 1  2  h W  1 + 12  cid:2   + 1.393 + 0.677 ln  ,   cid:3  cid:6 −1  + 1.444  W h  Z0 = 120π√   cid:21 e r  W h   11.44   .   11.45   ⎧⎨⎩ 8eA  cid:22   e2A−2 , 2 π  =  W h  where  In the above, W is the width of the microstrip line. For a very thin conductor, this solution provides an accuracy better than one percent [17].  Given Z0 and  cid:21 r, an expression for determining W  h is given as [17, 19, 36]   cid:17    cid:18  cid:23   ln B − 1  + 0.39 − 0.61  ,   cid:21 r  if W h if W h  < 2 > 2  ,  B − 1 − ln 2B − 1  +  cid:21 r−1  cid:31   cid:2   2 cid:21 r   cid:21 r + 1 2  +  cid:21 r − 1  cid:21 r + 1  A = Z0 60   cid:3   0.23 + 0.11  cid:21 r  , B = 377π √  cid:21 r  2Z0  .   11.46    11.47   The strip thickness is usually very small, and its effect is usually neglected. The effect of strip thickness on the characteristic impedance Z0 and the effective dielectric constant  cid:21 e r is given in [3, 19].  11.4 Microwave network analysis  A waveguide is characterized by electric ﬁeld and magnetic ﬁeld, and their relation by wave impedance. The measurement of voltage and current at microwave frequencies is difﬁcult. Equivalent voltage, current, and impedance for waveguides can be deﬁned. Once such voltages and currents are deﬁned at various points in a microwave network, the microwave system can be analyzed in a way similar to the conventional circuit theory.  Consider an N-port microwave network, illustrated in Fig. 11.5, where each port corre- sponds to a transmission line or a waveguide. At a phase reference plane of voltage and current phasors, called terminal plane, of port n, the equivalent voltage Vn and current In are given by their components for incident and reﬂected waves:  − I − n , which is the result at z = 0 from the transmission line theory.  Vn = V  + V − n ,  In = I  + n  + n  The impedance matrix Z = cid:19    cid:20   Impedance and admittance matrices  Zij  relates the voltages and currents by  V = ZI,   11.48    11.49       386   cid:2   RF and microwave subsystems  + +, V2 2I  V −, 2  − I  − 2  − V , N  − I  − N  + I N, +  VN  V  − 1  −, − I 1 + I,  + 1  V1   cid:2 Figure 11.5  An N-port microwave network.  where V =  V1, V2, . . . , VN  T and I =  I1, I2, . . . , IN  T. The entries Zij are deﬁned by  That is, Zij can be obtained by driving port j with current Ij, open-circuiting all other ports, and measuring the open-circuit voltage at port i.  Similarly, the admittance matrix Y = cid:19   relates the voltages and currents by  Obviously, Z and Y are inverse of each other. The entries Yij are given by   11.50    11.51    11.52   .  Ik=0,k cid:18 =j   cid:4  cid:4  cid:4  cid:4  Zij = Vi Ij  cid:20  Yij I = YV.  cid:4  cid:4  cid:4  cid:4   Yij = Ii Vj  .  Vk=0,k cid:18 =j  That is, Yij is obtained by driving port j with voltage Vj, short-circuiting all other ports, and measuring the short-circuit current at port i. For a reciprocal network, which contains no active devices, ferrites or plasmas, Zij = Zji and Yij = Yji. For a lossless network, all Zij’s and Yij’s are purely imaginary. A two- port reciprocal network can be represented by a T  for Zij  or π  for Yij  equivalent circuit.  The scattering matrix S = cid:19    cid:20   waves for an N-port microwave network  Scattering matrix  Sij  relates the incident voltage waves to the reﬂected voltage  − =  cid:7   where V deﬁned by  − 1 , V V  − − 2 , . . . , V N  + 1 , V V  + + 2 , . . . , V N   cid:8 T and V  V  +  − = SV  + =  cid:7   cid:4  cid:4  cid:4  cid:4  cid:4   − Sij = V i + V j  + V k  =0,k cid:18 =j   cid:8 T. The component Sij is   11.53    11.54       387   cid:2   11.4 Microwave network analysis  + j and no inci- That is, Sij is calculated by driving port j with an incident wave of voltage V − i at port i. This requires dent wave on all other ports, and measuring the reﬂected wave V all other ports be terminated in matched loads to prevent reﬂection. As a result, Sii is the reﬂection coefﬁcient of port i when all other ports are impedance matched, Sij is a trans- mission coefﬁcient from port j to port i when all other ports are impedance matched. Note  cid:9 i = Sii only when all other ports are matched. S can be derived from Z. For reciprocal networks, S is symmetric, Sij = Sji. For lossless   cid:20 −1, where the superscript ∗ indicates conjuga-  networks, S is a unitary matrix, S∗ = cid:19   ST  tion. In many practical cases, the characteristic impedances of all the ports are identical, often 50 ohms.  If port n has a real characteristic impedance Z0n, a generalized scattering matrix is  deﬁned by   cid:12   where>V  − =  Accordingly  >V − = S>V , >V  + =  +  ,   cid:12    cid:13 T   cid:4  cid:4  cid:4  cid:4  cid:4   √   cid:25   Z0i Z0j  − Sij = V i + V j        .  + V k  =0,k cid:18 =j  − 1√ V Z01  ,  − 2√ V Z02  ,··· ,  − N√ V Z0N  + 1√ V Z01  ,  + 2√ V Z02  ,··· ,  + N√ V Z0N  .  11.56   A signal ﬂow graph is very useful for analysis of microwave networks in terms of trans- mitted and reﬂected waves [36]. An unknown impedance at microwave frequencies is mainly measured by using a vector network analyzer. The S-parameters of a microwave network can also be measured using a vector network analyzer.  In practical applications, two-port or cascaded two-port networks are usually used. A 2- by-2 transmission matrix, or ABCD matrix, can be deﬁned for each two-port network  Transmission matrix   cid:5    cid:6   =   cid:5   V1 I1   cid:6   cid:5    cid:6   ,  A B C D  V2 I2  where V1 and I1 are the input voltage and current to port 1, and V2 and I2 are the output voltage and current from port 2. All the currents are speciﬁed to be along one direction.  For multiple two-ports in cascade, one can get the overall transmission matrix by multiplying the individual transmission matrices. This method is useful since a library of transmission matrices can be built up for many elementary two-port networks. The   11.55    cid:13 T   11.57    11.58       388   cid:2   RF and microwave subsystems  ABCD-parameters can be derived from the Y- or Z-parameters of a network. For a reciprocal network, AD − BC = 1.  11.5 Impedance matching  Impedance matching is important, for example, for reducing reﬂection and improving the sensitivity of a receiver. A matching network for connecting a load to a transmis- sion line can always be found, if the load impedance ZL = RL + jXL has nonzero real part, i.e., RL  cid:18 = 0. Although theoretical results can be obtained by using computer anal- ysis, the Smith chart provides a fast, sufﬁciently accurate solution and is widely used in practice. There are many lossless matching networks. The Bode-Fano criterion gives a theoretical limit on the minimum reﬂection coefﬁcient magnitude for any matching network [36].  11.5.1 Stub tuners  Impedance matching can be implemented by connecting a single open-circuited or shorted- circuited length of transmission line, known as a stub, in parallel  shunt  or in series with the feedline at a certain distance from the load. A proper length of open or shorted trans- mission line can result in any desired value of reactance. Given a reactance, its open-circuit and shorted-circuit implementations have a difference of λ 4 in stub length.  The shunt stub, as shown in Fig. 11.6, is especially suitable for microstrip or stripline realization. For microstrip or stripline implementation, open-circuited stubs are easier to manufacture since via holes on the circuit board are avoided. For coaxial lines or waveguides, short-circuited stubs can effectively prevent radiation.  The single-stub tuners are ﬁxed. Double-stub tuners provide better adjustability. Double- stub tuners are often fabricated in coaxial line, and the adjustable stubs are connected in parallel to the feed coaxial line. However, the double-stub tuner cannot match all load impedances.  d  Z0  ZL  Z0  Open- or short- circuited  Z0  l  Z   cid:2 Figure 11.6  The single, shunt stub tuner.      389   cid:2   11.5 Impedance matching  λ 4  Z1  Z0  ZL  Γ  Zin   cid:2 Figure 11.7  Quarter-wave transformer for impedance matching.  11.5.2 Quarter-wave transformer  Assume that we use a feedline of characteristic impedance Z0 to feed a load resistance ZL = RL. A quarter-wave transformer, characterized by  11.37 , can be used for impedance matching. This is shown in Fig. 11.7. For impedance matching,  This yields  Z0 = Zin = Z2 1 ZL  .  Z1 = cid:25   Z0ZL.   11.59    11.60   Here ZL is assumed to be real.  The quarter-wave transformer is used to match a real load impedance to a transmission line. A complex load impedance can be ﬁrst transformed to a real impedance by using a transmission line or a reactive stub of suitable length. The quarter-wave transformer is then applied.  The quarter-wave transformer matches the load at the design frequency f0. At f0, the matching section has a length of λ0 4. But at other frequencies f , the length is not a quarter wavelength, and hence mismatch occurs. Given a maximum tolerable reﬂection coefﬁcient  cid:9 m and assuming TEM waves, the fractional bandwidth is given by [36]  9  :  .   cid:9 m cid:25  1 −  cid:9 2  m  √ 2 Z0Z1 ZL − Z0  = 2 − 4  π  −1  cos   cid:18 f f0   11.61   It is seen that the bandwidth increases when ZL is close to Z0. In microwave design,  cid:9 m can be determined by the VSWR speciﬁcation.  When a bandwidth requirement cannot be satisﬁed by using a single section quarter-  wave transformer, a multi-section transformer can be used.  11.5.3 Multisection matching transformers  Multisection matching transformers can be either a binomial transformer or a Cheby- shev transformer. Each section is a quarter-wave transformer. The binomial transformer is maximally ﬂat near the design frequency. As opposed to the binomial transformer, the Chebyshev transformer achieves a maximal bandwidth, but with a Chebyshev equal-ripple passband. These transformers are actually passband ﬁlters.      390   cid:2   RF and microwave subsystems  For an N-section binomial transformer, assuming the reﬂection coefﬁcient  cid:9 n between  any two adjacent sections is small, the design equation is given by [36]  −NCN n ln = N! The fractional bandwidth is given by [36]  where the binomial coefﬁcients CN n  ZL Z0  N−n !n! .  Zn+1 Zn  ≈ 2  ln  ,  9  n = 0, 1, . . . , N,  cid:3 1 N  cid:2   :  ,   11.63   where  = 2 − 4  π   cid:18 f f0  cos  −1  1 2   cid:9 mA −N ZL − Z0 ZL + Z0  .  A = 2   11.62    11.64   A transformer with more sections achieves wider bandwidth. A thorough exposition on the design of binomial as well as Chebyshev multisection matching transformers is given in [31].  11.6 Microwave resonators  A resonator is any structure that is able to contain at least one oscillating electromag- netic ﬁeld. Resonators can be classiﬁed as lumped-element  or quasilumped-element  and distributed-element resonators. Microwave resonators are useful for many applications including the realization of ﬁlters, oscillators, frequency meters, and tuned ampliﬁers. They can be implemented using transmission lines or waveguides.  11.6.1 RLC resonant circuits  Near resonance, resonators can be modeled by a series or parallel RLC equivalent circuit, as shown in Fig. 11.8. The input impedance is   cid:2   Zin = R + jωL − j Zin = + 1 jωL  1 R  1 ωC + jωC   cid:3 −1   series RLC circuit ,   11.65    parallel RLC circuit .   11.66   The complex power delivered to the resonator is given by  Pin = 1 2  ∗ = 1 2  ZinI2 = Pl + 2jω  Wm − We  ,  VI   11.67  IL2 L is the average magnetic where Pl is power dissipated by the resistor R, Wm = 1 VC2 C is the average electric energy stored energy stored in the inductor L, and We = 1 in the capacitor C. Here, IL is the current ﬂowing through the inductor and VC is the voltage across the capacitor.  4  4      391   cid:2   11.6 Microwave resonators  V  +  −  Z in  R   a   L  I  C  Z  in  C  L  R  V  I  +  −   b    cid:2 Figure 11.8  RLC resonator circuits.  a  The series RLC circuit.  b  The parallel RLC circuit.   11.68    11.69    11.70    11.71    11.72    11.73   At resonance, Wm = We, we have the resonance frequency ω0  and a purely resistive input impedance  ω0 = 1√ LC  Zin = R.  The quality factor, Q, of a resonant circuit is deﬁned as = ω  average energy stored  Q = ω  power dissipated  Wm + We  .  Pl  At resonance, Q is given by  Q = ω0L R Q = R ω0L  = 1 ω0RC = ω0RC   series RLC circuit ,   parallel RLC circuit .  BW = 2 cid:18 ω ω0  = 1 Q  .  For both the circuits, the half-power fractional bandwidth of the resonator is given by  When a resonant circuit is coupled to other circuitry, the loaded Q, QL, is different from the unloaded Q. Since the resonant frequency is decided by L and C, the resonant circuit should be connected to an external resistor RL. For a series resonator, RL should be added in series with R, and the resulting external Q, Qe, can be deﬁned by Qe = 1 ω0RLC . For parallel resonators, RL should be added in parallel with R, and Qe can be deﬁned by Qe = ω0RLC. In both cases, the loaded Q can be expressed by = 1 Qe  + 1 Q   11.74   1 QL  .  11.6.2 Transmission line resonators  The RLC resonator can be implemented in microstrip line by using microstrip capacitor and inductor components. Such implementations may resonate at some higher frequencies      392   cid:2   RF and microwave subsystems  at which their sizes are no longer very small compared to a wavelength. In this sense, they are not lumped or quasilumped implementations any more. Here we are more interested in distributed-element implementations.  In order to implement a resonator and evaluate its Q, we consider lossy transmission lines. For a low-loss transmission line, the incident and reﬂected waves should have a form −γ z and eγ z, where γ = α + jβ. Accordingly, Zin in  11.33  can be recalculated by of e replacing jβz with  α+jβ z. By comparing Zin of the transmission line with that of a series or parallel RLC resonator circuit and making some approximation, we can obtain a number of transmission line resonators [36]:   Short-circuited λ 2 or nλ 2 line resonator  l = nλ 2, n = 1, 2, . . . . The equivalent series RLC parameters corresponding to Zin are given by  R = Z0αl, At resonance, Zin = R, and Q = ω0L 2α for the ﬁrst resonance at l = λ 2 and decreases as l increases.   Short-circuited λ 4 line resonator  l = λ 4 . It is a parallel-style RLC resonator with  L = Z0π 2ω0 2αl . Q = β = π  , C = 1 ω2 0L   11.75   R  .  R = Z0 αl  , C = π 4ω0Z0 At resonance, Zin = R, and Q = ω0RC = π   Open-circuited λ 2 or nλ 2 line resonator,  l = nλ 2, n = 1, 2, . . . . It is also a parallel resonant circuit, with  L = 1 ω2 0C  , = β 2α .   11.76   4αl  .  R = Z0 αl  L = 1 , C = π ω2 2ω0Z0 0C 2α for l = λ 2. This type of 2αl . Again Q = β At resonance, Zin = R, and Q = ω0RC = π resonator is more suitable for microstrip implementation.   11.77   ,  .  In order to achieve maximum power transfer between a resonator and a feedline, the resonator must be matched at the resonant frequency. In this case, Zin = R = Z0. Thus the unloaded Q equals the external Q, Q = Qe, and the resonator is said to be critically coupled to the feed.  A λ 2 open-circuited microstrip resonator can be fed by gap-coupling to a microstrip feedline. The gap in the microstrip line can be modeled as a series capacitor C. This is shown in Fig. 11.9. In this case, resonance occurs when Z = 0. Coupling to the feedline lowers the resonant frequency. When the normalized susceptance of C, bc = Z0ωC  cid:5  1,   cid:2 Figure 11.9  A microstrip resonator coupled to a microstrip feedline and its equivalent circuit.  C  Z0  λ 2  Z0  Z      393   cid:2   11.7 Power dividers and directional couplers  the resonant frequency is closed to the unloaded resonator. At bc = occurs.  π  2Q , critical coupling   cid:21   11.6.3 Waveguide cavities  Resonators can also be implemented using a closed section of waveguide. Both the ends are closed in order to prevent radiation loss. This corresponds to the short-circuited case of transmission line. This closed section becomes a cavity. Electric and magnetic energies are stored within the cavity, while dissipation occurs in the metallic wall and the dielectric. Coupling with other components is done via a small aperture or probe. For a rectangular or circular waveguide cavity, resonance occurs when the cavity has a length of nλg 2, n = 1, 2, . . ., where λg is the guided wavelength. For metallic cavities, the Q is decided by the Q due to conductor loss, Qc, and the Q due  to dielectric loss, Qd,  1 Q  = 1 Qc  + 1 Qd  .   11.78   Circular cavities are often used to make microwave frequency meters. The top wall is movable for tuning the resonant frequency. High Q is easier to obtain in the TE011 mode, and this corresponds to a higher frequency resolution.  Dielectric resonators are made of low-loss high dielectric material; they are similar to metallic cavities, but have some ﬁeld leakage from their sides and ends. Dielectric res- onators generally have a smaller size and a lower cost. They can be easily integrated into microwave integrated circuits or coupled to a microstrip line.  Due to the conductor loss, Q decreases as 1   f for a cavity or transmission line res- onator [36]. At very high frequency, Q will be too small for use. The Fabry-Perot resonator reduces the side walls of a cavity resonator to reduce the conductor loss and the possible number of resonant modes, and becomes an open resonator with two parallel metal plates. Spherical or parabolic reﬂecting mirrors can be used to conﬁne the energy to a region. Thus, quasi-optical resonators are especially useful for millimeter or submillimeter waves.  √  11.7 Power dividers and directional couplers  Power dividers and directional couplers are used for power division or combining. Power dividers take the form of three-port networks  T-junctions , while directional couplers take the form of four-port networks.  11.7.1 Three-port networks  Analysis based on the scattering matrix shows that a three-port network cannot be lossless, reciprocal, and matched at all ports, at the same time. If nonreciprocity is assumed, input      394   cid:2   RF and microwave subsystems   cid:2 Figure 11.10  1  2  3  Symbol of a circulator.  matching at all ports and lossless property can be satisﬁed. Such a device is called a circu- lator, and can be made by using anisotropic materials such as ferrite. If only two ports are matched, a lossless and reciprocal three-port network can be realized. On the other hand, if it is lossy, it can be reciprocal and matched at all ports.  A circulator can have two possible sets of S parameters  Circulators  ⎡⎣ 0 0 1  1 0 0 0 1 0  ⎤⎦ ,  S1 =  ⎡⎣ 0 1 0  0 0 1 1 0 0  ⎤⎦ .  S2 =   11.79    cid:5    cid:6   For S1, power ﬂow occurs from ports 1 to 2, 2 to 3, and 3 to 1. The circulator is represented by the symbol in Fig. 11.10. For S2, the opposite circularity holds; this can be obtained by changing the polarity of the ferrite bias ﬁeld.  A circulator can be used as an isolator when port 3 is terminated with a matched load. The S-parameter matrix of an isolator is S = port 2 are matched, but power transmission occurs only from port 1 to port 2. Since S is not unitary, the isolator is lossy.  ; this indicates that both port 1 and  0 0 1 0  Isolators are used to isolate a high-power source from a load to prevent damage or inter- ference. There are a number of ferrite isolators such as the resonance isolator and the ﬁeld displacement isolator. Circulators can be used as diplexers or used in reﬂection-type phase shifters attenuators.  Power dividers  The T-junction power divider is used for power division or combining. It takes the form of waveguide or microstrip. It can be designed as a lossless or resistive power divider. The output power ratio can be speciﬁed. Both the lossless and resistive power dividers cannot achieve isolation between output ports. The Wilkinson power divider, as shown in Fig. 11.11, is a lossy three-port network with all ports matched and isolation between output ports, that is, S32 = S23 = 0. The Wilkinson power divider can divide the input power according to any ratio. It uses a resistor connecting the two output ports. When the two output ports are matched, no power is      395   cid:2   11.7 Power dividers and directional couplers  Z0  λ 4  λ 4  Z02  Z2 0  Z0  Input  1  2  Through  Isolated  4  3  Coupled  Symbol of directional coupler.  The Wilkinson power divider in microstrip form. The power is equally split.   cid:2 Figure 11.11   cid:2 Figure 11.12  dissipated in the resistor. Only reﬂected power from port 2 or 3 is dissipated in the resistor. It is suitable for microstrip or stripline implementation. The Wilkinson divider has also been generalized to an N-way divider or combiner.  11.7.2 Four-port networks  ⎡⎢⎢⎣ 0  ⎤⎥⎥⎦ ,  ⎡⎢⎢⎣ 0  A directional coupler is any reciprocal, lossless, matched four-port network. Two particular choices of directional couplers, namely the symmetrical and antisymmetrical couplers, are commonly used in practice. Their scattering matrices are, respectively, derived as  β  α β  α 0 0  α jβ 0  S =  S =  jβ 0 0 α  0 jβ α 0  0 0 −β 0 0 −β α  α 0 0 jβ In both cases, α2 + β2 = 1. A directional coupler uses port 1 as input port, there are outputs from the other three ports, as shown in Fig. 11.12. Power outputs from ports 2, 3, 4 are respectively known as through power P2, coupled power P3, and isolated power P4. A directional coupler is characterized by three quantities, namely coupling C, directivity D, and isolation I   11.80   α 0  ⎤⎥⎥⎦ .  = −20 log10 β  dB , C = 10 log10 P1 P3 = 20 log10 D = 10 log10 P3 P4 = −20 log10 I = 10 log10 P1 P4  βS14 S14   dB ,   dB .   11.81    11.82    11.83   It is seen that I = D + C dB. For an ideal coupler  S14 = 0 , both D and I are inﬁnite.      396   cid:2   RF and microwave subsystems   cid:2 Figure 11.13  A branch line coupler.   cid:2 Figure 11.14  A coupled line coupler.  1  3  1  4  1  4  2  2  3  2  3  4   cid:2 Figure 11.15  A microstrip ring coupler.  √ Hybrid couplers are directional couplers with C = 3 dB, that is, α = β = 1  2. The outputs of the through and coupled arms have equal power. The phase difference between ◦  quadrature hybrid , which is an example of a symmetrical coupler , the output ports is 90 ◦  magic-T hybrid or rate-race hybrid , which is an example of an antisymmetrical or 180 coupler.  The quadrature hybrid can be designed as a branch-line hybrid  shown in Fig. 11.13 , coupled line coupler  shown in Fig. 11.14 , or Lange coupler. The bandwidth of coupling response C of the coupled line coupler can be improved by using multiple λ 4 sections, as in the case of multisection matching transformer. Coupling in a coupled line coupler is generally too loose to achieve C of 3 dB or 6 dB. The Lange coupler uses an interdigital hybrid can be fabricated as a ring hybrid geometry to increase the coupling. The 180 in microstrip or stripline form, shown in Fig. 11.15, tapered coupled line hybrid, or as a waveguide hybrid junction called magic-T.  ◦  The Bethe hole coupler is a single-hole waveguide directional coupler. In order to improve the bandwidth of the directivity response D, multiple hole waveguide couplers can be designed. Like the multisection matching transformer, the multihole waveguide coupler can be designed with a binomial response or Chebyshev response for its directivity. The spacing between the holes is λg 4.      397   cid:2   11.8 RF microwave ﬁlters  ω      H         1+  1−  δ 1 δ 1  δ 2  Passband  Stopband  Transition band   cid:2 Figure 11.16  Typical magnitude characteristics of physically realizable lowpass ﬁlters.  ω  p  ω  s  ω  11.8 RF microwave ﬁlters  RF microwave ﬁlters typically have lowpass, highpass, bandpass, or band-reject fre- quency response. Bandpass ﬁlters are particularly important in wireless communica- tion systems. For ﬁlter design, the insertion loss and passband characteristics are important.  The insertion loss method ﬂexibly controls the passband and stopband amplitude and phase responses in a systematic way, and hence is widely used in analog ﬁlter design. The method generates lumped-element circuits. Distributed implementation, especially microstrip implemention, which is of critical importance in modern wireless design, can then be obtained from the lumped-element circuits.  Filters can also be implemented using coupled resonators. In addition to microstrip ﬁlters fabricated by using conventional materials, more and more recent researches use advanced materials such as high-temperature superconductors  HTS , ferroelectric materials, MEMS technology, MMIC technology, or LTCC technology [19].  Ideal ﬁlters are noncausal and thus physically unrealizable. In practical realizations, we have to realize causal ﬁlters that approximate the ideal ﬁlters as closely as possible. For a practical ﬁlter, a small amount of ripple in the passband and stopband is tolerable. A typical ﬁlter design speciﬁcation is illustrated in Fig. 11.16, where δ1, δ2 denote the ampli- tudes of passband and stopband ripples, and ωp, ωs are the passband and stopband edge frequencies.  11.8.1 Insertion loss method  In the insertion loss method, a ﬁlter response is characterized by its insertion loss, or power loss ratio, PLR, which is the ratio of the incident power and the power delivered to load      398   cid:2   RF and microwave subsystems   11.84  Note that PLR = 1 S122 if both load and source are matched. Since  cid:9  ω 2 is an even function of ω, it can be expressed as a polynomial of ω2. Thus, we have  PLR =  1  1 −  cid:9  ω 2 .  cid:8   cid:8  ,   cid:7   cid:7   ω2  ω2  PLR = 1 + M L   11.85    cid:7    cid:8    cid:7    cid:8   ω2  where M methods for designing lowpass ﬁlters.  and L  ω2  are polynomials of ω2. In the following, we introduce several  Maximally ﬂat ﬁlters  The binomial or Butterworth ﬁlter has the maximally ﬂat passband response. For an Nth- order lowpass ﬁlter, it is speciﬁed as  PLR =  1  = 1 +  cid:21 2  S21  jω 2   11.86  The passband is from ω = 0 to ω = ωc, and at the edge of the passband ωc, PLR = 1+  cid:21 2. Its ﬁrst 2N − 1 derivatives are zero at ω = 0. For ω  cid:7  ωc, PLR increases at a rate of 20N dB decade. It is an all-pole ﬁlter.  .  ω ωc   cid:2    cid:3 2N  Example 11.1: For  cid:21  = 0.4, the transfer function S21  jω 2 corresponding to different orders is illustrated in Fig. 11.17.  1  1+ε2   2     ω    1 2  S    1  0.8  0.6  0.4  0.2  0  0  N = 1  2  100  30  7 10  3  4  5  1.5 ω ω c  0.5  1  2  2.5  3   cid:2 Figure 11.17  Amplitude response of the Butterworth ﬁlter:  cid:8  = 0.4.      399   cid:2   11.8 RF microwave ﬁlters  Equal ripple ﬁlters   cid:2    cid:3   ω ωc  ,  PLR = 1 +  cid:21 2T2  N  The type-I Chebyshev ﬁlter exhibits equal-ripple passband and maximally ﬂat stopband. It is also an all-pole ﬁlter. For an Nth-order lowpass ﬁlter, it speciﬁes PLR as  where ωc is the passband edge frequency, and TN x  is the Nth-order Chebyshev polynomial  T1 x  = x, T5 = 16x5 − 20x3 + 5x,  T2 x  = 2x2 − 1,  T3 x  = 4x3 − 3x,  T4 x  = 8x4 − 8x2 + 1,  T6 x  = 32x6 − 48x4 + 18x2 − 1,  ···   11.88   The recurrence is given by  Alternatively, TN x  can be written as  TN x  = 2xTN−1 x  − TN−2 x .  cid:15   TN x  =  cos N arccos x  , cosh Narccosh x  ,  x ≤ 1 x > 1  .  The type-I Chebyshev ﬁlter has a sharp cutoff, but has ripples of amplitude  cid:21 2 + 1. For ω  cid:7  ωc, PLR increases at 20 dB decade, but still 6 N − 1  dB greater than the binomial response.  The type-II Chebyshev ﬁlter has both poles and zeros. It exhibits a maximally ﬂat  passband but an equiripple behavior in the stopband. PLR is deﬁned as   cid:17   cid:7    cid:18   cid:8  ,  T2 N T2 N  ωs ωc ωs ω  PLR = 1 +  cid:21 2  Elliptic function ﬁlters   cid:2    cid:3   ω ωc  ,  PLR = 1 +  cid:21 2U2  N  where ωs is the stopband frequency.  The elliptic  or Cauer  function ﬁlter has equal-ripple passband and stopband. It has both poles and zeros. PLR is given as  where ωc is the passband frequency, UN is the Jacobian elliptic function of order N, and  cid:21  controls the passband ripple. As compared to the Butterworth and Chebyshev ﬁlters, it has better cutoff rate.   11.87    11.89    11.90    11.91    11.92       400   cid:2   RF and microwave subsystems  Linear phase ﬁlters  9  :   cid:3 2N  ,   cid:2   ω ωc  A linear phase response in the passband is very important for communication systems to prevent distortion. In addition to the amplitude requirement for a lowpass ﬁlter, a linear phase response of the voltage transfer function can be deﬁned as  φ ω  = Aω  1 + p which has maximally ﬂat group-delay τd = dφ complicated.  dω . Design for linear phase ﬁlters is more  The Bessel ﬁlter has a transfer function derived from a Bessel polynomial. It has a maxi- mally ﬂat group-delay in the passband; this is in a sense complementary to the Butterworth response, which has a maximally ﬂat amplitude. The Bessel ﬁlter is an all-pole ﬁlter with the transfer function   11.93    11.94   H s  = 1 BN s   ,  where BN s  is the Nth-order Bessel polynomial.  The Gaussian ﬁlter, whose transfer function is derived from a Gaussian function, has zero overshoot on the step and impulse response. The response is very close to that of the Bessel ﬁlter, giving poor selectivity and high sensitivity in exchange for superior delay and phase linearity.  The amplitude and delay responses of the ﬁve types of ﬁlters, i.e., the Butterworth,  Chebyshev, elliptic, Bessel, and Gaussian lowpass ﬁlters, are illustrated in Fig. 11.18.  11.8.2 Prototyping  Filter design starts from lowpass ﬁlter prototypes, which are normalized in impedance and frequency. The maximally ﬂat ﬁlters, the equal-ripple ﬁlters, the linear phase ﬁlters and the Gaussian ﬁlters are all-pole ﬁlters. They all can be implemented by using a doubly- terminated lossless ladder network or its dual, as shown in Fig. 11.19.  S 21  1.0  Delay  Elliptic  Butterworth  Chebyshev  Bessel  Gaussian  ω ω  c  Chebyshev  Elliptic  Gaussian  Butterworth  Bessel  ω ω  c   cid:2 Figure 11.18 The amplitude and phase responses of Butterworth, Chebyshev, elliptic, Bessel, and Gaussian  1.0  1.0  lowpass ﬁlters, for the same order  N = 2 .      401   cid:2   11.8 RF microwave ﬁlters  R0=1  L  2  L1  L3  C1  C3  RL  G0=1  C2  RL   cid:2 Figure 11.19   a    b   Two dual LC ladder circuits for lowpass ﬁlter prototypes.  For Nth-order maximally ﬂat and equal-ripple lowpass ﬁlter prototypes, the values for circuit elements for N = 1 to 10 are tabulated, and the attenuation characteristics for various N are also given in [19, 31, 36]. The element values for Gaussian ﬁlters of order 2 to 10 are tabulated in [19].  In many wireless communication systems, ﬂat group delay as well as selectivity is required for a bandpass ﬁlter. For the prototype lowpass linear phase ﬁlter, design val- ues are also tabulated for N = 1 to 10 for the ladder circuits [31, 36]. Another lowpass prototype for linear phase ﬁlters was introduced in [19, 40]. The optimized element values are tabulated in [19] for ﬁlters of orders 4 6 8 10 and a return loss S11 of −20 dB −30 dB at the passband. There is a tradeoff between linear phase response and selectivity in the ﬁlter design.  The prototype circuits and values for the elliptic function lowpass ﬁlter are also given in [19]. The prototype circuits are very similar to the LC ladder circuit, but using series parallel-resonant branches, or its dual using shunt series-resonant branches.  For designs of the same order, the equal-ripple response has the sharpest cutoff but the worst group delay. The maximally ﬂat response has a ﬂat amplitude attenuation and also a ﬂat group delay in the passband, but with a slightly lower cutoff. The linear phase ﬁlter has constant group delay, but the worst cutoff.  Transformations and distributed implementation  These lowpass ﬁlter prototypes are then scaled for arbitrary frequency and impedance, and can also be transformed into highpass, bandpass or bandstop types. These transformations are given in [19, 36]. The design in lumped-element circuit can then be implemented in distributed form. For microstrip ﬁlters, the desired source impedance is normally 50 ohms. In the following, we describe some conventional methods for microstrip ﬁlter design. Some advanced RF microwave ﬁlters are introduced in [19]. A most comprehensive text on microstrip ﬁlter design is by Hong [19].  11.8.3 Stub ﬁlters  The lumped-element design needs to be transformed into a distributed circuit such as a microstrip circuit. Richard’s transformation and Kuroda’s identities are used to trans- form the lumped-element circuits into distributed ones. Richard’s transformation converts      402   cid:2    cid:2 Figure 11.20  RF and microwave subsystems  A lowpass ﬁlter using stubs. Each section has a length of λ 8.   cid:2 Figure 11.21 A Hi-Z-low-Z lowpass ﬁlter. Note that the thick sections correspond to Zl, the narrow sections to Zh,  and the sections at the two ends correspond to Z0.  lumped elements to transmission line sections, and four Kuroda’s identities are used to separate the ﬁlter elements by using transmission line sections. Richard’s transformation is used to transform inductors and capacitors into short-circuited and open-circuited stubs of λ 8 at ωc, respectively. All the stubs are of the same length, and are called commensurated lines.  Kuroda’s identities employ redundant transmission line sections to achieve a practical microwave ﬁlter implementation: They physically separate transmission line stubs, con- vert between series and shunt stubs, and change impractical characteristic impedances into practical ones. The additional transmission line sections are also λ 8 long at ωc, and are called unit elements.  This generates ﬁlters using stubs. A lowpass ﬁlter using stubs is illustrated in Fig. 11.20.  A simple design procedure for using stubs λ 8 long is detailed in [36].  The stub ﬁlter implementation is suitable for all kinds of ﬁlters, and the open-circuited stub is more suitable for microstrip ﬁlters. The design equations for using λg 4 short- circuited stubs or λg 2 open-circuited stubs are given in [19, 31].  11.8.4 Stepped-impedance lowpass ﬁlters  Stepped-impedance, or Hi-Z-low-Z, lowpass ﬁlter is a popular microstrip or stripline design that uses alternating transmission line sections of very high and very low char- acteristic impedances. Such ﬁlters are easier to design and cover less space than ﬁlters implemented using stubs.  Due to approximation introduced, they are usually used when a sharp cutoff is not required, such as for rejecting unwanted mixer products. The designed lowpass ﬁlter is illustrated in Fig. 11.21, and has a one-to-one correspondence with the LC-ladder circuit shown in Fig. 11.19b. The method converts an inductor to a length of transmission line of a ﬁxed high impedance Zh, and a capacitor to a length of transmission line of a ﬁxed low impedance Zl. The values of Zh and Zl should be set to the highest and lowest characteristic impedances that can be fabricated. The value of each inductor or capacitor is determined by the length of the transmission line [36]      403   cid:2   11.8 RF microwave ﬁlters  βl ≈ LZ0 Zh βl ≈ CZl Z0   for inductors ,   for capacitors ,   11.95    11.96   where Z0 is the ﬁlter impedance, L and C are the normalized values of the lowpass prototypes, and β = 2π λ.  11.8.5 Coupled line bandpass ﬁlters  Like Kuroda’s identities, the impedance  K  or admittance  J  inverter can be used for conversion between series-connected elements and shunt-connected ones. The J-inverter converts a shunt LC resonator into a series LC resonator, while the K-inverter performs the inverse operation. They can be constructed by using a quarter-wave transformer. The K and J inverters are especially useful for bandpass or bandstop ﬁlters of narrow bandwidths [36]. Coupled resonator circuits are particularly useful for designing RF microwave narrow- band bandpass or bandstop ﬁlters. There is a general technique for designing coupled resonator ﬁlters for any type of physical resonator including waveguide ﬁlters, dielectric resonator  DR  ﬁlters, ceramic combline ﬁlters, and microstrip ﬁlters [19]. The method depends on the coupling coefﬁcients of the coupled resonators and the external quality factors of the input and output resonators.  Parallel-coupled half-wavelength resonator bandpass ﬁlters  Parallel-coupled transmission lines can be used for ﬁlter design. The microstrip or stripline implementation is easy to fabricate, and is suitable for fractional bandwidths less than 20%. Narrowband bandpass ﬁlters can be implemented using cascaded coupled line sections. A bandpass ﬁlter is illustrated in Fig. 11.22.  These coupled-line sections are identical; each coupled-line section is λ 2 long in the vicinity of the bandpass region of the ﬁlter, and can be modeled by a shunt-parallel LC resonator. The odd- and even-mode impedances of the coupled part are determined by the spacing between two coupled-line sections. Each coupled-line section has a λ 4 line coupled with the previous one, and a λ 4 line coupled with the following one. The coupled part of two coupled-line sections can be modeled by a J-inverter. Cascaded coupled-line sections thus have an equivalent circuit in the same form as that of the bandpass or bandstop ﬁlter. The design equations for parallel-coupled-line bandpass ﬁlters are given in [19, 36].   cid:2 Figure 11.22  Coupled line bandpass ﬁlter.      404   cid:2    cid:2 Figure 11.23   cid:2 Figure 11.24  RF and microwave subsystems  End-coupled resonator bandpass ﬁlter.  Hairpin-line bandpass ﬁlter.  End-coupled half-wavelength resonator bandpass ﬁlters  The end-coupled microstrip bandpass ﬁlter, as shown in Fig. 11.23, uses many open-end microstrip resonators, each of length approximately half a guided wavelength at the mid- band frequency f0 of the bandpass ﬁlter. The gap between two adjacent open ends can be modeled by a capacitor. All the microstrip-line sections have impedance Z0. Design is based on the length of each section and the gaps between these sections. Design equations are given in [19, 36].  Hairpin-line bandpass ﬁlters  The hairpin-line bandpass ﬁlter, as shown in Fig. 11.24, is very compact. It can be viewed as folding the resonators of the parallel-coupled bandpass ﬁlter into a U shape. Thus, the same design equations as for parallel-coupled half-wavelength resonator ﬁlters can be used, but must take the reduction of the coupled-line lengths due to folding into considera- tion [19]. The two arms of each hairpin resonator must also be well separated to reduce coupling. Due to the large coupling arising from the compact architecture, full-wave EM simulation is usually used to verify the design, that is, to calculate S21 and S11.  Interdigital bandpass ﬁlters  The interdigital bandpass ﬁlter, as shown in Fig. 11.25, consists of an array of TEM-mode or quasi-TEM-mode transmission line resonators, each of length λ 4 at the midband fre- quency and short-circuited at one end and open-circuited at the other end, arranged in an alternating orientation. Grounding is implemented by using via holes. Each resonator can have different length and width, and coupling is adjusted by the spacing between adjacent resonators.  The second passband of the ﬁlter is centered at about three times the midband frequency of the desired ﬁrst passband, and there is no spurious response in between. But for the parallel-coupled half-wavelength ﬁlters, a spurious passband at around twice the midband frequency almost always occurs [19]. The design equations are given in [19]. Use of full- wave EM analysis for design veriﬁcation is also desirable.      405   cid:2   11.8 RF microwave ﬁlters  via hole to ground  Interdigital bandpass ﬁlter   cid:2 Figure 11.25   cid:2 Figure 11.26  Combline bandpass ﬁlter.  Combline bandpass ﬁlters  The combline ﬁlter has a structure very similar to the interdigital ﬁlter. This is shown in Fig. 11.26. It is comprised of an array of coupled resonators. These resonators are short- circuited at one end, and at the other end they are connected to the ground with a lumped capacitance in between. A second passband at about three times the midband frequency occurs. The design equations are given in [19].  The larger the value of the lumped capacitance, the shorter the resonator line. This leads to a more compact structure with a wider stopband between the ﬁrst passband and the unwanted second passband. This provides a convenient method for ﬁlter tuning. The pseu- docombline ﬁlter is a variant of the combline ﬁlter, wherein the shorted-circuited ends are replaced by λg 4 open-circuited stubs.  11.8.6 Computer-aided design for RF microwave ﬁlter design  Computer-aided design  CAD  has been extensively used for RF microwave ﬁlter simula- tion, design and validation. For ﬁlter design, the most important performance parameters are S21 and S11. These are conventionally obtained by using the linear model obtained from cascaded ABCD matrices. Linear simulation based on network analysis is simple and fast. However, linear analysis is based on analytical circuit models, and the models are valid only for certain frequencies and physical parameters. For complex RF microwave structures or for a more accurate solution, full-wave EM solvers are preferred.  In Chapter 10, we have introduced a number of full-wave EM methods and the popular commercial EM solvers. There are also some other integrated packages such as Agilent’s      406   cid:2   RF and microwave subsystems  Advanced Design System  ADS , and Applied Wave Research  AWR ’s Microwave Ofﬁce. These integrated packages incorporate both full-wave EM solvers and linear simulators that are based on transmission line theory, and also provide optimizers. Ansoft’s Harmonica is a linear and nonlinear simulator.  When full-wave EM simulators are used, the RF microwave ﬁlter structure is divided into cells with 2D or 3D meshing. The smaller the meshing size, the smaller the simulation error but the longer the simulation time. By repeating the EM simulation using different mesh sizes, one can ﬁnd a very good compromise between the simulation error and time. As a rule of thumb, EM solvers are best suited to problems with physical dimensions of the order of 0.1λg to 10λg. Problems with smaller electrical lengths can be solved using quasi-static solvers, while large problems require more computing resources.  Neural networks [12] have also been used for ﬁlter modeling [33]. After training from existing examples or the results from full-wave EM simulators, a neural network extracts the nonlinear relation of existing devices. The method can provide the same degree of accuracy as that afforded by EM simulators, but with less computation. For example, an EM simulator is used to obtain the S parameters for all components to be modeled in a range of parameters and frequencies, and a neural network is then trained using these results. The trained neural network can be generalized over this range.  Computer-aided analysis is only suitable for validation of a ﬁlter. Given ﬁlter design speciﬁcations, an optimization design procedure can be applied. The designer can provide an initial design for a speciﬁc design method, and then adjust the parameters in a systematic manner. The performance of each new design is evaluated by the computer-aided analysis, and is also compared to the ﬁlter speciﬁcations. This procedure is repeated until the opti- mum design is achieved. Many optimization techniques including the conjugate gradient method and evolutionary algorithms are described in [12].  For ﬁlter synthesis by optimization, an objective function must be deﬁned. For a two-port  ﬁlter topology, the following error function can be used as the objective function [19]  E  f ,  cid:15   = I cid:26    cid:4  cid:4  cid:4 S21   fi,  cid:15   − Sd  i=1   cid:4  cid:4  cid:4 2 + J cid:26    cid:7    cid:4  cid:4  cid:4 S11  i=1   cid:8  − Sd   cid:7    cid:8  cid:4  cid:4  cid:4 2    fi   21  fj,  cid:15   fj  11  ,   11.97   where S21 and S11 are obtained from computer analysis, Sd 11 are the desired fre- quency response from the speciﬁcations, fi’s are frequencies at speciﬁed points, I and J are the numbers of evaluation points, and  cid:15  represents all designable parameters for a given ﬁlter topology. Many commercial computer-aided design packages can perform ﬁlter synthesis by optimization directly.  21 and Sd  11.8.7 Filters for wireless communications  A ﬁlter is used to reject the out-of-band interference prior to further processing. The inser- tion loss of the ﬁlter is an important factor. In wireless systems, the receive and transmit ﬁlters are combined by using a diplexer to allow them to share the same antenna.      407   cid:2   11.8 RF microwave ﬁlters  Filters can be designed by using circuits of electrically connected resonators  such as ladder ﬁlters  or as wave propagation coupled resonators. These ﬁlters can be manufactured using the thin-ﬁlm resonator technology, which uses thin ﬁlms of piezoelectric materials to manufacture resonators and ﬁlters over a range of 500 MHz and 20 GHz. Bandpass ﬁlters are more common in wireless communications.  Since bandpass and bandstop ﬁlters require LC segments that behave as either series or parallel resonant circuits, as seen from coupled line bandpass or bandstop ﬁlters, coupled resonators are also used for the design of such ﬁlters. Compared to the coupled line ﬁl- ter, the stub ﬁlter is more compact and easier to design. A quarter-wave open-circuited or short-circuited transmission line stub is a series or parallel resonant circuit, respectively. However, a ﬁlter using stub resonators often uses characteristic impedances that are dif- ﬁcult to fabricate. The capacitive-gap coupled resonator ﬁlter is a kind of bandpass ﬁlter suitable for fabrication in microstrip or stripline form. The direct-coupled cavity ﬁlter is also popular in waveguide form. Design details for various ﬁlters can be found in references [19, 31, 36].  At RF frequencies from 800 MHz to about 4 GHz, DR bandpass ﬁlters are generally used, and they provide small size and high Q. At IF frequencies below 100 MHz, band- pass ﬁlters typically use quartz crystal or SAW devices. Crystal resonators have high-Q resonance. Resonators are also used in SAW devices. SAW ﬁlters have very sharp cutoff. Above 4 GHz, waveguide resonator-based bandpass ﬁlters are usually used.  Filters for base stations  Filters used in wireless BSs can be either coaxial-cavity resonator ﬁlters or DR ﬁlters [30]. The coaxial-cavity ﬁlter offers low-cost design, but has limited Q. Coaxial TEM ﬁlters are widely used in BSs. They typically use combline or interdigital structure. Combline ﬁlters can be designed with a bandwidth of 1–50%, and are commonly deployed. Interdigital ﬁlters are used when wider bandwidth is needed. Coaxial TEM ﬁlters and diplexers can be machined from a single block of metal.  The DR ﬁlter is emerging as a more popular solution in view of its high performance. A DR ﬁlter typically consists of a number of dielectric resonators mounted inside cavities within a metal. It has a high unloaded Q, high dielectric constant  cid:21 r, and small temperature drift. DR ﬁlters can operate in different modes such as transverse electric  TE  or transverse magnetic  TM  modes. Each mode has a different ﬁlter size, unloaded Q and spurious per- formance. The unloaded Q is typically the reciprocal of the loss tangent of the dielectric material. The loaded Q is typically 70–80% of the unloaded Q, and the differ- ence is due to the size of the enclosure, support structure of dielectric resonators inside the cavity, and tuning screws. Dielectric resonators usually have poor spurious perfor- mance. There are also ﬁlters that combine the small-size advantages of coaxial-resonator ﬁlters and the high Q values of DR ﬁlters. These devices are typically machined from metals.   cid:17    cid:18   tan δ  1  HTS ﬁlters realize small-size, high-order ﬁlters with low insertion loss. Most supercon- ducting ﬁlters are simply microstrip ﬁlters using HTS thin ﬁlms instead of conventional      408   cid:2   RF and microwave subsystems  conductor ﬁlms. Receiver sensitivity can be signiﬁcantly improved by designing the receiver to operate in a cryogenic environment. This eliminates thermal noise from the LNA and improves the ﬁlter loss performance. Due to the low resistance of HTS materials, it is possible to use planar thin-ﬁlm technology to provide HTS ﬁlters that are two orders of magnitude smaller in size than conventional DR ﬁlters. Yttrium barium copper oxide  YBCO  and thallium barium calcium copper oxide  TBCCO  are the two most popular HTS materials, with critical temperature Tc of 92 K and 105 K, respectively [19]. HTS microstrip ﬁlters are desirable for future wireless systems.  Filters for mobile stations  MSs are restricted by size, and bandpass microstrip ﬁlters may not be useful. SAW ﬁlters are unique passive microwave components that are suitable for MSs. The use of SAW ﬁlters in modern MSs is decreasing due to the high integration of RF front ends. Meanwhile, multiband MSs require more SAW ﬁlters. SAW-based ﬁlters or resonators provide high- Q for frequencies up to 2 GHz. For use in MSs, SAW devices must withstand powers as high as 34 dBm for 2G and 3G mobile communications. The size of SAW ﬁlters has shrunk signiﬁcantly in recent years. SAW devices have superior performance such as high stability, low insertion loss, high stopband rejection, linear phase characteristics, narrow transition width between passband and stopband, small inﬂuence of the shape factor on frequency response, and temperature stability [44, 52].  SAW devices are based on the propagation of standing microacoustic waves. Transduc- tion and reﬂection are the basic mechanisms in most SAW devices. A SAW device consists of a piezoelectric substrate with metallic structures such as interdigital transducers, and reﬂection or coupling gratings on its polished surface [44]. Due to the piezoelectric effect, a microwave input signal at the transmitting interdigital transducer stimulates a microa- coustic wave that propagates along the surface of the elastic solid, and bounces into the cavity formed by the gratings, thus generating resonance. A SAW generates an electric charge distribution at the receiving interdigital transducer, and thus outputs a microwave electrical signal. Design of interdigital transducers is of critical importance in terms of frequency response characteristics.  Many passive components such as inductances and capacitors for matching and building LC ﬁlters can be integrated into SAW devices by using LTCC technologies. The balun functionality and impedance transformations can also be integrated into SAW modules. SAW technology now typically covers the frequency range from 10 MHz up to 3 GHz, since the frequency range is bounded by their size. SAW devices require proper packaging.  11.9 Phase shifters  Phase shifters can be easily implemented using transmission lines. A switched-line phase shifter is shown in Fig. 11.27. By changing the length of a transmission line by  cid:18 l, a phase shift ϕ is realized:      11.9 Phase shifters  Δl  409   cid:2    cid:2 Figure 11.27  A switched-line phase shifter.  ϕ = β cid:18 l = 2πf  cid:18 l  c  √   cid:21 r ,   11.98   where β = 2π λ, λ being the wavelength of the signal passing along the line. Phase shifts can also be achieved by changing the wave number β, which can be mod- iﬁed by changing the relative permittivity  cid:21 r of a dielectric. Switches are required for switching between transmission lines of different electrical lengths or different dielectrics. Popular RF switches are PIN diodes, FETs, and MEMS switches.  The ferrite phase shifter is based on the interaction between the electromagnetic waves and the spinning electrons in a magnetized ferrite. The latching ferrite phase shifter requires only a pulsed current to change its state. It has low insertion loss and can handle signiﬁ- cantly higher power, but is complex and expensive. Compared with ferrite phase shifters, PIN diode or FET phase shifters have smaller size, integrability with planar circuitry, higher speed, and lower cost; but they have higher insertion loss, because they require continuous bias current.  MEMS phase shifters have a very low insertion loss, less than 2 dB, over a full phase shift ◦ at microwave frequency ranges. They have high isolation and low drive power. The of 360 combination of MEMS with new dielectric tunable materials can achieve a lightweight, low cost as well as continuous phase change [52]. The MEMS bridge that is made of polymers having elastic modulus of one-tenth that of metals can effectively reduce the actuation voltage, which is around 100 V with conventional metal bridges.  ◦  ◦ , 90  ◦ , 45  ◦ , 22.5  ◦ , 11.25  Digital phase shifters are very similar to digital attenuators. They use switches to set the different states of a cascade of discrete phase shifters. They are usually designed for , etc arranged in cascade to realize all binary phase shifts of 180 possible combination of the phase. The switched-line phase shifter is most fundamental, but its size is dependent on the lowest frequency of operation and the number of bits. A satisfactory single-pole two-throw  SP2T  switch is essential. When the off line has a length of a multiple of λ 2, resonance may occur; this problem must be considered when selecting the lengths of the two transmission lines. There are several types of digital phase shifter. The loaded-line phase shifter can be ◦  , and it is realized by loading a trans- used for small phase shift  typically less than 45 mission line with a shunt susceptance, which introduces a phase shift in the transmitted wave. The reﬂection-type phase shifter is based on the total path length change between the two reﬂected waves. The switched-ﬁlter phase shifter is similar to the switched-line phase shifter, but the transmission lines are replaced by a lowpass ﬁlter  for phase lag  and a highpass ﬁlter  for phase advance . The switched-ﬁlter phase shifter is much smaller      410   cid:2   RF and microwave subsystems  than an equivalent switched-line, reﬂection-type, or loaded-line phase shifter, and is most popular for a digital MMIC phase shifter [41].  An analog phase shifter is one where continuous phase variation is possible. Analog phase shifters are desirable for adaptive phase arrays. An analog phase shifter can typically be implemented as a reﬂection-type phase shifter [41]. A line stretcher is also a phase shifter.  11.10 Basic concepts in active RF circuits  From this section on, we discuss various active RF circuits and components. We ﬁrst give some basic concepts in this section.  The use of nonlinear devices leads to undesired harmonics and intermodulation prod- ucts. These spurious signals increase the conversion loss and signal distortion of active RF components such as mixers and ampliﬁers. Amplitude nonlinearity between input and output power can be expanded into a power series  vo = k1vi + k2v2  i  + k3v3  i  + ··· .   11.99   For a single-carrier input signal, this yields harmonic products, which can be eliminated by ﬁltering in case of narrowband communications. For wideband communications with an octave or greater bandwidth, when more than one carrier frequency  or tone  is used, intermodulation products will occur. These intermodulation products are very close to the desired signals and cannot be easily removed by ﬁltering.  Minimum detectable signal   cid:18   cid:17  For a given system noise power, the minimum detectable signal  MDS  determines the minimum SNR at the demodulator. The minimum SNR at the demodulator, SNRo,min =  So No  min  , is associated with the MDS, Si,min, by  Si,min = So,min G  = kBB [TA +  F − 1 T0] SNRo,min,   11.100  where T0 = 290 K, TA is the antenna temperature, F is the receiver noise ﬁgure, G is the overall power gain, B is the channel bandwidth measured in Hz, So,min is the output signal, and kB is Boltzmann’s constant. In decibels Si,min = −174 + 10 log10 B + 10 log10  + SNRo,min  TA − T0   11.101   + F   dBm .   cid:3    cid:2   T0  The sum of the ﬁrst three terms is the total noise of the system, and is known as the noise ﬂoor, Nﬂoor. In view of this, the MDS is very weak for a narrowband channel. Assuming TA = T0, the third term reduces to F in dB. For example, GSM requires an MDS of −3. Thus, the maximum noise ﬁgure -102 dBm with an SNR of 9 to 12 dB at a BER of 10 is between 7 to 10 dB.      411   cid:2   11.10 Basic concepts in active RF circuits   cid:2 Figure 11.28  Δf  Δf  Δf  2 − f f 1 2  f 1  f2  f2 2  −f1  Third-order intermodulation products.  For digital demodulation, we have So No  Rb B , where Rb is the bit rate and B is bandwidth. The MDS power Si,min can be converted to the receiver voltage sensitivity  rms  by  = Eb n0  Vi,min = cid:25   2Z0Si,min,   11.102   where Z0 is the impedance of the receive antenna.  The dynamic range of a receiver is deﬁned as the ratio of the maximum allowable signal power to MDS power. The maximum allowable signal power can be selected as the third- order intercept point  IP3 .  Intermodulation products  For two carrier frequencies  two tones  f1 and f2,  cid:18 f = f2 − f1 > 0, the output spectrum contains harmonics of the form  mω1 + nω2, m, n = 0,±1,±2, . . . ,   11.103  where ω1 = 2πf1 and ω2 = 2πf2. When the harmonic is a combination of both the frequencies, it is referred to as an intermodulation product, with an order of m + n. The third-order term in  11.99 , k3v3 i , as well as the higher-order odd-power terms, lead to intermodulation products, and the third-order term is usually more signiﬁcant. The third- order term generates frequencies 2f2 − f1 = f2 +  cid:18 f and 2f1 − f2 = f1 −  cid:18 f . These terms set the dynamic range of the system. They are neighboring carrier frequencies, as shown in Fig. 11.28.  The spectrum resulting from a nonlinear device has many high-order distortion terms. This is known as spectral regrowth or intermodulation distortion  IMD , which forms the ACI. Some frequency components of the intermodulation products may fall into the IF band; and they are called spurious responses. The order must be above 6 to 10 so that the power included in these components is sufﬁciently small. A spectrum analyzer generates a frequency-domain representation of an input signal, and is a valid tool for measuring harmonics and intermodulation products.  One-dB compression point and third-order intercept point  The input-output power relationship for the nonlinear device is given by  11.99 . The third-order IMD of two nearby interferers is of critical importance. IP3 is deﬁned for the      412   cid:2   RF and microwave subsystems  P 3  P 1     m B d    o P  1 dB  R D  f  R D DR  Noise level   cid:2 Figure 11.29  Noise floor  MDS  P 1  P 3  P  dBm   i  Input vs. output power for nonlinear devices.  third-order IMD that intercepts with the linear small signal line. IP3 is a unique quantity that can be used for comparing the linearity of different circuits. The third-order IMD is due to kiv3 in  11.99 , so it has a slope of 3 in the input output power diagram  dB , as i shown in Fig. 11.29.  There is a saturation zone in the ﬁgure. This is because k3 is typically negative. The 1-dB compression point, whose power level is denoted as P1, is used to characterize the linear operating range of the device. The second-order term has a slope of 2; it is omitted in the ﬁgure, since it can be easily removed by ﬁltering. IP3 is denoted by P3. For ampliﬁers, P1 and P3 are usually denoted in terms of their output power, while for mixers they are in terms of the input power.  When two signals A cos ω1t and A cos ω2t are used as input to a nonlinear device, the  1-dB compression point and the input IP3  IIP3  in amplitude are related by [9, 37]   dB .   11.104   The 1-dB compression and IP3 are the two important parameters for characterizing a circuit’s linearity. The Nth-order intercept point is deﬁned as the point where the funda- mental signal and the Nth-order harmonic intercept with their linear extrapolations. IP3 is used to describe a receiver’s ability to handle large signals. That is, a large IP3 corresponds to a small intermodulation signal.   cid:2   A1dB AIIP3   cid:3 2 ≈ −9.6  Nonlinear Effects of Cascaded Systems  For cascaded RF systems, each component has its own linearity problem. Given the 1-dB compression point and IP3 of each component, the 1-dB compression point and IP3 of the entire system can be determined.  Assuming that the magnitudes of the multiple tones are the same, the overall 1-dB  compression point and IP3 are given by [29, 37]      413   cid:2   11.10 Basic concepts in active RF circuits  1  P1dB  1 PIP3  = 1  P1dB,1 ≈ 1 PIP3,1  + G1 P1dB,2 + G1 PIP3,2  + G1G2 P1dB,3 + G1G2 PIP3,3  + G1G2G3 P1dB,4 + G1G2G3 PIP3,4  + ··· ,  + ··· ,   11.105    11.106   where the subscript 1dB,k denotes the 1-dB compression point of the kth stage, and the subscript IP3,k denotes the input IP3 of the kth stage. Thus, the later stages inﬂuence the overall 1-dB compression point and overall IP3 more signiﬁcantly. To increase the overall 1-dB compression point or overall IP3, the gains of the components should be reduced, and the gain of the ﬁrst component has the most signiﬁcant inﬂuence. This is in contrast to the case of the noise ﬁgure, given by  11.12 , and becomes a tradeoff for RF system design.  Dynamic range  The dynamic range of a circuit is determined by its noise ﬁgure and linearity. The noise ﬁgure determines the MDS, and the IIP3 speciﬁes the maximum input power with a toler- able distortion. In an RF front-end, the noise ﬁgure is usually dominated by the LNA and the linearity is dominated by the mixer.  For different applications, the deﬁnition of dynamic range may be different. For mixers, the dynamic range is deﬁned in accordance with the input power. It is the range between the MDS and the 1-dB compression point, DR = P1−MDS. For ampliﬁers, it is in terms of the output power, and is deﬁned as the range from the noise ﬂoor to the 1 dB compression point, DR = P1 − No. For LNAs and some mixers, operation is limited to lower power level so that power contribution from the third-order intermodulation is lower than the output noise level No, thus leading to a minimal spurious response. This range is referred to as the spurious-free dynamic range  SFDR, DRf  , and is given by [35]  P3 − No    11.107    dB .  DRf = 2 3  In [37], the SFDR is deﬁned as the upper end of the dynamic range on the intermodulation behavior and the lower-end on the sensitivity, and is given by [37]  DRf = 2 3   P3 − Nﬂoor  − SNRo, min   dB .   11.108   Adjacent channel power ratio  For power ampliﬁers, ideally the phase shift, or time delay, should be constant for all power levels. Phase in practical ampliﬁers changes with the power level, thus with amplitude. Phase nonlinearity introduces intermodulation products in a fashion similar to amplitude nonlinearity.  Distortion is usually deﬁned as CIR power ratio, where the interference is composed of the intermodulation products. In order to make the contribution of the intermodulation products negligible to the system CNR, they should be at least 10 dB lower than the carrier level.      414   cid:2   RF and microwave subsystems  The sum of all intermodulation products in an adjacent channel is the adjacent-channel power level. The adjacent channel power ratio  ACPR , also known as adjacent channel leakage ratio  ACLR , is deﬁned as the ratio of the adjacent-channel power to the carrier power. For personal communications, ACPR is usually lower than −35 dB. For example, the WCDMA standard requires ACPRs at 5 MHz frequency offset to be −33 dB or better, and ACPR at 10 MHz frequency offset to be −43 dB or better.  11.11 Modeling of RF components  Semiconductor-based RF components such as various diodes and transistors are fundamen- tal to active RF circuits. The physical modeling of various diodes, transistors, and FETs is given in detail in [48]. In this section, we brieﬂy describe the physical characteristics of these components.  11.11.1 Diodes  PN diode   cid:7    cid:8   I V  = Is  eαV − 1  ,  A pn junction is obtained by connecting a p-type and an n-type semiconductor, with similar impurity concentrations. The PN diode has a dc V-I characteristic  where α = q nkBT , q being the charge of an electron, kB Boltzmann’s constant, T the tem- perature, n the ideality factor, and Is is the saturation current, which is typically less than −6 A. The I-V characteristic is illustrated Fig. 11.30. 10 Small-signal approximation gives   11.109    11.110   I V  = I0 + v Rj  + α 2Rj  v2 + ··· ,  I  I  p n  +  −  V   cid:2 Figure 11.30  V-I characteristic of a PN diode.  sI  V      415   cid:2   11.11 Modeling of RF components  1  α I0+Is  is the junction resistance of the diode.  where I0 = I  V0  is the dc bias current corresponding to the dc bias voltage V0, v is a small ac signal voltage, and Rj = Diodes have a typical nonlinear response, and are usually used for mixer design. A diode can be used as rectiﬁer to convert a fraction of RF signal to dc power. This is useful for power monitoring, automatic gain control, and signal strength indication. An input small- voltage RF  ac  signal can lead to a dc-rectiﬁed current plus ac signals. The ac signals are usually ﬁltered. The nonlinearity of the diode can also be used for demodulating an amplitude modulated RF signal, that is, for signal detection.  The PN diode can be modeled by a current source in parallel with two capacitors: Cj for the junction capacitance, and Cd for the diffusion capacitance. Most microwave applica- tions rely on Cj, which has a nonlinear dependence on voltage. Diodes in these applications are known as varactors. Varactor diodes can be used in designing amplitude modulators, phase shifters, and frequency multipliers.  PIN diode  The PIN diode is similar to the PN diode but has a very minimally doped region, called +   regions. The I intrinsic  I  region, sandwiched between the p-type  p region has high resistivity, and yields very small junction capacitance, due to the wider depletion region. The I region increases the breakdown voltage of the device, allowing a high reverse voltage. The PIN diode has higher impedance under reverse bias and thus has more isolation than the PN diode. The PIN diode can handle medium to large RF power levels.  +   and n-type  n  For a forward biased PIN diode, holes and electrons are injected into the I region. These charges do not annihilate each other immediately, but stay alive for an average carrier lifetime τ , yielding an average stored charge, Q, which lowers the effective resistance RS of the I region [47]  RS =  W2  ,   μn + μp Q   11.111  where Q = IFτ  in coulombs , IF being the forward bias current, W is the I region width, μn is the electron mobility, and μp is the hole mobility. The equation is valid at frequencies higher than the I region transmit time frequency, f > 1300 W2 , f being in MHz and W in μm. For a zero or reverse biased PIN diode, there is no stored charge in the I region and the diode can be modeled as a capacitor, CT, shunted by a parallel resistance RP. CT is given by  CT =  cid:21 A W  ,   11.112   where  cid:21  is the dielectric constant of silicon and A is the area of the diode junction. The equation is valid when the frequency is above the dielectric relaxation frequency of the I region, f > 1 2πρ cid:21  , with ρ being the resistivity of the I region [47]. At lower frequencies, the PIN diode behaves like a varactor. RP is proportional to voltage and inversely proportional to frequency. Its value is typically higher than the reactance of CT, and is less signiﬁcant. The PIN diode is mainly used as a switch, between the reverse biased and forward biased states, since it has V-I characteristic that is particularly suitable for this purpose.      416   cid:2   RF and microwave subsystems  The intrinsic layer exhibits a lower, variable resistance as a function of the forward bias, so that the PIN diode can be used as a variable resistor or attenuator. PIN switches and attenuators may be used as RF amplitude modulators. Square wave or pulse modulation uses PIN diode switch designs, whereas linear modulators use attenuator designs.  Schottky diode  The Schottky junction is a metal-semiconductor hetero-junction. It can be modeled using the same model as that of the PN diode, but without Cd. It works like a pn junction, but without the charge accumulation problem of the pn junction. This enables its use for forward bias applications such as rectiﬁcation, mixing, and detection.  Like the PN diode, the Schottky diode can be used as a varactor, but a smaller capaci- tance variation is generally obtained due to the smaller breakdown voltage of the Schottky diode. Schottky diodes can be manufactured in Si or GaAs.  Gunn diode  The Gunn diode is manufactured using III-V compound semiconductors, such as GaAs or PIn  Phosphorus-Indium . It is manufactured as an n-doped layer embedded between two + -doped layers. The Gunn diode exhibits negative resistance for suitably biased thinner n voltage. Gunn diodes can produce continuous power output of several hundred milliwatts from 1 to 100 GHz. They are mainly used in the design of negative resistance ampliﬁers and oscillators. The tunnel diode is a pn diode with a high-impurity density in between, and it also has negative resistance when suitably biased.  IMPATT diode  The avalanche diode is a reverse-biased pn junction diode. It has negative resistance when fed with suitable current. The dc V-I characteristic is depicted in Fig. 11.31. The IMPATT  impact avalanche and transit time  diode is a special kind of avalanche diode. It is a very powerful microwave source, which provides the highest output power in the  I  I  V  + n  p  +   cid:2 Figure 11.31  V  V-I characteristic of an avalanche diode.      417   cid:2   11.11 Modeling of RF components  millimeter-wave frequency range among solid-state devices. The IMPATT diode consists of a reverse-biased pn junction and a drift zone, or a reverse-biased PIN diode.  The IMPATT diode exhibits a dynamic negative resistance and is often used in the design of negative resistance oscillators and ampliﬁers, when high output power is required. It may be operated at frequencies from 10 up to 350 GHz, at relatively high powers. It is noisier than the Gunn diode, and thus is rarely used for local oscillators in receivers. The IMPATT diode can be manufactured using Si, GaAs, or InP. GaAs technology achieves a higher efﬁciency than Si technology.  The BARITT  barrier injection transit time  diode is similar to the IMPATT diode. It generally has a lower power output, but it generates lower AM noise. This makes it useful for local oscillators at frequencies up to 94 Ghz.  Step-recovery diode  The step-recovery diode, or snap diode, has a PIN structure. The doping level is gradually decreased as the junction is approached. This reduces the switching time, since the smaller amount of stored charge near the junction can be released more rapidly when changing from forward to reverse bias and the conduction abruptly halts. The abrupt current change is utilized to generate step-like voltage waveforms, and the step recovery diode can be used to produce sampling devices. The step-recovery diode is commonly used in high- order frequency multipliers, since it provides an efﬁciency much higher than that provided by the varactor diode.  11.11.2 Transistors  Transistors are the key active elements in RF and microwave circuits. They are most widely used for signal generation  oscillators , signal ampliﬁcation, and many other functions such as switching and signal processing.  Bipolar transistors  The bipolar transistor was invented in 1948, and it established the foundation of modern electronics. It is a three-terminal device. The emitter, base, and collector regions have a p- n-p or n-p-n doping strategy, yielding a device consisting of two back-to-back pn junctions. This is shown in Fig. 11.32.  For the npn transistor, the emitter and collector currents are given by [41]  Ie ≈ Ic ≈ qDnnb0Ae W  qVbe kBT  ,   11.113   where Dn is the electron diffusion coefﬁcient, A is the cross-section area of the device, q is the electron charge, nb0 is the equilibrium concentration of electrons in the base, Vbe is the base-emitter voltage, and W is the width of the base. The base current is modeled by [41]      418   cid:2   RF and microwave subsystems  E  C  E  p  n  p  C  n x  e  B  B  p W  n x  c  C  E  B  C  E  B   cid:2 Figure 11.32   a  npn   b  pnp  Schematics of the npn and pnp bipolar transistors.  Ib = qDppe0Ae xe  qVbe kBT  ,   11.114   where Dp is the hole diffusion coefﬁcient and pe0 is the equilibrium concentration of holes in the emitter. Since the emitter is much more heavily doped than the base, pe0  cid:5  nb0. From  11.113  and  11.114 , we have Ib  cid:5  Ie ≈ Ic. This feature can be used for voltage and current ampli- ﬁcation, based on the common-base and common-emitter conﬁgurations, respectively, and current-voltage  I-V  curves are constructed accordingly.  In the common-emitter conﬁguration, the input is Vbe and the output is Ic. The  transconductance gm is deﬁned by  gm = ∂Ic ∂Vbe  = Icq kBT  .   11.115   This value is obtained by differentiating  11.113 .  Bipolar transistor technology has used heterojunction strategies to achieve higher oper- ating frequencies. Three mature bipolar transistor technologies are the traditional silicon bipolar junction transistor  BJT , silicon-germanium  SiGe  heterojunction bipolar transis- tor  HBT , and GaAs-based HBT processes. The HBT technologies have higher transcon- ductance and output resistance, higher power handling capacity, and higher breakdown voltage than the BJT technology. BJTs are only suitable for lower gigahertz frequencies, while HBTs can be used for very high operating frequencies and high power applications. In addition, the InP-based HBT process was predicted to provide the highest levels of RF performance, when compared with other bipolar processes, and has received much atten- tion in recent years [41]. Silicon bipolar transistors usually have a much lower ﬂicker noise than GaAs devices do.  Field effect transistors  The GaAs metal-semiconductor ﬁeld effect transistor  MESFET  was the ﬁrst three- terminal active RF device. The MESFET has source, drain, and gate terminals, as shown in Fig. 11.33. The MESFET is one of the two types of FET. The FET, sometimes called a unipolar transistor, uses either electrons  in n-channel FET  or holes  in p-channel FET       419   cid:2   11.11 Modeling of RF components   cid:2 Figure 11.33  n-channel  p-channel  The symbols of p-channel and n-channel MESFETs.  D  S  W  G  G  D  S  Source  Gate  Drain  a  h  Depletion region  Channel  The schematic of a MESFET.   cid:2 Figure 11.34  for conduction. The GaAs MESFET has three metal contacts at the gate, drain, and source terminals. The source and drain contacts are ohmic, while the gate contact constitutes a Schottky diode junction.  In general, the n-type MESFET is used, where the device cap and channel are doped n- type and thus current is carried by electrons rather than the slow holes. The common-source conﬁguration is usually used. The GaAs MESFET is widely used for realizing oscillators, ampliﬁers, mixers, and switches. The MESFET can also be manufactured in Si technology, but limited to the operating frequency of 1 GHz. The schematic of a MESFET is shown in Fig. 11.34.  The transconductance gm, which characterizes the gain mechanism of an FET, is  deﬁned by  at a given Vds. It is derived as [41]  gm = ∂Ids ∂Vgs  gm =  cid:21 0 cid:21 rveffW  ,  a   11.116    11.117   where  cid:21 0 and  cid:21 r are the free space and semiconductor permittivities, respectively, veff is the velocity of carriers in the device channel, W is the Schottky contact width, and a is the thickness of the depletion region.  For a GaAs MESFET, given Vgs, the I-V curves are illustrated in Fig. 11.35. The curves have linear and saturation regions. When Vgs turns more negative, the size of the depletion region is increased, leading to a decreasing drain-source current. At a certain negative Vgs, the depletion region thickness extends over the full channel depth and no drain-source current can pass through. This is referred to as the pinch-off voltage.      420   cid:2   RF and microwave subsystems  I ds   cid:2 Figure 11.35  I-V curves of a GaAs MESFET.  V gs  more  negative  V ds  The high electron mobility transistor  HEMT  is an FET that operates in very similar a way to a GaAs MESFET. Unlike GaAs MESFETs, HEMT devices have heterostruc- tures, which allow operation at higher frequencies. The HEMT has larger electron mobility, and this leads to improved high-frequency noise and gain characteristics. Modern HEMT technologies are pseudomorphic GaAs HEMTs, lattice-matched and pseudomorphic InP HEMTs, and metamorphic GaAs HEMTs. For power-ampliﬁer applications in 3G wire- less communications, linearity is a key requirement. Both HBT and HEMT technologies deliver impressive power and linearity performance.  MOSFET  The metal-oxide-semiconductor ﬁeld effect transistor  MOSFET or MOS FET  is another type of FET. The MOSFET is by far the most common FET in both digital and analog integrated circuits  ICs , and is the core component in CMOS ICs. According to the p- and n-channel doping, it can be of nMOSFET or pMOSFET type.  For the nMOSFET, the source and drain are n+ regions and the body is a p-region, whereas for the pMOSFET the source and drain are p+ regions and the body is an n-region. The symbol of the MOSFET is very similar to that of the MESFET. Like the MESFET, the MOSFET is often used to convert an input voltage into an out- put current, and the transconductance is given by gm = Io Vin. By using an appropriate impedance at the output or input of the MOSFET, a voltage or current gain can be provided. A MOSFET has two operating modes. When the gate-to-source voltage Vgs is smaller than the threshold voltage Vth, the channel is in off or accumulation mode; when Vgs > Vth, the channel is in on or inversion mode. There is no distinct line between on and off. When Vgs is equal to or slightly smaller than Vth, there is a small current ﬂowing from drain to source; this current is known as the subthreshold current. This intermediate state is known as the subthreshold region or weak inversion region.  In the subthreshold region, there is an exponential relation between the drain current Id  and Vgs   cid:2    cid:3   W L  Id = Id0  Vgsq nkBT ,  e   11.118       421   cid:2   11.11 Modeling of RF components  where the constant Id0 is close to 20 nA, n ≈ 1.5, W and L are the gate width and length, kB = 1.38 × 10 −23 J K is Boltzmann’s constant, and T is the temperature in kelvins. This mode is generally not of interest in RF design.  When a MOSFET is in on mode, it has two operating regions: the triode and saturation regions. In the triode region, the drain-source voltage Vds is smaller than the over-drive voltage Vod  Vds < Vod = Vgs − Vth.  cid:8   9 cid:7   :  In this case, the drain current is given by [11, 27] Vgs − Vth  Id = μnCox  W L   11.120  where μn is the mobility and Cox is the gate capacitance per unit area. If Vds  cid:5  Vod, the V2 ds term is negligible and Id is proportional to Vds. In this case, the MOSFET can be used as an effective resistor.  ,  When Vds > Vod, the MOSFET is in the saturation region. A general relation of Id and Vod of a MOSFET in saturation is given in [11, 27]. For large L, the drain current and the small-signal transconductance can be approximated by  Vds − V2 ds 2   11.119   Id = μnCox 2  W L  V2 od ,  gm = μnCox  W L  Vod.   11.121    11.122   For the MOSFET, three basic sources of noise occur, namely, the thermal noise due to the resistive channel, the shot noise due to the junction diodes, and the ﬂicker noise arising from the surface traps between the silicon and the gate oxide. Another important noise in the MOSFET is induced gate noise, caused by some of the channel thermal noise being coupled into the gate. The induced gate noise increases with frequency, and is also called blue noise. The induced gate noise is correlated to the thermal noise, with a correlation of j0.395 for long channel devices [27]. When operating at radio frequency, the ﬂicker noise is negligible, and the thermal noise and the induced gate noise are the dominant contributors to the noise ﬁgure. In a mixer, where both low-frequency and high-frequency signals appear, the ﬂicker noise is also important. Although a MOSFET creates more noise than a bipolar device, a well designed CMOS circuit provides a noise ﬁgure compara- ble to those of bipolar and HBT circuits [11]. More detail on MOSFET physics is given in [27].  The success of the MOSFET has been mainly due to the development of digital CMOS logic, which uses as building blocks pMOSFET-nMOSFET pairs that are connected together at both gates and both drains. The CMOS structure produces very small power consumption. Silicon CMOS technology is now a viable technology for low-GHz RF appli- cations. RF CMOS is now receiving wide attention since it can provide a very inexpensive solution. RF CMOS technology is starting to challenge GaAs and bipolar technologies for      422   cid:2   RF and microwave subsystems  RF applications. However, CMOS is still inferior in terms of the noise and linearity perfor- mance. An advantage CMOS offers over bipolar and MESFET technologies is the ability to integrate a high degree of functionality on a single chip.  A number of nonlinear models for modeling MOSFET, MESFET, HEMT, and BJT  devices including HBT are given in [14, 41].  11.12 Switches  Microwave switches are used for directing signals. They are also used to construct other circuits such as phase shifters and attenuators. The selection of a switch is dependent on the signal level and speed of operation. Mechanical switches can deliver high power, and are widely used in TV, AM, FM and other broadcasting systems. High-power mechani- cal switches can be in the form of waveguide or coaxial connector ports, but they have low speed of operation. Solid-state switches are preferred when operation speed is more important than power handling capacity. PIN diodes and FETs are used for this purpose. MEMS switches are also receiving more attention.  PIN switches  The PIN switch is obtained by biasing the PIN diode to either a high or low impedance state. A single-pole single-throw  SPST  RF switch can be formed by using either a single series or shunt connected PIN diode. A series connected PIN switch has a low insertion loss over a wide range of frequency, and a shunt connected PIN switch provides high isolation. For a series switch, the insertion loss and power dissipation are functions of the diode resistance, while the isolation depends primarily on the capacitance of the PIN diode. In shunt switch designs, the isolation and power dissipation rely on the diode’s forward resistance, whereas the insertion loss is primarily determined by the capacitance.  It is difﬁcult for a single PIN diode, either in shunt or series to achieve an isolation of more that 40 dB at radio and microwave frequencies. Compound switches and tuned switches are used for this purpose. A compound switch combines series and shunt diodes, while a tuned switch employs a resonant structure. These PIN switches can be used as duplexers  transmit receive switches . Analyses of various PIN switches are given in [47].  FET switches  GaAs FET devices, which have a very high mobility of the carriers in GaAs, switch at nanosecond scale, much faster than the PIN diode. The GaAs FET switch has other inherent advantages over the PIN diode, such as simpliﬁed bias network, negligibly small dc power consumption, and simpliﬁed driver circuit design. Also it is compatible for MMICs. PIN switches are increasingly being replaced by GaAs FET switches, especially for low to medium power applications.      423   cid:2   11.12 Switches  The gate voltage Vgs acts as the control signal for the FET switch. From Fig. 11.35, when the gate voltage Vgs = 0, the GaAs MESFET is in low impedance or on state; when the gate voltage is greater than the pinch-off voltage, it is in high impedance or off state. Silicon FETs can handle high power at low frequencies, but the performance drops rapidly as frequency increases.  GaAs FET switches can be combined with passive components into an MMIC. MMIC switches operate over a broad bandwidth and have a much lower power consumption, com- pared with that of PIN switches. However, MMIC switches introduce a higher insertion loss than PIN diodes. For frequencies above 1 GHz, solid-state switches have a typical insertion loss of 1–2 dB at on state, and isolation of –20 dB to –25 dB at off state [52]. The PIN diode and the GaAs MESFET have good high-frequency performance, but only for signals with small power.  MEMS switches  RF MEMS is recently gaining wide interest. A classical review on RF MEMS is given in [4]. Most MEMS devices employ silicon as the basic material. RF MEMS switches [10] implement short circuit or open circuit operations in the RF transmission line by using mechanical movement. RF MEMS switches are extensively used in phase shifters and switching networks up to 20 GHz, and are targeted for operating at 0.1 to 100 GHz.  Switching is achieved via a micro-actuator generated by various actuation mechanisms, such as electrostatic, electrothermal, magnetic, piezoelectric or electromagnetic actuation. The current mature RF MEMS technique uses electrostatic force for the mechanical move- ment. The electrostatic mechanism has low power consumption. Unlike ICs, a MEMS device contains movable, fragile parts, and thus its packaging is expensive.  RF MEMS switches offer a substantially higher performance than PIN diodes or FET switches do [38]: near-zero power consumption, very high isolation, very low insertion loss of 0.1 dB up to 40 GHz, very low intermodulation products due to high linearity that is around 30 dB better than that of PIN or FET switches, higher power handling capability, and very low manufacturing cost.  In addition to high packaging cost, the RF MEMS switch also has some drawbacks −9 second for solid-state such as relative low speed  in the order of 10 switches , a high-drive voltage of 20–100 V for the electrostatic RF MEMS, and relatively low reliability [38, 52].  −6 second versus 10  In wireless communications, RF MEMS can be used in the switch network, recon- ﬁgurable Butler matrix, switched ﬁlter banks, switched phase shifters, transmit receive switches, SP2T  single-pole two-throw  to SP4T  single-pole four-throw  switches, and antenna diversity SP2T. RF MEMS is a state-of-the-art technology for enabling ubiqui- tous wireless connectivity, since it is being widely used in the reconﬁgurable hardware of SDRs. RF MEMS is an efﬁcient way to miniaturize RF radio: Since passive components account for 80% the total components, RF MEMS switches enable a reconﬁgurable passive network by incorporating MEMS ohmic switches and variable capacitors.  More description on RF MEMS is given in [52]. Almost all RF devices, includ- ing switches, inductors, capacitors, ﬁlters, phase shifters, transmission lines and RF      424   cid:2   RF and microwave subsystems  components, and antennas, have their micromachined versions, and these are reviewed in [52].  11.13 Attenuators  An attenuator is a device that reduces the amplitude or power of a signal without distort- ing its waveform. As opposed to an ampliﬁer, an attenuator provides loss instead of gain. Attenuators are frequently used for gain control. For example, in a multichannel commu- nication system, the gains through different channels need to be equalized. Attenuators are also used in phased array antennas and smart antenna systems.  Attenuators are usually passive devices made from resistors. The resistive characteristics of the PIN diode and the transistor can be used for this purpose. Attenuators are typically implemented in digital form. A digital attenuator consists of a cascade of attenuation units, each having an on or off state. When all the units are switched on, the maximum attenuation is achieved; when all the units are off, the system has the minimum attenuation, which is known as the zero-state or reference insertion loss of the attenuator. Switches are the most important components in a digital attenuator.  Attenuators are required to provide the speciﬁed attenuation over a certain frequency band. In applications such as phased arrays, the insertion phase is required to be invariant for all possible attenuation states. The GaAs dual-gate FET can be used to achieve equi- phase but different gain paths [41], where gate 1 is used for gain level control and gate 2 for on- off-state control.  Analog attenuators can provide a continuous amplitude control. This is desirable for cor- rection of any degradation arising from fabrication. Analog attenuators are usually used in AGC control loops and adaptive beamforming systems, and as variable taps in direct imple- mentation of digital ﬁlters. Various types of switched attenuators and analog reﬂection-type attenuators are described in [41].  The resistance characteristic of the forward biased PIN diode, as given by  11.111  can be used in an attenuator. The PIN diode attenuator is extensively used in AGC and RF leveling applications. It can take the form of a simple series or shunt mounted diode acting as a lossy reﬂective switch, or a more complex structure that maintains a constant matched input impedance across the full dynamic range of the attenuator [47].  Example 11.2: For a typical PIN diode, W = 250 μm, τ = 4 μs, μn = 0.13 m2 v· s, and μp = 0.05 m2 v· s. Figure 11.36 gives the resistance of the forward biased PIN diode as function of forward current IF.  In an extreme case, the attenuator becomes a microwave termination, which terminates a microwave transmission line without much reﬂection. The resistive, power-absorbing material is used for this purpose. The impedance of the termination should be equal to the waveguide impedance for minimum reﬂection.      425   cid:2   11.14 Mixers  104  103  102  101    s  m h o     S R    , e c n a t s i s e r   e d o i D  100  10–2   cid:2 Figure 11.36   cid:2 Figure 11.37  10–1  100  101  10–2  Diode current, IF  mA   The resistance of the PIN diode, RS, as a function of forward current IF.  V RF  VLO   a   VIF  VRF  VLO   b   VIF   a  A simple mixer.  b  Realization using switch.  11.14 Mixers  Mixers are essential for modulators, demodulators, frequency translators, and phase-locked loops. Mixers perform frequency translation by multiplying two input signals. Mixers can be made from nonlinear devices, such as diodes or transistors.  A simple switch can be used as a mixer, since the output is the RF input when the switch is on, or zero when the switch is off. This operation can be viewed as multiplying the RF signal by a rectangular waveform. This switch can be implemented by using a transistor, as shown in Fig. 11.37. This is a passive mixer. For an ideal switch, there is no distortion created by the mixer. For a practical switch, its resistance depends on the LO drive voltage as well as the input voltage, thus distortion is introduced. The simple switch mixer is a passive mixer, since it provides no gain. Active mixers generally provide gain, which is the IF power delivered to the load divided by input RF power.  11.14.1 Operation of mixers  The square-law term of the nonlinearity is used for mixers. When the RF signal of fre- quency ωRF and LO signal of frequency ωLO are combined by using a T-junction or directional coupler, the square law generates dc, 2ωRF, 2ωLO, and ωRF ± ωLO terms. Only      426   cid:2   RF and microwave subsystems  the ωRF ± ωLO terms are used for mixers, while all other terms are ignored. The dc term can be biased by using chokes, while the unwanted frequency terms can be removed by ﬁltering.  For mixing, the IF frequency is related to the RF frequency and LO frequency by  ωIF = ωRF − ωLO.   11.123  The mixer produces the RF frequency ωLO+ωIF = ωRF and a spurious image RF frequency at ωLO − ωIF = ωRF − 2ωIF. For a down-converter, if ωRF = ωLO ± ωIF, the ﬁltered mixer output is the ωIF or −ωIF term. These two terms are indistinguishable. The image response can be eliminated by using RF ﬁltering before mixing, but it is very difﬁcult since the desired RF frequency ωLO + ωIF is very close to the spurious image frequency ωLO − ωIF, as ωIF  cid:5  ωLO. Thus, this image RF frequency should be outside the RF bandwidth BRF so that it can be ﬁltered, that is,  fIF >  BRF 2  .   11.124   Image reject ﬁlters are usually placed after the RF ampliﬁer, so that they have less inﬂuence on the noise ﬁgure of the receiver and also remove harmonics due to the RF ampliﬁer. The image reject ﬁlters are typically ceramic DR ﬁlters. For upconversion or modulation, an LO signal and an IF signal are combined to generate ωLO ± ωIF terms. The upper frequency is called the upper sideband, the lower frequency is called the lower sideband. When ﬁltering out one of the sidebands, we get single sideband  SSB  modulation, while double sideband  DSB  modulation retains both sidebands.  Mixers require impedance matching at all the three ports  RF, LO and IF . Undesirable harmonic power can be dissipated in resistive terminations or blocked by reactive termi- nations. The conversion loss of a mixer is deﬁned as the ratio of available input power to output power. Practical diode mixers typically have a conversion loss of 4 to 7 dB, and transistor mixers have a lower conversion loss or even have a conversion gain of a few dB [35].  For heterodyne receivers that use image-reject ﬁlters, the mixer at the ﬁrst downconver- sion stage should employ conjugate matching at the input. The ﬁrst bandpass ﬁlter is the preselect ﬁlter, which is placed ahead of the ﬁrst ampliﬁer  LNA  and must have low inser- tion loss to retain a low noise ﬁgure. A down-conversion mixer often follows the LNA. Due to the high gain of the LNA, the mixer can have a higher noise ﬁgure but it requires a higher IIP3. Because the input signal to the mixer is higher than that of the LNA, the mixer is required to have higher linearity than the LNA, and in most cases the mixer’s IIP3 dominates the IIP3 of the front-end. The IF frequency is usually selected to be less than 100 MHz, due to the limitation on ADC DAC components.  The noise ﬁgure of a mixer is very important for a system. The noise ﬁgure in the SSB case is twice that of the DSB case, that is, 3 dB more than that of DSB, if the signal and image bands are subject to equal gains at the RF port of a mixer. This is because the noise of the image band is folded into the IF band. Noise ﬁgure for a practical mixer varies from 1 dB to 5 dB, and diode mixers generally achieve lower noise ﬁgure than transistor mixers do.      427   cid:2   11.14 Mixers  Impedance matching at RF and LO inputs ensures good signal sensitivity and noise ﬁg- ure. Isolation between RF and LO ports is also important to prevent LO-power leakage. As discussed in Chapter 1, the isolation between any two ports of a mixer is critical. Otherwise, LO leakage, dc offset or even-order distortion problems may occur.  11.14.2 Types of mixers  The most fundamental diode mixer is the single-ended diode mixer. The double-balanced diode mixer is popular since it provides complete port-to-port isolation between all the three ports and has excellent rejection of spurious mixing products, but it may require a large chip area in MMIC implementation. The Schottky diode is the most commonly used diode in mixer circuits. The GaAs Schottky diode can be used up to 1000 GHz, and is relatively cheap.  Compared with diode mixers, bipolar or FET mixers have a higher dynamic range, and require less LO power. FET mixers can be integrated with other FET-based RF circuitry. There are a number of FET mixers such as the single-ended FET mixer, the dual-gate FET mixer, the differential FET mixer, and the Gilbert-cell mixer. The MOSFET and the Si MESFET can be used for frequencies up to several GHz, the GaAs MESFET can be used up to Ku band, and the HEMT is used mainly at Ka band and above. A con- version gain can be achieved by using active FET mixers. FET mixers provide noise performance comparable to that of diode mixers. The dual-gate FET mixer is also widely used.  ◦  ◦ or 180  The single-ended mixer often has poor RF input matching and RF LO isolation. There are several types of mixers: the single-ended mixer, balanced mixer, double-balanced mixer, and image rejection mixer [36]. They all generate good conversion loss.   The single-ended mixer outputs all harmonic combinations of the RF and LO signals.   The balanced mixer combines two identical single-ended mixers with a 3 dB hybrid   to produce either better input VSWR or better RF LO isolation. junction  90 ◦ hybrid generates good RF VSWR, but poor RF LO The balanced mixer using a 90 ◦ hybrid suppresses all even harmonics of the LO. isolation, while that using a 180   The double-balanced mixer uses two 180 ◦ hybrid hybrid balanced mixers. Like the 180 balanced mixer, it has good RF LO isolation, but poor input VSWR. It suppresses all even harmonics of both the LO and RF signals, thus yielding a very low conversion loss.   The image rejection mixer is the most complex, but exhibits the best performance. It can generate good RF VSWR and also good RF LO isolation.  ◦  Diode and FET mixer design is described in [41]. Conventionally, mixing exploits the nonlinearity in diodes or FETs, but this generates spurious mixing products and intermod- ulation. The resistive FET mixer is based on an unbiased FET, which has a linear channel conductance, thus eliminating spurious responses. Resistive FET mixers are thus desirable [41]. The Gilbert-cell mixer is usually used in RF IC design; it provides better isolation between the LO and RF port than a passive mixer. It can also have positive conversion gain. It provides a smaller noise than a passive mixer, and requires a small LO drive amplitude,      428   cid:2   RF and microwave subsystems  but consumes more dc power. Bipolar and CMOS mixer IC design is discussed in [37]. CMOS mixer design is also described in [11].  11.15 Ampliﬁers  An ampliﬁer has a dynamic range within which it can keep a linear relation between its input power and output power. Below the lower end of the range, the input power is too low and the output is dominated by the noise of the ampliﬁer. The level at the lower end is known as the noise ﬂoor of the system, typically varying from −60 to −100 dBm over the bandwidth of the system for transistors. Above the dynamic range is the saturation area. If the input power is too large, the ampliﬁer can be damaged.  Three types of ampliﬁer are used in wireless systems, namely LNAs for receivers, power ampliﬁers for transmitters, and IF ampliﬁers for both receivers and transmitters. Impor- tant parameters for ampliﬁers are the power gain, noise ﬁgure, and intercept points. The intercept points determine the linearity of ampliﬁers, which is a critical parameter.  11.15.1 Requirements in wireless systems  For BSs, power ampliﬁers may be required to provide output power of 10–100 W. For MSs, the output power may be up to 1W. Since most components cannot provide such a power, various power combining techniques are used. For power ampliﬁer design, the input power is usually high, and the transistor does not perform linearly. This makes power ampliﬁer design much more complex than LNA design. For MSs, efﬁciency of the power ampliﬁer is a critical concern for the lifetime of the battery.  For SDRs, a suitable wideband LNA should have a large gain, acceptable input impedance matching, and low noise ﬁgure across the entire band. This broadband nature precludes the use of resonant circuits. A common-gate ampliﬁer is an attractive CMOS solution, where the input parasitic capacitance can be embedded in an LC ladder ﬁl- ter for impedance matching to get a maximally ﬂat frequency response over a wide bandwidth [21].  Quasi-optical ampliﬁers [5] are competitive with other solid-state and vacuum-based power ampliﬁer technologies in the upper microwave and millimeter-wave bands. Although still lagging in power-added efﬁciency  PAE , quasi-optical ampliﬁers have advantages of superior linearity, low noise, high SFDR, and added functionality such as electronic beam steering. This makes quasi-optical ampliﬁers attractive as robust LNAs.  For satellite communications, cryogenic cooling of receivers can reduce their noise tem- perature, since antenna noise is determined by celestial sources and the atmosphere. In the absence of strong celestial source, the antenna is toward a very cold sky with a cosmic microwave background radiation of 2.725 K, which is modiﬁed by the atmosphere. InP het- erostructure FET  HFET  technology is mature and is suitable for application in extremely low-noise ampliﬁers [34].      429   cid:2   11.15 Ampliﬁers  Most wireless standards employ quadrature modulation and or multiple carriers. In this case, the power of a signal varies or ﬂuctuates signiﬁcantly over time. The signals transmitted from BSs typically have a high PAPR, since they each serve multiple users by transmitting signals at multiple carrier frequencies with random phases at the same time. For CDMA systems, the superposition of multiple signals leads to a sum term similar to white Gaussian noise, which has a high PAPR. Signals at BSs are similar for all standards, and have an output power spectrum similar to that of AWGN, with a PAPR of, typically, 10 dB. At MSs, the PAPR values are different for different formats: For example, the PAPR is 0 dB for constant envelope modulation such as FM used in AMPS and GMSK in GSM, 5.1 dB for OQPSK in CDMA IS-95, and it would be greater than 13 dB for OFDM.  High linearity is necessary for efﬁcient use of spectrum. However, an increase in ampli- ﬁer linearity generally leads to a decreasing power efﬁciency. Nonlinear ampliﬁers usually have a high power efﬁciency, and their linearity can be improved via a linearization technique. Linearization of ampliﬁers can be realized by employing the feedforward lin- earization technique, linear ampliﬁcation using nonlinear components  LINC  [7], or an analog or digital predistorter followed by an ampliﬁer.  11.15.2 Structure of ampliﬁers  The basic topology of an ampliﬁer includes an active device such as a FET or a BJT, dc feed, input matching network, and output matching network. An RF choke is used to ﬁlter the dc drain. The ampliﬁer is a two-port network that consists of a source for feeding the input and a load connected to the output. This is shown in Fig. 11.38.  The power delivered to the load is given by ∗ L  VLI  PL = 1 2   cid:19  cid:7    cid:8  = 1  2  IL2 RL,  cid:18    cid:17   PL = Pout  1 −  cid:9 L2  ,  where VL and IL are the voltage and current of the load, respectively. The output power Pout is related to PL by   11.125    11.126   Input network  Output network  Vd  S   a   50Ω  Zs =Rs+Xs  sV  I L  Pout  + Zout VL −  Z L= R L+XL  Pin  Zin  Network   b    cid:2 Figure 11.38  Architecture of an ampliﬁer.  a  Circuit with ampliﬁer.  b  Schematic diagram.      430   cid:2   RF and microwave subsystems  where  cid:9 L is the reﬂection coefﬁcient at the load. When ZL = Z maximum RF power delivery occurs.  out,  cid:9 L = 0 and the ∗  The efﬁciency of an ampliﬁer can be characterized by two metrics: the drain efﬁciency  η and the maximum PAE ηPAE, deﬁned by η = PL Pdc G − 1 Pdc  ηPAE = PL − Pin  × 100% = Pin  Pdc  × 100%,   cid:2    cid:3    11.127   × 100% =  1 − 1 G  η,   11.128   where PL is the power delivered to the load, Pdc is the power drawn from the supply, and the network  power  gain G = PL Pin. Thus a high PAE requires a high η as well as a sufﬁcient power gain. For a large power gain, we have η ≈ ηPAE. The typical ampliﬁer performance for MSs is Pout = 20 to 30 dBm, η = 30 to 60%, G = 20 to 30 dB, IMD= −30 dBc, power control at 1-dB step, and output spurs and harmonics at −50 to 70 dBc [37]. Ampliﬁers must be band-speciﬁc, due to the strict requirement on linearity. For wide- band or SDR systems, several ampliﬁers may be needed, each for a speciﬁc band or standard. Ampliﬁers are required to work at low supply voltages and high operating fre- quencies. Some ampliﬁer circuits use a switch that is on and off periodically at the input frequency. The switch is usually implemented using active devices such as BJTs or FETs with a large gate width. Due to the prevalence of complex modulation techniques that result in a high PAPR, there is a more strict linearity requirement on ampliﬁers. SDR systems dictate the use of wideband ampliﬁers with good linearity and good power efﬁciency.  11.15.3 Classiﬁcation of ampliﬁers  According to the method of operation, efﬁciency, linearity, and power-output capability, −1  dual of class F , ampliﬁers are commonly grouped into class A, B, AB, C, D, E, F, F and S. Analysis of these classical ampliﬁers is based on the assumption that both the input and output waveforms are considered sinusoidal.  Class A ampliﬁers  The class A ampliﬁer operates linearly across the full input and output range. For the class A ampliﬁer, the transistor is biased with the input signal. A single-stage class A ampliﬁer typically provides a power gain of more than 10 dB. It is inherently a linear circuit, and is used mostly as LNAs or power ampliﬁers at MSs. The maximum efﬁciency is equal to 50%, and is less than 40% in practical designs [9, 11, 14, 37]. The device always dissipates the same amount of power, even at zero input. The dc power consumption is relatively high over the entire range of operation, leading to relatively low PAE. Typically, the ﬁrst low-power stage of multistage ampliﬁcation is the class A ampliﬁer.      431   cid:2   11.15 Ampliﬁers  Class B ampliﬁers  The class B ampliﬁer uses two transistors in a push-pull mode, and is implemented using a low-loss high-frequency transformer. Each transistor conducts half of the carrier period. The class B ampliﬁer is able to self-adjust its dc power consumption according to the input power level, leading to a higher PAE than that of the class A ampliﬁer. Class B provides a better efﬁciency than Class A, achieving a maximum efﬁciency of η = π 4 ≈ 79% [14, 37]. The gain of the class B ampliﬁer changes with the input signal level, resulting in a higher distortion than that of the class A ampliﬁer. For a long-channel CMOS class B ampliﬁer, the maximum efﬁciency reaches η ≈ 8  3π  ≈ 85%, and the PAE is usually between 30% and 40% [11]. Class B has essentially no power dissipation with zero input signal. It is typically used as an audio ampliﬁer, and is usually replaced by class AB for RF applications.  Class AB ampliﬁers  The class AB ampliﬁer has a drain current duty cycle that lies between those of class A and class B. For a very small input signal, the class AB ampliﬁer essentially operates as the class A ampliﬁer. The efﬁciency is between 50% and 78.5% at the 1-dB compression point, depending on the angle of conduction. Class AB has higher output power and better PAE, typically 40% at the maximum power level. However, the dc power consumption is relatively constant over the entire range of operation, and its PAE is much smaller when the output power is lower than P1dB [11]. For large dynamic range systems such as OFDM- based 802.11a, the power ampliﬁer needs to be backed off by 8 to 10 dB from its output P1dB point, and this may reduce the PAE to as low as 5%.  The Class AB ampliﬁer has a higher efﬁciency and a cooler heatsink than the class A ampliﬁer, but causes some tolerable nonlinear effects. The class AB ampliﬁer is biased to a quiescent point, which is somewhere in the region between the cutoff point and the class A bias point  Imax 2 . A harmonic short is placed across the output port to prevent any harmonic voltage from being generated at the output. Such a harmonic short can be real- ized by using a parallel shunt resonator that has a resonant frequency at the fundamental. The class B ampliﬁer corresponds to a zero level of quiescent bias  zero-bias ; the current waveform is a perfectly halfwave-rectiﬁed sinusoid, containing only even harmonics [8].  Most RF ampliﬁer ICs are based on the class AB mode. Final stages of a multistage ampliﬁer mainly use class AB. A linearization technique such as predistortion can be applied to Class AB to achieve high linearity.  Class C ampliﬁers  For the class C ampliﬁer, the output transistor is on for less than a half cycle to improve the power efﬁciency. Class C is a truly nonlinear mode of operation. It achieves a maxi- mum efﬁciency of 100%, and typically between 85 and 90%. This efﬁciency is achieved at the cost of reduced power-handling capacity, gain, and linearity. The class C ampli- ﬁer exhibits a high efﬁciency only when operating near cutoff, and is only suitable for      432   cid:2   RF and microwave subsystems  constant envelope signals such as FM signals; it also needs a resonant circuit to ﬁlter out the unwanted distortion. Since it only reproduces the peaks of the signal, it has a lower gain.  Classes D, E, F, F  −1 ampliﬁers  −1 are switch-mode ampliﬁers that use a transistor switch to pump a res- Classes D, E, F, F onant tank circuit. They achieve a very high efﬁciency, but have relatively poor linearity. These devices generate a ﬂatter, squarer periodic waveform, rather than a sinusoidal wave- form. The existence of higher harmonics helps to improve the power and efﬁciency of these ampliﬁers. The switched-mode ampliﬁers are inherently constant-envelope ampliﬁers, and thus linear modulation cannot be obtained. These switch-mode ampliﬁers are rejected by the wireless communications industry, but they were at one time commonly used in AM and SSB broadcasting.  The class D ampliﬁer uses two transistors, and achieves a theoretical efﬁciency of 100%, and very high power-handling capacity. However, it is limited by the requirement for a perfect switch, since otherwise large crowbar dissipation may occur. Classes E and F use only one transistor. They achieve PAE efﬁciency above 80% at fre- quency above 5 GHz, and a maximum theoretical efﬁciency η = 100% while delivering full power. There is a tradeoff between efﬁciency and output harmonic content. Class F usually achieves an efﬁciency superior to that of class E, and better power-handling capac- ity than class E, although it has half the power-handling capacity of class D. As a result, the class F ampliﬁer is more widely used in practice. Analysis and design of the class E ampliﬁer in CMOS is given in detail in [39]. −1  inverted class F  was introduced mostly for low-voltage ampliﬁcation used −1 is dual to class F mode with the collector voltage and for monolithic application. Class F current waveforms being mutually interchanged. Like class F, it also achieves a maximum theoretical efﬁciency of 100%. The Class E F ampliﬁer combines the advantages of both class E and class F  −1 operations [23].  Class F  Class S ampliﬁers  Class S uses an appropriate PWM of the input switch control voltage to a switch-mode ampliﬁer such as class D, then uses a low-loss lowpass ﬁlter to generate output signal with excellent linearity. It achieves a maximum theoretical efﬁciency of 100%. Class S is well suited for CMOS integration, except for the lowpass ﬁlter. Since the switch has to be n times faster than that in a non-PWM ampliﬁer, where n determines the desired dynamic range, it is difﬁcult to use the PWM over carrier frequencies above 10 MHz. This makes the class S ampliﬁer useless for wireless communications.  Nonlinear ampliﬁers typically have a much higher power efﬁciency than linear power ampliﬁers. This is because they do not need a large amount of dc power for maintaining a  Remarks      433   cid:2   11.15 Ampliﬁers  constant gain over the entire range of operation. For power ampliﬁer design, heat sink or good thermal dissipation is essential for the transistor packages.  Classes A, AB, and B ampliﬁers are most widely used in wireless transmitters due to their high linearity. They are so categorized according to the duty cycle of their drain currents. A parallel class A&B ampliﬁer is developed in [11] as a parallel combination of a class A and a class B ampliﬁer, and it provides a better performance compromise for both large and small input levels in comparison to class A, B, and AB ampliﬁers. With proper ratio between the sizes for MOSFETs of the class A and B ampliﬁers, a parallel class A&B ampliﬁer can have a larger linear range, a better power efﬁciency, and much lower dc power consumption. The PAE of the parallel class A&B ampliﬁer is almost the same as that of the class A ampliﬁer at low input and approximates that of the class B at high input.  In practical wireless systems, PAE is usually very low, typically at 10%. An overdriven class B is obtained by increasing the amplitudes of both the current and voltage wave- forms but keeping the truncated peak values the same as in the conventional class B; this leads to a maximum efﬁciency η = 88.6% [14]. Efﬁciency typically drops rapidly as the ampliﬁer output is below the saturation power level. The efﬁciency of the class A ampli- ﬁer increases linearly with the output power. The PAE can be improved by varying the dc current and or dc voltage supplied to the ampliﬁer as output power changes, as in the case of the dynamic supply voltage  DSV  ampliﬁer [2]. More discussion on ampliﬁers is given in [37]. Waveform analysis based on reduced conduction angle and design on different classes of ampliﬁers are given in [9, 14, 27].  Power combining  In order to increase the output power of ampliﬁers made of solid-state devices, power- combining and phased-array techniques can be employed. The conventional power- combining method uses the binary Wilkinson power splitter combiner. An increase in output power causes an increase in the length of transmission line as well as the number of combining nodes. The recent phased-array technique employs spatial or quasi-optical power combining by coupling the components to beams or modes in free space [18]. Spa- tially combined power sources can be implemented using an ampliﬁer array or an oscillator array.  11.15.4 Linearization techniques  Classes E and F are becoming popular since they have high efﬁciency and output power [2]. Band-efﬁcient modulation techniques typically require linear ampliﬁers to minimize spectrum regrowth, and multicarrier modulation techniques need linear ampliﬁers to avoid cross-modulation. For MSs, most linear ampliﬁers employ the class A technique, but the efﬁciency is too low for battery usage.  In order to achieve high linearity while providing the efﬁciency of the switching- mode circuits, linearization techniques such as LINC [7], feedforward linearization, and      434   cid:2   RF and microwave subsystems  predistortion linearization [8] can be applied to nonlinear but power-efﬁcient ampliﬁers. Switch-mode ampliﬁers rely on the high-frequency characteristics of the transistor due to high-speed switching transitions.  LINC combines the outputs of two nonlinear ampliﬁers, which are represented by two constant envelope vectors and the result is obtained by changing the phase difference between the two vectors. This technique requires an efﬁcient power combiner at the output, which is hard to integrate in CMOS.  Predistortion  Predistortion linearization places a small device on the ampliﬁer input, which consumes little power, and provides linearization comparable to the more complex feedforward linearization. The input signal is split into a distortion path and a linear path. The pre- distorion technique can take analog or digital form. The analog predistortion technique was extensively used to correct the nonlinear characteristics of traveling wave tubes, which are still used today for high power applications in the upper GHz bands. A pre- distorter ampliﬁer combination typically introduces a spectrum of distortion products that signiﬁcantly exceeds the spectral bandwidth of the uncorrected ampliﬁer output due to the high-order distortion products introduced by the predistortion process [9]. This can be troublesome for meeting regulatory spectral distortion masks for alternative channel power. The predistortion technique is mainly used as a complement to a system using feedback or feedforward linearization technique. An RF predistortion ampliﬁer typically provides a distortion correction of 5 to 10 dB. A simple analog predistorter can be made by using one or more diodes. The predistorter has a gain, but the use of passive components makes the gain negative.  Digital predistortion is now gaining more research interest [22]. Based on DSP tech- nology, it uses a look-up table  LUT  that is obtained from a priori characterization of the modulator. DSP predistortion is replacing analog predistortion in most applications. A hybrid analog and DSP implementation uses DSP to control the various amplitude and phase scaling adjustments.  Feedforward linearization  The feedforward linearized ampliﬁer is an open-loop correction system. It makes use of a main ampliﬁer and an error ampliﬁer. A correction signal with equal amplitude but opposite phase is added to the main ampliﬁer output by using a coupler to generate a linearization process. Compared to a feedback linearized ampliﬁer, the inherent delay for a closed-loop system is avoided and thus the correction is performed at a much faster speed. Also the stability problem facing a feedback system is avoided.  Feedforward linearized ampliﬁers need to maintain accurate gain and phase tracking. But drift due to temperature and aging is still a problem, and there are now dozens of patents for feedforward adaptation and drift cancellation. A feedforward ampliﬁer typically provides 25 dB distortion correction for a single forward loop. Multiple feedforward loops      435   cid:2   11.15 Ampliﬁers  can be used for greater linearity. Feedforward ampliﬁers are in mass production and have become key components in the infrastructure of mobile communications.  The efﬁciency of feedforward linearized ampliﬁers is low, typically 10–15% [9]. Feed- forward solutions have thus far dominated the power ampliﬁer market of multicarrier communications, since for multicarrier applications the reduction in intermodulation prod- ucts is very desirable. However, the extra cost arising from couplers and other components makes such techniques much more expensive than the digital predistortion technique.  11.15.5 Microwave transistors for ampliﬁers  There are several types of power ampliﬁers: solid-state power ampliﬁers, traveling-wave- tube ampliﬁers, and klystron power ampliﬁers. At high power  <100W , traveling-wave- tube ampliﬁers and klystron power ampliﬁers provide good performance in terms of size, cost, and efﬁciency, but solid-state power ampliﬁers are superior in linearity. At low power, solid-state power ampliﬁers such as microwave transistor ampliﬁers are more desirable, since they are low-cost, reliable, and can be easily integrated into microwave integrated circuits  MICs  and MMICs, and can presently be used at frequencies up to 100 GHz. Microwave tubes are still necessary for very high power and or very high frequency today, due to their better noise ﬁgures, tuning characteristics, temperature responses, and cost.  Microwave transistors are the crucial components for ampliﬁer design. They are also widely used for oscillators, switches, phase shifters, mixers, and active ﬁlters. The silicon  Si  BJTs and GaAs MESFETs are most widely used. Silicon BJTs are cheap, capable of high gain and power capacity at low frequencies, while GaAs MESFETs have better noise ﬁgure and can operate at high frequencies. This is because the GaAs MESFET has a higher electron mobility than silicon BJTs and has no shot noise. The silicon BJT can be used up to 10 GHz, the GaAs MESFET up to 100 GHz, and the GaAs HBT allows higher frequencies. BJTs are preferred over GaAs MESFETs at frequencies 2 to 4 GHz due to their higher power gain and lower cost. The GaAs MESFET provides good noise ﬁgure performance up to 18 GHz. The HEMT provides the best noise ﬁgure and is most suitable for low noise and millimeter-wave applications. For typical bias currents in RF applications, MOSFET devices have better linearity than BJTs.  For power ampliﬁers, the power output is also a concern. Conventionally, for BSs the large transmit power had to be obtained using microwave tubes. Recent progress in wide bandgap semiconductor materials such as SiC and the GaN-based alloys has enabled the fabrication of microwave transistors to replace microwave tubes [50]. The 4H-SiC MES- FET and AlGaN GAN HFET provide RF output power typically of the order of 4–6 W mm and 10–12 W mm with PAE approaching the ideal values for class A and B operations, compared to 1 W mm for the GaAs MESFET. The 4H-SiC MESFET can operate over a frequency range of 3 to 30 GHz with good PAE, and AlGaN GaN HFETs can operate in a wider range from 3 GHz to in excess of 30 GHz. The high power throughput in these power ampliﬁers is difﬁcult to completely dissipate through the substrate and thus, these power ampliﬁers suffer from self-heating effects. Recent AlGaN GaN HFETs achieve an RF out- put power density as high as 30 W mm, and microwave ampliﬁer output power approaching      436   cid:2   RF and microwave subsystems  100 W for single-chip operation [51]. The GaAs HBT also demonstrates excellent output power capability.  11.15.6 Stability  Passive circuits are unconditionally stable. For active circuits such as ampliﬁers, stability analysis must be made, or the designed ampliﬁer may become an oscillator. To ensure stability, the input and output ports of the ampliﬁer must have  cid:9 in < 1 and  cid:9 out < 1, where the input and output reﬂection coefﬁcients  cid:9 in and  cid:9 out are, respectively, determined by the reﬂection coefﬁcients of the source and load matching networks,  cid:9 S and  cid:9 L. The ampliﬁer is unconditionally stable subject to the necessary and sufﬁcient conditions [36, 37, 43]  K = 1 − S112 − S222 +  cid:18 2  > 1,  2S12S21  cid:18  < 1,   cid:18  = S11S22 − S12S21,  μ =   cid:4  cid:4 S22 − S   cid:4  cid:4  + S21S12 > 1.  1 − S112 ∗ 11   cid:18    11.129    11.130    11.131    11.132   Sij are the S-parameters of the ampliﬁer, and K is known as Rollett’s stability factor. As S12 decreases, that is, as the reverse isolation of the circuit increases, the stability is increased. Another criterion for unconditional stability, which also gives relative stability, is given  where  by [15, 36]  The greater the value of μ, the better the stability.  When the device is potentially unstable, the load and source stability circles can be plotted on the Smith chart to ﬁnd the range of values of  cid:9 S and  cid:9 L, and the stable and unstable regions can be identiﬁed [36].  11.15.7 Transistor ampliﬁer design  For ampliﬁer design, we need ﬁrst to conduct stability analysis. The maximum gain of an ampliﬁer is achieved when the source and load matching sections provide a conjugate match between the source or load impedance and the transistor, that is,  cid:9 in =  cid:9 ∗ S and  cid:9 out =  cid:9 ∗ L. For a single-stage transistor ampliﬁer, the transducer power gain is given by  GT = GSG0GL,   11.133   where GS, G0, and GL are, respectively, the gain contributions of the source-matching sec- tion, the transistor, and the load-matching section. G0 = S212 is a ﬁxed value determined by the transistor, while GS and GL are decided by the source and load matching sections.      437   cid:2   11.16 Oscillators  This leads to narrowband frequency response, because most transistors have a signiﬁcant impedance mismatch  large S11 and S22 . In many practical cases S12 can be ignored, and the transistor is then unilateral. This can signiﬁcantly simplify the design procedure. Design can be made using the Smith chart.  The design procedure is detailed in [36], and exploits the constant gain circles for GS  and GL on the Smith chart, which represents the loci of  cid:9 S and  cid:9 L.  Broadband ampliﬁers can be designed at the expense of gain and complexity. A fairly ﬂat gain can be obtained if the ampliﬁer has a gain smaller than the maximum gain, but the source and load matching is poor. The balanced ampliﬁer solves the input and out- couplers to cancel the input and output reﬂections put matching problem by using 90 from two identical ampliﬁers [36]. The distributed ampliﬁer uses multiple identical FETs, whose gates and drains are, respectively, connected to different transmission lines at equal spacing. Such an ampliﬁer is known as a traveling wave ampliﬁer.  ◦  Conjugate matching between the source and the input impedance of the transistor achieves the maximum gain, but generally not the minimum noise ﬁgure, Fmin. For LNA design, a compromise has to be made. Design can be done by plotting constant gain cir- cles and constant noise ﬁgure circles and selecting a suitable tradeoff between them. The design makes use of the noise parameters of the particular transistor being used, the mini- mum noise ﬁgure Fmin of the transistor, the optimum reﬂection coefﬁcient  cid:9 opt that results in minimum noise ﬁgure, and RN equivalent noise resistance of the transistor. More discus- sion is given in [37, 41]. For multistage LNA design, from the Friis noise formula  11.12 , the ﬁrst ampliﬁer stage should achieve the optimum noise ﬁgure rather than the optimum gain, while the later stages can be designed with higher gain, since their noise ﬁgures are less important.  11.16 Oscillators  Oscillators are nonlinear circuits that convert dc power to an RF waveform, typically a sinusoidal waveform. Local oscillators  LOs  are used with mixers for frequency synthesis. The frequency of the LO in a radio transceiver is typically adjustable over the signal band. This is implemented by using a PLL that contains a VCO. The VCO is an oscillator whose frequency is set by a voltage signal. For the VCO, the tuning range is measured in MHz V.  11.16.1 Analysis methods  An oscillator can be viewed as a transistor ampliﬁer with linear positive feedback. When the denominator of the transfer function is zero at a particular frequency, a zero input can lead to a nonzero output, and thus the circuit produces an oscillating waveform at that frequency. Unlike ampliﬁer design that aims at a high stability, an oscillator works only when the circuit is not stable.      438   cid:2    cid:2 Figure 11.39  RF and microwave subsystems      sX  +  +       sH      sY  Feedback circuit of an oscillator.  Feedback model  Htot s  = Y s  X s   = H s  1 − H s   .  H   jω0  = 1,   cid:18  H   jω0  = 0.  For a simple linear feedback system, as shown in Fig. 11.39, the system transfer function is given by   11.134    11.135   For self-sustaining oscillation, two conditions must be satisﬁed at ω0:  These are known as the Barkhausen criteria. In order to start up oscillation, an input signal containing a spectral component at the desired frequency must be available. This signal is already available as the white noise.  In most RF oscillators, a frequency-selective network called a resonator is included in the feedback loop to stabilize the frequency. The feedback model is a two-port model, and is valuable for low-frequency oscillators.  Negative-resistance model  Another approach to describing the operating principle of an oscillator circuit is through the one-port negative-resistance model. This model is more useful for microwave oscil- lator analysis. Losses in the resonator circuit are compensated by a negative resistance demonstrated by an active device. Oscillation occurs at ω0 when [37]   cid:19  [ZT s ] +  cid:19  [ZA s ]s=jω0  = 0,   11.136   where ZT and ZA are the resonator impedance and the impedance of the active circuit. The power produced by the active circuit is delivered to the load.  The Gunn and IMPATT diodes have a negative-resistance behavior in a certain frequency range. The Gunn oscillator is a voltage-controlled oscillator, while an IMPATT oscillator is a current-controlled oscillator. A Gunn oscillator is of relative low power and can be used as an LO or transmitter oscillator. An IMPATT oscillator is noisier but provides higher power. Negative-resistance diode oscillators are the more powerful solid-state sources at very high frequencies, and are now the only viable solid-state source in the frequency range of millimeter waves. They are one-port networks designed using these diodes, which are biased to generate an impedance with a negative real part, or created by terminating a potentially unstable transistor with an impedance that drives the device in an unstable region. A positive resistance implies energy dissipation, and similarly a negative resistance implies an energy source.      439   cid:2   11.16 Oscillators       S f  Ps       m L  f  nP  1 Hz   cid:2 Figure 11.40  0f  f +f0 m  f  Output spectrum S  f  of a typical oscillator.  11.16.2 Phase noise  Consider a generated oscillating signal  x t  = A cos  ωct + φn    11.137   where φn is the phase noise. Phase noise leads to spectrum spread from the ideal spectrum line at ωc, as shown in Fig. 11.40. A low-noise RF VCO requires a high-Q device, since the phase noise of the oscillator is proportional to 1 , where QT is the overall quality factor. Q2 ◦ ◦ T The stability of frequency f0 is speciﬁed in ppm  C, and it ranges from 0.5 to 2 ppm   C for typical wireless systems. To quantify the phase noise, we need to consider the noise power in a unit bandwidth at an offset fm with respect to f0. This quantity, denoted by L   fm , measured in dBc Hz, is deﬁned as the ratio of the noise power in a single side- band per hertz bandwidth to the carrier power, at an offset frequency, fm, from the carrier frequency f0, where dBc means dB with respect to carrier. The phase noise is typically required to be within the range −80 to −110 dBc Hz at a 10-kHz offset from the carrier. Phase noise spills the spectrum of a carrier signal into adjacent carriers, leading to ICI. Phase noise of an LO also corrupts the information in phase modulation. By increasing the Q of the LC oscillator, phase noise can be reduced; for this reason, passive resonators are usually incorporated into oscillators.  Modern wireless systems require stable, low-phase noise VCOs with wide tuning range. Electronically tunable capacitors are key components in such VCOs. Variable capacitors  varactors  with high Q are not available in standard silicon or GaAs processes, thus they are still external to the chip, while MEMS tunable capacitors have lower loss and greater tuning range [52].  Oscillator phase noise arises from thermal and ﬂicker  1 f   noise sources. Small changes in frequency can also be modeled as phase noise. The two-sided PSD associated with phase noise is Sθ   fm  = 2L   fm . The PSD of oscillator phase noise that uses a transistor ampliﬁer can be modeled by Leeson’s model. The Leeson phase noise model is given by [26, 28]  L   fm  = Pn  fm  Ps  = FkBT 2Ps  f0 Q fm   11.138    cid:2    cid:3 2  ,      440   cid:2   RF and microwave subsystems  where Q is the quality factor of the resonator, f0 is the oscillator frequency, Pn  fm  is the noise power, Ps is the signal power measured at the input of the transistor, fm is the frequency offset, F is the noise factor for active devices in saturation, kB is Boltzmann’s constant, and T is the temperature. From this equation, it is seen that Q, F and Ps have signiﬁcant effects on phase noise. A low-noise VCO requires small F, and large Q and Ps. Q is the most effective parameter for improving the phase noise, but the Q of the integrated LC VCO is limited by the Q of the spiral inductor used.  Phase noise degrades receiver selectivity, since unwanted noise signal is also down- converted to the IF band. The maximum phase noise required for achieving an adjacent channel rejection or selectivity S dB is given by [35]  L   fm  = 10 log10  = C − S − I − 10 log10 B    dBc Hz ,   11.139    cid:2    cid:3   Pn Ps  where C is the desired signal level measured in dBm, I is the interference signal level measured in dBm, and B is the bandwidth of the IF band in Hz. IS-54 requires phase noise to be about −115 dBc Hz at 60-kHz offset.  11.16.3 Classiﬁcation of RF oscillators  Diode and transistor microwave sources  Solid-state microwave sources can be grouped into diode or transistor oscillators. The most common diode sources are the Gunn and IMPATT diode oscillators, both of which convert a dc bias to RF power in the frequency of 2 to 100 GHz. Most microwave diode oscillators are built in coaxial resonator or waveguide cavity structure for high quality  Q  factor. The efﬁciency of negative-resistance diodes is very low, and a heatsink must be included to reduce the diode temperature to a reliable operating value.  Transistor oscillators have lower operating frequency or power capacity, but have some advantages over diode oscillators. They can be easily integrated with MIC or MMIC cir- cuitry, and can also be much more ﬂexible than a diode source. The well-known Hartley, Clapp and Colpitts oscillators are LC transistor oscillators. These oscillators are very similar, but differ in the system employed to feed back from the resonator and the imple- mentation of the resonator itself. The schematic of the Colpitts oscillator is shown in Fig. 11.41.  For the Colpitts oscillator, a gross estimation of the oscillation frequency can be obtained  from the resonator elements as   11.140   ω0 =  1 cid:21   .  L C1C2 C1+C2  The loaded Q can be increased by increasing C2 and decreasing C1 in the capacitive divider, or by increasing both C1 and C2 but decreasing L. A more accurate oscillation frequency can be obtained by using the equivalent circuit of the transistor and by applying the oscillation condition.      441   cid:2   11.16 Oscillators  C1  C2  L  Output signal   cid:2 Figure 11.41  Schematic of the Colpitts oscillator.  Most discrete RF oscillators incorporate only one active device to minimize the noise as well as the cost. In RF oscillator ICs, the cost for using multiple active devices is not a problem. In this case, two major sources of phase noise are thermal and ﬂicker noise. The BJT provides lower ﬂicker noise than GaAs devices, and is more popular in low phase-noise microwave oscillators. HEMT and HBT devices are also suitable for low-noise applications, and they can work at higher frequencies.  In RF applications, the oscillator frequency is typically required to be adjustable, so as to be able to select the frequency-divided channels. The resonant frequency of an oscillator can be adjusted by changing the L and C values of the network. This can usually be more easily implemented using voltage-controlled capacitors, such as varactors. The resulting oscillator is known as VCO. A varactor is a diode whose junction capacitance varies with the applied dc reverse bias; dc blocking capacitors and or RF chokes must also be used with a varactor to prevent detuning or shortening the RF circuit. A varactor can be used as a capacitor in a transistor oscillator circuit, and thus forming a VCO.  Resonator-based oscillators  Oscillator stability can be enhanced by using a high-Q tuning network [36]. Resonator- based oscillators, also known as harmonic oscillators, are characterized by an equivalence of two energy storage elements, operating in resonance, to produce a periodic output signal. The Hartley, Clapp and Colpitts oscillators are all harmonic oscillators  The Q of a resonant network using lumped elements or microstrip lines is typically lim- ited to a few hundred, and the Q of dielectric resonators  DRs  can be several thousand. For waveguide cavity resonators, a Q of 104 or more is achieved. The quartz crystal resonator ◦ achieves an unloaded Q as high as 100,000 and a temperature drift of a few ppm   C.  The quartz crystal resonator is composed of a slab of crystal between two metallic plates, and oscillates on the piezoelectric effect. It is a stable frequency source for wireless systems at frequencies up to a few hundred MHz. At its usual operating point, a crystal has an inductance, and for this reason a crystal is used in place of the inductor in a Colpitts or Pierre transistor oscillator. The quartz crystal resonator can be typically used up to 30 MHz. For a higher frequency, SAW devices that use a piezoelectric material allow high-volume, low-cost applications such as front-end ﬁlters for MSs. Unfortunately, neither of these resonators is suitable for IC implementation.      442   cid:2   RF and microwave subsystems  The transistor DR oscillator is now gaining popularity over the entire microwave and millimeter wave frequency range [36]. A small, high-Q DR is used for the load of an FET oscillator circuit. This achieves a very good temperature stability and a compatibility with MIC design. In order to generate RF power, the device must have a negative resistance, which can be realized by using a negative-resistance diode or a transistor. A DR is usually coupled to an oscillator circuit by placing it in close proximity to a microstrip line.  Off-chip quarter-wave resonators, in which piezoelectric material is used as the dielec- tric, are widely used in MSs. This high dielectric constant allows realizing physically small resonators with Q as high as 20,000.  Resonator-based oscillators have excellent jitter performance. The use of an off-chip LC tank or crystal makes MMIC integration difﬁcult. Bipolar and CMOS LC oscillator IC design has been discussed in [37].  Ring oscillators  The VCO is conventionally implemented in either BJT or GaAs MESFET technology, while most of the low-frequency digital circuits are implemented in CMOS technol- ogy. Recently, more and more oscillators are being designed based on the analog CMOS technology [32, 49]. The ring oscillator is usually used in bipolar or CMOS IC implementation.  The ring oscillator consists of a ring of N delay stages with a wire inversion, for N odd, and the ring oscillates with a period of 2N times the state delay. The oscillation frequency is given by  fosc = 1 2NTpd  ,   11.141   where Tpd is the propagation delay, which can be adjusted by changing the load or the current drive of the inverters. The current-starved ring oscillator is especially suitable for IC implementation [27]. The delay element is typically an inverter or a differential pair, corresponding to either single-ended or differential ring oscillator. The element delay is controlled by a bias voltage. The differential conﬁguration provides better common-mode rejection. The ring oscillator is shown in Fig. 11.42.  The ring oscillator is used as the VCO in jitter-sensitive applications. It has high speed and ease of integration. The ring oscillator is extremely popular, since it is derived from digital-like building blocks. Compared to resonator-based oscillators, ring oscillators have relatively large tuning range and are simple, but have substantially inferior phase noise performance since all the energy stored during one cycle is dissipated.   cid:2 Figure 11.42   a    b   Schematic of the ring oscillator.  a  Single-ended.  b  Differential.      443   cid:2   11.17 Frequency synthesis  Monolithic integrated ring oscillators require little silicon due to the absence of induc- tors. Voltage controlled ring oscillators are especially useful for designing as fully integrated, low-jitter clock-recovery PLLs. Jitter performance of a ring depends primar- ily on the individual gate and not on the number of gates in the ring or the ring operating frequency [32]. In addition, quadrature outputs can be extracted directly from an approx- imately selected pair of nodes in the ring, if the ring oscillator consists of four or more inverters.  Relaxation oscillators  The relaxation oscillator operates by alternately charging and discharging the energy stored in a capacitor or inductor by using a nonlinear device such as a transistor, causing abrupt changes in the output waveform. The relaxation oscillator is often used to produce a nonsinusoidal output, such as a square wave or sawtooth.  11.17 Frequency synthesis  The frequency synthesizer derives many frequencies from a stable oscillator, thus avoiding the use of multiple independent oscillators in a multichannel system. The stable oscillator is usually a crystal-controlled oscillator. Frequency synthesizers are used in almost all mod- ern wireless communication systems. Direct synthesis, PLL, and direct digital synthesis  DDS  are three common frequency synthesis methods.  Practical frequency synthesizers are usually a combination of the three methods. PLLs with a programmable divider, or direct digital synthesizers, are often com- bined with mixers to generate the desired frequencies. In this section, we introduce PLL and direct synthesis. DDS achieves the same goal as PLL, but in a differ- ent way. DDS generates the signal in digital domain, and then applies D A con- version and lowpass ﬁltering to obtain the analog waveform. DDS is introduced in Section 13.6.2.  11.17.1 Composition of phase-locked loops  A PLL is a closed-loop feedback control system that automatically adjusts the frequency of a controlled oscillator such as VCO until it matches the reference  input  signal in both frequency and phase. It is used to synchronize electronic tunable oscillators. A PLL has very good frequency accuracy and phase noise characteristics, but may have a long settling time. It can be implemented in either analog or digital form. The PLL is more widely used in modern wireless systems, especially where certain synchronization is required.  A PLL is composed of a phase detector, a lowpass ﬁlter, a variable oscillator such as VCO, and a negative feedback path with optional frequency divider. The architecture of a      444   cid:2   RF and microwave subsystems  XTAL  f ref φref  1 M  Phase detector  φe  −  Charge pump  K  PD  Lowpass  filter       F s  VCO  K       s VCO  f  o φ o   cid:2 Figure 11.43  1  N  Basic PLL model.  basic PLL is shown in Fig. 11.43. There may also be a divider in the reference path. The divider makes the output clock of the PLL a rational multiple of the reference, so that both input frequencies at the phase detector are the same and only the phases are compared at the phase detector. The phase detector compares the phase of the reference and that from the oscillator, and adjusts the charge pump to change the control voltage. The lowpass ﬁlter smoothes out the signal from the charge pump.  Phase detector, phase-frequency detector charge-pump  A phase detector generates an output voltage corresponding to the phase differ- ence between two input signals. For an ideal phase detector, the output signal con- tains a dc component, which is proportional to the phase difference of two input signals  vo = KPDφe,   11.142   where KPD is the gain of the phase detector.  Design of an analog phase detector is very similar to that of a balanced mixer [35]. A mixer can be used as a phase detector to transform the phase difference into the amplitude of a signal, after lowpass ﬁltering. The phase detector can be simply an exclusive-OR gate, , but cannot lock the JK-ﬂipﬂop, or S-R latch. It can maintain a phase difference of 90 signal unless the two frequencies are close.  ◦  A phase-frequency discriminator operates as a frequency discriminator for large initial errors and then as a coherent phase detector once the system falls within the lock range. It deﬁnes a simple ﬁnite-state machine to determine which signal has an earlier or more frequent zero-crossing. This two-step procedure ensures that the frequency is locked at the designed value. Typically, the phase-frequency discriminator is used with a charge pump to supply an amount of charge in proportion to the phase error. In a PLL, the charge pump can be used to amplify the phase error obtained by the phase detector, and to provide inﬁnite gain for a static phase difference [37]. A charge-pump PLL is also called a digital PLL. The charge pump is a current source that is turned on or off by the difference of the UP and DN signals of the phase-frequency discriminator, which is proportional to the phase frequency errors φe. The charge-pump output is Vcon = Kφe, which is used for VCO control.      445   cid:2   11.17 Frequency synthesis  VCO  The VCO can be made by using LC circuits, whose oscillation arises from charging and discharging a capacitor through an inductor. The voltage-controlled capacitor can be used to change the frequency of the LC oscillator in response to a control voltage. A reverse- biased semiconductor diode has voltage-dependent capacitance, and varactors are widely used in VCOs. LC-tuned oscillators, such as the Colpitts, Clapp or Hartley topology, achieve the low-noise requirements for wireless applications, and are suitable for bipo- lar and CMOS IC technologies [46]. The appropriate tuning range and phase noise are the two major design speciﬁcations. YIG  Yttrium Iron Garnet or ferrite sphere  resonators or varactor diodes can be used for tuning. YIG is a high-Q resonator, while varactors provide lower Q but a cheaper and more compact solution, dominating the commercial applications.  An ideal VCO is characterized by  where ω0 is the reference frequency. Thus the excess phase in the generated output signal is given by  ωo = ω0 + KVCOVcon,   cid:14   t  φo t  = KVCO  −∞ Vcondt.   cid:23 o s  Vcon s   = KVCO s  .   11.143    11.144    11.145   This corresponds to a transfer function  That is, changing phase is realized by changing frequency and then performing integration. The VCO phase noise can be modeled as an additive component. Analysis shows that the VCO phase noise experiences a highpass transfer function, and thus its contribution to the output phase can be lowered by increasing the bandwidth of the PLL [37].  Reference frequency  The reference frequency is generated by using a crystal oscillator. Crystals have very high Q, but are tunable within a very small frequency range. When an ac signal is applied to the crystal at a frequency near the mechanical resonance, it excites a mechanical vibration, which in turn generates a current ﬂow of an electrical resonance at the elec- trical terminals. For reference of very accurate high frequencies, SAW devices can be used.  Frequency multiplier  Frequency multipliers and frequency dividers are essential algebraic functions used in most synthesizer architectures. Diode multipliers can utilize either varactors, step recov- ery diodes, or Schottky diodes. Transistor multipliers are based on the device nonlinearity under large-signal conditions.      446   cid:2    cid:2 Figure 11.44  RF and microwave subsystems  R  vin  C  vout  One-pole RC lowpass ﬁlter.  Frequency divider  Frequency dividers can use either varactors or step-recovery diodes. The division ratio is usually 2. Digital dividers are more commonly used, and the division ratio can be ﬁxed or programmable. Digital dividers can be made of silicon or GaAs.  The dividers may be programmable to produce many frequencies from a single stable, accurate reference oscillator. The fractional-N PLL can have a VCO output frequency at an integer-plus-fractional multiple of the reference frequency. This can be achieved by also including a divider, 1 M, between the reference crystal and the reference input to the phase detector. In this case, the output frequency of the VCO is multiplied by N M. A fractional-N PLL can also be achieved by using an accumulator [42].  Loop ﬁlter  A lowpass ﬁlter is used to remove high-order harmonics. It can be a simple loop ﬁlter, such as a one-pole RC circuit. For the one-pole RC circuit, as shown in Fig. 11.44, the loop ﬁlter transfer function F s  = 1  1 + sRC .  11.17.2 Dynamics of phase-locked loops  The loop transfer function between the output phase φo and input reference phase φref is derived as  H s  = φo s  φref s   KVCO  = 1 M KPD 1 + 1  N KPD  s F s  KVCO  s F s   =  KPDKVCO  s2 + s  RC  MRC  + KPDKVCO  .  NRC   11.146   The last equality is for the one-pole RC loop ﬁlter. This is a second-order PLL, since the denominator is of the second degree in s. In this case, we can rewrite as  where the natural frequency of the loop ωn and the damping factor ζ are given by  H s  =  N M  ω2 n  ,  s2 + 2sζ ωn + ω2    n   cid:31   ωn =  KPDKVCO  ,  NRC  ζ = 1 2  N  KPDKVCORC   11.147    11.148   A more complex design enables the adjustment of ωn and ζ independent of each other.      447   cid:2   11.17 Frequency synthesis  10  5  0  −5  −10  −15     B d        ω   H    −20  10 −1  ζ=0.05  0.25  0.5  0.7 1 2 ζ=5  ζ=0.05  0.25  0.5  0.7  1  2  ζ=5  0  −30  −60  −90  −120  −150    s e e r g e d       ω   H ∠   cid:2 Figure 11.45  10 0 ω ω n  10 1  −180  10 −1  10 0 ω ω n  10 1  Amplitude and Phase response of H  jω .  All second-order loops are inherently stable. Note that a high-order loop ﬁlter can be used to replace the one-pole ﬁlter. However, each additional pole introduces phase shift, and stability is more difﬁcult to maintain [16]. To ensure stability the poles of H s  must be in the left half of the s plane. Most practical PLLs are second-order PLLs.  Example 11.3: The frequency and phase responses of the transfer function  11.147  are plotted in Fig. 11.45, for N M = 1. When ζ = 0.707, we get critical damping, and the maximally ﬂat frequency response for H ω . An ideal PLL should have a high ωn and ζ close to 0.707.  Accordingly, the loop error response can be derived as  = 1 M  − 1 N  H s  = 1 M  He s  = φe s  φref s  9 cid:12    cid:13    cid:17   s2 + 2 sζ ωn s2 + 2sζ ωn + ω2  cid:12   n  .   cid:13    cid:18   at the input, and can be obtained by the inverse Laplace transform of He s  s −ωn φe t  = 1 e 2M  ζ cid:25  ζ 2 − 1  ζ cid:25  ζ 2 − 1  √ ζ−  −ωn e  + 1  − 1  ζ 2−1  t −  The step error time response of the PLL is the phase error φe t  in response to a unit step   11.149   :   cid:18    cid:17   √ ζ+  ζ 2−1  t   11.150   for t > 0.  Example 11.4: The time-domain response of the phase error, given by  11.150 , is plotted in Fig. 11.46. It is seen that at ζ = 0.707 the maximally ﬂat frequency response is achieved. −ζ ωnt, until it is stabilized at the The typical transient response of a PLL is enveloped by e ﬁnal frequency.      448   cid:2   RF and microwave subsystems  1  0  0.5    t    e  φ  −0.5  ζ=5  2  1  0.7 0.5  ζ = 0.25   cid:2 Figure 11.46  10 −1 Time-domain response of φe for a step input, M = 1.  ωnt  10 0  10 1  10 2  The 3-dB bandwidth of the loop is given by [35]   cid:2    cid:21    cid:3 1 2  B = ωn  1 − 2ζ 2 +  2 − 4ζ 2 + 4ζ 4  and the acquisition time of the PLL is given by Ta = 2.2 B  .   11.151    11.152   Tracking and acquisition characteristics are important aspects of a PLL. The lock time is typically deﬁned in terms of the phase difference between the input and output. For a wide tracking and acquisition frequency range, most PLLs also incorporate frequency comparison. When the VCO is far from the input frequency, frequency detection is started so as to drive the VCO frequency closer to the input frequency. When the two frequencies are sufﬁciently close, phase detection is started for ﬁnal phase-locking. A phase frequency detector can be used for this purpose [37]. National Semiconductor provides a number of PLLs from 50 MHz to 5 GHz and integrated PLL plus VCO from 0.8 GHz to 2.4 GHz.  11.17.3 Direct frequency synthesis  In order to realize an output frequency that is a multiple of the input frequency, in the feedback path of the PLL  Fig. 11.43 , a division ratio 1 N is applied, and the division is the modulus operation. This can achieve ωout = Nωin. This is very important for RF synthesizers.  Usually, we need to generate an output frequency given by  fout = f0 + kfch   11.153       449   cid:2   11.18 Automatic gain control  A1f  f A2 A3f fA4  Af  Filter  f  B  fC  Filter  f o   cid:2 Figure 11.47  f  B1  f  B2  f  B3  fB4  f  C1  f  f  f  C2 C3  C4  C5  f  An example of direct frequency synthesis.  where f0 is the lower end of the range, the integer k is used to select the channel, and fch is the bandwidth of each channel. PLLs must be used to maintain the exact relationship between the input and output frequencies, in locked state.  A direct frequency synthesizer creates its output frequency by mixing two or more sig- nals to produce sum or difference frequencies, using frequency multiplication, frequency division, or their combination. The reference source is often a temperature-controlled crys- tal oscillator  TXCO . Selection of different output frequencies is performed by using switches. This approach achieves fast frequency switching and low phase noise, but is more hardware intensive and expensive, and generates a large number of spurious signals. It is not very ﬂexible for generating all desirable frequencies. It requires a large number of reference oscillators. A direct frequency synthesizer is illustrated in Fig. 11.47. The output frequency is given as fo = fA ± fB ± fC. All together 13 reference oscillators are used, and 4 × 4 × 5 = 80 different combinations of frequency are obtained. This approach is now mainly used for RF test and measurement.  A number of RF synthesizer architectures such as integer-N, fractional-N, and dual- loop architectures are discussed in [37]. These architectures can be used to generate many different types of input to output frequency relations.  11.18 Automatic gain control  For wireless receivers, the dynamic range of the received signal may be up to 100 dB or more, due to power ﬂuctuations arising from shadowing and fading. In order to track the fast ﬂuctuations, an AGC with good tracking capability is used. An AGC is absolutely necessary to raise the MDS to a level of a few milliwatts  dBm  so that the ADC can correctly quantize the signal. The total gain should be well distributed among the RF, IF and baseband stages. A moderate gain at RF is necessary to prevent too high a 1-dB compression point or IP3 and to set a good noise ﬁgure for the receiver.  While most of the gain can be ﬁxed at different stages, an AGC with a range of 20 to 60 dB may usually be used to adapt the receiver to different levels of the received signal. It is common to implement AGC at the IF stage, as shown in Fig. 11.48, so that the AGC will attenuate the signal and any noise inserted by the IF ampliﬁer in the same proportion to      450   cid:2   RF and microwave subsystems  IF amp.  VGA  ADC  Rectifier  LNA  dc reference   cid:2 Figure 11.48  LPF  Architecture of an AGC circuit.  maintain a constant noise ﬁgure while the overall receiver gain is variable. The AGC loop is in general a nonlinear system with a gain acquisition time depending on input signal level. With a logarithm function applied to the RSSI or rectiﬁer output, the AGC system can operate linearly in decibel. The rectiﬁer is a rms-to-dc converter.  The AGC processes information in the digital domain, and sends control information to the analog component. The analog component then adjusts its power level prior to A D conversion. Depending on the sum of the ﬁxed gains at different stages, the AGC circuit may compensate as a variable gain ampliﬁer  VGA  or attenuate as a variable voltage- controlled attenuator. The ﬁnal output signal at the ADC or demodulator is detected and rectiﬁed to a dc signal, which is compared with a reference level. The result is ampliﬁed, lowpass ﬁltered, and then used as the control to the AGC circuit.  The VGA can be implemented by varying the gain of an RF transistor ampliﬁer, and the attenuator can be realized by using a PIN diode attenuator. The PIN diode attenuator generally results in lower power drain, less frequency pulling, and lower RF signal distor- tion, especially when using diodes with thick I regions and long carrier lifetimes. Using the PIN diode, wide dynamic range attenuation with low signal distortion can be achieved at frequencies ranging from below 1 MHz up to well over 1 GHz [47].  At the RF stage, the input signal is strictly restricted to the linear section to avoid  saturation. This requires the maximum received signal power Si,max to satisfy  Si,max + GRF < min  P1, P3  ,   11.154   where GRF is the gain of the RF stage, and P1 and P3 are, respectively, the 1-dB compres- sion point and IP3. An AGC attenuator at the RF stage helps to reduce saturation, but it also degrades the noise ﬁgure.  Feedforward AGCs have a more rapid tracking capability than feedback AGCs, but feed- back AGCs are more robust to misadjustment or errors. Feedback AGCs use the RSSI value and a gain control ampliﬁer. Feedback AGCs are based on the signal power error.  Amplitude acquisition using AGC circuits usually occurs during a preamble duration. The preamble duration must exceed the acquisition time of the AGC loop but should be as small as possible to reduce channel bandwidth. A generalized design of AGC circuits that have constant settling time is available [24]. The settling time is independent of the absolute gain, and the method is applicable for an arbitrary monotonic nonlinear function in the gain control characteristic of the VGA. The method is also fully applicable to digital AGC loops. A digital programmable dB-linear CMOS AGC is described in [13], and a cascode 6-bit digitally controlled AGC implemented. In CMOS technology, most VGAs      451   cid:2   11.19 MICs and MMICs  are implemented by using binary weighted arrays of resistors or capacitors, and these arrays are digitally controlled, leading to discrete gain steps.  In the superheterodyne structure, the gain control is continuous. In the direct-conversion receiver, discrete step gain control is implemented for both the I and Q channels in the baseband in order to minimize the mismatch between the two channels. For the low-IF architecture, the receiver AGC is very similar to that of the direct-conversion receiver.  11.19 MICs and MMICs  MICs and MMICs are used when the volume is high. In an MIC, a number of discrete active and passive components are externally attached to an etched circuit on a common substrate. An MMIC is a microwave circuit in which all active and passive components are made on one piece of semiconductor substrate. The frequency of operation can range from 1 GHz to above 100 GHz.  MMICs typically have a performance inferior to standard hybrid MICs. This is because of the low Q of the passive components in MMIC implementation. But MMICs are more compact, more reliable, more cost-effective for mass production than hybrid MICs, and have very good reproducibility. Hybrid MICs are cheaper for simple circuits. Hybrid MICs may be preferable for LNAs and power ampliﬁers, since the best transistors can be selected.  11.19.1 Major MMIC technologies  Today, GaAs, silicon  Si  bipolar, and BiCMOS techniques constitute the major portion of RF IC market [37]. The GaAs FET and heterojunction devices offer high power toler- ance, but are usually a low-yield, high-cost solution. Most power ampliﬁers and front-end switches employ GaAs technologies. On the contrary, silicon technologies are more suit- able for a higher level of integration in VLSI technology, and thus provide a cheap solution. A BiCMOS technology can incorporate SiGe HBTs into the CMOS technology. This achieves a tradeoff between performance and cost.  GaAs has been more widely used than silicon for MMICs, since it is suitable for both high-frequency transistors and low-loss passive components. The vast majority of MMICs above a few GHz are based on GaAs MESFET. Improvements on the silicon bipolar devices make them suitable for over 25 GHz, and most applications up to 5 GHz are domi- nated by silicon [41]. In recent years, heterojunction devices with both materials have been produced.  The GaAs MESFET technology is easily fabricated using ion-implantation, and has good noise ﬁgure and output power performance. It can be used for circuits operating up to 30 GHz. The GaAs-based pseudomorphic HEMT has a considerably larger transconduc- tance than the MESFET, and can operate at over 100 GHz. The GaAs HBT has a very high gain, and offers exceedingly high power density and efﬁciency. Due to its large parasitic resistance and capacitance, its noise ﬁgure is considerably higher than that of HEMTs [41].      452   cid:2   RF and microwave subsystems  Silicon bipolar technology has advanced rapidly, and SiGe HBTs can operate at over 25 GHz. Silicon bipolar technology can be readily integrated with conventional CMOS digital IC technology, leading to the BiCMOS process that achieves digital analog circuit integration.  CMOS technology has also been applied to RFIC MMIC design for up to a few GHz. Recently, a number of millimeter-wave single-chip transmitters and receivers have been fabricated in CMOS technology [20, 25]. The application of silicon technology to MMIC is desirable, since it is a mature technology in the digital market and is cheap. CMOS technology is receiving active research in RF IC design.  11.19.2 Approach to MMIC design  MMIC design can employ the all-transistor technique, the lumped-element technique, or the distributed-element technique [41]. The all-transistor technique is suitable when the operating frequency is below 5 GHz, beneﬁting from the low capacitance of the microwave transistor. It has high packing density, and has been popular in wireless communications. The RF CMOS, silicon bipolar, and GaAs HBT technologies are more suitable for the all-transistor technique.  When the frequency is above 5 GHz, the capacitances at the input and output of the transistors introduce much higher impedances, and the all-transistor technique is not appli- cable. The lumped-element method is suitable for the frequency range below 20 GHz, and the classical type of MMIC employs the lumped-element method. Figure 11.49 shows an MMIC ampliﬁer operating at 1 GHz to 2 GHz. This method is featured by the spiral inductors. It offers higher performance in terms of noise ﬁgure and power handling than the all-transistor technique. A large number of passive components are used for matching networks.  When the frequency is above 20 GHz, the spiral inductors will generate self-resonance, and the distributed design approach is suitable. The distributed elements are typically  Output  Input  VD  VG   cid:2 Figure 11.49 A 1 to 2 GHz MMIC ampliﬁer using the lumped-element technique.  a  Photograph.  b  Circuit   a    b   diagram. From [41] Fig.1.9. c cid:2 IEE.      453   cid:2   11.19 MICs and MMICs  designed by using microstrip or coplane waveguide. Microstrip is more widely used in MMIC design. Coplane waveguide is extensively used for millimeter-wave circuits, since it provides low dispersion and low inductance grounding. Using the coplane waveguide or other coplanar techniques, through-substrate via-holes are not required for grounding, thus the packing density can be increased; moreover, lumped elements exhibit less parasitic capacitance [41]. The lowest frequency of operation is determined by the chip size.  The majority of MMIC designs is based on the traditional microstrip design developed for hybrid MICs, where passive components take more area than active devices. Multi- layer techniques and micromachined passive components are used to make more compact packaging or to improve the performance of the circuits.  Computer-aided design techniques are an integral part of MMIC design. For RF IC design, computer-aided design tools are still in their infancy, and designers have to rely on experience and approximate simulation techniques. The standard SPICE software is used for ac analysis and is based on linear, time-invariant models, and thus is not suitable for RF circuits due to nonlinearity, time variance, and noise. Major computer-aided design pack- ages for MMIC design are Ansoft’s Serenade Desktop, Agilent’s Advanced Design System  ADS , and Applied Wave Research  AWR ’s Microwave Ofﬁce. These software packages typically contain or interface with some linear simulators as well as EM solvers for design simulation. Cadence’s Analog Artist is ideally suited for low RF frequency MMIC designs. A good monograph that addresses all major aspects of MMIC design is [41].  11.19.3 Passive lumped components  The inductor and the capacitor are two critical passive devices used in RF ICs. The inductor is used for ﬁltering, isolation, and compensation for parasitic capacitors, and the capaci- tor is used for ac coupling, ﬁltering, and decoupling of supply voltages. The resistor is also used in RF ICs. The via-hole is an essential component for all but the most simple microwave circuits. It provides a low inductance grounding within the circuit.  Planar microwave lumped inductors and capacitors have physical dimensions that are much smaller than the free space wavelength of the highest operating frequency. Due to the small size, they are particularly useful for MMICs. But they have lower Q and lower power handling capability than distributed elements. Lumped components are suitable only when the total line length of a lumped inductor or overall size of a lumped capacitor is a small fraction of a wavelength. However, this is usually not satisﬁed, and other parasitics also degrade the accuracy of the model. In this case, the basic design equations can only be used for initial design, and a full-wave EM solver is used to validate and optimize the design.  Resistors  In RF IC design, on-chip resistors can be realized by many methods. The deposited thin- metal resistor has the lowest resistance. The doped semiconductor layer, such as mesa resistors, implanted planar resistors, well resistors and polysilicon resistors can also be      454   cid:2   RF and microwave subsystems  L  R   cid:2 Figure 11.50 Lumped-inductors.  a  Straight-line inductor.  b  Circular spiral inductor.  c  Their circuit   a    b    c   representation.  implemented. Thin-ﬁlm resistors have better linearity and lower temperature coefﬁcients than GaAs mesa resistors.  Lumped inductors  A high-impedance, straight-line section is a form of inductor. It can be used for low induc- tance values up to 3 nH. A spiral inductor can provide larger inductance, typically 10 nH. These models can be characterized by an inductor in series with a resistor. The induc- tance can be calculated from the physical dimensions, and the approximate equations for inductance L and the associated resistance R are given for the straight-line inductor and the circular spiral inductor in [6, 19], and other structures in [6]. The inductance of one single turn is smaller than that of a straight line with the same length and width, due to the proximity effect.  The unloaded Q of an inductor is deﬁned by Q = ωL R  .   11.155   Straight-line and circular spiral inductors are shown in Fig. 11.50.  Spiral inductors of square and octagonal shapes are also used. The circular spiral induc- tor is most area-efﬁcient, but it requires inﬁnite angle step. Octagonal inductors are the most popular inductors on chip. The realization of a spiral inductor requires two layers of metal, and an airbridge or a dielectric via hole for the connection to the center of the inductor. The single-layer air core inductor is also practical, and it consists of a single layer of turns and uses air as the dielectric.  Lumped capacitors  The interdigital capacitor is usually used as a lumped-element capacitor for capacitance less than 1.0 pF, above which its size leads to considerable distributed effects. The metal- insulator-metal  MIM  capacitor can achieve higher capacitance such as 30 pF. These capacitors can be modeled by a capacitor C in series with a resistor R. There are also capacitors with nonlinear characteristic with respect to voltage, such as MOS caps and var- actors. A varactor is a variable capacitor and is usually made of an active device such as a PN diode or a MOSFET. It is mainly used to tune the resonant frequency of an LC tank such as in a VCO.      455   cid:2   11.19 MICs and MMICs  l  w  s  C  R   cid:2 Figure 11.51   a    b   The interdigital capacitor and its circuit representation.  The MIM capacitor is constructed as a thin layer of low-loss dielectric between two  metal plates. The capacitance is given by  C = A cid:21 0 cid:21 r d  ,   11.156   where A is the area of each plate,  cid:21 r is the relative permittivity, d is the dielectric thickness, and  cid:21 0 is the free space permittivity.  For the interdigital capacitor, as shown in Fig. 11.51, when the ﬁnger width W equals the ﬁnger spacing s, the maximum capacitance density is achieved; in this case, if the substrate thickness h  cid:7  W, the capacitance is given by a very simple closed-form expression [1, 19]  C = 3.937 × 10  −5l   cid:21 r + 1  [0.11 n − 3  + 0.252]   pF ,   11.157   where l is in μm, n is the number of ﬁngers, and  cid:21 r is the relative dielectric constant of the substrate. The resistance is given by  where Rs is the surface resistance rate of the conductor in ohms m2.  The quality factor Q for the capacitor is deﬁned by  The MIM capacitor has a high Q in general.  R = 4 3  Rsl Wn  ,  Q = 1 ωCR  .  11.19.4 RF CMOS   11.158    11.159   The entire RF front-end can be integrated into an MMIC. The GaAs process is more popu- lar than Si CMOS technology. However, in recent years, more attention is being paid to the low-cost RF CMOS technology. RF CMOS technology is preferable for low cost and better integration with DSP chips, but it has limitations in terms of noise and linearity properties when compared with GaAs and SiGe processes.      456   cid:2   RF and microwave subsystems  I  +  I  –  M1  od + V  0.5  V  in  M2  od − V  0.5  Vin   cid:2 Figure 11.52  A common-source grounded MOSFET pair used as a linear transconductor cell.  Linearity in RF CMOS  High linearity is required for a system with a large dynamic range. This requires the transconductance of a linear MOSFET to be constant over the input voltage. From  11.122 , the transconductance depends on the input voltage, which indicates a nonlinear property of the MOSFET. For the long-channel MOSFET, only the second-order distortion can be can- celled at the output by using a differential design. A common-source grounded MOSFET pair, as shown in Fig. 11.52, is usually used as a linear transconductor cell. Most CMOS circuits are based on the use of linear transconductors.  For long-channel MOSFET pair, the output current is derived as [11]  Iout = I+ − I− = μnCox  W L  VodVin.   11.160   For short-channel MOSFETs, odd-order distortion is generated at the output even with a differential design. This is characterized by the input referred voltage IP3, which increases with Vod. The dc power consumption also increases with Vod, and thus a compromise between linearity and power consumption must be made. A larger channel length L leads to a higher linearity, but a slower circuit response.  The MOSFET has a lower linearity than the GaAs FET and BJT under the same con- ditions. The linearity of the differential pair is not sufﬁcient for most RF circuits, and linearization techniques are often used to improve the basic differential pair. A lineariza- tion technique using harmonic cancellation is given in [11]. It is a feedforward technique in which the unwanted harmonics are cancelled. This technique has been applied to the common-gate LNA, common-source LNA, and a double-balanced Gilbert mixer in CMOS. A MOSFET has a lower IP3 than a GaAs device. In the CMOS implementation, the Gilbert multiplier cell is very widely used in mixers and AGC ampliﬁers. Designs of LNAs, mixers, and power ampliﬁers using CMOS technology are given in detail in [27].  11.19.5 Impedance matching  In order to match an RF IC to a standard external impedance such as 50 ohms, a match- ing network is implemented in the RF IC. The quarter-wave transformer, which uses a transmission line of a quarter wavelength, is a popular solution to impedance matching.      457   cid:2   Problems  L  Z  l  C  Z  h   cid:2 Figure 11.53  LC network for impedance matching.  However, due to the size restriction, it is seldom used in RF ICs. Instead, an LC network, known as L-match, as shown in Fig. 11.53, is usually used in RF ICs [11, 27, 39].  The L-match circuit realizes a transform  where QC is the quality factor of the capacitor C, and Zl and Zh are the low and high impedance at the resonant frequency ω0 = 1   ,  Zl = Zh Q2 C √ LC. There is relation ≈ QL = ω0L Zl  .  QC = 1 ω0CZh   11.161    11.162   The lattice-type LC balun can be derived from an L-match network. It is used for power- combining in RF ICs [39].  Problems  11.1 Consider an IS-95 system. Assume the path loss of 140 dB in a rural environment, a frequency of 860 MHz, a transmit antenna gain of 10 dB, a receive antenna gain of 0 dB, a data rate of 9.6 kbits s, antenna feed line loss of 8 dB, and all other loss of 15 dB, a fade margin of 8 dB, and a required Eb N0 of 9.6 dB, the receive ampliﬁer gain of 18 dB, the total noise ﬁgure of 6 dB, and a noise temperature of 290 K, and a link margin of 8 dB. Determine the total transmit power required.  11.2 An rms voltmeter  assumed noiseless  having an effective noise bandwidth of 20 MHz is used to measure the noise voltage of a 10-k cid:20  resistor at room temperature. What is the meter reading?  11.3 A pager operating at a center frequency of 100 MHz has a noise bandwidth of 10 kHz. If the antenna efﬁciency is 40 percent and the noise ﬁgure is 10 dB, what is the minimum signal power into the receiver for a SNR of 5 dB?  11.4 For a lossless microstrip line with width a and dielectric strip thickness d, the capac- itance per unit length is C =  cid:21  a a . What is the characteristic impedance?  d and the inductance per unit length is L = μ d      458   cid:2   RF and microwave subsystems  From antenna  1G = −3 dB NF1 = 3 dB  Cable  2G = −3 dB NF2 = 2 dB  3G = 8 dB NF3 = 2 dB  BPF  LNA  NF4 = 4 dB  To IF stage  LO   cid:2 Figure 11.54  Figure for Problem 11.6.  11.5 Explain why the single-wire transmission line is rarely used compared to waveguide or coaxial lines.  11.6 The block diagram of an RF stage of a receiver is shown in Fig. 11.54. The signal from the antenna is connected by the cable to the BPF, then to the LNA, and the output of the mixer is passed to the IF stage. Calculate the noise ﬁgure. If the BPF and the LNA are placed before the cable, what is the noise ﬁgure? 11.7 Given a QPSK signal x t  = A cos ωt + B sin ωt, where A, B = ±1. Due to nonideal LOs, the I Q mismatch at LO is modeled as  ILO t  =  1 +  cid:21  A cos ωt − θ , QLO t  =  1 −  cid:21  B sin ωt + θ .  Plot the constellation diagram of the downconverted baseband signal for θ = 10  cid:21  = 0.2. Compare it with that of ideally demodulated QPSK. 11.8 Given a signal level of −100 dBm, the signal bandwidth of 1 MHz, C N = −2 dB for demodulation, and an interfering tone of 71 dB above the signal at 900 kHz offset from the desired signal, for a superheterodyne receiver, what is the required phase noise of the LO in dBc Hz? Assume the phase noise is constant.  and  ◦  11.9 Determine the available power in dBm at room temperature in a 10 MHz bandwidth for a resistance R = 100 k cid:20 .  Hint: the noise power P = kTB.  11.10 A GEO satellite is used as a regenerative repeater. For the satellite-to-earth link, the satellite antenna has a gain of 8 dB, the earth station antenna has a gain of 50 dB. The center frequency for the downlink is 3.5 GHz, and the signal bandwidth is 1 MHz. For required communication the Eb N0 is required to be 10 dB. What is the transmitted power for the satellite? Assume N0 = 4 × 10 11.11 A transmission line has the parameters: L = 0.2 μH m, C = 400 pF m, R = 4  cid:20  m, and G = 0.01 S m. Calculate the propagation constant and the characteristic impedance of the line at 1 GHz. What are results in the absence of loss  R = G = 0 ? 11.12 The transmission line parameters of a coaxial line are given by [36]  −20 W Hz.  ln  b a  L = μ  cid:2  2π  R = Rs 2π  1 a  + 1 b   H m , C = 2π  cid:21  cid:14   cid:3   ln b a     cid:20  m , G = 2π ω cid:21  cid:14  cid:14    F m ,   S m ,  ln b a       459   cid:2   Problems  where a, b are the radii of the inner and outer conductors, Rs is the surface resistivity of the inner and outer conductors, the material ﬁlling the space between the conductors has a complex permittivity  cid:21  =  cid:21  cid:14  − j cid:21  cid:14  cid:14  =  cid:21  cid:14   1 − j tan δ  and a permeability μ = μ0μr. The RG-402 U semi-rigid coaxial cable has an inner conductor diameter of 0.91 mm, and the inner diameter of the outer conductor of 3.02 mm. The conductors are copper, and the dielectric material is Teﬂon. Calculate R, L, G, C at 1 GHz. Compare your results to the manufacture’s speciﬁcations of 50  cid:20  and 0.43 dB m, and explain the reason for the difference. The dielectric constant of Teﬂon  cid:21 r = 2.08, tan δ = 0.0004 at 25 ◦ . For copper, σ = 5.813 × 107 S m, the skin depth δs = 11.13 Design a quarter-wave transformer to match a 50- cid:20  to a 75- cid:20  cable. Plot the VSWR for 0.5 ≤ f  f0 ≤ 2.0, where f0 is the frequency at which the line is λ 4 long. 11.14 Design a microstrip line with Z0 = 100  cid:20 . The substrate thickness is 0.128 cm, with  cid:21  = 2.20. What is the guided wavelength on this line at 2.0 GHz? 11.15 Given a four-port network with the scattering matrix  ωμσ , and Rs = 1   cid:21   σ δs  2  .  ⎡⎢⎢⎣ 0.2e j90  ◦ 0.8e j−45 ◦ ◦ 0.2e j45  0  S =  0.8e j−45  ◦  ◦  0.2e j45  0 0  0 0  ◦  0.3e j45  0.7e j−45  ◦  0  ◦ 0.3e j45 0.7e j−45 ◦  0  ⎤⎥⎥⎦ ,   a  Is the network lossless?  b  Is the network reciprocal?  c  Find the return loss at port 1 when all other ports are matched with loads.  d  Find the insertion loss and phase delay between ports 2 and 4, when all other ports are matched with loads.  11.16 A nonlinear device is governed by the law  v2 t  = a1v1 t  + a2v2  1 t ,  where v1 t  is input, v2 t  is output, and a1 and a2 are constants. Assume the input is an AM signal  v1 t  = Ac [a + kam t ] cos 2πfct .  Determine the output v2 t . What is the condition for restoring the message signal m t  from v2 t ? 11.17 A satellite system has a downlink C N0 of 80 dB·Hz. The parameters of the links are: The EIRP of the satellite is 55 dBW, downlink carrier frequency is 12.2 GHz, the data rate is 10 Mbits s, the C N0 required at the earth receiver is 10 dB, the distance between the satellite and the earth receiver is 41,000 km. Assume that the efﬁciency of the dish antenna is 50%, and the ambient temperature is 310 K. Determine the diameter of the dish antenna at the receiver.      460   cid:2   RF and microwave subsystems  fR  Crystal  controlled oscillator  Fixed  frequency divider  N 2  Phase detector  Amplifier  LPF  VCO  fo   cid:2 Figure 11.55  Programmable  frequency divider N 1  Figure for Problem 11.25.  11.18 Given the link: The transmitter power is 30 dBm, transmitter antenna gain is 5 dB, receiver antenna gain is 1.5 dB, line loss at the transmitter is 2 dB, line loss at the receiver is 1.5 dB, fade margin is 15 dB, noise PSD is −173 dBm Hz, a bit rate of 384 kbits s, and the required Eb N0 is 24 dB. Determine the maximum allowable path loss.  11.19 Calculate the power reﬂected to the source by an antenna with a VSWR of 2.0 for an input power of 1W.  11.20 A coaxial three-way power divider has an input VSWR of 1.6 over a frequency range of 2.4 to 3.0 GHz. What is the return loss? If the insertion loss is 0.5 dB, what are the percentages of power reﬂection and transmission?  11.21 Given two linearly polarized antennas in free space oriented at 10 Calculate the polarization mismatch loss.  ◦  to each other.  11.22 A BS transmits a power of 20 W into a feeder cable with a loss of 8 dB. The transmit antenna has a gain of 10 dB in the direction of the receiver. The receiver has a antenna gain of 0 dB, a feeder loss of 3 dB, and a sensitivity of −104 dBm. Calculate the EIRP and the maximum acceptable path loss.  11.23 A receiver has a noise bandwidth of 200 kHz and requires a input SNR of 9 dB for an input signal of −98 dBm. Determine the maximum allowable value of the receiver noise ﬁgure, and the equivalent input noise temperature of such a receiver.  11.24 A receiver operating at room temperature has a noise ﬁgure of 6 dB and a bandwidth of 1 GHz. The input 1-dB compression point is 1 dBm. Find the minimum detectable signal and dynamic range.  11.25 Determine the output frequencies of the frequency synthesizer shown in Fig. 11.55 for N1 = 20 and N1 = 30. Assume that fR = 1 MHz and N2 = 100. 11.26 Compare the advantages and disadvantages of the MMIC, HMIC, and hybrid printed circuit approaches.  11.27 For Problem 10.20, the designed antenna is fed by a 50- cid:20  microstrip line and a quarter-wave transformer is used for impedance matching. Find the dimensions of the feed line and the quarter-wave transformer. Draw the design. 11.28 A 10-dB directional coupler has a directivity of 40 dB. If the input power P1 = 1 W, calculate the power output at the other three ports.      461   cid:2   References  References  [1] G. D. Alley,  Interdigital capacitors and their application to lumped-element microwave integrated circuits. IEEE Trans Microwave Theory & Techniques, 18:12  1970 , 1028–1033.  [2] P. M. Asbeck, L. Larson, Z. Popovic & T. Itoh, Power ampliﬁer approaches for high efﬁciency and linearity. In T. Itoh, G. Haddad & J. Harvey, eds., RF Technologies for Low Power Wireless Communications  New York: Wiley-IEEE, 2001 , pp. 189–227. [3] I. J. Bahl & R. Garg, Simple and accurate formulas for microstrip with ﬁnite strip  thickness. Proc. IEEE, 65  1977 , 1611–1612.  [4] E. R. Brown, RF MEMS switches for reconﬁgurable integrated circuits. IEEE Trans.  Microwave Theory Tech., 46:11  1998 , 1868–1880.  [5] E. R. Brown & J. F. Harvey, System characteristics of quasi-optical power ampliﬁers.  IEEE Circ. Syst. Mag., 1:4  2001 , 22–36.  [6] M. Caulton, S. P. Knight & D. A. Daly, Hybrid integrated lumped-element microwave  ampliﬁers. IEEE Trans. Microwave Theory Tech., 16:7  1968 , 397–404.  [7] D. C. Cox, Linear ampliﬁcation with nonlinear components. IEEE Trans. Commun.,  [8] S. C. Cripps, Advanced Techniques in RF Power Ampliﬁer Design  Boston: Artech  [9] S. C. Cripps, RF Power Ampliﬁers for Wireless Communications, 2nd edn  Boston:  [10] H. J. De Los Santos, RF MEMS Circuit Design for Wireless Communications  Boston:  [11] Y. Ding & R. Harjani, High-Linearity CMOS RF Front-End Circuits  New York:  [12] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework  [13] H. O. Elwan, T. B. Tarim & M. Ismail, Digitally programmable dB-linear CMOS  AGC for mixed-signal applications. IEEE Circ. Devices Mag., 14:4  1998 , 8–11.  [14] A. Grebennikov, RF and Microwave Power Ampliﬁer Design  New York: McGraw-  Hill, 2005 .  [15] M. L. Edwards & J. H. Sinsky, A new criterion for linear 2-port stability using a single geometrically derived parameter. IEEE Trans. Microwave Theory Tech., 40:12  1992 , 2303–2311.  [16] W. E. Egan, Phase-Lock Basics  New York: Wiley, 1998 . [17] E. O. Hammerstard, Equations for microstrip circuit design. In Proc. 5th European  Microwave Conf., Hamburg, Germany, Sep 1975, 268–272.  [18] J. Harvey, E. R. Brown, D. B. Rutledge & R. A. York, Spatial power combining for  high-power transmitters. IEEE Microwave Mag., 1:4  2000 , 48–59.  [19] J.-S. Hong & M. J. Lancaster, Microstrip Filters for RF Microwave Applications  New  York: Wiley, 2001 .  22:12  1974 , 1942–1945.  House, 2002 .  Artech House, 2006 .  Artech House, 2002 .  Springer, 2005 .   London: Springer, 2006 .      462   cid:2   RF and microwave subsystems  [20] D. Huang, R. Wong, G. Qun, N. Y. Wang, T. W. Ku, C. Chien & M.-C. F. Chang, A 60 GHz CMOS differential receiver front-end using on-chip transformer for 1.2 volt operation with enhanced gain and linearity. In IEEE Symp. VLSI Circuits Dig., Honolulu, HI, Jun 2006, 144–145.  [21] A. Ismail & A. Abidi, A 3–10-GHz low-noise ampliﬁer with wideband LC-ladder  matching network. IEEE J. Solid-State Circ., 39:12  2004 , 2269–2277.  [22] P. Jardin & G. Baudoin, Filter lookup table method for power ampliﬁer linearization.  IEEE Trans. Veh. Tech., 56:3  2007 , 1076–1087  [23] D. Kee, I. Aoki, A. Hajimiri & D. B. Rutledge, The class-E F family of ZVS switching  ampliﬁers. IEEE Trans. Microwave Theory Tech., 51:6  2003 , 1677–1690.  [24] J. M. Khoury, On the design of constant settling time AGC circuits. IEEE Trans. Circ.  Syst. II, 45:3  1998 , 283–294.  [25] E. Laskin, M. Khanpour, R. Aroca, K. W. Tang, P. Garcia & S. P. Voinigescu, A 95 GHz receiver with fundamental-frequency VCO and static frequency divider in 65 nm digital CMOS. In Proc. ISSCC, San Francisco, CA, Feb 2008, 180–181.  [26] T. H. Lee & A. Hajimiri, Oscillator Phase Noise: A Tutorial. IEEE J. Solid State Circ.,  35:3  2000 , 326–336.  [27] T. H. Lee, The Design of CMOS Radio-Frequency Integrated Circuits, 2nd edn   Cambridge, UK: Cambridge University Press, 2004 .  [28] D. B. Leeson, A simple model of feedback oscillator noise spectrum. Proc. IEEE,  54:2  1966 , 329–30.  [29] J. G. Ma, Design of CMOS RF ICs for wireless applications: system-level com- promised considerations. In J. G. Ma, ed., Third Generation Communication Sys- tems: Future Developments and Advanced Topics  Berlin: Springer, 2004 , pp. 199–236.  [30] R. R. Mansour, Filter technologies for wireless base stations. IEEE Microwave Mag.,  [31] G. L. Matthaei, L. Young & E. M. T. Jones, Microwave Filters, Impedance-Matching  Networks, and Coupling Structures,  Dedham, MA: Artech House, 1980 .  [32] J. A. McNeill, Jitter in Ring Oscillators. IEEE J. Solid-State Circ., 32:6  1997 ,  5:1  2004 , 68–74.  870–879.  [33] A. Patnaik & R. K. Mishra, ANN techniques in microwave engineering. IEEE  Microwave Mag., 1:1  2000 , 55–60.  [34] M. W. Pospieszalski, Extremely low-noise ampliﬁcation with cryogenic FETs and  HFETs: 1970–2004. IEEE Microwave Mag., 6:3  2005 , 62–75.  [35] D. M. Pozar, Microwave and RF Wireless Systems  New York: Wiley, 2001 . [36] D. M. Pozar, Microwave Engineering, 3rd edn  New York: Wiley, 2005 . [37] B. Razavi, RF Microelectronics  Upper Saddle River, NJ: Prentice Hall, 1998 . [38] G. M. Rebeiz & J. B. Muldavin, RF MEMS switches and switch circuits. IEEE  Microwave Mag., 2:4  2001 , 59–71.  [39] P. Reynaert & M. Steyaert, RF Power Ampliﬁers for Mobile Communications   Dordrecht, The Netherlands: Springer, 2006 .  [40] J. D. Rhodes, A lowpass prototype network for microwave linear phase ﬁlters. IEEE  Trans. Microwave Theory Techn., 18:6  1970 , 290–301.      463   cid:2   References   London: IEE Press, 2001 .  Wiley, 1997 .  Theory, 9:1  1962 , 29–32.  [41] I. D. Robertson & S. Lucyszyn  ed , RFIC and MMIC Design and Technology  [42] U. L. Rodhe, Microwave and Wireless Synthesizers: Theory and Design  New York:  [43] J. Rollett, Stability and power gain invariants of linear two-ports. IRE Trans. Circ.  [44] C. C. W. Ruppel, L. Reindl & R. Weigel, SAW devices and their wireless communi-  cations applications. IEEE Microwave Mag., 3:2  2002 , 65–71.  [45] A. Rusu, D. R. D. L. Gonzalez & M. Ismail, Reconﬁgurable ADCs enable smart radios for 4G wireless connectivity. IEEE Circ. & Devices Mag., 22:3  2006 , 6–11. [46] C. Samori, S. Levantino & A. L. Lacaita, Integrated LC oscillators for frequency  synthesis in wireless applications. IEEE Commun. Mag., 40:5  2002 , 166–171.  [47] Skyworks, Design With PIN Diodes, Application Note APN1002, 200312 Rev. A, Jul  2005.  [48] A. Suarez & T. Fernandez, RF devices: characteristics and modelling. In I. A. Glover, S. R. Pennock & P. R. Shepherd, eds., Microwave Devices, Circuits and Subsystems for Communications Engineering  Chichester, UK: Wiley, 2005 .  [49] M. Thamsirianunt & T. A. Kwasniewski, CMOS VCO’s for PLL frequency synthesis in GHz digital mobile radio communications. IEEE J. Solid-State Circ., 32:10  1997 , 1511–1524.  [50] R. J. Trew, Wide bandgap semiconductor transistors for microwave power ampliﬁers.  IEEE Microwave Mag., 1:1  2000 , 46–54.  [51] R. J. Trew, G. L. Bilbro, W. Kuang, Y. Liu, and H. Yin, Microwave AlGaN GaN  HFETs. IEEE Microwave Mag., 6:1  2005 , 56–66.  [52] V. K. Varadan, K. J. Vinoy & K. A. Jose, RF MEMS and Their Applications   Chichester, UK: Wiley, 2003 .      12  A D and D A conversions  12.1 Introduction  Analog input signals are converted into digital signals for digital processing and trans- mission. The analog-to-digital  A D  converter  ADC  performs this functionality using two steps: the sample-and-hold  S H  operation, followed by digital quantization. The ADC is primarily characterized by the sampling rate and resolution. A sampling rate of above twice the Nyquist frequency is a must; otherwise, aliasing occurs and the result is not usable. A higher sample rate leads to a more accurate result, but a more com- plex system. The successive-approximation ADC successively increases the digital code by digitizing the difference until a match is found. The successive-approximation ADC is the most popular type of ADC. The sigma-delta   cid:27 - cid:18   ADC uses oversampling and noise shaping to signiﬁcantly attenuate the power of quantization noise in the band of interest.  The digital-to-analog  D A  converter  DAC  is used to convert the processed digital signal back to an analog signal by comparing it to the input voltage. This chapter introduces ADCs and DACs that are used in wireless communication systems.  12.2 Sampling  12.2.1 Ideal and natural sampling  ∞ cid:26   An analog signal x t , bandlimited to fmax, can be transformed into digital form by periodically sampling the signal at time nT, where T is the sampling period.  Let the sampling function be a periodic impulse train given by  p t  =  δ t − mT ,   12.1  where δ t  is the Dirac δ function, which takes on the value 1 at t = 0 and is 0 otherwise. −j2πnfst, where The coefﬁcient in the Fourier series of p t  is given by 1 ∞ cid:26  fs = 1 T is the sampling frequency  see Chapter 13 . Hence, T  ∞ cid:26   m=−∞  T 2−T 2  δ t e   cid:27   p t  =  δ t − mT  = 1 T  m=−∞  e j2πnfst.  n=−∞   12.2       465   cid:2   12.2 Sampling  The sampled version of x t , ˆx t , is the product of the continuous-time signal x t  and the sampling function p t :  ˆx t  = x t p t  =  x kT δ t − kT .  ∞ cid:26   k=−∞  ∞ cid:26   k=−∞  ∞ cid:26   The sampled signal is held until it is quantized into a b-bit digit.  In the frequency domain, the spectrum of the sampling function p t  is the Fourier  transform of the impulse train and is given by  see Chapter 13   P  f   = 1 T  δ   f − kfs  .  ∞ cid:26   k=−∞  It is seen that P  f   is also a periodic impulse train.  The spectrum of the sampled digital signal is then given by the convolution of X  f   and  P  f  . Thus,  ˆX  f   = X  f   ∗ P  f   = X  f   ∗ 1  δ   f − kfs  = 1 T  T  k=−∞  X  f − kfs  .   12.5   This is known as the Poisson summation formula. Thus, it is seen that sampling of a signal x t  produces a periodic repetition of its spectrum.  When the sampling function is a periodic train of rectangular pulses rather than a peri- odic train of impulses, as shown in Fig. 12.1, we call it natural sampling, as opposed to ideal sampling. The rectangular pulse train has a Fourier series given by  ∞ cid:26   m=−∞  ∞ cid:26   k=−∞  p t  =  prec t − mT  =  cke j2πfskt,  where  with τ being the pulse width. The sampled signal is thus given by  sin kπ τ T   kπ τ T  ck = 1 T ∞ cid:26   n=−∞  ˆxrec t  =  x nT prec t − nT .   12.3    12.4    12.6    12.7    12.8       x   t  xrec t   τ   cid:2 Figure 12.1  Ideal and natural sampling.  0  T  2T  T3  T4  5T  t  0  T  T2  3T  4T  5T  t      466   cid:2   A D and D A conversions  For natural sampling, the spectrum of the sampled signal is accordingly  ˆXrec  f   =  ckX   f − kfs  .   12.9   ∞ cid:26   k=−∞  Comparing  12.9  to  12.5 , it is seen that  12.9  denotes the same spectrum as  12.5  does, except that the displaced side-bands vary with ck.  12.2.2 Sampling theorem  fs ≥ 2fmax.  Theorem 12.1  Sampling Theorem : A bandlimited signal with the maximum frequency fmax is speciﬁed uniquely by its values at uniformly spaced intervals of Ts = 1 fs apart, if the sampling frequency satisﬁes   cid:20    cid:19 −fs 2, fs 2   12.10  The minimum allowable sampling rate fs = 2fmax is called the Nyquist rate, fs 2 = fmax is known as the Nyquist frequency is the Nyquist frequency, and the interval interval. The sampling is known as lowpass sampling, since all the frequency compo- nents from 0 Hz to fs 2 are recoverable. Thus, for a baseband signal with a frequency band limited from −B 2 to B 2 Hz, its digitalization requires a sampling frequency fs ≥ B. According to  12.5 , if the signal is bandlimited to fmax and fs ≥ 2fmax, the replicas do not overlap; then, in the Nyquist interval, we have  T ˆX  f   = X  f  , − fs  ≤ f ≤ fs 2  .  2   12.11   That is, the sampled signal spectrum ˆX  f   is identical to the original spectrum X  f   within  the Nyquist interval. There are also several generalizations of the sampling theorem [7, 19]. One class of uniform sampling theorem is given as: If x t  and its ﬁrst M − 1 derivatives are avail- able, then each of these can be uniformly sampled at the rate of fs M without losing any information. The second generalization is a class of nonuniform sampling theorems. There is, however, no closed-form expression for reconstruction of x t  from these samples. The problem of reconstruction of signals from nonuniform samples has been discussed in [14, 16].  12.2.3 Aliasing and antialiasing  From  12.5 , it is seen that sampling causes spectrum replication. When spectrum repli- cation leads to confusion of the original frequency f with f + mfs, m = ±1,±2,··· , aliasing occurs. Analog reconstruction from aliased sampling will map all the out- interval by using the aliased frequency fa = f of-band signals onto the Nyquist      467   cid:2   12.2 Sampling  1  0.5  y  0  −0.5  −1    0     1 Hz 4 Hz 9 Hz   cid:2 Figure 12.2  A 1 Hz, a 4 Hz, and a 9 Hz signal yield the same output, when sampled at 5 Hz.  0.2  0.4  0.6  0.8  1  t  Input spectrum  Replicated spectrum  –fs 2 0  fs 2  f  −fs  0  fs  Prefiltered spectrum  Prefilter  Replicated spectrum  f  f   cid:2 Figure 12.3  –fs 2 0  fs 2  f  −fs  0  fs  Aliasing and the antialiasing preﬁlter.  mod  fs . Aliasing distorts irreversibly the frequency response within the Nyquist interval.  Example 12.1: Aliasing is illustrated in Fig. 12.2. For three signals, y t  = − sin 2πt , y t  = − sin 8πt , and y t  = − sin 18πt , when sampled at 5 Hz, the outputs for the three signals coincide.   cid:19 −fs 2, fs 2   cid:20   To avoid aliasing, an antialiasing preﬁlter is used to limit the cutoff frequency to fmax ≤ fs 2. Thus, the ﬁlter band is limited to . In this case, spectrum replication does not overlap. This is illustrated in Fig. 12.3.  An antialiasing preﬁlter must precede the ADC to bandlimit the input spectrum to within the Nyquist interval. SAW ﬁlters are antialiasing ﬁlters with excellent roll-off in the tran- sition band but with a high insertion loss. A high quality LNA can precede the SAW ﬁlter to achieve adequate noise ﬁgure.      468   cid:2   A D and D A conversions  Input spectrum  Prefiltered spectrum  Prefilter  Replicated spectrum  −fs 2  0  fs 2  f  −B 2  0  B 2  f  −fs  0  fs  f  Prefilter  Replicated spectrum  fs = B  fs > B   cid:2 Figure 12.4  Oversampling and the antialiasing preﬁlter.  −fs  0  fs  f  12.2.4 Oversampling and decimation  When fs is greater than twice the required Nyquist frequency, the signal is oversampled. Oversampling increases the periodicity of the spectral replicas, and allows a less sharp cutoff for the preﬁlter. Oversampling is usually used to relax the attenuation requirements on the lowpass antialiasing ﬁlter that has a cutoff frequency at the Nyquist frequency, thus reducing the order of the ﬁlter [13]. After oversampling, the original baseband [−B 2, B 2] is replicated into many spectral replicas that are separated by a wider spectrum spacing of fs > B, as shown illustrated in Fig. 12.4. This makes preﬁlter design much easier. will If the sampling rate is reduced to B, some frequency components in be outside the Nyquist interval [−B 2, B 2], and aliasing is introduced inside the interval. To prevent aliasing, those out-of-band frequencies must be removed by a lowpass digital ﬁlter before resampling at the lower rate. Such a ﬁlter is known as a digital decimation ﬁlter. Such ﬁlters just throw away some samples at ﬁxed time intervals, achieving lowpass ﬁltering and sampling.   cid:19 −fs 2, fs 2   cid:20   12.2.5 Bandpass sampling theorem  For a bandwidth B that is centered on fc, the lowpass sampling scheme requires a sampling frequency of 2  fc + B 2 . Bandpass sampling allows sampling rates consis- tent with the bandwidth B, rather than the highest frequency fc + B 2 of the signal spectrum. Bandpass sampling is of signiﬁcant importance for wireless communica- tions. fs can be selected as 2B ≤ fs ≤ 2fc + B, by using the frequency-domain repetition caused by the sampling process. This is called bandpass-limited subsampling or undersampling. Bandpass-limited subsam- pling also achieves frequency downconversion at the same time. A bandpass ﬁl- ter is used after bandpass sampling. The bandpass sampling criterion is stated as follows [15].  is very large,  When fc      469   cid:2   12.2 Sampling  Theorem 12.2  Bandpass Sampling : A bandpass signal is speciﬁed uniquely by its values at uniformly spaced intervals of Ts = 1 fs apart, if  Q k  ≤ fs B  ≤ 2  Q − 1 k − 1  2   12.12  where B = fH − fL, Q = fH B, k is a positive integer and k ≤  cid:24 Q cid:25 , with  cid:24 · cid:25  denoting the integer part of the quantity within. When k = Q, there is zero tolerance in the sampling rate. Thus, k is usually selected to be less than Q.  ,  Example 12.2: The condition  12.12  is plotted in Fig. 12.5. Only the wedge regions satisfy the bandpass sampling condition, while the forbidden region generates aliasing. From the plot, we can see that the waveform may be reproduced from sample values if the sampling rate is fs ≥ 2B.  Reconstruction of the signal is done by using the formula x nT g t − nT ,  x t  =  ∞ cid:26   n=−∞  where  g t  = sin πBt πBt  cos 2πfct   12.13    12.14   k = 1  k = 2  k = 3  fs = 2 fH  f H   2 3 fH   k = 4   1 2 fH   B     s  f  8  7  6  5  4  3  2  1  2  4  8  10  Forbidden region  6  f H B   cid:2 Figure 12.5  Condition for bandpass sampling: The wedges correspond to alias-free sub-band sampling.      470   cid:2   A D and D A conversions  is the inverse Fourier transform of the bandpass frequency gating  rectangular  function, and it is the ideal interpolation function for lowpass sampling, modulated by a carrier with frequency fc. More detailed analysis on bandpass sampling is given in [15, 20]. Bandpass sampling is extremely popular in software radio systems. To avoid aliasing, bandpass ﬁltering is a prerequisite for implementing bandpass sampling.  12.3 Quantization  Quantization is the mapping of continuous amplitude values into a ﬁnite number of bits. After sampling, each sample x mT  must be held constant for a period of at most T seconds by using a sample hold circuit; during this time the ADC must convert it to a quantized sample, xQ mT , represented in a number, n, of bits.  12.3.1 Uniform quantization  Usually, the ADC equally divides the full-scale range R into 2n quantization levels, and the quantization step size or resolution is given by Q = R 2n .   12.15  The denominator can be changed to 2n − 1, since the up end R is not realizable as a level. Quantization is performed by rounding. Assuming that the quantization error e = xQ − x is uniformly distributed in the interval of [−Q 2,+Q 2] with zero mean, the worst-case quantization error is ±Q 2. The mean-square value of e or the quantization noise power is given by  Q 2 −Q 2  e2de = Q2 12  = E[e2] = 1 Q √ 12.  .  σ 2 e The rms error is thus erms = Q  For binary coding, one needs to consider the polarity of the input signal. For unipo- lar analog input with range [0, R , the natural binary coding is used. For bipolar analog input with range [−R 2, R 2 , the natural binary coding can lead to the coding of the level xQ = 0 as 10··· 0, and two’s complement code is usually used instead. Two’s complement code is obtained by complementing the MSB  most signiﬁcant bit , replacing bn−1 by 1 − bn−1.   12.16    cid:14   Example 12.3: If the reference voltage is +10 V, and the input signal is +2 V, for a 10-bit coding, then the sampled digital value is  xQ = vi vref  × max_value = 2 10  × 1023 = 205 = 11011101b.      471   cid:2   12.3 Quantization  After digital processing, a digital signal may be converted to an analog signal. The DAC performs an operation which is the reverse of that of the ADC. The analog output for sampled value 205 is calculated by  vo = xQ × vref max_value = 205 × 10 1023 = 2.0   V .  The above quantization technique is known as the uniform pulse code modulation  PCM  technique. It is a uniform quantization technique followed by a process of representing the quantized samples into bits of ﬁxed length. The signal-to-quantization-noise ratio  SQNR  is obtained from  12.15  and  12.16  as  SQNR = x2  = 3 × 22n  x2  σ 2 e   R 2 2 = 4.8 + 6n + 10 log10  x2   R 2 2   dB ,   12.17   where x2 is the mean-square value of x. Nonuniform PCM ﬁrst applies a nonlinear element to the input signal to reduce its dynamic range, followed by a uniform PCM. This will be introduced in Chapter 16.  Midtread and midrise quantizers  For uniform quantization, the quantizer is typically symmetric in the sense that there are equal numbers of positive and negative levels. The midrise and midtread are two popular quantizers and are shown in Fig. 12.6. The midtread quantizer has a zero output, and there are an odd number of output levels. The midrise quantizer does not have a zero level, and thus has an even number of output levels. For an n-bit quantizer, the midtread allows for 2n − 1 different codes, as opposed to 2n codes allowed by the midrise quantizer. The midtread quantizer is more popular for quantization, since it results in more zero levels, leading to a larger compression ratio in data compression, such as in speech and video coding.   cid:2 Figure 12.6  Midrise  Midtread  The midtread and midrise quantizers.      472   cid:2   A D and D A conversions  Other quantization techniques  General ADC techniques use PCM, differential PCM, scalar quantization, and vector quantization  VQ  for quantization of the held samples. The performance of these lossy data compression techniques is limited by the rate-distortion bound. After the samples are quantized into digital form, entropy coding can be applied to represent them using as few bits as possible. Entropy coding will be introduced in Chapter 14.  Uniform and nonuniform PCM are two scalar quantization techniques, where each dimension of the source is quantized separately. Nonuniform quantization provides bet- ter performance than uniform quantization due to its variable length of the quantization regions. The Lloyd-Max conditions give the optimal solution to nonuniform quantization [11]: the quantization levels are the centroids of the quantization regions and the boundaries are the midpoints between the quantization levels.  VQ quantizes several dimensions of the source together, thus achieving much higher  compression. More detail on VQ is given in Subsection 19.2.6 and [4].  12.3.2 Improving resolution by oversampling  When the ADC is limited by the resolution, oversampling can be used to achieve higher accuracy. In the case of oversampling, each sample may have a low accuracy, but many samples can be averaged to remove noise [13]. This is similar to multiple measurements of a quantity x. Assuming that the mean-square error is σ 2 x in a single measurement, L independent measurements of the quantity can reduce it to σ 2 x   L.  Consider two sampling rates fs and f  bits, respectively. To maintain the same level of quality in the two cases, the PSDs of the quantization noise in the two cases are required to be the same, that is,  > fs, with n bits and n   cid:14  s   cid:14   The PSDs of quantization noise for both the cases are illustrated in Fig. 12.7a. By deﬁning the oversampling ratio L = f   fs, we have  = σ cid:14 2 f  cid:14   e  s  σ 2 e fs  = η.   cid:14  s L = σ cid:14 2  e σ 2 e  .   12.18    12.19   PSD  η  0  a   PSD  η   b   –f ’ 2s  –f s 2  f s 2  f ’ 2s  f  –f ’ 2  s  –f s 2  0  f s 2  f ’ 2s  f   cid:2 Figure 12.7  Spectrum of oversampled quantization noise power.  a  Without noise shaping.  b  With noise shaping.      473   cid:2   12.4 Analog reconstruction  Substituting  12.16  in  12.19 , we have [13]  cid:18 n = n − n   cid:14  = 0.5 log2 L.   12.20    12.21    12.22    12.23    12.24   From this, we can see that a saving of half a bit is achieved when L is doubled.  A noise shaping quantizer operating at an oversampling rate f   cid:14  s can reshape the ﬂat noise spectrum to squeeze most of the power out of the fs Nyquist interval. The spectrum of the oversampling noise shaping quantizer is shown in Fig. 12.7b. The pth-order noise shaping ﬁlter at f   cid:14  s has a magnitude response  HNS  f   =  , −f   cid:14  s   2 ≤ f ≤ f   cid:14  s   2.  For small f , we have  HNS  f   =  f  cid:5  f   cid:14  s   2.  ,  After noise shaping, the total quantization noise power within the fs Nyquist interval is  calculated by   cid:4  cid:4  cid:4  cid:4 2 sin   cid:3  cid:4  cid:4  cid:4  cid:4 p  cid:3  cid:4  cid:4  cid:4  cid:4 p  πf f  cid:14   s  2πf f  cid:14   s   cid:2   cid:4  cid:4  cid:4  cid:4  cid:2   cid:14   = σ cid:14 2 f  cid:14   e  s  σ 2 e  fs 2 −fs 2  HNS  f  2 df .  For a large oversampling rate L,  12.22  can be used in the integrand, and this gives  = σ cid:14 2  e  σ 2 e  π 2p 2p + 1  1 L2p+1 .  cid:2    cid:3   Inserting  12.19  and  12.24  into  12.20 , the gain in bits is derived as [13]   cid:18 n =  p + 0.5  log2 L − 0.5 log2   12.25  This leads to a saving of more bits when L is doubled. For example, for L = 8, without noise shaping a gain of 1.5 bits is achieved, but with noise shaping of order p = 2 a gain of 5.4 bits is achieved. Practical values for the order p are typically 1, 2, 3.  .  π 2p 2p + 1  Sigma-delta modulation is ideal for ADCs and DACs. Such an ADC employs high sam- pling rate and spreads the quantization noise across the band up to fs 2. The DAC uses sigma-delta modulation in a loop that is the reverse of the loop for the ADC. For example, the Analog Devices AD9772 is a 2× oversampled interpolating 14-bit DAC, and it handles 14-bit input word rates up to 150 Msamples s, and the output word rate is 300 Msamples s at maximum [8].  12.4 Analog reconstruction  Analog reconstruction transforms the sampled digital signal into an analog one. Filling the gaps between the samples results in a smoother signal, and this operation can be treated as lowpass ﬁltering.      474   cid:2   A D and D A conversions  Ideal reconstructor  H  f   = T = 1 fs  , − fs 2  ≤ f ≤ fs 2  The ideal reconstruction ﬁlter H  f   is an ideal lowpass ﬁlter with   12.26    12.27    12.28    12.29   and zero otherwise. For a bandlimited spectrum Y  f   with nonoverlapped replicas, then the sampled spectrum satisﬁes  The analog signal obtained has a spectrum  ˆY  f   = 1  Y  f  , − fs 2  ≤ f ≤ fs 2  .  T  Ya  f   = H  f  ˆY  f   = T · 1  Y  f   = Y  f  .  T  Thus, the ideal reconstructor can completely remove the replicated spectrum images.  The corresponding impulse response of H  f   is given by h t  = sinc πt T  = sin πt T  πt T  .  The sinc function has inﬁnite anticausal part, and thus is noncausal and not realizable. An approximation to the ideal reconstructor can be obtained by truncating it to ﬁnite length.  Staircase reconstructor  A simple and widely used implementation is to hold the current sample constant for a period T = 1 fs to ﬁll the gap until the next sample appears. The reconstructed signal thus has a staircase amplitude. The nonsmooth characteristic introduced by the staircase introduces spurious high-frequency components, which are outside the Nyquist interval. The staircase DAC has an impulse response h t  = 1,   12.30   0 ≤ t ≤ T and 0 otherwise. The corresponding frequency response is −jπf  fs. e  H  f   = T  sin  πf  fs    12.31   πf  fs  The staircase reconstructor is a ﬁlter with a sinc-like shape spectrum. It is seen that h t  and H  f   for the ideal as well as the staircase reconstructor are dual to each other.  The staircase reconstructor ﬁlter shapes the replicated spectrum images and leaves some remnant image components, as illustrated in Fig. 12.8. These image components in the vicinity of the Nyquist interval may be signiﬁcant, and may introduce aliasing into the Nyquist interval. Thus, an anti-image lowpass postﬁlter must be applied to reject the spectral replicated images as much as possible.  cid:14  s through interpolation, the ﬁrst image of the By increasing the clock frequency to f s rather than on ±fs. D A conversion is then applied. This spectrum can be centered on ±f  cid:14  permits a signiﬁcant relaxation of the speciﬁcations for the anti-image lowpass postﬁlter. If the oversampling rate is increased by a factor of K, at the cutoff frequency fc = fs 2,      475   cid:2   12.5 Parameters for A D and D A converters  Ideal reconstructor  Staircase reconstructor   cid:2 Figure 12.8  Spectrum of the staircase reconstructor.  −2fs  −fs  −fs 2  0  fs 2  fs  2fs  f  −2fs  −fs  −fs 2  0  fs 2  fs  2fs  f  we have HDAC  fc  = sin π 2K  π 2K . For large K, this attenuation approaches 0 dB, and thus the aperture effect of the DAC is eliminated. For small oversampling rates, an inverse shape of the DAC frequency response can be applied over the passband, that is, an equalizer, which can be designed using the frequency sampling design method.  It is worth mentioning the fundamental difference between aliasing and imaging: alias- ing causes loss of information, while imaging does not. We will give more description on sampling rate conversion in Section 13.7.  12.5 Parameters for A D and D A converters  The static nonlinearity of an ADC or DAC, caused by its physical imperfection, can be characterized by its dc transfer function, and is presented in terms of the number of bits of integral nonlinearity  INL  and differential nonlinearity  DNL  errors. These errors are measured in units of least signiﬁcant bits  LSBs . The INL error is obtained by draw- ing a line that best ﬁts the converter’s dc transfer function and calculating the difference between the line and the actual transfer function. The DNL error is calculated as the dif- ference between the actual step width and that for 1 LSB. These static parameters are very important in high-resolution imaging. For example, ADI provides AD9821  12-bit, 40- Msamples s  and AD9854B  12-bit, 30-Msamples s  ADCs for high-performance digital still cameras and camcorders.  For evaluating ADCs or DACs for SDRs, the most important parameters are the sam- pling rate, bits of resolution, and SFDR. The signal-to-noise-and-distortion  SINAD  ratio is deﬁned by the ratio of the rms signal power to the rms of all the unwanted spec- tral components but excluding the dc component. Sometimes SINAD is referred to as signal-plus-noise-and-distortion-to-noise-and-distortion ratio, since the measured signal may include noise and distortion, in this case, SINAD =  S + N  N = 1 + S N, N being the noise and distortion. In either case, the SINAD of a high-performance ADC should be very close to its SNR. SFDR is the ratio of the rms signal amplitude to the rms value of the peak spurious spectral component. SFDR is more important than SNR or SINAD for SDRs, since it combines linearity and quantization noise performance.  Whereas jitters may happen in ADCs, glitches may occur in DACs. The decoder in a DAC attempts to simultaneously adjust several switches to change the output voltage level so as to match the input digital word. When there are small timing discrepancies between      476   cid:2   A D and D A conversions  the switches, glitches occur. This may cause signiﬁcant distortion to the output signal. Glitches can be reduced by double buffering the input or adding a deglitching circuit to the output of the decoder in the DAC.  A straight binary DAC with one current switch per bit  e.g., R-2R DAC  produces code-dependent glitches. A DAC with one current source per code level does not have code-dependent glitches, but is not practical for high resolutions. A practical approach is to decode the ﬁrst few MSBs into a code and have one current switch per level. This sub- stantially reduces the code-dependent glitch. This process is called segmentation and is quite common in low distortion DACs, e.g., in the Analog Devices’ AD977x-family DACs and the AD985x-family DDS devices [8].  12.5.1 SNR of A D and D A converters  The noise of an ADC contains thermal noise that includes the capacitance noise of the S H stage, quantization noise, and aperture-jitter noise. = The variance of the quantization error is the quantization noise power, given by σ 2 e Q2 12. For an analog sinewave of amplitude A, the average signal power is A2 2, the quantization step size is Q = 2A 2n , where n is the ADC resolution in bits. The SQNR can be calculated by   cid:2    cid:3   SQNR = 10 log10  A2 2 Q2 12  = 1.76 + 6.02n   dB .   12.32   For the more general case [9]  SQNR = 6.02n + 4.77 − 10 log10 η  dB ,   12.33  where η is the PAPR of the signal. For sinusoidal signals, η = 2. The SNR of a prac- tical ADC cannot reach the theoretical ﬁgure, especially when the number of bits is increased.  If the signal is treated as a zero-mean random process and its power is σ 2  x , then the  SQNR is given by  σ 2 x σ 2 e  = 10 log10  + 4.77 + 6.02n  SQNR = 10 log10  σ 2 x A2 where A takes half the full-scale range, A = R 2. For a signal with a bandwidth of B and a sampling rate fs, taking  12.20  into account, for the sinewave of amplitude A, the signal SNR and the conversion resolution are related by [6]   12.34    dB ,  SQNR = 1.76 + 6.02n + 10 log10 L  dB ,   12.35   where L = fs 2B is the oversampling ratio. Thus, the SNR rises with 6.02 dB per bit of quan- tizer resolution, and 3.01 dB per doubling of the oversampling ratio, which is equivalent to 0.5 bit quantizer resolution.      477   cid:2   12.5 Parameters for A D and D A converters  When the signal has a normal distribution of amplitude, with zero mean and variance σ 2 x , based on  12.34  and taking oversampling into account, the corresponding result is derived as [5]  SQNR = 10.8 + 6.02n + 10 log10 L + 10 log10  σ 2 x V2 pp   dB ,   12.36   where the peak-to-peak voltage Vpp = 2A = R. Clock jitter is referred to as varying or jittering of the time interval between successive clock edges. This variation in time interval is random with a mean and a variance. Clock jitter increases the system noise, causes uncertainty in the sampled phases, and introduces ISI. Traditional nonspread narrowband modulation is more sensitive to clock jitter and a small amount of clock jitter can lead to a considerable SNR reduction of the ADC output. For the ADC, if the rms of the clock jitter is στ , the signal-to-jitter-noise ratio  SJNR  is limited to  SJNR =  1   2πfsστ  2  = −20 log10  2πfsστ     dB .  The maximal jitter is determined by the frequency of the input signal and the resolution of the ADC [9]  στ ,max =  1  .  2nπfmax  For a well referenced clock, the SJNR is much higher than the SQNR, and the SNR is determined by the SQNR. For IF sampling in SDRs, an rms sampling clock jitter of 1 picosecond is recommended.  When the noise plus distortion is high, an ADC is characterized by the effective number of bits  ENOB  rather than the actual number of bits, since the conversion is prone to error and there are mistakes in the bits. The ENOB is calculated by [9]  where SINAD, in decibels, corresponds to that for the case when all the three noise sources are included.  In case of bandpass sampling, the SNR is given by [10]  ENOB = SINAD − 1.763  ,  6.02  SNR =  1 32f 2 c  σ 2 τ  fs 2B  ,   12.37    12.38    12.39    12.40   where fc is the carrier frequency and B is the signal bandwidth. Thus, the SNR increases with the oversampling ratio.  12.5.2 SFDR and dithering  Dithering can effectively increase the SFDR. It is performed by adding pseudorandom noise to the input analog signal prior to sampling and digitalization. Dithering smears out the energy in the spurious signals over a wide frequency band.      478   cid:2   A D and D A conversions     B d      m u r t c e p s   r e w o P  0  −20  −40  −60  −80  −100  −120  −140   cid:2 Figure 12.9  0  5  15  10 Frequency  MHz   20  25  30  Sampling without dithering.  Example 12.4: The spectrum of a sine wave of 10 MHz, when sampled by using a 12-bit ADC at a sample rate of 32 MHz without dithering, is plotted in Fig. 12.9. It is shown that there are many spurious components in the Nyquist band.  Example 12.5: Corresponding to the case of Example 12.4, when the signal is sampled with dithering, the spectrums are shown in Fig. 12.10 for different dithering schemes. In Fig. 12.10a, the added noise signal is AWGN with σ = 2 × 10 −4A, where A is the ampli- tude of the sine wave. This can effectively reduce the level of the spurious components by approximately 10 dB. By removing the dither from the reconstructed sine wave, the power of the spurious components is further reduced by approximately 5 dB and is shown in Fig. 12.10b. In Fig. 12.10c, the added noise is AWGN with σ = 2 × 10 −3A. From Fig. 12.10c, it is seen that the added noise is so large that the SFDR is actually lower than that without dithering. In Fig. 12.10d, the spurious components in Fig. 12.10c are reduced to approximately −110 dBFS by removing the dither. Thus, the addition and removal of dithering can increase the SFDR of ADCs.  Three common types of dithers are noises with Gaussian, rectangular, and triangular 4 Q2, pdfs. For the zero-mean Gaussian dither, the variance is recommended to be σ 2 corresponding to vrms = Q 2, or half-LSB. For the rectangular-type dither, the pdf has a width of Q, or 1-LSB, and a height of 1 Q. This is equivalent to σ 2 12 Q2. This leads to a decrease in SNR of 3 dB for the rectangular dither, and a decrease in SNR of 6 dB for the Gaussian dither [13].  v = 1  v = 1  To prevent aliasing arising from the wideband noise signal, the noise signal should be lowpass ﬁltered before being added to the input sine wave. When the power of the added noise is orders of magnitude lower than that of the signal, as shown in Example 12.5, the added noise signal need not be lowpass ﬁltered and this does not incur a problem.      479   cid:2      B d      m u r t c e p s   r e w o P     B d      m u r t c e p s   r e w o P  0  −20  −40  −60  −80  −100  −120  −140  0  −20  −40  −60  −80  −100  −120  −140  12.6 A D converter circuits  σ = 2 × 10−4 A      B d      m u r t c e p s   r e w o P     B d      m u r t c e p s   r e w o P  0  −20  −40  −60  −80  −100  −120  −140  0  −20  −40  −60  −80  −100  −120  −140  0  5  10  15  20 Frequency  MHz    a   25  30  0  5  10  15  20  25  30  Frequency  MHz    b   σ = 2 × 10−3 A   0  5  25  30  0  5  10  15  20 Frequency  MHz    c   10  15  20 Frequency  MHz   25  30   d    cid:2 Figure 12.10 Dithering.  a  Dithering by using the noise, σ = 2 × 10  reconstructed signal in  a .  c  Dithering by using the noise, σ = 2 × 10 noise from the reconstructed signal in  c .  −4A.  b  Removing the noise from the −3A.  d  Removing the  Dithering increases the system noise energy, thus raising the noise ﬂoor and leading to a decrease in SNR; this is acceptable if the SFDR is the prime requirement of the system. One method to reduce the noise ﬂoor is to subtract the digitalized dithering signal following digital conversion. Although the dithering addition and removal scheme can improve the SFDR, it is not practical since a copy of the dither is required at the receiving end. In many applications, dithering is not necessary, since the inherent analog noise of the mixers and other devices provides some dithering.  12.6 A D converter circuits  Three common types of ADC circuits are the ﬂash ADC, the successive approximation register  SAR  ADC, and the sigma-delta ADC. The SAR ADC is most widely used today, and the sigma-delta ADC is gaining more attention.      480   cid:2    cid:2 Figure 12.11  A D and D A conversions  n   2 −1   Vref n 2  Vref 2 n  2  Vref 2 n  Vref  inV  Comparators  +  +  +  Decoder  Digital output  Structure of the ﬂash ADC.  V in  +  Comparator  Control logic  b  n−1  b1 b0  Digital output   cid:2 Figure 12.12  Structure of the successive-approximation ADC.  DAC  12.6.1 Flash A D converters  The structure of a ﬂash  or parallel  ADC is shown in Fig. 12.11, where all the resistors have the same resistance and n is the wordlength of the ADC. The decoder is used to transform the output of the comparators into parallel PCM output.  Flash ADCs have the fastest conversion time, and thus are suitable for applica- tions with high sampling rates, such as in SDRs and UWB applications. These ADCs are constrained by the high complexity, and hence are typically used in the case of a wordlength of 10 bits or less. However, they are expensive, and have a high power consumption. The resistors in the voltage divider chain must have high accu- racy. The number of comparators and complexity of the decoder are of the order O  2n .  12.6.2 Successive-approximation register A D converters  The SAR ADC consists of only one analog comparator, and utilizes a control logic, a register of n bits, and a DAC of n bits, as illustrated in Fig. 12.12. The method uses the register bn−1 ··· b2b1 to store the converted digit output; the output is further converted into an analog value by the DAC and fed back to the analog comparator. The comparator compares the analog input and the DAC output, and the error signal is used to tune the register. Initially, all the b bits are set to zero in a SAR, then starting from the MSB bn−1, the bit is turned on sequentially and the difference between the analog input x and the analog signal converted from the DAC, xQ, is tested to decide whether it is left on  x ≥ xQ       481   cid:2   12.6 A D converter circuits  or turned off  x < xQ . The process is repeated for the second MSB and so on, until all the n bits in the register are tested. This method requires n tests, and the result in the SAR bn−1 . . . b1b0 is the digital output.  SAR ADCs are very fast, although not as fast as ﬂash ADCs. They have low complex- ity and are inexpensive. They are the most widely used ADCs for sampling rates up to some MHz.  12.6.3 Sigma-delta A D converters  Unlike the Flash and SAR ADCs, the sigma-delta   cid:27 - cid:18   ADC uses a 1-bit or multiple- bit ADC with noise shaping to achieve high resolutions. The single bit codes whether the current sample has a higher or lower voltage than the previous sample. High resolution is achieved by oversampling. Conversion from this oversampled 1- or more-bit stream into a slower, high-resolution stream is performed by using digital decimation ﬁlters. A sigma-delta ADC is usually split into a sigma-delta modulator and a decimator. The sigma- delta modulator is used as the A D interface, while the latter, sometimes called a serial-to- parallel  S P  converter, is a ﬁlter followed by a down-sampler.  Sigma-delta modulator  The sigma-delta modulator is a combination of delta modulator and demodulator. A generic sigma-delta modulator is shown in Fig. 12.13, where A z  is the transfer function of the delta demodulator and B z  the transfer function of the loop-ﬁlter of the delta modulator. Usually, A z  = B z  for DM, and this is also widely used for the sigma-delta modulator, although choosing A z   cid:18 = B z  can lead to better performance [5]. The noise transfer function He z  and the signal transfer function Hx z  are, respectively,  given by  He z  =  1  1 − B z   cid:17   .  , Hx z  = A z  1 − B z   cid:18 2  , Hx z  = z  −1  in Fig. 12.14, it can be shown that [1, 5] 1 − z −1  He z  =  For a classical second-order sigma-delta modulator using double-integration, as shown   12.41    12.42   X  z   A  z   Quantizer  Y  z    cid:2 Figure 12.13  Architecture of the generic sigma-delta modulator.  B  z   DAC      482   cid:2   A D and D A conversions  X  z   Integrator  z−1  Quantizer  N  z   Y  z   Integrator  z −1  DAC   cid:2 Figure 12.14 The classical second-order sigma-delta modulator. DAC is assumed to be ideal with unit gain.  and  Y z  = X z z  −1 + E z  1 − z  −1 2.   12.43    12.44   That is, the input signal X z  is ﬁltered by an all-pass ﬁlter, while the quantization noise E z  by a highpass ﬁlter.  The SNR is derived as [5]  SNR = 10 log10  σ 2 x  Q2 12  + 10 log10   cid:27  π L  0  π  ,  16 sin4 ω  2 dω  where the ﬁrst term stands for the SQNR of the quantizer without noise shaping and the sec- ond term gives the contribution to SNR within the Lth fraction of the total frequency band caused by noise shaping, L being the oversampling ratio. An approximation is obtained by applying the 3rd-order Taylor series expansion to the sine function [5]  SNR ≈ 20 log10  + 6.02n + 50 log10 L − 2.1  σx Vpp  An order-M sigma-delta modulator is a straightforward extension of the ﬁrst-order sigma-delta modulator by setting Hx z  = z by  12.45  can be generalized to the Mth-order with noise shaping [1, 5]  1 − z  −1   dB ,  −1 and He z  = cid:7   for L ≥ 4.   12.45    cid:8 M. The result given  SNR ≈ 20 log10  σx Vpp  + 6.02n + 10 2M + 1  log10 L + 10.8 + 10 log10 for L ≥ 4.  2M + 1   12.46  Thus, for every doubling of the oversampling ratio L, an extra  6M + 3  dB of SNR, or an extra  M + 1 2  bits of resolution, is obtained. The SNR also increases by 6.02 dB for every additional bit of quantization resolution.   dB ,  π 2M  Comparison of  12.36  and  12.45  shows that a higher resolution is achieved with sigma-delta modulators, leading to more efﬁcient and lower-power implementations. This makes the sigma-delta ADC most desirable for mobile communications. The sigma-delta ADC has the highest resolution, and is the only choice when a resolution of more than 16 bits is desired [9]. Sigma-delta ADCs are widely used for audio ADCs. A reconﬁg- urable sigma-delta ADC for a GSM WCDMA Wi-Fi WiMAX zero-IF receiver has been presented in [17].      483   cid:2   12.6 A D converter circuits  Discussion  The above result is for lowpass sigma-delta modulators. The result can be transformed to a bandpass sigma-delta modulator with equivalent noise shaping characteristic, and thus a bandpass sigma-delta ADC can be obtained from a lowpass prototype by transformation [1, 12]. The bandpass sigma-delta ADC operates in a manner similar to that of the corre- sponding lowpass one. In a communication system, A D conversion at either the IF or RF stage yields a more robust system with improved IF strip testability, and is necessary for SDRs.  From  12.46 , the effectiveness of increasing the order of noise shaping, M, is signif- icantly diminished as the oversampling ratio L is decreased. However, the effectiveness of the quantization resolution n is independent of L. Multi-bit modulators are particularly attractive. While multi-bit quantization is tolerant of nonlinearity in the quantizer’s ADC due to noise shaping, it imposes stringent linearity requirements on the quantizer’s DAC [12]. The error due to nonlinearity in the DAC enters the modulator at its input. Thus, the linearity and resolution of the demodulator are limited by the multi-bit DAC. Several methods for reducing the dependence of multi-bit modulators on the linearity of the DAC are described in [12]. The multi-bit modulator has a more complex analog circuitry than that of the 1-bit modulator, and has to use matched components. Noise-shaping modulators using multi-bit quantizers can be used for both ADCs and DACs.  Instead of the multi-bit quantizer, the 1-bit quantizer can be used. Although the 1-bit quantizer is inherently linear, its large quantization noise can cause instability for M > 2. To maintain stability for M > 2, modiﬁcations in the architecture are necessary; this, however, generally reduces the SNR. The full dynamic range given by  12.46  can be achieved for M > 2 by cascading multiple ﬁrst-order modulators with 1-bit quantizers. This requires precise quantization noise shaping in the ﬁrst stage, especially for a low oversampling ratio. In practice, the number of cascaded ﬁrst-order stages is limited to M = 3. The 1-bit noise-shaping modulator is popular for use in CMOS integrated circuit data converters, since the use of a 1-bit DAC does not require precision component matching. At a given oversampling ratio, the resolution that a 1-bit noise-shaping modulator can achieve is limited. Also, due to the substantial quantization noise, the design of analog output ﬁlters for oversampled ADCs is difﬁcult [12].  Although sigma-delta modulation is inferior to PCM in terms of distortion for a given bit budget n, it is robust to analog implementation. Using an imprecise quantizer, the error made by a PCM scheme is bounded below by a positive constant, whereas the error made −k, and thus can be made by a kth-order sigma-delta modulation scheme still decays as n arbitrarily small irrespective of the quantizer precision [2]. Due to the relaxed requirements in terms of the precision of analog circuitry and digital decimation ﬁltering, the sigma-delta ADC has become a good candidate for fabrication using CMOS technology. The task of decimation can be handled entirely by a DSP. Most IC implementations of the sigma-delta ADC use switched-capacitor circuits.  As an alternative to PCM for A D conversion, beta-encoders with error correction have been introduced in [2, 3]. An n-bit beta-encoder quantizes a real number by com- puting one of its n-bit truncated β-expansions. These encoders have almost optimal      484   cid:2   A D and D A conversions  rate-distortion properties similar to that of PCM; also, like sigma-delta modulators, they exploit the redundancy of beta-expansions and thus they are robust with respect to quantizer imperfections.  Since high SNR is achieved only at the center frequency of noise shaping ﬁlters, digital- ization of multiple narrowband channels is not possible for the conventional sigma-delta modulators. This restricts their application in BSs where multiple channels are processed at the same time. One solution is to design B z  as a parameterizable multi-notch function [12]. For more on the theory and design of the delta-sigma data converter, the reader is referred to [12].  12.7 D A converter circuits  The DAC is commonly implemented in the form of a multiplying DAC. The output of such a converter is the product of an array of reference currents or voltages and the input digital code. The input digital code is the PCM code in parallel format. The multiplying DAC has a fast settling time. A generic current source multiplying DAC is shown in Fig. 12.15.  The different current sources can be realized by using a common input reference voltage  Vref but different resistors so that  Ii = 2iI0 = Vref Ri   12.47  where Ri is the resistance of the resistor in the ith branch. This leads to Ri = R0 2i. Such a circuit has some problems for large word length. For SDR applications, typically n = 14. This will lead to R13 = R0 8192. This makes the manufacture of the resistors very difﬁcult, in view of the precision required.  ,  The R-2R ladder structure uses a common reference voltage, but uses current division. All the resistors are either R or 2R. It is more suitable for manufacturing and integration on a single chip. The charge redistribution structure is quite common in CMOS implemen- tation of multiplying DACs, in the same way as in switched-capacitor ﬁlters. The R-2R ladder and charge redistribution structures are discussed in more detail in [18].  Counting DACs and bitstream DACs are two other classes of DACs. Like in the ADC, a S H device is required to counteract problems that occur during the transition from one  n−1I  2  0  4  I  0  2  I  0  I  0  bn  −1  b 2  b1  b  0   cid:2 Figure 12.15  A generic current source multiplying DAC. The digital code is in the form bn−1 ··· b1b0.  MSB  LSB  I  out      485   cid:2   12.8 A D and D A converters for software-deﬁned radios  sample to another, such as glitches and ringing. The zero-order hold, which holds the output constant until the DAC receives the next sample, is commonly used. Sample-and-hold is typically integrated into the DAC.  12.8 A D and D A converters for software-deﬁned radios  For SDRs, the dynamic linearity of an ADC is an important parameter. This parameter is deﬁned by harmonic performance and level of intermodulation products. The SNR is dependent on the number of bits that a sample is represented by. The SNR is improved by the ratio between the bandwidth of a single modulated carrier and that of the Nyquist zone. This ratio is improved by digital ﬁltering following A D conversion. SFDR is a parameter that is more important than SNR or SINAD for evaluation of the performance of ADCs or DACs in SDRs.  For mobile communication systems, the hostile RF environment prevents sophisticated modulation schemes such as 512QAM. Thus mobile systems cannot beneﬁt much from a sampling resolution above 16 bits. This is a reason for many DSPs to perform 16-bit ﬁxed-point arithmetic.  The successive-approximation method is a very common A D conversion technique. Due to the sequential nature, the successive approximation ADC is usually imple- mented for low sampling rates. This is due to the fact that an n-bit ADC uses n successive iterations and the clock rate must be n-times the sampling rate. This lim- its its application for ADCs used in wideband SDRs. For higher rates, the ﬂash ADC, which determines all bits simultaneously, can be used. For n-bit conversion, 2n − 1 comparators are required, thus the ﬂash ADC is limited to low-resolution applications.  Higher resolution can be achieved by cascading two or more lower-resolution successive approximation or ﬂash ADCs. Such ADCs are known as pipeline ADCs. For example, ADI provides the AD6644 ADC, which is a 14-bit, 65-Msamples s device using the multipass conversion technique. The multipass technique is based on the successive-approximation technique, but is much more complex. It uses three cascaded successive-approximation ADCs, and is actually a divide-and-conquer implementation.  Statistics drawn from 914 commercially available ADCs are given in [9]. These ADCs are grouped into seven types of structures: ﬂash, half-ﬂash, folding, SAR, pipelined, sigma- delta, and unknown. The numbers of bits and the sampling rates are plotted in Fig. 12.16. The pipelined and unknown structures have the best overall performance. The SAR ADC has widely ranging sampling rates, and is popular for its range of speeds and resolutions, as well as low cost and power dissipation. Sigma-delta ADCs have the highest resolution with relatively low sampling rates from K samples s to M samples s, while ﬂash ADCs have the highest sampling rates up to G samples s but with a resolution limited to no more than 8 bits. Between these two structures are the unknown structures compromising speed or resolution.      486   cid:2   A D and D A conversions  Theoretical slope = 1 3 b dB  Actual Slope  = 1 2.3 b dB  Flash Folding Half-Flash Pipelined SAR Sigma-Delta Unknown  25  23  21  19  17  15  13  11  9  7  5     N      s t i  B    f o    r e b m u N d e t a t S     0  10  20  30  70  80  90  100  50  60 40 10log fs   dBsps   P Degradation   cid:2 Figure 12.16 Statistics of 914 commercially available ADCs: The number of bits versus sampling rate. P = 2nfs is  a ﬁgure of merit. From [9], Fig.1. c cid:2 IEEE 2005.  Today, ADCs available for SDR span from 12–16 bits with SFDR around 100 dB, and sampling frequency ranging from 60–100 MHz. DACs with 12–14 bits, SFDR of 95 dB, sampling rate up to 400 MHz are now available. Major ADC and DAC vendors for SDR are ADI, National Semiconductor, TI, and Intersil. The UWB technique continues pushing the boundaries of ADCs. The Maxim MAX19693 is a 12-bit, 4.0-Gsamples s DAC, and consumes 1180-mW at 4.0 Gsamples s.1 Atmel’s AT84AS008 is a 10-bit, 2.2-Gsamples s ADC.2 The LTC2209 of the Linear Technology Corp is a 16-bit, 160-Msamples s ADC having an SFDR of 100 dBc at baseband, consuming 1450 mW.3 TI’s ADS548x is a family of 16-bit, 80- to 200-Msamples s ADCs, with an SFDR of 87 to 98 dBc at baseband and a power consumption of up to 2160 mW.4  Problems  12.1 Calculate the SQNR for a signal quantized using 10-bit PCM  uniformly distributed quantization levels . The input signal has the following distribution:  a  px = 1 , for Vfs − Vfs 3 , and 0 elsewhere.  2 , and 0 elsewhere;  b  px = 1  ≤ x ≤ 2Vfs  ≤ x ≤ Vfs  , for − Vfs  2  3  Vfs  12.2 For ADC selection, if the full-scale range of the converter is 10 volts and the rms quantization error is less than 1 millivolt, how many bits are required for the converter? What is the dynamic range of the converter?  1 http:  www.maxim-ic.com   2 http:  www.atmel.com  3 http:  www.linear.com   4 http:  www.ti.com       487   cid:2   References  12.3 Verify that the mean and variance of the random variable ν = 0.5R u − 0.5 , where R is the full-scale range and u is a uniform random number in [0, 1], are mν = 0 and ν = R2 48. σ 2 12.4 The triangular dither pdf is given by Q−ν Q2     ,  p ν  =  if − Q ≤ ν ≤ Q otherwise  0,  ν = 1  and σ 2 6 Q2, where Q is the quantization resolution. The triangular pdf is the convolution of two rectangular ones, and thus ν, a random variable with the triangular pdf, can be obtained as the sum of two independent rectangular random numbers, νi = Q ui − 0.5 , ui = [0, 1], i = 1, 2. Consider the following dither sinusoid:  y n  = x n  + ν n  = A cos 2πf0n  + ν n .  Let A = 0.5Q, f0 = 0.0025 cycles sample, fs = 40 kHz. If the signal is quantized using a 4-bit ADC, and the full range R = 16 volts, plot the spectrums of the quantized undithered sinusoid xQ n  and the quantized dithered sinusoid yQ n .  12.5 Generate an array of 10,000 random numbers with a symmetrical triangular pdf deﬁned on [-1, 1].  References  [1] P. M. Azizi, H. V. Sorensen & J. Van der Spiegel, An overview of sigma-delta  converters. IEEE Signal Process. Mag., 13:1  1996 , 61–84.  [2] I. Daubechies, R. A. DeVore, C. S. Gunturk & V. A. Vaishampayan, A D conversion  with imperfect quantizers. IEEE Trans. Inf. Theory, 52:3  2006 , 874–885.  [3] I. Daubechies & O. Yilmaz, Robust and practical analog-to-digital conversion with  exponential precision. IEEE Trans. Inf. Theory, 52:8  2006 , 3533–3545.  [4] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [5] T. Hentschel & G. Fettweis, Software radio receivers. In F. Swarts, P. van Rooyen, I. Oppermann & M. P. Lotter, eds., CDMA Techniques for Third Generation Mobile Systems  Norwell, MA: Kluwer, 1999 , pp. 257–283.  [6] A. Jamin, P. Mahonen & Z. Shelby, Software radio implementability of wireless LANs. In E. Del Re, ed., Software Radio: Technologies and Services  London: Springer, 2001 .  [7] A. J. Jerri, The Shannon sampling theorem – its various extensions and applications:  a tutorial review. Proc. IEEE, 65:11  1977 , 1565–1596.  [8] W. Kester, ed., Mixed-signal and DSP Design Techniques  Analog Devices Inc.   [9] B. Le, T. W. Rondeau, J. H. Reed & C. W. Bostian, Analog-to-digital converters. IEEE   Oxford, UK: Newnes Elsevier, 2003 .  Signal Process. Mag., 22:6  2005 , 69–77.      488   cid:2   A D and D A conversions  [10] J.-F. Luy, T. Mueller, T. Mack & A. Terzis, Conﬁgurable RF receiver architectures.  IEEE Microwave Mag., 5:1  2004 , 75–82.  [11] J. Max, Quantization for minimum distortion. IRE Trans. Inf. Theory., 6:2  1960 ,  [12] S. R. Norsworthy, R. Schreier & G. C. Temes, eds., Delta-Sigma Data Converters:  Theory, Design, and Simulation  New York: IEEE Press, 1997 .  [13] S. J. Orfanidis, Introduction to Signal Processing  Englewood Cliffs, NJ: Prentice  7–12.  Hall, 1995 .  [14] E. I. Plotkin, M. N. S. Swamy & Y. Yoganadam, A novel iterative method for the reconstruction of signals from nonuniformly spaced samples. Signal Process., 37:2  1994 , 203–213.  [15] J. G. Proakis & D. G. Manolakis, Digital Signal Processing: Principle, Algorithms,  and Applications, 4th edn  Upper Saddle River, NJ: Pearson Prentice Hall, 2007 .  [16] J. Romero, E. I. Plotkin & M. N. S. Swamy, Reproducing kernels and the use of root loci of speciﬁc functions in the recovery of signals from nonuniform samples. Signal Process., 49:1  1996 , 11–23.  [17] A. Rusu, D. R. D. L. Gonzalez & M. Ismail, Reconﬁgurable ADCs enable smart radios for 4G wireless connectivity. IEEE Circ. & Devices Mag., 22:3  2006 , 6–11. [18] D. Stranneby & W. Walker, Digital Signal Processing and Applications, 2nd edn   London: Elsevier, 2004 .  [19] P. P. Vaidyanathan, Multirate digital ﬁlters, ﬁlter banks, polyphase networks, and  applications: a tutorial. Proc. IEEE, 78:10  1990 , 56–93.  [20] R. G. Vaughan, N. L. Scott & D. R. White, The theory of bandpass sampling. IEEE  Trans. Signal Process., 39:9  1991 , 1973–1984.      13  Signals and signal processing  13.1 Basic transforms  We introduce in this section the Fourier, Laplace, and z-transforms, which are closely related. The Fourier transform transfers a time-domain signal into its frequency-domain version, and it is a fundamental transform used in signal processing. The Laplace trans- form is useful for characterizing an analog system, and the z-transform is useful for digital signal processing.  13.1.1 Fourier transform  ∞ cid:26   n=−∞  x t  =  cid:14   It is well-known that a periodic analog piece-wise continuous signal x t  can be represented by a Fourier series  dne jnωt,   13.1   where  dn = 1 T  T 2 −T 2  −jnωtdt,   13.2  T being the period of the signal, and ω = 2π T is the fundamental  ﬁrst harmonic  angular frequency.  x t e  On the other hand, in communication systems, we often have to deal with non-periodic signals, and such signals can be characterized by the Fourier transform. The Fourier transform X  f   of a time-domain signal x t  is deﬁned by −j2πftdt   13.3   −∞ x t e  and the inverse Fourier transform by x t  =  Often the pair can be written in terms of the angular frequency ω = 2πf as   cid:14  ∞ X  f   =  cid:14  ∞  cid:14  ∞  X ω  =  −∞ X  f  e j2πftdf .  −jωtdt,  −∞ x t e   13.4    13.5       490   cid:2    cid:14  ∞  Signals and signal processing  x t  = 1 2π  −∞ X ω e jωtdω.   13.6   A sufﬁcient condition for x t  to have a Fourier transform is that x t  is absolutely integrable over  ∞,∞ . It should be emphasized that this is only a sufﬁcient, but not a necessary condition. An example is x t  = sin ω0t for which X ω  = jπ[δ ω + ω0  − δ ω − ω0 ]. For an LTI system, the input and output are related by   13.7  where h t  is the impulse response of the LTI system, and ∗ represents the convolution operator. Applying the Fourier transform yields  y t  = h t  ∗ x t ,  Y  f   = H  f  X  f  ,   13.8   where H  f  , Y  f  , and X  f   are the Fourier transforms of h t , y t , and x t , respectively.  13.1.2 Laplace transform   cid:14  ∞  The unilateral Laplace transform of a time-domain signal x t  is deﬁned by  X s  =  −stdt,  x t e   13.9  where s = σ +jω is a complex value. The unilateral Laplace transform is typically used for causal signals. When the lower integration limit is −∞, we get the bilateral Laplace trans- form. The Laplace transform reduces to the Fourier transform for σ = 0; it can transform signals that have no Fourier transform.  0  The inverse Laplace transform is deﬁned as   cid:14  ∞ −∞ X σ + jω e jωtdω.  x t  = 1 2π  eσ t  Computation using this deﬁnition is very complex. Laplace transforms for many functions are given in most textbooks on signals and systems.  For the ﬁlter given in time-domain form  13.7 , the Laplace transform gives  Y s  = H s X s .  The s-domain is usually used to characterize continuous-time systems.  The Laplace transform is one of the most powerful tools for analysis and design of linear systems and networks. The Laplace transform unravels the structure of a signal in terms of its poles and zeros. For a stable system, the transfer function H s  has all its poles located in the left half of the s-plane.  Performing the inverse Laplace transform  Given a real rational function of the form F s  = N s  D s   = P s  + N1 s  D s   ,   13.10    13.11    13.12       491   cid:2   13.1 Basic transforms  where N s , D s , P s , and N1 s  are polynomials with real coefﬁcients, and the second term in the last equation is a proper fraction, with the degree of the numerator smaller than the degree of the denominator. The inverse Laplace transform can be easily obtained: the inverse Laplace transform of P s  can be obtained by using   13.13    13.14    13.15   The proper fraction N1 s    cid:19   sn  dtn . D s  can be expressed in partial fractions  L−1[1] = δ t , L−1  cid:26    cid:26    cid:20  = dnδ t  Kj cid:26   =  N1 s  D s   +  Ai s − pi  i  j,j cid:18 =i  k=1  Bj,k  s − pj k ,  cid:3   where Ai’s and Bj,k’s are constants, Kj ≥ 2 for all j. Thus, the inverse transform of N1 s  can be obtained by using  D s    cid:2    cid:3    cid:2   L−1  1 s − pi  = e pit, L−1  1   s − pi k  = tk−1  k − 1 !  e pit.  For signal design, we usually assume there are no multiple-order poles, and thus the second sum-term in  13.14  does not occur.  In order to implement an analog signal processing system, many element building blocks, such as adder, multiplier, differentiator, and integrator, must be used. These building blocks can be active circuits employing the basic operational ampliﬁer. Filters implemented using active circuits are known as active ﬁlters. For ﬁlter design, there are also many passive analog lowpass prototypes making use of LC ladder circuits, as introduced in Chapter 11.  13.1.3 z-transform  ∞ cid:26   ∞ cid:26   The z-transform is the discrete-time counterpart of the Laplace transform, and it is a gen- eralization of the Fourier transform of a sampled signal. The two-sided z-transform is deﬁned as  X z  =  −n,   13.16  where z = es = re jω, r = eσ , is a complex variable. Similarly, the one-sided z-transform of the sequence is deﬁned by  n=−∞  x n z  X z  =  −n.  x n z   13.17  For causal signals, x n  = 0 when n < 0, the two- and one-sided z-transforms are identical. When z = e −st, the z-transform and the Laplace transform of the causal sampled signal are identical. The mapping between the s-plane and the z-plane is shown in Fig. 13.1. The  n=0      492   cid:2   Signals and signal processing  jω  σ  Im z  z    = 1  Re z   cid:2 Figure 13.1  s−plane  z  −plane  Mapping between the s-plane and the z-plane.  left and right halves of the complex s-plane are mapped onto the inside and outside of the unit circle z = 1 in the z-plane, respectively. The jω-axis in the s-plane maps onto the unit circle in the z-plane, since σ = 0 corresponds to the unit circle in the z-plane: zσ=0 = ejωt. The z-transform of a signal exists under certain conditions. The extension of the Fourier transform from the frequency axis to the complex space enables the Laplace transform and the z-transform for transient signals analysis, while the Fourier transform is suitable only for steady-state or time-invariant signal analysis. The z-transforms of some common sequences are given in many textbooks, e.g., [39].  The z-transform is a linear transform just as the Fourier and Laplace transforms are. Hence, all the properties of a linear transform are applicable to the z-transform includ- ing the convolution property. For an LTI system, the input and output sequences are related by  ∞ cid:26   k=−∞  y n  =  x k h n − k  = x n  ∗ h n ,  where h n  is the impulse response of the system. The convolution property leads to the relation   13.18    13.19   Y z  = H z Z z .  H z  is known as the transfer function of the system.  Causality and convergence  When the input x n  exists only for n ≥ 0, the signal is causal  physically realizable . A causal system produces an output response at time t1 for an input at t0, where t0 ≤ t1. When x n  exists for both n ≥ 0 and n < 0, the signal is double-sided, and thus non- causal. LTI systems can be so classiﬁed according to the causality of h n . Noncausal systems are counter-intuitive, they violate the sense of causality, and thus are physically not implementable.      493   cid:2   13.1 Basic transforms   a   Unit circle   b   Unit circle   c    cid:2 Figure 13.2  Stable ROCs for  a  causal,  b  anticausal, and  c  mixed signals. The ×’s represent poles. Note that the ROCs cannot contain any poles.   cid:26   j, j cid:18 =i  Kj cid:26   k=1  The z-transform has a region of convergence  ROC  so that the series in  13.16  con- verges. When the z-transform is a rational function, it is broken into partial fraction expansion   cid:26   m   cid:26   i  X z  = N z  −1  D z−1   =  −m +  A−mz  Ai  1 − piz−1  +  Bj,k   1 − pjz−1 k ,   13.20   where A−m, Ai, and Bj are expansion coefﬁcients, Kj ≥ 2 for all j. The ﬁrst sum-term corresponds to time delays, and the index m can be a positive integer, a negative integer, or zero. Causal signals have ROCs that are outside the maximum pole circle, z > maxi pi, while anticausal signals have an ROC that is inside the minimum pole circles, z < mini pi. Mixed signals have an ROC that is an annular region between two circles: the poles that lie inside the inner circle contributing causally and the poles that lie outside the outer circles contributing anticausally.  A necessary and sufﬁcient condition for the stability of a signal is that the ROC of the corresponding z-transform contains the unit circle [54]. This is illustrated in Fig. 13.2. For a stable causal system all its poles must lie strictly inside the unit circle in the z-plane, that is, 1 > maxi pi. For a stable mixed signal, those poles inside the unit circle contribute causally and those outside the unit circle contribute anticausally. When the poles are on the unit circle, these signals are marginally stable: They neither diverge nor converge to zero for large n, but rather remain bounded.  The inverse z-transform is deﬁned as  Inverse z-transform  ?  x n  = 1 2πj   cid:9   X z z n−1dz,  where  cid:9  is a closed contour lying within the region of convergence.   13.21       494   cid:2   When X z  is a ratio of polynomials, N  −1 z very efﬁciently computed by using the residue theorem  −1   D  z  , the inverse z-transform can be   cid:17    cid:18   resz=pk  X z z n−1  ,  Signals and signal processing   cid:7    cid:8    cid:7    cid:8  X z zn−1dz = K cid:26   k=1  ?  X z z n−1 =     K k=1  ,  N z   z − pk mk  cid:19   x n  = 1 2πj   cid:9   where   13.22    13.23    13.24    13.25    13.26   mk being the multiplicity of pk, and the residue of X z  with respect to pk is given by  resz=pk   X z   =  1   mk − 1  !  dmk−1 dzmk−1   z − pk mk X z    cid:20  cid:4  cid:4  cid:4  cid:4   .  z=pk  The inverse z-transform of X z  may be not unique. It can be unique only by specifying the corresponding ROC. −1, we usually do not use the above residue theorem to solve the inverse z-transform. Instead, it is usually broken into partial fraction expansion of the form  13.20 . The inverse transform can be performed according to  When X z  is a ratio of two polynomials in z  −m −→ δ n − m ,  z  for m∈ Z,   cid:15   1  1 − piz−1  −→  pn i u n , i u −n − 1 , −pn  z > pi z < pi  .  If there are multiple-order poles, one has to resort to some tables for ﬁnding the transforms. The MATLAB function residuez performs the partial fraction expansion.  13.2 Discrete-time Fourier transform  The discrete-time Fourier transform  DTFT  is obtained by evaluating the z-transform on the unit circle, z = e jω. For a discrete signal x n , its frequency response is given by  X ω  =  −jωn.   13.27  Note that here ω = 2πf  fs, in radians sample, where fs is the sampling frequency. The spectrum X ω  of a signal only exists for a stable signal, that is, a signal whose ROC of z-transform contains the unit circle.  n=−∞  x n e  The inverse DTFT recovers the discrete signal x n  from its spectrum X ω  over the  Nyquist interval  x n  = 1 2π  X ω e jωndω.   13.28   ∞ cid:26    cid:14  π  −π      495   cid:2   13.2 Discrete-time Fourier transform  Parseval’s theorem relates the total energy of a sequence to its spectrum  ∞ cid:26   n=−∞   cid:14  π  −π  x n 2 = 1 2π  X ω 2dω.   13.29   The shape of a spectrum X ω  is inﬂuenced by the pole zero pattern of the corresponding z-transform X z . When a pole is close to the unit circle, the denominator will have a small distance at the frequency corresponding to the pole, leading a peak there. Similarly, when a zero is close to the unit circle, it causes a dip in the frequency spectrum at a certain frequency. By suitably placing the poles and zeros, one can design some simple ﬁlters such as resonator, notch, or comb ﬁlters. This has been discussed in [54]. Notch or comb ﬁlters are used for cancellation of periodic interference such as harmonics, while peaking comb ﬁlters are used for enhancement of periodic signals in noise.  The discrete Fourier transform  DFT  and its fast implementation, the fast Fourier trans- form  FFT  are most important for digital signal processing. They are mainly used for calculation of the frequency spectrum of a signal, efﬁcient implementation of convolution, and speech or image coding. The discrete cosine transform  DCT , as a variant of DFT, is widely used for image coding. Note that the DTFT is deﬁned for aperiodic signals.  13.2.1 Windowing  Implementation of DTFT must employ time-windowing, since the number of samples may be inﬁnite, x nT , −∞ < n < ∞. We need to keep only a ﬁnite number of samples, x nT , 0 ≤ n ≤ L − 1. Thus, DTFT is actually performed on the windowed signal  A rectangular window of length L is deﬁned by  xL n  = x n w n .  cid:15   w n  =  1, 0,  .  0 ≤ n ≤ L − 1 otherwise ∞ cid:26   The DTFT of the length-L signal at a single frequency is thus given by −jωn = XL ω .  −jωn =  xL n e  x n e  X ω  = L−1 cid:26   n=0  n=−∞  Windowing reduces the frequency resolution of the computed spectrum, and the resolv- able frequency resolution is given by  cid:18 f = 1 LT . Also, spurious high-frequency components are introduced into the spectrum due to the hard clipping of the signal x n  by the window, leading to frequency leakage. This is because the rectangular window has the spectrum of a sinc function, which has many undesirable sidelobes. The height of the sidelobes is 13 dB lower than the mainlobe. The mainlobe width determines the frequency resolution limits of the windowed signal spectrum   13.30    13.31    13.32    13.33    cid:18 f ≥  cid:18 fw = 1 LT  .      496   cid:2   Signals and signal processing  From this a desirable data length L can be calculated according to the frequency resolution.  The rectangular window cuts the data to zero sharply, and this leads to signiﬁcant fre- quency leakage. By using windows that cut off to zero gradually, the sidelobes can be effectively suppressed. The widely used Hamming window can suppress the sidelobe to at least 40 dB lower than the mainlobe. The Hamming window is given by 0 ≤ n ≤ L − 1 otherwise  0.54 − 0.46 cos 0,  w n  =   13.34      2πn L−1   cid:18    cid:17   ,  .  The Kaiser window has a controllable suppression of the sidelobes by adjusting the shape  cid:25  parameter α. The Kaiser window is deﬁned by [40] 1 −  n − M 2 M2   cid:18    cid:17    13.35  where L = 2M + 1, and I0 x  is the modiﬁed Bessel function of the ﬁrst kind and zeroth order. It is also symmetric about its middle n = M. When α = 0, it reduces to the rectangular window.  I0 α   0 ≤ n ≤ L − 1,  w n  = I0  α  ,  Example 13.1: The rectangular, Hamming, and Kaiser windows are plotted in Fig. 13.3. It is seen that the Kaiser window approximates the Hamming window for α = 5 and reduces to the rectangular window for α = 0.  1  0.8  0.6  0.4  0.2    n      w     rectangular Hamming Kaiser, α = 1 Kaiser, α = 5 Kaiser, α = 9  30 n  0 −10  0  10  20  40  50  60  70   cid:2 Figure 13.3  Illustration of different windows.      497   cid:2   13.2 Discrete-time Fourier transform     B d        W    2  0  −20  −40  −60  −80  −100  −120  0  Rect Hamming Kaiser, α = 4 Kaiser, α = 6   cid:2 Figure 13.4  Illustration of different windows in the frequency domain, for L = 128.  0.02  0.04  0.06  0.08  f  fs  The Fourier transform of these windows are given as  −jπfLT sin πfLT   ,  πf   cid:17   Wrec  f   = e  cid:18   −j2πft  1 − e  WHamming  f   = 0.04 jπf   13.36    13.37   πf  −jπft sin πfLT   + 0.46e  cid:17  cid:25   cid:25  π 2α2 −  LTπf  2 π 2α2 −  LTπf  2  sinh  1  1 −   fLT 2 .  cid:18   .   13.38   WKaiser  f   = LT I0 π α   The closed-form expression for the Kaiser window does not exist, and an approximation is given by [35]  Example 13.2: The frequency spectrums of the rectangular, Hamming, and Kaiser win- dows, for L = 128, are plotted in Fig. 13.4. It is observed that the rectangular window has the narrowest mainlobe  best frequency resolution  but the sidelobes are only 13 dB lower than the mainlobe. The Hamming window has a wider mainlobe with the sidelobe 40 dB lower. The Kaiser windows for α = 4 and 6 are wider than that of the Hamming window, but the sidelobes are more than 90 dB lower than the mainlobes.  Nonrectangular windows lead to a lower and wider mainlobe, thus reducing the  frequency resolution. The effective width of the mainlobe is given by [54]   13.39  where c = 1 for the rectangular window, c ≈ 2 for the Hamming window, and c = 6 R+12  for the Kaiser window, R being the variable sidelobe suppression in decibels and from  155  ,   cid:18 fw = c  1 LT      498   cid:2   Signals and signal processing  which α can be calculated [40]. A longer window achieves a better frequency resolution  cid:18 f . By using the Kaiser window with adjustable sidelobe level R, very weak sinusoids can be pulled out of the DTFT spectrum, while for the Hamming window, sinusoid amplitude 40 dB less than the strongest sinusoid in the signal cannot be detected in the spectrum.  13.2.2 DFT  The N-point DFT of a length-L signal is the DTFT evaluated at N equally spaced frequen- cies over the Nyquist interval, 0 ≤ ω ≤ 2π, that is, ωk = 2πk N-point DFT is given by  N , k = 0, 1,··· , N − 1. The  xnWkn,  k = 0, 1,··· , N − 1,   13.40   Xk = X ωk  = L−1 cid:26   x n e  n=0  −jωkn = L−1 cid:26   n=0  where W = e In matrix form  −j2π N.  X = DFT x  = Ax,   13.41  where x =  x0, x1, . . . , xL−1 T, X =  X0, X1, . . . , XN−1 T, and A = [Akn]N×L. The DFT requires NL complex multiplications. Usually, N and L are selected to be equal. In this case, the inverse DFT can be derived from  13.41  by using matrix inversion. If L < N, N − L zeros are padded at the end of the data record; zero padding has no effect on the DTFT. If L > N, the data record can be reduced to N by modulo-N wrapping, since the length-N wrapped signal ˜x has the same N-point DFT as the original unwrapped signal x  X = Ax = ˜X = ˜A˜x.   13.42   For L > N, the required number of complex multiplications for DFT after wrapping is N2 and wrapping requires L − N complex multiplications, thus the total cost for wrapped DFT is N2 + L − N MACs  multiply-accumulates ; if the Cooley-Tukey version of FFT [21] is used for the implementation of DFT, the required number of MACs reduces to 2 N log2 N + L − N. 1 ∗ cid:8  cid:20 ∗ The inverse DFT of X gives an unique wrapped version of x, i.e., ˜x [54]   13.43  where * stands for complex conjugate. Note that ˜x = x only if N ≥ L. Similarly, IFFT can be performed by  ˜x = IDFT X  = ˜A  ˜A ∗  DFT   cid:7   X  ,  −1X = 1 N  cid:19    cid:19  X = 1 N ∗ cid:8  cid:20 ∗  cid:7   IFFT X  = 1 N  FFT  X  .   13.44   The discrete Hartley transform can be viewed as the real counterpart of DFT, when it is applied to real signals. It has efﬁcient fast algorithms [15, 45]. The discrete Hartley transform can be used as a tool for performing fast convolutions and for performing FFT and fast DCT.      499   cid:2   13.2 Discrete-time Fourier transform  13.2.3 FFT   cid:7    cid:8   FFT is based on a divide-and-conquer approach to the computation of DFT. The simplest Cooley-Tukey version of FFT [21], known as the radix-2 FFT, requires N to be a power of two, so that the dimension of the DFT is successively divided in half until it reduces to unity. FFT can be implemented as decimation-in-time FFT or decimation-in-frequency FFT. Both FFT algorithms have a computational cost of N complex multiplica- tions and N log2 N complex additions. Note that a complex multiplication requires four real multiplications and two real additions, and a complex addition corresponds to two real additions. When the number of samples is not a power of two, in order to use FFT, zero padding can be used. Zero padding does not increase the true resolution in frequency, but interpolates the spectrum at more points. An efﬁcient bit-reversal algorithm for FFT implementation is given in [64].  2 log2   cid:7    cid:8   N 2  When N is a power of four, the radix-4 FFT algorithm can be used. The radix-4 FFT further reduces the computational complexity to 3 complex multiplications, but has the same number of complex additions, compared to the radix-2 FFT. This leads to a reduction in the number of multiplications by at least 25%. These algorithms are described in most signal processing texts such as [57].  4 N log4  N 4  In the radix-2 decimation-in-frequency FFT algorithm, the even-numbered points can be computed independent of the odd-numbered points. The split-radix FFT, known as radix 2 4 FFT, exploits the idea by using the radix-2 algorithm for computing the even- numbered samples and radix-4 for computing the odd-numbered samples. The split-radix FFT requires the lowest number of multiplications and additions, amongst the radix- 2, radix-4, radix-8, and split-radix FFTs [31]. A best implementation of the split-radix FFT can reduce the total number of multiplications to less than half that of the radix-2 FFT, while the number of additions remains almost the same [61]. Radix-2 4 and 2 8 FFT algorithms have also been proposed for computing the DFT of length N = q × 2m [5, 8]. In [65], DFT algorithms for real signals have been derived from the radix-2 FFT for complex data. The number of required real multiplications for the proposed algorithms is one half that of the radix-2 FFT, and the number of required real additions is also less than that for the radix-2 FFT. In [66], FFT algorithms were designed by operating on vectorized data. This leads to a signiﬁcant reduction in the overhead operations associated with the radix-2 FFT while improving the simplicity and regularity of their implementations.  FFT pruning algorithms increase the efﬁciency of the FFT by removing operations on input values which are zero, and on output values which are not required. In [3], a new pruning FFT algorithm was proposed, using a simple modiﬁcation in the decimation-in- time or decimation-in-frequency FFT algorithm. Also, the number of inputs or desired outputs can be arbitrary and can be located in any position of the input  output vector. Efﬁcient pruning algorithms for computing the DFT for a subset of output samples have been proposed based on the radix-2 decimation-in-time and decimation-in-frequency FFTs in [7].  The radix-2 and split-radix FFT algorithms have been generalized to 2-D, 3-D, or an arbitrary dimension by several authors [10, 11, 14]. These algorithms, known as vector radix FFT algorithms, substantially reduce the number of arithmetic operations over the      500   cid:2   Signals and signal processing  method that implements FFT dimension by dimension. The radix-2 8 approach is the best among all the existing radix-based approaches for 1-, 2-, and 3-D cases [11]. These results have been extended to the discrete Hartley transform [9, 12, 13].  FFT based on logarithmic number system  log-FFT  has also been proposed [67]. Log- FFT provides better SNR than that FFT implemented with a ﬁxed-point or ﬂoating-point number system. Use of ﬁnite-precision log-FFT substantially reduces the complexity, com- pared to ﬁxed-point FFT [74]. C codes for the DTFT and the decimation-in-time radix-2 FFT algorithm are given in [39, 54].  Convolution of two sequences h and x corresponds to the frequency domain relation  Convolution using FFT  y = h ∗ x ←→ Y ω  = H ω X ω .  cid:8    cid:7   FFT h  · FFT x   ˜y = IFFT  ,  Thus, y can be derived as the inverse DTFT of Y ω . By using the modulo-N circular convolution, we have  2 N log2 N + N complex multiplications.  which has a complexity of 3 To make the circular convolution ˜y equal to the ordinary convolution y, it is necessary to have N ≥ L y, where L y is the length of the sequence of y. Assuming the signal x having a length of L and the ﬁlter h having an order of M, we have L y = L + M. The sequences h and x are zero-padded to length N before applying the N-point FFT.  A spectral power estimate can be obtained as  Power spectrum density  ∞ cid:26   n=−∞  Sxx ω  = X ω 2,  cid:14  π  cid:4  cid:4  cid:4  cid:4  cid:4 2 =  −jωn  x n e  x n 2 = 1 2π  −π  ∞ cid:26   k=−∞  where X ω  is the Fourier transform of the signal x n . From Parseval’s theorem, given by  13.29 , the energy of the signal x n  can be expressed by  Sxx ω dω.   13.48   For a signal with inﬁnite energy, the PSD is deﬁned by   cid:4  cid:4  cid:4  cid:4  cid:4  N cid:26   cid:23 xx ω  = lim  cid:20   cid:19  2N + 1 N→∞  n + k  ∗  x n x  1  n=−N  where Rxx k  = E of the ACF.  −jωn,  Rxx k e   13.49   is the ACF. Thus, the PSD can be obtained as the DFT   13.45    13.46    13.47       501   cid:2   13.3 Digital ﬁlters  13.3 Digital ﬁlters  13.3.1 FIR and IIR ﬁlters  An LTI system can be either a ﬁnite impulse response  FIR  or an inﬁnite impulse response  IIR  system, depending on whether its impulse response has ﬁnite or inﬁnite duration. An LTI system is characterized uniquely by its impulse response sequence h n , which is the output of the system when the input is unit impulse δ n . For an input sequence x n , the output sequence is the convolution of the input with the impulse response h m x n − m .  y n  = h n  ∗ x n  =  x j h n − j  =   cid:26    cid:26    13.50   j  m  The impulse response coefﬁcients h 0 , h 1 ,··· , h M  are known as the ﬁlter coefﬁcients or ﬁlter taps.  For the IIR ﬁlter,  ∞ cid:26   m=0  y n  =  0 ≤ n < ∞.  The z-transform of h n  is known as the transfer function of the ﬁlter  IIR ﬁlters  H z  =  −n,  h n z  n=−∞  h m x n − m , ∞ cid:26  = b0 + cid:24  1 + cid:24  aiy n − i  + M cid:26   i=0  y n  = − N cid:26   i=1  which can be represented in a recursive form  H z  = B z  A z   −i M i=1 biz i=1 aiz−i N  ,  where ai and bi are the ﬁlter coefﬁcients. The IIR ﬁlter has L zeros and N poles, an order of N. The output of the ﬁlter is given by  bix n − i .   13.54   For stable and causal IIR ﬁlters the speed of response is controlled by the poles nearest to the unit circle. The closer the poles to the unit circle, the sharper the peak of the time response, but the slower the ﬁlter reaches its steady state response.   13.51    13.52    13.53       502   cid:2   Signals and signal processing  FIR ﬁlters  For the FIR ﬁlter, h n  extends only over a ﬁnite time interval, from 0 ≤ n ≤ M. The length M is referred to as the ﬁlter order  h m x n − m ,  0 ≤ n ≤ M.   13.55   y n  = M cid:26   m=0  The FIR ﬁlter corresponds to the case when A z  in  13.53  reduces to 1.  Linear-Phase FIR Filters  An FIR ﬁlter has an exact linear phase property only when it has symmetric impulse response h n  = h M − n  or antisymmetric impulse response h n  = −h M − n . In the latter case, a constant phase shift of π 2 is introduced. An FIR ﬁlter with nonlinear phase delay causes ISI. −1, can be implemented using memory or by a shift register. Var- ious block- and sample-based DSP implementations of FIR and IIR ﬁltering in C language are given in [54].  The one-sample delay, z  FIR ﬁlter versus IIR ﬁlter  The FIR ﬁlter is often used in communication system design. It is always stable, and is free of limit cycles that arise from ﬁnite wordlength representation. By selecting the FIR coefﬁcients as being symmetric or antisymmetric about the center of the ﬁlter, linear phase response is achieved, and this effectively avoids distortion. This is important since both the amplitude and the phase carry information.  The IIR ﬁlter contains feedback from the past output values. It can generally achieve the same magnitude response of an FIR ﬁlter by using a lower-order design. Thus, for a given frequency response, the FIR ﬁlter usually has more coefﬁcients, resulting in more computation and longer processing delay. However, IIR ﬁlters are much more difﬁcult to design. An IIR implementation is not unconditionally stable: it is stable only when the poles are all inside the unit circle. IIR implementation may be used in consumer electronics, where price and power are primary concerns. The low computation load of IIR enables the use of lower-cost DSP, and consumes less power.  13.3.2 Stability  According to the deﬁnition of causality, some ﬁlters, such as FIR smoothing ﬁlters, FIR interpolation ﬁlters, and inverse ﬁlters, are double-sided  noncausal  ﬁlters. For FIR smoothing and interpolation ﬁlters, their negative-side or anticausal part has ﬁnite duration. The ﬁltering equation is given by  h m x n − m .   13.56   y n  = M cid:26   m=−D      503   cid:2   13.3 Digital ﬁlters  yD n  = M+D cid:26   hD m x n − m ,  Such ﬁlters can be made causal by the following transformation so that they are imple- mentable in real time  m=0   13.57  where yD n  = y n − D  and hD m  = h m − D  are the delayed versions of y n  and h m  by time D. For LTI systems, stability is more important than causality. A stable LTI system has an impulse response tending to zero in a sufﬁciently fast manner as n → ±∞, so that a bounded input yields a bounded output. A necessary and sufﬁcient condition for stability in this sense is given by  ∞ cid:26   n=−∞  h n  < ∞.  A stable doubled-sided system can be implemented by taking a sufﬁciently large neg- ative integer n = −D and setting h n  = 0 for n < −D. This is because h n  tends to zero for large negative n. Such treatment is useful for the design of the inverse ﬁlter, Hinv z  = 1 H z , which is used for equalization. The stability of an IIR ﬁlter is determined by the coefﬁcients in the denominator A z , namely ai. To maintain the stability of the ﬁlter, the ROC must contain the unit circle. To further make the stable ﬁlter causal, all the poles must lie inside the unit circle.  Given input x n  and ﬁlter h n , the output y n  is obtained by convolution  If one needs to calculate x n  from y n , the inverse ﬁlter can be used  In the z-domain, we have  13.3.3 Inverse ﬁlters  y n  = h n  ∗ x n .  x n  = hinv n  ∗ y n .  Hinv z  = 1 H z   .  Inverse ﬁltering is typically used for channel equalization. In digital communications, the channel distorts the original transmitted signal, and an inverse ﬁlter is needed to restore the transmitted signal, which is distorted by the channel. Such a ﬁlter is called a channel equalizer. For inverse ﬁlter design, we need to consider the stability and also the effect of noise on the restored result. Assuming H z  to be both stable and causal, the poles of H z  must be strictly inside the unit circle but the zeros can be anywhere on the z-plane. Since Hinv z  = 1 H z  , those zeros of H z  becomes poles of Hinv z , which may be outside the unit circle. In this case, the stable inverse z-transform hinv n  is anticausal. This stable and anticausal ﬁlter can be   13.58    13.59    13.60    13.61       504   cid:2   Signals and signal processing  implemented by clipping off at some large negative time n = −D. For multiple poles outside the unit circle, the one closest to the circle controls the decay time-constant of the negative-time tail of hinv n , and D is actually decided by it.  13.3.4 Minimum-, maximum-, and mixed-phase systems  An Mth-order FIR system has M zeros 1 − z1z −1  H z  = b0   cid:17   For the FIR system   cid:18  cid:17   1 − z2z  cid:7    cid:17    cid:18   cid:8    cid:18   where zi’s are zeros and b0 is a gain constant. The frequency response is given by H ω  = H . When all the zeros of the ﬁlter are inside the unit circle, for each real-valued zero or each pair of complex-conjugate zeros, the corresponding term or the pair of complex-conjugate factors in H ω  have a net phase change of zero between ω = 0 and ω = π, leading to a total system phase relation  e jω   cid:18  H π  −  cid:18  H 0  = 0.   13.63   −1  ···  1 − zMz  −1  ,   13.62   Such a system is called a minimum-phase system. On the contrary, when all the zeros are outside of the unit circle, each real-value zero will contribute a net phase change of π over the frequencies ω = 0 and ω = π, and each complex-conjugate pair contributes 2π over the same frequency range. The resulting system phase change is given by   cid:18  H π  −  cid:18  H 0  = Mπ.   13.64   Such a system is a maximum-phase system. When some of the zeros are distributed inside as well as outside the unit circle, the system is called a mixed-phase system.  The derivative of the phase characteristic is a measure of the time delay of the signal frequency components. The minimum-phase systems correspond to minimum delay, and are thus especially important.  For the IIR system  An IIR system with a transfer function rational form H z  = B z  A z    13.65   is a minimum-phase system if all its poles and zeros are inside the unit circle. When all the poles are inside the unit circle, we get a stable and causal system; such a system can be further classiﬁed as maximum-phase if all the zeros are outside the unit circle and mixed- phase if some of the zeros are outside the circle. As a result, a stable pole-zero system that is minimum-phase has a stable inverse H  −1 z  = A z  Z z  .      505   cid:2   13.3 Digital ﬁlters  A mixed-phase pole-zero system can always be implemented as a cascade of a  minimum-phase system and a stable, all-pass, maximum-phase system  H z  = Hmin z Hap z ,   13.66   where the all-pass ﬁlter Hap z  is an IIR ﬁlter whose magnitude response is unity for all ω, i.e., H ω 2 = 1.  13.3.5 Notch and comb ﬁlters  A comb ﬁlter is a narrowband peaking ﬁlter with several equally spaced passbands starting at f = 0, whereas a dual notch ﬁlter has narrowband nulls at these frequency points. Peaking  comb  and notch ﬁlters can be designed using pole zero placement. They are complementary with transfer functions H z  and H s , frequency responses H ω , and the magnitude responses squared H ω 2 [54]  Hcomb z  + Hnotch z  = 1; Hcomb ω  + Hnotch ω  = 1; Hcomb ω 2 + Hnotch ω 2 = 1.  The pole zero placement-based method is sufﬁcient for narrow-width ﬁlters. For wider peak or notch widths  cid:18 f at peak notch frequency f0 with sampling rate fs, one can use second-order analog peak or notch ﬁlter prototypes and transform them into digital ﬁlters by using the bilinear transformation [54].  The notch or peaking ﬁlter can be designed by using a second-order transfer function of  the form  where  ,  H z  = B r, z   cid:18  cid:17  A ρ, z  1 − ρe  cid:18  cid:17    cid:17  1 − ρe jω0z  cid:17   −1   cid:18   cid:18   −jω0z  −1  ,  A ρ, z  =  B r, z  =  1 − re jω0z  −1  1 − re  −jω0z  −1   13.72  for 0 < r ≤ 1 and 0 < ρ ≤ 1. It is clear that the larger the distances from the zeros to the unit circle and the smaller the distances from the poles to the unit circle, the larger the magnitude of H ω . Hence, by properly placing the poles and zeros we can obtain various magnitude response. If ρ  cid:2  r, the pole is closer to the unit circle than the zero, leading to a peak at ω = ω0; if ρ  cid:3  r there is a dip at the frequency. If r = 0, it becomes a resonator at ω = ω0. Finally, if r = 1, we gets an exact zero, or a notch, at ω = ω0. High-order resonators, comb and notch ﬁlters can be obtained by cascading second-order ones.   13.67    13.68    13.69    13.70    13.71       506   cid:2   Signals and signal processing  The case of r = 1 for a notch ﬁlter can be extended to multiple frequencies. In this case, the numerator becomes   cid:18  cid:17    cid:18   1 − e jωiz  −1  1 − e  −jωiz  −1   13.73   B z  = M!   cid:17   i=1  −1 with ρz  −1. All the zeros are on the unit and the denominator is obtained by replacing z circle at the desired notch frequencies. If ρ is close to but less than unity, we get notch ﬁlters. Note ρ should be less than unity, since this helps to ensure the poles are inside the unit circle to ensure the stability of the system. −1z, and r is close to but less than ρ If in the numerator z in  13.73  is replaced by r so that the notch zeros are moved inside the unit circle and behind the poles, this leads to sharp peaks at ω = ωi. Notch and comb ﬁlters are used for signal enhancement  noise reduction. Notch ﬁlters are used to remove these harmonics of a noise signal as shown in Fig. 13.5, while comb ﬁlters are used to enhance harmonics of the desired signal as shown in Fig. 13.6. Para- metric equalizer ﬁlters can be designed as a linear combination of notch and peaking ﬁlters. For a comb ﬁlter that enhances all harmonics of a fundamental frequency f1 at a sampling rate of fs = Df1, one can use a transfer function of the form  Hcomb z  = b  1 + z −D 1 − az−D ,  b = 1 − a  .  2   13.74   Hnotch ω   Noise  Signal  Filtered signal  Hnotch ω    cid:2 Figure 13.5  Notch ﬁlter for noise reduction.  0  ω  1  2ω  1  3ω  1  ω  0  ω  1  2ω  1  3ω  1  ω  Signal Hcomb   ω   Noise  Signal   ω   Hcomb  Filtered noise   cid:2 Figure 13.6  Comb ﬁlter for signal enhancement.  0  ω  1  2ω  1  3ω  1  ω  0  ω  1  2ω  1  3ω  1  ω      507   cid:2   13.4 Digital ﬁlter design  b m o C    , 2    ω   H    h c t o N    , 2    ω   H    1  0.5  0  0  1  0.5  0  0  0.2  0.4  0.6  0.8  1  1   cid:2 Figure 13.7  Illustration of a comb ﬁlter and its dual multi-notch ﬁlter.  0.2  0.4  0.6  0.8  ω π  The ﬁlter parameters can be determined by the desired 3-dB width of the peaks,  cid:18 ω, and can be obtained using the bilinear transformation method [54]   cid:2    cid:3   a = 1 − β 1 + β The frequency response magnitude squared is given by  β = tan  D cid:18 ω  4  ,  ,  b = β 1 + β  .   13.75    13.76   Hcomb ω 2 =  β2  tan2 ωD 2  + β2 .  Example 13.3: The magnitude responses squared of a comb ﬁlter and its dual multi-notch ﬁlter with D = 20 and 3-dB width  cid:18 ω = 0.01π are shown in Fig. 13.7.  Based on the complementary properties, the equations for notch ﬁlters can be easily obtained from  13.67  to  13.69 . Comb ﬁlters with variable gain and peak width can also be designed using IIR ﬁlters. Retrieval of a signal corrupted by a strong FM interference has been studied by applying constrained notch ﬁltering in [76–78].  13.4 Digital ﬁlter design  Digital ﬁlter design starts with a set of design speciﬁcations and produces a set of impulse response coefﬁcients h =  h0, h1,··· , hM−1 T for FIR ﬁlters, or the numerator and denominator coefﬁcients for IIR ﬁlters.  Popular ﬁlters are lowpass, highpass, bandpass, and bandstop ﬁlters. These ﬁlters have symmetric frequency response in the Nyquist interval, and have real-valued and symmetric      508   cid:2   Signals and signal processing  impulse responses. Ideal differentiator and Hilbert transformer ﬁlters have antisymmetric frequency responses, and real-valued and antisymmetric impulse responses.  For the same cutoff frequencies, the lowpass highpass and bandpass bandstop ﬁlters are  complementary. That is,  dLP n  + dHP n  = δ n  ←→ DLP ω  + DHP ω  = 1, dBP n  + dBS n  = δ n  ←→ DBP ω  + DBS ω  = 1.  D ω  =  1, −ωc ≤ ω ≤ ωc 0, −π ≤ ω < −ωc, or ωc < ω ≤ π .   cid:15   The frequency response of an ideal lowpass ﬁlter over the Nyquist interval is deﬁned by  The impulse response is given by  d n  = sin ωcn   , −∞ < n < ∞,  which is double-sided and inﬁnite, and d 0  = ωc π. Similarly, the impulse response for the bandpass ﬁlter with cutoff frequencies ωa < ωb  is given by  d n  = sin ωbn  − sin ωan   , −∞ < n < ∞.  πn  πn  13.4.1 FIR digital ﬁlter design  Window method  In order to implement these ﬁlters, d n  must be clipped at a large negative value of n, say −M, by using a rectangular or other window, and then making it causal by introducing an appropriate delay:  h n  = d n − M w n , −∞ < n < ∞,   13.82  where w n  is nonzero only when n = 0, 1, . . . , L − 1, and L = 2M + 1. The rectangular, Hamming, or Kaiser window can be used. For the rectangular window, we have  h n  = d n − M ,  n = 0, 1, . . . , L − 1.  The ﬁlter can be implemented by  h m x n − m .  y n  = 2M cid:26  M cid:26   m=0  −M  k=−M  The transfer function is given by H z  = z  −k = z  −M ˆD z ,  d k z   13.77    13.78    13.79    13.80    13.81    13.83    13.84    13.85       509   cid:2   13.4 Digital ﬁlter design  where ˆD z  is the truncated z-transform. The window design leads to a linear phase prop- −jωM, since ˆD z  has the same symmetry or  −M = e  erty, arising from the delay factor z antisymmetry property as D z .  The rectangular window has the Gibbs phenomenon of Fourier series: it has largest rip- ples of approximately 8.9% near the passband-to-stopband discontinuity on both sides, and this is independent of the window size L. The Hamming window is a popular choice. The ripples in the passband stopband have maximum overshoots of about 0.2%, but a wider transition width is obtained compared to the rectangular window. The Kaiser window design provides a good control over the ﬁlter design speciﬁcations, and the designer can arbitrarily specify the passband and stopband overshoot δpass, δstop and the transition width  cid:18 f . The M and α parameters of the Kaiser window  13.35  are computed from the ﬁlter speciﬁcations.  The Kaiser window method is a simple and popular ﬁlter design method for most ﬁlter speciﬁcations [4]. However, it may result in a long ﬁlter length that is not satisfactory for a stringent applications.  An FIR ﬁlter H z  can be sharpened by cascading the same ﬁlter, leading to a new,  sharpened transfer function H2 z  [34].  Parks-McClellan method  The window method is a straightforward design procedure for approximating the desired magnitude response. The method is, however, not efﬁcient for designing FIR ﬁlters with speciﬁc speciﬁcations. A number of optimization-based FIR design methods such as the weighted least squares method and the Chebyshev method are given in the literature [29]. The Parks-McClellan method [42] is a Chebyshev optimal method, which is based on the optimum equiripple approximation in both the passband and the stopband. It is used for linear-phase FIR ﬁlter design. The method uses the minimax criteria, and thus the designed ﬁlter is an equiripple ﬁlter. It generally leads to a shorter ﬁlter than the Kaiser window method. The Parks-McClellan method employs the Remez exchange algorithm, and is a common method for designing optimal linear-phase FIR ﬁlters. The method approximates the passband speciﬁcation while requiring as few taps as possible. A computer program is available for designing all types of linear-phase FIR ﬁlters [43].  Frequency sampling method  For an arbitrary frequency response D ω , the frequency integral may be very difﬁcult to obtain. In this case, the frequency integral can be obtained by using the frequency sampling method  ˜d k  = 1  D ωi e jωik,−M ≤ k ≤ M,   13.86  where N = 2M + 1, and ωi = 2πi N, −M ≤ i ≤ M. After the frequency response is obtained, a suitable window method can be applied.  i=−M  N  M cid:26       510   cid:2   Signals and signal processing  FIR ﬁlter design using MATLAB  MATLAB provides the Filter Design and Analysis Tool  FDATool  as the interface to its Signal Processing Toolbox and Filter Design Toolbox. FDATool provides easy and optimal ﬁlter design.  For the window method, given the design speciﬁcations, if the Kaiser window is used, the MATLAB function kaiserord is used to estimate the order of the FIR ﬁlter. After the order of the FIR ﬁlter is obtained, the fir1 function can be used to design the ﬁlter. MATLAB provides the fir1 function for linear-phase FIR ﬁlter design using the window method, fir2 for FIR ﬁlter design using the frequency sampling method, and firls for FIR ﬁlter design using least-squares error minimization.  For using the Parks-McClellan method, the remezord function is used to estimate the FIR order, given the FIR design speciﬁcations. Its output can be used to design the FIR using the remez function. The remez function gives the Parks–McClellan optimal equiripple FIR ﬁlter design.  Example 13.4: Design an FIR lowpass ﬁlter with speciﬁcations: ωs1 = 0.28, ωp1 = 0.30, ωp2 = 0.40, and ωs2 = 0.42, δp = 0.1, δs = 0.001. The results obtained by using the Kaiser window method, the Hamming window method, and the Parks-McClellan method are shown in Fig. 13.8. For the Hamming window method, the ﬁlter order is estimated by using remezord. The order obtained by remezord is very conservative. Thus, the corresponding ﬁlter obtained does not meet the passband speciﬁcations. This can be solved by extending the passband range and increasing the ﬁlter order N by trial and error until the speciﬁcations are satisﬁed.  Kaiser N = 363 Hamming N = 179 Parks-McClellan N = 179     B d     2     ω H       0  −20  −40  −60  −80  −100  0   cid:2 Figure 13.8 Magnitude responses of FIR bandpass ﬁlters. The normalized frequency ω = 1 represents the  Nyquist frequency.  0.2  0.4  0.6  0.8  1  ω      511   cid:2    cid:2 Figure 13.9  13.4 Digital ﬁlter design  Digital filter spec.  Bilinear transform. Ω = g ω   Analog filter spec.  Analog filter design  Analog filter Ha S   Bilinear transform. s = f z   Digital filter H z   IIR ﬁlter design using the bilinear transformation method  13.4.2 IIR ﬁlter design  By far the most popular IIR design method is the bilinear transformation method. The dig- ital ﬁlter speciﬁcations are ﬁrst mapped onto equivalent analog ﬁlter speciﬁcations, based on which an analog ﬁlter is designed. The designed analog ﬁlter is then mapped back to obtain the corresponding digital ﬁlter. This procedure is shown in Fig. 13.9. This method cannot transform all the properties of an analog ﬁlter to a digital one. Many other IIR ﬁlter design methods are available in [4, 29].  The digital ﬁlter is based on the z-plane design, while the analog ﬁlter is based on the s-plane design. The relation between the two planes is given by a transformation of the type  s = f  z .   13.87  In the frequency domain, s = j cid:20  and z = ejω, where  cid:20  and ω are the analog and digital frequencies, respectively. From  13.87 , we have  cid:20  = g ω .   13.88   For a digital lowpass ﬁlter design, we select   13.89    13.90    13.91   Similarly, for bandpass ﬁlter design, we use  and thus  and accordingly  s = f  z  = 1 − z −1 1 + z−1   cid:20  = g ω  = tan    s = 1 − 2cz  −1 + z 1 − z−2  cid:20  = c − cos ω  ω 2   .  −2  .  sin ω   13.92  When c = 1, the bandpass ﬁlter reduces to the lowpass ﬁlter, and c = −1 leads to a highpass one. It requires c ≤ 1 to ensure that the left half of the s-plane is mapped into the inside of the unit circle in the z-plane to guarantee the stability and causality of the designed digital ﬁlter. The bilinear transformations for the highpass and bandstop cases can be similarly deﬁned [54]. A lowpass ﬁlter H z  can be transformed into a highpass ﬁlter by substituting z → −z. This changes the impulse response hn →  −1 nhn. A bandpass or bandstop digital ﬁlter can      512   cid:2   Signals and signal processing  also be designed by using a lowpass ﬁlter prototype with a bandpass or bandstop version of the bilinear transformation.  Higher-order ﬁlters achieve sharp cutoffs. The lowpass ﬁlter prototype can be designed using the analog Butterworth, Chebyshev, or elliptic ﬁlter design methods. Compared to the Butterworth ﬁlter, the Chebyshev and elliptic ﬁlters have a steeper transition width and also a smaller ﬁlter order, for a given set of design speciﬁcations. The Chebyshev ﬁlter can take the form of either equiripple passband and monotonic stopband  type-I , or equiripple stopband and monotonic passband  type-II .  IIR ﬁlter design using MATLAB  In MATLAB Signal Processing Toolbox, there are several functions for analog ﬁlter design, buttap, cheb1ap, cheb2ap, and ellipap, and several functions for analog frequency transformations lp2bp, lp2hp, lp2lp, lp2bs etc.  MATLAB provides functions for IIR ﬁlter design: buttord and butter  Butter- worth , cheb1ord and cheb1  Chebyshev type-I , cheb2ord and cheb2  Chebyshev type-II , and ellipord and ellip  elliptic ﬁlters .  Example 13.5: Consider the design of an IIR bandpass ﬁlter with ωs1 = 0.2, ωp1 = 0.3, ωp2 = 0.5, ωs2 = 0.6, the passband ripple Rp = 1 dB, and stopband attenuation Rs = 60 dB. The magnitude responses of the designed ﬁlters using the Butterworth, Chebyshev type-I, Chebyshev type-II, and elliptic ﬁlters are plotted in Fig. 13.10. Among the four designs, the Butterworth ﬁlter has the largest order N = 11, while the elliptic ﬁlter has the lowest order N = 5.  Butterworth, N = 11 Chebyshev I, N = 7 Chebyshev II, N = 7 Ellipse, N = 5     B d      2     ω   H    0  −10  −20  −30  −40  −50  −60  −70  −80   cid:2 Figure 13.10 Magnitude responses of IIR bandpass ﬁlters. The normalized frequency ω = 1 represents the  Nyquist frequency.  0  0.2  0.4  0.6  0.8  1  ω      513   cid:2   13.5 Adaptive ﬁlters  Many signal processing programs, including FIR and IIR ﬁlter design programs, are  available in [39] in the C and MATLAB languages.  Yule-Walker approximation   cid:14    cid:7    cid:7    cid:8  cid:4  cid:4 H  W  e jω  e jω   cid:8  cid:4  cid:4 2 dω,   cid:8  − D  cid:7   cid:7   e jω   cid:8   ejω  In addition to the maximally ﬂat approximation, the Chebyshev approximation, and the equiripple approximation we have discussed so far, the least-squares approximation is also widely used in ﬁlter design. The least-squares approximation minimizes the error function over a frequency region  J ω  =   cid:7    cid:8    cid:7    cid:8   e jω  where D designed, and W  is the desired frequency response, H  is the response of the ﬁlter  e jω  is a weighting function.  The Yule-Walker approximation is an IIR ﬁlter design technique that approximates arbi- trary magnitude response. The method minimizes the error between the desired magnitude in the least squares sense. In MATLAB, the and the magnitude of the IIR ﬁlter H yulewalk function is given for this purpose.  e jω   cid:7    cid:8    13.93   13.4.3 Hardware implementation of digital ﬁlters  For the ﬁxed-point implementation of digital ﬁlters, round-off errors and coefﬁcient quan- tization errors must be considered. These errors arise from rounding the ﬁlter coefﬁcients, or the internal computation result, to a ﬁnite number of digits. These errors may lead to inaccurate frequency response for FIR ﬁlters and may lead to instability for IIR ﬁlters.  For IIR ﬁlters, conventional direct or canonical ﬁlter realizations are extremely sensi- tive to these errors. IIR ﬁlters can be efﬁciently implemented in cascade of second-order sections. The cascade second-order realizations may be made more robust to such round- off errors by suitably ordering pairing the conjugate pairs. After the design of a hardware implementation of a digital ﬁlter is completed, one must reexamine the stability and the speciﬁcations of the ﬁlter.  For the implementation of high-order ﬁlters with closely clustered poles in the z-plane, the cascaded form can lead to less stability and inaccurate frequency responses. Modern DSP chips are reducing these errors by using long wordlength for coefﬁcient storage and double precision accumulators for calculation. The use of ﬂoating-point DSPs can further reduce these errors.  13.5 Adaptive ﬁlters  Estimation theory started from Kolmogorov and Wiener’s work in the 1940s for  wide sense  stationary processes. When the MMSE criterion is used for the solution, the resulting estimation is known as the Wiener estimation. The Wiener ﬁlter requires the      514   cid:2   Signals and signal processing  knowledge of the auto- and cross-correlations, and it also involves complex matrix inver- sion operation. To adjust the ﬁlter coefﬁcients as new data arrive in real time, the LMS algorithm [75] modiﬁes the MSE along the steepest gradient direction. For a time-varying channel, a forgetting factor is introduced for calculating the autocorrelation matrix, and the RLS algorithm is derived by using the matrix inversion lemma.  For a nonstationary signal plus noise, Kalman proposed an optimum solution using the method of least squares in the 1960s. The method tries to ﬁnd the estimate that minimizes the conditional-error covariance matrix, and the solution is known as the Kalman estima- tion. The criterion is the minimum variance, which can be viewed as a stochastic version of the least squares criterion. The RLS algorithm is a simpliﬁed version of the Kalman ﬁlter. The Kalman ﬁlter is the optimum ﬁlter in the Gaussian noise case, and is the best linear ﬁlter in the non-Gaussian case, in the sense of the minimum variance criterion. In the fre- quency domain, the Kalman ﬁlter can be regarded as a lowpass ﬁlter with a varying cutoff frequency [63]. The Kalman ﬁlter is introduced in most texts for adaptive signal processing such as [63, 71]. The 2-D Kalman ﬁlter is an extension to the Kalman ﬁlter [81].  In addition to these adaptive implementations of linear ﬁlters, many nonlinear signal processing applications based on neural networks and fuzzy logic [30] are available in the literature.  13.5.1 Wiener solution  The most common processor model is the adaptive linear combiner, which is widely used for adaptive interference cancellation, predictive coding, equalization, and beamforming. It has M inputs, each being scaled by a different coefﬁcient or weight  y k  = xT k w k  = wT k x k ,   13.94  where the inputs x k  =  x0 k , x1 k ,··· , xM−1 k  T, and the weights w k  =  w0 k , w1 k ,··· , wM−1 k  T. These weights are adjustable. The ﬁlter output is compared with the desired signal, and the error is used to adjust the weights so that the error is further reduced. The error at time k is deﬁned by  where d k  is the desired signal at time k. Accordingly  Assuming that e k , d k  and x k  are statistically stationary, the MSE E  e k  = d k  − y k  = d k  − wTx k ,  cid:8   e2 k  = cid:7  = d2 k  + wTx k xT k w − 2d k xT k w.  cid:22    cid:8  cid:7  d k  − xT k w  cid:23   d k  − wTx k   cid:22   cid:20   = E  e2 k    cid:23    cid:19   x k xT k   ,  d2 k   + wTRxxw − 2rT  cid:20    cid:19   d k xT k   .  rdx = E  w,  dx  MSE = E  Rxx = E   13.95    cid:19    cid:20    13.96   e2 k   is   13.97    13.98   given by  where      515   cid:2   13.5 Adaptive ﬁlters   cid:19    cid:20   The Wiener ﬁlter is obtained by differentiating E  e2 k   with respect to w and setting  the derivative to zero  The MSE obtained by the Wiener solution is minimum  w = R  cid:22   cid:23   −1 xx rdx.   cid:22    cid:23   MSEmin = E  = E  − rT  dx  w.  σ 2 d  e2 k  The Wiener ﬁlter can also be formulated in the frequency domain by minimizing E where E  f   is the frequency-domain representation of e t  with respect to W  f   [71].  ﬁcients. For the FIR or transversal ﬁlter, xn = cid:7   Digital ﬁlters are typically comprised of a tapped delay line with unit delays and coef-  xn, xn−1, . . ., xn−M+1  at time n, and w is the channel impulse response vector of length M. The Wiener solution can also be applied to an IIR ﬁlter, but results in a set of nonlinear equations.   13.99    cid:19    13.100    cid:20   cid:8 T is the input vector  E2  f    ,  13.5.2 LMS algorithm  The Wiener solution is computationally expensive due to the matrix inversion operation. Conventional gradient-descent and Newton’s methods can be applied to the MSE to ﬁnd the optimum solution. These methods can ﬁnd the optimum solution in a few steps. However, since the performance surface is noisy, in order to estimate the gradient at each step, many samples are required.  The LMS algorithm is widely used in adaptive signal processing. For the adaptive linear combiner, the LMS algorithm uses a special estimate of the gradient. It uses e2 k  as an estimate of E  for the purpose of gradient estimation, thus  e2 k    cid:19    cid:20   ˆ∇ k  = ∂e2 k   ∂w  = −2e k x k .  The LMS algorithm is a gradient-descent algorithm of the form  w k + 1  = w k  − μ ˆ∇ k  = w k  + 2μe k x k ,  where the choice of the step size μ must be 0 < μ < 2 , λmax being the maximum λmax eigenvalue of Rxx, to ensure convergence [30, 71]. The spread in the convergence speed of weights is proportional to the spread in eigenvalues of Rxx, that is, λmax λmin.  The LMS algorithm is simple and efﬁcient, since the gradient estimate is obtained from a single data input. It converges to a solution much faster than the gradient-descent algorithm, particularly for a large number of weights.   13.101    13.102   13.5.3 RLS algorithm  The RLS algorithm is a recursive formulation of the Wiener solution. It can also be derived by applying the matrix inversion lemma to R−1 xx . Like the LMS algorithm, the RLS is also a most widely used adaptation algorithm. The RLS algorithm can be derived by      516   cid:2   Signals and signal processing  exponentially weighting the data to remove gradually the effects of old data on w k  and to allow the tracking of slowly varying signal characteristics. It is given as [39]  where  w k  = w k − 1  + G k e k , P k  = 1  P k − 1  − G k xT k P k − 1    cid:20   ,   cid:19   γ  P k − 1 x k ,  G k  = 1 α k  α k  = γ + xT k P k − 1 x k .   13.103    13.104    13.105    13.106   P k  is essentially a recursive way of computing the inverse matrix R−1 xx . The forgetting factor γ is typically elected between 0.98 and 1. Smaller values add weight to the more recent data, leading to ﬂuctuations in the estimation. When γ = 1, the RLS reduces to the LS.  The RLS algorithm is one-order of magnitude faster in convergence than the LMS algo- rithm. However, the RLS method has two main problems [39]. The blow-up problem occurs if the signal xk,i is zero for a long time. This causes P k  to grow exponentially as a result of division by the forgetting factor γ . The second problem is its sensitivity to round-off errors, and this may lead to a negative deﬁnite P matrix and eventually to instability. This latter problem can be solved by using the UD factorization of P [39].  13.6 Digital up-conversion and digital down-conversion  The digital front-end of a wireless transceiver performs digital up-conversion in the trans- mit path and digital down-conversion in the receive path. Digital up-conversion is used to transform baseband signal to digital bandpass signal, whereas digital down-conversion performs the reverse operation. The idea is to modulate the signal using an NCO. For the classical SDR structure, as shown in Fig. 1.3, both digital down- and up-conversion contain a digital frequency-conversion part and a sampling-rate conversion part.  For numerical implementation, an LUT is conventionally employed for calculating the sine and cosine of the angle. The carrier frequency is adjustable. To avoid a large LUT, the CORDIC  Coordinate Rotation Digital Computer  processor [72] can be used to cal- culate the sine and cosine functions. CORDIC is an iterative method that computes the rotation of a two-dimensional vector  rotation mode  or converts between cartesian and polar coordinates  vectoring mode  by using only additions and shift-operations.  Typically, for each carrier the digital down- or up-conversion module requires several thousand MIPS  million instructions per second . This is equivalent to the processing power of one or more high-end DSPs such as Texas Instruments  TI ’s TMS320C6x or Analog Devices Inc  ADI ’s TigerSHARC [38]. Some spare capacity is also required. When the budget for processing power is tight, hand-crafted assembly code may have to be      517   cid:2   13.6 Digital up-conversion and digital down-conversion  used to provide a processing capacity margin. In order to reduce cost and power consump- tion as well as space, digital up- down-conversion can be conveniently implemented using ASICs or ﬁeld programmable gate arrays  FPGAs . There are many commercially available digital up- and down-conversion chips that are designed for popular wireless communica- tion standards. Major vendors of digital down- and up-conversion chips are Intersil, ADI and TI. Their chips are software programmable ASICs, also known as application-speciﬁc standard parts  ASSPs , and they are programmable within a speciﬁed range. These devices have internal microcode processors, and can be programmed via microprocessor interfaces. Digital down- and up-conversion chips have on-chip NCOs. The NCO generates digital sine waveforms for digital mixers. Sine and cosine NCOs are used for quadrature I and Q mixing, respectively. A digital mixer multiplies the input digital signal with a digital sine  or cosine  waveform, and produces sum and difference frequencies. The SFDR of the NCO must be considerably better than the SFDR of the digital down- up-conversion output, since the spurious response in the NCO also mixes with unwanted out-of-band signals.  13.6.1 Numerically controlled oscillators  A simple numerical oscillator   cid:7    cid:8    cid:8  cid:7   From  13.70 , we see that the ﬁlter 1 + a1z−1 + a2z−2  H z  =  1   13.107  is a resonator at ω = ω0. We have a1 = −2r cos ω0 and a2 = r2. The unit sample response is given by  1 − rejω0z−1  1 1 − re−jω0z−1  =   13.108  where u n  is the Heaviside step function, u n  = 1 for n ≥ 0 and 0 otherwise. When the poles are placed on the unit circle  r = 1 , we obtain a digital sinusoidal oscillator  h n  = rn sin ω0  sin n + 1 ω0u n ,  h n  = 1 sin ω0  sin n + 1 ω0u n .  Coupled-form oscillator   13.109   An oscillator can be modeled as an ampliﬁer with its output fed back to its input via a phase-shifting network [68]. As mentioned earlier in Chapter 11, two necessary conditions for oscillation, namely, Barkhausen’s criteria, are: the total loop gain is one, and the total loop phase shift is a multiple of 2π radians.  In order to generate two sinusoidals at the same time, an oscillator iteration can be  written as [68]   cid:2    cid:3    cid:5   =  x1 n  x2 n   a c  b d   cid:6  cid:2    cid:3   .  x1 n − 1  x2 n − 1    13.110       518   cid:2   Signals and signal processing  This is known as the coupled-form oscillator. It is not driven by any input, but it requires initial conditions in order to start self-sustaining oscillation.  The discrete-time equivalents of Barkhausen’s criteria are given as  After some manipulation, the generated sine waves are given by   cid:6   ,  a + d < 2.  ad − bc = 1,  cid:5   =   cid:5   x1 n  x2 n    cid:6   cid:31 −c , ψ =  cid:5   b  ,  cos nθ   ψ cos nθ + φ    cid:12    d − a  + j  cid:6   φ = arg  cid:5    cid:6   =  x1 0  x2 0   1  ψ cos φ   .   cid:13    cid:25  4 −  a + d 2 2b   13.111    13.112    13.113    13.114   where θ = cos −1   cid:3    cid:2   a + d 2  and  , accordingly a = d.  The angle θ is the step angle for iteration, and φ is the phase shift between the two state variables. To obtain a quadrature oscillator, φ = ±90 ◦ By selecting different parameters for ψ, φ, and θ, different types of oscillators are designed. Accordingly, a, b, c, and d can be decided. DSP implementation can be eas- ily realized by using  13.110 . The generated sine waves are always of the same frequency. A number of oscillators in this framework are also introduced in [68]. To combat accu- mulated errors, a dynamic amplitude control using an AGC is also given. For NCOs, the oscillator frequency can be changed via θ. A procedure for designing a dynamic amplitude, frequency controlled oscillator is also given in [68].  When Barkhausen’s criteria are satisﬁed,  13.110  corresponds to vector rotation in the two-dimensional coordinate system, and the coupled-form oscillator can be implemented using the CORDIC algorithm.  13.6.2 Direct digital frequency synthesis  DDS is a technique for generating waveforms. DDS generates a digital sine wave from an LUT, and uses a DAC and a lowpass ﬁlter to generate the analog waveform. This method is extremely accurate. A cheap solution is to use the CORDIC algorithm [72] to generate a digital waveform. For analog modulation, the signal to be modulated is fed as input to the CORDIC processor, and the result is then transformed to analog form using a DAC [70]. The maximum frequency that DDS can generate is limited by the sampling rate of existing DACs, typically a few hundred megahertz.  ICs are available for generating waveforms up to hundreds of MHz. The DDS technique has a number of advantages: an arbitrary tuning frequency resolution, the phase and fre- quency of the waveform controllable in one sample period, implementation using integer arithmetic, guaranteed stability and non-requirement of AGC, and phase continuity in case      519   cid:2   13.6 Digital up-conversion and digital down-conversion  t  t  N  Accumulator  ROM   cid:2 Figure 13.11  Clock  DDS principle.  of frequency change. These features make DDS desirable for realizing PM and tunable waveform generators.  DDS is used to generate any periodic, discrete-time waveform of known frequency fo. It is implemented in two steps. An accumulator is used to generate a discrete-time phase value, followed by a phase-to-waveform converter to generate the desired signal. This is shown in Fig. 13.11. In the ﬁgure, N is a programmable step. The accumulator is a register of word length M bits. When the ROM contains a table for generating a sine function, the generated waveform is a digital representation of a sinusoid. In this case, the DDS system is actually an NCO. By changing N, we can synthesize waveforms of different frequency. The generated digital waveform can be converted into an analog waveform after being D A-converted and ﬁltered.  The output frequency fo is given by [22] fo = fs 2M   cid:18 ACC,   13.115  where  cid:18 ACC is the phase increment during one sample period, coded as an integer of M−1 bits and fs is the sampling frequency. Thus the maximum and minimum output frequencies are fs 2 and fs 2M, respectively. For phase-to-waveform conversion, the phase is converted into amplitude using P ≤ M bits. The output waveform is stored in an LUT with 2P entries. To generate a sine wave, the corresponding sine function is stored in the LUT  LUT i  = a sin   13.116   4   cid:17    cid:18  where a is a peak amplitude. To generate two quadrature signals, both LUT i  and i + 2P LUT are read to generate the two waveforms. The LUT memory size is of 2P P − 1  bits. One can increase P to improve the SFDR of generated waveform. Techniques for improving SFDR can be implemented through waveform compression, through the CORDIC algorithm, by using odd-number  cid:18 ACC, or by adding a dither signal to the ACC phase values, followed by noise shaping [22]. The CORDIC algorithm conﬁgured   cid:2    cid:3   2πi 2P      520   cid:2   Signals and signal processing  in the rotation mode can behave as a quadrature phase-to-amplitude converter that directly generates sine and cosine waveforms [70].  A digital waveform generator can be implemented as a circular buffer, which can be accessed from a table. This is the so-called wavetable synthesis. Various wavetable gen- erators and oscillators are implemented in C and hardware DSP in [54]. The inputs to the generator are amplitude, frequency and the wavetable, and the output is the generated oscillating signal.  DDS offers a number of advantages over PLL-based frequency synthesis. First, it avoids analog VCO devices, leading to a low phase noise, which is approximately that of the clock. Since there is no analog feedback loop, DDS is much faster for channel switching than the PLL technique. It also allows direct signal modulation in the digital domain. The frequency steps can be made very small by increasing the word length. However, due to Nyquist’s sampling theorem, the sampling rate would be very high for the RF band, exceed- ing today’s DAC capability. This is the major restriction that prevents its wide use in the RF band.  An all-digital PLL can be realized by feeding back the generated digital waveform to a register that performs phase comparison so as to stabilize the generated waveform [33], just like an analog loop with a sinusoidal phase detector in the analog domain. Stability analysis of ﬁrst-order and second-order all-digital PLLs is given in [33].  13.7 Sampling-rate conversion  In SDR applications, the wideband ADC uses a ﬁxed sampling rate, while different air- interfaces use different chip or symbol rates. This requires multirate processing.  The sampling rate needs to be an integer multiple of the modulation symbol rate to achieve synchronization between the receiver and the transmitter. For multiple carrier and or symbol rate systems, it is not uncommon that the sampling rate is not an integer multiple of the symbol rate. For example, if the sampling rate is 2.4 times the symbol rate, the oversampling rate can be selected as 3 or a large integer multiple. Sample-rate conver- sion between them is necessary. This can be achieved by ﬁrst applying interpolation by 5, ﬁltering, and then decimation by 4, that is, 2.4 × 5 4 = 3. Decimation periodically removes all samples except every Rdth sample. This leads to a reduction in sample rate by a factor of Rd, hence a reduction in bandwidth by a factor of Rd. Interpolation increases the sampling rate by Ri. Interpolation is achieved by ﬁrst stufﬁng Ri − 1 zero-valued samples, then using a lowpass ﬁlter to remove images, and using a gain stage to restore the amplitude of the original signal.  A large oversampling rate requires more computation for signal processing. Since syn- chronization is performed at the receiver side, the transmitter side does not need sampling rate conversion, but interpolation is still required to raise the digital sampling rate to be an integer multiple of the symbol rate. The resampling processing must be followed by ﬁlter- ing to eliminate aliasing. Interpolation can be very efﬁciently implemented as polyphase ﬁlters.      521   cid:2   13.7 Sampling-rate conversion  T  n  f  s  n  n  T  = T K  T  = T K  Kf s  Kf  s  Hint  Upsampler  FIR filter  K  f   cid:2 Figure 13.12  0  f  s  Kfs  0  f  s  Kf  s  f  Increasing sampling rate by interpolation.  13.7.1 Interpolation  Interpolation is used to increase the sampling rate by resampling the original low-rate sam- ples. For an upsampling factor of K, K − 1 zeros are inserted between any two adjacent low-rate samples. The upsampled signal is given by   cid:15    cid:7    cid:14  cid:8  =  xup  n   cid:14  = nK n otherwise  .  x n , 0,   13.117   An FIR interpolation ﬁlter is a lowpass ﬁlter that removes the high frequencies intro- duced by the inserted zeros, and as a result, in the time domain, the K−1 zeros are replaced by the calculated interpolated values. The interpolation ﬁlter operates at a sampling rate of Kfs, and is also called the oversampling digital ﬁlter, as an analogy to the oversampling analog ﬁlter. Use of digital oversampling helps to alleviate the need for high-quality analog anti-image postﬁlters after the DAC. The interpolation procedure is shown in Fig. 13.12. = Kfs,  cid:14  The ideal K-fold interpolation ﬁlter is a lowpass ﬁlter, operating at the fast rate f and having a cutoff frequency at the low-rate Nyquist frequency fc = fs 2. Digital over- s sampling keeps one of every Kth image of those of the low-rate images, thus making the post-image ﬁlter much cheaper. The FIR interpolation ﬁlter can be designed by truncating the impulse response d  k  k  d   cid:7    cid:14  cid:8   cid:7   cid:14  cid:8  = sin  cid:7   cid:14  cid:8   cid:14  cid:8   cid:14  cid:8  = w  cid:7   cid:7   cid:14  cid:8  = KM cid:26   cid:14  cid:8    cid:7   h  d  n  n  k  d  k  k cid:14 =−KM   cid:7   yup  n   cid:8   to ﬁnite length N = 2KM + 1: , −KM ≤ k  cid:8    cid:7   cid:14  K πk πk cid:14  K  cid:7    cid:14  − KM n  cid:14  cid:8   cid:7    cid:14  − k n  ,  ,  xup  The impulse response d window is applied  is ﬁrst delayed by KM samples to make it causal, then a   cid:14  = 0, 1, . . . , N − 1.  n   13.119   The ideal interpolation is obtained by the convolution of the unsampled input with the windowed impulse response; for the rectangular window   cid:14  = 0, 1, . . . , N − 1.  n   13.120    cid:14  ≤ KM.   13.118       522   cid:2   Signals and signal processing   13.121    13.122    13.123    13.124   The function of an ideal interpolation ﬁlter is to reproduce the interpolated samples correctly. In the frequency domain, it reshapes the low-rate sampled spectrum X  f   by using the ideal interpolation ﬁlter D  f  , and the output spectrum is given by  For the ideal interpolator, we have D  f   =  Yup = D  f  X  f  .  cid:15   f ≤ fs 2 fs 2 < f ≤ f   cid:14  s  .   2  K, 0,  Thus, the ﬁlter removes all replicas at multiples of the input sampling rate fs, except those that are multiples of the output rate Kfs. Many interpolation techniques are discussed in [71].  Polyphase form  The high-rate FIR interpolating ﬁlter can be implemented by K FIR subﬁlters, called polyphase ﬁlters, each operating at a low rate of fs and having 1 K length of the origi- nal ﬁlter. This leads to considerable saving in complexity and is also suitable for parallel processing. The polyphase form works on the low-rate sample rather than the upsampler output. The ith polyphase subﬁlter is deﬁned by [54]  di k  = d kK + i , −M ≤ k ≤ M − 1  and  yi n  = M−1 cid:26   k=−M  di k x n − k ,  i = 0, 1, . . . , K − 1.  The polyphase form requires a complexity of only 2KM multiplications, while the direct form requires 2K2M multiplications.  Multistage form  Ki and an interpolator Hi, i = 1, . . . , Nstage. The overall interpolation factor is K =  and the overall frequency response is H  f   =   Interpolation ﬁlters can be implemented in the multistage form, by gradually increasing the sampling rate until the ﬁnal rate is reached. Each stage contains an upsampler with a factor Ki Hi  f  . Such multistage realizations allow additional savings in complexity over the multiphase form. Each interpolator removes all replicas at multiples of its input rate, except those at multiples of its output rate. Finally K − 1 out of K replicas are removed and only those replicas at multiples of Kfs remain. Interpolators at each stage can be designed using the Kaiser window method.  The effective passband ripple of the whole ﬁlter H  f   is worse than the ripples of the individual factors. For a multistage ﬁlter, when the oversampling ratios are placed in an ascending order from the ﬁrst to the last stage, it can lead to reduced passband ripples [54]. The ﬁrst ﬁlter has typically a very narrow desired transition width  cid:18 f , and thus has the most stringent speciﬁcations. Following stages have wider transition widths, and thus can      523   cid:2   13.7 Sampling-rate conversion  be implemented with shorter ﬁlter lengths, and the simple hold or linear interpolators can be used. These simple hold or linear interpolators do not have ﬂat passband. The ﬁrst ﬁlter can be designed by equalizing all the passband attenuation of the subsequent stages. The general multistage design procedure is given in [23].  Hold and linear interpolators  The ideal interpolator is an ideal lowpass ﬁlter. It can be treated as the sampled version of  cid:14  s. Like the analog reconstructor, the ideal analog reconstructor, sampled at the high rate f two simple interpolators are the hold and linear interpolators. Unlike the ideal interpo- lator that is approximated by using long ﬁlter length, these simple interpolators can be used in the case of later stages of multistage implementation of interpolators, where the speciﬁcations are not stringent. These ﬁlters can also implemented in the polyphase form. Interpolation between low-rate samples can be performed by holding the previous sample constant until the next low-rate sample. This is the simplest hold interpolator resulting from the S H analog reconstructor. The linear interpolator between two low-rate samples, which is based on the linear analog reconstructor, is also used. An interpola- tion ﬁlter that uses more adjacent samples for interpolation usually yields more accurate values.  The impulse responses of the hold and linear interpolators are given, respectively, by   cid:15      cid:7   cid:7   d  k  d  k   cid:14  cid:8  =  cid:14  cid:8  =  1, 0, otherwise  0 ≤ k 1 − k  cid:14  K ,   cid:4  cid:4 k   cid:14  < K − 1   cid:14  cid:4  cid:4  ≤ K − 1  0,  otherwise   hold ,   13.125    linear .   13.126   The corresponding ﬁlter implementations in the polyphase form are given by   cid:2  yup nK + i  = x n  yup nK + i  =   cid:3   1 − i K  x n  + i K  x n + 1    hold ,   linear ,   13.127    13.128   for i = 0, 1, . . . , K − 1. Their frequency responses are given by [54]  −jπ K−1 f  Kfs e  D  f   = sin πf  fs  sin  πf  Lfs  D  f   = 1 L   cid:4  cid:4  cid:4  cid:4  sin  πf  fs   sin  πf  Kfs    cid:4  cid:4  cid:4  cid:4 2   cid:14  Both frequency responses are periodic in f with period f n = 1, 2, . . . , K − 1. s   hold ,   13.129    linear . = Kfs, and are zero at f   13.130  = nfs,  cid:14  s  Example 13.6: The frequency responses of the hold and linear interpolators are compared with the ideal interpolator in Fig. 13.13, for K = 10. The linear interpolator has much better frequency response than the hold interpolator.      524   cid:2   Signals and signal processing  Hold Linear Ideal     f    D    10  8  6  4  2  0  0   cid:2 Figure 13.13  Frequency responses of ideal, hold, and linear interpolators, for K = 10.  2  4  6  8  10  f  f  s  n T  = T K  n  T  f s = Kfs  Kfs  Hdec  FIR filter  fs  K  Downsampler   cid:2 Figure 13.14  0  f  s  Kf  s  f  0  f  s  Kf  s  f  0  f  s  Kf  s  f  Decreasing sampling rate by decimation.  13.7.2 Decimation   cid:14  s to f   cid:14  s   13.131   Decimation is the reverse of interpolation: It reduces the sampling rate from f  K. This downsampling process keeps one out of every K high-rate samples and discards all the remaining K − 1 samples. The downsampled signal is deﬁned by   cid:14  cid:7  xdown n  = x   cid:14  cid:8    cid:14    nK .   cid:19 −fs 2, fs 2   cid:20   In the ideal case, the high-rate signal x has no frequency components outside the low- . The downsampled signal xdown n  is equal to the low- rate Nyquist interval rate signal x n  which corresponds to the resampled signal from the original analog signal at the lower rate fs. The decimation process is shown in Fig. 13.14. Note the downsampling process leads to replicas of the original spectrum at multiples of the low rate fs.  n  In general, a digital lowpass ﬁlter called the decimation ﬁlter is located in front of the downsampler to remove those frequency components of the high-rate signal that are outside , and in this case, the downsampler output gives the low-rate Nyquist interval the correct decimation result. Without this decimation preﬁlter, the out-of-band frequency   cid:19 −fs 2, fs 2   cid:20       525   cid:2   13.7 Sampling-rate conversion  components will lead to aliasing, and the downsampler output will not be the correct dec- imation output. The combination of the decimation preﬁlter and downsampler is called a decimator.  In multistage implementation of decimators, the most stringent decimator is placed as the last stage, as opposed to the case of the interpolation ﬁlter. The earlier decimators can be implemented using the decimation version of the hold interpolator, which is a simple FIR averaging ﬁlter that averages K successive high-rate samples. Conversely to the inter- polator, the passbands of the earlier decimators can be equalized by the last decimator. The use of decimators can also alleviate the need for high quality analog preﬁlters prior to the ADC.  13.7.3 Sample rate converters  In order to achieve a sampling rate by any rational factor, K M, so that the input and output  cid:14  rates are related by f s  =  K M fs, a common oversampling rate is required   cid:14  cid:14  f s  = Mf   cid:14  s  = Kfs   13.132   cid:14  This can be achieved by ﬁrst interpolating from fs by a factor of K and then decimating f  cid:14  s by a factor of M. The interpolating ﬁlter and decimating ﬁlter both operate at f s and are lowpass ﬁlters, thus they can be combined into a single lowpass ﬁlter by selecting a cutoff frequency fc = 1 . This sampling rate conversion process is shown in Fig. 13.15. The combined ﬁlter has a complexity that is M times smaller than the polyphase rate Kfs for full interpolation, since the downsampler selects only every Mth ﬁlter output from the interpolator output.  2 min  fs, f   cid:8    cid:7    cid:14  s  The sequence of the cascade decimator and interpolator in a sample rate converter is very important. Decimation by a factor M followed by interpolation by K is not equivalent to interpolation by K followed by decimation by M. They are identical if and only if K and M are relatively prime [69]. This is important for efﬁcient implementation of ﬁlter banks. More discussion on multirate digital signal processing is given in [23, 39, 54].  13.7.4 Cascaded integrator comb  CIC  ﬁlters  CIC ﬁlters efﬁciently perform decimation and interpolation without using multiplication [37]. This multiplierless architecture is especially attractive for hardware implementation. The basic building blocks are integrator and comb. An integrator is a single pole IIR ﬁl- , or y n  = y n − 1  + x n  in the time domain. A comb is an ter, HI z  = 1   1 − z  −1   cid:8    cid:7   f  s  f  s  K  Upsampler  H  Filter  f  s  f s  M  Downsampler   cid:2 Figure 13.15 Sampling rate converter from fs to K  M fs. The ﬁlter is a combined interpolation decimation ﬁlter.      526   cid:2       nx  dR   a   Signals and signal processing  R i   b   I  I  C  C  C  C  I  I  ny          nx      ny   cid:2 Figure 13.16 Two-stage CIC ﬁlters.  a  Decimation by a factor of Rd.  b  Interpolation by padding Ri zeros.  −M, or y n  = x n − x n− M  in the time domain, odd-symmetric FIR ﬁlter, HC z  = 1− z M usually being one or two. A CIC ﬁlter is realized by cascading the integrator with the comb ﬁlter or vice versa.  A decimating CIC can be formed by cascading N integrators, followed by a decimator that reduces the rate by a factor of Rd, and N combs. An interpolating CIC can be built by cascading N combs, followed by an interpolator that increases the rate by a factor of Ri, and N integrators. Two-stage decimating and interpolating CIC ﬁlters are shown in Fig. 13.16. A single integrator by itself is unstable. For CIC ﬁlters, the integrators and comb ﬁlters work at different sampling frequencies: one at a high frequency and the other at a low frequency. The Noble identities are used to generate an equivalent frequency response of their cascade at the high frequency, in which all the integrator and comb ﬁlters use the same sampling frequency. The transfer function for a CIC ﬁlter is [37]  H z  = HN  I  z HN  C  zR  =  1 − z  −RM N  1 − z−1 N  =   cid:13 N  −k  z  ,   cid:12  RM−1 cid:26   k=0  where R can be Ri or Rd. Thus, a CIC ﬁlter is equivalent to N FIR ﬁlters, and it is uncondi- tionally stable. Since these FIR ﬁlters are symmetric, the CIC ﬁlter has a linear phase and hence constant group delay.  The magnitude response of an N-stage CIC ﬁlter at high frequency is given by [37]   13.133    13.134    cid:4  cid:4  cid:4  cid:4  sin πMf    sin πf  R    cid:4  cid:4  cid:4  cid:4 N  .  H  f   =  However, the passband of a CIC ﬁlter is not ﬂat, and this problem can be alleviated by a compensation ﬁlter. Design of the compensation ﬁlter is described in [2].  For example, the quadrature digital up-conversion chip from ADI, AD9856, consists of two interpolating ﬁlters, a quadrature mixer, a DDS circuit, and a 12-bit DAC with a sampling frequency up to 200 MHz. Each interpolating ﬁlter includes three half-band ﬁlters with an upsampling rate of 2 or 4, and a CIC ﬁlter, which can integrate the baseband signal by an integer factor between 2 and 63 inclusive. The total upsampling rate is in the range of 8 to 504. The DDS circuitry is employed to generate a complex local clock of frequency ranging from DC to 80 MHz with 32-bit resolution.  Half-band ﬁlters  For an FIR ﬁlter with an odd number of coefﬁcients M = 2K + 1, as given by  13.55 , in most applications, the impulse response h n  is assumed to be Hermitian-symmetric with respect to n = K, thus we get the linear-phase ﬁlter, which is in fact a zero-phase ﬁlter.      527   cid:2   13.8 Discrete cosine transform  If every other coefﬁcient except hK is selected as zero, that is [46, 69]  h 2n  =  n = K  c, 0, otherwise   13.135  for n = 0, 1, . . . , N − 1, where c is a constant, typically taken as 0.5, we get a zero-phase ﬁlter  and  H z  + H −z  = 2c = 1  H ejω  + H ej π−ω   = 1.  Thus, the ﬁlter has a symmetry with respect to the half-band frequency π 2. It also has symmetric passband and stopband edges and peak errors  see Fig. 11.16 . Thus, this ﬁlter is referred to as the half-band ﬁlter. It is a lowpass ﬁlter whose passband extends from zero to one-fourth of the Nyquist band. The half-band ﬁlter is useful for digital frequency convertion by ignoring every second sample, since every other h n  is zero. This achieves decimation by two.  The half-band ﬁlter can be easily extended to the Mth band ﬁlter [46, 69]   cid:15    cid:15   for n = 0, 1, . . . , N − 1, where c typically takes the value 1 M. Accordingly   13.136    13.137    13.138    13.139   n = K  c, 0, otherwise   cid:18   zWk−1  = Mc = 1.  H  h Mn  =  cid:17  M−1 cid:26   k=0  That is, the M uniformly shifted frequency responses add up to a constant for all ω, for the Mth band ﬁlter H z .  The Mth band ﬁlter has applications in the exact reconstruction of a signal x n  after it has been split into M sub-bands. In most applications, the Mth band ﬁlter is selected to be a linear-phase lowpass ﬁlter with cutoff π M. Standard techniques for designing the FIR Mth band ﬁlter are given in [46].  13.8 Discrete cosine transform  From this section on, we will introduce some transforms that are fundamental to source coding.  The length-N DCT of a signal s n  is deﬁned by [1]   cid:31   2 N  N−1 cid:26   n=0  S k  =  c k   s n  cos   cid:17   ⎛⎝ π  n + 1 N  2   cid:18   ⎞⎠  k   13.140        13.141    13.143    13.144    13.145    13.146   528   cid:2   Signals and signal processing  for k = 0, 1, . . . , N − 1, where  The inverse DCT  IDCT  is accordingly given by     1√ 2  ,  1,  c t  =  cid:31   2 N  s n  = N−1 cid:26   k=0  t = 0 t > 0  ⎛⎝ π  .   cid:17    cid:18   ⎞⎠  k  n + 1 N  2  c k S k  cos   13.142   for n = 0, 1, . . . , N − 1. The DCT and IDCT are linear transforms that map between a real signal and real DCT  coefﬁcients. In matrix form  S = Cs, s = CTS,   cid:17   ⎛⎝ π   cid:18   ⎞⎠ ,  n + 1 N  2  where C = [Ckn]N×N,   cid:31   Ckn =  c k  cos  2 N which is a unitary matrix, C−1 = CT. N−1 cid:26  It is easily shown that the Parseval’s relation holds for DCT  k  S2 k  = N−1 cid:26   n=0  k=0  s2 n .  When the DCT is applied to voice or video signals, the energy is typically concentrated in the ﬁrst few transform coefﬁcients, thus the coefﬁcients with very low energy can be discarded without introducing signiﬁcant distortion [29].  The DCT consists essentially of the real part of the DFT. The DCT can be implemented based on the FFT, and a fast DCT is more efﬁcient than the FFT-based implementation. In terms of compression, the DCT outperforms the DFT. This is because the DFT introduces sharp discontinuities at the beginning and end of the sequence for a periodic sequence of length N, which introduces high frequencies as well as adjustment in low frequency components. The DCT can be obtained from the DFT by mirroring the N-point sequence to obtain a 2N-point sequence, and then taking the ﬁrst N points of the resulting 2N-point DFT. In this way, the discontinuity at the edges is completely eliminated. This is illustrated in Fig. 13.17.  In the worst case, the DCT can be computed by using a length-2N DFT [1]. A popular + 4 real multiplications   cid:8  + 2 real additions. This algorithm is six times faster compared to the  fast DCT algorithm is given in [17], which requires N log2 N − 3N and 3N 2 length-2N FFT [17].  log2 N − 1   cid:7   2      529   cid:2   13.8 Discrete cosine transform  The sequence  DFT   cid:2 Figure 13.17 A comparison of the DFT and the DCT: The DFT introduces sharp edges while the DCT introduces  continuous edges.  DCT   cid:19    cid:20    cid:19    cid:20   xnxn+1 E  x2 n  .  ρ = E  The DCT also substantially outperforms the DFT in terms of energy compaction for  correlated sources [59]. For Markov sources with high correlation coefﬁcient,   13.147   The DCT approximates the Karhunen-Loève transform in terms of the compaction ability [59]. This makes the DCT the most popular transform for information compression.  Two-dimensional DCT  The two-dimensional  2-D  DCT can be implemented using two one-dimensional  1-D  DCTs: one in the horizontal direction followed by one in the vertical direction. For N × N input data s, the 2-D DCT can be implemented as S = CsCT.   13.148   c v c u   s y, x  cos  N−1 cid:26   N−1 cid:26    2x + 1 uπ  The 2-D DCT is deﬁned for image processing. The 2-D DCT extracts all coefﬁcients for an N × N block as S v, u  = 1√ 2N  x=0 where S v, u  corresponds to the amplitudes of the frequency components, and s y, x  is a pixel value in the N × N block. N−1 cid:26  The 2-D IDCT for image reconstruction is given by s y, x  = 1√ 2N   2x + 1 uπ   2y + 1 vπ   2y + 1 vπ  c u c v S v, u  cos  N−1 cid:26    13.150    13.149   y=0  cos  cos  2N  2N  2N  2N  ,  .  u=0  v=0  Like fast DCT, fast 2-D DCT is also based on simple lookup tables. The product of the two cosine terms can be tabulated as a table at the beginning and multiplications are avoided. In addition, efﬁcient 2-D IDCT implementations based on an on-line CORDIC and distributed arithmetic have been given in [79, 80].      530   cid:2   Signals and signal processing  Sinusoidal family of unitary transforms  The discrete sine transform  DST  is complementary to the DCT. Unlike the DCT, the compaction ability of the DST is very close to that of the statistically optimal Karhunen- Loève transform when the correlation coefﬁcient ρ, deﬁned by  13.147 , is very small. This feature leads to its often being used as the complementary transform to the DCT for image and audio coding [59]. For signals with high correlation, the DCT yields bet- ter results; however, for signals with a low correlation coefﬁcient, the DST yields lower BERs.  The DCT and DST belong to a sinusoidal family of unitary transforms. Some other members in this family are the even discrete cosine transform II  EDCT-II  [47], the DCT-II, the DST-II, the DCT-IV, and the DST-IV [48, 52]. The DCT-II is known as the standard DCT. These transforms can generally be implemented based on the DFT [47, 52] or the standard DCT [50].  Systolic architectures are suitable for implementation in VLSI form for real-time com- putation of the DFT and the DCT, and extension of the architectures to the 2-D transform computation is given in [51]. Systolic array VLSI architectures for the DST and prime length DST are given in [18, 44], and a uniﬁed design framework for prime length DCT IDCT with a high throughput has been presented in [20]. A memory-based uniﬁed systolic array implementation for DCT, DST, IDCT, and inverse DST has been proposed in [19].  13.9 Wavelet transform  The wavelet transform is similar to the Fourier transform. The Fourier transform decom- poses a signal into a weighted sum of sinusoids. The wavelet transform decomposes a signal into a weighted sum of wavelet functions by simply correlating a set of wavelet functions with the signal. In analogy to the frequency spectrum obtained by using the FFT, a wavelet spectrum can be obtained by using the wavelet transform. Using the wavelet transform, localized temporal and frequency information can be obtained. Wavelet analysis is very useful for processing nonstationary signals.  The set of wavelet  functions is generated from a single mother wavelet by using translations and dilations. Given a mother wavelet ψ t , the wavelets can be generated by   cid:2    cid:3   ,  t − b a  ψa,b t  = 1√ a  ψ   13.151   where a > 0, −∞ < b < ∞, and a is referred to as the scale or dilation variable. An inﬁnite number of real or complex functions can be used as the mother wavelet. To be used as a mother wavelet, a function must be zero mean over the time axis, and be square- integrable. Some well-known wavelets are the Morlet or modiﬁed Gaussian wavelet, and      531   cid:2   13.9 Wavelet transform  the Mexican hat wavelet. The Mexican hat wavelet is the normalized second derivative of a Gaussian function.  The wavelet transform of a real signal x t  is deﬁned as  a,b t x t dt,   cid:14  ∞ X a, b  = −∞ ψ∗  cid:14  ∞  cid:14  ∞  cid:14  ∞  b=−∞  a=0 ψ ω 2  cψ = 2π  dω < ∞,  where * is the complex conjugate. The inverse transform is deﬁned by  x t  = 1 cψ  X a, b ψa,b t   dadb a2 ,  where  −∞ ψ ω  being the Fourier transform of ψ t .  ω  Example 13.7: The Morlet wavelet is given by ψ = ejω0te  −t2 2,  which has a frequency spectrum  using the Fourier transform  given by  H ω  = √  −  ω−ω0 2  2  .  2πe  The Morlet wavelet and its frequency spectrum are shown in Fig. 13.18, for ω0 = 4.   13.152    13.153    13.154    13.155    13.156   Example 13.8: For a function x t  = cos sin t2 the Morlet wavelet is demonstrated in Fig. 13.19.  , its wavelet transform, X a, b , based on   cid:7    cid:8   2.5  3  2  1  0.5    ω   H  1.5      t   ψ   e R  0.5  1  0  −0.5  −1 −10   cid:2 Figure 13.18  0 t  10  0 −5  0  5  10  ω  The Morlet wavelet and its Fourier transform, ω0 = 5.      532   cid:2   Signals and signal processing  1  0.8    t   x  0.6  0  60 50 40 30  20  10  1  a  0.2  0.4  0.6  0.8  1  t 4π  b   cid:2 Figure 13.19 The continuous wavelet transform of x t  = cos sin t2 , by using the Morlet wavelet with ω0 = 5.  20  40  60  80  100  120  13.9.1 Discrete wavelet transform  A popular approach to discretization of a and b is given by   13.157    13.158    13.159   where a0 > 1, m and n are integers. Thus, the wavelet set is given by , m, n ∈ Z. From  13.152 , the wavelet coefﬁcients are accordingly obtained as  ψm,n t  = a  t − nb0  −m 2 0  ψ  X m, n  = a  −m 2 0  −m a 0  t − nb0  x t dt.   cid:8   b = nb0am 0 ,  cid:8   a = am 0 ,  −m a 0   cid:7   cid:14  ∞ −∞ ψ∗ cid:7  ∞ cid:26   ∞ cid:26   This is called the discrete-time wavelet transform  DTWT  or discrete wavelet transform  DWT . The inverse DWT  IDWT  is obtained by  x t  =  m=−∞  n=−∞  X m, n ψm,n t .   13.160   The DWT and IDWT processes are known as analysis  decomposition  and synthesis  reconstruction . These operations are in analogy to ﬁlter banks. The fast wavelet transform  FWT  [41] is derived based on dyadic wavelets, which are obtained by scaling the mother wavelet by powers of two, that is, a0 = 2, b0 = 1. The FWT is essentially the classical two-channel sub-band coder using conjugate quadrature ﬁlters  CQFs  or quadrature mirror ﬁlters  QMFs . The dyadic wavelet transform corre- sponds to signal analysis with octave band decomposition, since every increment of m doubles the width in the time domain and halves the width in the frequency domain. The FWT is asymptotically faster than the FFT, requiring a complexity of O N  as opposed to O  N log N  for the FFT [62].      533   cid:2   13.9 Wavelet transform    t     x    t     x  l  1  0.5 1.5  0  1  0  0  1  0.2 0 −0.2  0.5  0    t     h x    t      c e r x  0.2  0.4  0.6  0.8  0.2  0.4  0.6  0.8  0.2  0.4  0.6  0.8  0.2  0.4  0.6  0.8  1  1  1  1   cid:2 Figure 13.20  t 4π   cid:7   Analysis and synthesis of x t , by using the db2 wavelet.   cid:8  + 0.02N  0, 1 , N  0, 1  being zero-  sin t2  Example 13.9: For a function x t  = cos mean unit-variance Gaussian noise, the one-stage discrete wavelet transform generates a low frequency xl t   called an approximation , and a high frequency signal xh t   called a detail , based on the db2 wavelet of the Daubechies family wavelets; this is demonstrated in Fig. 13.20. The reconstructed signal xrec is shown to be exactly x t . The analysis process can repeatedly decompose the approximation signal xl t  into next-level approximation and detail. This is known as wavelet analysis. When the details as well as the approximations can be split, we get wavelet packet analysis.  The DWT is especially useful for signal de-noising and compression. MATLAB pro- vides the wavemenu graphic interface for 1-D and 2-D wavelet analysis. The 2-D DWT is especially useful for image de-noising and compression, and is introduced in Chapter 17. The Gabor ﬁlter is an example of a wavelet ﬁlter, and is widely used in image processing for texture analysis, segmentation and classiﬁcation. Lifting-based DWT provides advantages over the convolution-based DWT [28].  13.9.2 Multiresolution analysis  Multiresolution analysis is one of the most important applications of the wavelet transform. The complete representation of f  t  requires a discrete wavelet family of an inﬁnite number of orthogonal functions, {ψmn t }. By introducing a lowpass scaling function φ t , with the set {φ t− n , n ∈ Z} being orthonormal, f  t  can be represented by multiresolution analysis of the signal [26]  ∞ cid:26   n=−∞   cid:7    cid:8  + M cid:26   ∞ cid:26   m=1  n=−∞  f  t  =  −M 2φ  −Mt − n 2  cM,n2  −m 2ψ  −mt − n 2  dmn2  ,   13.161    cid:7    cid:8       534   cid:2   Signals and signal processing   cid:14  ∞   cid:7   7 = 2  cid:8   where M is a ﬁnite integer, and  cM,n =6  cid:8   cid:7  with φM,n t  = 2 −M 2φ . Note that the wavelet and scaling functions are orthog- onal to each other. All the scaling functions are of the same scale, since they are shifted −Mt , while the wavelet functions have M scales. The simplest wavelets versions of φ 2 are Haar wavelets.  f  t , φM,n t  −Mt − n 2  −Mt − n  −∞ f  t φ   13.162   −M 2   cid:8    cid:7   dt,  2  Wavelets can be built from a lowpass ﬁlter H0 z  and a highpass ﬁlter H1 z . The  multiresolution analysis equation is derived by [59]  ∞ cid:26   ∞ cid:26   √ 2φ 2t − k ,  k=−∞  k=−∞  φ t  =  h0 k φ1,k t  =  cid:14  ∞  h0 k  2φ 2t − k , φ t  is a scaling function, and √ 2φ 2t − k dt.  cid:26   h0 k  = ∞ cid:26   −∞ φ t   ψ t  =  h1 k φ1,k t  =  k=−∞  k  √ 2φ 2t − k .  h1 k    13.163    13.164    13.165   The scaling function φ t  is closely related to the mother wavelet  where φ1,k t  = √  Example 13.10: The Haar scaling function φ t  is a unit rectangular pulse of length 1, φ t  = u t  − u t − 1 , where u t  = 1 for t ≥ 0 and u t  = 0 for t < 0; thus, φ t  satisﬁes φ t  = φ 2t + φ 2t − 1 . The Haar wavelet is obtained by ψ t  = φ 2t − φ 2t − 1 . They correspond to the sum  lowpass ﬁltering  and the difference  highpass ﬁltering  of φ 2t . The Haar scaling and wavelet functions are plotted in Fig. 13.21. The spectrum of φ t     t   φ       t   ψ     1  0  1  0  −1  −1  −1  −1  −0.5  0  1  1.5  2  0.5 t  0.5 t   cid:2 Figure 13.21  The Haar scaling function and wavelet.  −0.5  0  1  1.5  2      535   cid:2   13.10 Filter banks  is a sinc function that has a lowpass property, while the spectrum of ψ t  has a bandpass property with its energy concentration moved to higher frequency. The PSD of ψ 2t  shifts its energy concentration further to the higher frequency.  Multiresolution analysis can be implemented using a hierarchical ﬁlter structure similar to that used in sub-band coding. By integrating both sides of the multiresolution analysis equation and after manipulation, three equations are obtained for h0 k  [59] h0 k h0 k − 2m  = δm.  h0 k  = √  ∞ cid:26   ∞ cid:26    13.166   2,  When the wavelet function is orthogonal to the scaling function at the same scale, that is,  k=−∞  we have [59]  k=−∞  k=−∞  0 k  = 1, h2  ∞ cid:26   cid:14  ∞ −∞ φ t − k ψ t − m dt = 0, h1 k  = ± −1 kh0 N − k , ∞ cid:26  h0 k h1 n − 2k  = 0, ∞ cid:26   k=−∞  h1 k  = 0.  k=−∞   13.167    13.168    13.169    13.170   where N is the length or the ﬁlter. Further  In [59], h0 k ’s for 4- 12- 20-tap Daubechies and 6- 12- 18-tap Coiﬂet, lowpass ﬁlters are tabulated.  The wavelet transform is suitable for multiresolution analysis. Natural signals such as image, speech audio signals are well suited for this type of analysis, since it divides frequency into octaves, and the human visual cortex uses a multifrequency channel decom- position to process images. The practical implementation of wavelet compression is very similar to sub-band coding. When the DWT is applied to image compression, some coefﬁcients are discarded to increase the compression rate.  13.10 Filter banks  We are now in a position to discuss ﬁlter banks. When the spectrum of an input signal is divided into several nonoverlapping frequency bands that cover the Nyquist interval, we get a parallel ﬁlter bank. Filter banks are typically used for multirate sample conversion and sub-band coding of speech or picture signals.  The basic building blocks in a multirate DSP system are decimators and interpolators. Multirate systems can be implemented in the polyphase form. The decimator is the cascade      536   cid:2   Signals and signal processing  M  G z   G zM    M   cid:2 Figure 13.22  Two identity transforms for multirate systems.  G z   K  K  G zK    x  n   H0  z   H1  z   x0  n   x1  n   y0  n   y1  n   G0  z   G1  z    b   HM–1  z   xM–1  n   yM–1  n   GM–1  z   x  n    a   0  π 4  H0  H1  H3  H2   c   H0  2π  ω   cid:2 Figure 13.23 Analysis and synthesis ﬁlter banks.  a  Analysis bank.  b  Synthesis bank.  c  Typical frequency  response of uniform DFT ﬁlter bank, for M = 4.  Fig.10 [69]   c cid:2 1990, IEEE.  of a lowpass pre-aliasing ﬁlter and a downsampler, and the interpolator is the cascade of an upsampler and a lowpass post-image ﬁlter. These ﬁlters are the canonical components used in ﬁlter banks. In ﬁlter banks, if a downsampler  decimator  is followed by a transfer function G z , or a downsampler  interpolator  is preceded by G z , they can be transformed by the identity transforms for multirate systems provided that G z  is rational [69]. Two identity transforms known as the Noble identities are shown in Fig. 13.22. They are most valuable for efﬁcient implementation of ﬁlters and ﬁlter banks.  Sub-band coding can effectively reduce the number of bits for quantization of each ﬁlter output and sampling rates of each ﬁlter, leading to an overall reduction in the total bits for coding. The DWT is an example of a ﬁlter bank. More discussion on ﬁlter banks is given in [29].  Analysis and synthesis banks  Two basic types of ﬁlter banks are the analysis and synthesis banks. The analysis bank uses a set of analysis ﬁlters Hk z , k = 1, 2, . . . , M, to split a signal x n  into M sub-band signals xk n , while the synthesis bank combines the M sub-band signals yk n  into a reconstructed signal ˆx n  by using M synthesis ﬁlters Gk z . These are illustrated by Fig. 13.23. Perfect reconstruction is an important topic for ﬁlter banks.      537   cid:2   13.10 Filter banks   cid:8  When all Hk z ’s are derived from the prototype ﬁlter H0 z  by Hk z  = H0 zWk ,  cid:7  k = 0, 1,··· , M − 1, where W = e −j2π M, such an analysis ﬁlter is referred to as a uniform DFT ﬁlter bank. The frequency responses of Hk z  are uniformly shifted versions of H0  , and this is shown in Fig. 13.23c.   cid:8    cid:7   ejω  Common transforms as ﬁlter banks  The DCT does a job similar to that of a ﬁlter bank. The DCT divides a signal into several frequency components, while a ﬁlter bank divides the frequency band into several channels. The block DCT transform used for data compression is shown to be equivalent to a perfect reconstruction M-band ﬁlter bank [29]. Both the analysis and synthesis ﬁlter banks have linear phase.   cid:31   2 N   cid:17   ⎛⎝ π  n + 1 N  2   cid:18   ⎞⎠  k  Example 13.11: As given in  13.145 , deﬁned by  the elements of the DCT matrix Ckn are  Ckn = Ck n  =  c k  cos   13.171  for k = 0, 1,··· , N − 1. The DCT and IDCT together constitute an analysis-and-synthesis ﬁlter bank, where hi n  = Ci −n  and gi n  = Ci n , for i = 0, 1, . . . , N − 1. Since the impulse response is antisymmetric, Ck n  =  −1 kCk N − 1 − n , k = 0, 1, . . . , N − 1, the ﬁlter bank has linear phase. The analysis and synthesis ﬁlters have the same magnitude response, and they are shown in Fig. 13.24 for N = 8.  The cosine-modulated ﬁlter bank is suitable for design and implementation of ﬁlter banks with a large number of sub-bands, since it has a simple design procedure and has low     B d        ω   H    0  −5  −10  −15  −20  −25  −30  0   cid:2 Figure 13.24  0.1  0.2  0.3  0.4  0.5  ω  ω 0  Magnitude responses of the DCT ﬁlters hi n , for N = 8.      538   cid:2   Signals and signal processing  complexity due to its fast DCT-type implementation. The cosine-modulated ﬁlter bank has a nonlinear phase for the analysis ﬁlters, and thus is not desirable for image coding. The lapped orthogonal transform  LOT  is a block transform with overlapped basis functions so as to reduce blocking effects, which occur in the case of the DCT. The blocking effect is seen as discontinuities that appear across the block boundaries. The LOT-based design has linear phase analysis ﬁlters and has fast implementation. The LOT is also based on the DCT, which enables fast implementation [49]. Design and implementation of these ﬁlter banks are addressed in [29].  In [36], the design of general biorthogonal modulated ﬁlter banks  cosine-modulated and modiﬁed DFT  has been developed, using the polyphase representation. Working with the design parameters of the number of channels M, the prototype ﬁlter length N, and the system delay D, necessary and sufﬁcient conditions for perfect reconstruction are derived using the polyphase representation. These perfect reconstruction conditions are shown to be identical for all types of modulation: modulation based on the DCT, both DCT-III DCT-IV and DCT-I DCT-II, and modulation based on the modiﬁed DFT. A quadratic-constrained least-squares technique has been derived for the design of proto- type ﬁlters for perfect reconstruction modulated ﬁlter banks, with full generality in setting the parameters M, N, and D. The best subchannelization  greatest stopband attenuation  is obtained for D = N − 1. For digital signals, the wavelet transform is shown to be a special case of critically decimated ﬁlter banks [29]. Nonuniform perfect reconstruction ﬁlter banks with integer decimation factors are also useful for linear multirate systems.  13.11 Sub-band coding  Sub-band coding, also known as frequency-domain coding, was ﬁrst introduced in [24]. For sub-band coding, the signal is split into M sub-band signals using M analysis ﬁlters Hk z . Each sub-band signal is decimated by M, and is then quantized using a number of bits that depend on the energy content. This strategy is a generalization of the decimation process. The reconstruction of the signal is performed by ﬁrst interpolating each sub-band signal by  cid:7  M to restore the original sampling rate and then combining all the interpolated sub-band signals using synthesis bank ﬁlters Gk z , which also eliminate the images. For M = 2,   cid:8  cid:4  cid:4  with respect to the quadrature frequency π 2,   cid:8  cid:4  cid:4  is usually an image of   cid:4  cid:4 H0   cid:4  cid:4 H1   cid:7   ejω  ejω  thus the name QMF. The parallel structure is shown in Fig. 13.25.  For M > 2, such an analysis synthesis system for sub-band coding is called the M-band maximally decimated analysis synthesis system, but is sometimes also called a pseudo- QMF ﬁlter bank for simplicity. For sub-band coding, the M analysis ﬁlters Hk z  divide the band into overlapping lowpass, bandpass and highpass portions. The overlaps allow that no portion of the frequency response is severely attenuated, which, however, introduces aliasing when the corresponding subband signals are decimated. The synthesis ﬁlters Gk z  are used to cancel this aliasing as well as the images introduced by interpolation at the reconstruction stage.      539   cid:2   x  n   13.11 Sub-band coding  H0  z   H1  z   HM–1  z   M  M  M  G0  z   G1  z   M  M  M  GM–1  z   x  n   coding and transmission   cid:2 Figure 13.25 The M-band maximally decimated analysis synthesis system for sub-band coding. For M = 2, it is  the two-band QMF bank.  The magnitude response of the M sub-bands can be made to have different amplitudes  βk; this leads to FIR ﬁlters with adjustable multilevel response  G z  = M−1 cid:26   k=0   cid:17    cid:18   βkH  zWk  .  By selecting a large M and different βk, one can adjust the magnitude response of the ﬁlter. The pseudo-QMF bank is very important for modern audio coding. Frequency-domain coding has an advantage over time-domain coding, in that each frequency component can be allocated different numbers of bits. This allows us to control the level of quantization noise in each component. Filter banks are also used in the multirate generalized multi- carrier  GMC  CDMA model [73].  13.11.1 Two-channel perfect reconstruction ﬁlter banks  Quadrature mirror ﬁlter bank  For the two-band QMF bank, we need to deﬁne ﬁlters h0 n , h1 n , g0 n , and g1 n  that allow perfect reconstruction of the input x n . Let y0 n  and y1 n  be the transmitted intermediate data streams. We have, from the synthesis ﬁlter bank   cid:17    cid:18   z2   cid:18    cid:17   cid:17   z2  G1 z    cid:18  cid:18   ˆX z  = Y0  cid:18   cid:17   cid:18    cid:17    cid:17   and from the analysis ﬁlter bank  Yi z  = 1 2  + Hi Combining  13.173  and  13.174  yields  z1 2  z1 2  Hi  X  G0 z  + Y1  cid:17   cid:18   −z1 2  X  −z1 2  i = 0, 1.  ,   13.174   ˆX z  = 1  H0 z G0 z  + H1 z G1 z   X z  2  H0 −z G0 z  + H1 −z G1 z   X −z . + 1 2   13.172    13.173    13.175       540   cid:2   Signals and signal processing   13.176    13.177    13.178    13.179    13.180    13.181    13.182    13.183    13.184    13.185   In order to remove the aliasing term, the synthesis ﬁlters can be chosen as  G0 z  = H1 −z , G1 z  = −H0 −z   and only the ﬁrst term in  13.175  remains:  ˆX z  = 1  2   H0 z H1 −z  − H1 z H0 −z   X z .  To achieve perfect reconstruction, we can set  P z  − P −z  = H0 z H1 −z  − H1 z H0 −z  = z  −D,  where  P z  = H0 z H1 −z .  That is, the reconstructed signal is a D-samples-delayed replica of the input signal.  There are a number of methods to achieve perfect reconstruction. The FIR QMF ﬁlter order must be even for perfect reconstruction. The QMF solution [25] is the most popular one, which takes the form  H1 z  = H0 −z .  This implies that if H0 is a lowpass ﬁlter then H1 is highpass. The four ﬁlters are related by  H1 z  = H0 −z  ←→ h1 n  =  −1 nh0 n ,  G0 z  = H0 z  ←→ g0 n  = h0 n ,  G1 z  = −H0 −z  ←→ g1 n  = − −1 nh0 n .   cid:17    cid:18   ˆX z  = 1  2  0 z  − H2 H2  0 −z   X z .  Finally, we have  In case of perfect reconstruction, the output signal is a time-delayed version of the input signal, thus the ﬁlter should be designed so that  0 z  − H2 H2  0 −z  = z  −D.  No exact solution for FIR ﬁlters with more than 2 taps has been found to satisfy the QMF perfect reconstruction condition, but it can be approximated very well by using long FIR ﬁlters. The Haar ﬁlters, given by H0 z  = 1 −1  are examples of a QMF ﬁlter bank. For a QMF bank, the QMF symmetry constraint H1 z  = H0 −z  makes the implementation of linear-phase FIR ﬁlters only exist in the two-tap case.  −1  and H1 z  = 1  2  1− z  2  1+ z  Conjugate quadrature ﬁlter bank  Another solution that is better adapted for FIR implementation is the CQF solution [60]. The synthesis ﬁlters g0 n  and g1 n  are just time reversals of the analysis ﬁlters of length N  g0 n  = h0 N − 1 − n ,   13.186       541   cid:2   and  13.11 Sub-band coding  g1 n  =  −1 nh0 n  = h1 N − 1 − n   h1 n  = − −1 nh0 N − 1 − n .   13.187    13.188    13.189    13.190    13.191   These ﬁlters can be represented in the z-domain as [6] − N−1 H0 z − N−1 H1 z − N−1 H0 −z  cid:17   G0 z  = z G1 z  = z H1 z  = z  cid:18   cid:17   −1 , −1 , −1 .   cid:18   These ﬁlters satisfy the alias cancellation conditions for even N. Note that the ﬁlters  H0 z  and H1 z  do not have linear phase. The perfect reconstruction condition leads to  H0 z H0   13.192  when D = N − 1. This condition corresponds to the power complementary condition in the frequency domain,  z  −1  + H0 −z H0  −z −1  = 1  H0 ω 2 + H1 ω 2 = 1.   13.193   A ﬁlter bank satisfying the power complementary condition gives perfect reconstruction, but the reverse does not necessarily hold.  13.11.2 Pseudo-QMF ﬁlter bank  The two-channel CQF is generalized into the pseudo-QMF ﬁlter bank. The pseudo-QMF ﬁlter bank is a near-perfect reconstruction ﬁlter bank. It is used in the layer-I and layer-II audio coders in the MPEG-1 and MPEG-2 standards for time to frequency mapping.  The pseudo-QMF bank consists of M channels. The analysis and synthesis ﬁlters are   cid:12    cid:2    cid:3    cid:13   hk n  = h n  cos   k + 1 M  2  π  n − N − 1  2  + φk  ,  given by   13.195  for k = 0, 1, . . . , M − 1, where N is the length of the lowpass prototype window h n , and the phase φk satisﬁes  gk n  = hk N − 1 − n    13.194    13.196   φk − φk−1 = mπ + π 2  , m ∈ Z.  This corresponds to the anti-aliasing conditions between adjacent bands. The perfect reconstruction condition requires to that the power complementary equation be satisﬁed within f ≤ fs 2M : H ejω 2 +   cid:18  cid:4  cid:4  cid:4 2 = 1,  ej π M−ω    cid:4  cid:4  cid:4 H   13.197    cid:17   .  for ω ≤ π 2M      542   cid:2   Signals and signal processing  13.11.3 Modiﬁed DCT  MDCT   Like the pseudo-QMF, the MDCT is also used for time-to-frequency mapping of sig- nals. The MDCT is a block transform method that transforms a block of time-domain samples into its frequency-domain representation, and the method is called transform cod- ing. Mathematically, both sub-band coding and transform coding are essentially using the same technology. Usually, coders with a small number of frequency bands are referred to as sub-band coders, while coders with many frequency channels are called transform coders.  The MDCT corresponds to a perfect reconstruction ﬁlter bank. It can be used in the case of a very high number of frequency bands. The MDCT inverse MDCT  IMDCT  is used in the MPEG AAC  ISO IEC 13818-7  and Dolby AC-2 and AC-3 [6] audio standards. A hybrid ﬁlter bank that cascades the pseudo-QMF and the MDCT is used in MPEG Layer III Audio.  The MDCT is a special case of a class of transforms called time domain aliasing cancel- lation  TDAC  transform, and is also known as an oddly-stacked TDAC  OTDAC  transform [55, 56]. In the TDAC transform, an overlap-and-add procedure is used to exactly can- cel the time-domain aliasing by using an overlap between blocks. The TDAC can lead to perfect reconstruction ﬁlter banks without increasing the data rate. The MDCT allows us to have 50% overlap between successive data blocks without increasing the overall data rate. It is a special case of the N = 2M pseudo-QMF ﬁlter bank that produces exact perfect reconstruction but allows a wider set of prototype ﬁlters, where M is the number of frequency channels [6]. The MDCT phase term cancels frequency aliasing between all pairs of frequency bands, not merely adjacent bands. The MDCT allows lower-cost ﬁlters than the pseudo-QMF due to a lesser requirement on stopband atten-  cid:7  uation, and has become the transform of choice for most of the newer audio coders. The implementation of the MDCT using the FFT reduces the number of operations to N log2 N O The MDCT transforms N inputs from the ith and  i − 1 th sets of N 2 inputs into N 2 frequency-domain outputs   cid:8   .   cid:2    cid:2    cid:3  cid:3   x n wa n  cos   n + n0   2π N  k + 1 2  k = 0, 1, . . . ,  ,  − 1,  N 2  n=0 where n0 = 2+N At synthesis stage the N 2 frequency-domain outputs are transformed back into N time-  4 , and wa is the analysis window.   13.198   domain samples, via the IMDCT  X k  = N−1 cid:26    cid:2    cid:2    cid:3  cid:3   ˆx n  = ws n   2 N  X k  cos   n + n0   2π N  k + 1 2  n = 0, 1, . . . , N−1,  13.199   ,  N 2−1 cid:26   k=0  where ws is the synthesis window.      543   cid:2   Problems  The windows wa and ws should satisfy the condition that their overlapping por- tions between adjacent blocks should be time-reversals of each other, and the perfect reconstruction condition   cid:3    cid:2    cid:3   wi a n wi  s n  + wi−1  a  + n  wi−1  s  N 2  N 2  + n  = 1,  n = 0, 1, . . . ,  − 1.  N 2   13.200    cid:2   The windows can be a Kaiser window or a sine window. The resolution of the ﬁlter bank can be altered by changing the window length N. The blocking effect requires the use of smooth windows for the input signals and overlap-and-add of the output data for reconstruction of the signal [6].  There are some algorithms available for efﬁcient implementations of MDCT  IMDCT [16, 32]. In [53], a parallel pipelined algorithm for the computation of both the MDCT and IMDCT has been proposed based on the FFT.  Problems  13.1 A signal x t  = sin πt  + 4 sin 2πt  cos 5πt , where t is in msec. The signal is sampled at a rate of 5 kHz. Determine the signal xa t  aliased with x t . Then, give two other signals x1 t  and x2 t  that are aliased with xa t , that is, x1 nT  = x2 nT  = xa nT . [Hint: Expand x t  into a sum of sines and cosines.]  with the convolutional equation y n  = cid:24   13.2 Implement in MATLAB a CIC ﬁlter with six stages of integrate and six stages of comb to reduce the sampling rate by a factor of four. Filter a sinusoidal signal with a frequency of 0.3 Hz to illustrate the effect of aliasing. Assume the normalized sampling rate is 1 Hz. 13.3 Determine the impulse response h of the following FIR ﬁlters:  a  y n  = 2x n  + 4x n − 1  + 5x n − 2  + 2x n − 4 ;  b  y n  = x n  − x n − 5 . 13.4 A causal IIR ﬁlter has impulse response h n  = 5δ n  + 3 0.5 n−1u n . Working m h m x n − m , derive the difference equation for y n . 13.5 Calculate the output y of the following ﬁlter with input: h = [1, 2 − 1, 1], x = [1, 1, 2, 1, 2, 2, 1, 1].  a  Use y = h ∗ x.  b  Use z-transform Y z  = H z X z . 13.6 Using the unit-step identity u n  − u n − 1  = δ n , determine the z-transform of:  a  x n  = u n  and  b  x n  = −u −n − 1 . Verify that their z-transforms are the same. One of the signals is causal and the other is anticausal. What are their ROCs?  13.7 Compute all possible inverse z-transforms of −1  X z  = 5 + z  1 − 0.25z−2 .      544   cid:2   Signals and signal processing  13.8 Prove the modulation property of z-transforms. If the z-transform of x n  is X z , show the z-transform of anx n  is X z a . In the frequency domain, derive the spectrum of ejω0nx n  is X ω − ω0 , by using a = ejω0. 13.9 For a ﬁlter with frequency response  H ω  = −0.5 + e  −jω4 1 − 0.5e−jω4 ,  H z  = 1 − z −16 1 − az−16 ,  where ω is the digital frequency in radians sample, determine the causal impulse response h n  for all n ≥ 0. 13.10 For a digital ﬁlter,  where 0 < a < 1,  a  What are the poles and zeros? Plot them on the z-plane.  b  Draw the magnitude response H ω  over 0 ≤ ω ≤ 2π.  c  Determine the causal stable impulse response h n . 13.11 Design a multi-notch ﬁlter with D = 8 and the 3-dB width in the range of 0 and 0.05π.  13.12 Determine the length-9, rectangularly windowed impulse response that approxi- mates:  a  an ideal lowpass ﬁlter of cutoff frequency ωc = π 5,  b  an ideal bandpass ﬁlter with cutoff frequencies ωa = π 5 and ωb = π 3. 13.13 Using the Kaiser window, design a bandpass digital ﬁlter with fs = 20 kHz, fsa = 3 kHz, fpa = 4 kHz, fpb = 7 kHz, fsb = 8 kHz, Apass = 0.1 dB, Astop = 80 dB. 13.14 Determine whether the following systems are causal and or stable:  a  h n  = 0.5nu n ,  b  h n  = u n + 2  − u n − 1 ,  c  h n  = sin πn 4 u n ,  d  h n  = 0.5nu n  + 2nu −n − 1 . 13.15 Consider a discrete-time LTI system with impulse response h n . If the input x n  is a periodic sequence with period N, show that the output y n  also has a periodic of N.  13.16 A discrete causal LTI system has the system function −2   H z  =  1 + 0.4z  −1  1 − 9z 1 + 0.64z−2  .  Is the system stable? Express H z  as the product of a minimum-phase system and an all-pass system.  13.17 Design an FIR lowpass ﬁlter satisfying the speciﬁcations: 0.95 < H ejω  < 1.05 for 0 ≤ ω ≤ 0.26π, −0.1 < H ejω  < 0.1 for 0.4π ≤ ω ≤ π. The cutoff ωc = 0.3π. Which windows can be used for this speciﬁcation? What is the ﬁlter length?      545   cid:2   References  References  [1] N. Ahmed, T. Natarajan & K. R. Rao, Discrete cosine transform. IEEE Trans.  [2] Alterra, Understanding CIC Compensation Filters, Application Note 455, v1.0, Apr  Computers, 23:1  1974 , 90–93.  2007.  [3] R. G. Alves, P. L. 0sorio & M. N. S. Swamy, General FFT pruning algorithm. In Proc.  IEEE Midwest Symp. Circ. Syst., Lansing MI, Aug 2000, 1192–1195.  [4] A. Antoniou, Digital Signal Processing: Signals, Systems, and Filters  New York: [5] G. Bi & Y. Q. Chen, Fast DFT algorithms for length N = q ∗ 2m. IEEE Trans. Circ.  McGraw-Hill, 2006 .  [6] M. Bosi & R. E. Goldberg, Introduction to Digital Audio Coding and Standards  Syst. II, 45:6  1998 , 685–690.   Boston, MA: Kluwer, 2003 .  [7] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, Efﬁcient pruning algorithms for the DFT computation for a subset of output samples. In Proc. IEEE ISCAS, Bangkok, Thailand, May 2003, 4, 97–100. length-q × 2m DFTs. IEEE Trans. Circ. Syst. I, 51:9  2004 , 1723–1732. for length-q ∗ 2m DHTs. IEEE Trans. Circ. Syst. I, 51:10  2004 , 2031–2043.  [9] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, A new split-radix FHT algorithm  [8] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, A new radix-2 8 FFT algorithm for  [10] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, A note on “Split vector-radix-2 8 2-D fast Fourier transform”. IEEE Signal Process. Lett., 12:3  2005 , 185. [11] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, New radix- 2 × 2 × 2   4 × 4 × 4  and radix- 2× 2× 2   8× 8× 8  DIF FFT algorithms for 3-D DFT. IEEE Trans. Circ. Syst. I, 53:2  2006 , 306–315.  [12] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, Multidimensional vector radix FHT  algorithms. IEEE Trans. Circ. Syst. I, 53:4  2006 , 905–917.  [13] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, A split vector-radix algorithms for the 3-D discrete Hartley transform. IEEE Trans. Circ. Syst. I, 53:9  2006 , 1966–1976. [14] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, A general class of split-radix FFT algorithms for the computation of the DFT of length-2m. IEEE Trans. Signal Process., 55:8  2007 , 4127–4138.  [15] R. N. Bracewell, The fast Hartley transform. Proc. IEEE, 72:8  1984 , 1010–1018. [16] V. Britanak & K. R. Rao, An efﬁcient implementation of the forward and inverse  MDCT in MPEG audio coding. IEEE Signal Process. Lett., 8:2  2001 , 48–51.  [17] W.-H. Chen, C. H. Smith & S. C. Fralick, A fast computational algorithm for the  discrete cosine transform. IEEE Trans. Commun., 25:9  1977 , 1004–1009.  [18] D. F. Chiper, M.N.S. Swamy, M.O. Ahmad & T. Stouraitis, A systolic array archi- tecture for the discrete sine transform. IEEE Trans. Signal Process., 50:9  2002 , 2347–2354.  [19] D. F. Chiper, M. N. S. Swamy, M. O. Ahmad & T. Stouraitis, Systolic algo- rithms and a memory-based design approach for a uniﬁed architecture for the      546   cid:2   Signals and signal processing  computation of DCT DST IDCT IDST. IEEE Trans. Circ. Syst. I, 52:6  2005 , 1125–1137.  [20] D. F. Chiper, M. N. S. Swamy & M. O. Ahmad, An efﬁcient uniﬁed framework for implementation of a prime-length DCT IDCT with high throughput. IEEE Trans. Signal Process., 55:6  2007 , 2925–2936.  [21] J. W. Cooley & J. W. Tukey, An alorithm for the machine computation of complex  Fourier series. Math. Comput., 19:2  1965 , 297–301.  [22] L. Cordesses, Direct digital synthesis: a tool for periodic wave generation  Part 1; Part  2 . IEEE Signal Process. Mag., 21:4  2004 , 50–54; 21:5  2004 , 110–112, 117.  [23] R. E. Crochiere & L. R. Rabiner, Multirate Digital Signal Processing  Englewood  Cliffs, NJ: Prentice Hall, 1983 .  [24] R. E. Crochiere, S. A. Weber & J. L. Flanagan, Digital coding of speech in sub-bands.  Bell Syst. Tech. J., 55:8  1976 , 1069–1085.  [25] A. Croisier, D. Esteban & C. Galand, Perfect channel splitting by use of interpola- tion, decimation, and tree decomposition techniques. In Proc. Int. Conf. Inf. Sci. Syst., Patras, Greece, Aug 1976, 443–446.  [26] I. Daubechies, Orthonormal bases of compactly supported wavelets. Commun. Pure  Appl. Math., 41:7  1988 , 909–996.  [27] I. Daubechies, The wavelet transform, time frequency localization and signal analysis.  IEEE Trans. Inf. Theory, 36:5  1990 , 961–1005.  [28] I. Daubechies & W. Sweldens, Factoring wavelet transformations into lifting schemes.  J. Fourier Analysis & Applic., 4  1998 , 247–269.  [29] P. S. R. Diniz, E. A. B. da Silva & S. L. Netto, Digital Signal Processing: System  Analysis and Design  Cambridge, UK: Cambridge University Press, 2002 .  [30] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [31] P. Duhamel. Implementation of split-radix FFT algorithms for complex, real, and real-symmetric data. IEEE Trans. Acoustics Speech Signal Process., 34:2  1986 , 285–295.  [32] P. Duhamel, Y. Mahieux & J. P. Petit, A fast algorithm for the implementation of ﬁlter banks based on time-domain aliasing cancellation. In Proc. IEEE ICASSP, Toronto, Canada, May 1991, 2209–2212.  [33] W. E. Egan, Phase-Lock Basics  New York: Wiley, 1998 . [34] R. W. Hamming, Digital Filters, 3rd edn  Mineola, NY: Dover, 1998 . [35] F. J. Harris, On the use of windows for Harmonic analysis with the discrete Fourier  transform. Proc. IEEE, 66:1  1978 , 51–84.  [36] P. N. Heller, T. Karp & T. Q. Nguyen, A general formulation of modulated ﬁlter banks.  IEEE Trans. Signal Process., 47:4  1999 , 986–1002.  [37] E. B. Hogenauer, An economical class of digital ﬁlters for decimation and interpola-  tion. IEEE Trans. Acoust. Speech Signal Process., 29:2  1981 , 155–162.  [38] X. H. Huang, K.-L. Du, A. K. Y. Lai & K. K. M. Cheng, A uniﬁed software radio  architecture. In Proc. IEEE SPAWC, Taoyuan, Taiwan, Mar 2001, 330–333.  [39] E. C. Ifeachor & B. W. Jervis, Digital Signal Processing: A Practical Approach, 2nd  edn  Harlow, UK: Prentice Hall, 2002 .      547   cid:2   References  [40] J. F. Kaiser & R. W. Schafer, On the use of the I0-sinh window for spectrum analysis.  IEEE Trans. Acoust. Speech Signal Process., 28:1  1980 , 105–107.  [41] S. Mallat, A theory for multiresolution signal decomposition: the wavelet representa-  tion. IEEE Trans. Pat. Anal. Mach. Intell., 11:7  1989 , 674–693.  [42] J. H. McClellan & T. W. Parks, A uniﬁed approach to the design of optimum FIR  linear-phase digital ﬁlters. IEEE Trans. Circ. Theory, 20:6  1973 , 697–701.  [43] J. H. McClellan, T. W. Parks & L. R. Rabiner, ‘A computer program for designing optimum FIR linear-phase ﬁlters. IEEE Trans. Audio Electroacoustics, 21:6  1973 , 506–526.  [44] P. K. Meher & M. N. S. Swamy, New systolic algorithm and array architecture for prime-length discrete sine transform. IEEE Trans. Circ. Syst. II, 54:3  2007 , 262–266.  [45] P. K. Meher & M. N. S. Swamy, High throughput memory-based architecture for DHT using a new convolutional formulation. IEEE Trans. Circ. Syst. II, 54:7  2007 , 606–610.  [46] F. Mintzer, On half-band, third-band and Nth band FIR ﬁlters and their design. IEEE  Trans. Acoust. Speech Signal Process., 30:5  1982 , 734–738.  [47] N. R. Murthy & M. N. S. Swamy, On the algorithms for the computation of even discrete cosine transform-2  EDCT-2  of real sequences. IEEE Trans. Circ. Syst., 37:5  1990 , 625–627.  [48] N. R. Murthy & M. N. S. Swamy, On the computation of running discrete cosine and  sine transforms. IEEE Trans. Signal Process., 40:6  1992 , 1430–1437.  [49] N. R. Murthy & M. N. S. Swamy, On the hardware implementation of the lapped orthogonal transform and the modulated lapped transform. In Proc. IEEE ISCAS, San Diego, CA, May 1992, 1, 145–148.  [50] N. R. Murthy & M. N. S. Swamy, On a novel decomposition of the DCT and its  application. IEEE Trans. Signal Process., 41:1  1993 , 480–485.  [51] N. R. Murthy & M. N. S. Swamy, On the real-time computation of DFT and DCT  through systolic architectures. IEEE Trans. Signal Process., 42:4  1994 , 988–991.  [52] N. R. Murthy & M. N. S. Swamy, On the on-line computation of DCT-IV and DST-IV  transforms. IEEE Trans. Signal Process., 43:5  1995 , 1249–1251.  [53] N. R. Murthy & M. N. S. Swamy, A parallel pipelined algorithm for the computa- tion of MDCT and IMDCT. In Proc. IEEE ISCAS, Bangkok, Thailand, May 2003, 4, 540–543.  [54] S. J. Orfanidis, Introduction to Signal Processing  Englewood Cliffs, NJ: Prentice  Hall, 1995 .  [55] J. P. Princen & A. B. Bradley, Analysis synthesis ﬁlter bank design based on time domain aliasing cancellation. IEEE Trans. Acoust. Speech Signal Process., 34:5  1986 , 1153–1161.  [56] J. P. Princen, A. W. Johnson & A. B. Bradley, Subband transform coding using ﬁlter bank designs based on time domain aliasing cancellation. In Proc. IEEE ICASSP, Dallas, TX, Apr 1987, 12, 2161–2164.  [57] J. G. Proakis & D. G. Manolakis, Digital Signal Processing: Principle, Algorithms,  and Applications, 4th edn  Upper Saddle River, NJ: Pearson Prentice Hall, 2007 .      548   cid:2   Signals and signal processing  [58] S. Samadi, M. O. Ahmad & M. N. S. Swamy, Characterization of nonuniform perfect-reconstruction ﬁlter banks using unit step signal. IEEE Trans. Signal Process., 52:9  2004 , 2490–2499. – Also see, Correction to “Characterization of nonuni- form perfect-reconstruction ﬁlter banks using unit step signal”, ibid., 52:10  2004 , 2946.  [59] K. Sayood, Introduction to Data Compression, 2nd edn  San Mateo, CA: Morgan  Kaufmann, 2000 .  [60] M. J. T. Smith & T. P. Barnwell III, Exact reconstruction techniques for tree- structured sub-band coders. IEEE Trans. Acoust. Speech Signal Process., 34:3  1986 , 431–441.  [61] H. V. Sorensen & C. S. Burrus, Efﬁcient computation of the DFT with only a subset  of input or output points. IEEE Trans. Signal Process., 41:3  1993 , 1184–1200.  [62] G. Strang & T. Nguyen, Wavelets and Filter Banks  Wellesley, MA: Wellesley-  [63] D. Stranneby & W. Walker, Digital Signal Processing and Applications, 2nd edn  Cambridge Press, 1997 .   London: Elsevier, 2004 .  [64] D. Sundararajan, M. O. Ahmad & M. N. S. Swamy, A fast FFT bit-reversal algorithm.  IEEE Trans. Circ. Syst. II, 41:10  1994 , 701–703.  [65] D. Sundararajan, M. O. Ahmad & M. N. S. Swamy, Fast computation of the discrete Fourier transform of real data. IEEE Trans. Signal Process., 45:8  1997 , 2010–2022. [66] D. Sundararajan, M. O. Ahmad & M. N. S. Swamy, Vector computation of the discrete  Fourier transform. IEEE Trans. Circ. Syst. II, 45:4  1998 , 449–461.  [67] E. E. Swartzlander, Jr., D. V. S. Chandra, H. T. Nagle, Jr. & S. A. Starks, Sign logarithm arithmetic for FFT implementation. IEEE Trans. Comput., 32:6  1983 , 526–534.  [68] C. S. Turner, Recursive discrete-time sinusoidal oscillators. IEEE Signal Process.  Mag., 20:3  2003 , 103–111.  [69] P. P. Vaidyanathan, Multirate digital ﬁlters, ﬁlter banks, polyphase networks, and  applications: a tutorial. Proc. IEEE, 78:10  1990 , 56–93.  [70] J. Valls, T. Sansaloni, A. Perez-Pascual, V. Torres, & V. Almenar, The use of CORDIC  in software deﬁned radios: a tutorial. IEEE Commun. Mag., 44:9  2006 , 46–50.  [71] S. V. Vaseghi, Advanced Signal Processing and Digital Noise Reduction  Chichester,  [72] J. E. Volder, The CORDIC trigonometric computing technique. IRE Trans. Electron.  UK: Wiley & Teubner, 1996 .  Comput., 8:3  1959 , 330–334  [73] Z. Wang & G. B. Giannakis, Block spreading for multipath-resilient generalized multi-carrier CDMA. In G. B. Giannakis, Y. Hua, P. Stoica & L. Tong, eds., Signal Processing in Wireless & Mobile Communications: Trends in Single- and Multi-user Systems 2  Upper Saddle River, NJ: Prentice Hall, 2001 , pp. 223–266.  [74] Y. Wang, H. M. Lam, C.-Y. Tsui, R. S. Cheng & W. H. Mow, Low complexity OFDM receiver using log-FFT for coded OFDM system. In Proc. IEEE ISCAS, Scottsdale, AZ, May 2002, 3, 445–448.  [75] B. Widrow, J. M. McCool, M. G. Larimore & J. C. R. Johnson, Adaptive switching  circuits. In Proc. IRE WESCON Conv., Los Angeles, CA, 1960, 96–104.      549   cid:2   References  [76] D. Wulich, E. I. Plotkin & M. N. S. Swamy, Discrete time-varying ﬁlter and PLL for synchronous estimation of parameters of a sine signal corrupted by a closely spaced FM interference. Signal Process., 21:2  1990 , 183–194.  [77] D. Wulich, E. I. Plotkin & M. N. S. Swamy, Constrained notch ﬁltering of nonuni- formly spaced samples for enhancement of an arbitrary signal corrupted by a strong FM interference. IEEE Trans. Signal Process., 39:10  1991 , 2359–2363.  [78] D. Wulich, E. I. Plotkin, M. N. S. Swamy & W. Tong, PLL Synchronized time-varying constrained notch ﬁlter for retrieving a weak multiple sine signal jammed by FM interference. IEEE Trans. Signal Process., 40:11  1992 , 2866–2870.  [79] Y. Yang, C. Wang, M. O. Ahmad & M. N. S. Swamy, An on-line CORDIC based 2-D IDCT implementation using distributed arithmetic. In Proc. IEEE ISSPA, Kuala Lumpur, Malaysia, Aug 2001, 296–299.  [80] Y. Yang, C. Wang, M. O. Ahmad & M. N. S. Swamy, An FPGA implementation of an on-line radix-4 CORDIC 2-D IDCT core. In Proc. IEEE ISCAS, Scottsdale, AZ, May 2002, 4, 763–766.  [81] C. R. Zou, E. I. Plotkin & M. N. S. Swamy, 2-D fast Kalman algorithms for adap- tive parameter estimation of nonhomogeneous Gaussian Markov random ﬁeld model. IEEE Trans. Circ. Syst. II, 41:10  1994 , 678–692.      14  Fundamentals of information theory  14.1 Basic deﬁnitions  The foundation of information theory was established by Shannon, who formulated three important fundamental theorems: source-coding, channel-coding, and rate-distortion the- orems [21, 22]. Source coding or data compression is used to remove redundancy in a message so as to maximize the information storage or spectral efﬁciency for transmis- sion, and the source-coding theorem answers the question as to how much information is left after the removal of the redundancy. In contrast, channel coding adds redundancy to a message to combat errors caused by the channel. The rate-distortion theorem relates the minimum average bit rate for representing a discrete or continuous random variable with a speciﬁed distortion, and this is very useful for quantization. Channel capacity of a communication network is another important topic of information theory.  Information  Consider a random process X that takes values from a ﬁnite alphabet X consisting of elements Xi with probability Pr  Xi , i = 1, . . . , M. Information of an event or a symbol Xi is deﬁned as  I  Xi  = log2  1  Pr  Xi   = − log2 Pr  Xi    bits .   14.1   Base 2 is generally used, since binary representation for symbols is used in digital communications.  Entropy   symbols  X = For a signal with statistically independent discrete sources {Xii = 1, . . . , M}, by deﬁning Ai as the event of X = Xi, the entropy of variable X is obtained by taking the average of the information for all the events  H X  = E [I  Ai ] = M cid:26   Pr  Xm  log2  m=1  1  Pr  Xm    bits symbol .   14.2   The entropy is treated as the information inherent in the variable X, and it is always a positive number. In communication systems, typically all symbols are assumed to have      551   cid:2   14.1 Basic deﬁnitions  equal possibility Pr  Xm  = 1 M; this leads to the maximum possible entropy H = log2 M bits symbol. The entropy function is concave with respect to Pr  Xi .  Example 14.1: For an alphabet of only two symbols with probabilities Pr  X1  = P and Pr  X2  = 1 − P, the entropy function is  H P  = −P log2 P  −  1 − P  log2 1 − P .   14.3   This is plotted in Fig. 14.1. The entropy achieves the maximum 1 bit at the highest uncer- tainty Pr  X1  = Pr  X2  = 0.5. At P = 0 or 1, the symbols are known a priori, thus no information is contained.  Mutual information   cid:3    cid:2   Pr AB  Pr A   The concept of mutual information is to obtain information about A  as an event of the pro- cess X  by observing B  as an event of the process Y . It describes the average information common to X and Y. The mutual information of two events A and B is deﬁned as  I A; B  = log2  1  = − log2 Pr A; B  = log2   bits ,  Pr A; B    14.4  where Pr A  and Pr B  are assumed to be nonzero, and Pr AB  is the conditional probability, that is, the probability of A for given B. Using Bayes’ rule, I A; B  = I B; A . When A and B are completely independent, Pr AB  = Pr A , and I A; B  = 0. When A and B are completely dependent, then Pr AB  = 1, and I A; B  = − log2 Pr A   = − log2 Pr B  . The maximum informa- tion inherent in A is given by I A; A  = I A ; for this reason, I A  is also called the self-information of the event A.    P        H  1  0.8  0.6  0.4  0.2  0  0   cid:2 Figure 14.1  0.2  0.4  0.6  0.8  1  P  Binary entropy function.      552   cid:2   Fundamentals of information theory  For two signals X and Y with statistically independent symbols, X = {Xii = 1, . . . , M} and Y = {Yii = 1, . . . , N}, the mutual information of X and Y is deﬁned by taking the average of the mutual information for all the events  I X; Y  = E[I A; B ] = M cid:26  = M cid:26   i=1  N cid:26  N cid:26   j=1  Pr Xi, Yj I Xi; Yj    cid:3    cid:2   Pr XiYj  Pr Xi   Pr Xi, Yj  log2  i=1  j=1   bits ,   14.5   whose maximum that is achievable is called the channel capacity. Given the mutual infor- mation of event A and event B, I A, B , in the channel context, event A stands for the transmitted data symbol and event B for the received symbol.  Conditional self-information  The mutual information is the most important entropy. In addition to mutual information and self-information, conditional self-information of two events A and B is deﬁned as  I  AB  = log2  1  Pr  AB   = − log2 Pr  AB    bits .   14.6   Joint information and entropy  Likewise, the joint information of A and B, as two events of process X and of process Y, is deﬁned as  I A, B  = − Pr A, B  log2 Pr A, B    14.7  Let us assume the input symbol Xi ∈ X and the output symbol Yj ∈ Y. A stands for event X = Xi, and B stands for event Y = Yj. The joint entropy of the two processes is deﬁned by   bits .   cid:26    cid:26    cid:7    cid:8    cid:7    cid:8   H X, Y  = E[I A, B ] = −  Pr  Xi, Yj  log2 Pr  Xi, Yj   bits .   14.8   i  j  Conditional entropy  The conditional entropy, H XY , is deﬁned by  H XY  = − M cid:26   N cid:26   i=1  j=1   cid:7    cid:8    cid:7   Pr  Xi, Yj  log2  Pr XiYj    cid:8    bits ,   14.9   where M and N are the numbers of elements in X and Y. The conditional entropy characterizes the uncertainty caused by the channel. Note that  H X, Y  = H Y  + H XY  = H X  + H YX .   14.10       553   cid:2   14.1 Basic deﬁnitions  Relationships  The mutual information satisﬁes the chain rule  I X; Y  = E[I A; B ] = M cid:26   N cid:26   N cid:26   = M cid:26   i=1  j=1  Pr Xi, Yj  log2  i=1  j=1   cid:7   Pr Xi, Yj  log2  Pr XiYj    cid:3   Pr XiYj  Pr Xi    cid:2   cid:8  − M cid:26   i=1  Pr Xi  log2 Pr Xi    = −H XY  + H X . Thus, we have the following relationships  I X; Y  = H X  − H XY  = H Y  − H YX  = I Y; X ,  I X; Y  = H X  + H Y  − H X, Y ,  I X; X  = H X .  cid:7    cid:8   YjXi  These relationships can be illustrated by a Venn Diagram, as shown in Fig. 14.2 [3]. The mutual information I X; Y  is shown as the intersection of the information in X with the information in Y.  Since the conditional probabilities Pr  are determined by the channel, the only parameter that can be optimized for a given channel for a maximum channel capacity is the statistics of the input alphabet.  Differential entropy  For a random process X that consists of continuously distributed variable x, the entropy deﬁnition for discrete symbols is not applicable. Instead, the differential entropy is deﬁned by   cid:19 − log2 p x    cid:20  = −   cid:14  ∞  h X  = E  −∞ p x  log2 p x dx   bits ,   14.15    14.11    14.12    14.13    14.14   H Y,X   H XY   I X;Y   H YX    cid:2 Figure 14.2  H X   H Y   Relationships between mutual information and entropies.      554   cid:2   Fundamentals of information theory  where p x  is the pdf of X. Unlike the entropy, the differential entropy may be a negative value.   14.16    14.17    14.18    14.19   Example 14.2: Consider a random variable with uniform distribution between 0 and a,     p x  =  cid:14   a  a , 0 ≤ x ≤ a  1  0,  elsewhere  .  The differential entropy is  For a < 1, we have h X  < 0.  h X  = −  1 a  log2  1 a  0  dx = log2 a   bits .  Given a real Gaussian process with mean μX and variance σ 2  X, we have  hg X  = 1 2  log2  2πeσ 2 X   bits .  For a circularly symmetric complex random Gaussian process with variances σ 2 X, the real and imaginary parts are independent, the pdf is the product of the two independent Gaussian pdfs, and the entropy is derived as   cid:17    cid:17    cid:18    cid:18   hg X  = log2  πeσ 2 X   bits .  Thus, the differential entropy of a complex Gaussian random variable is the joint entropy of two independent real Gaussian variables with half the variance. The differential entropy of any continuous random process X, h X , is upper bounded by the differential entropy of the memoryless Gaussian source hg X  [21].  For a multivariate normal distribution with mean μ and covariance matrix  cid:17 , the pdf is  p x  =   cid:17 √   cid:18 n  cid:17 1 2  1  2π  1  2  x−μ T  cid:17 −1 x−μ .  e   14.20   given by  We have  h  x1, x2, . . . , xn  = h  Nn μ,  cid:17    = 1 2  log2 2πe n det  cid:17     bits .   14.21   Similar to the discrete case, if two random processes X and Y have a joint pdf p x, y , the joint entropy h X, Y  is deﬁned by  Joint Entropy   cid:14  ∞   cid:14  ∞  h X, Y  = −  −∞  −∞ p x, y  log2 p x, y dxdy   bits .   14.22       555   cid:2   Likewise, if X and Y have a joint pdf p x, y  = p x p yx , the conditional joint entropy h XY  can be deﬁned by  h XY  = −   bits .   14.23   14.2 Lossless data compression  Conditional Joint Entropy   cid:14  ∞  −∞   cid:14  ∞ −∞ p x, y  log2 p xy dxdy  Thus  h XY  = h X, Y  − h Y .   14.24   Mutual Information  The mutual information between two random variables with joint density p x, y  is deﬁned by  I X; Y  =  −∞  −∞ p x, y  log2  p x, y  p x p y   dxdy   bits .   14.25    cid:14  ∞   cid:14  ∞  From this deﬁnition, we can derive  I X; Y  = h X  − h XY  = h Y  − h YX  = I Y; X .  From  14.24  and  14.26 , we have  I X; Y  = h X  + h Y  − h X, Y .   14.26    14.27   Equations  14.24 ,  14.26 , and  14.27  resemble their discrete random variable counter- parts.  14.2 Lossless data compression  Data compression can be either lossless or lossy. Lossless compression is absolutely necessary for many types of data, including executable code and computer documents. This requires that the restored data ﬁle is identical to the original. In contrast, data ﬁles of images, audio, and other acquired signals allow some variations for storage or transmission.  The simplest lossless data compression method is run-length encoding  RLE . RLE is most efﬁcient for data ﬁles that frequently contain the same character repeated many times in a row. This may be a number of spaces in a text ﬁle, or a long run of zeros between two songs in a music, or runs of same values in a sampled digital signal. For RLE, the other parts of the data do not need to be encoded, but only the long runs of the same values are encoded. For example, a run of 100 zeros can be simply encoded as  0,100 . RLE followed by either Huffman or arithmetic encoding is a common strategy for lossless data compression.      556   cid:2   Fundamentals of information theory  14.2.1 Source coding theorem  For real coding systems, the average codeword length R is calculated as the sum of the probability Pm times its binary coding length lm:  R = M cid:26   m=1  Pmlm,  η = H X  R  ≤ 1.   14.28    14.29    14.31   where M is the number of symbols. The source-coding theorem [22] states that the code efﬁciency of any real code must satisfy  The source coding or noiseless coding theorem can also be described as follows [3, 18]:  Theorem 14.1  Source coding : Consider a discrete memoryless source  DMS  with ﬁnite entropy H X , X being the ensemble of symbols Xi, i = 1, . . . , M, with the corresponding probability of occurrence Pk, k = 1, . . . , M. It is possible to construct a code that has an average length R satisfying  H X  ≤ R < H X  + 1   14.30   subject to the preﬁx condition.  The preﬁx condition ensures the received sequence to be uniquely and instanta- neously decodable. The preﬁx condition states: given a codeword having k members {b1, b2, . . . , bk}, there is no other codeword of length l, for 1 ≤ l ≤ k − 1, with ele- ments {b1, b2, . . . , bk}. For example, a code consisting of symbols {1, 00, 01} is preﬁx free, while a code like {1, 10, 00, 01} is not preﬁx free. Given a received stream 11001, it can be decoded as 1,1,00,1 with the former code, but when the latter code is used, the decoder does not know whether it is 1,1,00,1 or 1,10,01. A necessary and sufﬁcient condition for the existence of a binary code with code words having lengths lk, k = 1, . . . , K that satisﬁes the preﬁx condition, known as the Kraft– McMillan inequality, is [3]  K cid:26   k=1  −lk ≤ 1. 2  Shannon-Fano coding is the ﬁrst well-known method that is based on the entropy of the symbols. Symbols with low probabilities are encoded into more bits, and those with high probabilities with fewer bits. The code satisﬁes the preﬁx condition, so that a coded message can be uniquely decoded. The Huffman coding shares most of the characteristics of the Shannon-Fano coding. Both the Shannon-Fano coding and the Huffman coding use a binary tree data structure, but the former is a top-down technique that works from the root to the leaves, while the latter is a bottom-up technique that starts from the leaves to the root. The two techniques are close in performance and complexity, but the Huffman coding is optimal [3].      557   cid:2   14.2 Lossless data compression  14.2.2 Huffman coding  The Huffman code [13] is a well-known variable-length code, which minimizes the average codeword length, subject to the constraint that the codewords satisfy the preﬁx condition. Huffman code may not be unique. Huffman coding is based on the probabilities P  Xi , i = 1, . . . , M, of the alphabets Xi. The idea of Huffman coding is to assign longer codewords to less probable symbols and shorter codewords to more probable ones. This idea was ﬁrst used in the Morse code invented in 1840s. The method starts from merging the two least probable sources into one new source with a probability of the sum of the two probabilities. This process is repeated until there is only one merged source, and a tree is generated. Then, starting from the root of the tree, assign 0 and 1 to the two branches at each node, until all the branches of the tree are reached. This generates the code tree and code is generated for each symbol of the alphabet.  Example 14.3: Design a Huffman code for a source with ten symbols in the alphabet X = {X0, X1, . . . , X9} with corresponding probabilities 0.08, 0.06, 0.20, 0.14, 0.09, 0.07, 0.02, 0.19, 0.11, 0.04. The procedure for deriving the code is illustrated in Fig. 14.3. From the ﬁgure, we calculate the average codeword length R = 3.13 bits symbol, while the cal- culated entropy for the source H X  = 3.0819 bits symbol. The histogram of the alphabet is shown in Fig. 14.4. When the histogram demonstrates rapid peaks, the compression is high.  Codewords X0  1100  1010  00  100  010  1101  10110  111  011  10111  X1  X2  X3  X4  X5  X6  X7  X8  X9  0.08  0.06  0.20  0.14  0.09  0.07  0.02  0.19  0.11  0.04  1100  1010  0.15  110  100 0.26  010  0.12  101  0.34  10110  1101  0.20  0.06  1011  10111  111  011  0.40  00  01  10  0.60 11  1.00  0  1   cid:2 Figure 14.3  Step  0  1  2  3  4  5  6  7  8  The process of Huffman coding.      558   cid:2   Fundamentals of information theory  i    X     r P  0.1  0.2  0.15  0.05  0   cid:2 Figure 14.4  0  1  2  3  4  5  6  7  8  9  i  The histogram of the alphabets.  Huffman coding requires the knowledge of the source statistics, which is usually not available. For this reason, Huffman coding is usually applied by reading the original data twice. The ﬁrst pass is used for frequency calculation and Huffman tree construction, and the data is compressed during the second pass. Such a method is a semiadaptive method and is normally too slow for practical implementation.  To design a Huffman code for a DMS, the probabilities of occurrence of all the source alphabets must be obtained. These probabilities can be empirically obtained by observing a long information sequence emitted from the source. For a discrete source with memory, the joint probability of the blocks of length L ≥ 2 must also be known. Estimation of joint probabilities is extremely expensive, and thus the Huffman coding is not suitable for real sources with memory.  Reversible variable-length codes  Huffman coding is very sensitive to transmission errors. An error in a sequence of variable- length codes may cause a decoder to lose synchronization, leading to propagation of the error into the decoded sequence. Reversible variable-length codes that can be decoded in either the forward or the backward direction can reduce errors. A decoder ﬁrst decodes each packet in the forward direction. If an error is detected, the packet is decoded in the reverse direction from the next resynchronization marker. This can limit the error to just one macroblock, in case of image coding.  Higher-order Huffman encoding  Huffman coding can be used in a more efﬁcient way by encoding a block of L symbols into one codeword at a time. In this case, the average number of bits per source symbol R will be more close to the entropy H X  [18]      559   cid:2   14.2 Lossless data compression  H X  ≤ R < H X  + 1 L  .   14.32   Thus, this method always provides a performance as good as or better than that of Huffman coding, although the computational burden is signiﬁcantly greater. This is known as a Lth- order Huffman encoding.  Adaptive Huffman coding  Adaptive or dynamic Huffman coding implements coding in a one-pass procedure. It starts with an empty Huffman tree and the tree is modiﬁed as symbols are being read and pro- cessed  compressed or decompressed  [20]. The performance of the adaptive Huffman coder is very close to that of the Huffman coder. For Huffman coding, a copy of the prob- ability table is required to be transmitted with the compressed data; otherwise, the decoder has no way to decode the data. For a large alphabet, the overhead arising from this table reduces the compression ratio signiﬁcantly. Adaptive Huffman coding adjusts the Huffman tree on the ﬂy, by using data previously seen. The encoder and the decoder use identical models for compression and decompression. As a result, adaptive Huffman coding leads to signiﬁcantly improved compression.  The adaptive Huffman code is a universal code  i.e., a code that does not depend on the distribution of the source . It is an asymptotically optimal universal data compression algorithm. The adaptive Huffman encoder is suitable as a real-time coder, but it is more vulnerable to errors and is more difﬁcult to implement. The Unix compact program uses adaptive Huffman coding.  Detailed C programs for Huffman coding and adaptive Huffman coding are given in [17].  14.2.3 Exponential-Golomb variable-length codes  Huffman coding needs to store a predeﬁned code table at both the encoder and the decoder. Also, when the size of the alphabet is very large, the Huffman table is very large. The Golomb code [12] and the exponential-Golomb  Exp-Golomb  code [23] are other types of variable-length codes, and they can be generated on the ﬂy for an input sym- bol. Golomb code divides the alphabet into groups of equal size, while the group size in the Exp-Golomb code increases exponentially. The Exp-Golomb code is a universal code for integers, and it is simpler and faster to encode and decode than the Huffman code.  Exp-Golomb codes are constructed to a format of the type   14.33  which corresponds to a total of  2M + 1  bits. Given the index of a codeword code_num, the codeword can be constructed as  ,   cid:19    cid:20   M zeros1 M-bit INFO    cid:7    cid:8  M = ﬂoor log2 code_num + 1  INFO = code_num + 1 − 2M.  ,   14.34    14.35       560   cid:2   Fundamentals of information theory  Table 14.1. Exp-Golomb codewords.  code_num  codeword  0 1 2 3 4 5 6 7 8 9 ···  1 010 011 00100 00101 00110 00111 0001000 0001001 0001010 ···  The decoding process is given as follows: count the number of zeros that are followed  by one as M; read the M-bit INFO ﬁeld; then  code_num = INFO − 1 + 2M.   14.36   The parameter to be encoded is ﬁrst mapped to code_num, by producing short code- words for frequently-occurring values and longer codewords for less common values. The coding result is given in Table 14.1. Exp-Golomb coding is used in the JPEG-LS image and H.264 MPEG-4 AVC video compression standards.  14.2.4 Arithmetic coding  Huffman coding achieves the entropy of the source only when the symbol probability is an integer power of 1 2 . Arithmetic coding [19] is a direct extension of the Shannon- Fano coding scheme [3]. The idea of arithmetic coding is to efﬁciently calculate the probability mass function Pr  Xi  and the cumulative probability function F  Xi  for the source symbol Xi. Using the ideas of Shannon-Fano coding, we can use a number in the cumulative probability interval [F  Xi  − Pr  Xi  , F  Xi   = [Li, Ui  as the code for Xi. Methods of arithmetic coding vary, but they all have certain common features. Each source symbol Xi, i = 1, . . . , M, is assigned a disjoint subinterval of the unit interval [0, 1 . In a pure arithmetic coding method, the subintervals for the M symbols partition [0, 1 . This allows the use of a fractional number of bits for each symbol. This method replaces a stream of input symbols with a single ﬂoating-point output number in the interval [0, 1 , and more digits  bits  are assigned for a longer, complex message [15, 17]. The encoding process narrows the range of a ﬂoating number with every new symbol, and decoding is the inverse procedure that expands the range in proportion to the probability of each extracted symbol.      561   cid:2   14.2 Lossless data compression  Table 14.2. Symbol probabilities of the  arithmetic coding example.  Symbol  Probability  [Li, Ui  in [0, 1   a b c d e f g  0.2 0.1 0.1 0.3 0.1 0.05 0.15  [0, 0.2  [0.2, 0.3  [0.3, 0.4  [0.4, 0.7  [0.7, 0.8  [0.8, 0.85  [0.85, 1.0   Table 14.3. Coding process of the message cbf gbadd.  Increase in the Interval  upper − lower × new portion  Encoded Interval  – [0.02, 0.03  [0.008, 0.0085  [0.000425, 0.0005  [0.000015, 0.0000225  [0.0, 0.0000015  [0.0000006, 0.00000105  [0.000000180, 0.000000315   [0.3, 0.4  [0.32, 0.33  [0.328, 0.3285  [0.328425, 0.3285  [0.328440, 0.3284475  [0.328440, 0.3284415  [0.3284406, 0.32844105  [0.328440780, 0.328440915   Message  c cb cbf cbfg cbfgb cbfgba cbfgbad cbfgbadd  Example 14.4: Given the alphabet {a, b, c, d, e, f , g}, with the corresponding probabilities of 0.2, 0.1, 0.1, 0.3, 0.1, 0.05, 0.15, code the message cbfgbadd by using arithmetic coding. The ﬁrst step is to assign each symbol a portion in the [0, 1  interval, which corresponds to the cumulative probability function. The result is shown in Table 14.2. To code the ﬁrst symbol c, we have its range is [0.3, 0.4 . The next symbol b is in the range [0.2, 0.3  of the new interval [0.3, 0.4 , leading to an updated range of 0.3+ 0.1× [0.2, 0.3  = [0.32, 0.33 . The coding process is shown in Table 14.3. The ﬁnal interval [0.328440780, 0.328440915  represents the message, and any number within this range represents the whole message.  Given a ﬂoating-point number, the decoding process extracts the symbols one-by-one,  until a speciﬁed number of digits is reached. The decoding process can be formulated as  Rn+1 = Rn − Ln Un − Ln   14.37       562   cid:2   Fundamentals of information theory  Table 14.4. Decoding process of the message cbf gbadd.  Encoded number  encoded – lower   upper – lower   Interval  Decoded symbol  0.3284408 0.284408 0.84408 0.8816 0.21067 0.1067 0.5335 0.445  [0.3, 0.4  [0.2, 0.3  [0.8, 0.85  [0.85, 1.0  [0.2, 0.3  [0, 0.2  [0.4, 0.7  [0.4, 0.7   c b f g b a d d  where Rn is a code within the cumulative probability range [Ln, Un  for the nth sym- bol. Therefore, the cumulative probabilities have to be transmitted with the code for decoding.  Example 14.5: Given a number that represents the encoded message, 0.3284408, by using the same probability intervals as the encoder given by Example 14.4, demonstrate the decoding process.  At the ﬁrst step, we ﬁnd that the message 0.3284408 is within [0.3, 0.4 . From Table 14.2, we decode the ﬁrst symbol as c. By applying  14.37 , the message for the sequence remov- ing the ﬁrst symbol is obtained as 0.284408. The decoding process is shown in Table 14.4. For the given number, the decoding process can be continued after the message cbfgbadd is obtained, so we have to truncate the message to the speciﬁed digits. Only when the number is very close to 0.328440780 can we get the exact message.  Arithmetic coding yields a number 0.328440780 that can be represented as a ﬁxed-point number of 23 bits, 0.010101000001010010110012, corresponding to 0.32844078540. . . + The sequence of data symbols can be represented by log2 = 22.8205 bits, which is very close to the optimum 1 log2 Pb coding.  + log2  + log2  + log2  +log2  +log2  +log2  1 Pd  1 Pb  1 Pd  1 Pg  1 Pa  1 Pc  1 Pf  Unlike Huffman coding that has a one-to-one mapping between the symbols and the codewords, arithmetic coding uses a single variable-length codeword to code a variable- length block of symbols. In arithmetic coding that uses ﬂoating-point representation, as the length of the message increases, the range of the message becomes smaller, which may be too small for computer representation given a large message length. Binary arith- metic coding is used to solve this problem. The binary arithmetic coding is relatively complex, and is well expounded in [7]. Detailed C programs for arithmetic coding are given in [7, 17].      563   cid:2   14.2 Lossless data compression  Context-based arithmetic coding  Like Huffman coding, arithmetic coding can be implemented by a ﬁxed or adaptive model. In the ﬁxed model, the algorithm needs two passes of the data, the ﬁrst pass for symbol statistics, and the second pass for coding. The probability table needs to be included in the compressed ﬁle. The adaptive model can dynamically estimate the symbol probabilities at the time of coding. Like Huffman coded data, arithmetic coded data is prone to channel errors, due to the cumulative impact on decoding of the subsequent data.  Context-based arithmetic coding is a popular adaptive arithmetic coding method that adapts the assigned probability to a symbol, according to the context of its spatial and or temporal neighbors. Use of arithmetic coding can improve the efﬁciency over Huff- man coding by approximately 5–10% [7]. Arithmetic coding plays an important role in advanced image video coding standards, and context-based arithmetic coding is employed in the JBIG, JPEG-LS, JPEG2000, H.263, H.264, MPEG-4 Visual, and MPEG-4 Audio standards. A similar idea is also used in the context-based adaptive variable-length code  CAVLC .  14.2.5 Dictionary-based coding  Dictionary-based coding was ﬁrst proposed by Lempel and Ziv in their 1977 and 1978 papers [28]. The proposed methods are now known as LZ77 and LZ78, respectively. The idea is to encode by decomposing the source bitstream into many short, previously unseen substreams. A variable-length string of symbols is encoded by a single token, which is an index to a phrase dictionary. Dictionary-based coding can be applied without knowledge of the source statistics, and can be used for general-purpose data compression due to its simplicity and versatility. Compression and decompression are simply a table-lookup and string replacement operation.  Dictionary-based compression requires low system resources, and this has made such compression algorithms more popular in recent years. It has become the standard algorithm for ﬁle compression on computers. Both the LZ77 and LZ78 algorithms have an asymptotic rate approaching the entropy of the source [3]. The Lempel–Ziv codes are asymptotically optimal universal codes. LZ78 typically compresses ASCII text ﬁles by a factor of 2.  LZ77 and LZSS  LZ77 uses a dictionary based on a sliding ﬁxed-size window that moves through the text, and the implementation is relatively simple. The LZ77 algorithm has a number of perfor- mance problems, which made it not a very practical algorithm to implement, until some of these problems were overcome in one of its variants, LZSS. LZSS improves the way the text window is maintained and the way the output tokens are represented.  It has been shown in [29] that the LZ77 universal compression is essentially optimal for ﬁnite N-blocks, whereas the adaptive universal Huffmann coding is not essentially optimal for ﬁnite blocks. Many general-purpose ﬁle compression and archive programs, such as arj      564   cid:2   Fundamentals of information theory  and LHarc, are based on LZSS. Other examples are popular programs such as all the zip variants  e.g. GNU gzip, winzip, pkzip  and the PNG  Portable Network Graphics  image format. The output from LZSS is a stream of tokens referring to individual characters or strings. In arj and LHarc, Huffman coding is further performed on the output of LZSS.  LZ78 and LZW  LZ78 builds its dictionary out of all the previously seen symbols. LZ78 scans the input sequence and matches it with a dictionary it maintains. When a failure of match occurs, the resulting word is then added to the dictionary. LZ78 requires two passes over the string: The ﬁrst pass parses the string, and the second pass generates the coded string. Unlike LZ77, LZ78 has to maintain a dictionary tree. LZ78 can potentially have an unlimited list of previously seen phrases. For LZ78, a string can be extremely long, leading to a high compression ratio. When implementing LZ78, both the encoder and decoder can start with a nearly empty dictionary. Arc and pkarc are general-purpose ﬁle compression and archival programs based on LZ78.  Welch [25] proposed a variant of LZ78, which is known as the Lempel-Ziv-Welch  LZW  coding algorithm. LZW improves LZ78 by outputting only phrases and never single char- acters. LZW gained immediate popularity after its appearance. A dictionary keeps a list, or a codebook of frequently occurring patterns. When these patterns appear in the source output, they are referred to the dictionary, while infrequently occurring patterns can be encoded by some other methods. The LZW algorithm employs a dynamic dictionary.  LZW is a variable-to-ﬁxed-length algorithm, and is widely used in the compression of computer ﬁles. It typically achieves a compression ratio of 2:1 for text and executable code, and 5:1 for extremely redundant data ﬁles such as computer source code and acquired signals. If an ergodic source generates the input string, the LZW ratio can be arbitrarily close to the entropy of the source.  The GIF  Graphics Interchange Format  image ﬁle is a lossless image compression tech- nique that employs LZW coding. It is also used in TIFF  Tagged Image File Format  and PostScript ﬁle formats. The UNIX compress program is also based on LZW. Compress provides a signiﬁcant by better compression than compact, and it is also faster. LZW is also the basis of many personal computer utilities for doubling the capacity of the hard disk. LZW is a patent of Unisys Corporation, but the patient expired in 2004. Detailed C programs for LZSS and LZW coding are given in [17].  Example 14.6: We now demonstrate the encoding of the LZ78 algorithm for the binary input sequence: 0010010111011001011 . . . Assume that 0 and 1 are stored in the codebook. As 0 and 1 have been stored in the codebook, the ﬁrst previously unseen shortest  subsequence is 00, thus Stored subsequences: 0, 1, 00 Sequence to be parsed: 10010111011001011 . . . The next unseen shortest subsequence is 10. This procedure is given in Table 14.5.  In the third line of Table 14.5, since 00 is composed of two 0’s in the codebook and 0 is at position 1 of the codebook, so it is represented as 11. This process is also applied to other      565   cid:2   14.3 Rate-distortion theorem  Table 14.5. Procedure for Lempel–Ziv encoding.  Stored subsequences Position in codebook Digital representation Binary coding  0 1  1 2  00 3 11 0010  10 4 21 0100  01 5 12 0011  011 6 52 1011  101 7 42 1001  100 8 41 1000  1011 9 71 1111  stored subsequences. The binary representation of the subsequence is given in the fourth line. The last symbol of each subsequence in the codebook is an innovation symbol, which makes the subsequence different from a previously stored subsequence. In the fourth line, each binary code has four bits; the ﬁrst three denote the binary representation of pointer of its root subsequence and the last bit is the innovation symbol.  For decoding, for example, the encoded binary representation for the subsequence at position 9 in the codebook is 1111, thus the last bit is 1 and ﬁrst three bits 111 points to position 7 in the codebook whose stored subsequence 101, thus the decoded subsequence is 1011.  From this example, we see that, unlike Huffman coding, the Lempel-Ziv algorithm employs ﬁxed-length codewords to represent source symbols of different lengths. This makes Lempel-Ziv coding especially suitable for synchronous transmission. In practice, a 12-bit ﬁxed block size is employed, corresponding to a codebook size of 4096. At present, the Lempel-Ziv algorithm has become the standard algorithm for ﬁle compression and achieves a better compression ratio than Huffman coding.  14.3 Rate-distortion theorem  The rate-distortion theorem quantiﬁes the minimum average bit rate RD, in bits sample, for representing a discrete or continuous random variable X with a distortion less than D. The lossless data compression we have discussed earlier in this chapter is a special case of rate-distortion theory applied to a discrete source with zero distortion. Shannon was the ﬁrst to establish the rate-distortion theorem in connection with the quantization of signals [21, 22].  The rate-distortion function R D  for a source X with distortion measure d  deﬁned as  subject to   cid:17   X; ˆX   cid:18   cid:8  ≤ D,  ,  x, ˆx  R D  = min p ˆxx   cid:26   cid:8    cid:7 ˆxx  p x p  d  I   cid:7    x,ˆx    cid:7    cid:8   x, ˆx  is   14.38    14.39       566   cid:2   Fundamentals of information theory x, ˆx   cid:8    cid:7 ˆxx   cid:7    cid:8  = p x p   cid:8    cid:7 ˆxx  where the minimization runs over all p satisﬁes the expected distortion constraint. The two common distortion measures are the Hamming distance and the MSE.  for which p  The rate-distortion theorem with a distortion measure states that for any given dis- tortion D, there exists a coding scheme that maps the source output into codewords such that the minimum rate R D  is sufﬁcient to reconstruct the source output with an average distortion arbitrarily close to D. The rate distortion theorem can be stated as follows [3, 22]:  Theorem 14.2  Rate distortion : If R ≥ R D , there exists a sequence of codes ˆXn  Xn  → D. If R < R D , no  Xn, ˆXn  Xn   d   cid:4  cid:4  cid:4 ˆXn ·    cid:4  cid:4  cid:4  ≤ 2nR and E   cid:22    cid:18  cid:23    cid:17   Note that the sequence Xn = X1, X2, . . . , Xn, and ˆXn is a quantized representation of Xn.  The rate-distortion function for a memoryless Gaussian source X, N cid:7    cid:8   , with the  0, σ 2 X  with number of codewords such codes exist.  MSE distortion measure, is given by [3, 22]  Rg D  =  ⎧⎨⎩ 1  2 log2 0,   cid:22  cid:7    cid:2    cid:3   σ 2 X D  ,   cid:23    cid:8 2  X  0 ≤ D ≤ σ 2 D > σ 2 X  cid:22    cid:23   where the MSE distortion D is given by D = E  x − ˆx  = E  e2  .  ,   14.40    14.41   This rate-distortion function for the memoryless Gaussian source is the upper bound of any memoryless, discrete-time, non-Gaussian source with zero mean and ﬁnite variance σ 2 X [5]. The rate-distortion theorem implies that no information needs to be transmitted if the distortion D ≥ σ 2 X. The rate-distortion theorem is most fundamental for quantization.  Example 14.7: The distortion function for a memoryless Gaussian source,  14.40 , is plotted in Fig. 14.5.  The lower bound on the rate-distortion function is given by the Shannon lower bound for an MSE distortion measure. For a continuous-amplitude, memoryless source X, the lower bound is given as  ∗ R   D  = h X  − 1 2  log2 2πeD ,   14.42   where h X  is the differential entropy of a continuous source X. The rate-distortion theorem states that R D  is the minimum information rate necessary to represent the output of a discrete-time, continuous-amplitude, memoryless stationary Gaussian source, based on the MSE distortion measure per symbol.      567   cid:2   14.4 Channel capacity  g R  3  6  5  4  2  1  0   cid:2 Figure 14.5  0  0.2  0.4  0.8  1  1.2  0.6 D σX  2  Rate distortion function of a Gaussian source.  For uniform signal pdf, as in the case of a uniform quantizer, we can derive, from  14.40 ,  that the SNR is given by  SNR = σ 2  X σ 2 q  = 22R D  ≈ 6.02R D  = D.  where the MSE of the quantization σ 2 q  Also from  14.40 , the distortion-rate function is derived as   dB ,   14.43   D R  = 2  −2Rσ 2  X  ≈ −6.02R + 10 log10 σ 2  X   dB ,   14.44   where R is the number of bits per sample.  The rate distortion function R D  for a multivariate normal vector source with Euclidean MSE distortion gives the allocation of R bits to the different components to minimize the total distortion. This can be realized by reverse water-ﬁlling [3].  14.4 Channel capacity  Channel capacity is the maximum rate for reliable transmission of information over the channel. Nyquist showed that a channel of bandwidth W Hz is capable of transmission of PAM signals at a rate of 2W samples per second without causing ISI.  Spectral or bandwidth efﬁciency is referred to as the rate of information transmission  per unit of occupied bandwidth. It can be deﬁned as  ηs = Transmission rate Channel bandwidth  = RsH B   bits s Hz ,   14.45   where Rs is the symbol rate, H is the entropy, that is, the average amount of informa- tion, measured in bits, conveyed per symbol, and B is the occupied bandwidth. For an      568   cid:2   Fundamentals of information theory  M-ary modulation, H = log2 M bits symbol. Nyquist’s sampling theorem limits Rs ≤ 2B  symbols s.  The channel capacity C, also known as Shannon capacity, is deﬁned as the maximum  average mutual information for a channel with power constraint S  C =  max  pX x :E[X2]≤S  I X; Y .   14.46   This capacity is determined by the transition probability, i.e., the conditional probability Pr YX , which can be expressed by the error probability. The rate R of an  M, n  code is deﬁned as  R = log2 M  n   bits per transmission ,   14.47   where M is the constellation size of the symbols, and n is the length of the code. codes A rate R is said to be achievable if there exists a sequence of the maximum probability of error λn → 0 as n→∞. There is duality such that between channel capacity and rate distortion for arbitrary pairs of i.i.d.  indepen- dent and identically distributed  correlated state information available at the sender and at the receiver, respectively [4]. The channel coding theorem was also given by Shannon [3, 21].  Theorem 14.3  Channel coding : All rates below capacity are achievable. Speciﬁcally, codes with maximum probability of for any R < C, there exists a sequence of error λn → 0. Conversely, any sequence of codes with λn → 0 must have R ≤ C. According to the channel coding theorem, it is possible to transmit data without errors as long as the bit rate is below the channel capacity. Channel coding is targeted at achieving this absence of errors. Channel coding is most important for improving the BER of digital communication systems that are susceptible to noise and interference.  For discrete memoryless channels, Shannon deﬁned the capacity as the maximum mutual information between the channel input X and the channel output Y for all input probability distribution   cid:8   cid:7  cid:29 2nR cid:30 , n  cid:7  cid:29 2nR cid:30 , n   cid:8    cid:7  cid:29 2nR cid:30 , n   cid:8   C = max  I X; Y  = max  Pr Xi    cid:26   cid:26   cid:24   Xi  Yj  Pr Xi   × log2   cid:7   cid:8   cid:7    cid:7   Pr  Xi  Pr YjXi Xk Pr  Xk  Pr  Pr  YjXi  YjXk   cid:8   cid:8  ,   14.48   where Pr  is the channel transition probability.   cid:8    cid:7   YjXi  14.4.1 Capacity of the AWGN channel for Gaussian distributed input  For an AWGN channel, the output Y and the input X are related by  Y = X + N,   14.49       569   cid:2   N cid:7    cid:8   14.4 Channel capacity  where the output Y and input X are continuous, and N is a white Gaussian noise with  0, σ 2 N The mutual information I X; Y  is given from  14.26  as  and a two-sided PSD N0 2.  I X; Y  = h Y  − h YX    14.50   = h Y  − h X + NX  = h Y  − h N .  cid:7   cid:17    cid:8   X. The entropy of Y is bounded by 1  In the second equality, the information in Y from known X is determined by the noise N. The last equality is due to the independence of N from X. For independent real Gaussian processes X and N, the powers satisfy σ 2 S = σ 2 Y thus, we have the one-dimensional  1-D  capacity C1d = I X; Y  = h Y  − h N   cid:13  − 1 log2 2  cid:3   S + σ 2  cid:18   N, where 2 log 2πeσ 2 N;  , and h N  = 1   bits per transmission   = S+σ 2   cid:17   cid:12   cid:2   2 log 2πe  πeσ 2 N   14.51   log2  log2   cid:18   N  = 1 2 = 1 2 = 1 2  πeσ 2 Y 1 + S σ 2 N 1 + 2 Es N0  log2   bits s Hz .   14.52   The last equality is obtained by inserting S = BEs and σ 2 2 . The dimen- sional capacity is thus equal to ηmax. Note that bits per transmission is the same as bits s Hz.  = B N0  N  Likewise, for independent complex Gaussian processes X and N, we can derive the two-  dimensional  2-D  capacity as   14.53    cid:8   14.54  S + σ 2 , In order to obtain the above result, we exploit that h Y  is bounded by log2 πe h N  = log2 πeσ 2 At the highest spectral efﬁciency, Es = C2dEb for complex-valued signal alphabet; thus, we have from the capacity for the AWGN channel with Gaussian input  = BN0.  n , and σ 2 N   bits s Hz .   cid:7   N  = 2C2d − 1  Eb N0   14.55  From this, we have γb = Eb → ln 2 = −1.59 dB as C2d → 0  for inﬁnite bandwidth , and increases exponentially as C2d → ∞. γb = −1.59 dB is the lower bound of γb, and is called the Shannon bound. The same lower bound is obtained for a real-valued signal alphabet.  C2d  N0  .   cid:13   cid:3    cid:12   cid:2  1 + S σ 2 N 1 + Es N0  C2d = log2 = log2      570   cid:2   Fundamentals of information theory  1–D 2–D  1–D 2–D    z H   s   s t i b      d C  20  15  10  5  0    z H   s   s t i b      d C  20  15  10  5  0   cid:2 Figure 14.6  The dimensional capacity for the AWGN channel with Gaussian distributed input.  0  20 b  dB   γ  40  0  20 b  dB   γ  40  Example 14.8: The channel capacities of the AWGN channel versus γb = Eb are plotted in Fig. 14.6, for both the 1-D and 2-D cases.  N0  and γs = Es  N0  The channel capacity C for a band-limited channel is given by the well-known formula [21]  Channel capacity for band-limited channels   cid:2    cid:3   C = B log2  1 + S BN0   bits s ,   14.56   where B is the channel bandwidth in Hz, S is the average signal power, and BN0 is the noise power. This result is valid for both real and complex band-limited Gaussian channels. The maximum spectral efﬁciency is given by the normalized capacity C B bits s Hz. Equation  14.56  can be derived as follows. For a period of T, the power per sample is ST 2BT = S 2B, where 2BT is the number of samples, based on the Nyquist theo- 2 2B = N0B, and the noise variance per sample is thus  cid:13  rem; the noise has a power of N0  N0B  T 2BT = N0 2. As a result, the capacity per sample is derived from  14.51  as   cid:12    cid:3    cid:2    bits sample .   14.57   C = 1 2  log2  1 + S  2B N0 2  = 1 2  log2   cid:2  Since there are 2B samples each second, we obtain the capacity given by  14.56 . As B → ∞, we get from  14.56 ,  C∞ = lim B→∞  S N0  log2  1 + S N0B  log2 e = 1.44  S N0  .   14.58   This is the maximum channel capacity. A practical system usually increases SNR and reduces B to improve the spectrum efﬁciency. The relation of C versus B is illustrated in Fig. 14.7.  1 + S N0B  cid:3  N0B  S = S N0      571   cid:2   14.4 Channel capacity  C  1.44S N0  S N0   cid:2 Figure 14.7  S N0  B  Shannon capacity C versus B for a ﬁxed S N0 ratio.  For parallel Gaussian channels with a common power constraint, an optimization  process, known as water-ﬁlling, is used to maximize the channel capacity [3].  Feedback  It is proved in [3] that feedback does not increase the capacity for discrete memoryless channels. But it helps to signiﬁcantly reduce the complexity of encoding or decoding. The same is true for the AWGN channel. For channels with memory, feedback does increase the capacity. The capacity without feedback can be calculated using water-ﬁlling, but the capacity with feedback is more difﬁcult to characterize. Feedback increases the capacity of a non-AWGN channel by at most half a bit per transmission [3].  14.4.2 Capacity of the AWGN channel for discrete input alphabets  There is no closed-form capacity bound for discrete input alphabets. They can only be evaluated numerically according to  14.48 . An example is given here for this purpose.  Example 14.9: The binary symmetric channel  BSC  is a mathematical model for binary transmission over a Gaussian channel with hard decisions at the output. The capacity of the BSC is given by  C = 1 − Hb P ,  where Hb P  is the binary entropy function,  Hb P  = −P log2 P −  1 − P  log2 1 − P .  P is the crossover probability, that is, the probability of input 0 becoming output 1 or vice versa, or the error probability. For the Gaussian channel using BPSK modulation, the error probability for optimal detection is Pb = Q from  7.55 . The channel capacity C versus γb is plotted in Fig. 14.8.  2γb   cid:7 √   cid:8    14.59    14.60   In case of soft decoding, the channel input is discrete, while the channel output may be continuous. Assuming the input constellation {cm} of size M,  14.48  can be written as      572   cid:2   Fundamentals of information theory  1  0.8  0.6  0.4  0.2    z H   s   s t i b      C   cid:2 Figure 14.8  0 −20  −15  −10  0  5  10  −5 b  dB   γ  The channel capacity of the BSC.  M−1 cid:26   C =  max  P  cm   P ci ,i=0,...,M−1   14.61  where P  cm  is the probability of the constellation point cm, and p  ycm  is the conditional pdf. The maximization is subject to the average power constraint  m=0   cid:24    cid:8   cid:7   cid:7  p  ycm  p cj j P  ycj   cid:8  dy,   cid:14  ∞ −∞ p  ycm  log2 M−1 cid:26   P  cm  c2 m  ≤ S.  m=0  For M-ary modulation, it is common to assume that the channel input probabilities are equal with P cm  = 1 M .  For a real-valued random variable y, the conditional pdf is given by  One-dimensional case  Thus, for a one-dimensional constellation with equal-distance points, from  14.61 , we have  −  y−cm 2 e 2σ 2  .  p  ycm  = 1√ 2π σ  cid:14  ∞  √ 1 2π  −∞  σ  −  y−cm 2 e 2σ 2  log2  M−1 cid:26   m=0  C = 1 M   cid:24   −  y−cm 2 e 2σ 2 −  y−cj 2 2σ 2  j e  1 M  dy.   14.64   Substituting y = zσ + cm =  z + cm  σ , we have  M−1 cid:26    cid:14  ∞  M  m=0  −∞  M−1 cid:26   i=0  C = log2 M − 1  1√ 2π  − z2 e  2 log2  −  cm−ci 2 e  2  −z cm−ci dz. e   14.65    14.62    14.63       573   cid:2   14.4 Channel capacity  M−1 cid:26   m=0  c2 m.  γ = 1 M  Note here cm is cm normalized by σ . The corresponding SNR is given by   14.66    14.67   For a given constellation, the relation between C and γ can be evaluated by numerical integration. For MASK, we have cm =  2m + 1 − M d0, i = 0, 1, . . . , M − 1. Thus,  Thus, d0 =  γ KM  . Substituting z = d0u, after manipulation, we ﬁnally get   cid:21   M−1 cid:26   2m + 1 − M 2d2  γ = 1 M  m=0   cid:31   M−1 cid:26   C = log2 M − 1 √  cid:12  M−1 cid:26  2π − 2γ e KM  × log2  M  γ KM  m−i  m−i+u   m=0  i=0  0  = KMd2 0.  cid:14  ∞  cid:13   − γ 2KM  −∞ e  u2  du   MASK .   14.68   Example 14.10: The capacity for MASK signaling in the AWGN channel is plotted in Fig. 14.9. It is seen that at low SNR, the capacity of MASK signaling is close to that of the AWGN channel.  Two-dimensional case  For the complex AWGN channel, the constellation is in the complex plane. MPSK and MQAM have signaling constellations in the complex plane. The channel input cm and output y are both complex numbers. The conditional pdf p  ycm  is given by  p   ycm  = 1  − y−cm2 2σ 2   14.69  Substituting y = zσ + cm =  z + cm  σ , where z = u + jv, and using a procedure similar to that used for the real AWGN channel, the channel capacity can be derived. When all the symbols have equal probability, the capacity is derived as  2π σ 2 e  .  M−1 cid:26    cid:14  ∞   cid:14  ∞  −∞  −∞ m=0 −cm−ci2 e  2  −Re[z ∗ e  2  − z2 e  1 2π  cm−ci ]dudv.  C = log2 M − 1 M−1 cid:26   M  × log2  i=0   14.70       574   cid:2   Fundamentals of information theory  0 −10  0  10  30  40  50   cid:2 Figure 14.9  The channel capacity of the MASK modulation in the AWGN channel.  7  6  5  4  3  2  1    z H   s   s t i b      C  64ASK  32ASK  16ASK  8ASK  4ASK  ASK  AWGN, 1–D  20 γ  dB   M−1 cid:26   m=0  The passband signal has an SNR  γ = 1 2M  cm2 .   14.71   M , m = 0, 1, . . . , M−1. From  14.71 , we have γ = A2 For MPSK, let cm = Aej 2πm A = √  cid:14  ∞ 2 . Thus, M−1 cid:26  2γ . Substituting u = u1A and v = v1A, after manipulation we ﬁnally obtain  cid:18  1−cos 2π m−i  C = log2 M − γ  cid:17   γ log2  cid:18  cid:23   M−1 cid:26   −2γ e  i=0  +v2  πM   cid:17    cid:22   u2 1   cid:8   M  1   cid:14  ∞ − cid:7   cid:18   cid:17  −∞ e +v1  m=0 cos 2πm M  −∞ −cos 2πi  M  sin 2πm M  −sin 2πi  M  du1dv1   MPSK .   14.72   −2γ  × e  u1  Similarly, C as a function of γ can be derived for any MQAM signaling. This is left as Problem 14.23.  Example 14.11: The capacity for MPSK signaling in the AWGN channel is plotted in Fig. 14.10. At low SNR the capacity of MPSK signaling is close to that of the AWGN channel.  14.4.3 Area spectral efﬁciency  Area spectral efﬁciency  ASE  is a capacity measure that can better characterize the capac- ity of a cellular network than the Shannon capacity. In cellular systems, the channels are reused at a distance D, and the area covered by each channel is roughly a circle with area A = πD2 4. ASE is deﬁned as the maximum throughput per unit bandwidth per unit area that is achieved in a cell      575   cid:2   14.5 Source-channel coding theorem  AWGN, 2–D    z H   s   s t i b      C  7  6  5  4  3  2  1  0 −10  64PSK  32PSK  16PSK  8PSK  QPSK  BPSK   cid:2 Figure 14.10  The channel capacity of the MPSK modulation in the AWGN channel.  0  10  30  40  50  20 γ  dB   ηASE = CSR B πD2 4   bits s Hz m2 ,   14.73   where CSR is the system throughput or sum-rate capacity, i.e., the maximum of the sum of data rates of all users in a cell,  K cid:26   k=1  CSR = max  Rk,   14.74   with each user’s capacity being calculated as Shannon limit by using SIR obtained from the analysis of the intercell and intracell interferences.  An overall investigation of ASE for the uplink of a cellular system with orthogonal channelization has been conducted in [1]. The investigation is based on the assumption of variable-rate transmission as well as different intercell interference conditions, different fading models, cell sizes, and system loads. For best-case and average interference, the optimal reuse factor is unity, no matter whether spreading is used for interference reduction or not. ASE also decreases as an exponential of a fourth-order polynomial of the cell radius.  14.5 Source-channel coding theorem  Shannon’s source-channel separation theorem states that source coding and channel coding can be performed separately and sequentially without loss of optimality. However, the two-stage encoding method is optimal only for inﬁnite block length codes, which induces inﬁnite complexity and delay. This makes separate source and channel coding undesirable for most real-time applications. Moreover, separate source and channel coding is designed for the worst case scenario, and it is not applicable for multi-user and nonergodic channel environments [3, 11].      576   cid:2   Fundamentals of information theory  The redundancy in the source is usually suited to the channel, and joint source- channel coding provides a performance superior to the two-stage method. The joint source-channel coding approach shares information between the source coder and the channel coder, and utilizes the soft information from the physical layer [11]. It allows the coder to better exploit the changes in the channel conditions or variations of the source contents.  The source coding theorem requires R > H for data compression, and the channel cod- ing theorem requires R < C for data transmission [3]. The source-channel coding theorem addresses that H < C guarantees reliable transmission of source over a channel. To send a sequence of symbols Vn = V1, V2, . . . , Vn over the channel, one needs to map it onto a codeword Xn Vn  and send the codeword over the channel. The receiver makes an estimate of the sequences, ˆVn, from its received sequence Yn.  Theorem 14.4  Source-Channel coding : All sources with entropy H below the chan- nel capacity C can be reliably transmitted. Speciﬁcally, if Vn = V1, V2, . . . , Vn is a ﬁnite alphabet stochastic process that satisﬁes the asymptotic equipartition property  AEP  and H V  < C, there exists a source-channel code with probability of error Pr ˆVn  cid:18 = Vn  → 0. the process over the channel with arbitrarily low probability of error, Pr ˆVn  cid:18 = Vn  ≥  Conversely, for any stationary stochastic process V, if H V  > C, it is not possible to send   cid:21  > 0, where  cid:21  is a constant.  −nH.  The AEP is the direct consequence of the weak law of large numbers. The AEP n log2 Pr Vn  → H with probability 1, as n → ∞, where Vn can be a states that − 1 sequence of i.i.d. random variables or a sequence of states of any stationary ergodic source and Pr Vn  is the probability of observing the sequence Vn = V1, V2, . . . , Vn. Thus, Pr Vn  → 2 Similarly, AEP for continuous random variables drawn from the density pV v  is given n log2 pV Vn  → h V  with probability 1, as n → ∞. by − 1 The LZ77 encoder does not completely eliminate the redundancy present in the input sequence. For example, when an LZ77 phrase has multiple matches, the LZ77 encoder can issue a pointer to any of those matches and a particular choice carries some additional bits of information. A RS channel coder exploits the inherent redun- dancy left by the LZ77 encoder to detect and correct a limited number of errors. The resulting LZRS’77 algorithm is backward-compatible with LZ77 in [16], that is, a ﬁle compressed with the LZRS’77 can still be decompressed by a generic LZ77 decoder.  14.6 Capacity of fading channels  The ergodic capacity C represents the average capacity among all channel states, and is mainly used for fast fading channels when coding is performed over many channel states. The outage capacity Cout is particularly used for slowly-fading channels.      577   cid:2   14.6 Capacity of fading channels  14.6.1 Capacity with CSI at receiver only  Ergodic capacity   cid:14  ∞   cid:14  ∞  The ergodic capacity of a fading channel with receiver CSI  channel state information  for an average power constraint S is given by  C =  C γ  pγ  γ  dγ =  log2 1 + γ  pγ  γ  dγ  0  0   14.75  where the received SNR γ = h2Es N0, h being the instantaneous channel coefﬁcient, and pγ  γ   is the pdf of γ . In a fading environment with receiver CSI, the Shannon capacity is less than that of an AWGN channel with the same average SNR. For the Rayleigh channel, pγ  γ   = 1  cid:12  γ e can be shown that [14]  −γ  γ with γ = σ 2  cid:12   . Inserting it into  14.75 , it   bits s Hz ,   cid:13   Es N0  h  C = log2 e · exp  1  σ 2 h Es N0  1  σ 2 h Es N0  ,  where  expint x  =   cid:13  · expint  cid:14  ∞  −t e t  dt.  x   14.76    14.77   Example 14.12: The ergodic capacity of the Rayleigh fading channel is plotted in Fig. 14.11. For large SNR, a loss of roughly 2.5 dB is observed due to fading. This is very small compared to the BER loss of approximately 17 dB in the uncoded case. This is because the channel coding theorem assumes inﬁnitely long codewords so that a high diversity gain can be achieved at the decoder. It is observed that both AWGN and Raleigh fading channels achieve the lower limit of −1.59 dB.  AWGN Ergodic Cout, p%  14  12  10  8  6  4  2    z H   s   t i b      C  p = 65  16  p = 1  0 −10  0  10  30  40  4  20  γ  dB    cid:2 Figure 14.11 Ergodic and outage capacities of a ﬂat Rayleigh fading channel for Gaussian input, where p%  denotes the outage probability.      578   cid:2   Fundamentals of information theory  Outage capacity  The relation between an outage probability Pout and the corresponding outage capacity Cout is given by  5.26 . We reproduce it here  Pout = Pr  C γ   < Cout  =  pγ  γ  dγ ,   14.78   where γmin can be obtained from Cout. For the AWGN channel, Cout = log2  1 + γmin , thus γmin = 2Cout − 1. For a Rayleigh fading channel with the same SNR as that of the AWGN channel, that is, γ = Es N0, we have, from  3.50    cid:14  γmin  0   cid:2   1 − 2Cout Es N0   cid:3   .   cid:3   Pout = 1 − exp   cid:2   From  14.79 , Cout is obtained as a function of Pout and Es N0 ln  1 − Pout   Cout = log2  .  1 − Es N0   14.79    14.80   Example 14.13: The outage capacity, given by  14.80 , is also plotted in Fig. 14.11, for different values of Pout. When Pout = 64%, Cout is greater than the capacity of the AWGN channel. As expected, for a small Pout the outage capacity Cout drops dramatically for a given SNR.  Example 14.14: The relation between Pout and Cout, given by  14.79 , is plotted in Fig. 14.12 for different SNRs.  −5dB 0 dB 5 dB  10 dB  15 dB  Es N0 = 20 dB  1  0.8  0.6  0.4  0.2  t u o P   cid:2 Figure 14.12  Pout as a function of Cout for the ﬂat Rayleigh fading channel with Gaussian input.  0  0  2  6 4 Cout  bits s Hz   8  10      579   cid:2   14.6 Capacity of fading channels   cid:14  ∞  cid:14  ∞  0  0  S γ  pγ  γ  dγ = S.    − 1  S γ    =  S  1 γ0 0,   cid:2   cid:14  ∞  cid:14  ∞  γ0  1 γ0  − 1  γ  ,  γ , γ ≥ γ0 γ < γ0  cid:3  p γ  dγ = 1.  cid:3   cid:2   p γ  dγ .  C =  B log2  γ0  γ γ0  The outage probability is an effective tool for characterizing nonergodic channels, since we cannot compute the ergodic capacity or the average error probability. In such cases, the error probability Pe h  and the capacity C h  are random variables. The outage probability can be deﬁned as Pout = Pr{Pe h  > P0} or Pout = Pr{C h  < C0}.  14.6.2 Capacity with CSI at transmitter and receiver  If both the transmitter and the receiver have CSI, the transmitter can adapt its transmission strategy. Assuming the transmitted power S γ   to vary with the received SNR γ subject to an average power constraint S, the fading channel capacity is deﬁned by maximizing [9]   cid:2    cid:3   C =  B log2  1 + S γ  γ S  pγ  γ  dγ   14.81   subject to  By using the Lagrange multiplier method, the optimal power adaptation is derived as [9]  where γ0 is the cutoff SNR. Thus, only when γ > γ0, is there data transmission. The cutoff SNR γ0 can be derived from the power constraint  Finally, the capacity formula is given by [9]  For Rayleigh fading, this capacity exceeds that of the AWGN channel with the same average SNR, which is in contrast to the case of CSI at the receiver end only.  Zero-outage capacity  When the transmitter uses the CSI to maintain a constant received power, the channel appears to be a time-invariant AWGN channel to the encoder and decoder. This power adaptation scheme, called channel inversion, is given by [9]  S γ    S  = σ  γ  ,   cid:22  where σ is the constant received SNR that satisﬁes the transmit power constraint  14.82 , from which σ is given by σ = 1   cid:23  .  E  1 γ   14.82    14.83    14.84    14.85    14.86       580   cid:2   Fundamentals of information theory  Finally the capacity of the fading channel is given by  C = B log2 1 + σ  .   14.87   This capacity can be achieved using a ﬁxed-rate encoder and decoder designed for the AWGN channel with SNR σ . Since the receiver gets constant power and there is no channel outage, this capacity is also called zero-outage capacity. Zero-outage capacity may be signiﬁcantly smaller than Shannon capacity in fading environments, since E may be very large. The channel-inversion strategy is used in CDMA systems to combat the near-far effect.   cid:23    cid:22   1 γ  Outage capacity  The non-outage capacity can be signiﬁcantly improved by modifying the power adaptation strategy in the following way: suspend transmission in outage channel states  when γ < γ0  and use a constant data rate in the other states. Such a capacity is referred to as the outage capacity. The power adaptation scheme compensates for fading only when γ ≥ γ0  where γ0 is calculated from the outage probability: Pout = Pr γ < γ0 . Accordingly,   14.88   pγ  γ  dγ .   14.89    cid:15   S γ    =  S  σ γ , γ ≥ γ0 0, γ < γ0  cid:14  ∞  ,  1 γ  , Eγ0[1 γ ] =  cid:3   cid:2   1  Eγ0[1 γ ]  σ =  1  γ0 This scheme is known as truncated channel inversion.  Eγ0[1 γ ]  The outage capacity is thus given by 1 +  C = B log2  Pr  γ ≥ γ0  .   14.90   By searching over all γ0, a maximum outage capacity can be achieved. The maximum outage capacity is still less than the Shannon capacity  14.85 , but is easier to implement.  Dirty paper coding  The notion of dirty paper coding  DPC  [2] can be used to improve channel capacity. If the transmitter has perfect, noncausal knowledge of interference to a given user, then the capacity of the channel is the same as that in the case of no interference to the user, or is equivalent to the case where the receiver has perfect knowledge of the interference so that it can subtract it. Based on this idea, the interference can be presubtracted at the transmitter without increasing the transmit power [6].  Comparisons between different transmission schemes  The AWGN channel has a larger capacity than that of all fading channels. However, at low SNR, fading channels with transmitter and receiver CSI have the same capacity as the      581   cid:2   14.6 Capacity of fading channels  AWGN channel. When the SNR is lower than 0 dB, the fading channel with transmitter and receiver CSI has a larger capacity than the AWGN channel. This is because the fading channel will occasionally have higher SNR due to its distribution over an inﬁnite range and high data rates are transmitted during these periods.  Simulation in [9] shows that transmitter adaptation yields a negligible capacity gain compared to using only receiver CSI. Nevertheless, the power adaptation scheme with transmitter and receiver CSI requires a more complex transmitter and a feedback path for sending the CSI from the receiver to transmitter, but the decoder in the receiver is simpler. On the other hand, the nonadaptive policy leads to a simple transmission scheme, but its code design must make use of the channel correlation statistics and the decoder complexity is increased. Channel inversion and truncated channel inversion use codes designed for the AWGN channel and are easy to implement, but there is a large capacity loss in severe fading conditions.  Channel inversion is much less power-efﬁcient in a fading channel, compared to water- ﬁlling, since the majority of the power is used to invert the bad channel condition. However, channel inversion achieves a ﬁxed rate in all fading states. Thus, channel inver- sion eliminates the delay associated with the time-scale of channel variations. Without diversity, the capacity is typically very small. With increase of the diversity order, the probability of occurrence of a bad channel is reduced, and accordingly the capacity increased.  14.6.3 Capacity of frequency-selective fading channels  A frequency-selective fading channel with frequency response H f   can be divided into many subchannels. For time-invariant channels, one can select each subchannel to be of  cid:24  bandwidth B and H f   = Hj constant over the subchannel. Each subchannel is a ﬂat-fading channel. Such a channel H f   is known as block fading. j Sj ≤ S, and the  The total power of the subchannels is subject to the power constraint  capacity is the sum of the data rates on each subchannel [9]   cid:12  1 +   cid:13    cid:4  cid:4 Hj   cid:4  cid:4 2 Sj  N0B  .   cid:26   j   cid:8   =  C =  cid:7   Sj  γj S  B log2     − 1  γj  , γj ≥ γ0 γj < γ0  1 γ0 0,  ,   cid:2    cid:26   j   cid:3   1 γ0  − 1 γj  = 1.  The optimum power allocation can be derived using the Lagrange multiplier method, leading to the water-ﬁlling power allocation on each subchannel  where γj = Hj2S  N0B is the SNR of the jth subchannel assuming that the entire power budget  is allocated to it, and the cutoff value γ0 is derived from the power constraint as   14.91    14.92    14.93       582   cid:2   Fundamentals of information theory  Finally, the capacity is given by [9] C =   cid:26   B log2  j:γj≥γ0   cid:2    cid:3   .  γj γ0   14.94   Note that this optimum capacity is achieved by transmitting at different rates and powers over the subchannels. This idea is used in multicarrier modulation. For time- invariant frequency-selective fading channels, given continuous H f  , similar results can be obtained, wherein the capacity is given in integral form.   cid:7   The capacity of time-varying frequency-selective fading channels is very difﬁcult to cal- culate, due to the effect of ISI. This capacity can be approximated by dividing the channel into many subchannels, each having a bandwidth of the channel-coherent bandwidth Bc. Each of these subchannels is assumed to be independent, time-varying, and ﬂat fading with H using the Lagrange multiplier method subject to power constraints on each subchannel and on the whole channel.   cid:8  = Hj i  on the subchannel. The derivation for the optimum capacity can be made  fj, ti  Approximate water-ﬁlling schemes can greatly simplify transmitter and receiver design. In a constant-power allocation strategy, the transmitter allocates zero power to subchan- nels that would receive zero power in exact water-ﬁlling, but allocates constant power in subchannels that would receive positive power in exact water-ﬁlling. A constant-power allocation strategy was observed to be close to the optimal in the adaptive modulation setting [10]. In [27], the performance of constant-power water-ﬁlling algorithms was inves- tigated for the ISI channel and for the i.i.d. fading channel. Upper bounds on the maximum difference between the achievable rate under constant-power water-ﬁlling and that under true water-ﬁlling is given. In particular, for the Rayleigh fading channel, the spectral efﬁ- ciency loss due to constant-power water-ﬁlling is at most 0.266 bit s Hz. The performance bound allows the development of a low-complexity, logarithm-free, power-adaptation algorithm.  14.7 Channel capacity for multiuser communications  For multiuser communications, each user has its own QoS constraints such as target data and error rates. In this case, we need to consider not only the maximum cell throughput or sum rate, but also the set of achievable individual data rates for all users, called capacity region. In the following, we discuss the case when the BS and all the users have a single antenna. This can be extended to the multiuser MIMO case.  14.7.1 AWGN channel  Given a common BS and Nu mobile users, for the uplink the optimum strategy is to transmit all user signals xu simultaneously using the entire bandwidth. The received signal at time k is given as      583   cid:2   14.7 Channel capacity for multiuser communications  The achievable rate Ru of user u is limited by the individual capacity in the absence of all the other users  using  14.54    r k  = Nu cid:26   u=1  Ru ≤ Cu = log2  xu k  + n k .  cid:2   1 + Es,u N0   cid:3   .   14.95    14.96   By summing up the rates of all the Nu users, we may obtain the sum rate. However, this sum rate is too optimistic, since mutual interference is not considered. The sum rate can be obtained as the capacity achieved by a single user that transmits with the power of all Nu users   cid:12    cid:24 Nu   cid:13   .  Ru ≤ Cmax = log2  1 +  u=1 Es,u N0  Nu cid:26   u=1   14.97   Equations  14.96  and  14.97  constitute the multiple access channel capacity [3, 14]. More generally, we have the following theorem [3]:   cid:7   Theorem 14.5  Capacity of multiple access channel : The capacity region of the m-user multiple access channel  X1 × X2 × . . .Xm, p yx1, x2, . . . , xm , Y  is the closure of the convex hull of the rate vectors satisfying X M ; YX   14.98  for some product distribution p1  x1  p2  x2  . . . pm  xm  on X1 × X2 × . . .Xm, where Mc is  the complement of M, and R M  = cid:24   for all M ⊆ {1, 2, . . . , m},  i∈M Ri, X M  = {Xi : i ∈ M}.  R M  ≤ I   cid:8  cid:8   Mc   cid:7   ,  For the two-user case,  14.97  can be written as   cid:2   cid:2   Two-user case   cid:3   Cmax = log2 = log2   cid:3   1 + Es,1 + Es,2 N0 1 + Es,1 + log2 N0   cid:2    cid:3   .  1 + Es,2  Es,1 + N0   14.99   In the last equality, Es,1 and Es,2 can be interchanged. This maximum sum rate can be real- ized by using successive decoding with interference cancellation, which is discussed for CDMA systems in Chapter 8. If detection begins with user two, the second term corre- . Thus, if the rate of user two, R2 ≤ CMUI sponds to the maximum rate of user two, CMUI , it can be perfectly cancelled, and user one can thus achieve its maximum rate C1 given as  cid:8   cid:7  the ﬁrst term, R1 = C1 = I  x1 k ; r k x2 k  , which is exactly the maximum mutual information between x1 k  and r k  when x2 k  is known. Thus, we obtain a rate pair C1, CMUI can also be obtained if we start with the detection of user one. The capacity region is the area inside the pentagon, as shown in Fig. 14.13.  . Alternatively, a rate pair  CMUI  , C2   cid:8    cid:7   2  2  1  2      584   cid:2   Fundamentals of information theory  R2  MUI   C1   ,C2   C2  MUI  C2  MUI  C1,C2          cid:2 Figure 14.13 The capacity region for uplink transmission in the AWGN channel and two users. The dotted line  corresponds to orthogonal multiple access schemes.  MUI  C1   cid:7   C1  R1   cid:8    cid:7    cid:8   C1, CMUI  2  and  by using succes- The maximum sum rate is achieved at sive interference cancellation. The line between these two points can be achieved by approximately switching between the two transmission strategies. It is noted that Cmax ≥ max  C1, C2 . The optimum strategy with successive decoding can be generalized for Nu users in a straightforward manner. For each of the Nu! possible detection orders, a point consisting of Nu individual rates is obtained. Usually, the Nu users have an ascending order of detection.  , C2  1  CMUI  Some orthogonal multiple access schemes  For orthogonal multiple access schemes such as TDMA and FDMA, the time or frequency is shared among the users, and the capacity is inferior to that discussed above. Consider the two-user case with the received symbol energies Es,1 and Es,2, and assume that the two users obtain the portions α  0 < α < 1  and 1−α of the resource, respectively. For TDMA, the received powers for the two users are, respectively, Es,1  αT  and Es,2   1 − α T , and the noise power is N0B = N0 T for both the users, where T is the symbol period. For FDMA, the noise powers for the two users are, respectively, αBN0 and  1 − α BN0. Thus, the corresponding capacities are 1 + Es,1 αN0  , C2 =  1 − α  log2  C1 = α log2   1 − α N0   14.100   1 +   cid:2    cid:3    cid:2    cid:3   Es,2  .  The maximum capacity is given by  Cmax = C1 + C2.   14.101   This capacity reaches the maximum sum rate only at a few points, as shown in Fig. 14.13. In the downlink, a common BS transmits to many mobile users. Each user receives all the transmitted signals and extracts its desired one. Unlike the uplink case, where each user has its own power constraint, the total transmitted power is shared among the users. The individual rate Ru also needs to satisfy the constraint Ru ≤ Cu or Ru ≤ CMUI . The same strategy of successive detection of the uplink can be applied to the u downlink.      585   cid:2   14.8 Estimation theory  14.7.2 Flat-fading channels   cid:3   Es N0  In the ﬂat-fading uplink channel, simultaneous transmission with successive decoding still achieves capacity. Without CSI at the transmitter, the best strategy is that all users transmit with the same average signal power Es T, and then the ergodic maximum sum rate is given by [14]  9   cid:12    cid:13 :  Nu cid:26    cid:2   1 + Es N0  Cmax = E  Hu2  ≤ log2  1 + Nu  log2  u=1   14.102  where the upper bound is based on the assumption of E[Hu2] = 1 for u = 1, 2, . . . , Nu. For Rayleigh fading, the sum of the squares of the channel coefﬁcient magnitudes is χ 2- distributed with 2Nu degrees of freedom. The upper bound corresponds to the maximum sum rate for the AWGN uplink channel.  ,  We now consider the ﬂat-fading downlink channel. Without CSI at the transmit- ter, capacity can be achieved by superposition coding with successive decoding at the receiver, as in the case of the AWGN downlink case. If the common BS has CSI, the maximum throughput can be signiﬁcantly increased by using the multiuser diversity technique, which has been discussed in Section 5.4. The basic idea of mul- tiuser diversity is that only the user with the largest instantaneous channel gain hu k 2 transmits. The optimum solution is that the system distributes the power of each user onto its active time instances based on the water-ﬁlling principle. For i.i.d. channels, each user can transmit its power constraint.  the same average data rate and fulﬁll  The capacity regions of the MIMO broadcast channel and the MIMO MAC channel are discussed in [24]. The problem of ﬁnding the optimal transmitter covariance matrices that achieve the sum capacity in a Gaussian vector multiple-access channel is addressed in [26] by using an iterative water-ﬁlling algorithm. The capacities of MIMO channels for both single-user and multiuser systems are summarized in [8].  14.8 Estimation theory  Estimation theory is concerned with the problem of ﬁnding the optimum value for an unknown continuous variable, given a collection of measurements. The quality of esti- mation is determined by the accuracy of the measurements. The Cramer-Rao inequality is the most important information-theoretic inequality that pertains to estimation theory. It is a lower bound on the performance of an estimator, known as the Cramer-Rao lower bound  CRLB . Assume c =  c1, . . . , cm  to be an unknown vector that is to be estimated, and the measurement x to be a random variable vector. The vector estimator is given by its mean vector and covariance matrix   cid:19 ˆc   cid:20  = E   cid:20    cid:19 ˆc x   ,  E   14.103       586   cid:2   Fundamentals of information theory   cid:7 ˆc   cid:8  = E   cid:22  cid:7 ˆc x  − E   cid:7 ˆc   cid:8  cid:8  cid:7 ˆc x  − E   cid:8  cid:8 T   cid:7 ˆc   cid:23   .   cid:17    14.104    14.105    14.106    14.107    14.108    14.109    14.111   where l = ln p xc  is the log-likelihood function. The elements are given by  For estimation problems, the variance of the estimates of the unknown parameters is subject to the CRLB for any estimator [3]. Theorem 14.6  Cramer-Rao Lower Bound : For any unbiased estimator ˆc, E[ˆc] = c0, its covariance matrix  cid:17  c  satisﬁes  i.e.,   cid:17  c  ≥ J  −1 c ,  wT  cid:17 w ≥ wTJ  −1w,  for any w,  where J is the Fisher information matrix, deﬁned below. Let p xc  denote the joint pdf of x conditioned on the unknown vector c  The Fisher information matrix J c  is an m × m matrix, and is deﬁned by  p xc  = p  x1, . . . , xnc1, . . . , cm  .   cid:3  cid:2   cid:5   ∂l ∂c  9 cid:2  J c  = E  cid:14  ∞ −∞ p xc   cid:22   cid:23   cid:20  ≥   cid:19 ˆci  −1 J  Jij c  =  : cid:4  cid:4  cid:4  cid:4  cid:4    cid:3 T  cid:6  cid:5   ,  c0   cid:6   ∂l ∂c  ∂l ∂ci  ∂l ∂cj  dx.  i = 1, 2, . . . , m.  cid:3   Jij = 1 2  tr  −1 R  −1 R  ∂R ∂ci  ∂R ∂cj  ,  For the parameter ci, we may write   14.110  For a zero-mean Gaussian vector x t , the measurement error e = x − E[x] is also Gaussian with zero mean, and the Fisher information matrix can be derived as  var  ii  ,   cid:2   where tr is the trace operator for a matrix and R is the covariance matrix of x. The CRLB is generally evaluated numerically, since analytical inversion of R is intractable, except for the case of each signal being stationary.  In wireless communications, CRLB sets the lower bounds for the estimation of  parameters such as the channel, position, delay of multipath, and signal direction.  Problems  14.1 A random variable has the distribution P X = k  = p 1 − p k−1, k = 1, 2, 3, . . .. What is the entropy of X? 14.2 Prove that I X; Y  = H X  + H Y  − H X, Y .      587   cid:2   Problems  14.3 Show that the entropy of an n-dimensional Gaussian vector X =  x1, . . . , xn T with zero mean and covariance matrix M is H X  = 1 14.4 Which of the following are uniquely decodeable?  a  {0, 10, 11}.  b  {0, 01, 11}.  c  {0, 01, 10}.  d  {110, 11, 10}.  e  {0, 01}.  g {110, 100, 00, 10}. Apply the Kraft-McMillan inequality to these codes.  2 log2 2πe nM.  14.5 Is it possible for the following codes to be Huffman codes?  a  {00, 01, 10, 110}.  b  {10, 01}. 14.6 A DMS has an alphabet of eight letters, Xi, i = 1, 2, . . . , 8, with probabilities of 0.15, 0.10, 0.35, 0.10, 0.14, 0.06, 0.03, and 0.07. Encode the source using Huffman coding. Compare the average number of bits per letter with the entropy of the source. 14.7 For a random variable X with an alphabet of seven letters, with probabilities of 1 28 , 2 28 , 3 28 , ﬁnd  a  the binary Huffman codes and their average length,  b  the ternary Huffman codes and their average length. 14.8 Given the binary source {0, 1} with p0 = 0.125 and p1 = 0.875, encode the sequence 11110111011110 using arithmetic coding.  28 , and 7  28 , 4  28 , 6  28 , 5  14.9 Prove that the capacity C of a discrete memoryless channel with input alpha- bet X = {X1, X2, . . . , XN} and output alphabet Y = {Y1, Y2, . . . , YM} satisﬁes C ≤ min{log2 M, log2 N}. 14.10 Use the sliding window version of the Lempel-Ziv algorithm with a window size of 10 to parse and encode the binary sequence 1011001110 0111010110 0100110011 11001101011 10000010000. What is the encoder output as a binary sequence? Decode the encoded sequence.  14.11 Use the LZ78 algorithm to solve the above problem.  14.12 Determine the capacity of the channel illustrated in Fig. 14.14.  0.5p  1−p  x1  x2  x3  1−p 0.5p  p p  1−p  y1  y2  y3  Figure for Problem 14.12.   cid:2 Figure 14.14  14.13 If the SNR of a wireless channel is 10 dB and the RF bandwidth is 30 kHz, deter- mine the theoretical maximum data rate that can be supported. If the RF bandwidth is 200 kHz, what is the result?  14.14 Compare the channel spectral efﬁciencies of IS-54, GSM, PDC, and IS-95. What are their theoretical spectral efﬁciencies at a SNR of 20 dB?      588   cid:2   Fundamentals of information theory  14.15 A receiver has a received signal power of −110 dBm, a received noise power spec- tral density of −160 dBm Hz, and a bandwidth of 2000 Hz. Determine the maximum rate of error-free information transfer for this system.  14.16 Plot on the same ﬁgure the capacities of an AWGN channel with binary antipo- dal signaling and binary orthogonal signaling as a function of Eb N0. Optimal bit-by-bit detection is assumed at the receiver.  14.17 For any concave function f and a random variable x, establish Jensen’s inequality  E[f  x ] ≤ f  E[x] .  [Hint: geometrical analysis can be applied.] 14.18 For an additive noise channel, Y = X + Z, where the noise Z is independent of X, Pr Z = 0  = Pr Z = a  = 1 14.19 Consider a zero-mean complex random vector x with ﬁxed covariance E[xx∗ Show that the differential entropy satisﬁes  2 , and X takes 0 or 1, derive the channel capacity.  ] = K.  h x  ≤ log2 det πeK   with equality when x is a complex Gaussian distribution with zero mean and covariance K. 14.20 Evaluate the differential entropy h X  for the exponential density pX x  = λe −λx, x ≥ 0. 14.21 Consider a pair of parallel Gaussian channels   cid:7   Yi = Xi + Zi,  i = 1, 2,   cid:8  ≤ 2P. According to water-ﬁlling, at what power does the channel  2 . There is a power  i , and σ 2 1  > σ 2  where Zi’s are zero-mean AWGNs with variance σ 2 constraint E transfer from one channel mode with noise variance σ 2  + X2  X2 1  2  2 to two-channel mode?  14.22 Derive the rate-distortion function given by  14.40 . 14.23 Derive and plot the capacity for square-MQAM signaling with M = L2, L = 2, 4, 8, 16, in the AWGN channel. The reader can use the MATLAB code for Exam- ple 14.11, which is available at the website for this book. Like MPSK, the capacity of MQAM at high SNR is log2 M bits s Hz. Note that MQAM signaling approaches the channel capacity log2 M at a lower SNR compared to MPSK signaling. 14.24 Plot the capacity with BPSK, QPSK, and 8PSK modulation schemes, over an ergodic Rayleigh ﬂat-fading channel, as a function of the average SNR.  14.25 Consider a sequence of i.i.d. measurements x1, x2, . . ., xn of a Rayleigh-distributed random variable with parameter f .  a  Determine the CRLB.   cid:24    b  Consider the estimator ˆf = 1  N k=1 x2  2N  k. Determine its variance and check if it achieves  the CRLB.      589   cid:2   References  References  [1] M.-S. Alouini & A. J. Goldsmith, Area spectral efﬁciency of cellular mobile radio  systems. IEEE Trans. Veh. Tech., 48:4  1999 , 1047–1066.  [2] M. H. N. Costa, Writing on dirty paper. IEEE Trans. Inf. Theory, 29:3  1983 ,  [3] T. M. Cover & J. A. Thomas, Elements of Information Theory, 2nd edn  Hoboken,  439–441.  NJ: Wiley, 2006 .  [4] T. M. Cover & M. Chiang, Duality between channel capacity and rate distortion with  two-sided state information. IEEE Trans. Inf. Theory, 48:6  2002 , 1629–1638.  [5] J. R. Deller, Jr., J. H. L. Hansen & J. G. Proakis, Discrete-Time Processing of Speech  Signals  New York: Wiley-IEEE, 2000 .  [6] U. Erez, S. Shamai & R. Zamir, Capacity and lattice strategies for cancelling known  interference. In Proc. IEEE ISITA, Honolulu, HI, Nov 2000, 681–684.  [7] M. Ghanbari, Standard Codecs: Image Compression to Advanced Video Coding   London: IEE Press, 2003 .  [8] A. Goldsmith, S. A. Jafar, N. Jindal & S. Vishwanath, Capacity limits of MIMO  channels. IEEE J. Sel. Areas Commun., 21:5  2003 , 684–702.  [9] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [10] A. J. Goldsmith & S.-G. Chua, Variable-rate variable-power MQAM for fading  channels. IEEE Trans. Commun., 45:10  1997 , 1218–1230.  [11] A. J. Goldsmith & M. Effros, Joint design of ﬁxed-rate source codes and multiresolu-  tion channel codes. IEEE Trans. Commun., 46:10  1998 , 1301–1312.  [12] S. W. Golomb, Run-length encoding. IEEE Trans. Inf. Theory, 12:3  1966 , 399–401. [13] D. A. Huffman, A method for the construction of minimum redundancy codes. Proc.  IRE, 40:9  1952 , 1098–1101.  [14] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [15] G. G. Langdon, An introduction to arithmetic coding. IBM J. Res. Dev., 28:2  1984 ,  135–149.  [16] S. Lonardi, W. Szpankowski & M. D. Ward, Error resilient LZ’77 data compres- sion: algorithms, analysis, and experiments. IEEE Trans. Inf. Theory, 53:5  2007 , 1799–1813.  [17] M. Nelson, The Data Compression Book  New York: M&T Books, 1992 . [18] J. G. Proakis & M. Salehi, Digital Communications, 5th edn  New York: McGraw-  [19] J. J. Rissanen, Generalized Kraft inequality and arithmetic coding. IBM J. Res. Dev.,  [20] K. Sayood, Introduction to Data Compression, 2nd edn  San Mateo, CA: Morgan  [21] C. E. Shannon, A mathematical theory of communication. Bell Syst. Tech. J., 27  Hill, 2008 .  20:3  1976 , 198–203.  Kaufmann, 2000 .   1948 , 379–423, 623–656.      590   cid:2   Fundamentals of information theory  [22] C. E. Shannon, Coding theorems for a discrete source with a ﬁdelity criterion. In Proc.  IRE National Convention Record, New York, Mar 1959, part 4, 142–163.  [23] J. Teuhola, A compression method for clustered bitvectors. Inf. Process. Lett., 7:6   1978 , 308–311.  [24] S. Viswanath, N. Jindal & A. Goldsmith, Duality, achievable rates, and sum-rate capacity of Gaussian MIMO broadcast channels. IEEE Trans. Inf. Theory, 49:10  2003 , 2658–2668.  [25] T. A. Welch, A technique for high-performance data compression. IEEE Computer,  17:6  1984 , 8–19.  [26] W. Yu, W. Rhee, S. Boyd & J. M. Ciofﬁ, Iterative water-ﬁlling for Gaussian vector  multiple-access channels. IEEE Trans. Inf. Theory, 52:1  2004 , 145–152.  [27] W. Yu & J. M. Ciofﬁ, Constant-power waterﬁlling: performance bound and low-  complexity implementation. IEEE Trans. Commun., 54:1  2006 , 23–28.  [28] J. Ziv & A. Lempel, Compression of individual sequences via variable-rate coding.  IEEE Trans. Inf. Theory, 24:5  1978 , 530–536.  [29] J. Ziv, The universal LZ77 compression algorithm is essentially optimal for individual  ﬁnite-length N-blocks. IEEE Trans. Inf. Theory, 55:5  2009 , 1941–1944.      15  Channel coding  15.1 Preliminaries  A channel is an abstract model describing how the received  or retrieved  data is associ- ated with the transmitted  or stored  data. Channel coding starts with Claude Shannon’s mathematical theory of communication [63].  Error detection correction coding  Channel coding can be either error detection coding or error correction coding. When only error detection coding is employed, the receiver can request a transmission repeat, and this technique is known as automatic repeat request  ARQ . This requires two-way communi- cations. An ARQ system requires a code with good error-detecting capability so that the probability of an undetected error is very small.  Forward error correction  FEC  coding allows errors to be corrected based on the received information, and it is more important for achieving highly reliable communica- tions at rates approaching channel capacity. For example, by turbo coding, an uncoded BER −6 after turbo decoding. For applications that of 10 use simplex  one-way  channels, FEC coding must be supported since the receiver must detect and correct errors, and no reverse channel is available for retransmission requests.  −3 corresponds to a coded BER of 10  Another method using error detection coding is error concealment. This method pro- cesses data in such a way that the effect of errors is minimized. Error concealment is especially useful for applications that carry data for subjective appreciation, such as speech, music, image, and video. Loss of a part of the data is acceptable, since there is still some inherent redundancy in the data. Interpolation or extrapolation can be used to generate values to replace the values with errors. Error concealment is usually used when ARQ is difﬁcult or impossible; for example, in speech application, the vocoder only generates output speech, but no feedback is available. Hybrid with FEC is also possible.  From the viewpoint of implementation, ARQ is simple and provides higher system reli- ability than FEC. However, its throughput drops rapidly with increasing channel error rate. FEC systems have a constant throughput, but the probability of a decoding error is much higher than the probability of an undetected error in ARQ systems. To achieve high relia- bility, a long powerful code has to be used, leading to expensive decoding. For this reason, ARQ is preferred for error control in data communication systems, while FEC is the only choice in voice communication or data storage systems, where the return channel is not available, or the delay is intolerable, or retransmission is not possible. Hybrids of ARQ      592   cid:2   Channel coding  and FEC combine the advantages of both methods, and are known as HARQ, which will be introduced in Section 15.12.  Block and convolutional codes  Channel codes are traditionally classiﬁed into block codes and convolutional codes. For block codes, redundancy is added to blocks of data, while for convolutional codes redundancy is added continuously. For an  n, k  or  n, k, d  block code, each codeword has a length of n bits, where the ﬁrst k bits are the information bits and the following n− k bits are redundant parity bits generated from the k information bits by an algebraic relation, and d is the minimum Hamming distance of the code. The ratio Rc = k n is known as the code rate, and 0 < Rc ≤ 1. The encoder is memoryless, and can be implemented with a combinatorial logic circuit.  Convolutional codes are generated by the discrete-time convolution of the informa- tion bit sequence with the impulse response of the encoder. The duration of the impulse response is characterized by the memory of the encoder. Thus, the convolutional encoder generates a continuous sequence of coded bits from a continuous sequence of input bits. The encoder accepts k-bit blocks of input information sequence and produces an encoded sequence of n-bit blocks. Each encoded block depends not only on the k-bit input block but also on m previous message blocks. The encoder thus has a memory order of m. The code obtained is an  n, k, m  convolutional code. The code rate is given by Rc = k n. Since the encoder has memory, it must be implemented by using a sequential logic circuit.  Finite ﬁelds  A ﬁeld F is a set of elements that is closed under two binary operations, namely, addition and multiplication. A ﬁeld having a ﬁnite number of elements is called a ﬁnite ﬁeld or Galois ﬁeld. A ﬁnite ﬁeld of q elements is denoted by GF q , with the number of elements deﬁned as q = pm, where p is a prime number and m is a positive integer. The most common ﬁnite ﬁeld is the set {0, 1} under the operations of standard modulo-2 addition and multiplication.  15.2 Linear block codes  Linear block codes have the property that the modulo-2 addition of any two codewords must be a codeword and the all-zeros word is also a permitted codeword. Block coding is widely used for error detection correction in data storage systems and communication systems.  Linear block coding has a general coding equation  c = mG,   15.1       593   cid:2   15.2 Linear block codes  where the coded message c = [c1c2 . . . cn], the message word m = [m1m2 . . . mk], and G is the k × n generator matrix. Entries of c, m, and G are elements belonging to GF p , where GF p  is the ﬁnite ﬁeld of the integers modulo a prime p. For the common binary code, GF 2  = {0, 1}. The  n, k  block code is generated by encoding k information digits and outputting an n-digits codeword, which is composed of the k information digits and  n − k  redundant parity check digits. The rate, or efﬁciency, of the code is Rc = k n. Normally Rc is between 1 2 and 1. In many cases, the ﬁrst k bits of the coded message c remain the same as the message word, and the remaining n− k bits are used as parity bits. Such codes are called systematic codes. This can be expressed by setting  where Ik is a k × k identity matrix and P is a k ×  n − k  matrix. To decide whether the received codeword ˆc is valid, it is multiplied by a parity check matrix H. This yields an  n − k -dimensional syndrome vector ssyn   15.3  The entries of ssyn correspond to the n − k parity bits. If ssyn is a zero vector, the received codeword is valid.  G = [IkP] ,  ssyn = ˆcHT.   15.2   The selection of H must retain the relationship HGT = O,  where H is an  n − k  × k matrix. It is equivalent to cHT = 0. One simple solution is  H = cid:19 −PT In−k   cid:20   .  For binary codes, the minus sign can be dropped since modulo-2 subtraction is identical to modulo-2 addition. Since cHT = 0, the syndrome only depends on the error word e. This is given by   15.4    15.5    15.6   ssyn = ˆcHT =  e + c HT = eHT  A nonzero syndrome identiﬁes an error. The syndrome digits are simply linear combina- tions of the error digits.  The popularity of linear block codes may be due to the algebraic decoding methods. , with dmin being the minimum distance  They can be decoded at a complexity of O of the code, by using ﬁnite-ﬁeld arithmetic which is efﬁcient in VLSI implementation.  d2 min   cid:7    cid:8   15.2.1 Error detection correction  The Hamming weight of a block codeword c of length n, denoted w c , is deﬁned as the number of nonzero elements of the code.  The Hamming distance between two codewords c1 and c2, denoted d  c1, c2 , is deﬁned  as the number of places where they differ.      594   cid:2   Channel coding  The minimum distance of a block code C, denoted dmin, is deﬁned as  4   cid:4  cid:4 c1, c2 ∈ C, c1  cid:18 = c2  5  .  dmin = min  d  c1, c2    15.7   The Hamming distance is related to the Hamming weight by  d  c1, c2  = w  c1 + c2  .   15.8  For example, the Hamming distance between c1 =  11001010101  and c2 =  01111001010  is 8, which is equal to the weight of c1 + c2 =  10110011111 , that is 8. For linear block codes, the sum of two codewords is also a codeword. Thus, it follows  from  15.7  that  dmin = min{d c c ∈ C, c  cid:18 = 0} = wmin.   15.9   Thus, the minimum distance of a linear block code equals the minimum weight of its nonzero code words. For linear block codes, there are a number of bounds on dmin, such as the Hamming or sphere packing bound, and the Plotkin bound. These bounds are described in [56]. A block code with minimum distance dmin is capable of detecting all the error patterns of dmin − 1 or fewer errors, or guaranteeing the correction of all the error pat- terns of  cid:24  dmin − 1   2 cid:25  or fewer errors. That is, the error-detection capability ted and error-correction capability tec are determined by [47, 66]   15.10   ,  2   15.11  where  cid:24 · cid:25  rounds down the number to an integer. For all Hamming codes, dmin = 3 and tec = 1. Thus one error in each codeword can be corrected. A block code with random error correcting capability tec is usually capable of correcting many error patterns of tec + 1 or more errors. For an  n, k  linear code, it is capable of correcting a total of 2n−k error patterns, including those with tec or fewer errors; however, it is capable of detecting 2n − 2k error patterns [47]. For large n, 2n−k  cid:5  2n − 2k. The upper bound on the average probability of an undetected error for an  n, k  linear  systematic code over a BSC is given as [47]  Pu,E ≤ 2  − n−k   1 −  1 − p n  − n−k ,   15.12    cid:19    cid:20  ≤ 2  where p is the transition probability of the BSC. Thus, Pu,E decreases exponentially with the number of parity-check digits, n − k. If a binary linear block code  n, k, dmin  is able to correct to tec errors, each possible error pattern needs to be assigned a unique syndrome. The following Hamming bound is obtained:  @ A ted = dmin − 1, dmin − 1 tec =   cid:2   2n−k ≥ tec cid:26   r=0  n r   cid:3   .   15.13   The left-hand side is the number of syndromes, and the right-hand side is the number of error patterns with w e  ≤ tec. When equality holds, the code is called a perfect code.      595   cid:2   15.2 Linear block codes  15.2.2 Simple parity check and Hamming codes  Simple parity check codes  The most simple channel coding is parity checking. The simple parity check code is a linear block code. It performs mod-2 addition of all bits in a block, and appends the result as parity bit to the end of the frame. For a length n codeword, there is k = n−1 information bits, and thus Rc =  n − 1  n. In case of even parity, when the code word contains an even number of ones, the parity bit is zero; in case of odd parity, when the code word contains an odd number of ones, the parity bit is zero. For even-parity condition, the parity bit p is formed as p = c1 ⊕ c2 ⊕ ··· ⊕ cn. At the receiver, the parity bit is recalculated to decide whether the correct data is received. This method can only detect an odd number of bit errors, but cannot detect the errors in case of an even number of bit errors. The minimum Hamming weight is 2, which is also the code’s minimum distance, dmin. Thus, the code is a  n, n − 1, 2  code. The single parity bit can only be used for error detection, most notably in the 8-bit ASCII codes. By using more parity bits, one can also estimate the position of the bit errors. This can be performed by arranging the codeword into a two-dimensional array, and then apply- ing parity for each row and for each column. The resulting parity bits are then appended to the end of the codeword. The received codeword will be mapped to the same two- dimensional array, and the parity bits are examined at each column and each row. For a single bit error, the intersection of the row and column corresponding to the parity failure is the error position, and it thus can be corrected.  Hamming codes  One special and well-known class of linear codes is the Hamming codes [36]. It was invented shortly after the channel-coding theorem was published in 1948. For such codes, the columns of H contain all 2n−k possible bit combinations of length k  except the all-zero word . The resulting Hamming code has a size of  2m − 1, 2m − 1 − m , for m = 2, 3,··· . There are m redundant bits in the code. Its minimum distance is 3. The Hamming codes are a class of single-error-correcting perfect code, since they correct all single errors but no patterns of more than one error. An  n, k  linear code can be extended by adding an overall parity-check bit. This is known as an extended  n + 1, k  code. The parity-check bit is added so as to give even parity codewords, as this preserves the linearity of the code. The extended Hamming code has a minimum distance of 4.  Example 15.1: Given the parity check matrix  ⎡⎣ 1 1 1 0 1 0 0  1 1 0 1 0 1 0 1 0 1 1 0 0 1  ⎤⎦ ,  H =  verify that the corresponding block code is a Hamming code.   15.14       596   cid:2   The code can be easily veriﬁed to be a  7, 4  Hamming code. This can be solved by ﬁrst  obtaining the generator matrix G from H, from  15.2  and  15.5 , as  Channel coding  ⎡⎢⎢⎣ 1 0 0 0 1 1 1  0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1  ⎤⎥⎥⎦ .  G =   15.15   We can then obtain altogether 16 codewords from 16 messages of length 4, start- ing from all-zeros message to all-ones message, by using c = mG. The minimum distance of the 16 codewords in c is calculated as 3, by using the MATLAB code Example_Hamming_Code.m.  A more powerful linear block coding scheme is cyclic redundancy check  CRC  coding,  which will be introduced in Section 15.4.  15.2.3 Syndrome decoding  The decoding of the block code is to ﬁnd a code that is closest to the transmitted codeword. Syndrome decoding, also called table-lookup decoding, can be used for any linear block code. This leads to minimum decoding delay and minimum error probability. The method calculates the syndrome ssyn = ˆcHT, then ﬁnding the error pattern that has the same syn- drome. The decoded result is given by c = ˆc + e. For large n − k, this decoding scheme is too complex to implement, since it needs either a large storage for the table or a complex combinatorial logic. From  15.6 , given a syndrome, there are 2n−k distinct error patterns. Only the error pattern that has the smallest number of nonzero components is the most probable one. The lookup table is obtained as the truth table of n switching functions  ei = fi  s0, s1, . . . , sn−k−1  ,  i = 0, 1, . . . , n − 1,   15.16  where s0, s1, . . . , sn−k−1 are the syndrome digits. This table can be implemented using a combinatorial logic with n − k syndrome digits as inputs and n outputs as the estimated error pattern.  Example 15.2: For the  7,4  Hamming code, given message m =  1100 , the generated codeword is c =  1100001 . The received codeword is ˆc =  1100011 , show the procedure of error correction. First, the syndrome is computed as s = ˆcHT =  010 , where H is given by  15.14 .  Then, from s = eHT, we have ⎧⎨⎩e0 + e1 + e2 + e4 = 0  e0 + e1 + e3 + e5 = 1 e0 + e2 + e3 + e6 = 0  .   15.17       597   cid:2   15.3 Hard soft decision decoding  Table 15.1. The lookup table for syndromes and correctable error patterns.  s0  0 1 0 0 1 0 1 1  s1  0 0 1 0 1 1 1 0  s2  0 0 0 1 0 1 1 1  e0  e1  e2  e3  e4  e5  e6  0 0 0 0 0 0 0 1  0 0 0 0 0 0 1 0  0 0 0 0 0 1 0 0  0 0 0 0 1 0 0 0  0 0 0 1 0 0 0 0  0 0 1 0 0 0 0 0  0 1 0 0 0 0 0 0  There are a total of 24 = 16 error patterns satisfying the above equations:   0000010 ,  0001001 ,  0010111 ,  0011100   0100100 ,  0101111 ,  0110001 ,  0111010   1000101 ,  1001110 ,  1010010 ,  1011011   1100011 ,  1101000 ,  1110110 ,  1111101 .  The error pattern e =  0000010  has the smallest number of nonzero digits, and is the most possible error pattern. It is selected as the lookup table item for syndrome  010 . The decoded codeword is obtained as  ∗ = ˆc + e =  1100011  +  0000010  =  1100001 ,  c   15.18   which is exactly the transmitted codeword.  A lookup table  LUT  for all the correctable error patterns for the  7,4  Hamming code can be obtained for all the syndromes. The result is listed in Table 15.1. From this truth table, the error pattern can be obtained from the syndrome by a simple logic circuit, and a decoding circuit can be accordingly designed. From this table, we can see that Hamming codes can correct only the error patterns of single errors and no others. For a Hamming code, all the columns in H are linearly independent; it can correct exactly one error and the location of the error is given by the syndrome.  15.3 Hard soft decision decoding  Decoding takes place by either hard decision or soft decision. In case of soft decision, the channel output is used directly without quantization, while in hard decision an optimal decision is based on each input level. As a hard decision, the decoder makes a decision on a rigid condition. Soft decoding can achieve better performance, but at a much greater complexity. For binary coding, if the demodulator output uses binary quantization, Q = 2,      598   cid:2   Channel coding  the decoder is said to make hard decisions; if the quantization level Q > 2 or the output is unquantized, the demodulator will make soft decisions.  For a given power, the encoder produces more bits compared to the uncoded case, this results in a reduction in Eb, and thus the coded bitstream has a larger BER. This is com- pensated by the coding gain. When Pe = 10 −5 and hard decision decoding is employed, the coding gain is 3 to 5 dB for block codes, 4 to 5.5 dB for convolutional codes with Viterbi decoding, and 6.5 to 7.5 dB for concatenated codes of Reed-Solomon block codes and convolutional code using Viterbi decoding [70].  Hard decision decoding  Hard decision decoding uses the minimum distance decoding that detects or corrects errors based on the Hamming distance. For an  n, k  block code, if the error correction capability is tec errors, under hard decision decoding, a received codeword may be decoded in error if it contains more than tec errors.  Assuming the bit errors occur independently on an AWGN channel, for a linear block  code, the probability of codeword error is upper bounded by  pi 1 − p n−i,   15.19    cid:2   n i  Pe ≤ n cid:26   cid:7 √  i=tec+1   cid:3   cid:8   βMEc N0  where p is the error probability of the bit transmission in the codeword. For coherent modulation, typically p = αMQ , where Ec is the energy per codeword symbol. For  n, k  block codes, there are k information bits, thus Ec = kEb n. Thus block codes with a large number of parity bits  k n is small  have a small Ec, leading to an increase in the error probability. This loss in the error probability is, however, compensated by the error correction capability of the codes. At high SNR, coding yields a coding gain. At low SNR, coding yields a higher error probability than uncoded modulation does, leading to a negative coding gain. This is due to reduced energy per symbol.  At high SNR, the codeword error probability can be approximated by the nearest- neighbor errors. For a given nearest neighbor at distance dmin, a simple upper bound is given by [31, 56]  Pe ≤  M − 1 [4p 1 − p ]dmin 2,   15.20   where M = 2k is the number of codewords. The BEP after decoding depends on the speciﬁc code, decoder, and the bit-to-codeword mapping. The BEP for block codes using hard decision decoding in the AWGN channel is  cid:2  often approximated by [31]   cid:3   n cid:26   Pe ≈ 1 n  i  i=tec+1  n i  pi 1 − p n−i.   15.21       599   cid:2   15.3 Hard soft decision decoding  The probability of correct decoding, Pc, is given by the probability of no errors occurring, that is, Pc =  1 − p n. The probability of decoding failure is thus  Pf = 1 − Pe − Pc.   15.22   Soft decision decoding  Soft decisions may be made depending on the actual conditions such as SNR. A soft deci- sion can be regarded as a hard decision plus a measure of conﬁdence. The coding gain provided by an error-correcting code to a system can be deﬁned as the reduction, which can be realized due to the code, in the required Eb N0 for a given BEP.  Coding gain obtained using soft decision decoding depends on the code rate, Rc, the number of information bits per codeword, the minimum distance of the code, dmin, and the channel SNR, Eb N0. In soft decision decoding, the decoding is based on the minimum Euclidean distance, dE, between the received signal and the signal corresponding to the codeword. The codeword-error is upper-bounded by dE√ 2N0  Pe ≤  M − 1 Q   15.23    cid:3    cid:2   ,  where N0 is the one-side noise-power spectral density, and   15.24  with c0 = 1 for orthogonal signaling and c0 = 2 for antipodal signaling, and E the energy per bit of the codewords. The energy per information bit, Eb, is given by  c0dminE,  dE = cid:25   Thus,  = E Rc  .  Eb = nE  cid:12   k  Pe ≤  M − 1 Q  c0dminRcEb  2N0   cid:13   .   15.25    15.26   The Viterbi algorithm, as a decoding algorithm for convolutional codes, implements soft decision decoding using the trellis diagram [76]. The trellis diagram as well as the Viterbi algorithm can also be applied to the decoding of block codes [78]. For an AWGN channel, decoders using soft decisions can typically improve coding gain by about 2 dB compared to hard-decision decoders [47, 56, 66].  Example 15.3: The codeword error probability for hard and soft decoding of a  7, 4  Hamming code is shown in Fig. 15.1, which is based on  15.20  and  15.26 . As expected, the bipolar scheme has a 3-dB SNR advantage over the orthogonal binary mod- ulated scheme. The upper bound for soft decoding is slightly lower than that for hard decoding.      600   cid:2   Channel coding  Bipolar, HD Orthogonal, HD Bipolar, SD Orthogonal, SD  e P  100  10–2  10–4  10–6  6   cid:2 Figure 15.1  The codeword error probability for binary modulated  7,4  Hamming codes, hard and soft decoding.  8  10  14  16  18  12 b  dB   γ  15.4 Cyclic codes  Cyclic codes, also called CRC codes, are a special class of linear block codes. Cyclic codes are based on a cyclic algebraic structure. An  n, k  linear block code C is called a cyclic code if every cyclic shift of a codeword in C is also a codeword in C. All codewords can be obtained from a single codeword by shifting and addition. For cyclic codes, data encoding and error detection can be efﬁciently performed by means of a shift register. The location of errors can also be easily found.  Extra bits are appended to each frame. At the receiver, the CRC bits are recalculated and compared with that in the codeword. The cyclic code is popular due to its effectiveness in error protection, low overhead and ease of implementation due to the efﬁcient encoding and decoding algorithms.  15.4.1 Encoder and decoder   cid:19   Encoder   cid:20   The codeword can be generated using a code polynomial in a dummy variable x. This representation has the advantage that cyclic shifts may be expressed as multiplication by x. A k-bit message,  , can be represented by a polynomial of order k − 1  mk−1 ··· m1 m0  m x  = mk−1xk−1 + ··· + m1x + m0.  m x  is then multiplied, or left bit shifted, by the order of the generator polynomial g x , namely n − k. The extended version of m x  is divided by g x ,   15.27    15.28   xn−km x  mod g x       601   cid:2   15.4 Cyclic codes  gn−k−1  g2  g1  r1  r0  Codeword c x    rn−k−1  Message m x    Parity-check digits   cid:2 Figure 15.2  The encoding circuit for an  n, k  cyclic code.  and the remainder r x  appended to the original m x  to obtain the codeword as  c x  = xn−km x  + r x .   15.29   There exist circuits for performing polynomial multiplication and division [47, 56]. The encoded codeword is in a systematic form, where the leftmost k digits are the orig- inal information digits and the rightmost n − k digits are the parity-check digits. The encoding circuit is shown in Fig. 15.2. The circuit is operated as follows.   First, turn on the switches at the position in the ﬁgure and shift the k information bits into the circuit and simultaneously into the channel.   Then turn off the feedback connection and shift the parity-check bits rn−k−1,··· , r1, r0 out and send them into the channel.  Thus a complete codeword of n digits is formed. An encoding circuit can also be implemented using its parity polynomial h x  [47].  Encoding is traditionally implemented using shift registers and logic circuits. It can also be very easily implemented by using DSP, where the shift operations can be implemented as FIR and IIR ﬁlters.  Example 15.4: Given the generator polynomial g x  = x3 + x2 + x + 1, the message  cid:18  m x  = x3 + x + 1, then the extended version m x  is divided by g x   x3   cid:18    cid:17   x3 + x + 1   cid:17   cid:8  = x6 + x4 + x3 + x, or 1011010.  mod   15.30  By long division of polynomials, we have the remainder x and the quotient x3 + x2 + x. Note that for modulo-2 operation −x mod 2 = x mod 2. Thus the encoded message is x + x3  x3 + x + 1   cid:7   x3 + x2 + x + 1  Generator polynomial  An  n, k  cyclic code is completely speciﬁed by the generator polynomial g x . The degree of g x  is equal to the number of parity-check digits of the code, n − k. The generator polynomial g x  is unique, and takes the form of      602   cid:2   Channel coding  g x  = xn−k + gn−k−1xn−k−1 + ··· + g1x + 1.   15.31   Every code polynomial is a multiple of g x , and every binary polynomial of degree n − 1 or less that is a multiple of g x  is a code polynomial [47]. g x  is a factor of xn + 1. On the other hand, if g x  is a factor of xn + 1, and has a degree of n − k, then it can generates an  n, k  cyclic code.  Decoder  Decoding of cyclic codes consists of the same three steps as for decoding linear codes. The linear property as well as the cyclic property also simpliﬁes the decoding of these codes.  On reception the received data is again divided by g x . If there is no error, the remainder is zero. If there is an error, the decoder can identify the position of the error digit via the remainder and the syndrome table.  As in the linear block codes, the syndrome depends only on the error, which can, in turn, be obtained from the syndrome  used as index  by using an LUT. For a cyclic code in sys- tematic form, the syndrome can be computed easily by using a division circuit composed of a shift circuit with feedback [47]. The division circuit has a complexity that is linearly proportional to the number of parity-check digits, n − k. The general-purpose cyclic code decoder is known as the Meggitt decoder [54]. For practical implementation of the Meggitt decoder, some restrictions are put on the error patterns to be corrected. Error-trapping decoding is a practical variant of the Meggitt decoder, and it can be implemented using a very simple combinatorial logic circuit for error detection and correction. Error-trapping decoding is most effective for decoding single-error-correcting codes and burst-error-correcting codes. The majority-logic decod- ing is also effective for certain classes of cyclic codes [51]. For more details, refer to [47]. An  n, k  cyclic code is capable of detecting any error burst of length n − k or less, including the end-around bursts. For bursts of length l = n − k + 1, the undetectable − n−k−1 , while for l > n − k + 1, the undetectable probability of probability is 2 − n−k  [47]. 2 A careful selection of the generator polynomial is necessary to ensure that all errors can be detected. A generator of order k allows detection of all burst errors affecting up to k consecutive bits. Two popular generator polynomials are g x  = x16 + x12 + x5 + 1   15.32   for wide area networks, and  for local area networks.  g x  = x32 + x26 + x23 + x22 + x16 + x12 + x11 + x10  + x8 + x7 + x5 + x4 + x2 + x + 1   15.33       603   cid:2   15.4 Cyclic codes  15.4.2 Types of cyclic codes   cid:19    cid:20   The simple parity check code is a cyclic code, since any cyclic shift of a codeword still leads to an even weight word, and thus is a codeword. The generator matrix is , and the generator polynomial is 1 + x. The Hamming code can be put in In−11n−1,1 cyclic form: The columns of the parity check matrix H can be arranged so that the resulting code is a cyclic code.  The Bose-Chaudhuri-Hocquenghem  BCH  code is a binary cyclic code. The nonbinary BCH code is a generalization of the binary BCH code to a code with pm symbols, where p is a prime number. The Reed-Solomon  RS  code is the most important subclass of the nonbinary cyclic code. Both the binary and nonbinary BCH codes are based on the theory of Galois ﬁelds.  Golay code  The  23, 12  Golay code [30] is another binary perfect code. It is capable of correcting any combination of three or fewer errors in a block of 23 digits. It has dmin = 7. The  23, 12  Golay code is used in the GSC paging system and deep space missions.  The  23, 12  Golay code is generated by either of the two generator polynomials  or  which are factors of x23 + 1,  g1 x  = x11 + x10 + x6 + x5 + x4 + x2 + 1  g2 x  = x11 + x9 + x7 + x6 + x5 + x + 1  x23 + 1 =  x + 1 g1 x g2 x .   15.34    15.35    15.36   The encoding can be implemented by an 11-stage shift register with feedback connections. To achieve its error-correcting capability, tec = 3, a reﬁned error-trapping scheme such as the Kasami decoder can be used [47]. The  23, 12  Golay code is often modiﬁed by adding a parity bit, making the extended  24, 12  Golay code. The extended code has dmin = 8, but it is not a perfect code. The extended code has a rate of 1 2 and has a performance slightly better than the original code. The performance of the Golay code is also upper-bounded by  15.19 .  BCH code  The BCH code can be treated as a generalization of the Hamming code for multiple-error correction, and the Hamming code is a special case of the BCH code, with tec = 1. It typically outperforms all other block codes of the same size  n, k  at moderate to high SNR, and can be designed to correct almost any required number of errors. The BCH code is used in the POCSAG, NEC, FLEX, and RDS paging standards, DVB-S2, AMPS, and PDC. For example, PDC selects rate-1 2 BCH as its channel coding technique, and FLEX uses BCH  32, 21  code with interleaving.      604   cid:2   Channel coding  For the BCH code, there is a large selection of n, Rc, and tec. For any positive integer m, m ≥ 3, and tec, tec < 2m−1, there exists a BCH code with n = 2m − 1, n − k ≤ mtec, and dmin ≥ 2tec + 1. The BCH code is capable of correcting any combination of tec or fewer errors in a block of n = 2m − 1 digits. The generator polynomial is speciﬁed in terms of its roots from the Galois ﬁeld GF  2m . Let α be a primitive element in the Galois ﬁeld GF  2m . The generator polynomial g x  is the lowest-degree polynomial over GF 2  for which α, α2, . . . , α2tec are the roots. Let φi x  be the minimum polynomial of αi. Then g x  is given as the least common multiple of φi x , i = 1, 2, . . . , 2tec  .  φ1 x , φ2 x , . . . , φ2tec x    15.37  Comprehensive tables for all the BCH codes of length 2m − 1 with m ≤ 10 are given in [47], listing n, k, dmin, and their generator polynomials. The coding gain of the BCH code is larger than that of the Hamming code, and it continues to increase with the code length, while the coding gain of the Hamming code rapidly tends to a limit as the code length increases. Decoding of BCH codes can be performed by using Berlekamp’s iterative algorithm [9] and Chien’s search algorithm [14].  4  g x  = LCM  5  Reed-Solomon code  The binary BCH code can be generalized into the nonbinary BCH code in a straightforward manner. For any s and tec, there exists a q-ary  q being any power of a prime number p  BCH code of length n = qs − 1 with no more than 2stec parity-check digits, which is capable of correcting any combination of tec or fewer errors. For q = 2, we get the binary BCH codes. The RS codes correspond to the nonbinary BCH codes in the case of s = 1. An  n, k, dmin  RS code maps k q-ary information symbols into n q-ary encoded symbols, and dmin is the minimum number of symbols that differ between codewords. Typically q = 2m, and thus the RS code is made of n symbols, each symbol being m bits long. For a tec-error-correcting RS code with symbols from GF q ,  n = q − 1,  n − k = 2tec,  dmin = 2tec + 1.   15.38   That is, the length of the code is one less than the size of code symbols, and the minimum distance is one greater than the number of parity-check digits. Given an RS code, its error correcting power is given by  tec = n − k  .  2   15.39   The RS codes have the best error-correcting capability among codes of the same length and dimension. RS codes are very effective for correcting burst errors, which typically occur at a fading dip. The RS code has a minimum distance of dmin = n − k + 1, which is the largest possible dmin for any linear code  n, k . The probability of codeword error is also upper bounded by      605   cid:2   15.4 Cyclic codes   15.19 , with p replaced by PM, the error probability associated with M-ary modulation. The probability of information symbol error can also be approximated by  15.21 , with Pb substituted by Ps and p by PM.  An RS code with code symbol from GF  2m  can correct tec or fewer m-bit bytes. Binary codes derived from the RS code are more effective against clustered errors than random errors, since clustered errors usually cause several errors per byte and accord- ingly relatively few byte errors. Such codes are capable of correcting any combination of [47]  λ =  tec  1 +  cid:24  l + m − 2  m cid:25    15.40  or fewer bursts of length l, or correcting any single burst of length  tec − 1  m + 1 or less. Simultaneously, it corrects any combination of tec or fewer random errors. Decod- ing of nonbinary BCH and RS codes can be performed by using Berlekamp’s iterative algorithm [9].  The RS code is used for data storage and retrieval on CDs  compact discs . It works at a symbol level, and is very effective against burst errors. Concatenated and cross-interleaved RS coding is used to handle random and burst errors. The RS code is also used in CDPD, DAB+, and DVB-C H.  Example 15.5: The BERs of a number of linear block codes, namely, Hamming  7, 4 ,  15, 11 ,  31, 26 ,  63, 57 , BCH  127, 64  with tec = 10, and RS  127, 106  with tec = 10,  cid:7 √ are calculated for coherent BPSK modulation, when hard decision is employed. The result is shown in Fig. 15.3. The simulation is based on  15.21 , where p = Q Q most of the coded cases at low SNR.  . Note that the BER performance of the uncoded cases is better than that of   cid:8  =   cid:7 √  2Ec N0  2Rcγb   cid:8   100  10–2  10–4  b P  Uncoded Hamming  7,4  Hamming  15,11  Hamming  31,26  Hamming  63,57  BCH  127,64 , t = 10 RS  127,106 , t = 10   cid:2 Figure 15.3  10–6  0  2  4  6 γb  dB   8  10  12  BER for different linear block codes.      606   cid:2   Channel coding  15.5 Interleaving  On many communication channels, errors occur as random errors as well as burst errors. Codes for random error correction are generally not efﬁcient for burst error correction. Interleaving is a most effective method for correcting random errors as well as single or multiple bursts.  Interleaving is a channel coding method that achieves time diversity. It effectively resists a deep fading or a noisy burst, and the successive digits are not corrupted at the same time. Block, convolutional, and coded modulation codes are designed for the AWGN channel. These codes are typically interleaved to mitigate the effect of error bursts. The interleaver reshufﬂes N continuous digits into N independent digits, and the respective BER perfor- mance can be easily explained by using the BER equation  7.141 . For an uncoded system, the interleaver breaks up the error bursts, but does not really lead to a reduction in the mean BER. The interleaver reduces the mean BER only for coded bitstreams that are then decoded.  The simplest interleaver is the block interleaver. By interleaving an  n, k  code with tec random error correcting capability to degree λ, a  λn, λk  code is obtained, which is capable of any combination of tec bursts of length λ or less. A sequence is divided into blocks of length Lπ . The symbols within each block are then permuted by writing them column-wise into a rectangular array of m rows and n columns, Lπ = m × n. If the bitstream is read into the block row-wise, it will be read out and transmitted column- wise, or vice versa. As a result, two adjacent bit errors are spaced by n  or m  symbols. The value of n  or m  should be selected to be sufﬁciently large so that the errors affect different codewords, and are corrected by their respective CRC bits independently. At the receiver, the de-interleaver stores the received data by sequentially increasing the row number of each successive digit, and then clocks out the data row-wise, one row at a time.  The interleaver should have a size that is large enough so that fading is independent across each received codeword. During transmission, symbols in the same codeword are separated by n − 1 symbols. If the separation in time is greater than the channel coherent time, Tc, that is, nT > Tc ≈ 1 BD, where T is the symbol duration and BD is the channel Doppler spread, the interleaver is called deep interleaver and the symbols in the same codeword are subject to independent fading.  For an  n, k  block code with soft decision decoding, the minimum Hamming distance of the code, dmin, provides the diversity order. For hard decoding, the diversity order is reduced by a factor of 2 relative to soft decision decoding. Thus, designs for block coding and interleaving should maximize the Hamming distance of the code. Random interleaving permutes the row and column indices randomly by modulo arithmetic, and it can be used to replace rectangular interleaving.  Both interleavers and deinterleavers have inherent delays since the operations have to be performed after all the Lπ symbols are received, and the interleaving delay is Lπ T. For voice communications, a tolerable maximum delay is 40 ms, and this must be consid- ered when designing wireless communications systems. However, for MSs, the typical      607   cid:2   15.6 Convolutional codes  fading dips are separated by a distance λ 4, which corresponds to a duration of up to 100 ms. If the maximum latency is smaller than the duration of fading dips, such as in the case of voice communications, the effectiveness of the interleaver is greatly reduced.  Interleaving has no inﬂuence in the case of nonfading or ﬁxed amplitude and phase. In contrast, FEC not only improves the performance of channels of ﬁxed amplitude and phase, but also that of fading channels. FEC also leads to a signiﬁcantly smaller time delay. Convolutional interleaving provides the same interleaving depth as block interleaving, but with lower delay and less memory.  15.6 Convolutional codes  Unlike block codes that are limited to codeword blocks, convolutional codes have a struc- ture that effectively extends over the entire transmitted bitstream. Convolutional coding requires a simple encoder consisting of a shift register and adders, and a sophisticated decoder. Convolutional codes are also linear codes, that is, the sum of any two codewords is another codeword and the all-zeros sequence is also a codeword. The convolutional encoding process can be viewed as delay-line binary FIRs.  For an  n, k, K  convolutional code, the convolutional encoder consists of a shift register with K stages of k bits and n linear modulo-2 addition functions for output, as shown in Fig. 15.4. For encoding, k bits are shifted into the encoder at a time, and an output of n bits is generated  k < n , leading to a code rate Rc = k n. The parameter K is known as the constraint length; it is the number of shifts through a ﬁnite state machine over which a single input data bit can inﬂuence the output bit. Typically, n and k are small integers, but K must be sufﬁciently large to achieve low error probability. When k = 1, the information sequence is processed continuously.  The best known code, prior to the turbo code, is the RS-Viterbi code, which is a combination of the RS block code and the Viterbi-decoded short constraint-length convo- lutional code. Convolutional coding is widely used in 2G and 3G mobile communications standards.  Stage 1  Stage 2  1  2  ...  k  1  2  ...  k  Stage K ...  2  1  k   cid:2 Figure 15.4  1 Encoded sequence  2  n  Schematic of the convolutional encoder.      608   cid:2   Channel coding  15.6.1 Encoding of convolutional codes  The structure of the convolutional encoder is shown in Fig. 15.4. The convolutional encoder is characterized by K-stage shift registers together with n modulo-2 adders and a mul- tiplexer for serializing the encoder outputs. The encoder is a linear feedforward shift register.  The convolutional encoder is a linear system. The n-bit encoder output can be obtained as the convolution of the input sequence a with the impulse responses of the n branches of the encoder. The impulse responses of the ith encoder branch for the jth input bit aj =  0, 0, 1,···   is denoted g i   . The impulse responses have a duration of at most K   cid:17   j  =  g i  j   cid:18   g i  j,0, g i   j,1, . . . , g i  j,K  ,  which are also known as generator sequences.  The encoding equations are given by  b l  = a ∗ g l  = k cid:26  a p  = cid:7   p=1  a p  ∗ g l  p ,  cid:8   where ∗ denotes discrete convolution and all operations are modulo-2, p = 1, 2, . . . , k,  cid:18   ap, ap+k, ap+2k, . . .   cid:17   ,  b l  =  b l  0 , b l   1 , b l   2 , . . .  .  The encoding equation can be written in matrix form as  l = 1, 2, . . . , n,  b = aG,  ⎤⎥⎥⎥⎦ ,  G =  ··· GK  ··· GK  G0 G1 G2  G0 G1 G2  ⎡⎢⎢⎢⎣ G0 G1 G2 ⎡⎢⎢⎢⎢⎣ g 1   Gl =  ... where Gl, l = 0, 1, . . . , K, is a k × n submatrix g 2  1,l g 2  2,l ... g 2  k,l  1,l g 1  2,l ... g 1  k,l  ··· GK ...  ⎤⎥⎥⎥⎥⎦ .  ··· ··· ... ···  g n  1,l g n  2,l ... g n  k,l  where G is called the generator matrix of the convolutional code, and all operations are modulo-2. For an  n, k, K  code, the generator matrix is given by   15.41    15.42    15.43    15.44    15.45    15.46    15.47   For a message a of length kL, G has kL rows and n K + L  columns and b has a length of n K + L .      609   cid:2   15.6 Convolutional codes   cid:2 Figure 15.5  A simple convolutional encoder, Rc = 1 2 and K = 3.  b 1   b 2   b   cid:18   a   cid:17   The codeword is a single sequence obtained as the multiplexing of the n output  sequences  b =  b 1  0 , b 2   0 , . . . , b n   0 , b 1   1 , b 2   1 , . . . , b n   1 , . . .  .   15.48   Example 15.6: For a simple convolutional encoder with Rc = 1 2 and K = 3, as shown in Fig. 15.5, derive the encoded sequence for an input data sequence a =  1000 . For this encoder, k = 1, K = 3, n = 2, and g 1  =  0, 1, 1, 1 ,  g 2  =  0, 1, 0, 1 .   15.49   For input sequence a =  1000 , we have  b 1  =  1000  ∗  0111  =  0111000 ,  b 2  =  1000  ∗  0101  =  0101000 .   15.50    15.51   By multiplexing the two subsequences, we can easily derive that the encoded sequence is  11101100 .  For convolutional coding, it is assumed that the encoder is initialized with the zero state and information bit sequences are padded with  K − 1 k zeros to bring back the convolu- tional encoder to the all-zeros state. If the input sequence has a length that is not a multiple of k, it is padded with zeros so as to get an input length of mk, m being a positive integer. The rate of the code is thus given as  Rc =  mk   m + K − 1 n  .   15.52   Typically, the sequence is long and m  cid:7  K, and in this case Rc ≈ k n .      610   cid:2   Channel coding  Alternative representation  The encoding equations can be represented by polynomials. Let a i  D  be the ith input sequence and b j  D  be the jth output sequence, where D is the delay operator. The gen- erator polynomial g j  i  D  corresponds to the encoder transfer function relating input i to output j. For a k-input, n-output linear system, there are a total of kn transfer functions, which can be packed into a matrix  ⎤⎥⎥⎥⎥⎦ .  ⎡⎢⎢⎢⎢⎣ g 1   G D  =  1  D  g 2  1  D  g 1  2  D  g 2  2  D  ... ... g 1  k  D  g 2  k  D   ··· g n  1  D  ··· g n  2  D  ... ... ··· g n  k  D    cid:22   cid:22    cid:23  a 1  D , a 2  D ,··· , a k  D   cid:23   b 1  D , b 2  D ,··· , b n  D   A D  =  B D  =  By denoting  as the k-tuple of input sequences and  as the n-tuple of output sequences, the encoding equations can be represented by  B D  = A D G D . After multiplexing, the codeword can be represented by  b D  = b 1   Dn   cid:7    cid:8   Dn  .  From the above equations, the codeword can be expressed by   cid:7   Dn   cid:7    cid:8  + ··· + Dn−1b n   cid:8  + Db 2  b D  = k cid:26   cid:8   cid:7   cid:8  + ··· + Dn−1g n   cid:7   cid:18   cid:17   gi D ,  i=1  a i    cid:7    cid:8   Dn  Dn  Dn  ,  i   cid:8  + Dg 2   cid:18   cid:17   i  + Dg 2   cid:17   cid:18   b D  = a  D2  g D  = D2 + D3 + D4 + D6 + D7,  Example 15.7: For the  2, 1, 3  encoder given by Fig. 15.5, and a =  1000 , we have  g D  = g 1   D2  = D2 + D3 + D4 + D6 + D7,  D2   cid:7   where  gi D  = g 1   i  Dn  i = 1, 2, . . . , k.   15.59   which corresponds to the codeword  0011101100 . This result is the same as that given in Example 15.6.   15.53    15.54    15.55    15.56    15.57    15.58    15.60    15.61       611   cid:2   15.6 Convolutional codes  Systematic codes  Like block codes, convolutional codes may be systematic codes if the ﬁrst k output sequences are exactly the same as the k input sequences, i.e., i = 1, 2, . . . , k.  cid:20    15.62  = 1 for j = i and 0 otherwise, where i, j = 1, 2, . . . , k. The corresponding  Thus, g j  i transfer function matrix is given by  b i  = a i ,   15.63  where Gk× n−k  D  is the rightmost n − k columns of G D . In this case, the ﬁrst k output sequences are called information sequences, and the other n−k output sequences are called parity sequences. Systematic codes require less hardware for decoding than nonsystematic codes. Also no inverting circuit is required for recovering the information sequences from the codeword.   cid:4  cid:4 Gk× n−k  D   G D  = cid:19   Ik×k  ,  For nonsystematic codes, an inverter is required for recovering the information  sequences such that  −1 D  = DqIk×k   15.64  for a delay q ≥ 0, where the right inverse G−1 D  is an n × k matrix. In this case, we can get the information sequences by  G D G  −1 D  = a D G D G  −1 D  = a D Dq.  b D G   15.65  If the inverse G−1 D  does not exist, the code will become a catastrophic code, for which a ﬁnite number of channel errors will cause an inﬁnite number of decoding errors [47]. Any code with G−1 existing is noncatastrophic, and systematic codes are always noncatastrophic [47, 62]. When using nonsystematic codes, catastrophic codes must be avoided. A nonsystematic code can be identiﬁed as a catastrophic code if all the generator polynomials have a common factor, or if the ﬁnite state diagram contains a closed loop with zero weight, other than the loop in the all-zero state.  15.6.2 Encoder state and trellis diagrams  Encoder state diagram  A convolutional encoder is a sequential circuit, thus it can be represented by a state dia- gram, or ﬁnite state machine, whose state is deﬁned as the contents of the shift register. For an  n, k, K  encoder, there is a total of kK-bit memory. Since the ﬁrst stage is controlled by the input, there are 2k K−1  different possible states. The output depends only on the input and the current state but not on the previous states, and thus it can be interpreted as a Markovian process of ﬁrst order. For a rate-k n code, each new block of k input bits leads to a transition to a new state on the state diagram, and there are 2k branches entering and leaving each state.      612   cid:2   Channel coding  1 11  1 01  0 00  00  0 10  1 00  11  0 11  0 01  1 10  01  10   cid:2 Figure 15.6  State diagram for the simple convolutional encoder with Rc = 1 2 and K = 3.  From the state diagram, the transfer function, T D , for the code can be deﬁned. The transfer function gives us the distance properties of the convolutional code. The minimum distance of the code, dfree, is obtained.  Example 15.8: For the simple convolutional encoder shown in Fig. 15.5, the state diagram is shown in Fig. 15.6. The arcs or lines with arrows and labels indicate allowed transitions from the associated input to output. The states are labelled as the contents of the encoder memory. From the state diagram, we can see that k = 1 and that there are four states in the state diagram, thus K = 3. The memory constraint length, K, is easily determined from the number of states. Assuming that the encoder starts with the all-zero state, for an input sequence  1000 , we have  1 −→ 0 −→ 0 −→ 0 input: state: 00 −→ 01 −→ 10 −→ 00 11 −→ 10 −→ 11 −→ 00. output:  The encoded sequence is 11101100, and this result is the same as given in Example 15.6.  Trellis diagram  Although the state diagram fully describes a convolutional encoder, it does not contain temporal information that is necessary for decoding. The trellis diagram, created by For- ney [24], overcomes this disadvantage. It expands the encoder state diagram by adding a time axis, and can be reduced to a state diagram. The trellis diagram simpliﬁes the tree representation by merging nodes in the tree corresponding to the same encoder state. It arranges the ﬁnite states vertically, and the horizontal axis represents time. A state transi- tion is represented by a branch with a label of the corresponding input and output bits. The trellis is fully developed after K steps.  The performance of the convolutional coder is dependent on the Hamming distance between the valid paths through the trellis. Since the code stream of a convolutional code cannot be divided into distinct codewords, as is the case for block codes, the distance      613   cid:2   15.6 Convolutional codes  0  1  2  3  4  5  Time  6  State 00  00  11  01  10  11  00  11  10  00  11  00  11  00  11  11  11  11  00  11  10  10  00  10  00  10  00  11  00  01  01  01  01  01  01  10  01  10  01  10  01  10  input 0  input 1   cid:2 Figure 15.7  Trellis diagram for the simple convolutional encoder with Rc = 1 2 and K = 3. The encoded sequence 11101100 is shown as the bold trace.  between complete code sequences is considered. The free Hamming distance of a con- volutional code is deﬁned as the minimum distance between any pair of code sequences that starts from and ends at the same state. This distance has a signiﬁcant impact on the BER performance, just as the minimum Hamming distance has on the performance of a block code.  The convolutional codes are linear codes. The free Hamming distance between the all- zero sequences and a sequence that starts and ends at the zero state becomes the free Hamming weight, that is, the number of nonzero symbols.  Example 15.9: For the simple convolutional encoder shown in Fig. 15.5, the trellis dia- gram is shown in Fig. 15.7. Each node corresponds to the state of the encoder after a transition from the previous node for an input bit. The labels on the branches are the encoder output bits corresponding to a state transition, and the input is represented by a dashed line  for 0  and a solid line  for 1 . The shortest path from the zero state to the all-ones state gives the memory order m = K − 1 = 2. A path corresponds to a code sequence. For input  1000 , the encoded sequence 11101100 is shown as the bold trace in the diagram.  15.6.3 Sequence decoders  Decoding of convolutional codes is much more complex than decoding of block codes, since there are no distinct codewords, only potentially inﬁnite code sequences. Thus, in principle, the decoder may have to wait an unlimited time to give a possible code sequence.  Decoding of convolutional codes can be performed in a number of ways. Convolutional code decoders are categorized into two classes, namely the tree decoders and the trellis decoders, which make use of the code tree and the trellis, respectively. The depth-ﬁrst      614   cid:2   Channel coding   sequential  algorithms and limited-size breadth-ﬁrst algorithms such as the M-algorithm are well-known tree decoders. The Viterbi algorithm is the major trellis decoder.  Viterbi decoding  The Viterbi algorithm implements MLSE, which searches for the path through the code trellis most closely resembling the received signal sequence. The principle is to deter- mine the path to each node that is closest to the received sequence, and this path is known as the survivor path. Since there are 2m states in the encoder state diagram for a memory order m = K − 1, the decoder must reserve 2m words for storage of the sur- vivors. Each word must be capable of storing the surviving path as well as its metric. The Viterbi algorithm is relatively easy to implement for codes with small memory orders. This also offers possibility for joint decoding and equalization using the same Viterbi decoder. Viterbi decoding is dominant in the decoding of convolutional codes with short con- straint lengths  K ≤ 10 . This limits the available free distance, and the error probability cannot be made arbitrarily small. The complexity of the Viterbi algorithm increases lin- early with the sequence length, N. The Viterbi algorithm implements a nearest-neighbor decoding strategy, and it is given in Section 6.2.5.  Example 15.10: From Example 15.6, we know for an input sequence 1000, the output sequence from the simple encoder is 11101100. Now given a received code sequence 11101100 and the simple encoder, decode the input sequence.  Decoding starts from the zero state. The decoding process is shown in Fig. 15.8. In the ﬁgure, on each branch there is a two-bit number representing the output bits and another number representing the branch metric, and the digit at each node denotes the cumulative metric. The branch metric is obtained as the Hamming distance between the two-bit input  11 00  11  2  0  11  2  0  Time  Input State 00  01  10  11  cid:2 Figure 15.8  deleted path  10 00  11  10  1  1  0  01  2  3  3  0  2  11 00  11  1  0 11 0 2  00 1 1  01  10  01  1  10  1  0  2  3  3  3  3  0  2  2  11  00 00  11  00  0 0 2 2  2  0  10 1 1 01 1  1  3  3  01 10  0  3  3  Trellis diagram for decoding the received code sequence 11101100, corresponding to the simple convolutional encoder with Rc = 1 2 and K = 3.      615   cid:2   15.6 Convolutional codes  and the output bits of the state. At each stage of decoding, one of the two paths leaving a node is deleted, since it generates a larger cumulative metric. When there is a tie between the metrics of two branches that enter one node, an arbitrary decision is made. After all the received code sequence is processed, the path that leads to the shortest cumulative metric corresponds to the decoded sequence. The shortest path is shown as the bold path. From the trellis diagram of the encoder, as shown in Fig. 15.5, we conclude that the decoded sequence is 1000.  In Example 15.10, the Hamming distance is used as the metric, but any appropriate metric can be used. If soft information is available, the Euclidean distance can be used, and this results in soft decision decoding. When a convolutional code is used for encoding short packets of data, it is common practice to add K − 1 zeros to the end of the data before encoding so as to make the encoder return to the zero state. These added zeros are known as tail bits, and this addition leads to a slight increase in redundancy.  The convolutional code was ﬁrst used in satellite and deep space communications before 1980. The Viterbi algorithm was implemented as the major decoding technique. The Link- abit Corporation and the Harris Corporation were among the ﬁrst that designed high-speed hardware Viterbi decoders [47]. Qualcomm Inc. provides a number of ASIC decoders for standard codes.  Sequential decoding  The Viterbi algorithm is only suitable for small constraint length K, since its complexity increases exponentially with K. For long-constraint-length codes, sequential decoding can be applied. The most popular sequential decoding algorithm is the Fano algorithm [21]. Unlike the Viterbi algorithm, the computation required for each decoded bit may be highly variable.  Both the stack algorithm and the Fano algorithm are sequential decoding algorithms of code trees. The complexity of the algorithm is very much dependent on the quality of the channel, and the reordering of the stack leads to an increasing complexity. The stack- bucket algorithm introduces a signiﬁcant increase in speed with a very slight degradation in performance. The Fano algorithm is a depth-ﬁrst tree search procedure in its purest form. The algorithm stores only one path. Compared to the stack-bucket algorithm, the Fano algorithm decodes at a slower speed for high rates, but at a faster speed for moderate rates [47]. It almost always ﬁnds the same path as the stack-bucket algorithm. Some good codes for use with sequential decoding are also listed in [47].  In the Viterbi algorithm, the ﬁxed number of 2K computations must be performed per decoded information block. For sequential decoding, the computational complexity is essentially independent of the constraint length, K; hence, a large K can be used, gen- erating arbitrarily low achievable error probability. For noisy frames, the decoding time may exceed some upper limit, causing some information to be erased. Sequential decod- ing has a computational advantage over the Viterbi algorithm when the received sequence      616   cid:2   Channel coding  is not too noisy. The number of computations is a random variable. The average number of computations for a sequential decoder is normally much less than that of the Viterbi algorithm.  A sequential decoder almost always produces the maximum-likelihood path, achieving the same error probability as the Viterbi decoder. For high code rates, sequential decoding is optimum and has the same error probability as Viterbi decoding; for low rates, it is subop- timum. Since Viterbi decoding is only practical for small K, the suboptimum performance of sequential decoding at low rates can be compensated by using larger K. −3 due to input Sequential decoding may introduce a typical erasure probability of 10 buffer overﬂow. The high erasure probability, which usually occurs for very noisy received sequences, can be exploited. In Viterbi decoding, the noisy frame will always be decoded and the decoding error is likely to be very high. In sequential decoding, these noisy frames will be erased, and an ARQ retransmission is then activated.  M-algorithm  The M-algorithm is a purely breadth-ﬁrst synchronous algorithm that moves forward in the time dimension. Only M candidate paths are kept at each iteration. Unlike depth-ﬁrst algorithms, the M-algorithm is independent of the channel quality, since there are always M paths retained. It has a simpler metric than that of sequential decoding. Its implementation is straightforward. The complexity of the M-algorithm is independent of the code size and constraint length. For this reason, very long constraint-length codes are usually selected to ensure appropriately large dfree. The M-algorithm is not a viable choice for decoding binary convolutional codes, but it may work well with nonbinary modulation [62].  Remarks  In addition to the above algorithms, majority-logic or threshold decoding for complete orthogonalizable codes leads to an inferior performance when compared to Viterbi and sequential decoding, but the implementation is much simpler [47, 51].  Sequential decoding is popular for relatively low transmission speeds. However, the metric used may contain the bias term accounting for the different path lengths, and the method is difﬁcult to parallelize. Breadth-ﬁrst algorithms, such as the Viterbi algorithm and the M-algorithm, do not have the metric bias term, and are more suitable for VLSI implementations. They are popular for high-speed transmissions.  15.6.4 Trellis representation of block codes  Block codes can also be represented by a terminated trellis. This trellis view of block codes enables soft decoding. A code trellis is a visual method of keeping track of the pk codewords of a block code. This representation is based on the parity check matrix H, and the number of states is 2n−k. Trellis representation of linear block codes was ﬁrst introduced in [5], and was later explored by several other authors [52, 78].      617   cid:2   15.6 Convolutional codes  0  1  2  3  4  0  0  0  0  1  0  0  0  0 1  1  1  1  1  1  0  1  1  0  0  0  0  0  0  1  1  1  1  1  0  1  State 000  001  010  011  100  101  110  111  6  1  0  5  1  0  1  7  Time  input 0  input 1   cid:2 Figure 15.9  Trellis diagram of the  7, 4  Hamming code.   cid:20  An  n − k  × n parity check matrix H can be written as  h0 h1 ··· hn−1   15.66  where hi’s are the column vectors of H. A valid linear block code c =  c0c1 ··· cn−1  has a syndrome  ,  H = cid:19  ssyn = cHT = n−1 cid:26   i=0  cihi = 0.  This relationship is used for construction of the trellis of a linear block code. The states at time i, si, and at time i + 1, si+1, are related by  and at time n, from  15.66 , we have sn = 0.  si+1 = si + cihi  Example 15.11: Given a  7, 4  Hamming code with the parity check matrix  H = cid:19   h0 h1 ··· hn−1   cid:20  =  ⎡⎣ 1 1 1 0 1 0 0  1 1 0 1 0 1 0 1 0 1 1 0 0 1  ⎤⎦ ,  the trellis diagram of the code is shown in Fig. 15.9. The codeword 1100001 is represented by a bold line starting and terminating at the zero state.   15.67    15.68    15.69   Viterbi decoding, also called trellis decoding, of block codes has also attracted many investigations, but is restricted mainly by its complexity. Based on the trellis, binary block codes can be decoded by using the BCJR  Bahl-Cocke-Jelinek-Raviv  algorithm [5].      618   cid:2   Channel coding  15.6.5 Coding gain and error probability  The performance of a convolutional code is determined by its decoding algorithm and its distance properties. The minimum free distance dfree is a most important measure.  Minimum free distance and weight  The minimum free distance of a convolutional code is deﬁned as the minimum distance between any two codewords in the code dfree = min  d  b1, b2    15.70    cid:4  cid:4 a1  cid:18 = a2  5  4  .  When a1 and a2 have different length, the shorter sequence is padded with zeros.  The deﬁnition of the weight of a codeword is similar to that of a block code, but for a codeword, it is produced by a nonzero input information sequence. As a linear code, we also have  dfree = min{w b a  cid:18 = 0}.   15.71   That is, dfree is the minimum weight of the codeword produced by any nonzero information sequence. For a given rate and encoder memory, the free distance of a nonsystematic code is larger than that of a systematic code [47].  The coding gain for a convolutional code over an uncoded BPSK or QPSK system is upper- bounded by [47]   dB    15.72   Coding gain   cid:2    cid:3   G ≤ Gc = 10 log10  Rcdfree  2  in the hard-decision case. The corresponding gain in the soft-decision case is given by [47, 56]  G ≤ Gc = 10 log10  Rcdfree    dB .   15.73   That is, soft decision introduces an additional 3 dB in the asymptotic coding gain.  For hard-decision Viterbi decoding, the coding gain, G, reduces by approximately 2 dB for small Eb N0 when compared to soft-decision decoding, but over the entire range of Eb N0 ratio, it introduces a loss of between 2 and 3 dB for the AWGN channel [47]. The asymptotical coding gain, Gc, is reduced by 3 dB for large Eb N0 [47]. It is found that a soft quantization of Q = 8 achieves a performance within about 0.25 dB of the optimum performance that an unquantized demodulator achieves [47].  The minimum free distance dfree, the corresponding Gc, and the generators for a number of binary, short-constraint-length K convolutional codes at several code rates Rc including Rc = 1 n, n = 2, . . . , 8, 2 3, and 3 4 have been tabulated in [47, 56, 62]. The listed dfree are the largest possible values for the given Rc and K. These codes are nonsystematic codes, since for a given Rc and encoder memory, dfree is larger for nonsystematic codes than for systematic codes. The value of dfree can be increased by decreasing Rc or by increasing K.      619   cid:2   15.6 Convolutional codes  Error probability  ∞ cid:26   Pb ≤   cid:12    Nd ˜wd N  2RcEb  Q  d   cid:13   ,  The BER performance of a ﬁnite-length, N, convolutional code with ML decoding and binary antipodal signaling on the AWGN channel is upper bounded by [62]  N0 where ˜wd is the average information weight per codeword  d=dfree  ˜wd = wd Nd  ,   15.74    15.75   most cases, K being the memory order or total constraint length of the encoder K = cid:24   with wd being the total information weight of all codewords of weight d and Nd being the number of codewords of weight d. For the BSC  i.e. hard-decision decoding , the minimum truncation length τmin = 4K in Ki, and the error contribution due to truncation is negligible. For small SNR, τmin = 5.8 K is sufﬁcient so as not to introduce much error probability due to truncation [25]. A truncation length of 4K to 5K is usually employed [47]. In practice, decoding may not always start with the ﬁrst branch transmitted after the encoder is set to the all-zero state, and the effect of lack of initial branch synchronization is negligible after 5 K branches are decoded. Thus, the decoding decision over the ﬁrst 5K branches is usually discarded and the succeeding decision is reliable [25].  For hard-decision decoding, the ensemble average error-rate performance of a con- volutional code on a discrete memoryless channel, similar to block coding, can be upper-bounded by [56, 76]   cid:8 2 , Rc ≤ R0,   cid:7   Pb <   q − 1 q −KR0 Rc 1 − q− R0−Rc  Rc  cid:7   cid:8   1 + e  −Rcγb  R0 = 1 − log2  where q is the number of channel input symbols, K is the constraint length of the code, and R0 is the cutoff rate, which is deﬁned as   bits dimension    15.77   for M-ary binary-coded signals with antipodal signaling [56]. For block coding correspond- ing to M-ary binary-coded signals, the average probability of error [56]   15.76    15.78   −n R0−Rc  for Rc < R0; Pe → 0 as the code block length n → ∞.  Pe < 2  15.6.6 Convolutional coding with interleaving  Convolutional interleavers are used with convolutional codes. The data are interleaved in a continuous stream. This leads to a smaller latency when compared with the block inter- leaver. The minimum length of two convolutional sequences is known as the effective length of the code, and should be as large as possible.      620   cid:2   Channel coding  Encoder  Channel  Decoder  1  1 2 ...  N–1  1 2 ...  N–1  1   cid:2 Figure 15.10  Block diagram of the convolutional interleaver.  The block diagram of a convolutional interleaver is shown in Fig. 15.10. The encoder shifts its output bits into a buffer of increasing size, from no buffer to buffer size N − 1. These buffered output bits are transmitted to the channel in the same order. At the decoder, reverse operation is performed. Thus, the delay at the encoder output increases progres- sively. Each encoder output symbol is separated by N − 1 other symbols by the interleaver. The total buffer size required is N N − 1  2, and the delay is N N − 1 T, where T is the symbol time. The error probability of a convolutional interleaver is given in [56].  Interleavers can be realized as the bit-interleaved coded modulation  BICM  or symbol- interleaved coded modulation  SICM . In BICM, the bits are interleaved before being mapped to modulated symbols, while in SICM the modulated symbols are interleaved prior to transmission. BICM achieves a much better performance than SICM [12], and BICM is now dominant for coded modulation for fading channels; for example, it is used in many OFDM-based standards like IEEE 802.11, 802.16 and 802.22. In BICM, the code diver- sity is the smallest number of distinct bits in case of errors, as opposed to the number of channel symbols in SICM.  15.6.7 Punctured convolutional codes  When a high-rate convolutional code such as  n−1  n is used, the trellis has 2n−1 branches that enter each state, and thus 2n−1 metric computations per state must be performed in the Viterbi algorithm. The same number of comparisons are also required for selection of the best path at each state. As a result, the complexity for decoding is very high.  The rate 1 n codes are most widely employed because this reduces the decoding effort, and higher rates can also be obtained by puncturing. Puncturing is a popular method for adapting the code rate. After encoding, only a subset of the code bits is transmitted, and thus the code rate is increased. This puncturing scheme does not affect the decoder; thus, a single decoder can be used for a number of code rates. Puncturing must be used carefully since it may generate catastrophic codes.  Punctured convolutional codes are high-rate codes obtained from puncturing rate-1 n codes, so that the decoder maintains the low complexity of the rate 1 n code. This also reduces the free distance of the rate 1 n code. Puncturing can be applied in a periodical process by using a puncturing matrix P. High-rate codes with good distance properties can be obtained by puncturing rate-1 2 maximum free distance codes. A list of punctur- ing codes with rate  n − 1  n, n = 2, . . . , 8, obtained by puncturing rate-1 2 codes with constraint lengths K = 3, . . . , 9, are tabulated in [56].      621   cid:2   15.6 Convolutional codes  Decoding of punctured convolutional codes is performed in the same way as decoding the 1 n parent code. Error events in a punctured code are generally longer than that in the low-rate 1 n parent codes. Rate-compatible punctured convolutional  RCPC  codes [33] are desirable for adaptive channel coding. They are obtained by puncturing the same low rate 1 n convolutional code by different amounts. The puncturing matrices should satisfy a rate-compatibility criterion: The lower-rate codes should contain the same coded bits as all higher-rate codes. Given the code rate of the parent code R = 1 n with constraint length Lc, the parent code is completely determined by n generator polynomials Gj D , each of length Lc. Puncturing is performed periodically with a period of Lp codewords. The puncturing pattern matrix deﬁnes the transmitted and punctured bits during one period   cid:22   cid:20 T. Generally, P contains l + Lp ones, with 1 ≤ l ≤  p1 p2 ··· pLp  b1 j , . . . , bn j   which is an n × Lp matrix. The columns pi are periodically assigned to successive whole  n − 1 Lp. Thus the code rate is obtained as [29] ≤ Rc = Lp Lp + l   15.80  That is, a family of  n − 1 Lp different codes is obtained. The largest achievable code rate is decided by Lp.  ≤ Lp Lp + 1  codewords b[j] =  cid:19   = 1 n  Lp nLp  P =   15.79    cid:23   ,  .  For decoding, the positions of punctured bits have to be ﬁlled with dummy bits such as zeros, since zeros do not affect the incremental metric for Viterbi decoding. Since punc- turing yields a reduced Hamming distance between code sequences, the truncation length should be increased to make a reliable decision.  15.6.8 Trellis-coded modulation  Channel coding, such as block coding and convolutional coding, leads to a coding gain at the cost of spectral efﬁciency or data rate. Although this is attractive for power-limited applications, it is not desirable for band-limited applications. A natural idea is to map the coded data into high-order modulation symbols. The result of this method is usually not satisfactory. The trellis-coded modulation  TCM  [74] uses a joint modulation and encoding process, leading to a signiﬁcant coding gain without bandwidth expansion. TCM employs a rate m  m + r  convolutional encoder, and maps the coded bits onto signal points by a technique called mapping by set partitioning. The critical step for the design of TCM codes is the mapping of the convolutional encoder outputs to points in the expanded signal constellation. Redundancy is added to the code by increasing the dimen- sion of the signal space, while some symbol sequences are not allowed to be in the enlarged signal space. TCM uses M-ary modulation and simple convolutional coding with mapping by set partitioning. Decoding is performed by using a soft-decision Viterbi decoder. More detail on TCM code design is given in [67].      622   cid:2   Channel coding  TCM can be viewed as a generalization of convolutional coding. Convolutional codes attempt to maximize the minimum Hamming distance between code symbol sequences, whereas TCM codes try to maximize the Euclidean distance. For the AWGN channel, a coding gain of 3–6 dB can be obtained with respect to an uncoded system by using TCM codes with 4–128 encoder states, without a loss of bandwidth or data rate [74]. For this reason, the TCM code is especially attractive for power-efﬁcient or bandwidth-efﬁcient communications, such as cellular communications and MSs.  TCM was adopted in the ITU-T Rec. V.32 33 34 for data communications over the stan- dard telephone network; these standards are used for analog full-duplex modems, and they use QAM constellations. V.34, also called V.fast or V.last, achieves a rate of 33.6 kbits s, which is very close to the information-theoretic capacity. Note that V.90, the 56 kbits s modem in common use today, relies on a digital channel rather than a noisy voice-band channel. TCM is also used in IEEE 802.15.3.  Similarly, the turbo code can also be employed in coded modulation schemes, to improve spectral efﬁciency. Turbo-coded modulation can be based on TCM or on multilevel coded modulation. The former, called turbo trellis coded modulation  turbo-TCM , uses one turbo code, while the later uses multiple separate turbo codes. Both approaches have quite similar performance, but the turbo-TCM approach is a good compromise between complexity and performance.  15.7 Conventional concatenated codes  Concatenated coding was ﬁrst proposed by Forney in 1966 [23]. The conventional concate- nated code is a simple cascade of the RS code and the convolutional code. The turbo code is a parallel concatenated convolutional code  PCCC  [10]. The serially concatenated convo- lutional code  SCCC  is another concatenated code. This section describes the conventional concatenated code, and the turbo code and the SCCC are described in the following two sections.  In Forney’s paper on convolutional codes, he proposed two forms of convolutional codes: nonrecursive nonsystematic and recursive systematic. Based on the ﬁrst form, For- ney proposed the conventional nonrecursive convolutional codes. The recursive systematic convolutional codes are now used in the turbo code or PCCCs. A recursive systematic code can be obtained from a nonrecursive nonsystematic code by choosing one of the generator polynomials, g j  The recursive code and its nonrecursive counterpart have the same distance spectra, but different IOWEF  input-output weight enumeration function .  i  D , as the denominator, as shown in Fig. 15.11 for Rc = 1 2 and K = 3.  Simple concatenated codes  The RS code is inefﬁcient in error correction, where the errors are randomly distributed. The simple concatenated code combines codes designed for random error correction and      623   cid:2   15.7 Conventional concatenated codes  b 1   b 1   a  a  b 2    a    b   b 2    cid:2 Figure 15.11 Convolutional encoders with Rc = 1 2 and K = 3.  a  Nonrecursive nonsystematic encoder: g1 D  = 1 + D + D2 and g2 D  = 1 + D2.  b  Recursive systematic encoder: g1 D  = 1 and g2 D  =  1 + D2   1 + D + D2 .  Outer encoder  Interleaver  Modulator  Inner encoder  bit stream  Channel   cid:2 Figure 15.12  Outer decoder  bit stream  Deinterleaver  Demodulator  Inner decoder  Block diagram of concatenated coding.   cid:7    cid:8   codes for burst error correction. The method uses two smaller, cascaded codes to construct one long code.  The block diagram of simple concatenated coding is shown in Fig. 15.12. The inner  n1, k1  binary code, C1, protects the data in the usual way by correcting random errors, further eliminates and the outer  n2, k2  nonbinary code, C2, with symbols from GF the remaining, typically burst errors. The critical issue is to ﬁnd a good combination of the inner and outer codes. If the inner code is a block code, then the length of the burst is k1 bits. The RS code is suitable for the outer code, C2.  2k1  Encoding is implemented in two steps [47]: The k1k2 information bits are divided into k2 bytes of k1 information bits, and the k2 bytes are encoded into an n2-byte codeword according to the rules for C2. The second step is to encode each k1-digit byte into a n1-digit codeword in C1, yielding a string of n2 codewords of C1, a total of n2n1 digits. The resulting digits are transmitted one C1 codeword at a time, resulting in an  n1n2, k1k2  binary linear code. If dmin  C1  = d1 and dmin  C2  = d2, the minimum distance of the concatenated code is at least d1d2.  Decoding is also performed in two steps. It is a straightforward combination of the decoding implementations for codes C1 and C2. The hardware required is roughly the total of that of both the codes.  The inner code, C1, can also be selected as a convolutional code. The concatena- tion of the inner convolutional code with the outer RS code is an important class of codes for fading channels. The data is ﬁrst convolutionally encoded, and the output bit- stream is interleaved. This is because the convolutional code may not see error bursts, but      624   cid:2    cid:2 Figure 15.13  Channel coding  k2  n2–k2   k1  n1–k1  The product code.  decoding of a convolutional code using the Viterbi decoder will result in error bursts at low SNR. The RS code is then used to effectively remove burst errors arising from deep fading.  Product codes  The product code [20] is obtained by using an  n1, k1  inner block code, symbol- interleaving it to a degree k2, and then applying an  n2, k2  outer block code with the same symbol size. This yields an n1 × n2 block code. Block interleaving is applied between the two block codes. Data is written row by row from left to right and from top to bottom, and is read out column by column from top to bottom and from left to right. This is illustrated in Fig. 15.13.  Decoding is performed by decoding the block code in one direction, followed by decod- ing in the other direction. In general, if the minimum distances of the row and column codes are d1 and d2, correcting t1 and t2 errors, respectively, then the minimum distance of the product code is d1d2, correcting 2t1t2 + t1 + t2 errors. The code rate is the product of the rates of the two codes, R1 and R2.  The serial concatenated block codes including the product code achieve capacity- approaching performance when being decoded with the iterative decoding technique. In this case, they are also termed block turbo codes. The Chase-II algorithm can be used to avoid the complexity associated with turbo decoding, but it only provides a near-ML decoding of the product code [57]. The trellis-based MAP algorithm is described in [35].  Applications  Concatenated codes achieve a very low error probability at a complexity which is much lower than that of a single code for the same error probability performance. The decoding process is in the reverse order to that of the coding process. Concatenation of the RS code with an inner convolutional code is a common conﬁguration. It is widely used as wireless communication channel coding. Such codes are used in IEEE 802.16, 802.16a d e, DVB, and as an optional scheme in WCDMA.  The classical concatenated code is also used in the Consultative Committee for Space Data Systems  CCSDS  standard. Concatenation of an RS code with another RS code is also used for CD-ROM and DVD storage. For DVD, the code is actually an RS product code.      625   cid:2   15.8 Turbo codes  The block turbo code is also deﬁned as an optional channel coding scheme in IEEE 802.16e, and consists of two binary extended Hamming codes that are applied on the original and interleaved information bit sequences, respectively.  Prior to 1995, concatenated codes were widely used when extremely high coding gains were required. Now, the turbo code and the LDPC code are gaining more popularity. The turbo and LDPC codes are special variants of the convolutional code, and they are used as integral or optional channel coding techniques in 3G and some other recent wireless standards.  15.8 Turbo codes  The turbo code is a PCCC [10]. It is created by a concatenation of several parallel, simple component codes. These parallel component codes are obtained from the ﬁrst code by interleaving. By using an iterative decoding scheme, the turbo code was the ﬁrst code capable of approaching Shannon’s capacity limit to within some hundredths of a decibel on both the AWGN and the interleaved ﬂat fading channels, whilst the complexity of the turbo decoder is much smaller than that of the Viterbi decoder. In the turbo code, the component codes can be either convolutional codes or block codes.  The turbo code is now used in DVB, all CDMA-based 3G standards and beyond, and IEEE 802.20. It will be replacing the RS code and the RS-Viterbi code in future systems. In CDMA-based 3G systems, the convolutional code and the turbo code are adopted for speech and data trafﬁc, respectively. The turbo code is also used in the CCSDC standard to replace its old traditional concatenated coding system. The convolutional turbo code is also deﬁned as an optional channel coding scheme in IEEE 802.16e  WiMAX . WiMAX employs the duo-binary turbo code, which is obtained by encoding two consecutive bits from the uncoded bitstream [11].  Just as TCM is an extension of binary convolutional coding to large signal constellations, so is turbo-coded modulation an extension of turbo coding to larger signal constellations. Turbo-TCM is a parallel concatenation of the TCM code. Serial concatenation of binary error control codes with TCM is receiving more interest in the context of space-time coding [62]. Block turbo-coded modulation is based on the traditional product code.  15.8.1 Turbo encoder  The turbo code can be generated by parallel concatenation of circular recursive systematic convolutional  CRSC  codes M times. Each parallel path, except the ﬁrst one, encodes the k information bits by permutation  interleaving , drawn at random. For a recursive encoder with ν memory units, the probability that any given sequence is an RZ sequence is 1 2ν . 1 2Mν , which is very The probability that the sequence remains RZ for all the M encoders is low. This multiconcatenated code is similar to a random code. The classical turbo code is a concatenation of two parallel CRSC codes, as shown in Fig. 15.14. The substreams      626   cid:2   Channel coding  a k bits  Encoder 1  Π  Encoder 2  a  b 1   b 2   b  X U M   cid:2 Figure 15.14  The classical turbo encoder.  generated by individual encoders are ﬁnally multiplexed. Unlike convolutional coding, which codes on a continuous stream, the turbo encoder codes data block by block, whose size is determined by the size of the interleaver.  In Fig. 15.14, each RSC component may contain a parity sequence. If higher code rates are desired, the parity section of the RSC component can be punctured. A punctured turbo code is obtained by puncturing the speciﬁed parity-check symbols from a rate-1 n turbo code. b1 and b2 correspond to the parity-check symbols generated by the interleaved input bits. The interleavers are used to permute the input bits. The input bitstream is grouped into blocks of length N, where N is the size of the interleaver. In order to adjust the overall code rate, appropriate puncturing of a, and the output parity check bits b 1 , b 2  can be performed.  For the turbo code, each encoder processes the same information bits, but in a different  order due to interleaving. The total code rate is given by  Rc =  k  n1 + ··· + nM  =  + 1 Rc,2  1 Rc,1  1 + ···  ,  1  Rc,M   15.81   where Rc,i is the rate of the ith constituent encoder.  For the classical turbo encoder, if the two component encoders have parity-check poly- nomials h0 D  and h1 D , respectively, and the interleaver of encoder 1 has a length of N, it is identiﬁed as an  h0, h1, N  turbo code, where h0 and h1 are the octal representations of h0 D  and h1 D . For example, if h0 D  = D2 + 1, h1 D  = D and N = 32, we obtain a  5, 2, 32  turbo code.  The interleaver used is a pseudorandom block interleaver: the bitstream is read into the buffer by rows and columns, but is read out in a pseudorandom order. The size of the interleaver should be as large as possible. The pseudorandom interleaving patterns can be generated in many ways. The m-sequence can serve this purpose. A simple determinis- tic algorithm for generating pseudorandom interleaving patterns is based on the quadratic congruence [47, 68]  cm = km m + 1   0 ≤ m ≤ K  mod K,  15.82  → cm+1 mod K, where K is the inter-  cid:14  to generate an index mapping function c leaver size and k is an odd integer. For K = 8 and k = 1, we have  c0, c1, . . . , c7  = m  0, 1, 3, 6, 2, 7, 5, 4 . This implies that index 0 in the interleaved sequence is mapped  2      627   cid:2   15.8 Turbo codes   cid:14   cid:14  1, . . . , c 7   cid:8  =  1, 3, 7, 6, 0, 4, 2, 5 .   cid:7  to index 1 in the original sequence, and so forth. The resulting permutation is  cid:29 8 =  cid:14  0, c c The s-random interleaver [19] ensures the generation of sequences with reasonable Hamming weight. The interleaver has a fundamental inﬂuence on the overall minimum distance of the code, and it largely determines the error ﬂoor of the BER performance of the code. The large interleavers also result in a signiﬁcant latency, which rules it out for some delay-limited applications such as speech communications. WCDMA uses the classical turbo encoder, which consists of two RSC encoders of con- straint length K = 4. The overall code rate is approximately 1 3. Prior to encoding, both constituent encoders are in all-zeros state, and the encoders return to the all-zeros state after having encoded the entire input. This leads to a much better decoding performance. In WCDMA, the interleaver sizes are allowed to be 40 ≤ N ≤ 5114 in order to adapt to different block lengths, and prime interleavers, which can be efﬁciently generated, are used [62]. In CDMA2000, N must be one of the twelve speciﬁc values between 378 and 20730 bits, and a similar turbo encoder structure is adopted. CDMA2000 also uses tail bits to bring back the encoders to the all-zeros state.  Both convolutional and turbo encoders are trellis encoders that map a long input sequence to a coded stream. The coded stream of convolutional coding can be viewed as the convolution of the input stream with an encoder polynomial. For both encoders, the constraint length K corresponds to the encoding delay in bits, and the ratio of the number of input bits to the number of output bits is the code rate.    =  3, 5, 6, 0, 2, 4, 1 . The input to the turbo  Example 15.12: Consider the conventional rate-1 3 turbo coder with RSC encoders given by Fig. 15.11b. Let the interleaver to be encoder is a =  1101010 . Determine the encoded bit sequence. Convert the turbo encoder to rate 1 2, and give the encoded bit sequence. The interleaver ﬁrst maps the input sequence a to a cid:14   =  1101001 . Assuming both  , a cid:14   encoders are initialized to state 0, we have b 1  =  1001100 ,  b 2  =  1001110 .  The encoder output is  111100000111011101000 . The rate 1 2 turbo encoder can be realized by alternately deleting parity bits as  11100011011000 .  15.8.2 Turbo decoder  The optimum ML decoding for the turbo code is too complex to implement. Instead, an iterative symbol probability-based decoding algorithm is employed. The reliability of indi- vidual transmitted or information symbols is calculated, rather than decoding the whole sequence. The most popular symbol probability decoding algorithm is the a posteriori probability  APP  algorithm, also known as the BCJR algorithm or the forward-backward algorithm [5].      628   cid:2   Channel coding  The decoder can be broken up into several simple decoders, and soft information is exchanged between them. For the classical turbo code, decoding uses two soft-in soft- out  SISO  decoders, also called probabilistic decoders. Each SISO decoder outputs the various bits as well as its conﬁdence in the decision, that is, the a posteriori probability. The MAP rule is given by   cid:22    cid:4  cid:4 y 0 , y 1 , y 2    cid:23   ,  ˆbi = max b={0,1} P  bi = b   15.83   where y 0  is the received systematic bit sequence, and y 1  and y 2  are the received parity sequences corresponding to the two constituent encoders.  Log-likelihood ratios  For binary codes, the conﬁdence is described by the log-likelihood ratio  LLR , which is deﬁned as   cid:5    cid:6    cid:5   L  bi  = ln  Pr  bi = +1y  Pr  bi = −1y   = ln  Pr  bi = +1  1 − Pr  bi = +1    cid:6    cid:4  cid:4  cid:4  cid:4  y   15.84   where y is the received sequence. The sign of L  bi  can be used for hard decision, while the magnitude represents the conﬁdence. A larger difference between Pr  bi = +1y  and Pr  bi = −1y  leads to a larger magnitude of L  bi , while the conﬁdence of a decision is low with L  bi  = 0 when the probabilities are equally likely. From  15.84 , the probability of a correct decision ˆb = bi ∈ {0, 1} is given as  cid:4  cid:4  cid:4 L  cid:18  cid:4  cid:4  cid:4   cid:17 ˆb  cid:4  cid:4  cid:4 L  cid:18  cid:4  cid:4  cid:4  .  cid:17 ˆb = e 1 + e   cid:17 ˆb = bi   15.85    cid:18   Pr  The deﬁnition of LLR can be extended to nonbinary turbo codes, such as the double-binary turbo code used in WiMAX and DVB-RCS  Return Channel via Satellite .  The extrinsic information related to bi is deﬁned as the difference between the input and  output LLRs associated with bi  Le  bi  = Lout  bi  − Lin  bi  .   15.86   It is a reliable measure for each component decoder’s estimate of the transmitted infor- mation symbol, based on the received component parity sequence only. The received systematic sequence can be used by each component decoder directly. The component decoders only exchange extrinsic information.  Applying Bayes’ rule on  15.84 , the a-posteriori LLR is obtained as  L  bi  = L 2   e,i  + L 1   e,i  + Ls,   15.87   where L 2  decoders, respectively, and Ls is the a-posteriori LLR of the systematic bits  e,i are the extrinsic information contributed by the second and ﬁrst  e,i and L 1       629   cid:2   15.8 Turbo codes   0  yk  L 1  bk      Π  Decoder 1  z−1  y  X U M e D   1  yk   2  yk  Decoder 2  Π–1  Le 2  bk      L 2  bk      bk  Decoded output   cid:2 Figure 15.15  The decoder for the classical turbo code. Reproduced with permission from [65] c cid:2 IEEE.   cid:18   cid:18  . Based on the LLR, the estimate ˆbk of data bit bk is derived  bi = 1 bi = 0  Ls = ln  y 0  i y 0  i   cid:17   cid:17   P  P  ˆbk = sign  L bk   .  Decoding algorithms   15.88    15.89   The structure of the classical turbo decoder is shown in Fig. 15.15. Each SISO decoder processes its own input constituent codes and passes the extrinsic information to the other SISO decoder. The interleavers are identical to the interleavers in the turbo encoder so that the sequence at each decoder is properly aligned. Turbo decoding can be based on a message-passing or belief propagation algorithm.  The a posteriori probabilities or LLRs in the SISO decoder can be generated or approx- imated by using the MAP algorithm, which is a modiﬁed BCJR algorithm [5], or by using the soft output Viterbi algorithm  SOVA  [34].  Unlike the Viterbi algorithm whose decision is hard, the decisions of the BCJR are soft. While the Viterbi algorithm yields the most likely sequence as the codeword, the BCJR algorithm produces the most likely symbol along with its reliability at each time. The MAP algorithm outperforms the Viterbi algorithm by quite a margin at low Eb N0 and high BERs. The BCJR algorithm can be used to estimate a posteriori LLRs in systems represented by a trellis diagram; thus it can be used for the decoding of convolutional and linear block codes and for channel equalization.  Due to the overwhelming complexity of the BCJR algorithm, many reduced complexity variations have been developed. These include the M-BCJR and T-BCJR algorithms [26], reduced-complexity BCJR algorithms for turbo equalization [22], and the reduced-state BCJR  RS-BCJR  algorithm [17]. These algorithms are based on search over a reduced number of states on the trellis [26], or on a full search on a reduced-state trellis [17], or on search over a reduced number of paths on the trellis [22]. The BCJR algorithm has also been extended to trellis rate-distortion data compression [3].      630   cid:2   Channel coding  In general, the SOVA is less complex than the MAP algorithm, but at a cost of perfor- mance. The SOVA is also used in decoding convolutional codes. For small memory, the SOVA is roughly half as complex as the log-MAP algorithm [60].  The decoding process using the MAP algorithm is given as follows:   Set Le = 0; decoder 1 decodes the received signal like a convolutional decoder, but gives soft output.   From the soft output of decoder 1, Le for decoder 2 is calculated.   Le for decoder 2 is fed back to decoder 1, resulting a reﬁnement of the data estimate.   This is then used as a priori information for a second iteration of code 1.   This procedure continues until the speciﬁed number of iterations is reached or the convergence is achieved.  The BER performance improves as the number of iterations increases.  The main drawbacks of the turbo code are the relatively high decoding complexity and  an increase in latency due to large interleaver size, and a performance ﬂoor at high SNR.  Discussion  Both Viterbi and turbo decoders are based on trellis processing of the received sample sequence. Unlike the Viterbi decoder, the turbo decoder makes multiple decoding passes over the received samples. The number of decoding passes for the turbo decoder is deter- mined by SNR, and in 3G standards the maximum number of decoding passes is typically 6 to 10. Turbo decoder quantization usually employs 4-bit quantization.  TI’s C64x DSPs integrate Viterbi and turbo co-processors that provide ASIC-like perfor- mance. In [73], a uniﬁed Viterbi turbo decoder that shares some function blocks between the two decoding techniques is designed for 3GPP standards; this decoder operates in either the convolutional or the turbo decoding mode, and it can switch between the two modes or different turbo block sizes very rapidly. A high-speed radix-4 log-MAP turbo decoder targeted for HSDPA-MIMO mobile terminals has also been designed in [73]. The radix-4 architecture increases the throughput using parallelism in the trellis computations.  15.8.3 MAP algorithm  The turbo decoder may be implemented using the MAP algorithm. The MAP algorithm achieves the soft decision decoding by making two passes through the trellis, one pass in the forward direction and the other in the backward direction. For this reason, the MAP and its variants are sometimes called the forward-backward algorithm.  cid:8  Let k be the time index, αk m  be the probability of the prior observations y up to time k − 1 with the decoder ending in state m at time k, βk+1 m  be the probability of future observations y at time k with the decoder starting at state m at time k + 1, γi yk, m , for the data bit i = 0, 1, be the probability of transition at time k from state m  cid:14  to state m for each branch, that is, the branch metric.   cid:7   , m   cid:14       631   cid:2   15.8 Turbo codes  State  α,β  l  γi  yk, l, n  Input 0  State  α,β  n  γi  yk, m, n   Input 1   cid:2 Figure 15.16  m  Trellis diagram for calculations of α, β, γ .  The trellis diagram for the calculation of α, β, γ is shown in Fig. 15.16. Each current state combines two paths from the previous states, one for input 1 and the other for input 0.  There are the following relations [1, 10, 47]:   cid:24   cid:24  αk m  =  cid:24   cid:24   M−1 m=0  M−1 m cid:14 =0   cid:24   cid:24   cid:24   cid:24   M−1 m cid:14 =0   cid:24   cid:24   1 i=0 M−1 m cid:14 =0   cid:7   γi 1 i=0   cid:7   1 i=0 M−1 m cid:14 =0  γi 1 i=0  M−1 m=0  βk m  =  cid:17    cid:7    cid:8  = p  where M is the number of decoder states and γi channel; for the AWGN channel we have ·p  cid:18   bk = i, m  cid:14   yk, m  y u  k   cid:17   with   cid:7   , m  , m  γi   cid:14    cid:18    cid:7    cid:14  cid:8   cid:14  cid:8    cid:7    cid:14   αk−1  , m  yk, m γi  yk, m cid:14 , m  αk−1  m cid:14    m  ,  m  , m  βk+1  yk+1, m  cid:7  γi  yk+1, m cid:14 , m  βk+1  m cid:14   yk, m  , m   cid:14   ,   cid:8    cid:8    cid:14    cid:8   cid:8 ·p   cid:14  cid:8   cid:7  mm  cid:22    cid:23 2   cid:23 2  ,  − 1 e 2σ 2  −ak i   y 0  k   cid:17   p  y 0  k  , m  bk = i, m  cid:14   cid:18   =  1√ 2π σ 2  =  1√  cid:22  2π σ 2  bk = i, m  cid:14   p  , m  y u  k k  i , u = 1, . . ., being the signal and parity bits on the trellis.  ,  − 1 e 2σ 2  −b u    cid:14  k  i,m  y u  k  ,m   u = 1, . . . ,  ak i , b u   is dependent on the transmission  bk = im   cid:14   , m  u = 0, 1, . . .  15.92   ,   15.90    15.91    15.93    15.94   Example 15.13: Consider the RSC given by Fig. 15.11b, with input sequence a =  1011 . The encoder starts at state 0. Assuming that antipodal bits are transmitted over the AWGN channel with channel SNR 3 dB, use hard decoder and the MAP decoder to decode the received sequence. Assuming a unit average signal power, from the channel SNR = 2 dB = 100.2, we have the noise variance σ 2 = 10 The trellis of the RSC encoder is shown in Fig. 15.17. The encoded sequence is thus given as  11011010 , or in antipodal bits  +1 + 1 − 1 + 1 + 1 − 1 + 1 − 1 .  −0.2.      632   cid:2   Channel coding  State  State  0 0  1 1  1 1  0 0  1 0  0 1  0 1  0  1  2  3  1 0  input parity  0  1  2  3   cid:2 Figure 15.17  Trellis diagram of the RSC encoder.  For a random run, the received sequence is  y =  1.1022, 1.5215,−1.9276, 0.6341, 0.7915,−1.9636,−0.0481,−0.2603  If hard decision is employed, the sequence is  11011000 , there is one bit in error.  Now we turn to soft decision using the MAP algorithm. The decoding is also based on s , and those of the p. The probabilities for the signal and parity are assumed  the trellis. Let the probabilities of the signals for inputs 0 and 1 be p0 parities for inputs 0 and 1 be p0 to be independent. At time k, the probability of transition is given by  s , p1  p, p1   cid:7    cid:14  cid:8  = pi  γi  yk, m, m  i = 0, 1.  spi p,   15.95   We now calculate αk m . At time k = 0, since the encoder starts at state 0, we have  [α0 0 , α0 1 , α0 2 , α0 3 ] = [1, 0, 0, 0].  At time k = 1,  where  Note that y 0  = 0.0108, p0 1 p0 s  p  α1 0  = α0 0 γ0 y1, 0, 0  + α0 1 γ1 y1, 1, 0  = γ0 y1, 0, 0  = p0 s p0 p,  cid:18 2   cid:18 2   cid:17    cid:17   y 0  1  −a1  1√ 2π σ 2  − 1 = p0 e 2σ 2 s = 1.1022, y 1  = 0.0023, γ0 y1, 0, 0  = 2.4868 × 10  =  p0 p  1  ,  1√ 2π σ 2  = 1.5215. From trellis, a1 = −1, b 1   − 1 e 2σ 2  −b 1   1  y 1  1  −5, and α1 0  = 2.4868 × 10  1  −5.  . = −1, we have  α1 1  = α0 2 γ1 y1, 2, 1  + α0 3 γ0 y1, 3, 1  = 0,  α1 2  = α0 0 γ1 y1, 0, 2  + α0 1 γ0 y1, 1, 2  = α0 0 γ1 y1, 0, 2  = 0.1017,  α3 1  = 0.  The normalized values of αk m  are given by α1 1  = 0,  α1 0  = 0.0002,  Repeating the same procedure for k = 2, 3, 4, we get  α1 2  = 0.9998,  α1 0  = 0.      633   cid:2   15.8 Turbo codes  state  0  1  2  3  1  1  0.0002  0  0.0000  0  0.0000  0  0.0000  0   0  0  0  0  0.0003  0  0.0002  0  0.3379  0   0  0  0.9998  1  0.0000  0  0.0000  0  0.0001  0   0  0  0  0  0.9997  1  0.9998  1  0.6620  1   The results in parentheses are for the case of no noise. Following the same procedure, by starting from β4 to β0, we have, at time k = 4,  [β4 0 , β4 1 , β4 2 , β4 3 ] = [0, 0, 0, 1],  and we get the values of β to be  state  0  1  2  3  0.9980  1  0.0001  0  0.0010  0  0  0  0  0   0.0013  0  0.9597  0  0.0002  0  0.3379  0  0  0   0.0004  0  0.0000  1  0.0398  0  0.0952  0  0  0   0.0003  0  0.0401  0  0.9591  1  0.6621  1  1.000  1   α0 α1 α2 α3 α4  β0 β1 β2 β3 β4  The posterior input bit at time k is decided by computing the sum of all the probabilities for bk = 1 conditioned on y, Pr  bk = 1y , and the sum of all the probabilities for bk = 0 conditioned to y, denoted Pr  bk = 0y . From the trellis diagram shown in Fig. 15.18, we can extract these branches with input 1 for the calculation of Pr  bk = 1y . Thus,  Pr  bk = 1y  = αk 0 γ1 yk, 0, 2 βk+1 2  + αk 1 γ1 yk, 1, 0 βk+1 0   + αk 2 γ1 yk, 2, 1 βk+1 1  + αk 3 γ1 yk, 3, 3 βk+1 3 ,  State  State  State  State  1 1  1 1  1 0  αk 0   αk 1   αk 2   αk 3   0  1  2  3  1 0  input parity   a   βk+1 0   βk+1 1   βk+1 2   βk+1 3   0  1  2  3  αk 0   αk 1   αk 2   αk 3   0  1  2  3  0 0  0 0  0 1  0 1  input parity   b    cid:2    cid:3  bk = 0y  .   cid:2    cid:3  bk = 1y  ,  b  Pr  βk+1 0   βk+1 1   βk+1 2   βk+1 3   0  1  2  3   cid:2 Figure 15.18  Trellis diagram for calculations of  a  Pr      634   cid:2   Channel coding  Pr  bk = 0y  = αk 0 γ0 yk, 0, 0 βk+1 0  + αk 1 γ0 yk, 1, 2 βk+1 2   + αk 2 γ0 yk, 2, 3 βk+1 3  + αk 3 γ0 yk, 3, 1 βk+1 1 .  At k = 1, we have  Pr  bk = 1y  = 2.3277 × 10  −9, where the γi’s are available when calculating αk m ’s. The normalized values are  Pr  bk = 0y  = 3.2416 × 10  −6,  Pr  bk = 1y  = 0.99861,  Pr  bk = 0y  = 0.00139.  Thus, the decision is ˆb0 = 1. Repeating the procedure for k = 2, 3, 4, we have ˆbk  k  Pr  bk = 1y  0.99861 7.0485 × 10 0.99992 0.99999  −8  Pr  bk = 0y  0.00139 1.00000 8.2247 × 10 1.2387 × 10  −5 −5  1 2 3 4  1 0 1 1  The MAP decoder generates the same output as the input sequence.  The quantization of channel values is considered in [18]. For an AWGN channel, even with four bits of quantization, the result based on quantized data is practically equal to the MAP algorithm operating on inﬁnite precision data. The decoder’s internal vari- ables, αk m ’s and βk m ’s, can also be quantized; however, these internal variables may not present a major storage problem, if sliding window schemes are used. The quan- tization of extrinsic information passed between two component decoders in a binary turbo decoder is considered in [42]. It is found that decoding with single-bit quantization introduces a performance loss of only about 0.6 dB, compared to inﬁnite precision turbo decoding.  Log-MAP  The MAP algorithm is usually implemented in the logarithmic domain on a speciﬁc hardware.  The logarithm of a sum can be calculated by   cid:7   ex1 + ex2  ln   cid:8  = max [x1, x2] + ln   cid:17   −x1−x2 cid:18   .  1 + e   15.96   That is, it can be calculated as the maximum of x1 and x2, plus a correction term. The correction term depends on the difference between x1 and x2, and has a small range for quantization. An LUT can be used to avoid the computation of exponential and logarithmic functions, and a simple LUT for 3-bit quantization is given in Table 15.2. This version of the BCJR algorithm is known as log-MAP [61].      635   cid:2   15.8 Turbo codes  Table 15.2. Look-up table for the correction term in  15.96  for 3-bit quantization.   cid:17  x1 − x2 1 + e  ln  −x1−x2 cid:18   0.00  0.25  0.50  0.75  1.00  1.25  1.50  1.75 > 2.00  0.69  0.58  0.47  0.39  0.31  0.25  0.20  0.16  0.00  The max function  15.96  can be extended to k sum-terms in the logarithm function   cid:12  k cid:26    cid:13   ln  exi  i=1   cid:13    cid:12  k cid:26   i=1  = max  xi  + ln  exi−max xi   .   15.97   This equation is useful for calculating the LLR for nonbinary constellations.  A static LUT introduces error in the LLR estimation due to its limited size and res- olution. A dynamic LUT, which has partial resolutions in separate decision regions and is updated at each iteration of decoding, is described in [39]. By using dynamic LUTs of sufﬁcient length, the LLR values obtained are close to their natural logarithmic coun- terparts. The dynamic-LUT architecture effectively eliminates the error ﬂoor that static LUT has.  Max-log-MAP  A suboptimal but lower-complexity max-log-MAP algorithm is implemented as an approx- imation of the optimum log-MAP algorithm by neglecting the correction terms in  15.96 . The performance of the max-log-MAP degrades slightly, but it is still better than that of the SOVA. The hard decisions of the max-log-MAP output equal those of the Viterbi algorithm [60].  The max-log-MAP algorithm can be implemented using a pair of Viterbi algorithms, one for the forward direction and the other for the backward direction [77]. The complexity of the log-MAP is about twice that of the SOVA; however, the log-MAP is more suited to parallel processing [60].  15.8.4 Analysis of the turbo code  The BER performance of the turbo code has a distinct turbo cliff region and an error ﬂoor region. The turbo code has an impressive performance at low SNR  Eb N0 , but at high SNR the performance is not very remarkable; this can be seen from the BER performance: An error ﬂoor  i.e. a change in the slope of the error rate curve  has been introduced at high SNR, due to the relatively small free distance of the turbo code [6, 62]. The excellent performance of the turbo code at low SNR is due to the sparse distance spectrum that results from a pseudorandom interleaver. The free dis- tance as well as the distance spectrum can be calculated using the algorithm described in [28].      636   cid:2   Channel coding   cid:13    cid:13   Distance spectrum analysis of the turbo code  The BER performance of a turbo code with ML decoding is also upper bounded by the union bound for the convolutional code, as given by  15.74  [62]  ∞ cid:26   Pb ≤  Nd ˜wd N   cid:12    2RcEb   cid:12     15.98  Although they have the same form, for the turbo code Nd ˜wd  cid:5  N for low-weight code- words due to the pseudorandom interleaver. After the distance spectrum is obtained, this bound can be determined.  d=dfree  N0  Q  d  .  For moderate and high SNRs, the free distance term in the union bound dominates. In this case, the asymptotic performance of the convolutional and turbo codes with ML decoding is given by  Pb ≈ Nfree ˜wfree  2RcEb  ,  N  Q  N0  dfree   15.99  where Nfree and ˜wfree correspond to Nd and ˜wd for d = dfree. This is the free distance asymptote of the code, which can be used to characterize the error ﬂoor of turbo codes. Increasing the interleaver length N while preserving dfree and Nfree will lower the asymptote without changing its slope. The inﬂuence of N is illustrated in Fig. 15.19 for the same turbo code at a given number of iterations. For a ﬁxed N, the error ﬂoor can be modiﬁed by increasing dfree while keeping Nfree unchanged; this increases the slope of the asymptote. The interleaver is most important for the turbo code. It should be selected as a pseu- dorandom interleaver. For a  37, 21, 65536  turbo code with pseudorandom interleaver, it is found that Nfree = 3, dfree = 6, and ˜wfree = 2 [62]. The effective multiplicity Nfree N = 3 65536 is very small. When the interleaver is selected as a rectangular inter- leaver, the result is totally different. For a  37, 21, 14400  turbo code with a 120 × 120 rectangular interleaver, it is found that dfree = 12 with a multiplicity of Nfree = 28, 900  b P  0.1  0.01  10−3  10−4  10−5  10−6  10−7  0  Small N  Large N  1  2  γb  dB   3   cid:2 Figure 15.19  The inﬂuence of the interleaver size on the performance of a turbo code.      637   cid:2   15.8 Turbo codes  10−2  10−4  10−6  b P   37,21,14400 , rectangular   37,21,65536 , pseudorandom   10−8  0  0.5  1  2  2.5  3  1.5 γb  dB    cid:2 Figure 15.20  The free distance asymptotes for turbo code with different interleavers.  and ˜wfree = 4 [62]. Thus, the effective multiplicity Nfree N = 28900 14400 ≈ 2, which is much larger than that for the pseudorandom interleaver. This large multiplicity of dfree for a rectangular interleaver leads to relatively poor performance. According to the analy- sis given in [62]: for the rectangular interleaver, Nfree is of the order of N, and increasing N does not lead to an increase in dfree; thus Nfree N does not change signiﬁcantly and an increase in N does not lead to a sufﬁcient lowering of the error ﬂoor.  Example 15.14: The free distance asymptotes for the  37, 21, 65536  and  37, 21, 14400  turbo codes discussed above can be obtained from  15.99 . They are plotted in Fig. 15.20. These asymptotes correspond to the error ﬂoor for medium and large SNR. For the  37, 21, 65536  turbo code, the contribution of the free distance term dominates the BER for SNR as low as 0.75 dB [62].  In the low SNR region, the contribution of other distances d in addition to dfree must be considered. In this case, the distance spectrum is referred to as sparse or spectral thin. For a convolutional code, higher distance spectral lines have an overall BER contribution greater than that of the free distance term for small SNR. The free distance asymptote dominates the BER performance only for large SNR, and this is due to the rapid increase of the multiplicity for large d. Such a distance spectrum is referred to as spectrally dense.  Weight enumeration analysis of the turbo code  For convolutional or turbo codes, the distance spectrum information can be rewritten in the form of the IOWEF  Aw,dW wXd,   15.100   A W, X  =  ∞ cid:26    cid:26   d=dfree  w      638   cid:2   Channel coding  where Aw,d is the number of codewords of weight d caused by information sequences of weight w, and W and X are dummy variables. For convolutional codes, the IOWEF can be calculated via the transfer function method. However, for turbo codes the transfer function is hard to obtain due to the use of an interleaver. An approximate weight enumeration function  WEF  can be obtained by using a probabilistic uniform interleaver model. The corresponding bound on the BER of the turbo code with uniform interleavers is derived as [7, 62]  Pb ≤ N cid:26   w=wmin  w N   cid:4  cid:4   W wAw Z   W=Z=e  −RcEb N0 ,   15.101   where wmin is the minimum weight of the information sequence that generates a code- word in the terminated convolutional component code, and Aw Z  is the conditional WEF  CWEF  for the overall turbo code, Z being a dummy variable.  For the turbo code with uniform interleaving, the overall CWEF can be approximated   cid:7    cid:7   w! nmaxw !   cid:8 2 N2nmaxw−w  Aw Z  ≈   cid:8 2 ,  Anmaxw  w   Z    15.102   by [7, 62]  where nmaxw is the maximum number of error events due to a weight w information sequence that can be positioned in an interleaver of length N.  Substituting this approximation into  15.101 , the bound obtained for Pb can be used for  developing some design rules for turbo codes. These rules are given as follows [7, 62]:   Rule 1. Select component encoders with feedback.   Rule 2. Select the feedback polynomial as a primitive polynomial.   Rule 3. Select an interleaver with appropriate spreading factors.  For rule 3, a rectangular interleaver has too much regularity, leading to a good spreading factor, but yielding poor overall performance due to large multiplicity. On the other hand, a pseudorandom interleaver has a thin distance spectrum but has a poor spreading factor. The s-random interleaver achieves a desired spreading property and its random-like index points avoid large multiplicity; thus, it yields an excellent performance in the error ﬂoor region, since its free distance is larger than that of the pseudorandom interleaver. Also, rules 2 and 3 are based on the approximations that are only valid for high SNR and large N.  EXIT analysis of the turbo code  The behavior of turbo codes at low SNR, or in the turbo cliff region, can be analyzed by the extrinsic information transfer  EXIT  analysis [72]. The component decoder is treated as a nonlinear LLR transfer function that transforms the input extrinsic LLR  mutual a priori information  Ia into an output extrinsic LLR Ie.  The EXIT analysis takes into consideration the iterative nature of the decoding process. It makes use of the iterative decoding algorithm. The method is also used for prediction of the turbo cliff for SCCCs [71].      639   cid:2   15.9 Serially concatenated convolutional codes  15.9 Serially concatenated convolutional codes  The SCCC with iterative decoding is an alternative to the PCCC. The SCCC encoder has the same block diagram as that of the conventional concatenated code, as shown in Fig. 15.12. The SCCC uses a recursive or nonrecursive convolutional outer code with rate Ro = k m, encoder memory Ko, and generator matrix Go D , and a recursive convolutional inner code with rate Ri = m n, encoder memory Ki, and generator matrix Gi D . The over- all code rate is R = RoRi = k n if the effect of trellis termination is negligible. Unlike the conventional concatenated code, for the SCCC the interleaver that separates the inner and outer encoders is mandatory. The interleave length N is usually divisible by m. In the SCCC, the interleaver is used for spectral thinning, as opposed to the spectrally dense case of the convolutional code. It also introduces randomness necessary for iterative decoding. The BICM resembles the SCCC code, and iterative decoding can be applied to approx- imate the a priori probability [16, 46]. Uniform soft-decision feedback iterative decod- ing [46] provides a tradeoff between hard-decision and soft-decision feedback iterative decoding schemes in terms of performance gain and complexity. Without the interleaver, the concatenated code simply becomes a convolutional code with an overall code rate Rc = RoRi and overall generator matrix G D  = Go D Gi D . This is called a cascaded convolutional code, and can be decoded by using Viterbi decod- ing. This cascade will yield a reasonably large free distance, which increases with the component code complexity. But the free distance is not maximal.  SCCC versus PCCC  The PCCC or turbo code is an inherently unequal error protecting code [67]. Occasional bad interleaver mappings make a few bit positions affected by the dominant error events, leading to small dfree and hence a BER ﬂoor [67]. On the contrary, for the convolutional code all bit positions in the input sequence are subject to the same error events, leading to equal likelihood of error. Analysis and simulation for the BER performance show that the SCCC has a distinct advantage over the PCCC with random interleavers for large N and −1, SNR [8, 62] in the AWGN channel. For the PCCC, the interleaving gain is ﬁxed at N free is the free distance of the outer encoder. Due while for the SCCC it is N to its large free distance, the SCCC does not manifest an error ﬂoor at high SNR. However, at very low SNR, the SCCC is inferior to the PCCC. The same conclusion is obtained in the presence of ISI [45].   2, where do  −do  free  Product code  The product code is a well-known serial concatenated block code [47]. Two minor com- ponent codes encode a block of identical, but permuted, information symbols. The product code employs the regular rectangular block interleaver. Its powerful potential can be achieved by using the turbo decoding principle [62]. For this reason, the product code is also known as a block turbo code. Like the SCCC, the product code does not suffer from      640   cid:2   Channel coding  the problem of an error ﬂoor as the turbo code does, and no special interleaver design is required. The product code with iterative decoding is now used as optional FEC in IEEE 802.16e.  15.9.1 Design of the SCCC  Like the PCCC, analysis of the SCCC can be based on the IOWEF of the code. A bound on the BER probability of the SCCC is derived in [8, 62], based on which some design rules for the SCCC are given as follows.   Rule 1. The inner encoder should be a recursive convolutional encoder  i.e., with feedback  so that a gain is achieved by increasing the interleaving size N.   Rule 2. The effective free distance, deff, of the inner encoder should be maximized by selecting a primitive feedback polynomial.   Rule 3. The feedback polynomial of the inner encoder should have a factor of 1 + D.   Rule 4. The outer encoder should have the free distance, do free, as large as possible to achieve a large interleaving gain.  The ﬁrst two design rules are also used for selecting component encoders for the PCCC. Thus, a component encoder optimized for the turbo code is also suitable for using as the encoder of the inner code in the SCCC. For rule 4, a good nonrecursive convolutional code is suitable. A nonrecursive convolutional code has a slight advantage in BER performance for large SNR, and should be preferred for the outer encoder. Rule 3 is in conﬂict with rule 2, since the feedback polynomial constructed using rule 3 will not be primitive. As with the turbo code, the use of a primitive or nonprimitive feedback polynomial leads to a tradeoff between the performance at low and high SNRs. Analysis and simulation show that if both the inner and outer convolutional encoders have no feedback, the concatenated code has a free distance dfree = do free [62]. The interleaver introduces a signiﬁcant improvement in free distance compared to the cas- caded convolutional code case. However, there is no interleaving gain associated with the free distance multiplicity, leading to a free distance asymptote that is not associated with N. Nonetheless, for large N the pseudorandom interleaver has a spectral thinning effect, yielding an improved performance at moderate SNR.  freedi  15.9.2 Decoding of the SCCC  The SCCC can be decoded in a manner very similar to that of the PCCC. The interleavers decouple the concatenated codes so that the extrinsic informations obtained by the two decoders are mutually independent. Exchanging extrinsic information between the two SISO decoders may improve the overall performance. The block diagram of the iterative SCCC decoder is shown in Fig. 15.21. The two SISO decoders are the same as those used in the iterative decoder of the turbo code. A difference from the turbo decoder is that the outer SISO decoder of the SCCC has no access to channel observations, and can only rely on information received from the inner decoder.      641   cid:2   15.10 Low-density parity-check codes  z–1  ′ Le 1  dk      Inner decoder  Le 1  dk      −1Π  Outer decoder  Le 2  dk      Π  y  bk  L 2  dk      ′ Le 2  dk      dk  Decoded output   cid:2 Figure 15.21  Iterative decoder for the SCCC code.  For each input symbol bk, the inner decoder receives the channel LLR and the extrinsic  information from the outer decoder and calculates a new LLR as   cid:8   cid:8  = ln   cid:7   cid:7  yb  cid:14  k yb  cid:14  k  Pr Pr   cid:8   cid:8  + ln  = 1 = 0   cid:7   cid:7    cid:14  b k  cid:14  b k  = 1 = 0  Pr Pr   cid:8   cid:8   L 1  k  = 1y = 0y .   cid:7   cid:7   cid:14  = ln Pr b k  cid:14  Pr b k = L 1  cid:14  + L 1  cid:14  Only L 1  cid:14   cid:17  Likewise, the outer decoder output  cid:17  = 1L 1   cid:14  b k = 0L 1   cid:14  Pr b k + L 1  cid:14  = L 2  e,k .  = ln  L 2  k  Pr  e,k  e,k  k  k  k  e,k is passed to the outer decoder.   cid:18   cid:18  = ln   cid:17   cid:17   b  cid:14  k b  cid:14  k  L 1  k L 1  k  = 1 = 0  Pr  Pr   cid:18   cid:18  + ln   cid:7   cid:7    cid:14  b k  cid:14  b k  = 1 = 0  Pr Pr   cid:8   cid:8    15.103    15.104   Only L 2  decoding decision is then made on the symbol.  e,k is passed to the ﬁrst decoder. The decoder performs a few iterations, and a  15.10 Low-density parity-check codes  The LDPC code [27], developed by Gallager in 1960, is another error-correcting code that approaches the Shannon limit. The LDPC code and an iterative decoding algorithm, which involves calculation of probabilistic information that is passed from one iteration to another, were ﬁrst introduced by Gallager in [27], but they were ignored until the invention of turbo codes in 1993. The LDPC code was rediscovered by MacKay and Neal [49, 50]. The LDPC code can be constructed for any rate.  15.10.1 LDPC code: a linear block code  The LDPC code is a linear block code whose parity check matrix H is primarily composed of zeros. LDPC codes can be categorized into regular and irregular LDPC codes. The original Gallager codes are regular binary LDPC codes. The LDPC encoder uses the parity      642   cid:2   Channel coding  check matrix H rather than the generator matrix G. The size of H is usually very large, but the density of nonzero elements is very low. By suitably deﬁning H, decoding of the LDPC code is made easy. When the parity-check matrix H,  n − k  × n, has the same number p of ones in each column and the same number q of ones in each row, the code is a regular  p, q  LDPC code of length n, or denoted as an  n, p, q  LDPC code. Thus, each information bit is involved with p parity checks, and each parity-check bit is involved with q information bits. The fraction of ones in the parity-check matrix is  n−k q = q n, which is very small  n−k n for large block length n. For a regular code, we have  n − k q = np, thus p < q. If all rows are linearly independent, the code rate is  q − p  q, otherwise it is k n. Typically, p ≥ 3. When H has multiple column weights and multiple row weights, we get an irregular LDPC code. When p ≥ 3, there is at least one LDPC code whose minimum distance dmin grows linearly with the block length n [27]; thus a longer code length yields a better coding gain. Most regular LDPC codes are constructed with p and q on the order of 3 or 4. A  n = 20, p = 3, q = 4  code constructed by Gallager [27] is given as  ⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣  1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1  ⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦  .  The matrix is composed of p submatrices, each has a single 1 in each column. The ﬁrst submatrix contains all its 1s in a descending order: the ith row contains all 1s in columns  i − 1 q + 1 to iq. The lower submatrices are column permutations of the ﬁrst subma- trix. Analysis based on all codes constructed in this way shows that for ﬁxed p, the error probability of the optimum decoder decreases exponentially for sufﬁciently low noise and sufﬁciently long block length [27]. The typical minimum distance increases linearly with the block length [27].  The irregular LDPC code achieves better performance than the turbo code and the reg- ular LDPC code. The regular LDPC code can utilize memory more efﬁciently and this simpliﬁes the implementation of the LDPC coder. A method for construction of the parity check matrix for the irregular LDPC code was proposed in [48].      643   cid:2   15.10 Low-density parity-check codes  The LDPC code can be decoded using the iterative soft-decision decoding algorithm based on the factor graph. It is constructed in a random manner, and the complexity of the decoding algorithm is linear in the block length of the code. Like RCPC codes, rate- compatible puncturing LDPCs provide different code rates [32, 75]. For channels with memory in the form of burst erasures, structured LDPC codes are designed in [38].  LDPC code versus turbo code  The LDPC code has better block error performance compared to the turbo code [58], and has no error ﬂoor, whereas error ﬂoors are commonly exhibited in the turbo code. In a sequal, the LDPC code becomes a serious competitor to the turbo code. In fact, the irreg- ular LDPC code has achieved the closest proximity to capacity [62]. The irregular repeat accumulate codes are a class of irregular LDPC codes with linear encoding complexity; they have a performance that is superior to that of turbo codes of comparable complexity and as good as the best known irregular LDPC codes [37].  The LDPC code tends to have a higher encoding complexity than the turbo code, but has a lower decoding complexity than the turbo code. The LDPC code is extremely good in terms of the BER performance for large code block length. This large block length, however, introduces a signiﬁcant decoding delay. The turbo code also has good BER performance, but the error ﬂoor occurs at relatively high BERs. The turbo code is more suitable for medium block size or constraint lengths.  The LDPC code has been adopted in the DVB-S2 standard, which was approved as the replacement of DVB-S by ETSI in 2005. More importantly, the turbo code is a patented technique, while the LDPC patents have expired. There are some hardware implementa- tions of the LDPC codes such as Flarion Technologies’ programmable LDPC decoder, and the LDPC codes for optical networking by Lucent Technologies and Agere. The LDPC code is speciﬁed as an optional channel coding scheme in IEEE 802.16e, 802.11n, and 802.20.  Representation using Tanner graphs  The LDPC code can be visualized by using the Tanner graph [69]. The Tanner graph is a bipartite graph associated with H, where the nodes are divided into two disjoint classes with edges only between nodes in different classes. The information bits are placed on cer- tain variable nodes, and the values for the remaining variables are determined by satisfying all the parity check constraints. Variable nodes correspond to the columns of H, while con- straint nodes correspond to the rows of H. There is an edge  connection  between constraint node i and variable node j, if hij = 1. The number of edges incident upon a node is called the degree of the node. Thus, the bipartite graph of a  p, q  LDPC code has n variable nodes of degree p and m check nodes of degree q. A graph without cycles is said to be acyclic and is called a tree. The length of the shortest cycle in a graph is deﬁned as the girth of the graph.      644   cid:2    cid:2 Figure 15.22  Channel coding  rows  columns  A Tanner graph.  ⎡⎣ 1 0 1 1  0 1 0 0 1 1 0 1  ⎤⎦ .  H =  Example 15.15: Consider  The Tanner graph is shown in Fig. 15.22, where circles denote variable nodes and squares denote constraint nodes. This graph is acyclic.  H = cid:19   cid:22   AT 1 AT 2  ,   cid:20    cid:23   G =  −1 Ik×k A1A 2  .  c = mG.   cid:7    cid:8   n2  15.10.2 LDPC encoder and decoder  LDPC encoder   cid:8  After the selection of the parity check matrix H, we need to calculate the generator matrix G. This can be obtained by using Gaussian elimination and column reordering to transform . Accordingly, the generator matrix can be selected as G =  IP . For  H into ˜H = cid:7 −PTI  an  n,k  LPDC code, if H is espressed as  where A1 is a k ×  n − k  matrix and A2 is an  n − k  ×  n − k  matrix, then  The generated G is usually not sparse. The information is encoded as  , whereas the decoding com- Encoding by matrix multiplication has a complexity of O plexity of the LDPC code is linear with n. Some examples of LDPC codes with encoding complexity of O n  are the irregular repeat accumulate codes [37], and two rate-compatible LDPC codes [41, 79]. In [59], an encoding algorithm at O n  is proposed for systematic codes. Encoding can also be implemented via message-passing [62].  LDPC decoder  Soft information from the observed signals is connected to the variable nodes. The probability of a variable node being in a certain state is then determined for the   15.105    15.106    15.107       645   cid:2   15.10 Low-density parity-check codes  given soft information. Decoding can be done by a procedure of belief or probabil- ity propagation  also known as message-passing  on the Tanner graph [43]. Based on the Tanner graph, decoding can be performed at each node in parallel process- ing. Belief or probability propagation in the Bayesian network was ﬁrst proposed for use in acyclic graphs [55] for modeling human reasoning, but it is applicable in any probabilistic inference problem such as in error control decoding, where the probabilis- tic value of transmitted information symbols needs to be inferred from noisy received symbols.  The sum-product algorithm, ﬁrst proposed in [27],  is a belief propagation algo- rithm for LDPC decoding. It implements probability calculations at each node based on local distributions, and passes a message on to connecting nodes in a factor graph. The sum-product algorithm has three steps: initialization, horizontal step and verti- cal step. It can operate on conditional probability measures or LLR. The use of LLR can reduce the computational complexity substantially. The min-sum algorithm approxi- mates the vertical step using minimum operation rather than summation and hyperbolic functions, leading a further reduction in complexity with a slight performance degra- dation [2]. The optimality of the sum-product algorithm on acyclic  cycle-free  graphs was proved in [69]. A detailed exposition of the sum-product algorithm can be found in [50].  The sum-product algorithm is suboptimal in general. For the LDPC code, the calcula- tions for each bit node are independent of all the other bit nodes, and the calculations for each check node are also independent of all the other check nodes. Thus, all the check nodes and the bit nodes can be potentially implemented in parallel [44]. The sum-product algorithm has a complexity lower than the MAP or the log-MAP algorithm for turbo decoding [44].  The MAP algorithm for standard turbo decoding can be closely approximated by belief propagation on a graph with cycles [53, 62]. For the turbo code, the MAP algorithm requires the serial calculation of all of the state metrics, and this limits its parallel imple- mentation. The optimal decoder for BPSK signals in the AWGN channel is the MAP decoder that computes the LLR and makes a decision by comparing the LLR to the threshold zero.  There are also hard-decision decoding algorithms for the LDPC code, such as the majority-logic decoding [47, 51] and iteratively bit-ﬂipping decoding [27]. The ﬂipping algorithm has a lower complexity but with a reduced performance when compared to the sum-product algorithm. It is more suitable for very-high-speed scenarios such as optical networking. Recent research in the LDPC code has lead to coding systems with lower complexity, yet matching or outperforming the turbo code.  Recent hardware LDPC decoders are capable of throughputs of hundreds of Mbits s. In [40], the FPGA-based LDPC decoder implementation is able to perform 15 decoding iterations with the  1944, 972  code at around 300 Mbits s. The ﬂexible decoder archi- tecture for irregular LDPC codes supports twelve combinations of code lengths and code rates based on the IEEE 802.11n standard. All the codes correspond to a block-structured parity check matrix, in which the sub-blocks are either a shifted identity matrix or a zero matrix.      646   cid:2   Channel coding  15.11 Adaptive modulation and coding  The time-varying wireless channel condition leads to a time-varying system capacity. To achieve the optimum performance, adaptivity in data rate, power control, coding, band- width, antenna, and protocols is necessary. In future generation wireless communication systems, link adaptation such as AMC is necessary.  AMC corresponds to data rate adaptation. It changes the modulation and coding format according to the channel condition. Users close to the BS can be assigned a modulation with a high code rate, while users close to the cell boundary can be assigned a modulation with a lower code rate. However, AMC is sensitive to channel measurement error and delay.  AMC has been deployed in many wireless standards such as GSM, IS-95, wireless LANs, HSDPA, WCDMA and WiMAX, and will also be deployed in 4G standards. It achieves a robust and spectrally efﬁcient transmission over time-varying channels. The transmitter needs to have the CSI before it can adapt its transmission scheme according to the channel condition. The CSI is usually estimated at the receiver, and is then fed back to the transmitter. For a multicarrier system such as OFDM, modulation and or coding can be different for each subcarrier.  The power gain or the received SNR at time i is estimated, this information is then used to adapt the modulation and coding parameters such as the data rate R i , transmit power P i , and coding parameters C i . These parameters are adjusted according to the received SNR at time i.  Some adaptation techniques are described below [31].  Variable-rate modulation  In variable-rate modulation, the data rate R γ   is adjusted according to γ . This is done either by ﬁxing the symbol rate Rs = 1 T but adjusting the modulation schemes or con- stellation sizes, or by ﬁxing the modulation scheme but adjusting Rs. Varying symbol rate Rs leads to a varying signal bandwidth, and this is not practical for bandwidth allocation. Rather, with Rs ﬁxed, changing the constellation size or modulation type is used in current systems such as EDGE, HSDPA, and IEEE 802.11a g. For implementation of variable-rate modulation, the modulation parameters are ﬁxed over a block or frame of symbols.  After the information bit is channel encoded, one of the K M-ary modulation schemes can be selected at the transmitter, based on the short-term channel quality such as SNR measured at the receiver. This channel quality is fed back to the transmitter. According to the level of channel quality, a suitable modulation mode is selected. This is illustrated in Fig. 15.23.  Variable coding  Different channel codes are used for different channel conditions. A stronger error correct- ing code is used when γ is small, and a weaker code or no coding is used for large γ . This      647   cid:2   bit  stream  15.11 Adaptive modulation and coding  Channel encoder  M−ary  modulator  Channel  Processing  M−ary  demodulator  Channel decoder  bit  stream  Transmit  mode control  Transmitter  Feedback CSI  CSI  estimator Receiver   cid:2 Figure 15.23 Model for adaptive modulation and coding. Power control can also included in the transmitter  after the channel modulator module.  technique requires a constant channel over the block length of the code. It is particularly useful for ﬁxed modulation due to the PAPR constraint. The RCPC code also achieves different code rates Rc = k n by not transmitting certain coded bits. RCPC codes can be used for AMC. The code rate change for RCPC codes can be implemented frame by frame or even bit by bit. The RCPC code is used in EDGE.  The instantaneous BER can also be adapted subject to an average BER constraint Pb. The BER is typically adapted along with some other form of adaptation such as data rate. There are also various hybrids of these schemes. The variable rate and power techniques for M-ary modulations have been described in [31]. The objective is to maintain a ﬁxed instantaneous BER for each symbol while maximizing the average data rate by adapting the transmit power and constellation size. Implementation of adaptive coding is also illustrated in Fig. 15.23.  AMC combines adaptive modulation and adaptive coding, and adjusts the data rate according to the channel quality. On poor channels, lower data rates can be achieved by using a small constellation and a robust  low-rate  error-correcting code, while on good channels the higher data rates can be achieved with large constellations and a high-rate error correcting code. The normalized throughput is given by  T =  1 − BLER Rc log2 M  bits s Hz    15.108   where BLER is the block-error rate, Rc ≤ 1, and M is the constellation size.  Variable-power transmission  The variable-power technique is used to compensate for SNR variation due to fading. It aims to achieve a constant received SNR, or equivalently a ﬁxed BEP. The channel inver- sion scheme cannot realize any target Pb for Rayleigh fading, because E[1 γ ] = ∞. The truncated channel inversion scheme inverts the fading above a given cutoff γ0.  Variable frame length  For packet radio, frame length adaptation is also very important [29]. With a large frame length, the goodput of the link can drop to zero if every packet is corrupted. Thus the radio      648   cid:2   Channel coding  1400  1200  1000  800  600  400  200    s   s t i b k     t u p d o o G  0 0  10–8  4 × 10–4   6 × 10–4  10–3  3 × 10–3  200  400  600  800  1000  1200  1400  Frame length  Bytes    cid:2 Figure 15.24 Goodput versus frame length for different BERs [15]. Redrawn from Fig.5a in [15]. c cid:2 1999, IEEE.  will continue transmitting or retransmitting and thereby wasting battery energy. Reducing frame length can increase the goodput and thus the energy efﬁciency due to the reduction of retransmission. However, the relative overhead of the frame header also increases. For a given BER, we can ﬁnd an optimum frame length that maximizes the goodput or minimizes the transmit power in a fading channel [15]. In [15], a goodput versus frame length for different BERs is given in Fig. 15.24, which was obtained from measurements of a real peer-to-peer wireless link. An adaptive radio was designed in [15] that adapted the frame length, error control such as FEC ARQ and SACK, processing gain, and equalization to different channel conditions, while minimizing battery energy. These adaptations can be achieved in MAC layer protocol.  Variable processing gain  In shared bands such as for the CDMA technique, the signal-to-interference ratio  SIR  can be less than 0 dB. The processing gain can be controlled at the link layer. Given a ﬁxed chip rate  baseband bandwidth , if the SIR is greater than a threshold, then the product of the processing gain and the data rate  user throughput  is constant and equals the occupied bandwidth, that is, increasing the processing gain reduces the data rate. For a very low SIR, a large processing gain can be used. For the ﬁxed chip rate, the transmitted power keeps constant, thereby a higher processing gain yields a higher energy per information bit. For an adaptive-processing-gain DSSS radio with a ﬁxed chip rate of 2 Mchips s [15], the result is shown in Fig. 15.25.  For packet radios, changes in frame size, error control, and processing gain used in each frame must be passed by the sender node to the receiver so that it can decode the packets. This may lead to a high signaling overhead. A better solution is to make each packet self- describing, and in this case, no synchronization between the sender and receiver nodes is necessary.      649   cid:2   15.12 ARQ and hybrid-ARQ  100  80  60  40  20    s   s t i b k     t u p h g u o r h T   r e s U  0 –15  PG = 12 dB  PG = 15 dB  PG = 21 dB   cid:2 Figure 15.25 Throughput versus SIR for different processing gains [15]. Redrawn from Fig.12a in [15].  c cid:2 1999, IEEE  –10  –5  SIR  dB   0  5  15.12 ARQ and hybrid-ARQ  HARQ is an important topic for 3G 4G wireless systems. An introduction of ARQ and HARQ is given in this section.  ARQ  ARQ is typically used for packet transmissions in computer networking. For wireless appli- cations, it can be used in WCDMA or WiMAX data services, or wireless networking. ARQ-enabled transmission requires each transmitted packet to be acknowledged by the receiver. Unacknowledged packets are assumed to be lost and are retransmitted. ARQ has three basic types: stop-and-wait ARQ, go-back-N ARQ, and selective-repeat ARQ.  Stop-and-go ARQ is the simplest ARQ. The transmitter waits for an acknowledgement from the receiver. If a positive acknowledgment  ACK  is received, the next message is transmitted; if a negative acknowledgment  NACK  is received, the message is retrans- mitted. Packet retransmission continues until a positive acknowledgment is received. The scheme is not efﬁcient, since the channel stays idle between transmissions. Stop-and-go ARQ is very effective in the presence of high error rates. The throughput is very poor, and is given by [64]  η = K  1 − PB  LB + Rs cid:18 T   bits symbol ,   15.109   where K is the number of bits per block, LB is the block length in symbols, PB is the block error probability, Rs, in symbols s, is the signaling speed over the channel, and  cid:18 T is the overall round-trip delay.  In case of low error rate, go-back-N ARQ is more efﬁcient. Groups of N packets are transmitted, and each group requires only one acknowledgment. When one or more packets      650   cid:2   Channel coding  of a group have been received incorrectly, the last N packets are retransmitted. This method eliminates the waiting period to receive acknowledgment for every packet in stop-and-go ARQ. The throughput for go-back-N ARQ is given by [64]  η = K  1 − PB  LB + Rs cid:18 TPB   bits symbol .   15.110   Selective-repeat ARQ further improves the efﬁciency of go-back-N ARQ, by retrans- mitting only those packets that have not been received correctly. The throughput of selective-repeat ARQ is given by [64]  η = K LB   1 − PB    bits symbol .   15.111   The performance of an ARQ system is measured by its reliability and its throughput  efﬁciency. The reliability is measured by the probability of undetected errors, P E .  For a linear code, let the probabilities of a received codeword containing no error, a detectable error pattern, and an undetectable error pattern be Pc, Pd, and Pe, respectively; of course, Pc + Pd + Pe = 1. A received codeword is accepted only when it contains no error or an undetectable error pattern, thus the probability of the receiver committing an error is given by  P E  = Pe  Pc + Pe  ,   15.112   where Pc is determined by the channel. For a BSC with a transition probability p, Pc =  1 − p n for a codeword of length n, and Pe can also be calculated for the corresponding code.  Example 15.16: A  7, 4  Hamming code is used for error detection in an ARQ system. This code has dmin = 3. There are 24 − 1 = 15 speciﬁc error patterns, corresponding to nonzero codewords. Analysis of the weight structure of the code shows that there are seven codes with Hamming weight 3, seven with 4, and one with 7. The occurrence of these error patterns is undetectable, thus the probability of undetectable error is given by  Pe = 7p3 1 − p 4  + 7p4 1 − p 3 + p7,  where p is the BSC error probability. The probability of correct transmission is  Pc =  1 − p 7.  Accordingly, the probability of detectable error Pd = 1 − Pe − Pc. The block error probability PB of the Hamming code is the probability that two or more errors occur during transmission, as the Hamming code can only correct one error. PB is calculated as 1.0 minus the probability of the occurrence of 0 or 1 error  PB = 1.0 −  1 − p n − n cid:26   p 1 − p i−1.  i=1      651   cid:2   15.12 ARQ and hybrid-ARQ  Hybrid-ARQ  The combination of ARQ and FEC leads to the HARQ scheme. This can eliminate the drawbacks of either scheme. HARQ uses a code that is designed for simultane- ous error detection correction. If the received codeword is detected in error, the receiver will determine whether to correct or request a retransmission according to the error- correction capability of the code. In HARQ, FEC is used to correct the error patterns that occur most frequently. When a less frequent error pattern is detected, a retransmis- sion is requested. This achieves a simple decoder, a high reliability as well as a high throughput.  Unlike in conventional ARQ techniques, where all transmissions are decoded indepen- dently, in HARQ all transmissions associated with the same data block are jointly decoded to reduce the probability of decoding error. Compared with ARQ, HARQ reduces the control delay between transmissions by operating HARQ at the physical layer, and advo- cates efﬁcient and complex signal combining strategies. An optimal combining scheme combines information from all transmissions, without discarding those packets containing errors. For ARQ, a simple one-bit feedback  ACK NACK  can be sent to the transmitter, when the transmitter operates without CSI.  For type-I HARQ, often called chase combining, all retransmissions are identical to the ﬁrst transmission. The receiver combines the current and all previous HARQ transmissions of the data block before decoding it. In noise-limited cases, MRC can be performed.  For type-II HARQ, also called incremental redundancy, the parity-check digits for error correction are transmitted to the receiver only when needed. Two linear codes are used: A high-rate code is for error detection only, while an invertible low-rate code is used for simultaneous error detection correction. The invertible property of the low-rate code enables reconstruction of the message uniquely from the parity block, and only the parity-check digits are transmitted for error correction.  RCPC codes have an advantage with type-II HARQ protocols. A transmitter sends par- tial redundancies by puncturing a mother code based on the CSI. If the receiver fails to recover the message, it progressively requests additional redundancies which were previ- ously punctured. For a given code rate, a punctured code usually has a poorer coding gain than the corresponding dedicated code, which is optimized for that rate. Thus, punctured bits must be chosen such that the performance gap between the dedicated and punc- tured codes is minimized. Likewise, by puncturing bits from a speciﬁc mother code, good rate-compatible LDPC codes of ﬁnite length are obtained, and they achieve a favorable complexity performance tradeoff compared to dedicated LDPC codes [32, 41, 75]. Rate- compatible LDPC codes can also be constructed from a mother code by using puncturing and extending [79], or by combining rows of the lowest-rate parity-check matrix to produce the parity-check matrices for higher rates [13].  Both type-I and type-II HARQ schemes provide a signiﬁcant beneﬁt at low SNR, and type-II HARQ provides higher gain, most prominently for higher code rates [4]. At high SNR, the beneﬁt from HARQ is not signiﬁcant, as the FEC blocks can generally be decoded without error in the ﬁrst transmission. Type-II HARQ leads to lower BER and block error rate  BLER  than type-I HARQ.      652   cid:2   Channel coding  The selective-repeat type-I HARQ is supported in recent 3G standards such as IEEE 802.16e  WiMAX , 1xEV-DO, HSDPA, HSUPA and 3GPP LTE. These standards also optionally support type-II HARQ.  Problems  15.1 Using the CRC-CCITT polynomial, generate the 16-bit CRC code for a message consisting of two 1s followed by fourteen 0s by using long division.  15.2 Consider the  4,3  even-parity code with the 8 codewords  1 1 0 0 ,  0 1 1 0 ,  1 1 1 1 ,  1 0 0 1 ,  0 0 0 0 ,  0 0 1 1 ,  0 1 0 1 ,  1 0 1 0 . Verify that the code is linear.  15.3 A  10,5  LDPC code has the following parity check matrix H:  ⎡⎢⎢⎢⎢⎢⎣  ⎤⎥⎥⎥⎥⎥⎦ .  1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0  ⎡⎣ 1 0 0 1 0 1 1  0 1 0 1 1 1 0 0 0 1 0 1 1 1  G =  ⎡⎣ 1 1 0 1 1 0 0  1 1 1 0 0 1 0 0 1 1 1 0 0 1  H =  ⎤⎦ ,  ⎤⎦ .  Determine the generator matrix G.  15.4 For the  7, 3  code with generator matrix  determine the correctable error patterns and their syndromes.  15.5 A parity-check code has the parity-check matrix  Find the generator matrix and all possible codewords.  15.6 Determine the parity check matrix for the  15, 11  Hamming code.  15.7 Show that the  5,2  linear code with nonzero codewords  0 1 1 0 1 ,  1 0 1 1 1 ,  1 1 0 1 0  is not cyclic.  15.8 Calculate the probabilities of correct decoding Pc, decoding error Pe, and decoding failure Pf for  a  a  4,3  single-parity-check code, and  b  a  4,1  repetition code.      653   cid:2    cid:2 Figure 15.26  Problems  b0  b1  b2  bf  bin  Figure for Problem 15.12  ⎡⎣ 0 0 0 1 1 1 1  0 1 1 0 0 1 1 1 0 1 0 1 0 1  ⎤⎦  H =  15.9 A block code with parity-check matrix  is used for communication over a BSC with 0 < p < 0.5.  a  Find dmin.  b  How many errors can the code correct?  c  How many errors can be detected?  d  For each syndrome, give the error pattern that corresponds to the error-correcting capa- bility of the code.  e  For the received message  0111011 , ﬁnd the codeword based on the maximum- likelihood decision.  15.10 Given a  31, 15  RS code, ﬁnd the number of bits included in each symbol of this code. What is the minimal code distance? How many symbol errors can be corrected? 15.11 Represent the vector y =  11001101011  as a polynomial in D.  Hint: y D  = y0 + y1D + . . . + yn−1Dn−1.   15.12 An LFSR with high-order input is shown in Fig. 15.26. Determine the contents of the register for the input  1 1 0 1 1 0 0 . 15.13 Divide the polynomial m D  = 1 + D5 by g D  = 1 + D + D3 to obtain both the quotient and the remainder.  15.14 The generator polynomials for a convolutional code are given as  g1 = 1 + D + D4,  g2 = 1 + D + D3 + D4,  g3 = 1 + D2 + D4.   a  What is the constraint length of the code?  b  Draw the shift-register encoder.  c  Determine the state number of the trellis diagram of this code.  d  For message m D  = 1 + D + D4 + D5 + D6 + D10, what is the encoder output? 15.15 Develop a ﬂow chart of the Viterbi algorithm for software implementation. 15.16 A convolutional code is generated by g1 = [1, 0, 1], g2 = [1, 1, 1], g3 = [1, 1, 1].   a  Draw the encoder.  b  Draw the state diagram.  c  Draw the trellis diagram for this code.  d  When the convolutional code is transmitted over an AWGN channel with hard-decision decoding, ﬁnd the transmitted sequence for the received sequence  101 001 011 110 .      654   cid:2    cid:2 Figure 15.27  Channel coding  b 1   b 2   a  Figure for Problem 15.17.  15.17 Given a convolutional encoder shown in Fig. 15.27.  a  Draw the trellis corresponding to four information digits.  b  Find the number of codewords represented by the trellis in  a .  c  When the received sequence is  11 01 10 01  over a BSC with 0 < p < 0.5, decode the codeword using the Viterbi algorithm.  15.18 Write a program to implement the pseudorandom interleaver given by  15.82 . Also, write a program to deinterleave the received bitstream.  15.19 Write a MATLAB program to implement the BCJR algorithm.  15.20 Consider a LDPC code deﬁned as the null space of the parity-check matrix  ⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣  1 0 0 0 1 0 1  H =  ⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ .  1 1 0 0 0 1 0  0 1 1 0 0 0 1  1 0 1 1 0 0 0  0 1 0 1 1 0 0  0 0 1 0 1 1 0  0 0 0 1 0 1 1  References  What is the minimum distance of this code? Plot the Tanner graph. Show that the girth of this Tanner graph is 6.  [1] M. A. Abu-Rgheff, Introduction to CDMA Wireless Communications  Oxford, UK:  Academic Press, 2007 .  [2] A. Amastasopoulos, A comparison between the sum-product and the min-sum itera- tive detection algorithms based on density evolution. In Proc. IEEE GlobeCom, Nov 2001, 1021–1025.  [3] J. B. Anderson, T. Eriksson & N. Goertz, On the BCJR algorithm for rate-distortion  source coding. IEEE Trans. Inf. Theory, 53:9  2007 , 3201–3207.  [4] J. G. Andrews, A. Ghosh & R. Muhamed, Fundamentals of WiMAX: Under- standing Broadband Wireless Networking  Upper Saddle River, NJ: Prentice Hall, 2007 .  [5] L. Bahl, J. Cocke, F. Jelinek & J. Raviv, Optimal decoding of linear codes for  minimizing symbol error rate. IEEE Trans. Inf. Theory, 20:2  1974 , 284–287.      655   cid:2   References  [6] S. Benedetto & G. Montorsi, Unveiling turbo codes: some results on parallel  concatenated coding schemes. IEEE Trans. Inf. Theory, 42:2  1996 , 409–428.  [7] S. Benedetto & G. Montorsi, Design of parallel concatenated convolutional codes.  IEEE Trans. Commun., 44:5  1996 , 591–600.  [8] S. Benedetto, D. Divsalar, G. Montorsi & F. Pollara, Serial concatenation of inter- leaved codes: Performance analysis, design, and iterative decoding. IEEE Trans. Inf. Theory, 44:3  1998 , 909–926.  [9] E. R. Berlekamp, Algebraic Coding Theory  New York: McGraw-Hill, 1968 . [10] C. Berrou, A. Glavieux & P. Thitimajshima, Near Shannon limit error-correcting cod- ing and decoding: turbo-codes. Proc. IEEE ICC, Geneva, Switzerland, May 1993, 1064–1070.  [11] C. Berrou & M. Jezequel, Non-binary convolutional codes for turbo coding. Electron.  [12] G. Caire, G. Taricco & E. Biglieri, Bit-interleaved coded modulation. IEEE Trans. Inf.  Lett., 35:1  1999 , 39–40.  Theory, 44:3  1998 , 927–945.  [13] A. I. V. Casado, W.-Y. Weng, S. Valle & R. D. Wesel, Multiple-rate low-density parity- check codes with constant blocklength. IEEE Trans. Commun., 57:1  2009 , 75–83. [14] R. T. Chien, Cyclic decoding procedure for the Bose-Chaudhuri-Hocquenghem codes.  IEEE Trans. Inf. Theory, 10:4  1964 , 357–363.  [15] C. Chien, M. B. Srivastava, R. Jain, P. Lettieri, V. Aggarwal & R. Sternowski, Adap- tive radio for multimedia wireless links. IEEE J. Sel. Areas Commun., 17:5  1999 , 793–813.  [16] A. Chinapol & J. A. Ritcey, Design, analysis, and performance evaluation for BICM- ID with square QAM constellations in Rayleigh fading channels. IEEE J. Sel. Areas Commun., 19:5  2001 , 944–957.  [17] G. Colavolpe, G. Ferrari & R. Raheli, Reduced-state BCJR-type algorithms. IEEE J.  Sel. Areas Commun., 19:5  2001 , 848–859.  [18] U. Dasgupta & C. N. Georghiades, Turbo decoding of quantized data. IEEE Trans.  Commun., 50:1  2002 , 56–64.  [19] S. Dolinar & D. Divsalar, Weight distributions for turbo codes using random and non- random permutations. In TDA Progress Report 42´lC122, Jet Propulsion Laboratory  JPL , CA, USA, Aug 1995, 56–65.  [20] P. Elias, Error-free coding. IRE Trans. Inf. Theory, 4:4  1954 , 29–37. [21] R. M. Fano, A heuristic discussion of probabilistic decoding. IEEE Trans. Inf. Theory,  9:4  1963 , 64–74.  [22] D. Fertonani, A. Barbieri & G. Colavolpe, Reduced-complexity BCJR algorithm for  turbo equalization. IEEE Trans. Commun., 55:12  2007 , 2279–2287.  [23] G. D. Forney, Jr., Concatenated Codes  Cambridge, MA: MIT Press, 1966 . [24] G. D. Forney, Jr., Coding and its application in space communications. IEEE  Spectrum, 7  1970 , 47–58.  25:3  1974 , 222–266.  [25] G. D. Forney, Jr., Convolutional codes II: Maximum likelihood decoding. Inf. Control,  [26] V. Franz & J. B. Anderson, Concatenated decoding with a reduced search BCJR  algorithm. IEEE J. Sel. Areas Commun., 16:2  1998 , 186–195.      656   cid:2   Channel coding  [27] R. Gallager, Low-density parity-check codes. IRE Trans. Inf. Theory, 8:1  1962 ,  21–28.  [28] R. Garello, P. Pierleni & S. Benedetto, Computing the free distance of turbo codes and serially concatenated codes with interleavers: Algorithms and applications. IEEE J. Sel. Areas Commun., 19:5  1995 , 800–812.  [29] S. Glisic, Advanced Wireless Communications: 4G Technologies, 2nd edn  Chich-  ester, UK: Wiley-IEEE, 2007 .  [30] M. J. E. Golay, Notes on digital coding. Proc. IRE, 37:6  1949 , 657. [31] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [32] J. Ha, J. Kim, D. Klinc & S. W. McLaughlin, Rate-compatible punctured low-density parity-check codes with short block lengths. IEEE Trans. Inf. Theory, 52:2  2006 , 728–738.  [33] J. Hagenauer, Rate compatible punctured convolutional codes and their applications.  IEEE Trans. Commun., 36:4  1988 , 389–400.  [34] J. Hagenauer & P. Hoeher, A Viterbi algorithm with soft-decision outputs and its  applications. In Proc. IEEE GLOBECOM, Dallas, TX, Nov 1989, 1680–1686.  [35] J. Hagenauer, E. Offer & L. Papke, Iterative decoding of binary block and convolu-  tional codes. IEEE Trans. Inf. Theory, 42:2  1996 , 429–445.  [36] R. W. Hamming, Error detecting and error correcting codes. Bell Syst. Tech. J., 29:2  [37] H. Jin, A. Khandekar & R. McEliece, Irregular repeat-accumulate codes. In Proc. 2nd.  Int. Symp. Turbo Codes Related Topics, Brest, France, Sep. 2000, 1–8.  [38] S. J. Johnson, Burst erasure correcting LDPC codes. IEEE Trans. Commun., 57:3   1950 , 147–160.   2009 , 641–652.  [39] S. Kahveci, I. Kaya & K. Turk, Dynamic look-up-table-based maximum a posteriori  probability algorithm. Wireless Pers. Commun., 46:3  2008 , 317–328.  [40] M. Karkooti, P. Radosavljevic & J. R. Cavallaro, Conﬁgurable, high throughput, irreg- ular LDPC decoder architecture: tradeoff analysis and implementation. In Proc. IEEE ASAP, Steamboat Springs, CO, Sep 2006, 360–367.  [41] J. Kim, A. Ramamoorthy & S. W. McLaughlin, The design of efﬁciently- encodable rate-compatible LDPC codes. IEEE Trans. Commun., 57:2  2009 , 365–375.  [42] L. Krzymien & C. Schlegel, Turbo decoding with one bit extrinsic quantization. IEEE  Commun. Lett., 9:8  2005 , 732–734.  [43] F. R. Kschischang, B. J. Frey & H. A. Loeliger, Factor graphs and the sum-product  algorithm. IEEE Trans. Inf. Theory, 47:2  2001 , 498–519.  [44] B. Levine, R. R. Taylor & H. Schmit, Implementation of near Shannon limit error- correcting codes using reconﬁgurable hardware. In Proc. IEEE FCCM, Napa Valley, CA, Apr 2000, 217–226.  [45] Y. Li & W. H. Mow, Iterative decoding of serially concatenated convolutional codes over multipath intersymbol-interference channels. In Proc. IEEE ICC, Vancouver, Canada, Jun 1999, 2, 947–951.      657   cid:2   References  [46] T. Li, W. H. Mow & K. B. Letaief, Low complexity iterative decoding for bit-interleaved coded modulation. IEEE Trans. Wireless Commun., 5:8  2006 , 1966–1970.  [47] J. Lin & D. J. Costello, Jr., Error Control Coding: Fundamentals and Applications,  2nd edn  Upper Saddle River, NJ: Pearson Prentice Hall, 2004 .  [48] M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman, Improved low-density parity-check codes using irregular graphs. IEEE Trans. Inf. Theory, 47:2  2001 , 585–598.  [49] D. J. C. MacKay & R. M. Neal, Near Shannon limit performance of low density parity  check codes. Electron. Lett., 32:18  1996 , 1645–1646.  [50] D. J. C. MacKay & R. M. Neal, Good error-correcting codes based on very sparse  matrices. IEEE Trans. Inf. Theory, 45:2  1999 , 399–432.  [51] J. L. Massey, Threshold Decoding  Cambridge, MA: MIT Press, 1978 . [52] J. L. Massey, Foundations and methods of channel coding. In Proc. Int. Conf. Inf.  Theory & Syst., NTG-Fachberichte, Berlin, Germany, Sep 1978, 65, 148–157.  [53] R. J. McEliece, D. J. C. MacKay & J.-F. Cheng, Turbo decoding as an instance of Pearl’s ‘belief propagation’ algorithm. IEEE J. Sel. Areas Commun., 16:2  1998 , 140–152.  [54] J. E. Meggitt, Error correcting codes and their implementation for data transmission  systems. IRE Trans. Inf. Theory, 7:4  1961 , 232–244.  [55] J. Pearl, Fusion, propagation, and structuring in belief networks. Artif. Intell., 29:3  [56] J. G. Proakis & M. Salehi, Digital Communications, 5th edn  New York: McGraw-   1986 , 241–288.  Hill, 2008 .  [57] R. M. Pyndiah, Near optimum decoding of product codes: block turbo codes. IEEE  Trans. Commun., 46:6  1998 , 1003–1010.  [58] T. J. Richardson, M. A. Shokrollahi & R. L. Urbanke, Design of capacity-approaching irregular low-density parity-check codes. IEEE Trans. Inf. Theory, 47:2  2001 , 619–637.  [59] T. J. Richardson & R. L. Urbanke, Efﬁcient encoding of low-density parity-check  codes. IEEE Trans. Inf. Theory, 47:2  2001 , 638–656.  [60] P. Robertson, E. Villebrun & P. Hoeher, A comparison of optimal and sub-optimal MAP decoding algorithms operating in the log-domain. In Proc. IEEE ICC, Seattle, WA, Jun 1995, 1009–1013.  [61] P. Robertson, P. Hoeher & E. Villebrun, Optimal and sub-optimal maximum a poste- riori algorithms suitable for turbo-decoding. Euro. Trans. Telecommun., 8:2  1997 , 119–125.  [62] C. B. Schlegel & L. C. Perez, Trellis and Turbo Coding  Piscataway, NJ: IEEE Press,  [63] C. E. Shannon, A mathematical theory of communication. Bell Syst. Tech. J., 27  [64] A. U. H. Sheikh, Wireless Communications: Theory and Techniques  Boston, MA:  2004 .   1948 , 379–423, 623–656.  Kluwer, 2004 .      658   cid:2   Channel coding  [65] B. Sklar, A primer on turbo code concepts. IEEE Commun. Mag., 35:12  1997 ,  [66] B. Sklar, Digital Communications: Fundamentals and Applications, 2nd edn   Englewood Cliffs, NJ: Prentice Hall, 2001 .  [67] G. L. Stuber, Principles of Mobile Communication, 2nd edn  Boston, MA: Kluwer,  94–102.  2001 .  [68] O. Y. Takeshita & D. J. Costello, Jr., New deterministic interleaver designs for turbo  codes. IEEE Trans. Inf. Theory, 46:6  2000 , 1988–2006.  [69] R. M. Tanner, A recursive approach to low complexity codes. IEEE Trans. Inf. Theory,  [70] H. Taub & D. L. Schillings, Principles of Communications Systems, 2nd edn  New  27:5  1981 , 533–5547.  York: McGraw-Hill, 1986 .  [71] S. ten Brink, Rate one-half code for approaching the Shannon limit by 0.1 dB.  Electron. Lett., 36:15  2000 , 1293–1294.  [72] S. ten Brink, Convergence behavior of iteratively decoded parallel concatenated  codes. IEEE Trans. Commun., 49:10  2001 , 1727–1737.  [73] C. Thomas, M. A. Bickerstaff, L. M. Davis, T. Prokop, B. Widdup, G. Zhou, D. Garrett & C. Nicol, Integrated circuits for channel coding in 3G cellular mobile wireless systems. IEEE Commun. Mag., 2003, 150–159.  [74] G. Ungerboeck, Channel coding with multi-level phase signals. IEEE Trans. Inf.  Theory, 28:1  1982 , 55–67.  [75] B. N. Vellambi & F. Fekri, Finite-length rate-compatible LDPC codes: a novel  puncturing scheme, IEEE Trans. Commun., 57:2  2009 , 297–301.  [76] A. J. Viterbi, Error bounds for convolutional codes and an asymptotically optimum  decoding algorithm. IEEE Trans. Inf. Theory, 13:2  1967 , 260–269.  [77] A. J. Viterbi, An intuitive justiﬁcation and a simpliﬁed implementation of the MAP decoder for convolutional codes. IEEE J. Sel. Areas Commun., 16:2  1998 , 260–264. [78] J. K. Wolf, Efﬁcient maximum-likelihood decoding of linear block codes using a  trellis. IEEE Trans. Inf. Theory, 24:1  1978 , 76–80.  [79] M. R. Yazdani & A. H. Banihashemi, On construction of ratecompatible low-density  parity-check codes. IEEE Commun. Lett., 8:3  2004 , 159–161.      16  Source coding I: speech and audio coding  16.1 Introduction  Source coding or data compression is used to remove redundancy in a message so as to maximize the storage and transmission of information. In Chapter 14, we have introduced Shannon’s source-coding and rate-distortion theorems. We have also introduced lossless data compression based on the source-coding theorem. In Chapters 16 and 17, we will address speech audio and image video coding. Lossy data compression is obtained by quantizing the analog signals, and the performance of quantization is characterized by the rate-distortion bound. Source coding is the procedure used to convert an analog or digital signal into a bitstream; both quantization and noiseless data compression may be part of source coding.  16.1.1 Coding for analog sources  Source coding can be either lossy or lossless. For discrete sources, a lossless coding tech- nique such as entropy coding is used. Huffman coding is a popular entropy coding scheme. Lossless coding uses more radio spectrum. For analog sources, lossy coding techniques are usually used.  PCM is a digital representation of an analog signal. The signal magnitude, sampled regularly at uniform intervals, is quantized to a series of symbols in a digital, usually binary code. This can be performed by using A D converters. The demodulation of PCM signals can be performed by DACs. The PCM code is the original waveform for source coding. There are three approaches to source coding.  Waveform coding  The waveform coder uses fewer bits to encode the original PCM waveform. Increasing the bit rate will asymptotically lead to lossless transcoding of the original PCM waveform. A coding error signal can be deﬁned as the difference between the original and decoded waveforms. Waveform coding can be either temporal or spectral waveform coding. These coders typically work at a bit rate of 16 kbits s and above.  Temporal waveform coding is the most fundamental source coding technique. A tempo- ral PCM waveform can be encoded by using the differential PCM  DPCM , adaptive PCM, delta modulation  DM , or continuous variable slope DM  CVSDM  technique.      660   cid:2   Source coding I: speech and audio coding  Spectral waveform coding can be either sub-band coding or adaptive transform coding. In sub-band coding, the signal is divided into a few sub-bands and the temporal wave- form in each sub-band is encoded separately. For speech signals, the low-frequency bands contain more energy and also the human ear is more sensitive to low-frequency bands; thus lower-band signals should be assigned more bits. The QMF [35] is gener- ally used. The lower band is repeatedly subdivided by a factor of two, each subdivision using a pair of QMFs. The signal in each sub-band can be encoded by an adaptive PCM algorithm.  Transform coding can be treated as a kind of sub-band coding. In adaptive transform cod- ing, the signal is sampled and subdivided into frames of a number of samples. Each frame is transformed into the frequency domain for coding and transmission. The Karhunen- Loève transform is optimum since it generates uncorrelated spectral values [10]. DFT and DCT also yield good performance. DCT achieves a performance very close to that of the Karhunen-Loève transform, and is generally used for speech and image coding [5]. DWT is a subset of sub-band decomposition, in which the transformed representation pro- vides an intrinsic multiresolution data structure. All these transform coding techniques are used for speech and image coding. Due to the Gibbs phenomenon in linear ﬁlters, DCT and DWT introduce artifacts, called the ringing effect, at high compression factors  around 50 .  Model-based coding  Model-based coders use an explicit source model with a small set of parameters. Such coders can achieve a very low rate transmission. The source is modeled as a linear ﬁl- ter; instead of transmitting the samples of the source waveform to the receiver, the ﬁlter parameters as well as an appropriate excitation signal are transmitted. This leads to a large compression ratio. Since the decoded waveform is not synchronized with the input wave- form, the waveform error signal is not suitable for characterizing the performance of the model-based coder.  Linear predictive coding  LPC  and mixed excitation linear prediction  MELP  are two model-based coding techniques. The model-based speech coding techniques are gener- ally called vocoders  voice coders . For speech coding, the model-based coding approach generates a very low bit rate.  Hybrid coding  Hybrid coding combines the waveform and model-based coding techniques. The resid- ual waveform, which is the prediction error in a predictive signal model, is transmitted using a waveform coder, while the model parameters are quantized and transmitted as side information. The code-excited linear prediction  CELP  vocoder and its many vari- ants, including the residual excited linear prediction  RELP , the multipulse LPC, and the vector-sum excited linear prediction  VSELP  vocoders, are hybrid coding techniques. This class of vocoders dominates medium-bit-rate speech coding.      661   cid:2   16.2 Quantization  16.2 Quantization  Quantization is applied to waveform samples or model parameters. It can be scalar quanti- zation or vector quantization  VQ . For scalar quantization, each of the multiple variables is quantized independently of one another. VQ is an extension of scalar quantization to multi-dimensions. VQ combines d variables and jointly quantizes them to a single value  codeword . At the decoder, each codeword is restored to a prototype vector.  16.2.1 Scalar quantization  Given a random variable x with a known pdf px x , we ﬁnd a set of M quantization levels that minimizes the MSE distortion   cid:14  ∞  cid:23   cid:8 2  cid:7   cid:8 2 = min where ˆx is one of the M quantization levels ˆxi, and   cid:22  cid:7  x − ˆx  cid:7   D = E  x − ˆx  =  −∞ px x   x − ˆxi  i   cid:7   cid:8 2 .   cid:8 2 dx,  x − ˆx   16.1    16.2   The optimum solution is the Lloyd-Max algorithm. The performance measure of the quantizer is SQNR.  The different quantization levels are collectively known as the codebook, and each quan- tization level is called a codeword. The codebook can be designed based on the Lloyd-Max algorithm by using a set of training data. For the Lloyd-Max quantizer, the codewords are the centroids over the decision intervals. Each parameter to be quantized is compared with a codebook where the codewords are stored, and the codeword closest to the parameter is selected as the quantized value. The scalar quantizer is illustrated in Fig. 16.1a. Scalar quantization has been treated in more detail for the uniform quantizer in Subsection 12.3. Scalar quantization is generally used in speech coders standardized prior to 1994. It is used in LPC-based vocoder standards such as TIA IS54 VSELP, ETSI GSM RPE-LTP  reg- ular pulse excitation with long-term prediction , and FS1015 LPC, as well as in waveform codecs such as PCM and adaptive differential PCM  ADPCM .  x x5 x4 x3 x2 x1  x2  x6  x5  x7  x8  x1  x4 x2 x3  x9   cid:2 Figure 16.1  Scalar quantization and vector quantization.  a  Scalar quantizer  1-D .  b  Vector quantizer  2-D .  x1  x2  x4  x5  x  x3  a   x1   b       662   cid:2   Source coding I: speech and audio coding  16.2.2 Vector quantization  The vector quantizer maps an input vector signal onto a ﬁnite set of reproduction vectors, collectively known as the codebook. For a multi-dimensional pdf p x , the MSE distortion is deﬁned as   cid:14  ∞  cid:7  x − ˆx 882 = min where ˆx is one of the M quantization levels ˆxi, and   cid:22 88x − ˆx  cid:23  882 88x − ˆx   cid:8 T cid:7  882 . 88x − ˆxi  D = E  −∞  x − ˆx  p x dx,   16.4    16.3    cid:8   =  i  The optimum solution can be derived in the same manner as that for the Lloyd- Max quantizer. The codewords are the centroids over the decision regions. VQ for the two-dimensional case is also illustrated in Fig. 16.1b.  When the joint pdf is obtained from a ﬁnite set of input vectors, the C-means algorithm is obtained as the optimal VQ algorithm, where C is the number of codewords. The Linde- Buzo-Gray  LBG  or generalized Lloyd algorithm is a batch implementation of C-mean. VQ is very powerful and it can produce results very close to the theoretical limit. Com- pared to scalar quantization, codebook generation for VQ is computationally very complex. Dozens of online C-mean and VQ algorithms that are based on competitive learning have been described in [10].  For a given distortion, the size of the codebook can be signiﬁcantly reduced, compared to scalar quantization. This leads to a lower number of bits for coding. This advantage is obtained by exploiting the correlation among different components of the vectors. There- fore, a transformation of the vector that reduces this correlation decreases the advantage of VQ. In addition, VQ provides ﬂexibility in partitioning high-dimensional space.  Shannon showed that VQ with an increasing d can achieve the rate-distortion bound for source coding [27]. VQ is now being used in most of the recent vocoders for quantizing the linear prediction coefﬁcients and in image video codecs.  Some VQ strategies  ˆx = k cid:26   y k  ik  1  Multistage VQ of a vector x has K codebooks. In the encoder, at each stage, the input vector x is compared with   16.5   for k = 1, 2, . . . , K, where y k  is the ikth codevector from the kth stage codebook. The principle is very similar to that of the SAR A D converter. The output is an index set {i1, i2, . . . , iK} that minimizes the distance between x and ˆx. Multistage VQ and its codebook design are discussed in [7].  ik  A predictive VQ scheme can be used to eliminate the correlation between consecutive vectors that are to be quantized, as an extension of the DPCM in the scalar case. Other popular VQ methods are split VQ and conjugate VQ. Split VQ simply splits the vector      663   cid:2   16.3 Speech production and auditory systems  into n subvectors, so that the search of each subvector is performed independently in its codebook. Split VQ has n codebooks. The conjugate VQ can be treated as a special two- stage VQ. The two codebooks are conjugate in some sense [7]. Conjugate VQ is effective to reduce the quantization distortion for a noisy channel.  16.3 Speech production and auditory systems  16.3.1 Speech production  Through speech, information is communicated from a speaker to a listener. Speech consists of acoustic sound waves produced by the human speech production system, which consists of the lungs, trachea  windpipe , larynx  organ of voice production , vocal tract, and nose. The vocal tract is comprised of the oral cavity from the larynx to the lips  the throat and mouth ; the nose as well as the nasal passage is often called the nasal tract. The vocal tract takes on different lengths and cross-sections during speech activity. It has an average length of 17 cm in a typical adult male and is shorter for females, and the varying cross-section can be up to 20 cm2.  Speech signals are nonstationary, and they can be considered quasi-stationary over a very short period, typically 5–20 ms. Speech can be voiced  e.g.,  a: ,  e  , unvoiced  e.g.,  f ,  sh  , or mixed. Voiced speech is quasi-periodic in the time domain and has a harmonic structure in the frequency domain, while unvoiced speech is more like noise and with a broad bandwidth. The vocal cord does not participate in the voice production of unvoiced speech. The unvoiced sounds can be classiﬁed as fricatives  e.g.,  th  , plosives  e.g.,  p ,  t  , and whispered  e.g.,  h  . The mixed sounds can be voiced fricatives  e.g.,  z   or voiced plosives  e.g.,  b  . The energy of the voiced speech segments is generally higher than that of the unvoiced segments.  Spectrograms  A speech waveform consists of a sequence of sounds. A single Fourier transform of the entire waveform cannot capture its time-varying frequency content. The short-time Fourier transform is a Fourier transform of pieces of the waveform under a sliding window. The spectrogram is a graphical representation of the magnitude of the time-varying spectrum, and is given by  S ω, τ   = X ω, τ  2,   16.6   where X ω, τ   is the short-time Fourier transform of the speech signal x n . There are two kinds of spectrograms: narrowband and wideband, arising from the length of the window. Narrowband spectrograms give good spectral resolution, while wideband spec- trograms give good temporal resolution. A narrowband spectrogram is obtained by using a long window, typically with a duration of at least two pitch periods, while a wideband spectrogram uses a window with a duration less than a single pitch period.      664   cid:2   Source coding I: speech and audio coding  e d u t i l p m A  1  0  −1  0  y c n e u q e r F  4000 2000 0  0.1  0.2  0.3  0.4  0.5  Time  s   0.25 Time  0.05  0.1  0.15  0.2  0.3  0.35  0.4  0.45   cid:2 Figure 16.2  −70  −60  −50  −40  −30  −20  −10  0  10  20  A male speech of “Beep!” and its spectrogram.  Example 16.1: A male speech of “Beep!” and its spectrogram are shown in Fig. 16.2. Here fs = 8000 samples s, the FFT length is 256. A Hanning window of 128 is employed. Peaks in the spectrum appear as dark red horizontal bands, which correspond to formant resonances.  Speech production modeling   16.7    16.8   Human speech production can be modeled by three separate sections, namely the source excitation, vocal-tract shaping, and the effect of speech radiation  S z  = U z H z R z ,  where U z  denotes the voice waveform, H z  the dynamics of the vocal tract, and R z  the radiation effect. The vocal-tract transfer function can be modelled by an all-pole model  1 − cid:24  The source excitation can be u n  =  cid:24 ∞  H z  =  1 i=1 aiz−i M  .  q=−∞ δ n − qT , T being the peak time of the  pulse, for the voiced case, and be a zero mean, unitary variance, uncorrelated noise for the unvoiced case.  Note that IIR ﬁlters are more popular for speech synthesis since the human auditory system is not sensitive to phase information. The vocal tract can be modeled by a series of uniform lossless acoustic tubes [9]. To approximate this vocal tract model using an all-pole synthesis ﬁlter, the delay should be at least twice the time for the sound travel along the tract. Given a vocal tract of 17 cm long, the sound speed of 340 m s, and a sampling rate of 8 kHz, the corresponding ﬁlter order should be at least 8, which corresponds to 8 taps of 0.125 ms, or 1 ms. The sound propagation in the vocal tract during speech production is usually modeled by representing the vocal tract as a concatenation of short lossless uniform acoustic tubes.      665   cid:2   16.3 Speech production and auditory systems  Pitch and formants  Voiced speech is characterized by a set of resonant frequencies, which depend on the shape and physical dimensions of the vocal tract. The nominal center frequencies of the reso- nances are referred to as formants by speech scientists, since they form  or shape  the spectrum. The ﬁrst three formants fall below 3000 Hz for adult speakers. For most vowels, the formant frequency is near 2600 Hz, and the ﬁrst two formants can be used to distinguish vowels.  For voicing, the rate of vibration is called the fundamental frequency of phonation, also known as pitch. The pitch for men is typically in the range of 50–250 Hz, while for women and children the range is from 120–500 Hz [7, 9]. The period of pitch for a male is between 4 and 20 ms, while for a female it is 2 to 8 ms [7]. Everyone has a habitual pitch level, and the pitch is shifted up and down in speaking due to stress, intonation, and emotion. Pitch and formants are two important parameters for speech analysis, synthesis, and coding. The human ear is very sensitive to pitch estimation errors, but is relatively tolerant to errors in formant frequencies.  The basic unit for describing how speech conveys linguistic meaning is called a phoneme. Vowels are voiced speech sounds and are normally among the phonemes of largest amplitudes. Vowels can be distinguished by the location of the ﬁrst three formant frequencies. An overview of the fundamentals of speech science is given in [9].  Most speech codecs are bandlimited to the conventional 300 to 3400 Hz telephone band, sampled at 8 kHz, and then converted to 16-bit linear PCM for further process- ing. All vocoders attempt to model the speech generation process as a dynamic physical system.  16.3.2 Psychoacoustics  Human hearing system  The auditory system is composed of the outer ear, middle ear, and inner ear. Sounds enter the eardrum through the auditory canal in the outer ear, resulting in vibrations of the eardrum. The eardrum is connected to the middle ear. The middle ear is composed of three interconnected bones, which transform the vibrations of the eardrum to the inner ear by the oval window. The inner ear has a cochlea, which is a coiled, snail-like tube and is ﬁlled with ﬂuid. Vibrations of the eardrum result in a compression sound wave in the cochlear ﬂuid via the oval window. The compression wave causes a vertical vibration of the basilar membrane. Different regions of the basilar membrane respond maximally to different fre- quencies. The cell bodies embedded within the membrane will cause a chemical reaction that causes a ﬁring of short-duration electrical pulses in the nerve ﬁbers. The electrical pulses ﬁnally reach the auditory processing region in the brain along the auditory nerve, and are perceived as sound.  The human ear can hear sounds in the range of 20 Hz to 20,000 Hz. In the Human audi- tory system, one sound may mask the perception of another sound. Masking is a prominent feature of human audio perception. Masking can be spectral or temporal. This can be used      666   cid:2   Source coding I: speech and audio coding  to reduce the bit rate in a compression scheme. The human ear is sensitive only to the magnitude spectrum of the speech, and not to the phase. Retaining some phase information, however, adds naturalness to the synthetic speech.   cid:2    cid:3 2  p p0  Sound intensity and loudness  The human hearing system can sense a sound pressure ranging from 10 = 1 N m . This range is usually deﬁned as the sound pressure level  SPL   −5 to 100 Pa  1 Pa  SPL = 10 log10   16.9  where p0 = 20 μPa is roughly the sound pressure at the hearing threshold at frequencies around 2 kHz [3, 36]. The sound intensity I is proportional to p2.   dB ,  The hearing sensation is the loudness of the sound. The loudness of an audio signal depends on its duration, its temporal and spectral structure, as well as its intensity. A high frequency tone at a lower intensity level may have the same loudness as a low frequency tone at a higher intensity level. The loudness level of a test tone is deﬁned as the loudness of the sound relative to the level of a 1-kHz sound tone. It is determined by adjusting the level of a 1-kHz tone until it sounds equally as loud as the test stimulus, and the level above the threshold of the 1-kHz tone is the loudness level of the test stimulus. The unit of loudness level in decibels is the phon.  The unit of loudness L, the sone, is deﬁned as the loudness of a binaural 1-kHz tone at 40-dB sound pressure level above the hearing threshold. Above the hearing threshold, the loudness L and intensity I are related by [3]  L ∝ I0.3.   16.10   That is, the loudness is doubled when the intensity is increased tenfold.  Hearing threshold  The hearing threshold is the lowest sound level that can be heard at a given frequency. The hearing threshold for 20 year old subjects can be approximated by [31]   cid:2    cid:3 −0.8 − 6.5e   cid:17   −0.6  −3.3  f  1000   cid:2    cid:18 2 + 10  −3   cid:3 4  f  1000  SPL = 3.64  f  1000   dB .   16.11   This is plotted in Fig. 16.3. For frequency below 2 kHz, the threshold is independent of age. Above 2 kHz, the curve shifts upward as the age grows. Given the limit of human hearing, more hearing loss at higher frequency occurs with age.  This curve is extremely important for audio coding since frequency components in a signal that are below this level do not need to be transmitted. The quantization noise in frequency components cannot be perceived by the human hearing system, as long as it is below the hearing threshold.      667   cid:2   16.3 Speech production and auditory systems  160  140  120  100  80  60  40  20  0     B d     L P S  −20  10−2   cid:2 Figure 16.3  10−1  100 frequency  kHz   101  The hearing threshold for 20 year old subjects.  SPL  dB   Masking threshold  Masker  Masking threshold  Hearing threshold   cid:2 Figure 16.4  Frequency masking: A loud signal masks signals at nearby frequencies.  Frequency  Masked signals  Masking phenomenon  Masking of soft sounds by louder ones is embodied in human hearing. Masking can be either frequency or temporal masking. Temporal masking is the dominant effect for sounds with transients, while frequency masking is dominant in steady state conditions.  Given a masker at a frequency, a masking threshold is generated for those frequencies at both sides of the masker. This is illustrated in Fig. 16.4. Thus, frequency masking tem- porarily raises the hearing threshold in the spectrum near the masker. These maskees are not perceived by the human hearing even if they are well above the hearing threshold. The masking threshold in a critical band is given in [16].  Temporal masking corresponds to masking that occurs prior to and after the presence of the masker. Pre-masking is unexpected since it occurs before the masker is switched on, while post-masking has a stronger effect and has a much longer duration. Premask- ing tends to last only about 5 ms, whereas postmasking extends anywhere from 50 to      668   cid:2   Source coding I: speech and audio coding  300 ms, depending upon the strength and duration of the masker [36]. A good monograph on psychoacoustics is [36].  16.4 Speech audio quality  The audio or visual quality of a coding system can be examined by subjective or objec- tive methods. Subjective methods are based on listening and viewing tests, by comparing the original and processed speech video data. Since speech and videos are perceived by the human auditory and visual systems, listening and viewing tests are very reliable in the evaluation of codecs. However, their cost is very high, it is time consuming, and normally they give little insight for the improvement of a coding algorithm.  Objective methods can quantify performance over a variety of scales, and can assist in the improvement of a coding algorithm, but its usefulness lies in its correlation with sub- jective testing. Objective measures provide a quantitative, repeatable, and accurate means of codec performance evaluation. These measures are only meaningful for comparing sim- ilar algorithms applied to the same original speech or image. They provide mathematical tractability. However, for speech and images, the human auditory and visual perception features are also widely used to compare the performance of compression algorithms, and thus are used for compression. The human auditory and visual systems depend on the fre- quency, and this makes sub-band coding popular. Usually, objective measures are used at the development stage of a speech or video coding algorithm, while subjective measures are used to verify the ﬁnal design.  To evaluate the quality of speech audio codecs, a test vector can be generated from the TIA acoustic database [32]. Both speech and noise ﬁles of the database have been preprocessed by a modiﬁed-IRS  intermediate reference system  ﬁlter to emulate the trans- fer function of the telephone network. They are sampled at 8 kHz and linear quantized in 16 bits per sample. The database assumes two types of background noise: street and car noise. Clean speech is mixed digitally with the same length of noise with different SNRs.  Noise cancellation may be required prior to speech audio coding. For audio signals, due to the wide variation in the amplitude, median ﬁlter or other outlier elimination techniques [10], which are very effective for eliminating impulse noise in images, yield poor perfor- mance. The median ﬁlter may mistake a true signal as impulse noise. For speech signals, impulse noise removal can be performed by using linear prediction models. Active noise cancellation, which generates a controllable secondary source to compensate a noise in a certain spatial region, can also be applied [34].  16.4.1 Subjective quality measures  The most reliable and most popular performance measure is the mean opinion score  MOS , which is a subjective evaluation and is deﬁned in ITU-T Rec. P.800. Listeners      669   cid:2   16.4 Speech audio quality  Table 16.1. MOS ﬁve-point scale.  Rating  Speech quality  distortion level  5 4 3 2 1  Excellent Good Fair Poor bad  Imperceptible Perceptible but not annoying Perceptible and slightly annoying Annoying but not objectionable Very annoying and objectionable  Excellent  Good  MOS  ITU4  G.723  G.728  G.729 G.729A  GSM−EFR  IS−641  IS−54  GSM−FR  PDC−HR  GSM−HR  MELP  Fair  PDC−FR  IS−96  FS1016  PCM  G.727 G.726  G.711  FS1015  Poor  2   cid:2 Figure 16.5  Subjective speech quality of some speech codecs. From [12] c cid:2 IEEE, 2001  4  8  16  32  64  128  bit rate [kbit s]  are requested to group the quality of the encoded decoded speech into ﬁve categories, that is excellent, good, fair, poor, or bad, with values ranging from 5 to 1. The MOS ﬁve-point scale is given in Table 16.1.  The MOS for the coder is the average of all the numeric ratings. If the variance of the MOS value is too large, the test is unreliable. A value between 4.0 to 4.5 is considered toll quality, such as for the ITU-T G.711 standard.  Other subjective measures include the diagnostic rhyme test  DRT  and diagnostic acceptability measure  DAM . DRT measures intelligibility, and DAM provides a more complete quality evaluation.  Subjective speech quality comparison of speech codecs  A comparison of the subjective speech quality of some of the speech codecs has been made in [12], and is illustrated in Fig. 16.5. These codecs are described in the follow- ing sections. In the ﬁgure, ITU4 denotes the future 4 kbits s ITU codecs. The target performance for ITU4 is also shown. Note that all ITU codecs achieve an MOS of above 4.0.      670   cid:2   Source coding I: speech and audio coding  16.4.2 Objective quality measures  Objective quality assessment is based on a mathematical comparison of the original and processed signals. The distortion introduced by the compression process can be characterized by the MSE or the mean absolute difference  MAD, or MAE, mean abso- lute error  between the original {sn} and reconstructed sequences. The MSE is most widely used, and is deﬁned by  5  σ 2 d  = 1 N  sn − ˆsn   16.12   where N is the length of the sequence.  4ˆsn  cid:8 2 ,  N cid:26    cid:7   n=1  SNR  SNR is a simple and common measure for evaluating the performance of a compression algorithm based on waveform coding. It is deﬁned by  SNR = 10 log10 = 10 log10  σ 2 s σ 2 d   cid:24    cid:24    cid:19   M−1 n=0  M−1 n=0 s2 n  s n  − ˆs n    cid:20 2   dB ,   16.13   where s n  and ˆs n  are the original and decompressed signals, respectively. This measure is for long-term characterization of a codec, with very large M.  The SNR measure is unable to give equal weighting to high- and low-energy speech segments. Instead, its value is dominated by the SNR of the higher-energy voiced speech segments. The SNR measure is often used for waveform coding schemes such as the PCM and ADPCM.  SNR is a poor estimator for a broad range of speech distortions, since it  is not related to any subjective attribute of speech quality and because the method weights all the time-domain errors in the waveform equally [9]. In addition, since the human auditory system is insensitive to phase distortion, encoders based on the speech spectrum focus only on the magnitude of the speech spectrum. As a con- sequence, although the decoded time-domain speech is perceived to be very similar by the listener, it can be quite different from the original, making the SNR measure meaningless.  Segmental SNR  Segmental SNR  SEGSNR  is a frame-based measure that characterizes the time-varying speech by averaging over a number of N-point speech segments      671   cid:2   16.4 Speech audio quality  L−1 cid:26  L−1 cid:26   i=0  i=0  SEGSNR = 1 L = 10 L  SNRi  10 log10   cid:24   cid:19  N−1 n=0 s2 iN + n  s iN + n  − ˆs iN + n    cid:20 2   cid:24   N−1 n=0   dB ,   16.14   where L is the number of frames, each of length N.  Compared to the SNR measure, SEGSNR gives a fairer weighting to low-energy unvoiced segments by computing the geometric mean of the SNR values instead of the arithmetic mean. Thus, the SEGSNR measure penalizes more the coders with varying performance. It correlates better with subjective speech quality measures.  Problems can arise when using the SEGSNR measure if frames of silences are included, since this leads to large negative SEGSNR. The silent periods can be detected and then excluded from the SEGSNR calculation. Another method to eliminate the inﬂuence of silence is to set a lower threshold for all frames with lower SEGSNR. At the other extreme, frames with SEGSNR greater than 35 dB cannot be perceived by listeners as being very similar, and thus an upper threshold of 35 dB can be used to replace any larger SEGSNR values.  Like SNR, SEGSNR is meaningful only for waveform coders. Both SNR and SEGSNR are extremely sensitive to waveform alignments and phase distortions. For most vocoders, the original waveform cannot be preserved after synthesis. SNR and SEGSNR are thus not applicable, since they do not account for the perceptual properties of the human ear. For example, the 32 kbits s ADPCM codec has a SEGSNR of about 28 dB, while the 13 kbits s GSM RPE-LTP codec has a SEGSNR of about 16 dB, but both have a MOS of about 4.0 [12].  Other measures  Frequency-domain codecs can be best characterized in terms of spectral distortion between the original and processed speech signals. The articulation index  AI  measure splits the speech band into 20 sub-bands and computes the sub-band SNRs, and takes the average of the sub-band SNRs. The cepstral distance  CD  measure is highly correlated with subjec- tive measures. It is deﬁned in terms of the cepstral coefﬁcients of the original and processed speech signals  9 cid:17    cid:18 2 + 2  ∞ cid:26    cid:17   i=1  :1 2   cid:18 2  ,  CD =  − cout  0  cin 0  − cout  i  cin i   16.15   where the cepstral coefﬁcients of the input and output speech can be obtained from the LPC coefﬁcients ai [12].  Research on perceptual objective measurement has made much progress and percep- tual objective measurement has become an important complement to the assessment of audio codecs. Perceptual objective measurement predicts the basic audio quality by incor- porating psychoacoustic principles. The PEAQ  perceptual evaluation of audio quality       672   cid:2   Source coding I: speech and audio coding  measurement is an objective measurement that is conducted in conjunction with formal listening tests, and is adopted by ITU as ITU-R BS.1387.  The PESQ  perceptual evaluation of speech quality  algorithm was standardized in 2001 by the ITU’s Telecommunication Standardization Sector  ITU-T  as Rec. P.862, which is suitable for end-to-end measurement of telecommunication networks. PESQ demon- strates high superiority over other perceptual objective measures for various wireless, ﬁxed networks and VoIP  voice over IP  codecs, under a variety of background noise and language conditions. For 22 known ITU-T benchmark tests, 69.2% and 91.3% of the prediction errors are within 0.25 and 0.50 MOS, respectively. The average corre- lation between PESQ and the subjective MOS is 0.935 [15]. PESQ is not suitable for evaluation of noise-reduction algorithms, since it is not designed to evaluate loudness loss.  PEAQ and PESQ are intrusive methods that use a listening-only model. Intrusive tests inject a reference signal into the network under test, so as to produce a MOS rating by comparing it with the signal that is being tested. Other factors related to two-way con- versations, such as delay and echo are not considered. Thus, it is possible to have a high objective MOS, but the overall speech quality could still be poor.  Nonintrusive methods need no reference signal. They are not as accurate as their intru- sive counterparts, but they are useful where the reference signals are inaccessible, such as in monitoring live network speech quality. Nonintrusive methods are based on an analysis of degraded speech signals, voice packet header information, or voice and network param- eters. Nonintrusive methods are quite challenging because of the absence of a reference signal. ITU-T Rec. P.563, standardized in 2004, is the ﬁrst ITU-T single-ended method for predicting the subjective quality in narrowband telephone networks. P.563 generates a subjective MOS. It reconstructs a pseudo reference, and this complicates implementation compared to PESQ, though they have similar application coverage. For 24 known ITU-T benchmark experiments, the average correlation between P.563 and subjective MOS scores was 0.88 [14].  Many subjective and objective measures are described in [9].  16.5 Speech coding  For a raw sound ﬁle, which is pure binary recordings of eight-bit input data, experiments show that simple Huffman coding produces more compression than LZSS dictionary cod- ing in all the simulated cases [21]. This is because LZSS is effective when there are repeated strings of characters in the ﬁle, while Huffman coding is effective in case of overall frequency differences for individual sequences. In typical sound ﬁles, there are some overall frequency differences between the various codes, but not as many repeated strings.  When applying lossy compression to speech coding, a lossless stage usually follows. This is because lossy compression frequently smoothes out the data, making it more suitable for lossless compression.      673   cid:2   16.5 Speech coding  Major standard bodies for standardizing speech coders are ITU-T, the TIA of the ANSI, and the ETSI. For each standard, a reference source code, most commonly in the ﬂoating- point C language, is usually provided with the standard for the encoder and the decoder. The reference source code is very general, and can be modiﬁed for a speciﬁc platform. The developer still needs to transform it into ﬁxed-point C code or DSP assembly code. A set of test vectors are also provided for veriﬁcation of the implementation. Various speech coders used in 2G wireless standards and their resource requirements are listed in [17].  A classic tutorial on speech coding is given in [28], and two excellent texts on speech  coding and speech standards are [7] and [12].  16.5.1 Logarithmic PCM coding  Uniform quantization used in PCM is undesirable when signal amplitudes are not uni- formly distributed over the entire dynamic range of the signal. In this case, a nonuniform quantizer provides a better solution. The amplitude of a signal is ﬁrst compressed using a nonlinear device, and the compressed signal is then subjected to a uniform quantizer. At the receiver, the inverse of the nonlinear element used in the transmitter is used to restore the signal.  The speech signal is band-limited to between 300 Hz and 3400 Hz. For digital telephony, analog speech is sampled by using the PCM format at a sampling frequency of 8 kHz. Due to the large dynamic range of the human voice, a resolution of 12 or 13 bits is required in a telephone conversation. Each sample is quantized into 12- or 13-bit linear PCM format, which is encoded by a logarithmic compression system, to 8 bits; this gives a 64 kbits s digital signal known as DS0  Digital Signal 0 . Depending on the logarithmic relation, we get either the μ-law  mu-law  PCM  North America and Japan  or the A-law PCM  Europe and most of the rest of the world . This nonlinear quantization method is called compand- ing  compressing-expanding . This system is described by ITU-T G.711. The MOS speech quality is 4.3 out of 5.  The A-law is deﬁned by  ⎧⎨⎩sgn x  1+ln Ax   1+ln A , 1 A < x < 1 sgn x  Ax 0 < x < 1 A 1+ln A ,  ,  F x  =  vpeak  where x = v is the normalized input, and sgn x  is the signum function. A is com- monly adopted as 87.6, and this yields a 24 dB improvement on SQNR over linear PCM for small signals  x < 1 A  and a relatively constant SQNR of 38 dB for large signals  x > 1 A . The method compresses 13-bit linear PCM into 8-bit companded PCM. The A-law is normally implemented into a 13-segment piecewise linear approximation. The 8-bit PCM speciﬁes the location on the segment.  The μ-law is similar to the A-law. It slightly improves SQNR for voice signals compared  to the A-law, but with a slightly reduced dynamic range. The μ-law is deﬁned by   16.16   F x  = sgn x   ln 1 + μx  ln 1 + μ   ,   16.17       674   cid:2   Source coding I: speech and audio coding    x   F  1  0.8  0.6  0.4  0.2  0  0  A = 1 or µ = 0 A = 87.6 A = 1000 µ = 255 µ = 4000   cid:2 Figure 16.6  0.2  0.4  0.6  0.8  1  x  The A-law and μ-law.  where μ = 255 is selected in G.711, resulting in about 24 dB improvement on SQNR over linear PCM. The method compresses 12-bit linear PCM into 8-bit companded PCM. The μ-law uses 15-segment piecewise linear approximation.  Example 16.2: The A-law and μ-law are plotted in ﬁg. 16.6. For μ = 0 or A = 1, there is no compression. The two laws are almost identical when A = 87.6 and μ = 255. They are also very close when A = 1000 and μ = 4000.  The logarithmic compression achieves a very desirable property: It ensures a con- stant SNR across the signal’s dynamic range, regardless of the shape of the pdf of the signal [12]. That is, a large signal may have a large error, while a small signal must have a small error. The SNRs for the A-law and μ-law companders are, respectively, given by [12]  SNRμ = 6.02R + 4.77 − 20 log10 ln 1 + μ   SNRA = 6.02R + 4.77 − 20 log10 1 + ln A    dB ,   dB .   16.18    16.19   16.5.2 Linear prediction analysis and synthesis  LPC compresses speech by modeling the vocal tract that produces the speech. LPC is basically an auto-regressive model. The minimum-phase ﬁlter is selected to be an all-pole ﬁlter. This selection uses poles to shape its frequency response. These poles decide the frequency peaks, and human perception is more sensitive to spectral peaks than to valleys. The signal model can thus be written, in the z-transform domain, as      675   cid:2   16.5 Speech coding  X z  = U z  A z   ,   16.20   x n  = − m cid:26   where X z  denotes the speech signal, U z  the excitation signal, and 1 A z  the ﬁlter. The equivalent representation in the time domain is given by  aix n − 1  + u n ,   16.21  where m is the order of the ﬁlter or predictor, and ai, i = 1, 2, . . . , m, are known as the LPC coefﬁcients, and a0 = 1. For speech sampled at 8 kHz, m is selected as 10.  i=1  For each speech frame, ai’s are estimated, and the prediction error signal is given by  e n  = x n  − ˆx n  = m cid:26    cid:8    cid:7 ˆai − ai  i=1  x n − i  + u n .   16.22   For uncorrelated excitation u n , the quadratic function of the prediction error signal is minimized when ˆai = ai, i = 1, 2, . . . , m, leading to e n  = u n . For short-time stationary speech, for every frame with N samples, a window of L ≥ N samples is used, and there is overlap between windows. Minimizing the windowed squared error function yields a system of linear equations for ˆai. Estimation of the LPC coefﬁcients is based on the minimization of the MSE criterion   cid:22    cid:23   J = E  e2 n   = E  ⎡⎣ cid:12  x n  − m cid:26   i=1   cid:13 2  ⎤⎦ .  aix n − i    16.23   = 0, for k = 1, 2, . . . , m. This  The optimal LPC coefﬁcients can be found by setting ∂J ∂ak leads to  m cid:26   aiRx i − k  = −Rx k ,  k = 1, 2, . . . , m,  i=1   16.24  where the autocorrelations Rx i − k  = E[x n − i x n − k ] and Rx k  = E[x n x n − k ]. In matrix form, we obtain the normal equation Rx a = −rx,   16.25   ⎛⎜⎜⎜⎝ Rx 0   Rx 1  Rx 1  Rx 0  ... Rx m − 1  Rx m − 2   ...  Rx =  ⎞⎟⎟⎟⎠ ,  ··· Rx m − 1  ··· Rx m − 2  ... ···  ... Rx 0    16.26   where  a =  a1, a2, . . . , am T, and rx =  Rx 1 , Rx 2 , . . . , Rx M  T. The optimal LPC coefﬁcient vector a can be solved from the normal equation  16.25  by ﬁnding the matrix inverse for Rx. This linear equation can generally be solved by using      676   cid:2   Source coding I: speech and audio coding  l  kl = −a l  + kla l  l−i 1 − k2  ,  l  Gaussian elimination or similar linear algebra algorithms. By taking advantage of the spe- cial structure of Rx, efﬁcient algorithms such as the Levinson-Durbin algorithm can be used. The Levinson-Durbin algorithm is an iterative-recursive process that ﬁnds the solution to the mth-order predictor from that of the  m − 1 th-order predictor. For the deriva- tion of the algorithm, the reﬂection coefﬁcients  RCs  ki are deﬁned, which are an alternative representation of the LPC coefﬁcients. A one-to-one correspondence exists between the set of RCs and the set of LPC coefﬁcients [7]. The Levinson-Durbin algo- rithm is given in [7, 12]. In speech coding, estimation for a is performed for each frame. The RCs ki, i = 1, . . . , M, can be derived from ai, i = 1, . . . , M. For l = M, . . . , 1, [7]  16.27   ,  a l−1   i  = a l   i  i = 1, . . . , l − 1,   16.28   i  .  where ai = a M  The Levinson-Durbin algorithm is computationally very efﬁcient. Also, it generates a set of RCs ki, which can be used for the veriﬁcation of the minimum-phase property of the prediction-error ﬁlter A z . The prediction-error ﬁlter A z  is a minimum-phase system if and only if all the associated RCs satisfy ki < 1 [7]. When A z  is a minimum-phase system, all its zeros are within the unit circle in the z-plane. Thus, the inverse system 1 A z  has all its poles inside the unit circle, and this guarantees the stability of the inverse system.  The Levinson-Durbin algorithm relies on the values of the LPCs, which may be over a large dynamic range and have no known bound. This may cause difﬁculties for ﬁxed- point implementation, and careful planning is necessary to ensure all variables to be within the allowed range [6]. The Leroux-Gueguen algorithm provides a method to compute RCs from the autocorrelation values directly, and thus is suited for ﬁxed-point implementa- tion. The Levinson-Durbin algorithm is generally more popular than the Leroux-Gueguen algorithm [6, 7].  The RCs are good candidates for quantization, since the stability of the quantized value can be veriﬁed from its magnitude. When ki’s approach unity, they require more bits for quantization, since the spectral sensitivity function tends to be very large. Thus nonlinear quantization is desirable. The LAR is a nonlinear transform of RCs   16.29   Quantization  Log area ratio  LAR    cid:2    cid:3   .  1 + ki 1 − ki  f  ki  = log10  The LAR is subject to a uniform quantization.      677   cid:2   16.5 Speech coding  R A L  4  3  2  1  0  −1  −2  −3  −4   cid:2 Figure 16.7  −1  −0.5  0.5  1  0 ki  The LAR function.  Example 16.3: The LAR function is plotted in Fig. 16.7. Although LAR takes on value from −∞ to ∞, from the ﬁgure, when ki = 0.99, LAR = 3.3. Thus, the value of LAR is practically very limited. For ki < 0.7, the LAR function is almost linear, the quantization performance in the RC domain is similar to that in the LAR domain using a uniform quantizer, and we can apply uniform quantizer in the RC domain. Typically, ki < 0.7 for i > 3 [7]; in this case, high sensitivity for large ki is eliminated.  Each of the LPC coefﬁcients can be assigned a different number of bits for scalar quan- tization to represent the quantized codebook index. For example, in IS-54 VSELP, the ten RCs are quantized using 6, 5, 5, 4, 4, 3, 3, 3, 3, 2 bits, respectively, yielding a total of 38 bits frame. Another nonlinear transformation is the inverse sine transformation Si = sin −1  ki . The 5.6 kbits s half-rate  HR  GSM codec implements the VQ of Si.  Line spectral frequency  LSF   LSF is another alternative representation of the LPC coefﬁcients. LSFs are also known as linear spectral pairs  LSPs , since zeros in the prediction-error ﬁlter A z  occur in complex conjugate pairs. Two polynomials P z  and Q z  are deﬁned according to A z   P z  = A z  1 + G z  , Q z  = A z  1 − G z  ,   cid:8   .   cid:7   −1 z A z   G z  = z  − m+1  A   16.30    16.31   where      678   cid:2   LSFs are deﬁned as those values of frequency ω such that  Source coding I: speech and audio coding   cid:7    cid:8  = 0 or Q   cid:7   ejω   cid:8  = 0  P  ejω   16.32   with 0 < ω < π. For real coefﬁcients, the zeros occur in complex conjugate pairs. If A z  is minimum-phase, all the zeros of P z  and Q z  are on the unit circle, and they are interlaced with each other. During quantization, if the interlacing property is preserved, the stability of the synthesis ﬁlter is guaranteed. The LSF representation has a beneﬁt that the LPC coefﬁcients and RCs do not have, namely, modiﬁcation to one LSF has a local effect on the PSD. The LSFs are suitable for quantization, and they are highly suitable for ﬁxed-point representation since they are within the  0, 1  interval. The conversion between LSFs ωi, i = 1, . . . , M, and LPC coefﬁcients ai, i = 1, . . . , M, are given in [7]. The LSFs are an efﬁcient means to represent spectral envelopes, and become the dominant LPC representation for modern speech coders. In FS1016 CELP, scalar quantization of the LSFs is applied, where quantization is implemented on cos ω, with a interval of [−1, 1]. LSF VQ is used in most state-of-the-art vocoders including 8 kbits s G.729 ACELP  algebraic codebook excited linear prediction , dual-rate G.723.1 MP-MLQ  multipulse maximum likelihood quantization  ACELP, FS MELP, GSM EFR  enhanced full rate  ACELP, and the 7.4 kbits s IS-136 codec. Major techniques for LSF VQ are split VQ, multistage VQ, and predictive VQ. Split VQ is usually used, since its implementation complexity is low, but it has some performance degradation. Multistage VQ is used in FS MELP. In G.723.1 MP-MLQ ACELP, predictive VQ with split structure is used. In G.729 ACELP, a combination of multistage VQ, split VQ, and PVQ- MA  predictive VQ with moving average  with switched predictor is employed. In ETSI GSM EFR ACELP, a combination of PVQ-MA and split VQ is used. In the IS-136 codec, split VQ is used.  Interpolation of LPC coefﬁcients  For each frame, LPC coefﬁcients are obtained by linear prediction analysis. Since each frame has a period of 20 to 30 ms, rapid changes in the LPC coefﬁcients for adjacent frames can introduce undesirable transients in the synthesized speech signal. One method to deal with this is to subdivide the frame into subframes, and perform interpolation of the LPC coefﬁcients between these subframes. Interpolation of the LPC coefﬁcients is implemented in various standards such as TIA IS-54 VSELP, ETSI GSM RPE-LTP, and FS1016 CELP. Due to the stability problem, interpolation of the LPC coefﬁcients is usually performed on the RC, LAR, or LSF parameters. The LSF provides the best interpolation performance [7].  Long-term linear prediction analysis  A typical tenth-order linear predictor is not capable of accurately modeling the voice sig- nal with a pitch period of 50 samples. By increasing the prediction order to include one pitch period, the periodicity in the prediction error is substantially removed, leading to an increase in the prediction gain. However, this results in an excess bit rate as well as complexity.      679   cid:2   16.5 Speech coding  x n   eA n   e n   A z   m− Σ i = 1  aiz−i  Short-term predictor  −  +  HLT z  −  −bz−T Long-term predictor  +   cid:2 Figure 16.8  The cascade of a short-term prediction  STP -error ﬁlter to a long-term prediction  LTP -error ﬁlter.  The traditional solution is to cascade a short-term predictor with a long-term predic- tor, as shown in Fig. 16.8. The short-term predictor, as we discussed so far, typically has a relatively low prediction order m in the range of 8 to 12, to eliminate the correlation between nearby samples. The long-term prediction-error ﬁlter eliminates correlation between samples that are one pitch period apart.  The input to the long-term ﬁlter is the error generated from the short-term predictor and it produces the ﬁnal output error e n . The long-term prediction-error ﬁlter has a transfer function  HLT z  = 1 + bz  −T,  where T is the pitch period, and b is the long-term LPC coefﬁcient, also known as pitch gain. The second term bz  The long-term linear prediction aims to minimize  −T is known as the long-term predictor.  cid:22   N cid:26    cid:23    eA n  + beA n − T  2 ,  J = E  e2  = 1 N  n=1  where eA n  is the error generated from the short-term predictor A z . The optimal pitch gain can be derived by setting ∂J ∂b   cid:24  = 0, yielding  cid:24  n eA n eA n − T  b = − A n − T  n e2  .  The optimum LTP parameters can be obtained by computing J over all possible values of T, typically 20 to 147 samples, for a sampling rate of 8 kHz [12].  The synthesis of the received speech signal is the inverse of the analysis process. It can be based on the LPC coefﬁcients extracted from the original signal by using a synthesis ﬁlter  Linear prediction synthesis  H z  = 1 A z   =  1 + cid:24   1 i=1 aiz−i M  .  For the analysis process, as long as the prediction error is close to a white noise, the estimated LPC coefﬁcients are satisfactory. At the synthesis stage, when the excitation is a white noise with unit variance, the synthesis ﬁlter will generate the synthesized speech.   16.33    16.34    16.35    16.36       680   cid:2   Source coding I: speech and audio coding  e n   1 A z   1 HLT z   ˆ x[n]  e n   ˆ x n   G   a   G  −bz−T Long-term predictor   b   Σ m− aiz−i i = 1 Short-term predictor   cid:2 Figure 16.9  The cascade of a long-term synthesis ﬁlter and a short-term synthesis ﬁlter for speech production. e n  is a unit variance white noise.  a  The simpliﬁed model.  b  The expanded model.  Similarly, the long-term linear prediction model can also be taken into consideration.  The long-term or pitch synthesis ﬁlter is given by 1  HLT z  =  1 + bz−T .   16.37   In this case, the short-term synthesis ﬁlter is known as the formant synthesis ﬁlter.  The overall speech synthesis  production  model is shown in Fig. 16.9. The gain G in Fig. 16.9 can be obtained by comparing the power level of the synthesized speech. It is given by [7]   cid:28  cid:29  cid:29  cid:30 Rx 0  + m cid:26   i=1  G = γ  aiRx i ,   16.38   where γ is a scaling constant, whose value depends on the type of window selected, typically ranging from 1 to 2. We now discuss the stability of the two synthesis ﬁlters. As discussed earlier, for the short-term synthesis ﬁlter, as long as the RCs satisfy ki < 1, A z  is a minimum-phase ﬁlter; then 1 A z  has all its poles inside the unit circle of the z-plane, thus guaranteeing its stability. For the long-term synthesis ﬁlter, we can easily derive that in order to keep the ﬁlter stable the pitch gain must satisfy b < 1.   cid:2    cid:3   σ 2 x σ 2 e  Prediction gain   cid:2    cid:3    cid:12    cid:19   cid:19    cid:20  cid:13   cid:20   The prediction gain of a predictor is deﬁned by  PG = 10 log10  = 10 log10  Rx 0  Re 0   = 10 log10  E E  x2 n  e2 n    dB .   16.39   Prediction gain can be deﬁned for frame m, PG m . Similar to SEGSNR, the segmental prediction gain is the average of the prediction gains for many frames.  16.5.3 Predictive coding  Predictive coding eliminates the redundancy in the data by using values previously coded, and only codes the prediction error. This method is also known as DPCM. If the prediction      681   cid:2   16.5 Speech coding  error is not quantized, a lossless coding scheme using entropy encoding can be applied; if it is quantized, any further coding will yield lossy coding. At the decoder, the received error signal is added to the prediction and the signal is reconstructed.  Delta modulation  Delta modulation  DM  uses the difference between two successive PCM samples. The difference can usually be coded in fewer bits than the value of the samples themselves. In the simplest case, the difference is represented by only 1 bit denoting ±1 PCM step. When the prediction error d n  = x n  − ˆx n  is not less than 0, the output ˆx n + 1  is increased by δ, where ˆx n  is the predicted value and x n  is the incoming data sequence; otherwise, it is decreased by δ  ˆx n + 1  = ˆx n  ± δ.   16.40   This method has the slope overload problem. That is, when the signal has a slope above ±δ T, where T is the sampling period, the system is not capable of track- ing the signal. The slope overload problem can be overcome by oversampling or increasing the step size. The former reduces the advantage of using delta modula- tion, while the latter causes the granularity problem; these problems are illustrated in Fig. 16.10.  DM is not suitable for speech signals, due to the wide variation in amplitudes of sounds. Adaptive delta modulation is used to alleviate the problems in delta modulation. The CVSDM technique is a particularly effective and popular technique.  DPCM and ADPCM  DPCM is an extension of the delta modulation, but uses a quantizer with p values. A block diagram of the DPCM encoder and decoder is shown in Fig. 16.11. The predictor for predicting the future value of a signal is of a high order, and is commonly implemented as an FIR ﬁlter. The error between the actual and predicted values are quantized. The predictor is implemented as the linear weighted sum of the previous samples  i.e., a transversal digital ﬁlter .  Granular problem   cid:2 Figure 16.10  Slope overload  Illustration of the slope overload and granularity problems.      682   cid:2   PCM   Σ  +   cid:2 Figure 16.11  Encoder  Quantizer  Predictor  Σ  +  +  Source coding I: speech and audio coding  bitstream  bitstream  Channel  Entropy coder  Decoder  Entropy decoder  +  Σ  +  Predictor  PCM  The DPCM encoder and decoder.  In time-domain waveform coding, the scalar quantization should be adaptive for opti- mal performance for nonstationary signals such as speech, which has a wide dynamic range. In the adaptive PCM technique, two types of adaptive quantizers are used, namely, the forward gain-adaptive quantizer and backward gain-adaptive quantizer. The forward-adaptation method can accurately control the gain level of the input sequence, but the gain must be sent to the decoder. In the backward-adaptation technique, the gain is estimated from the quantizer output, to be trans- mitted. However, a transmission error will lead to forward error propagation. When the adaptation techniques are applied to the DPCM, the resulting system is called ADPCM.  thus the gain need not  The forward-adaptation scheme introduces a delay, since the processing requires to collect a sufﬁcient number of samples. This delay may generate echo and annoying arti- facts. Backward adaptation is preferred in those applications that have strict restriction on delay. However, in the backward-adaptation scheme, the predictor coefﬁcients are deter- mined from the previously recovered speech, and the frequency of the LPC coefﬁcient update is limited by the codec complexity. The autocorrelation method and the Levinson- Durbin algorithm can also be used to solve the ﬁlter coefﬁcients in adaptive forward predictive DPCM. Some backward-adaptation standards are ITU-T G.721, G.726, G.727, and G.728.  G.721 deﬁnes the ADPCM scheme. A series of 8-bit nonuniform PCM samples  G.711  is mapped onto a series of 4-bit ADPCM samples, reducing the data rate to 32 kbits s. This codec is popular due to its very low implementation complexity and its high speech quality. G.721 ADPCM is used in several cordless telephone systems such as CT2, DECT, PHS, and PACS.  G.726 and G.727 are two derivatives of G.721, and both can operate at transmission rates of 16, 24, 32 and 40 kbits s. G.721 has an attractive feature: its decoder can operate without prior knowledge of the transmission rate. This feature is useful in packeted speech transmission. G.727 is an embedded ADPCM codec, in which the decision levels of the lower-rate codec constitute a subset of those of the higher-rate codecs. A codeword is composed of core bits that must be decoded and enhancement bits that can be discarded by the coder.  Time-domain waveform encoding techniques, such as PCM, DPCM, ADPCM, DM, and adaptive DM, attempt to faithfully represent at the output the waveform from the source. Scalar quantization is used for these time-main predictive coding techniques.      683   cid:2   16.5 Speech coding  16.5.4 Frequency-domain waveform coding  Frequency-domain waveform coding ﬁlters a speech signal into a number of subbands, and separately encodes the signal in each sub-band. In sub-band coding, the signal is typically divided into four to eight sub-bands. Since the lower-frequency bands contain most of the spectral energy in voiced speech, more bits are assigned to the signals in the lower-frequency bands. The QMF bank can be used for subband coding [33]. The lower-frequency band can be repeatedly subdivided by a factor of two.  N4   cid:8    cid:7   Transform coding is similar to sub-band coding. It is a block coding technique. A frame of samples is transformed into the spectral domain for coding. At the decoder, the spec- tral samples are subject to the inverse transform and the speech signal is synthesized. The transform from the time domain to the frequency domain aims at obtaining uncor- related spectral samples. The Karhunen-Loève transform is optimal in the sense that it produces uncorrelated outputs. For a block of N samples, conventionally, the Karhunen- operations [9]. The Karhunen-Loève Loève transform requires a complexity of O transform can be effectively solved using the adaptive principal component analysis  PCA  method [10], which reduces the complexity to O Nn  operations, where n is the number of iterations. DCT is a suboptimal solution and is generally used. Transform coding can achieve toll-quality speech at 16 kbits s, and communication-quality speech at 9.6 kbits s. Wideband speech covers the range of 50 Hz to 7 kHz, with a quality similar to that of an FM radio. The sampling rate is 16 kHz. G.722 is a standard for wideband speech, and is used in the H.323 video-conferencing standard. It separates the speech into two sub- bands and uses ADPCM to code each band. G.722.1 and G.722.2 are two wideband speech codecs. G.722.1 employs the ﬁlter bank method by using two QMFs, and it performs well for speech and audio, operating at 64 kbits s. G.722.2 is the adaptive multi-rate wideband  AMR-WB  speech coder standardized by 3GPP. G722.2 is based on ACELP.  16.5.5 Voice activity detection  During the conversation of two persons, when one person speaks, the other person is silent. Statistics show that speech activity occupies only 3 8 of all the connection time [4]. In order to save radio spectrum, it is desirable to transmit speech frames over the air interface only when the person is actively speaking. This requires voice activity detection. The idea behind voice activity detection is that there is more energy in lower frequencies in the voiced speech than in the voiceless speech in the same band. Silence compression is the equivalent of RLE on data ﬁles.  Discontinuous transmission at the inactive speaker also leads to less power consump- tion and lower interference to other users. This is implemented by switching off speech transmission after several nonactive frames, and a silence descriptor  SID  frame is sent as a model for regeneration of a comfort noise at the receiver. At the encoder, the com- fort noise generation algorithm extracts the noise parameters, namely, the residual energy level and the spectrum of the background noise, to form the silence descriptor packets. At the decoder, the noise information contained in the silence descriptor packets is used to      684   cid:2   Source coding I: speech and audio coding  generate the comfort noise. The voice activity detection algorithm is computationally very intensive. It employs both the energy and LPC analyses, with the latter requiring a great deal of computations.  In GSM, when the user speaks, the speech is encoded at 13 kbits s. Otherwise, it is encoded at 500 bits s. At the receiver, some comfort noise is generated when no sig- nal is received. At the beginning of the nonactive period, a silence descriptor frame is transmitted, followed by interval transmission of silence descriptor frames, at least two frames per second, until the nonactive period is over. The ETSI AMR  adaptive multi- rate  codec utilizes discontinuous transmission, with voice activity detection and comfort noise generation to reduce bandwidth usage during the silence periods. Some earlier voice activity detection algorithms were implemented in G.729 Annex B  G.729B  and G.723.1 Annex A. There are some algorithms that provide better performance than that of G.729B [8, 18].  16.5.6 Linear predictive coding  Within each frame, the speech signal is a sample function of a stationary stochastic pro- cess. The Wold decomposition guarantees that a stationary stochastic process can be decomposed into the sum of a regular component xr n  and a singular component xs n   x n  = xr n  + xs n .   16.41   The regular term is a ﬁltered noise term that cannot be perfectly predicted by using a linear system, and the singular term is a sum of sinusoids that can be perfectly predicted by a linear system. The regular component can be represented as white noise passing through a linear ﬁlter. The linear ﬁlter is required to be causal and stable, and have a causal and stable inverse. Such a ﬁlter is a minimum-phase ﬁlter. This same ﬁlter is used for gen- erating the singular component, which can be modeled by a periodic pulse train passing through the linear ﬁlter. The linear predictive vocoder is an important stochastic model for speech.  Vocoders are based on modeling the speech production system using an all-pole model of the vocal tract. The classical LPC vocoder is shown in Fig. 16.12. For voiced speech, the excitation is a periodic impulse train with a period that is equal to the pitch period of the speech. For unvoiced speech, it is a white noise sequence. The model parameters are the voicing status, gain, LPC coefﬁcients, and pitch period. The voicing status uses one bit to denote whether the frame is voiced or unvoiced. The pitch period is estimated only for voiced frames. A encoder estimates the model parameters for every frame, quantizes and codes them, and then sends them to the receiver for speech reconstruction. The decoder is essentially the linear predictive model of speech production with parameters controlled by the bitstream.  In LPC, speech is classiﬁed as voiced and unvoiced. A frame with clear periodicity is treated as voiced, and a frame with noise-like appearance is treated as unvoiced. LPC requires a strict voice unvoiced classiﬁcation. The voiced speech has an energy concen- tration in the low-frequency band, since the pitch frequency is generally less than 500 Hz.      685   cid:2   16.5 Speech coding  x n   Preprocess  LPC STP analysis  Quantize  LPC  coefficients  Voiced  unvoiced decision  Pitch  detection  LPC coefficients  Pitch period  Voice unvoiced flag Gain RMS error  Noise source  Pulse source   a   Unvoiced  Voiced   b   x n   1 A z   LPC STP synthesis  Gain   cid:2 Figure 16.12  The traditional LPC vocoder.  The zero-crossing rate is also relatively low for voiced speech. These features can be used for voice detection.  Most vocoders assume the speech signal to be fairly constant over a time of approxi- mately 20 ms. LPC is a popular vocoding method, and it typically achieves communication- quality speech at data rates ranging from 2.4 to 9.6 kbits s. The FS1015 LPC  LPC-10  codec is a U.S. Government standard that uses 10 coefﬁcients. LPC-10 achieves a bit rate of 2.4 kbits s.  Speech quality in LPC can be improved by computing and encoding a residual error  as in DPCM , leading to a higher bit rate. This is implemented in the RELP vocoder, which provides communication-quality speech at about 9.6 kbits s.  Example 16.4: Given the original speech of 6 seconds long, the synthesized waveform using the LPC algorithm is shown in Fig. 16.13. The frame length is 25 ms.  Very-low-bit-rate coding  There are a number of problems with the LPC technique [7]. First, transition frames cannot be simply classiﬁed as voiced and unvoiced, otherwise artifacts like buzzes and tonal noises will be generated. Secondly, synthesis of voiced and unvoiced speech using strictly periodic pulse train or strictly random noise is not a true representation of the real speech. Also, no phase information of the original speech is captured by the model.  The MELP coder overcomes some of the problems of the LPC technique such as the buzzy problem [20]. It utilizes a more complex and accurate speech production model. The excitation signal is a combination of a ﬁltered periodic pulse sequence with a ﬁltered noise sequence. The MELP coder classiﬁes the speech into voiced, unvoiced, and jittery      686   cid:2   Source coding I: speech and audio coding  l a n i g i r  O  d e z i s e h t n y S  1  0  1  0  −1  0  −1  0  1  1  2  2  3  3 t  s   4  4  5  5  6  6   cid:2 Figure 16.13  The original speech and the LPC synthesized waveform.  voiced. Due to the use of VQ, the MELP coder does not elevate the overall bit rate of LPC. The FS MELP coder operates at 2.4 kbits s.  The zinc-basis function excitation  ZFE  waveform can efﬁciently model the LPC STP residual while reducing the buzziness of the synthesized speech. A prototype waveform interpolation  PWI  ZFE speech coder achieves a bit rate of 1.9 kbits s [12]. The mixed- multiband excitation  MMBE  technique addresses the buzziness problem of the LPC coder by splitting the speech into multiple frequency bands on a frame basis. MMBE can be added to the LPC vocoder or the PWI-ZFE coder to yield a very-low-bit-rate voice com- pression, as low as 1.85 kbits s. Sinusoidal transform coding, such as PWI and MMBE, is frequently used for bit rates of less than 4 kbits s. The three voiced excitation methods, namely ZFE, MMBE, and sinusoidal transform coding, have been found to have similar performance [12].  16.5.7 Pitch period estimation  One of the most important parameters in speech analysis, synthesis, and coding is the pitch of the voiced speech. Estimation of pitch makes sense only for voiced frames, since unvoiced frames have random nature. Accurate pitch detection is one of the most dif- ﬁcult problems in speech analysis, especially when the Fourier component at the pitch frequency is missing, as in the case of telephone communications. For vocoders that require the estimation of pitch, an accurate estimation of the pitch period is of a prime concern, since the human ear is sensitive to pitch estimation errors. Checking for pitch doubling and halving together with pitch tracking are frequently performed for pitch detection.  The simplest method for pitch estimation is the pitch picker that picks the prominent peaks of the signal or its envelope. This method may ﬁnd successive pitch periods, but the peak locations may be shifted by the formant frequencies, leading to a quavery voice in the synthesized speech signal. Popular pitch detection methods are the autocorrelation-based method and the cepstrum method. The dyadic wavelet transform is also used for voiced, unvoiced, and transient speech classiﬁcation, and for pitch detection [12].      687   cid:2   16.5 Speech coding  Autocorrelation-based method  m cid:26   R l, m  =  s n s n − l ,  n=m−N+1  Pitch can be estimated by using the short-time autocorrelation method. By calculating the autocorrelation values for the entire range of lag, the pitch period is estimated as the lag associated with the highest autocorrelation. The ACF is deﬁned as   16.42   where N is the frame length, m is the time instant that the frame ends, and l > 0 is the time lag.  This method can ﬁnd strong peaks at a period of T, and next strong peaks at 2T, 3T, . . ., where T is the pitch period. Since pitch associated with voice is below 500 Hz, a more accurate estimate for pitch is obtained by lowpass ﬁltering the speech so as to eliminate the high-frequency components and noise.  Unfortunately, there are secondary maxima in the autocorrelation function that are related to the formant frequencies. These formant peaks may exceed the pitch-period max- imum, during phoneme transitions, leading to large pitch estimation errors. A method frequently used to improve the autocorrelation method is oversampling, and this is known as the fractional pitch period detection [7]. Oversampling is employed in the FS1016 and GSM HR coders.  Magnitude difference function method  The magnitude difference function  MDF  method does not use multiplication. It is based on the expectation that s n  − s n − l  is small for l = 0, T, 2T, . . .. The magnitude difference function is deﬁned by  MDF l, m  =  s n  − s n − l .   16.43   m cid:26   n=m−N+1  Example 16.5: Given a speech of “Beep!”, for frame 5, the autocorrelation and magnitude difference as functions of the lag are plotted in Fig. 16.14, for a frame length of 20 ms. For the autocorrelation-based method, the second largest correlation value is at delay l = 56. For the MDF case, the second smallest MDF also occurs at delay l = 56. This corresponds to a pitch period of 7 ms or a pitch frequency of 142.86 Hz. The results for the two methods are very close for frames 1 to 8, which are voiced frames.  Cepstrum method  The most effective method for suppressing the formants during pitch extraction is the cepstrum method. The cepstrum is deﬁned as the Fourier transform of the logarithm of the power spectrum. In the cepstrum, the inﬂuence of the formants is almost completely removed from the pitch extraction.      688   cid:2   Source coding I: speech and audio coding  1  0  1  0  −1  0    n   s  5   e m a r F    ,   n   s  −1  20    l   R  0  −20    l   F D M  0  0  5  0  1000  2000  3000  4000  640  660  680  700  720  740  760  780  800  20  40  60  80  100  120  140  160   cid:2 Figure 16.14  The autocorrelation and magnitude difference values versus the lag.  20  40  60  80  100  120  140  160  Excitation generation  u  n   Synthesis  filter  x  n   Error  minimization  ew n    Weighting  filter   a   u  n   Excitation  index  Synthesis  filter  x  n    b    cid:2 Figure 16.15 Speech coding based on analysis-by-synthesis.  a  The analysis-by-synthesis encoder.  b  The  analysis-by-synthesis decoder.  Samples  x  n   e  n   Similarly to the autocorrelation method, if the peak cepstral exceeds a threshold, the speech is classiﬁed as voiced; otherwise, the zero-crossing counting is further performed. If the number of zero-crossings exceeds a threshold, the speech is classiﬁed as unvoiced; otherwise it is voiced. For voiced frames, the pitch period is the location of the peak cepstral value.  16.5.8 Analysis by synthesis  Most existing vocoders employ the principle of linear prediction based on analysis- by-synthesis [17]. Multipulse LPC is an analysis-by-synthesis method for synthesizing good-quality speech at 9600 bits s. This data rate can be further reduced in CELP [26] by selecting the excitation sequence e n  from a codebook of zero-mean Gaussian sequences. CELP and its variants are widely used in modern speech codecs.  Analysis-by-synthesis can be in either open-loop or closed-loop form. The architec- ture of closed-loop analysis-by-synthesis is shown in Fig. 16.15. Encoding  analysis  is performed by perceptually optimizing the decoded  synthesized  signal in a closed loop.      689   cid:2   16.5 Speech coding  Excitation generation is performed by multiplication of the excitation codebook and a gain. The closed-loop search procedure is repeated for all excitation codevectors stored in the codebook, and the best excitation sequence is encoded. Instead of minimizing the usual MSE term to generate the best waveform reproduction, the analysis-by-synthesis codec can minimize the perceptually weighted error ew n . The same codebook is used at the decoder.  Multipulse excitation model  In predictive coding, it is not necessary to encode all prediction errors. Typically, by preserving a small percentage of the nonzero samples, the synthesized speech has little per- ceptual distortion. The preserved samples are encoded by their amplitudes and positions. This approach is called the multipulse excitation  MPE  model [2].  The regular pulse excitation  RPE  model is a popular MPE model. The prediction- error sequence is down-sampled to several subsequences, with the subsequence having the highest energy selected. The RPE codec is an open-loop excitation optimization assisted codec.  For the RPE codec, only the amplitude of the pulses and the subsequence number are encoded. A variant of RPE, namely RPE-LTP, is used in the GSM 6.10 full-rate  FR  codec standard at the source bit rate of 13 kbits s. RPE-LTP is a hybrid method that tries to match in the magnitude spectrum domain using the LPC model, as well as in the time domain by approximating the original waveform. RPE-LTP preprocesses the sampled audio signal, applies STP analysis and ﬁltering, and then LTP analysis and ﬁltering. The remnant RPE, obtained by subtracting STP and LTP signal parts, are then evaluated. It uses a frame length of 20 ms.  RPE-LTP provides toll quality speech  MOS of 4.0 . It has a higher robustness than the 32 kbits s ADPCM codec, but has increased complexity and encoding delay. The predictor is implemented as a cascade of STP and LTP. A large amount of bits are allocated to the excitation signal due to the use of scalar quantization.  The MPE and RPE codecs can provide high quality speech at 10 kbits s and higher, since scalar quantization is employed and a large amount of bits must be used for transmitting the positions and amplitudes of the excitation pulses. The GSM EFR ACELP coder, operating at 12.2 kbits s, is designed to replace the GSM FR RPE-LTP coder. ACELP is a CELP type of algorithm.  Code-excited linear prediction  CELP is a descendant of the multipulse LPC. Like LPC, CELP utilizes a cascade of LTP and STP to avoid the voiced unvoiced decision, and phase information is partially retained through a closed-loop analysis-by-synthesis method. In CELP, instead of using a codebook of pulse patterns, a codebook of excitation signals is used. Like RPE-LTP, CELP is also a hybrid method.  A speech signal is coded as a set of parameters such as LPC coefﬁcients, gain coefﬁ- cients, and codebook indices. In CELP, the synthesis ﬁlter is a cascade of an LTP ﬁlter and      690   cid:2   Source coding I: speech and audio coding  Excitation codebook  u  n   Excitation  index  LTP filter  STP filter  x  n   G  ai  bi  Speech synthesis of CELP.   cid:2 Figure 16.16  a STP ﬁlter. The LTP ﬁlter is used for pitch synthesis, and the STP ﬁlter for generation of the spectral envelope  formants  of the speech signal. The LTP and STP ﬁlters are, respectively, used to model the long-term  ﬁxed codebook, innovation  and short-term correlations  adaptive codebook, pitch  of the speech signal. Typically, the STP uses a 10th-order all-pole ﬁlter, and the LTP uses a 1st- to 3rd-order all-pole ﬁlter to extract those parameters. Coders usually operate on a block of speech samples for a duration of 20–40 ms. The speech synthesis part of the CELP model is shown in Fig. 16.16.  In the CELP decoder, the excitation is produced by summing the contributions from an adaptive codebook  pitch  and a ﬁxed codebook  innovation . A synthesis ﬁlter of the all-pole model 1 A z  is used to shape the excitation. For the generic CELP encoder, STP analysis is performed in each frame to yield the LPC coefﬁcients, and the output STP error is then divided into subframes, which are further subject to LTP analysis. Excitation codebook search is the major part of the CELP coder.  For a typical CELP algorithm, the LPC coefﬁcients, pitch period, pitch gain, codebook index, and codebook gain are transmitted. Unlike MPE and RPE codecs, VQ of model parameters is used for LPC coefﬁcients for reducing the bit rate.  The prediction error or residual waveform, e n  = x n  − ˆx n , is transmitted with the source signal model. This residual waveform is also quantized for transmission  Signal Analysis  eq n  = e n  + q n ,  where the quantization noise q n  is modeled by a white noise. The decoder reconstructs the signal sample as  x d  n  = ˆx n  + eq n  = − m cid:26   aix d  n − i  + eq n .  i=1  In the frequency domain, we have  For closed-loop prediction, the reconstructed sample for prediction at the encoder is the  same as that in the decoder  A z X d  z  = E z  + Q z .  e n  = x n  − ˆx n  = x n  + m cid:26   aix d  n − 1 .  i=1   16.44    16.45    16.46    16.47       691   cid:2   As a result, the decoder output is derived as  or in the frequency domain  16.5 Speech coding  x d  n  = x n  + q n ,  X d  z  = X z  + Q z .  Error weighting ﬁlter   16.48    16.49    16.50    16.51   The masking phenomenon in the human auditory system is employed in CELP. A per- ceptual noise-shaping ﬁlter is used to shape the noise-like speech spectrum so that it is inaudible. The weighting ﬁlter is implemented as  = 1 + cid:24  1 + cid:24   −i m i=1 aiz i=1 aiγ iz−i , m  W z  = A z  A z γ    where γ is a constant in [0, 1], typically in the range of 0.6 to 0.85.  The error weighting ﬁlter ampliﬁes the error signal spectrum in nonformant regions, but deemphasizes the error signal spectrum in formant regions. This is because error in the regions of spectrum peaks is easily masked due to the high signal energy at these regions, while at spectrum valleys the signal has low energy and the error is prominent. Other forms of the error weighting ﬁlter are also used. For example, in G.728, the ﬁlter takes the form  with γ1 = 0.9 and γ2 = 0.6.  W z  = A  z γ1  A  z γ2   Postﬁlter  A postﬁlter can be used to augment spectral prominence and to attenuate the compo- nents in the spectral valley. This alters the waveform, but reduces the audible noise in the reconstructed speech. Thus, it yields a further improvement in the subjective quality of the synthesized speech.  Postﬁltering is used in G.721. Both adaptive short-term and long-term postﬁlters are employed in G.728. In G.728, the long-term postﬁlter is a comb ﬁlter that enhances the spectral peaks in the vicinity of the harmonics of the pitch frequency, while the adaptive short-term postﬁlter consists of a 10th-order pole-zero ﬁlter concatenated with a ﬁrst-order single-zero ﬁlter. Note that the weighting ﬁlter is implemented only in the encoder and the post-ﬁlter is implemented only in the decoder.  16.5.9 CELP-based codecs  Along with its variants, such as ACELP, relaxed CELP  RCELP , low-delay CELP  LD- CELP  and VSELP, CELP is currently the most widely used speech coding algorithm. CELP scales well to both low and high bit rates. The U.S. federal standard FS1016 is the      692   cid:2   Source coding I: speech and audio coding  ﬁrst CELP codec. It is a 4.8 kbits s CELP coder that uses a standard CELP structure. The frame length is 30 ms, split into four 7.5 ms subframes.  CELP can achieve communications of toll quality speech at bit rates between 4.8 and 16 kbits s. At 16 kbits s, G.728 produces reconstructed speech that is indistinguishable from the 64 kbits s G.711 PCM speech and is superior to the 32 kbits s G.726 ADPCM speech, while at 4.8 kbits s the FS1016 codec produces good communications-quality speech.  The PDC HR speech codec employs the pitch synchronous innovation CELP  PSI- CELP  principle [19]. It has a bit rate of 3.45 kbits s, and a total channel-coded rate of 5.6 kbits s. The frame length is 40 ms, which is divided into four 10 ms subframes. The PSI-CELP codec exploits the periodicity that occurs in voiced speech.  Speex is an open source free software speech codec under the BSD license,1and is based on CELP. It is targeted at VoIP and has a wide range of bit rates available  from 2 to 44 kbits s . Some of Speex’s features are: narrowband  8 kHz , wideband  16 kHz , and ultra wideband  32 kHz  compression in the same bitstream; intensity stereo encoding; packet loss concealment; variable bit rate; voice activity detection and discontinuous trans- mission; ﬁxed-point port; acoustic echo canceller; and noise suppression. Intensity stereo encoding, integration of multiple sampling rates in the same bitstream  embedded coding , and a variable-bit-rate mode are unique features in Speex. In the wideband mode, Speex uses a QMF to split the band in two.  Many mobile communication standards use codecs at different bit rates. For example, GSM uses FR HR EFR codecs. Other standards such as PDC and IS-136 also deﬁne HR, FR, EFR algorithms but may be at different bit rates.  Some important CELP variants are introduced below.  Vector-sum excited linear prediction  VSELP is a CELP coder with a particular codebook structure that has a reduced computa- tional cost. In VSELP, excitation vectors from the stochastic codebook are obtained by a linear combination of a number of ﬁxed basis vectors [11]. The TIA IS-54 VSELP standard is very similar to FS1016, except for the form and structure of the stochastic codebook. VSELP is implemented in TIA IS-54, operating at 7.95 kbits s, in ETSI HR GSM 6.20 at 5.6 kbits s, and in the PDC FR STD-27 codec at 6.7 kbits s. The channel-code data rates are 13 kbits s for IS-54 VSELP, 11.4 kbits s for the HR GSM codec, and 11.2 kbits s for the PDC FR codec. The additional data rate is utilized for channel coding and synchronization. In the IS-54 VSELP coder, a total of 159 bits are allocated for each frame of 20 ms, leading to a bit rate of 7950 bits s. The IS-54 coder outperforms FS1016. The HR GSM 6.20 and PDC FR STD-27 VSELP codecs are based on a structure similar to that of the IS-54 VSELP, and they were all originally developed by Gerson et al at Motorola Inc. They all use a frame length of 20 ms  four subframes , but use a different number of stochastic codebooks and or basis vectors.  1 http:  www.speex.org      693   cid:2   16.5 Speech coding  Algebraic codebook excited linear prediction  Excitation codebook search is the most computationally intensive among all CELP opera- tions. ACELP uses simple algebraic rules such as addition and shift to create the excitation codevectors, thus the storage of the codebook is avoided. The original idea of ACELP was ﬁrst introduced by Adoul et al [1], which was further reﬁned and used in many standards, such as ITU-T G.723.1 MP-MLQ ACELP, G.729 Conjugate Structure  CS -ACELP, TIA IS-641 ACELP, ETSI GSM EFR ACELP, and ETSI AMR ACELP.  G.729 uses an algebraic excitation codebook and conjugate VQ for the involved gain. The coder operates at 8 kbits s, with a delay of 25 ms. It has a frame length of 10 ms  with two subframes . G.729 gives synthesis speech quality equivalent to the 32-kbits s G.726 ADPCM codec in error-free conditions, but signiﬁcantly outperforms G.726 in case of channel errors. G.729 Annex A  G.729A  is a modiﬁcation of G.729, but its bitstream is compatible with G.729, with approximately half the complexity  12 MIPS vs. 22 MIPS for full-duplex operation using ﬁxed-point DSP . G.729A operates at 8 kbits s and gives speech quality equivalent to G.729 in most conditions, with only a slight degradation in performance in case of background noise and in case of three tandems. G.729 is a most prominent low-delay speech codec.  The G.723.1 MP-MLQ ACELP coder, standardized for very-low-bit-rate videophone, uses a 30 ms frame length. It operates at 5.3 kbits s  using ACELP  and 6.3 kbits s  using MP-MLQ excitation , with a coding delay of 67.5 ms and relatively low implementation complexity. The G.723.1 coder has a complexity of 14.6 MIPS for the 5.3 kbits s mode and 16.0 MIPS for the 6.3 kbits s mode. G.723.1 is amenable to voice-activity controlled discontinuous transmission and comfort noise injection. The G.723.1 speech codec and the H.263 video codec form the H.324 multimedia compression and transmission standard. Note that G.723.1 is different from the G.723 ADPCM standard. G.723.1 is one of the earliest codecs for VoIP applications, although today G.711, G.729, and G.722 are also supported in VoIP systems.  The IS-641 standard, which is used as the EFR IS-136 codec, was proposed to replace the 7.95 kbits s IS-54 coder. IS-641 operates on a frame of 20 ms  four subframes , with a bit rate of 7.4 kbits s and a channel coded bit rate of 13 kbits s. The EFR IS-136 codec is very similar to the EFR GSM ACELP codec. IS-641 uses the same algebraic codebook as G.729.  The GSM EFR ACELP operates at 12.2 kbits s. It was targeted to improve on the 13 kbits s GSM FR coder  6.10 RPE-LTP , and it uses the same channel bit rate of 22.8 kbits s as for the FR coder.  Adaptive multi-rate  Both channel and source statistics vary over time. AMR coding is a joint coding of the source and the channel. The source statistics vary very rapidly, while the CSI is updated much more slowly. For this reason, the source coder uses different number of source bits per frame, while the channel coder uses a varying number of bits for adequate channel protection, so that the total bit rate is kept constant.      694   cid:2   Source coding I: speech and audio coding  ETSI AMR ACELP, also known as network-controlled multimode coder, operates at eight modes 12.2, 10.2, 7.95, 7.40, 6.70, 5.90, 5.15, and 4.75 kbits s. There is also a silence descriptor mode operating at 1.8 kbits s. The 12.2 kbits s mode employs the GSM EFR coder, the 7.4 kbits s mode is compatible with the IS-641 EFR, and the 6.7 kbits s mode is compatible with the 6.7 kbits s PDC FR.  AMR coding utilizes recursive systematic convolutional coding, which is very similar to Turbo coding, and thus has an error correction capability superior to convolutional coding used in GSM EFR. For GSM, AMR has two trafﬁc channel modes, adaptive full-rate  AFS  at 22.8 kbits s and adaptive half-rate  AHS  at 11.4 kbits s. AFS has a MOS performance superior to GSM EFR, and AHS has a performance slightly worse, but close to that of GSM EFR.  AMR is now widely used in GSM and UMTS. Changing AMR adaptation in every frame is theoretically possible in WCDMA. AMR has also been considered for VoIP applications, where AMR adaptation is similar to WCDMA. For VoIP, rate adaptation is implemented so as to reduce network congestion.  Low-delay CELP  In PCM and ADPCM that encode the speech signal on a sample-by-sample basis, the delay is negligible. For CELP-based coders, a high compression ratio is achieved by processing the signal on a frame-by-frame basis. Conventional CELP codecs have a frame length of typically 20 to 30 ms, leading to a coding delay of at least 50 ms. The ITU-T G.728 LD-CELP codec, approved in 1991, was developed in [6]. G.728 operates at a bit rate of 16 kbits s with a one-way coding delay of less than 2 ms.  G.728 is a very successful low-delay coder. The G.728 coder uses many techniques to  achieve low delay [7]:   The method reduces the frame length to 20 samples, which are further divided into four ﬁve-sample subframes.   It uses recursive autocorrelation estimation for the calculation of the LPC coefﬁcients, known as external prediction; LPC coefﬁcients are estimated from the past frame due to the relatively short frames.   It employs backward adaptive linear prediction, with the LPC coefﬁcients being obtained from the synthetic speech. This avoids transmission of LPC coefﬁcients.   A short-term synthesis ﬁlter with a prediction order of 50 is employed, and avoids the error-sensitive long-term predictor.   It employs backward excitation gain adaptation.  G.728 LD-CELP achieves a speech quality that is better than or equivalent to that of the 32 kbits s G.726 ADPCM, while maintaining a high robustness against transmission errors. The G.728 coder has an implementation complexity of about 12.4 million operations  mul- tiplys and adds  per second for the encoder, and 8.7 million operations per second for the decoder, leading to a full-duplex complexity of about 21 million operations per second [12]. This complexity is higher than that of many low bit-rate coders. The codec provides      695   cid:2   16.5 Speech coding  an average SEGSNR of 20.1 dB [12]. This coder has been extended to lower bit-rate codes, at 8, 6.5, and 4.67 kbits s [6, 30].  Variable-bit-rate  VBR  CELP  The TIA IS-96 variable-bit-rate  VBR  CELP standard, also known as Qualcomm CELP  QCELP , was developed by Qualcomm to increase the capacity of CDMA systems in 1994. IS-96 employs the conventional CELP structure. It is a source-controlled variable- bit-rate coder, where the control mechanism for bit rate depends on the background noise estimation and the signal energy. QCELP was later replaced by EVRC.  The IS-96 coder uses a frame length of 20 ms, and depending on speech activity the data rate is dynamically selected among one of four choices every frame, 8.55, 4, 2, and 0.8 kbits s, known as FR, HR, quarter-rate, and eighth-rate, respectively. Depending on the bit rate, the frame is divided into different number of subframes, and the subframes can be either pitch subframe or codebook subframe. The encoder codes active speech frames at FR, and background noise and silence at lower rates. For a typical conversation, QCELP operates at an average bit rate of less than 4 kbits s, but the speech quality is compara- ble to that of the 8 kbits s IS-54 VSELP codec. In another version of QCELP, the FR is 13.2 kbits s.  Enhanced variable rate codec  The enhanced variable rate codec  EVRC , developed in 1995, was used to replace QCELP in IS-95. EVRC is also used in CDMA2000. EVRC is practically a ﬁxed-rate coder with a silence-coding mode [13]. It uses the RCELP codebook for representing the ﬁxed code- book. EVRC provides better voice quality than the variable-rate QCELP, but with lower bit rates. It reduces the number of bits for representing the pitch and uses more bits for representing the excitation.  In EVRC, speech is sampled at 8 kHz with 16-bit samples. The length of each frame is 20 ms. The data rates for FR, HR, eighth rate are, respectively, 8.55 kbits s, 4.0 kbits s, and 0.8 kbits s. The eighth rate is used for background noise. The average bit rate varies based on the network conditions. A quarter rate was later added into EVRC-B.  In addition to RCELP, EVRC-B uses the prototype pitch period  PPP  for the coding of stationary voice frames and noise excitation linear prediction  NELP  for the coding of unvoiced or noise frames. Using NELP and PPP coding provides EVRC-B with superior ﬂexibility in rate assignment. EVRC-B is replacing EVRC in CDMA2000. A wideband extension to EVRC-B, EVRC-Wideband  EVRC-WB , is also available.  Selectable mode vocoder  The selectable mode vocoder  SMV  is used in CDMA2000 and as an upgrade of EVRC. However, SMV is also being replaced by EVRC-B for CDMA2000.      696   cid:2   Source coding I: speech and audio coding  SMV is based on a variant of CELP called extended CELP. The operation mode of SMV is set by network operators. Rate adaptation in SMV is achieved as follows. For each frame  20ms  select the best rate  eighth rate, quarter rate, HR, or FR  based on the operation mode, according to the classiﬁcation of input speech  silence, noise-like, unvoiced, onset, nonstationary voiced, or stationary voiced . This avoids multiple convolutional codes. Self- power control leads to better power management and longer battery life. SMV provides a MOS performance of 4.1 at FR.  16.5.10 Wideband speech coding  For most speech codecs, the speech signal is band-limited to 300 to 3400 Hz and sam- pled at 8 kHz. The ﬁltering removes, on average, less than 1% of the energy of the speech signal. This ﬁltered band is, however, important for maintaining an improved intelligibility and naturalness. Although the perceived quality of speech reproduced from wideband speech codecs is not signiﬁcantly better, a better quality is desired in some applications.  SB-ADPCM  The ITU-T G.722 sub-band-split ADPCM  SB-ADPCM  codec operates at 64 kbits s. G.722 band-limits the signal within 50 to 7000 Hz, and then samples at 16 kHz.  Sub-band splitting is performed by the aliasing-free QMF, which splits the 0–8000 Hz frequency band into 0–4000 Hz and 4000–8000 Hz bands, which are then sampled at 8 kHz by decimation. The lower band contains the major part of the signal energy, and thus is much more subjectively important than the upper band. The principle of embedded ADPCM coding that is used in G.727 is also used in G.722, so as to support 8 or 16 kbits s data transmission.  G.722 has three operation modes: speech only at 64 kbits s in Mode 1, 56 kbits s speech plus 8 kbits s data in Mode 2, and 48 kbits s speech plus 16 kbits s data in Mode 3. In Mode 1, the lower band is using 6 bits sample ADPCM, accounting for 48 kbits s, and the upper band is encoded using 2 bits sample, or at 16 kbits s. The coded bitstreams for the two bands are then multiplexed for transmission.  Transform coding  The G.722.1 wideband audio coding standard is a transform coding codec, which is designed to replace the 64 kbits s G.722 SB-ADPCM codec. It has a frame length of 20 ms, sampled at 16 kbits s. G.722.1 is based on the modulated lapped transform  MLT , which is a derivative of the DCT. MLT can be used where blocking effects cause severe signal distortion. Quantization of the transform coefﬁcients employs a psychoacous- tic model, and Huffman coding is then employed. G.722.1 generates output bit rates of 16, 24, or 32 kbits s. The total delay  encoding plus decoding  is of the order of 60 ms.      697   cid:2   16.6 Audio coding  Adaptive multi-rate–wideband  ETSI has standardized AMR-WB, by extending AMR to the 50–7000 Hz band and sampling at 16 kHz [13]. AMR-WB is also based on ACELP. AMR-WB is approved as a 3GPP and ITU-T G.722.2 wideband standard. AMR-WB is used in GSM and UMTS.  Like AMR, AMR-WB processes audio data at blocks of 20 ms with a 5 ms internal subframe structure. AMR-WB provides excellent speech quality and is robust to error- prone radio channels. Discontinuous transmission is applied in AMR-WB during silence and background noise only. Like AMR, it has 9 different data rates for rate adaptation, 6.6, 8.85, 12.65, 14.25, 15.85, 18.25, 19.85, 23.05, and 23.85 kbits s. The lower rates are used for speech communications, and higher data rates are for music, bad background noise, or multiparty conversation. The speech quality of AMR-WB is equivalent to the 48 kbits s mode of G.722 at 8.85 kbits s, to 56 kbits s mode of G.722 at 12.65 kbits s, and to the 64 kbits s mode of G.722 at 23.85 kbits s.  3GPP has further extended AMR-WB to AMR-WB+, by using transform coding in addi- tion to ACELP. It supports both mono and stereo audios, with a bit rate ranging from 5.2 to 48 kbits s. AMR-WB+ is targeted for multimedia services. It provides backward compatibility with AMR-WB.  The variable multi-rate wideband  VMR-WB  speech codec was developed by 3GPP2 for CDMA2000. It is also capable of processing conventional narrow speech, and is inter- operable with AMR-WB at certain bit rates. The VMR-WB core technology is based on AMR-WB, but differs in the deﬁnition of the operation modes. Multimode operation in VMR-WB was inspired by 3GPP2 SMV. VMR-WB is based on CELP coding including RCELP and ACELP.  Wideband CELP  CELP can be employed for wideband coding. The 16 kbits s G.728 coder can be extended by using 16 kHz sampling, leading to a bit rate of 32 kbits s. A better result can be achieved by paying special attention to the 4–7 kHz band. A LD-CELP based 32 kbits s wideband codec was proposed in [23], and it is similar to G.728. It achieves a speech quality that is similar to that of the 64 kbits s G.722 codec, but with a higher complexity. The lower and upper sub-bands are split by the QMF band-splitting scheme, as used in G.722.  There are also a number of full-band wideband ACELP coding schemes, including the backward-adaptive 32 kbits s wideband ACELP and the forward-adaptive 9.6 kbits s wideband ACELP, which were developed by the Sherbrooke University team [12].  16.6 Audio coding  Audio quality codecs usually cover the frequency range of 20 Hz to 20 kHz. In the con- sumer electronics applications, audio CD uses PCM format sampled at 44.1 kHz, each sample having a 16-bit resolution, and reaching a dynamic range  SNR  of 96 dB.      698   cid:2   Source coding I: speech and audio coding  Lossless audio data compression is usually based on Huffman coding. The data compression ratio varies considerably with the audio waveforms, and is typically less than 3. The general-purpose LZW coding is not suitable for lossless audio compression, since the compressed ﬁles are typically 90% of the original ﬁle size [25]. Audio signals typically exhibit a degree of sample-to-sample correlation. This feature can be used to pre- dict the value of the next audio sample, and LPC can be used to remove the redundancy. Entropy coding can then be applied.  For speech signals, the LPC vocoder models the vocal tract and works very well for low data rates. Audio and music signals have a production mechanism different from that of the human speech, and thus the CELP codecs are unable to properly code music signals. Also, the LPC vocoders do not function well when several speakers speak simultaneously, since the speech production model is derived from a single voice source; in this case, an audio codec can be used.  Perception of speech is different from nonspeech audio, since the human brain has a region in charge of speech processing. Speech coding seldom exploits psychoacoustics. The CELP coder uses simple psychoacoustics in the perceptual weighting ﬁlter and the postﬁlter. In contrast, audio coding relies heavily on psychoacoustic models. This may be due to the high complexity arising from pschoacoustic coding.  In perceptual coding of audio signals, the input signal is subdivided into frequency components, which are then encoded separately. Frequency-domain coding has the ability to code each component separately with appropriate accuracy depending on its spectral strength. Based on the power spectrum, excitation patterns can be computed for each component from empirical masking data, and by appropriate bit allocation the quan- tization noise can be made inaudible. Given a predetermined bit rate, the number of bits available for each block of frequency samples can be calculated. These sub-band amplitudes can be sorted, and bits allocated to the highest amplitude sub-bands until the bit pool is exhausted. Optimal bit allocation can be achieved by minimizing the aver- age block error power [3]. A water-ﬁlling strategy for bit allocation is also popular. Frequency-domain coding is more popular for audio signals, since audio signals are highly tonal.  Some lossy and lossless audio codecs  The Dolby AC-3, also known as Dolby Digital, is similar in many aspects to MPEG-1 and MPEG-2 audio systems. They are lossy compression methods, and are widely used as the audio part in the DVD-Video, DVB, and North American HDTV standards. The sampling rate for AC-3 is 32, 44.1, and 48 kHz. Each channel is encoded with a bitstream ranging from 32 and 640 kbits s. Dolby Digital supports the coding of up to six channels. DVD-Video provides multichannel audio, and the sampling rate for audio in DVD-Video is 48 kHz.  Super-audio CD uses the direct stream digital  DSD  technique to record 1-bit data at a sampling rate of 2,822.4 kHz, achieving a dynamic range of over 120 dB. DVD-Audio uses 16-, 20-, 24-bit linear PCM data, and it also uses the Meridian lossless packing  MLP  lossless compression technique of Dolby Laboratories to provide high-quality audio at      699   cid:2   16.6 Audio coding  sampling rates of up to 96 kHz for up to six channels or 192 kHz for two channels. The MLP typically achieves a compression ratio of 2:1. The dynamic range of DVD-Audio can reach 144 dB. DVD-Audio also supports the audio CD format and is compatible with DVD-Video. The MLP decoder reverses the encoding process and has a relatively low com- plexity: 27 MIPS for extracting a two-channel stream at 192 kHz or 40 MIPS for decoding six channels at 96 kHz.  In the following, we introduce the most popular MPEG Audio standards.  16.6.1 MPEG-1 and MPEG-2 Audio  MPEG is an ISO IEC audio video standardization project. The MPEG  Moving Pictures Experts Group  develops standards for moving pictures, associated audio and their combination. MPEG-1  ISO IEC 11172  achieves a total data rate of 1.5 Mbits s, and MPEG-2  ISO IEC 13818  has a total data rate of 10 Mbits s. MPEG-4  ISO IEC 14496  targets at a wide range of applications including wired, wireless, streaming, digital broadcasting, multimedia, and high quality audio video. MPEG-7  ISO IEC 15938  addresses the description of multimedia content for multimedia database search. MPEG-21  ISO IEC N4318  addresses the many elements needed these MPEG to build an infrastructure for the usage of multimedia content. All standards standardize the bitstream and decoder speciﬁcations only, but not the encoder.  MPEG-1 Audio  MPEG-1 Audio supports one or two main channels, depending on the conﬁguration and sampling frequencies of 32, 44.1, and 48 kHz. MPEG-1 Audio aims at providing a percep- tually lossless coding scheme. The data rates vary between 32 and 224 kbits s per channel, corresponding to compression ratios ranging from 2.7:1 to 24:1. MPEG-1 Audio maintains CD-like quality but with reduced data rate.  MPEG-1 Audio speciﬁes three layers, which offer increasingly higher audio quality but slightly increased complexity. All the three layers cause lossy audio compression. Layer 1 is used in the digital compact cassette  DCC , Layer 2 in DAB and DVB, and Layer 3 for portable audio players and Internet. The MP3 ﬁle format is a modiﬁcation of the MPEG Layer-3 format at lower sampling frequencies. MPEG-1 Layers 2 and 3 are also used for broadcasting in ITU-R BS.1115.  The basic structures of the MPEG Audio encoder and decoder are shown in Fig. 16.17. The input PCM signal is ﬁrst mapped to the frequency domain, and bit allocation and coding of these frequency components are then performed. The input PCM is also fed to a psychoacoustic model whose output is used to determine the bit allocation. The bit- stream formatting block interleaves the coded PCM signal with side information, and generates the encoded bitstream. The decoding process separates the quantized spectral components of the signal, and then reconstructs the time-domain representation of the signal.      700   cid:2   Source coding I: speech and audio coding  PCM  Time to frequency mapping  Bit allocation and coding  Bitstream formatting  Encoded bitstream  Psychoacoustic  model  Side  information  Encoded bitstream  Unpacking  Frequency  sample  reconstruction  Frequency  to time mapping  Decoded PCM   a    b   Side  information   cid:2 Figure 16.17  The basic structure of MPEG Audio encoder and decoder.  a  Encoder.  b  Decoder.  Layers 1 and 2 of MPEG-1  and also MPEG-2  use M = 32 channel pseudo-QMF banks with the base ﬁlter h n  having 511 taps. The ﬁlter length N is 513, with the ﬁrst and last coefﬁcients being zero. Using  13.194 , φk is selected as [3]   cid:2    cid:3   φk = N − 1 − M  2K  k + 1 2  π   16.52   to ensure near neighbor alias cancellation. The prototype ﬁlter h n  has symmetrical coef- ﬁcients, and is deﬁned in ISO IEC 11172-3. A uniform midtread quantizer is then used to quantize the frequency components. The psychoacoustic model is obtained based on the Hanning windowed DFT. Layers 1 and 2 exploit the MPEG psychoacoustic model 1.  For Layer 3, each of the 32 pseudo-QMF outputs is cascaded with an 18 frequency- line MDCT, generating a total of 576 frequency channels. Blocks of 36 sub-band samples are overlapped by 50%, multiplied by a sine window, and then processed by the MDCT transform. The MDCT outputs are further subject to a nonuniform midtread quantizer, and the MPEG psychoacoustic model 2 is used for quantization. The psychoacoustic model is also obtained by using a Hanning-windowed DFT. For Layer 3, Huffman coding is further applied to the quantization bits. MPEG AAC and Dolby AC-3 are based on MDCT, and a Kaiser window is used in both the systems. In MPEG AAC, the Kaiser window with α = 4 for steady state conditions, and α = 6 for transients, is used; in Dolby AC-3, α = 5. MP3 is a popular audio ﬁle for sharing music over Internet. Typically, it achieves a com- pression ratio of 10:1. It achieves the best perceived audio quality at a speciﬁc, guaranteed bit rate. MP3 is a sub-band coding method. Each input sample enters a ﬁlter bank consist- ing of 32 polyphase sub-band ﬁlters. Each sub-band is encoded with a variable number of bits, which is determined by a psychoacoustic model based on the masking properties of the human ear [29]. A loud signal at one frequency makes the quantization noise at the neighboring frequencies inaudible, and thus fewer bits can be used to encode the neigh- boring sub-bands. The ﬁlter bank is followed by MDCT, and Huffman coding is ﬁnally applied to the quantized signal.      701   cid:2   16.6 Audio coding  Introduction to perceptual audio coding, and MPEG Audio and Dolby AC-3 standards  are given in [3].  MPEG-2 Audio  MPEG-2 is a multichannel extension of MPEG-1. MPEG-2 BC  Backwards Compatible  deﬁnes audio coding at half the MPEG-1 sampling frequencies. MPEG-2 AAC  Advanced Audio Coding  deﬁnes a higher-quality multichannel standard than is achievable with MPEG-1 extensions. AAC combines the coding efﬁciency of a high-resolution ﬁlter bank, prediction techniques, and Huffman coding to achieve very good quality audio at low data rates.  MPEG-2 AAC provides near-transparent subjective audio quality at a bit rate of 256 to 320 kbits s for ﬁve channels and at 96 to 128 kbits s for stereophonic signals. The MPEG-2 AAC coder is similar to the MPEG-1 2 Layer-3 coder since they both employ a switched ﬁlter bank, a nonuniform power-law quantizer, and Huffman coding.  16.6.2 MPEG-4 Audio  MPEG-4 speciﬁes a set of tools, which are used as components in different coding algo- rithms. MPEG-4 Audio proﬁles deﬁne subsets of the MPEG-4 Audio functionalities for speciﬁc applications. MPEG-4 Audio provides a high coding efﬁciency, reaching lower data rates.  MPEG-4 has many audio coding tools. Major audio tools are speech coding, general audio coding, synthesized audio coding, and synthesized speech coding tools. The ﬁrst two are used for natural speech audio coding, while the last two are used for synthetic speech audio coding. MPEG-4 Audio provides error-robustness tools that allow improved performance on error-prone transmission channels.  MPEG-4 speech coding  The speech coding tools support speech coding at bit rates from 2 up to 24 kbits s using a CELP coder and a parametric coder known as harmonic vector excitation coding  HVXC . HVXC allows the user to modify speed and pitch during playback.  MPEG-4 CELP is similar to that of a regular CELP codec, but is more ﬂexible. It sup- ports two different types of excitation generators: MPE and RPE. The MPEG-4 CELP MPE generator can operate in narrowband or wideband mode, at a sampling frequency of 8 kHz or 16 kHz. The bit rate can be adjusted in small steps by changing the frame length, the subframe length, and the number of pulses per subframe. The bit rate varies from 3.85 to 12.2 kbits s for 8 kHz sampling, and from 10.9 to 23.8 kbits s for 16 kHz sampling. The RPE generator is used for 16 kHz sampling, and it provides a bit rate ranging from 14.4 to 22.5 kbits s.  MPEG-4 CELP not only provides a wide range of bit rates, but also supports scalable coding in the MPE mode. The full-rate stream is composed of a base-layer stream and one      702   cid:2   Source coding I: speech and audio coding  or more enhancement-layer streams. The enhancement layer leads to an increase in the bit rate or bandwidth scalability.  Silence compression is a special MPEG-4 CELP mode. It reduces the bit rate in frames with no or low voice activity. The basic idea is similar to that of HVXC coding. The decoder generates comfort noise for nonactive frames. Comfort noise is generated as a random exci- tation signal using the same excitation generator as for active frames, but with randomly generated control parameters such as pulse positions or amplitudes.  MPEG-4 HVXC coding allows speech coding at very low bit rates with reasonable qual- ity: 2 and 4 kbits s [22]. This is achieved by representing LPC residuals with harmonic coding for voiced segments and vector excitation coding  VXC  for unvoiced segments. HVXC coding is based on LPC coding. It has a high complexity, but has speed-control and pitch-modiﬁcation functionalities during decoding.  MPEG-4 general audio coding  The MPEG-4 general audio coding tools can be either a time frequency  T F  coder or a parametric coder. Scalability is supported in both the coders. A parametric audio coder, called harmonic and individual lines plus noise  HILN , can operate at bit rates down to about 4 kbits s. MPEG-4 T F is based on MPEG-2 AAC, and is capable of coding music and speech.  The MPEG-4 T F coder deﬁnes a number of extensions to MPEG-2 AAC, in order to enhance the compression performance, such as perceptual noise substitution, LTP, and transform-domain weighted interleave vector quantization  TwinVQ . These enable the operation at extremely low bit rates, with very low delays and under error-prone trans- mission conditions. Bit-rate scalability is also provided in the T F coder. When TwinVQ is used in conjunction with the LTP and perceptual noise substitution tools, the code can operate at bit rates between 6 and 16 kbits s ch; and this method is frequently used in the scalable conﬁgurations of the MPEG-4 T F audio coder. Also, the coding quality scales with bit rate for all types of signals.  Parametric audio coding uses a signal representation that is based on parameterized models. This approach has long been used in musical analysis synthesis, as well as in speech vocoders. Sinusoidal modeling has been used for analysis synthesis of musical instruments, speech, and audio. There are also many other sound models such as harmonic models and noise models. Perceptual models are also considered in the parametric audio coder.  HILN audio coding [24] achieves very low bit rates, down to 4 kbits s. HILN uses three types of components of the source models: individual sinusoids  described by their fre- quencies and amplitudes , a harmonic tone  described by its fundamental frequencies, amplitude, and spectral envelope of its partials , and a noise component  by its amplitude and spectral envelope . For the typical target bit rates of 6 to 16 kbits s, only the param- eters for a small number of components can be transmitted, and thus a perceptual model is employed to select those most important components. The parameter estimation can be based on LPC estimation. HILN can be combined with the MPEG-4 HVXC parametric speech coder to cover a wider range of signals and bit rates.      703   cid:2   Problems  Problems  16.1 In an adaptive PCM speech coding system, the speech is sampled at 8 kHz, and each sample is represented by 8 bits. The quantizer step size is recomputed every 20 ms, and it is encoded using 4 bits. What is the bit rate of the speech coder? What is the SQNR of this system?  16.2 Consider a mobile communication system with the uplink frequency band between 800 MHz to 850 MHz and the downlink frequency band between 900 MHz to 950 MHz. Trafﬁc channels occupy 80% the bandwidth. The system is required to support at least 2500 simultaneous calls using FDMA. The modulation scheme has a spectral efﬁciency of 1.68 bits s Hz, and rate 2 3 FEC codes are used for channel coding. Determine the maximum transmission bit rate of the speech coder.  16.3 Take a voiced portion of any speech waveform for pitch period estimation. Compute and plot the autocorrelation for a delay of l = 20 to 150 samples. Estimate the pitch period.  16.4 Clipping is an effective method to improve pitch period estimation by using the autocorrelation method. It reduces the inﬂuence of formant frequencies by eliminating low-amplitude samples. Deﬁne a clipping function  ⎧⎨⎩x + c,  0, x − c,  f  x  =  x < −c −c ≤ x ≤ c x > c  ,  where c is a clipping limit. Solve Problem 16.3 by using the clipped signal as the input.  16.5 In order to estimate the pitch period, it is common to lowpass the speech signal at a frequency between 500 and 800 Hz before applying the autocorrelation method. Solve Problem 16.3 after lowpassing the speech signal.  16.6 Take a voice portion of any speech waveform. Solve Equation  16.25  for the LPC coefﬁcients by using the Levinson-Durbin algorithm. 16.7 Given the all-pole ﬁlter x n  = u n  − a1x n − 1  − a2x n − 2  − a3x n − 3  and all-zero ﬁlter x n  = u n  + a1u n − 1  + a2u n − 2  + a3u n − 3 , if a1 = −0.9, a2 = 0.6, and a3 = −0.5, derive the RCs ki. [Hint: The result is the same for both the ﬁlters.]  16.8 An autocorrelation coefﬁcient can be deﬁned to replace the autocorrelation func- tion for pitch period estimation. Using the autocorrelation coefﬁcient yields more precise estimations due to compensation for changing signal amplitudes. Apply this method for a segment of a voiced speech waveform.  16.9 For a voiced portion of a speech waveform, ﬁnd the LPC coefﬁcients. Using a pre- diction order of ten and a frame length of 240 samples, calculate the segmental prediction gain by averaging over many frames.      704   cid:2   Source coding I: speech and audio coding  16.10 Train scalar quantizers of 2, 3, 4, 5, 6, and 7 bits with a segment of speech waveforms  say, 2000 samples  by using the Lloyd algorithm. Plot the quantizer transfer characteristic for each case. Plot the distortion sum as a function of the quantizer size. Test the performance of the quantizers using a segment of another speech waveform.  16.11 The pdf of speech samples is commonly accepted to be approximated by the Laplacian distribution  −√  2x σ  f  x  = 1√ 2σ  e  Verify this by using a large amount of speech samples. 16.12 For input vector x =  x1, x2 T, a VQ is designed. Each dimension of the input vector is quantized using an identical uniform scalar quantizer, and 0 ≤ xi ≤ 1. Plot the cells and codewords in the 2-D plane when the scalar quantizers use two bits each.  16.13 Implement voiced unvoiced detection for LPC by using energy detection and ZCR detection. Test and compare the two methods on a segment of speech signals on a frame- by-frame basis. 16.14 The LPCs of a CELP encoder are given as a1 = −1.30, a2 = 1.14, a3 = −1.05, a4 = 0.70, a5 = −0.30, a6 = 0.38, a7 = −0.07, a8 = 0.01, a9 = 0.05, a10 = 0.06. Plot the magnitude functions of the formant synthesis ﬁlter and the formant analysis ﬁlter. Plot the magnitude function of the perceptual weighting ﬁlter for different values of γ .  16.15 The G.729 coder uses the following ﬁlter to process the input speech  −1 + 0.46364z −2 1 − 1.9059z−1 + 0.91140z−2 Plot the magnitude response of the ﬁlter and explain its purpose.  H z  = 0.46364 − 0.92725z  .  16.16 The TIA EIA IS96 deﬁnes the pseudorandom number generator as  x n  =  521x n − 1  + 259 mod 216.  Generate several sequences using different initial conditions. Verify their whiteness.  16.17 Download the codec Speex from http:  www.speex.org. Compile speex under UNIX Linux or Windows Cygwin. The conﬁguration option for compiling can be for different hardware platforms both ﬂoating-point and ﬁxed-point architectures, including TI C5xxx and C6xxx, ADI Blackﬁn, x86, ARM etc. The code works on various operating systems including many Linux UNIX variants, Symbian, and MacOS X. Learn the Speex Codec API  the libspeex library  and their control options.  Design a speech encoder for transmitter and a speech decoder for receiver. The speech encoder can adaptively change its encoding mode according to the channel quality which is measured at the receiver and is fed back from the receiver. At the receiver, the speech decoder is able to decode the speech. Write a C program for this purpose.      705   cid:2   References  References  [1] J. P. Adoul, P. Mabilleau, M. Delprat & S. Morissette, Fast CELP coding based on  algebraic codes. In Proc IEEE ICASSP, Dallas, TX, May 1987, 1957–1960.  [2] B. S. Atal & J. R. Remde, A new method of LPC excitation for producing natural- sounding speech at low bit rates. IEEE ICASSP, Paris, France, May 1982, 614–617. [3] M. Bosi & R. E. Goldberg, Introduction to Digital Audio Coding and Standards  [4] P. T. Brady, A statistical analysis of on-off patterns in 16 conversations. Bell Syst.   Boston, MA: Kluwer, 2003 .  Tech. J., 47:1  1968 , 73–91.  [5] S. J. Campanella & G. S. Robinson, A comparison of orthogonal transformations for  digital speech processing. IEEE Trans. Commun., 19:6  1971 , 1045–1049.  [6] J.-H. Chen, R. V. Cox, Y.-C. Lin, N. Jayant & M. J. Melchner, A low-delay CELP coder for CCITT 16 kb s speech coding standard. IEEE J. Sel. Areas Commun, 10:5  1992 , 830–847.  [7] W. C. Chu, Speech Coding Algorithms: Foundation and Evolution of Standardized  Coders  Hoboken, NJ: Wiley, 2003 .  [8] W. Chu, M. O. Ahmad & M. N. S. Swamy, Modiﬁed silence suppression algorithms and their performance tests. In Proc. IEEE Midwest Symp. Circ. Syst., Cincinnati, OH, Aug 2005, 1, 436–439.  [9] J. R. Deller, Jr., J. H. L. Hansen & J. G. Proakis, Discrete-Time Processing of Speech  Signals  New York: Wiley-IEEE, 2000 .  [10] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [11] I. A. Gerson & M. A. Jasiuk, Vector sum excited linear prediction  VSELP  speech  coding at 8kbps. In Proc. ICASSP, Albuquerque, NM, Apr 1990, 1, 461–464  [12] L. Hanzo, F. C. A. Somerville & J. P. Woodard, Voice Compression and Communica- tions: Principles and Applications for Fixed and Wireless Channels  New York: IEEE Press, 2001 .  [13] K. Homayounfar, Rate adaptive speech coding for universal multimedia access. IEEE  Signal Process. Mag., 20:2  2003 , 30–39.  [14] ITU-T, Single-ended Method for Objective Speech Quality Assessment in Narrow-  band Telephony Applications, ITU-T Rec. P.563, Geneva, May 2004.  [15] ITU-T, Perceptual Evaluation of Speech Quality  PESQ : An Objective Method for End-to-end Speech Quality Assessment of Narrowband Telephone Networks and Speech Codecs, ITU-T Rec. P.862, Geneva, Feb 2001.  [16] J. D. Johnston, Transform coding of audio signals using perceptual noise criteria.  IEEE J. Sel. Areas Commun., 6:2  1988 , 314–323.  [17] Z. Kostic & S. Seetharaman, Digital signal processors in cellular radio communica-  tions. IEEE Commun. Mag., 35:12  1997 , 22–35.  [18] K. Li, M. N. S. Swamy & M. O. Ahmad, An improved voice activity detection using  higher order statistics. IEEE Trans. Speech Audio Process., 13:5  2005 , 965–974.      706   cid:2   Source coding I: speech and audio coding  [19] K. Mano, F. Moriya, S. Mild, H. Ohmuro, K. Ikeda & J. Ikedo. Design of a pitch synchronous innovation CELP coder for mobile communications. IEEE J. Sel. Areas Commun., 13:1  1995 , 31–41.  [20] A. V. McCree & T. P. Barnwell III, A mixed excitation LPC vocoder model for low  bit rate speech coding. IEEE Trans. Speech Audio Process., 3:4  1995 , 242–250.  [21] M. Nelson, The Data Compression Book  New York: M&T Books, 1992 . [22] M. Nishiguchi, A. Inoue, Y. Maeda & J. Matsumoto, Parametric speech coding— HVXC at 2.0–4.0 kbps. In Proc. IEEE Workshop Speech Coding, Porvoo, Finland, Jun 1999, 84–86.  [23] E. Ordentlich & Y. Shoham, Low-delay code-excited linear-predictive coding of wideband speech at 32 kbps. In Proc. IEEE ICASSP, Toronto, Canada, May 1991, 9–12.  [24] H. Purnhagen & N. Meine, HILN: the MPEG-4 parametric audio coding tools. In  Proc. IEEE ISCAS, Geneva, Switzerland, May 2000, 201–204.  [25] K. Sayood  ed , Lossless Compression Handbook  San Diego, CA: Academic Press,  [26] M. R. Schroeder & B. S. Atal, Code-excited linear prediction  CELP : high-quality speech at very low bit rates. In Proc IEEE ICASSP, Tampa, FL, Mar 1985, 3, 937–940. [27] C. E. Shannon, Coding theorems for a discrete source with a ﬁdelity criterion. Proc.  IRE National Convention Record, New York, Mar 1959, part 4, 142–163.  [28] A. S. Spanias, Speech coding: a tutorial review. Proc. IEEE, 82:10  1994 , 1541–  2003 .  1582.  [29] D. Stranneby & W. Walker, Digital Signal Processing and Applications, 2nd edn   London: Elsevier, 2004 .  [30] H. Sun, C. Wang, M. O. Ahmad & M. N. S. Swamy, An 8 kb s low delay CELP speech coder. In Proc. 7th IEEE Int. Conf. Electron. Circ. Syst., Jounieh, Lebanon, Dec 2000, 1, 286–289.  [31] E. Terhardt, Calculating virtual pitch. Hearing Research, 1:2  1979 , 155–182. [32] TIA EIA, TDMA Cellular PCS–Radio Interface–Minimum Performance Standards for Discontinuous Transmission Operation of Mobile Stations, ch16:IS-727, Jun 1998. [33] J. M. Tribolet & R. E. Crochiere, Frequency domain coding of speech. IEEE Trans.  Acoust. Speech Signal Process., 27:5  1979 , 512–530.  [34] W. Tong, E. I. Plotkin & M. N. S. Swamy, Active acoustic noise cancella- tion with audio signal enhancement based on an almost-symmetrical time-varying autoregressive-moving average model. J. Acoust. Soc. Amer., 99:6  1996 , 3528–3538. [35] P. P. Vaidyanathan, Multirate digital ﬁlters, ﬁlter banks, polyphase networks, and  applications: a tutorial. Proc. IEEE, 78:10  1990 , 56–93.  [36] E. Zwicker & H. Fastl, Psychoacoustics: Facts and Models  Berlin: Springer-Verlag,  1990 .      17  Source coding II: image and video coding  17.1 Introduction  A digital image is a rectangular array of picture elements  pixels , arranged in m rows and n columns. The resolution of the image is m × n. Images can be categorized into bi-level, grayscale, and color images. A natural scene, such as a picture taken by a digital camera or obtained by using a scanner, is typically a continuous-tone image, where the colors vary continuously to the eye and there is a lot of noise in the picture. An artiﬁcial image, such as a graphical image, does not have the noise or blurring of a natural image. A cartoon-like image consists of uniform color in each area, but adjacent areas have different colors.  The features in each type of image can be exploited to achieve a better compression. For example, for the bi-level image, each pixel is represented by one bit. A pixel has a high probability of being the same as its neighboring pixels, and thus RLE is suitable for compressing such image. The image can be scanned column by column or in zigzag. For the grayscale image, each pixel is represented by n bits, and a pixel tends to be similar to its immediate neighbors but may be not identical, thus RLE is not suitable. By representing the image using a Gray code that differs in only one bit for two consecutive integers, a grayscale image can be separated into n bi-level images, and each can be compressed by using RLE. The similarity of neighboring pixels can be exploited by using a kind of prediction encoding.  A video is composed of many frames of image. It can be compressed by intraframe  spatial  as well as interframe  temporal  coding. Video compression is based on image compression. Image or video compression aims to remove the redundancy.  Lossless compression  Conventional lossless compression techniques that use Huffman coding or dictionary- based compression exploit the statistical variations in the frequency of individual symbols or the frequency of strings of symbols  i.e., phrases . For continuous-tone images, these lossless compression techniques cannot generate impressive compression. Since the pix- els tend to be well spread over their entire range, their histograms based on frequency are not so spiky, and this limits the compression. When Huffman coding is used to encode a grayscale image, which typically has a set of 255 levels, the compression result is usually very disappointing, with a reduction of only about 1 2 to 1 bit pixel [25].  Making use of the similarity of neighboring pixels, the difference between the real pixel value and its estimated value can be encoded with less bits. This is known as the      708   cid:2   Source coding II: image and video coding  DPCM technique. A ensuing Huffman coding step can lead to a substantial improvement in compression ratio. However, this technique cannot generate good compression ratio for a scene that looks much like white noise, since it is unpredictable both spatially and temporally.  For a color image, a pixel consists of three color components, red, green and blue. A continuous-tone color image can thus be separated into three grayscale images, and each grayscale image can be compressed separately. For discrete-tone images, they have uni- form regions, and this feature can be exploited to increase the compression ratio. Based on the similarity of neighboring pixels, many spatial prediction methods have been proposed. Popular lossless image compression formats are PNG, GIF, and TIFF. They make use of the LZ77 variants or LZW coding. PNG was developed for improving and replacing GIF. It combines LZ77 and Huffman coding with prediction.  The JBIG standard  ITU-T Rec. T.82, ISO IEC-11544  is a lossless image compression standard used for bi-level images. JBIG is used for compression of facsimile pages or scanned document compression. JBIG is based on prediction and context-based arithmetic coding. The lossless mode of the JBIG2  ITU-T T.88, ISO IEC 14492  standard generates ﬁles that are 2 to 4 times smaller than JBIG. JBIG-KIT is a free C program for JBIG encoder and decoder.1  Lossy compression  Image or video compression requires a compression ratio of 20:1 to 200:1. This makes conventional lossless coding techniques such as entropy coding and DPCM not very viable. Lossy compression using transform coding is the dominant image and video compression approach. In transform coding, the coding bit rate and picture quality are the two critical factors. The coding bit rate decides the bandwidth for transferring the images. Picture quality can be characterized by the MSE between the coded image or video and the original one. Both the reconstruction error and the data rate are controlled by the quantization parameters.  The JPEG and JPEG2000 formats are the most important image formats, and will be introduced in Sections 17.6 to 17.8. JBIG2 allows lossy compression of bilevel images [26]. Open-source JBIG2 encoder and decoder programs are available as jbig2enc and jbig2dec.2,3 JBIG2, JPEG, and JPEG2000 compression techniques for images, as well as popular general-purpose compression techniques such as RLE and LZW, are all integrated into Portable Document Format  PDF , which is a de facto standard for documentation.  Image processing  In some situations, an image may be subject to special processing before compression. An image may require the following processing:  1 http:  www.cl.cam.ac.uk $\sim$mgk25 jbigkit   2 http:  www.imperialviolet.org jbig2.html  3 http:  jbig2dec.sourceforge.net       709   cid:2   17.2 Perception of human vision    Noise ﬁltering: A corrupted image may require the removal of noise by a suitable ﬁlter. Averaging, Gaussian smoothing, and median ﬁlters are usually used for denoising.   Redundancy reduction: to eliminate redundancy and unimportant information for a speciﬁc image analysis.   Importance enhancement: such as edge enhancement for emphasizing the shapes in an image, image thresholding and edge detection for image segmentation.  Mathematical morphology is an important tool for image processing and analysis. Image dilation and image erosion are two basic morphology operations. Image restoration, segmentation, texture analysis, shape analysis, geometric transformations, and corner detection are all important topics of image processing. A good text on image processing and computer vision is by Sonka et al [31].  Denoising is one of the most important processing steps prior to image video com- pression. Impulse noise can be modeled by using the Bernoulli-Gaussian process or the Poisson-Gaussian process, where the random time of occurrence of impulses is mod- eled by a binary Bernoulli process or a Poisson process, while the random amplitude of the impulse noise is modeled by a Gaussian process. Impulse noise is more detectable in the time domain than in the frequency domain. The median ﬁlter is traditionally used for the removal of impulse noise. The median ﬁlter is a nonlinear ﬁlter that takes the median of a set of numbers. The median is insensitive to an outlier, which is a sample with an unusually large value. The median ﬁlter is especially useful for image processing, since it removes noise and speckles but preserves the edges or stepwise discontinuities in the image. A num- ber of techniques, which use an inﬂuence function to limit the inﬂuence of the outliers, are discussed in [10]. Other denoising techniques are Kalman ﬁltering for impulsive noise [23], DWT ﬁltering for correlated noise [15, 23], sampled function weighted order ﬁltering for multiplicative noise [27], video denoising based on spatial ﬁltering of the noisy wavelet coefﬁcients [21], spatially adaptive wavelet-based methods for speckle noise [3, 5] and for AWGN noise [4], adaptive wavelet-based Bayesian denoising [22], denoising AWGN and speckle in videos based on spatial and temporal ﬁltering [30], and despeckling using lossy compression [14].  17.2 Perception of human vision  17.2.1 Human visual system  The human visual system is an imaging system. Light enters the cornea, and the amount of light is controlled by the pupil in the iris. The light then passes through a crystalline lens and a vitreous body, which is ﬁlled with a transparent jelly known as vitreous humor, and is focused on the retina by the lens. The retina senses the light and then passes the signal to the brain via the optic nerve. The brain ﬁnally perceives the image. The eye is just a spatial sampling device.  In the retina, there are two types of discrete receptors called rods and cones from their shape. Rods dominate the periphery of the retina, while cones occupy a central area. Vision      710   cid:2   Source coding II: image and video coding  using the rods is monochromatic, has low resolution, but is effective at very low light level. On the other hand, using the cones leads to high resolution and color vision, but this also requires more light.  The cones on the retina occur in three different types, corresponding to different colors. The human vision is restricted to a light wavelength from 400 to 700 nanometers  nm , and the response is not uniform: It is very poor for blue lights, but it peaks in the area of green. This triple receptor characteristic of the eye enables to generate a range of colors by combining light sources having just three different wavelengths in different proportions. This is known as additive color matching. Weber’s law states that manipulation of colors is a linear operation: Any color can be created by a linear combination of the three colors and such a combination is unique.  The eye is sensitive to light over a very large range of intensities: The upper end is about 1010 times the lower end [25]. However, at any instant, the eye adapts only to an average brightness level, and the eye can only perceive a small fraction of the total range. The con- trast sensitivity of the eye is the smallest brightness difference that is visible. The contrast sensitivity is not constant, but increases in proportion to brightness. That is, a brightness change of one per cent is equally detectable for all brightness. Human vision is sensitive to small changes in luminance, but is relatively insensitive to changes in chrominance  color . Thus, for image compression, the chrominance can be compressed at a higher ratio.  The human visual system is not sensitive to high frequency components of spatial fre- quency. These high frequency components are usually treated as noise. The sensitivity of the eye to spatial frequency falls from the maximum, as the frequency increases from zero. This feature is usually used in image compression.  Masking occurs between periodic patterns with similar orientation and radial frequency, and between aperiodic patterns such as luminance borders, and an even greater masking effect occurs in textured regions. For videos, large-area ﬂicker is less perceptible at rates of the order of 60 Hz. These perceptual models are exploited in most image, television, and video systems.  Visually lossless compression  Like speech audio compression, the performance of image compression is evaluated by human perception, and thus these data can be slightly modiﬁed without affecting the per- ceived quality. Visually lossless compression is actually a kind of lossy compression, but the human viewer cannot detect a visual degradation. The strategy is to keep the difference between the original image and the reconstructed image below the threshold of perception. This principle is widely used in color space transformation and transform coding.  17.2.2 Color spaces  In computer image or video systems, a pixel of a color image can be represented as either RGB, YUV, or YIQ format. The RGB format represents the intensity values of red  R , green  G , and blue  B . The RGB color space is well suited to capture and display color      711   cid:2   17.2 Perception of human vision  images. RGB images are displayed on a color CRT  cathode ray tube  or an LCD  liquid crystal display  by separately illuminating the red, green and blue components of each pixel according to their intensities.  YCbCr, also known as YUV, is used in the European analog PAL  Phase Alternation Line  color TV system and international standards of digital video. The human visual system is less sensitive to color than to luminance  luma . In the RGB color space, the three components have the same resolution. The YUV format uses an independent inten- sity value  luminance, Y  plus two color  chrominance, U and V  values known as hue and saturation. The luminance component Y is a weighted average of R, G, and B   17.1    17.2    17.3   with  Y = krR + kgG + kbB,  kb + kr + kg = 1.  ITU-R Rec. BT.601 deﬁnes kb = 0.114 and kr = 0.299. Accordingly [16]  Y = 0.299R + 0.587G + 0.114B,  Cb = 0.564 B − Y , Cr = 0.713 R − Y ,   17.4  where 0 ≤ R, G, B ≤ 1 are normalized R, G, B values. The luma can be assigned a higher resolution than color.  Separation of luminance and color information is for the purpose of compatibility with old black and white TV systems. The Y, Cr, Cb components are further processed by using a DCT or wavelet transform.  There are also some other color spaces such as CMYK format for color printing and the  HSV format for perceptual uniform color space.  Analog video systems  In addition to the PAL system, two other major analog color TV systems are the NTSC  National Television System Committee  system and the SECAM  SEquential Couleur Avec Memoire  system. The NTSC system is employed in America and Japan, the SECAM system is used in France, Eastern Europe, Russia, and the Middle East, and PAL is used in West Europe, China, India, and Australia.  PAL and SECAM use the 625 50  625 scan lines and 50 ﬁelds s  system, and NTSC uses the 525 60 system. All the three systems are interlaced with a 4:3 aspect ratio. For interlaced scanning, each frame is formed by two successive  odd lines and even lines  scanning passes  two ﬁelds ; thus, the frame rate of the system is either 25 or 30 frames s. The three analog TV systems differ mainly in the way the luminance chrominance components are calculated from the RGB component. They calculate luma by  17.3  for compatibility with the monochrome TV system, but use different coefﬁcients for calcu- lating the chroma components. NTSC uses YIQ, where I and Q represent the in-phase and quadrature axes on the same color space spanned by the U and V axes. SECAM uses YDbDr, where Db = R − Y and Dr = B − Y.      712   cid:2   Source coding II: image and video coding  YCbCr sampling  The YCbCr data can be sampled by the 4:4:4, 4:2:2, or 4:2:0 format. The 4:4:4 sampling has the same resolution for Y, Cb and Cr, and has a sample of each component for every pixel. This provides no compression on the chrominance components. In 4:2:2  2h1v  sam- pling, Cb and Cr have the same vertical resolution  1:1  as Y, but are downsampled at 2:1 horizontally. The 4:2:2 sampling is used for high-quality color reproduction; it compresses the image to 2 3 of its original size.  In the popular 4:2:0  2h2v  sampling, Cb and Cr are downsampled at a ratio of 2:1 both horizontally and vertically, each having half the horizontal and half the vertical resolutions of Y. The 4:2:0 sampling requires half as many samples as 4:4:4 sampling.  In digital video, a pixel can be represented by either RGB or YUV format. Typically, a pixel can be represented by RGB format of 24 bits, where R, G, B each have 8 bits, or by YUV format of 16 bits, where Y uses 8 bits and U, V each use 4 bits. For video systems, the amount of data is excessive, and must be compressed for transmission and storage.  17.3 Quality of image and video coding  Like speech and audio coding, the quality of image and video coding can be evaluated by subjective or objective criteria. The subjective quality evaluation depends on the perception of the human visual system, as well as other factors like the viewer’s state of mind and visual attention.  The U. Waterloo Repertoire is a suite of 32 test images for comparing different image compression algorithms.4 MPEG has a wide library of video and audiovisual sequences for evaluation. The selection from this library is based on the criticality and the structure of the scene.  Subjective quality evaluation  The quality of image or video quality can also be subjectively evaluated by using the MOS measure. The test procedures for subjective quality evaluation are deﬁned in ITU-R Rec. BT.500-11. According to ITU-R Rec. BT.500-10, the number of nonexpert viewers that participate in a test should be not less than 15, and a lower number for expert viewers. The viewers must be screened for visual acuity to detect color blindness or strong color vision deﬁciencies. At the beginning, the viewers are subject to a training phase. The tests are carried out based on ITU-R BT.500 and ITU-T P.910.  The commonly-used procedure from BT-500 is the double stimulus continuous quality scale  DSCQS  method. In a typical test session, a series of sequence pairs are shown to the viewer in order to grade each pair  original and impaired . The order of the two sequences is randomized during the test session.  4 http:  links.uwaterloo.ca bragzone.base.html      713   cid:2   17.4 Predictive coding  Objective quality evaluation  The subjective evaluation method is costly and time-consuming. Objective quality evaluation methods are more widely employed during the period of image and video compression algorithm development. The most heavily employed measure is the peak signal-to-noise ratio  PSNR .  PSNR is deﬁned as the ratio of the square of the highest possible signal value in the  image video to the MSE between the original and the impaired image or video frame   cid:12    cid:13   PSNR = 10 log10 = 10 log10  x2 peak σ 2 d   2n − 1 2   17.5  where xpeak = 2n − 1 is the peak value of the signal, n is the number of bits per image sample, and the MSE σ 2  d is the variance of the distortion.   dB ,  The MAD measure is also quite frequently used for evaluating image compression  σ 2 d  algorithms   cid:4  cid:4 x − ˆx   cid:4  cid:4  .  MAD = 1 N   17.6   The PSNR measure usually indicates the quality of an image or video frame. However, in some special cases, the change in the background or a local area can lead to very low PSNR, while the subjective quality is still very high as long as there is not much degradation in the area of interest. This is also true with MAD.  17.4 Predictive coding  For a source with memory, predictive coding known as DPCM is usually used to exploit the inherent dependence within the various events. DPCM is not in itself a compression method. Instead it is a technique for data decorrelation. Differential coding and adaptive coding are successful for speech coding, but their performance is very poor for image data. This difference arises from the fact that audio data tends to be repetitive. This repetitive nature is exploited in the LPC and ADPCM. In general, differential coding of images does not produce compression much better than the high-performance lossless algorithms.  Adaptive coding, usually used with differential coding, predicts the upcoming data  pix- els  using previously seen data  pixels , and can adjust the coding scheme accordingly. The prediction MSE is signiﬁcantly inﬂuenced by just the ﬁrst three neighboring pixels, but less inﬂuenced by changes in pixels beyond that. The order of the predictors is the number of pixels used for prediction. Second- or third-order predictors are typically two-dimensional, that is, the predictor uses pixels that are displaced both horizontally and vertically from the pixel that is predicted. Given that the  i, j th pixel is to be predicted, a second-order 2-D predictor can be deﬁned by      714   cid:2   Source coding II: image and video coding ˆx i, j  = 0.5x i, j − 1  + 0.5x i − 1, j   and a third-order 2-D predictor by  ˆx i, j  = 0.75x i, j − 1  − 0.5x i − 1, j − 1  + 0.75x i − 1, j .  After using the predictive coding, the remanent error signal exhibits a very high spike at the location of zero, which is particularly suitable for entropy coding. Entropy coding is then employed to generate the compressed image data.  Although adaptive coding exhibits good performance, the compression is still far from being desirable. Adaptive coding combined with entropy coding is used in lossless compression in JPEG. Predictive coding is also used in lossy modes of JPEG and MPEG.   17.7    17.8   Example 17.1: Given an original image Cynric.bmp of size 240 × 320,  Fig. 17.1a  the outputs for the second- and third-order 2-D predictors,  17.7  and  17.8 , are very similar. The predicted and error images obtained, when the second-order 2-D predictor is used, are also shown in Fig. 17.1. The histograms for the original image and the error images obtained by the two predictors are plotted in Fig. 17.2. The histograms of the two predictors are very similar, and they are very spiky and suitable for entropy coding.   a    cid:2 Figure 17.1  Predictive coding.  a  The original image.  b  The predicted image.  c  The error image.   b    c       715   cid:2   17.5 Transform-based image compression  50  100  150  200  250  50  100  150  200  250  500  5000  5000  0  0  0  0  0  0   cid:2 Figure 17.2  Predictive coding: the histograms of the original, predicted, and error images.  50  100  150  200  250  17.5 Transform-based image compression  In Chapter 13, we introduced the Laplace, z-, and Fourier transforms. DCT is a very popular transform used in image and video processing [1], and belongs to a family of sine and cosine transforms. There are also many other important transforms, such as the Karhunen- Loève transform and DWT.  The Karhunen-Loève transform [10] is an optimum transform that minimizes the over- all MSE between the original and reconstructed images. The Karhunen-Loève transform is more complex than alternate suboptimum transforms such as the sine, cosine, or Fourier transform. A smoothly varying image area has an isotropic statistical depen- dency, which can be described by a ﬁrst-order Markov process with a correlation coefﬁcient of close to unity; under this condition, DCT has an image quality sim- ilar to the Karhunen-Loève transform, and is used in image or video compression standards.  For image compression, lossy compression based on DCT or DWT can generate remark- able compression, and both techniques are commonly employed in modern image and video compression.  Quantization of transform coefﬁcients  The transform itself does not yield any compression. A block of 64 pixels will generate 64 DCT coefﬁcients. Due to the orthogonality of the transform, the energy in both the pixel and transform domains are equal, and thus no compression is achieved. However, the signiﬁcant part of the image energy is at the lower frequency components, while the majority of the higher frequency coefﬁcients have little energy. Also, the human eye is not sensitive to higher frequencies. By discarding the higher frequencies or quantizing them using large step size, compression is achieved.      716   cid:2   Source coding II: image and video coding  Output  Dead zone  Input   cid:2 Figure 17.3  The uniform quantizer with dead zone.  The quantizers used in all standard image video codecs are based on the uniform quan- tizer. Typically, the uniform quantizer is used for quantizing the dc coefﬁcients, while the uniform quantizer with dead zone  UQ-DZ  is used for the ac coefﬁcients. This primar- ily transforms more nonsigniﬁcant ac coefﬁcients to zeros to increase the compression efﬁciency. The uniform quantizer is shown in Fig. 12.6, which can be classiﬁed as the midtread and midrise uniform quantizers. The midtread uniform quantizer is preferred for dc coefﬁcient quantization, since zeros are generated for small dc coefﬁcients. The UQ-DZ is shown in Fig. 17.3.  17.6 JPEG standard  The JPEG  Joint Photographic Experts Group  is a joint ISO IEC and ITU-T standard  IS10918-1, ITU-T T.81  for compression of still images, and was completed in 1992.  17.6.1 Four modes of operation  The JPEG speciﬁcations deﬁne four modes of operation, namely   Baseline sequential encoding: The image is encoded block-by-block from left to right, top to bottom.   Progressive encoding: The image is encoded in such a manner that during decoding the reconstructed image is successively reﬁned for each decoded block  known as scan .   Lossless encoding: The decoded image is the same as the original image bit-by-bit.   Hierarchical encoding: Multiple copies of the image are bundled together with each copy having a different resolution.  These modes rely on distinctly different technologies. The three lossy compression modes are all based on DCT, and the difference between them is the way in which the DCT      717   cid:2   17.6 JPEG standard  8 × 8 block  DCT  Zigzag  Quantization  Entropy encoding  Compressed  stream  Quantization  table  Huffman  table  Compressed  stream  Entropy decoding  Dequantization  Zigzag  IDCT  8 × 8 block   a    b   Huffman  table  Quantization  table   cid:2 Figure 17.4  The JPEG system.  a  Encoder.  b  Decoder.  coefﬁcients are transmitted. The lossless compression utilizes the predictive adaptive coding and a Huffman code output stage.  The baseline sequential mode is the simplest DCT-based coding technique. It is sufﬁcient for many applications, and is the default DCT-encoder for JPEG. The sequen- tial encoding decoding process is shown in Fig. 17.4. JPEG achieves image com- pression by discarding visually insigniﬁcant information such as the high frequency components.  The association between pixels tends to diminish rapidly. A pixel that is even 15 pixels away is of little use for the prediction of the current pixel [20]. For this reason, a DCT block of 64× 64 might not compress much better than if we compress four 16× 16 blocks, but DCT of a 64 × 64 block consumes considerably longer time. JPEG applies DCT to blocks of 8 × 8 image pixels, yielding 64 output frequency coefﬁcients. Progressive encoding is also desirable when the compressed image is transmitted and viewed in real time such as in a Web browser. JPEG uses DCT to transform the image into its spatial frequency components. In the progressive implementation of JPEG, the low-frequency components are compressed and transmitted ﬁrst. These low-frequency components provide the general information of an image, while high-frequency compo- nents give details of the image. On coding a coefﬁcient, a speciﬁed number of MSBs can be encoded ﬁrst, and the other bits can be encoded in subsequent scans. This is known as successive approximation or bit plane encoding.  In the hierarchical encoding mode, an image is coded as a sequence of layers in a pyramid. At different layers of the pyramid, the resolution is different. Each lower layer provides prediction for the next upper layer. The lower-layer image is a downsampling ver- sion of the source image. Except for the top layer, for each layer, the difference between the source image and its lower reference layer is encoded, for the luminance and chromi- nance components, by using DCT or lossless procedure. Thus, the hierarchical mode also provides a progressive representation of an image, but is used in case multiresolution is required.      718   cid:2   Source coding II: image and video coding  The lossless encoding calculates a predicted value for each pixel, and the difference  between the pixel and its predicted value is encoded using Huffman coding.  The decoding procedure is exactly the inverse of the encoding process. JPEG achieves a compression ratio of 2:1 for lossless compression to 20:1 for lossy com- pression. JPEG works best on continuous-tone images, but performs poorly on bi-level images.  The lossy JPEG standard is a modiﬁcation to the scheme proposed by Chen and Pratt [8]. DCT is a lossless transformation that does not perform compression, while the quantization of the DCT coefﬁcients is lossy. Sample C code for demonstrating DCT compression and its expansion is given in [20], and free C source code of JPEG encoder is provided by the Independent JPEG Group.5  Note that the lossless mode of JPEG is different from the later JPEG-LS  ISO IEC 14495-1:1999  standard for lossless coding of still images. JPEG-LS provides a low- complexity solution for lossless image coding with a compression efﬁciency of around 3 to 4. It is also based on adaptive prediction. JPEG-LS uses exponential-Golomb variable-length codes.  17.6.2 Quantization  In JPEG, the RGB image is ﬁrst transformed into a luminance chrominance color space to remove correlation. The pixels of each of the color components are then organized into 8 × 8 blocks. If the number of rows or columns are not a multiple of 8, the bottom row or the rightmost column are duplicated as many times as necessary. DCT is then applied to each 8 × 8 block, and extracts 64 frequency components. The input image is ﬁrst level shifted by 2P−1 from each pixel value, where P is the number of bits used for each pixel. DCT is then applied for each 8 × 8 block, and 64 DCT coefﬁcients are obtained. Uniform midtread quantization is applied to quantize these coefﬁcients, and the quantizer step sizes are given in the form of tables. The quantiza- tion tables for luminance and chrominance recommended by the JPEG standard are given in Table 17.1. These tables are obtained empirically from psychovisual thresholding for luminance and chrominance with 2:1 horizontal subsampling.  The step size generally increases as we move from the dc coefﬁcients to the high- order coefﬁcients. Since the human visual system is more acute to low frequency image information, the low frequency coefﬁcients are assigned more bits, and the dc coefﬁcient is assigned the largest number of bits. This creates more zeros for the high-frequency coefﬁcients, and in the bottom right of the DCT coefﬁcient array, there are some zeros. Compression mainly occurs at this stage. Thus, the quantization table Q = [Q i, j ] can be alternatively implemented by  Q i, j  = 1 +  i + j R,  5 http:  www.ijg.org    17.9       719   cid:2   17.6 JPEG standard  Table 17.1. The quantization tables giving the Q i, j  values, as recommended by JPEG.  luminance  grayscale   chrominance  Cr and Cb   16 12 14 14 18 24 49 72  11 12 13 17 22 35 64 92  10 14 16 22 37 55 78 95  16 19 24 29 56 64 87 98  24 26 40 51 68 81 103 112  40 58 57 87 109 104 121 100  51 60 69 80 103 113 120 103  61 55 56 62 77 92 101 99  17 18 24 47 99 99 99 99  18 21 26 66 99 99 99 99  24 26 56 99 99 99 99 99  47 66 99 99 99 99 99 99  99 99 99 99 99 99 99 99  99 99 99 99 99 99 99 99  99 99 99 99 99 99 99 99  99 99 99 99 99 99 99 99  where R is a parameter provided by the user. In image compression, each input vector is a two-dimensional m×n image block. Pattern matching occurs between the input vector and the constructed codebook. A set of RGB components can be quantized together.  In order to control the compression ratio, a quality factor q, in percentage value between 1 and 100 per cent, is used to scale the quantization matrix Q. In the implementation provided by Independent JPEG Group,6 the quantization matrix is scaled by a compression factor     α =   cid:7   50 q , 1 − q 2  100   cid:8   ,  1 ≤ q ≤ 50 50 ≤ q ≤ 99  ,  subject to the condition that the minimum element of αQ is 1. The value q = 100 corresponds to lossless compression, and in this case all elements of αQ are set as 1.  A For each of the DCT coefﬁcients, a label is obtained + 0.5  l i, j  =  @  ,  S i, j  Q i, j   where Q i, j  is the  i, j th element of the quantization table, S i, j  is the  i, j th DCT coefﬁ- cient, and  cid:24 x cid:25  takes the largest integer that is less than x. The reconstructed value of S i, j  is obtained by   17.10    17.11    17.12   ˆS i, j  = l i, j Q i, j .  The quantization error ˆS i, j  − S i, j  is generally large for high-frequency coefﬁcients due  to the large step size.  As the midtread quantizers have a zero output level, they also function as thresholding and generate zeros for those DCT coefﬁcients whose magnitude is less than half the step size. This typically leads to a long run of zeros.  6 http:  www.ijg.org       720   cid:2   Source coding II: image and video coding  17.6.3 Coding  Coding of the baseline encoder is implemented in two steps. The ﬁrst step converts the quantized DCT coefﬁcients into a set of symbols. Entropy coding is then applied to each symbol. JPEG speciﬁes two alternative entropy coding methods, namely Huffman coding and arithmetic coding. For baseline coding, only Huffman coding is speciﬁed, while for all other modes of JPEG either Huffman or arithmetic coding can be used.  For dc and ac coefﬁcients, as well as luminance and chrominance components, four  different entropy tables may be used. Entropy tables are obtained from the environment.  Coding of dc coefﬁcients  The top-left coefﬁcient  or label  in the DCT coefﬁcient matrix S = [S i, j ] is the dc term, and it is the mean signal level of the block. This component changes slowly between adjacent blocks, and thus can be encoded using DPCM, that is, the dc label is coded as the difference from that of the previous block. The differences can be quite large, and a Huffman code for such a large alphabet can be inefﬁcient.  JPEG resolves this by partitioning the possible values of the differences into categories. The size of the categories grows as a power of two: category 0 has one member, 0; category 1 has two members, -1 and 1, and category n has 2n members, −2n,−2n+1, . . ., −2n−1−1; 2n−1 + 1, . . ., 2n − 1, 2n, for n ≥ 2. Thus, for a difference of 2N possible values, only N bits are required for the Huffman code, and the elements within category n require extra n bits.  Coding of ac coefﬁcients  The ac coefﬁcients  or labels  are arranged in a zigzag sequence within the block, as shown in Fig. 17.5 in order to code all other coefﬁcients in an ascending order of frequency. This leads to a zigzag scan of spatial frequency. The ac coefﬁcients are also encoded in a manner similar to that for the dc coefﬁcients. The possible values of the ac coefﬁcients are   cid:2 Figure 17.5  The zigzag scanning of the 8 × 8 DCT coefﬁcients for an 8 × 8 image block.      721   cid:2   17.7 Wavelet-transform-based image coding  partitioned into categories, but Huffman coding is applied to the ac coefﬁcients themselves rather that to the differences, as in the dc coefﬁcient case. RLE can be applied if a long run of zeros occurs, and if a long run of zeros occurs at the end of the block, an end- of-block  EOB  codeword is used instead. This yields a varying data rate. An increase in compression ratio can be achieved by increasing the step sizes. The higher the compression ratio, the more frequency components in a block turn to zero.  Given an input array, RLE generates a series of  run, level  pairs, where run indicates the number of zeros preceding a nonzero coefﬁcient and level the nonzero coefﬁcient. For example, given an input array 18, 0, 0, 0,−2,−8, 0, 0, 0, 0, 0, −1,−9, the RLE output is  0, 18 ,  3,−2 ,  0,−8 ,  5,−1 ,  0,−9 . Each of these run-level pairs is then encoded as a separate symbol by the entropy encoder.  The nonzero ac labels are further bit-encoded using Huffman or arithmetic coding. The Huffman table is generated from the statistics of the image. Huffman coding is used in most JPEG implementations.  17.7 Wavelet-transform-based image coding  The DCT and other block-based transforms generate blocking artifacts in the image, and these artifacts are more visible at the block boundaries. LOT reduces the artifacts by overlapping adjacent blocks. The wavelet transform is a special type of LOT, and it can eliminate the blocking artifacts. The wavelet transform is used in JPEG2000. Coding of still images under MPEG-4 is also based on the wavelet transform.  17.7.1 Sub-band decomposition  In order to adapt the frequency response of the decomposed pictures to the human visual system, ﬁlters are employed for octave bands in sub-band coding. The wavelet transform is a special kind of sub-band coding. For image processing, the wavelet transform provides a multiresolution representation of an image signal. By using subsampling in the rows and columns, an Nr × Nc image is decomposed into many subimages. If each row is ﬁltered and downsampled, two Nr × Nc 2 subimages are obtained. If we further ﬁlter and downsample the columns of the two subimages, we get four Nr 2 subimages. The four subimages are, respectively, obtained by lowpass ﬁltering 2 the rows and columns  LL , lowpass ﬁltering the rows and highpass ﬁltering the columns  LH , highpass ﬁltering the rows and lowpass ﬁltering the columns  HL , and highpass ﬁltering the rows and columns  HH . This procedure is illustrated in Fig. 17.6, where H0 and H1 are lowpass and highpass ﬁlters, respectively.  × Nc  In fact, an original image can be divided into a variety of sub-band structures. For exam- ple, each of the four subimages in Fig. 17.6 can be further ﬁltered and subsampled, in a recursive fashion. A popular decomposition is to further subdivide the LL subimage into      722   cid:2   Source coding II: image and video coding   cid:2 Figure 17.6  Sub-band decomposition of an image.  2  2  2  2  LL  LH  HL  HH  H0  H1  H0  H1  LH  Image  H0  H1  L1  2  H1  2  LL2  LH2  HL2  HH2  LH1  HL1  HH1  HL  HH   cid:2 Figure 17.7  A popular structure for image sub-band decomposition.  four more subimages  LL1, LH1, HL1, HH1 , and LL1 is further divided into four more subimages, resulting altogether 10 subimages. This is shown in Fig. 17.7.  17.7.2 Wavelet ﬁlter design  In sub-band coding, perfect reconstruction is achieved if  13.178  is satisﬁed. By adding some constraints on H0 z  and H1 z  such that the property of the wavelet transform is maintained, wavelet ﬁlters can be designed. The wavelet deﬁnition requires H0 z  and H1 z  to be continuous functions of z. It is desirable to have the largest possible number of con- tinuous derivatives; this corresponds to having zeros at z = −1 for the wavelet ﬁlters. On the other hand, the wavelet ﬁlter is required to have linear phase response, since the phase carries information in the case of the image. Thus, for a wavelet ﬁlter having at least n zeros at z = −1, we can write [13]  P z  = H0 z H1 −z  =  Q z ,   17.13    cid:3 2n   cid:2   1 + z −1 2  where Q z  has n unknown coefﬁcients, and the notations H0 z , H1 z , and P z  are the same as those used in Section 13.11.1.      723   cid:2   17.7 Wavelet-transform-based image coding   cid:17  When n = 2 and Q z  = −1 + 4z   cid:18 4 cid:17   −1 − z −2, we have [13] 1 + z −1  −1 + 4z  −1 − z  −2   cid:18   P z  = 1 16  cid:17   By factorization, we have a  5,3  ﬁlter bank −1 + 6z −1 + 2z  cid:17   H0 z  = 1 8 H1 −z  = 1 2  1 + 2z  −2 + 2z  −4  ,  −3 − z  cid:18   −1 + z  −2  .  .   cid:18    17.14    17.15    17.16    17.17    17.18    17.19   The  5,3  wavelet ﬁlter pair is implemented using integer arithmetic, and the result- ing transform is reversible, enabling lossless compression. The  5,3  integer ﬁlter pair is recommended for lossless image coding in JPEG2000. In JPEG, lossless coding is not possible if DCT is used, since the cosine elements of the transformation matrix can only be obtained by approximation. In order to preserve the image energy in the pixel and wavelet domains, the ﬁlter coefﬁcients are normalized for unit gain. It should be noted that the paired lowpass and highpass ﬁlters are biorthogonal [13]. The highpass ﬁlter is given as   cid:17    cid:18   1 − 2z  −1 + z  −2  .   cid:18   ,   cid:18   −1 + 3z  −2 + z  −3  −1 + 3z  −2 − z  −3  .  H1 z  = 1 2  cid:17   cid:17   P z  can also be factored differently to obtain a  4,4  ﬁlter bank  1 + 3z  H0 z  = 1 4 H1 −z  = 1 4 Both pairs give P z  − P −z  = 2z −3. −1 + 38 When n = 3 and Q z  = 1 − 6z 3 z  9,3  pair of Daubechies wavelet ﬁlters [9, 13]:  −1 + 3z  H0 z  = 0.99436891104360 + 0.41984465132952  − 0.17677669529665 + 0.03314563036812  z2 + z z4 + z   cid:17   cid:17   −3 + z −4, P z  can be factorized into a  cid:17   −2 − 6z  cid:18   cid:18   −2 −4  −1  z + z   cid:18  − 0.06629126073624  cid:18    cid:17   ,   cid:17   z3 + z  −3   cid:18    17.20    17.21   H1 z  = 0.70710678118655 − 0.35355339059327  z + z  −1  .  The  9,3  Daubechies wavelet ﬁlter pair is recommended for still image coding in MPEG-4.  Another pair of wavelet ﬁlters supported by JPEG2000 is the  9,7  ﬂoating-point wavelet. The  9,7  wavelet transform uses ﬁlters with ﬂoating-point impulse responses      724   cid:2   Source coding II: image and video coding  H0 z  and H1 z  of length 9 and 7, as the lowpass and highpass analysis ﬁlters, respectively [13]:  H0 z  = 0.85269865321930 + 0.37740268810913   cid:17   cid:17   z2 + z z4 + z  −2 −4   cid:17   −1   cid:17    cid:18   cid:18   z + z   cid:18  − 0.02384929751586  cid:18  −1 − 0.06453905013246  z + z   cid:17    cid:17   ,   cid:18   z2 + z  −2   cid:18   z3 + z  −3   17.22    cid:18   z3 + z  −3  .  17.23   − 0.11062402748951 + 0.03782879857992  cid:17   0.04068975261660  H1 z  = −0.7884848720618 + 0.41809244072573  The QMF solution for the low- and highpass synthesis ﬁlters is given by  g0 n  = − −1 nh1 n ,  g1 n  =  −1 nh0 n .   17.24   This transform is known as the irreversible transform, and is used for high-performance lossy compression. The synthesis ﬁlter pair is related to the analysis ﬁlter pair by  13.176 . Nearly orthogonal ﬁlter banks with linear phase have been designed by optimization in [45], which makes a symmetric ﬁlter with a certain number of zeros at z = −1 to approximate the power complementary condition. Symmetric biorthogonal wavelets can be designed from a symmetric regular ﬁlter [44].  17.7.3 Coding of wavelet subimages  The lowest band of the wavelet subimages is a replica of the original image, but at a reduced size. When the number of wavelet decomposition levels is very high, as in JPEG2000, the correlation between the pixels in this subimage is very small. In this case, pixel-by-pixel coding can be used. In MPEG-4 still image coding, where the number of decomposition levels is not as high as that of JPEG2000, some correlation remains between pixels, and DPCM is used to reduce the correlation.  EZW and SPIHT  In Fig. 17.7, the subimages in each band are similar to its higher band subimages. A coef- ﬁcient in a lower band corresponds to four coefﬁcients in its immediate higher band. For example, a coefﬁcient in HL2 corresponds 4 coefﬁcients in HL1, and 16 coefﬁcients in HL. This is also true for LH2 and HH2 bands. Thus, if a coefﬁcient in a sub-band is zero, the corresponding coefﬁcients in the higher bands are likely zero. This yields a tree of zeros, called zero tree. This method is very efﬁcient for representing a very large num- ber of zeros in the wavelet coefﬁcients, since we need only specify the root of the zero tree.  The embedded zero-tree wavelet  EZW , or embedded coding using zero-trees of wavelet coefﬁcients, algorithm [28] is a breakthrough in coding of the wavelet coefﬁcients. For      725   cid:2   17.7 Wavelet-transform-based image coding   cid:2 Figure 17.8  Illustration of the quad zero tree representation of the bands.  compression of higher bands, the wavelet coefﬁcients are coded with a zero-tree structure using the EZW algorithm. It is observed that the nonsigniﬁcant coefﬁcients from bands of the same orientation tend to be in the same locations, thus a zero-tree representation of the bands can be implemented. This is illustrated in Fig. 17.8 for a three-stage wavelet transform.  The EZW method and its variants are based on quantization by successive approx- imation, where the wavelet coefﬁcients are represented by progressively decreasing quantization step sizes and the number of approximation passes depends on the speciﬁed quantization distortions. An adaptive arithmetic encoder is used to encode the generated symbols. In order to achieve spatial or SNR scalability, the algorithm scans the wavelet coefﬁcients from the lowest to the highest frequency sub-bands  spatial scalability , or for each tree from the root to the leaves.  The set partitioning in hierarchical trees  SPIHT  algorithm [24] is a variant of the EZW algorithm. SPIHT outperforms the EZW algorithm, even without arithmetic coding. Both EZW and SPIHT inherently offer only SNR scalability. By modifying the bitstream, spatial scalability can be achieved. This, however, leads to the loss of SNR scalability. The zero- tree structure also yields error propagation through the sub-bands.  Wavelet-Based Codecs in Source Code  There is a wavelet transform coder construction kit coded in C, which can be used for testing the performance of wavelets.7 The code is very modular, and it allows for simple replacements of individual components such as the quantizer, entropy coder, and wavelet ﬁlters. Although it does not use zerotrees, its performance is comparable to that of the EZW coder.  The SPIHT codec is also available in C and MATLAB code.8 The SPIHT codec achieves good image quality and high PSNR, especially for color images. It is optimized  7 http:  www.geoffdavis.net dartmouth wavelet wavelet.html  8 http:  www.cipr.rpi.edu research SPIHT       726   cid:2   Source coding II: image and video coding   a    c    b    d    cid:2 Figure 17.9  SPIHT coding at 0.1 bit pixel.  a  The original image.  b  The compressed wavelet transform.  c  The reconstructed image.  d  The error image.  for progressive image transmission, and produces a fully embedded bitstream with error protection. It can code to exact bit rate or distortion. It can also be used for lossless compression.  Example 17.2: Given an original image Huiyu.jpg of size 240 × 320 and a compression rate of 0.1 bit pixel, the result from SPIHT coding is displayed in Fig. 17.9. There are four images, namely the input, compressed wavelet transform, reconstructed, and error images. The PSNR is 29.7679 dB. The reconstructed pictures for two rates 0.25 and 0.5 bit pixel are shown in Fig. 17.10 for comparison with the 0.1 bit pixel case, with corresponding PSNRs 32.7689 and 35.6568 dB. It is shown that SPIHT coding achieves a very good image quality even at a very high compression ratio.  The deﬁciencies of EZW and SPIHT can be avoided if each sub-band is coded inde- pendently. Embedded block coding with optimized truncation  EBCOT  [33, 34] exploits  EBCOT      727   cid:2   17.7 Wavelet-transform-based image coding   cid:2 Figure 17.10  The reconstructed images of SPIHT coding:  a  at 0.25 bit pixel.  b  at 0.5 bit pixel.   a    b   this idea. It further partitions sub-band samples into small blocks and codes each block independently. EBCOT offers an excellent compression performance together with a set of bitstream features, including resolution scalability, SNR scalability and a spatial random access capability. All features can exist coexist within a single bitstream with- out a substantial sacriﬁce in compression efﬁciency. The EBCOT algorithm is adopted in JPEG2000.  The EBCOT algorithm uses a wavelet  transform to generate the sub-band sam- ples that are to be quantized and coded. Block coding is independently performed on nonoverlapping blocks within individual sub-bands. All blocks within a sub-band are required to have the same dimensions, except for those blocks on the right or lower boundaries.  EBCOT in Comparison with EZW and SPIHT  The embedded coding strategy used in EBCOT is similar to that used in EZW, but their data structures are different. EZW is capable of compressing an image with excellent rate times distortion performance, and the encoding rate can be precisely controlled with optimal performance for all rates. EZW utilizes the fact that some wavelet coefﬁcients in different sub-bands represent the same location in the image. In EBCOT, since each block is coded independently, it is suitable for parallel hard- ware encoding and decoding. Unlike EZW and SPIHT that use the zero-tree struc- ture, the similarities between sub-bands are not exploited in EBCOT, but the more efﬁcient context-based arithmetic coding and the post-compression rate distortion opti- mization are used. EBCOT avoids the tree data structure, but uses a quadtree data structure.  An entropy-coded bitstream is extremely sensitive to channel errors. In EBCOT, each code block is independently encoded, and the individual quality packets can be indepen- dently decoded, and thus the effects of the channel errors are conﬁned to a small area. In contrast, due to the zero-tree structure together with entropy coding, a single bit error may destroy a whole picture encoded by EZW or SPIHT.      728   cid:2   Source coding II: image and video coding  EBCOT has low implementation complexity and excellent compression performance. Among EZW, SPIHT, and EBCOT, EZW provides the poorest compression performance, and the SPIHT and EBCOT have similar compression efﬁciency.  EBCOT Implemented in Three Stages  In EBCOT, the code block size is typically 32 × 32 or 64 × 64. The code block size can be freely selected, but the dimensions must be an integer power of two and the height cannot be less than four. EBCOT can be implemented in three stages, namely bit plane quantization, binary arithmetic coding  tier 1 coding , and bitstream organization  tier 2 coding .  At the quantization stage, all code blocks in a sub-band use the same quantizer, and successive approximation takes the form of bit plane quantization. The wavelet coefﬁcients are ﬁrst represented by their maximum precision and the process continues until the least precision; that is, they are encoded one bit at a time, starting with the MSB and terminating at the LSB. When the bitstream is truncated, some or all of the samples in a block may omit one or more LSBs. This is the same as using a UQ-DZ with a dead zone width of  cid:18 b2p, where  cid:18 b is the uniform quantization stepsize for K-bit representation, and p is the number of LSBs truncated.  After the bitstream is generated, EBCOT identiﬁes whether a coefﬁcient should be coded based on the binary signiﬁcant state and then codes it. The arithmetic coding of the bit plane, called tier 1 coding, generates one independent embedded bitstream for each code block. Tier 2 coding organizes the bitstreams for transmission. By sig- naling the ordering of the code bit plane pass, the SNR and spatial scalability is enabled.  In EBCOT, context-based adaptive binary arithmetic coding  CABAC  is used for entropy coding of each symbol, where the status of eight immediate neighbors is used for adaptation of the probability model. The entire bit plane is not encoded in one pass. Instead, each bit plane is encoded in three sub-bit-plane passes. This is called fractional bit plane coding. This creates an optimum bitstream after trunca- tion, and the technique is known as post compression rate distortion  PCRD  opti- mization. The ﬁrst pass of the fractional bit plane coding gives the largest reduc- tion in the encoding distortion. The PCRD optimization makes efﬁcient rate control possible.  Spatial and SNR Scalability  In EBCOT, spatial scalability is easily realized due to the octave sub-band decomposi- tion. The bitstream is organized such that all the bit planes of the lower level sub-bands precede those of the higher sub-bands. For SNR scalability, a succession of images of the same spatial resolution is involved. The lowest layer that corresponds to the low- est quality image is called the base layer, and the parts of the bitstream for enhancing the image quality are called enhancement layers. This is also achieved by bit plane coding.      729   cid:2   17.8 Wavelet-based image coding standards  17.8 Wavelet-based image coding standards  17.8.1 JPEG2000 standard  JPEG2000 is a new joint ISO IEC and ITU-T standard  IS 15444-1 and ITU-T T.800  for still image coding, and was completed in 2001. JPEG2000 is based on the two-dimensional DWT and EBCOT [33, 34]. JPEG may introduce blocky appearance for a large compres- sion ratio, and JPEG2000 outperforms the older JPEG standard by approximately 2 dB of PSNR, for several images across all compression ratios. JPEG2000 achieves a substantially decreased distortion at low-bit rates. In JPEG2000, a bit rate of less than 0.25 bit per pixel is expected for grayscale images. JPEG2000 is capable of compressing both continuous tone and bilevel images.  JPEG2000 provides a signal decompression architecture for greater interoperabil- ity. It combines all four JPEG modes. Many types of scalability are supported by JPEG2000, and this is very desirable for transmission over slow communication links. Progressivity can be achieved in terms of quality, resolution, spatial location, and com- ponent. It also supports region of interest  ROI  compression. Since only the data required by the viewer needs to be transmitted, the effective compression ratio at the client is much greater than the actual compression ratio that is calculated from the ﬁle size at the server. JPEG2000 also includes error-correcting codes into its com- pressed stream to achieve error resilience for reliable image transmission in noisy channels.  The JPEG2000 encoder is based on the EBCOT algorithm. Some speciﬁc features of  JPEG2000 are introduced here.  Tiling  In JPEG2000, the ﬁrst step is to divide an image into nonoverlapping rectangular blocks of the same size called tiles, each being encoded independently. The tile size can be arbitrary, and it can be as large as the whole image or as small as a single pixel. Due to tiling, correlation between pixels in adjacent tiles is not exploited.  Color decorrelation  As in JPEG, dc level offsetting is applied to the RGB components within each tile. This is implemented by shifting all RGB components by 2B−1, where B is the resolution of the color component.  For multicomponent images, two types of color decorrelation transforms, namely the irreversible color transform and the reversible color transform, are recommended. Irreversible color transform is used to generate the YCrCb components from RGB com- ponents, and this is described in Section 17.2.2. The irreversible transform is used only for lossy compression. The reversible color transform is an approximate version of the irreversible transform and generates only integer outputs      730   cid:2   Source coding II: image and video coding  ⎡⎣ Y  U V  ⎤⎦ =  ⎡⎣ 0.25  1 0  ⎤⎦ .  ⎤⎦⎡⎣ R  G B  0.25 0.25 −1 −1  0 1   17.25   Although the color decorrelation of the reversible color transform is not as good as that of the irreversible color transform, the original RGB values can be recovered if YUV is losslessly coded.  In JPEG, the chrominance components are subsampled by 4:2:2 or 4:2:0 image for- mats. In JPEG2000, color subsampling is not performed by spatially subsampling a block, but by setting the wavelet coefﬁcients of the highest LH, HL, and HH sub-bands to zero.  DWT and quantization  Instead of DCT, DWT has been applied to each tile. DWT is implemented by using the  9,7  or  5,3  wavelet ﬁlter bank. The wavelet coefﬁcients generated are then quantized using a uniform quantizer with a dead zone. The quantization step size varies from sub-band to sub-band and from tile to tile. Exploiting the human visual system, the selection of quan- tization step size could be similar to the use of the quantization matrices recommended in JPEG. EBCOT uses successive approximation for quantizing the wavelet transform coefﬁcients.  The basic quantizer step size  cid:18 b in the sub-band b is related to the dynamic range of the  sub-band. It is represented by [13]   cid:17    cid:18   ,   cid:18 b = 2Rb− cid:21 b  1 + μb 211   17.26   where R is the number of bits for representing the dynamic range of the sub-band, μb is a 11-bit mantissa, and  cid:21 b is a 5-bit exponent. 2Rb is greater than the magnitude of the largest coefﬁcient in the sub-band b. A total of 2 bytes  μb and  cid:21 b  is sent to the decoder. For the  5,3  ﬁlter bank, μ = 0 and  cid:21 b = Rb, thus  cid:18 b = 1.  Entropy coding and postprocessing  The indices of the quantized coefﬁcients in each sub-band are encoded by using arithmetic coding. EBCOT is used for efﬁcient coding of the indices, and the compressed bitstream is created. The compressed bitstream for each code block is then organized in a way similar to that in EBCOT.  17.8.2 MPEG-4 still image mode  MPEG-4 also supports still texture  image  coding, known as MPEG-4 Visual Texture Cod- ing  VTC . MPEG-4 VTC is very similar to JPEG2000. For coding of still images, DWT is used, and a high compression efﬁciency as well as spatial and SNR scalability is achieved [13]. MPEG-4 VTC does not provide a lossless functionality.      731   cid:2   17.9 Comparison of image coding standards  The Daubechies  9,3 -tap biorthogonal ﬁlter is used. The wavelet coefﬁcients of the lowest band are DPCM-coded with a uniform quantizer. A layered structure, which is a variant of EZW, is used to code the higher band wavelet coefﬁcients. The quantizer for each layer is uniform with a dead zone of twice the quantization step size of the layer.  The resulting bitstream is further encoded by an arithmetic encoder. A shape-adaptive DWT  SA-DWT  is used for compression of arbitrarily shaped textures. As in the case of the shape-adaptive DCT  SA-DCT  used in the MPEG-4 Video mode, the number of the transform coefﬁcients obtained for SA-DWT is exactly the same as the number of pixels in the arbitrarily shaped region. When the object boundary is rectangular, SA-DWT reduces to the regular wavelet transform.  17.9 Comparison of image coding standards  17.9.1 Comparison of six popular standards  A comparison of JPEG2000 with JPEG-LS, MPEG-4 VTC, JPEG and PNG, and well established algorithms, such as SPIHT has been performed in [29], by using seven images from the ofﬁcial JPEG2000 test set. The comparison makes use of the software implementations:   The JPEG2000 Veriﬁcation Model  VM  6.1  ISO IEC JTC1 SC29 WG1 N 1580 .   The MPEG-4 MoMuSys VM of Aug. 1999  ISO IEC JTC1 SC29 WG11 N 2805 .   The Independent JPEG Group JPEG implementation,9 version 6b.   The SPMG JPEG-LS implementation of the University of British Columbia,10 version 2.2.   The Lossless JPEG codec of Cornell University,11 version 1.0.   The libpng implementation of PNG,12 version 1.0.3.   The SPIHT codecs,13 version 8.01. For lossless compression, amongst JPEG2000, JPEG-LS, lossless JPEG  L-JPEG , PNG and SPIHT, JPEG-LS generally yields the best performance. JPEG2000 provides compet- itive compression ratios with the added beneﬁt of scalability. The performance of SPIHT and PNG are very close to that of JPEG2000 on most images. The performance of lossless JPEG is poorer than the others. They can be ordered as  L-JPEG < SPIHT, PNG  cid:4  JPEG2000 < JPEG-LS  Lossless Compression   For lossy compression, amongst JPEG2000, JPEG, MPEG-4 VTC, and SPIHT, in case of nonprogressive bitstreams, JPEG2000 outperforms all other algorithms at all bit rates,  9 http:  www.ijg.org   10 http:  spmg.ece.ubc.ca   11 ftp:  ftp.cs.cornell.edu pub multimed  12 ftp:  ftp.uu.net graphics png  13 http:  www.cipr.rpi.edu research SPIHT       732   cid:2   Source coding II: image and video coding  and the performance of JPEG is the poorest at all rates. The advantage of JPEG2000 over the others becomes signiﬁcant as the compression ratio increases. In case of SNR-scalable bitstreams across various bit rates, JPEG2000 outperforms all the other algorithms, and JPEG produces the worst performance. The performance of the various algorithms is also very close to their nonprogressive cases, except for JPEG. The order is  JPEG  cid:5  MPEG-4 VTC, SPIHT < JPEG2000   Lossy Compression   As for the complexity, in case of lossless compression and decompression, JPEG-LS provides the fastest compression, JPEG2000 is considerably more complex, and the com- plexity of SPIHT is higher than that of JPEG2000. The complexity of L-JPEG is slightly higher than that of JPEG-LS, and the complexity of PNG is higher than that of L-JPEG. That is,  JPEG-LS  cid:4  L-JPEG < PNG  cid:5  JPEG2000 < SPIHT  Complexity, Lossless   For nonprogressive coding, JPEG2000, MPEG-4 VTC and SPIHT are all signiﬁcantly slower than JPEG, with MPEG-4 VTC signiﬁcantly slower than the others. Similar behavior can be observed for the progressive case. That is,  JPEG  cid:5  JPEG2000, SPIHT  cid:5  MPEG-4 VTC  Complexity, Lossy   For error resilience, JPEG and JPEG-LS provide basic error resilience mechanisms, while JPEG2000 and MPEG-4 VTC offer stronger ones. PNG only provides support for error detection. The quality of reconstructed images is higher for JPEG2000 than for JPEG, for all encoding bit rates and error rates. That is,  PNG < JPEG, JPEG-LS  cid:5  JPEG2000, MPEG-4 VTC  Error resilience   ROI coding is a novel functionality of JPEG2000. The JPEG2000 implementation used for evaluation was JJ2000,14 version 4.0, contained in the JPEG2000 Part-5 FCD  ISO IEC JTC 1 SC 29 WG 1, ISO IEC FCD 15444-5: WG 1 N 2020, January 2000 , since it provides better ROI support than the VM.  JPEG2000 provides more progressive types and orderings than MPEG-4 VTC. MPEG- 4 VTC is the only evaluated standard, which is capable of coding individual objects of arbitrary shapes. Overall, JPEG2000 offers the richest set of features and provides superior rate distortion performance.  In summary, JPEG is suitable for lossy compression with the requirement of low complexity; JPEG-LS provides the best option for lossless compression, with the best compression efﬁciency at a low complexity; PNG is also a good solution for lossless com- pression. MPEG-4 VTC may be desirable when arbitrarily shaped objects are required to be coded. JPEG2000 provides the most ﬂexible solution, providing good compression efﬁciency as well as many other features.  14 http:  jj2000.epfl.ch      733   cid:2   17.10 Video data compression  17.9.2 DjVu and adaptive binary optimization  ABO   Different compression methods are normally used for different types of images. For exam- ple, JBIG is used for bi-level images, and JPEG for continuous images. In some pictures, such as a scanned document, features of various types of pictures are contained in one image. Djvu from AT&T Laboratories is designed for this purpose.15 DjVu is a free ﬁle format. It has been proposed as an alternative to the PDF format for documentation.  DjVu is a progressive compression method. DjVu typically achieves a compression factor as high as 1000 for scanned pages. For colored documents with both text and pictures, a DjVu ﬁle is typically 5 to 10 times smaller than the JPEG ﬁle with the same quality. DjVu ﬁles are about ﬁve times smaller than the PDF ﬁles for scanned documents.  DjVu decomposes the scanned document into three components, namely, mask, fore- ground, and background. The mask images contain the text and lines that are in bi-level form, and the foreground images contains their colors. The background is a continuous- tone image. Since each component has a different feature, they can be compressed at different resolutions. The background and foreground images are compressed using IW44, which is a method using integer wavelet, while the mask is compressed using an algorithm called JB2  similar to JBIG2 .  MatrixView’s adaptive binary optimization  ABO  is a versatile and pervasive tech- nique as it allows optimization of any form of digital content including images, videos, sound, and text.16 By using repetition and correlation coding  RCC , ABO exploits the repetition and correlation found in the data. It generates lossless compression and native- embedded encryption of data. ABO is claimed to be able to achieve at least 300% more lossless compression than the levels reached by JPEG and JPEG2000 in the lossless mode. Also ABO has a much lower complexity than JPEG and JPEG2000, achieving higher encoding decoding and transmission speeds.  17.10 Video data compression  Video is a succession of images. When each image is coded as an independent JPEG image, the process is called motion JPEG. Motion JPEG is very resilient to loss of information. Motion JPEG is popular for video capture, video editing, and security surveillance. It is most suitable for transmission over packet networks such as the Internet.  Video can be viewed as a sequence of correlated images. This temporal correlation is used by most video compression algorithms to remove redundancy. The 3-D DCT can be applied on an m-row, n-column, k-frame block. This method requires memories for k frames at both the encoder and the decoder to buffer the frames. This also limits its real-time applications, and k is typically selected between 2 and 4.  15 http:  www.djvu.org   16 http:  www.matrixview.com      734   cid:2   Source coding II: image and video coding  The standard video compression approach is based on motion compensation. The previous reconstructed frame is used to generate a prediction of the current frame, and only the difference between the prediction and the current frame, known as the predic- tion error, is encoded. The prediction operation must provide motion compensation to the motion of the objects in the frame. Currently, video codecs are standardized by MPEG and ITU-T. The structures of MPEG standards and ITU-T H-series standards are similar since many of the members have joined both the groups.  17.10.1 Frame format  ITU-R Rec. BT.601 deﬁnes a digital video format for broadcasting. It deﬁnes two inter- laced systems: 525 60 and 625 50, which are based on the 4:2:2 YCbCr sampling. For storage applications, the source input format  SIF  was deﬁned. SIF is based on a noninter- laced  or progressive  system with 4:2:0 YCbCr sampling. SIF has a luminance resolution of 352 × 240 at 30 frames s or 352 × 288 at 25 frames s, corresponding to the two ITU-R Rec. BT.601 systems. The quarter-SIF  QSIF  has half the resolution of SIF in both the row and column directions.  Common video compression standards deﬁne a number of video frame formats. The common intermediate format  CIF  is the basis for a popular set of formats. The CIF is deﬁned for compatibility between the two ITU-R Rec. BT.601 systems. It is a progres- sive system, with 4:2:0 mid-sited sampling and a frame rate of 30 frames s. The CIF has a luminance resolution of 352 × 288. Other four frame formats in the CIF family are 16CIF  1408 × 1152 , 4CIF  704 × 576 , quarter-CIF  QCIF, 176 × 144 , and sub-QCIF  128 × 96 . The selection of frame resolution depends on the application and transmission capacity. These frame formats are used for standard-deﬁnition television  SDTV , DVD  digital versatile disc  video, video conference, and mobile multimedia. For HDTV  high deﬁnition television , some other formats are also deﬁned.  17.10.2 Frame types  MPEG deﬁnes three coded pictures: intra-picture  I , predicted-picture  P , and bidirec- tional predicted picture  B . I-frames are coded independently of the other frames, and act as the start for replay sequences. P-frames are used to predict motion from the previous reference frames, which can be the last I-frame or P-frame, whichever is closer to it. I- and P-frames are called anchor frames, because they are used as references in the coding of other frames using motion compensation.  B-frames are generated from a previous anchor frame and a future anchor frame by using motion compensation. The B-frame achieves a higher compression, and it is gen- erated only after the future anchor frame has been generated. The use of B-frames can effectively compress the video, especially in case of a sudden change from one frame to the next. Use of B-frames increases the motion compensation efﬁciency, since occluded parts of moving objects can be compensated for from a future frame. Also, B-frames are      735   cid:2   17.10 Video data compression  not used for predicting any other frames, and thus can be discarded without affecting the pictures that follow. For this reason, B-frames can tolerate more error, and bit rate control can be performed by controlling the number of B-frames or the quantization of B-frames. However, the use of B-frames leads to a delay of several frames, which is equal to the num- ber of B-frames between two anchor frames, for the encoder and the decoder. This limits its application to telecommunications.  Finally, there is also a fourth picture type called D-frame. It is intraframe-coded, where only the dc coefﬁcients are retained. D-frames are intended for fast visible search modes, but not used in groups of pictures  GOPs . Of course, this fast search mode can also be supported by using the I-frames in a sequence.  17.10.3 Motion compensation  Motion compensation can effectively increase the compression efﬁciency of interframe coding. To perform motion compensation, motion estimation has to be performed ﬁrst. Block-based motion compensation, ﬁrst proposed by Jain and Jain in 1981 [17], is imple- mented in all the standard video codecs, and the technique is called the block matching algorithm. The motion estimation and compensation, sometimes referred to as DPCM, is used together with a DCT stage and an entropy encoder in all the major video stan- dards such as H.261 3 4 and MPEG-1 2 4 Visual. Motion estimation and compensation is optional in H.261, but is an important integral part of all later MPEG and ITU-T H-series video codecs standards. In a standard codec such as MPEG-1 2 4 or H.261 263 264, a block of 16 × 16 pixels, called a macroblock, is motion estimated and compensated. Motion estimation is per- formed only on the luminance parts of a frame. The motion vector is used for motion compensation of all the four luminance blocks in the macroblock, and is scaled for compen- sation of the chrominance blocks. After motion estimation, the residual block is encoded and transmitted, and the motion vector is also transmitted. Motion vectors for neighboring partitions are often highly correlated and each motion vector can thus be predicted from the motion vectors of nearby partitions, that is, the motion vectors can be DPCM coded and then entropy encoded.  Full-search method  In a typical block matching algorithm, the frame is ﬁrst divided into M × M blocks. For each block, the algorithm searches the previous reconstructed frame for the M × M block that most closely matches it, and the distance between the two blocks is measured in pixels. When the distance is greater than a prespeciﬁed threshold, the block is encoded without using prediction; otherwise, a motion vector is included into the bitstream. The motion vector gives the relative location of the two blocks. For a maximum motion speed of w pixels per frame, the current block of pixels with the upper-left corner at  m, n  is matched against a block with upper-left corner at  m + i, n + j , −w ≤ i, j ≤ w, in the previous frame. This is shown in Fig. 17.11.      736   cid:2   Source coding II: image and video coding         , n+j  m+i  Motion vector  A block in the current frame   m, n     A block in the previous frame   cid:2 Figure 17.11  Motion estimation based on the comparison of the current and previous frame.  Frame  M cid:26  M cid:26   cid:19  M cid:26  M cid:26   n=1  m=1  The motion vector corresponds to the best match, according to an MSE or MAD criterion  MSE i, j  = 1 M2  p0 m, n  − p−1 m + i, n + j    17.27    cid:20 2 ,  MAD i, j  = 1 M2  p0 m, n  − p−1 m + i, n + j  ,  n=1  m=1   17.28  for −w ≤ i, j ≤ w, where p0 m, n  is a pixel of the current block at coordinate  m, n , and p−1 m + i, n + j  is a pixel of the corresponding block in the previous frame. When the 1 M2 term is dropped, the MSE criterion becomes the sum of squared differences or errors  SSD or SSE  criterion, and the MAD criterion reduces to the sum of absolute differences or errors  SAD or SAE  criterion. SAD has lower complexity, and is used in all the video codecs. The block matching algorithm based on full search requires  2w + 1 2 tests of the cri- terion. The search range w = ±15 pixels is sufﬁcient for low-bit-rate applications, and H.263 uses a maximum displacement of ±15 pixels. In a typical video sequence, motion vectors are concentrated around  0, 0 . Full search thus starts at  0,0  and proceeds in a spiral pattern around this location. Motion estimations can occupy 50–70 per cent of the overall complexity of the encoder if the full search method is used [13]. Thus, the full search method is only suitable for hardware implementation.  Motion estimation is conventionally based on the assumptions that the motion is trans- lational and that the illumination is uniform. When these assumptions are not satisﬁed, such as in the case of the movement of human eyes, a geometrical transformation that con- verts a square block of N × N pixels into an irregular quadrilateral shape can be used, by using a bilinear transform [13]. This type of motion estimation compensation is extremely complex, and numerous methods for simplifying the operations are available.  Example 17.3: In this example, we select the ﬁrst 30 frames of the coastguard sequence in QCIF format at a frame rate of 8.33 frames s  a frame skip of 3 , and apply the block matching algorithm on the luma component only. Blocks of size 16 × 16 are used, and the maximum allowed motion displacement of ±15 pixels in both directions is applied. Motion is estimated and compensated using original previous frames, while the motion      737   cid:2   17.10 Video data compression   a      B d      R N S P  30  29  28  27  26  25  24  23  22  SAD SSD  0  10  20  40  50  60  30  Frame   b    cid:2 Figure 17.12 The block matching algorithm.  a  The 1st and 60th frames.  b  PSNRs of the reconstructed  frames.  vectors are restricted to points inside the reference frame. Motion vectors can be encoded using the predictive coding followed by variable-length coding. Neglecting the difference between the original and matched blocks, the PSNR values using the SSD and SAD mea- sures are plotted in Fig. 17.12. It is seen that the SSD criterion yields a slightly better PSNR performance than the SAD criterion does.  Fast block motion estimation  Instead of searching over all possible blocks within the search window, a number of fast block matching algorithms have been proposed, where the search is carried out over a sub- set of the blocks. Such algorithms are based on the assumption of unimodal error surface, namely that the block distortion measure increases monotonically as the search location moves away from the best-match location [17]; this may cause false estimations  a local      738   cid:2   Source coding II: image and video coding  minimum of distortion , for high motion speeds. Fast block matching algorithms, such as the two-dimensional logarithmic search [17] and the three-step search  TSS  method [18], typically have a complexity that grows with log2 w, where w is the search range [13]. They are more suitable for slow moving objects, as in video conferencing. The TSS requires 1 + 8 log2 w tests, and is recommended by ITU-T for software-based H.261.  A fast block matching algorithm based on a feature-bit-plane matching scheme has been proposed in [42], whose accuracy is very close to that of the full-search method, but with a complexity of only one-tenth that of the latter. A block of pixels are requantized into two levels based on a given grey level T and full search is then applied on the feature bit plane. Also, the addition operation is replaced by the XOR operation.  In [11], a fast block matching algorithm, which achieves the same accuracy of the full-search algorithm, is proposed. The method is well suited for SIMD implementation. Parallel SIMD implementation of block motion estimation can substantially decrease the encoding time [12]. In [37], motion estimation based on pyramidal data structure has been implemented by exploiting the inter-level motion correlation as well as the intra- level motion correlation. Motion estimation based on multiplicationless Burt and Adelson’s pyramids was implemented in [38].  Variable-size block motion compensation can effectively reduce the overhead of motion vectors, leading to very-low-bit-rate video coding [43]. In addition, global motion com- pensation is useful for increasing the coding efﬁciency at low bit rates for some video sequences that contain global motion arising from camera motion. This can signiﬁcantly reduce the number of motion vectors.  Motion estimation with fractional pixel accuracy  Motion estimation can be implemented with fractional pixel accuracy, and it can be with half pixel precision, quarter pixel precision, or eighth pixel precision. In the search pro- cess of fractional pixel accuracy, normal block matching with integer pixel position is performed ﬁrst. Then, the subpixel positions and their pixels are obtained by interpolation from the pixels of the macroblock in the previous frame.  In H.261, motion compensation with the full pixel precision is only optional. In MPEG- 1 and H.263, motion compensation with only half pixel accuracy is used. MPEG-4 uses quarter pixel accuracy. H.263++, as an enhancement to H.263, also recommends quarter and eighth pixel precisions. H.264 uses quarter pixel accuracy as the default mode for lower complexity mode and eighth pixel accuracy for the higher complexity mode.  Wavelet-based motion compensation  Motion compensation in the wavelet transform domain, known as multiresolution motion estimation, was originally proposed in [41], and a number of subsequent multiresolution motion estimation algorithms have been based on this work [36, 39].  The multiresolution motion estimation method is similar to DCT-based sub-band cod- ing. The wavelet coefﬁcients of each sub-band  block  are extracted and compared to those of the reference sub-band  block . The motion vectors in the lowpass sub-band can be      739   cid:2   17.10 Video data compression  properly scaled and used as the ﬁnal motion vectors for all the other sub-bands. It starts with estimating the motion vectors at the lowest resolution level. The motion vectors thus obtained are then used as predictions for the higher resolutions, where they are either accepted as ﬁnal motion vectors or further reﬁned. For the multiresolution motion esti- mation of video sequences, the 7 9 biorthogonal wavelet, one of the best wavelets for the coding of still images, is still a good wavelet for multiresolution motion estimation also [40].  Compared to the conventional spatial-domain motion estimation technique, the wavelet- based multiresolution motion estimation technique has the advantages of a substantial reduction in the computational load and ease of generating an embedded video bitstream. JPEG2000 is implemented by coding block by block, and it can be extended into a video format using multiresolution motion estimation.  17.10.4 Basic structure of video  Group of pictures  GOP   The different frames of a video are organized in GOPs. The beginning of a GOP is a point for random access in the video sequence. Each GOP must be independently decoded, thus the ﬁrst frame of a GOP must be an I-frame, or a B-frame that can be reconstructed from the following I-frame. For a closed GOP, all predictions take place within the GOP, while in an open GOP every frame boundary has predictions that cross it. A regular GOP has a ﬁxed pattern of P- and B-frames between I-frames. Regular GOPs can be characterized by the GOP length N and the distance M between the anchor frames. GOPs are important for random access, fast forward, fast or normal reverse play of a video. A typical GOP pattern used in MPEG-1 is shown in Fig. 17.13, where all the three main frame types have the same size with 4:2:0 chroma format.  Macroblocks and blocks  The frames of the video sequence are divided into macroblocks of size 16 × 16. MPEG- 1 uses a 4:2:0 structure for color information coding. This leads to a 16 × 16 luminance block, a 8 × 8 block for Cb, and a 8 × 8 block for Cr. The 16 × 16 luminance block is further divided into four 8 × 8 blocks, since 8 × 8 blocks are used for all DCT coding. The intracode of a macroblock in MPEG-1 is almost exactly the same as that for JPEG. In MPEG-2, the macroblock types may range from 4:2:0, 4:2:2, and 4:4:4 chroma formats.  BP  B I B B P B B I B B P B B I B B  M = 3  N = 12   cid:2 Figure 17.13  A typical GOP pattern used in MPEG-1.      740   cid:2   Source coding II: image and video coding  Slices  A group of macroblocks is called a slice  In H.261, it is called a group of blocks  GOB  . The reason for deﬁning slices is to conﬁne the channel error within the slices by resetting entropy coding. Slices can have different sizes within a frame, and the division of slices can be different in different frames. The organization of the slices introduces extra slice overhead. In order to optimize the slice structure, short slices can be used for macroblocks with signiﬁcant energy  such as macroblocks in I-frames , and long slices for macroblocks with less signiﬁcant energy  such as macroblocks in B-pictures . A slice has a raster scan structure.  17.10.5 Video encoder decoder  The basic structure of the MPEG compression algorithm is very similar to that of ITU- T H.261. Implementation of MPEG starts from transforming analog RGB pictures into YUV pictures with Y, Cr, Cb components, which are then digitalized. YUV pictures can be sampled by the 4:2:0 or 4:2:2 format.  The interframe predictive coding is ﬁrst applied. The difference between pixels in the current frame and their prediction is DCT-coded, quantized, and transmitted. The transmis- sion bit rate is controlled by the predictor. A better predictor based on motion estimation leads to a smaller error signal, thus yielding a smaller bit rate. At the receiver, the decoded error signal of each pixel is added to the prediction value to reconstruct the frame. DCT is applied to the difference image between the digitized image and the predicted image to extract spatial frequencies using 16 × 16 macroblocks. The DCT coefﬁcients are then quantized with the high spatial frequencies in coarser steps. The implementation is very similar to that of JPEG. In MPEG-1 and H.261, zigzag scanning of the DCT coefﬁ- cients is used, as in JPEG. In MPEG-2, the alternate scan is used, as shown in Fig. 17.14. Since the vertical correlation in the interlaced pictures is very small, an alternate scan gen- erates better results when the interlaced related operation ﬁeld prediction is used [13]. In H.263, for intracoding, in addition to zigzag scan, alternate horizontal and alternate vertical scans are also used. The alternate vertical scan is the same as the alternate scan mode in MPEG-2, as shown in Fig. 17.14, and the alternate horizontal scan is the transposed form of the alternate vertical scan. In MPEG-1 the quantization matrix for intraframe coding is different for different for- mats. The quantization matrix for the SIF size  352 × 288 × 25 or 30  is derived from the vision contrast sensitivity curve for a nominal viewing distance [13], and it can be different for best perceptual results if the resolution or the viewing distance is changed. The default intraframe quantization table is shown in Table 17.2.  The quantization table for interframe coding uses the same weighting for all the fre- quency components. The reason is that high frequency interframe error does not necessarily mean high spatial frequency. It may arise from poor motion compensation or block bound- ary artifacts. In MPEG-1, all the 64 elements of the interframe quantization matrix are selected as 16.      741   cid:2   17.10 Video data compression  Table 17.2. The intraframe quantization table used in MPEG-1.  8 16 19 22 22 26 26 27  16 16 22 22 26 27 27 29  19 22 26 26 27 29 29 35  22 24 27 27 29 32 34 38  26 27 29 29 32 35 38 46  27 29 34 34 35 40 46 56  29 34 34 37 40 48 56 69  34 37 38 40 48 58 69 83   cid:2 Figure 17.14  The alternate scanning of the 8 × 8 DCT coefﬁcients for an 8 × 8 image block.  In H.261, all the pictures are interframe coded, thus only the interframe quantiza- tion matrix is deﬁned. In MPEG-2, both linear and nonlinear quantization of the DCT coefﬁcients are supported. In H.261 and MPEG-1, the DCT coefﬁcients are coded, via a zigzag scanning process, as two-dimensional events  run, index , where run indi- cates the number of zero-valued coefﬁcients in front of a nonzero coefﬁcient in the zigzag scan, and index is the normalized magnitude of a nonzero coefﬁcient. In H.263, the DCT coefﬁcients are represented by a three-dimensional event  last, run, index , where the additional event last takes the value 0 or 1, corresponding to whether there are more nonzero coefﬁcients in the block or it is the last nonzero coefﬁcient in the block. Thus, is intended to replace the end-of-block  EOB  code of H.261 and MPEG-1.  it  The procedure for MPEG-2 encoding is given in Fig. 17.15. The H261 3 and MPEG-1 4  encoders are also similar to that of MPEG-2.  The decoding process, as shown in Fig. 17.16, is the inverse of the encoding process. The decoder demultiplexes the received video bitstream, entropy-decodes it, dequantizes it, and then applies IDCT on it. The result is then added to an interframe prediction, and a ﬁnal frame is obtained. The frame is then reordered, and the output pictures are obtained. Some control functions such as fast play, pause resume, and reverse play are also implemented in the decoder.      742   cid:2   Source coding II: image and video coding  A D  +  Σ  DCT  Quantizer  Buffer  Bitstream  Y Cr Cb Sync  Difference  image  Predicted  image  Rate control  Variable length coding  Inverse quantizer  Inverse DCT  Predicted  image  +  Σ  Motion  compensator  Reconstructed  image  Motion vector  Motion estimator   cid:2 Figure 17.15  The MPEG-2 encoder. Reproduction with the permission of IEEE [2].  Bitstream  Buffer  DeMUX  Dequantizer  DCT  Σ  Frame reorder  output image  Variable length coding   cid:2 Figure 17.16  + Frame store  prediction  The MPEG-2 decoder.  17.10.6 Scalability  Scalability is supported in MPEG-2. Scalable video coding, also known as layered video coding, encodes the frames into the base layer and the enhancement layer. In case of network congestion, the enhancement layer data can be discarded.  Scalability provides a means of delivering better quality video, but at a cost of higher encoder complexity and bit rate overhead. Scalability ﬁnds wide applications in telecom- munications, and broadcasting of TV and video over networks. MPEG-2 supports a variety of scalability [13]:   Data partitioning. It is intended for use when two channels are available for transmission of a video bitstream. It divides the bitstream into two layers: The base layer contains the critical parts of the bitstream, such as the headers, motion vectors and some lower- order DCT coefﬁcients; the enhancement layer contains other data such as the higher- order DCT coefﬁcients. The former is transmitted in a better quality channel, while the latter is transmitted in a channel with poorer quality. Data partitioning is only used for P and B-frames, but not for I-frames, since in I-frames all DCT coefﬁcients are important.      743   cid:2   17.10 Video data compression    SNR scalability. It generates two video layers of the same spatio-temporal resolution from a single video source. The basic layer by itself provides the basic video quality, and the enhanced layer, when added to the basic layer, can generates a higher quality video.   Spatial scalability. Two spatial resolution video streams are generated from a single video. The base layer by itself provides basic spatial resolution, and the enhancement layer, when added to the spatially interpolated base layer, generates full spatial resolution of the input video. Spatial scalability is a most complex form of scalability, where each layer requires a complete encoder decoder.   Temporal scalability. It partitions video frames into layers, with the basic layer providing the basic temporal rate and the enhancement layer being coded with temporal prediction based on the base layer. The spatial resolution of the frame in each layer is the same. In MPEG-1 and MPEG-2, the I- and P-frames can be treated as the base layer, while the B-frames can be treated as the enhancement layer.   Hybrid scalability. In MPEG-2, individual scalabilities can be combined to form a hybrid scalability. For each increment of scalability, an additional enhancement layer is added to the existing base and enhancement layers. Decoding of the upper enhancement layers requires the availability of the base and lower enhancement layers.  In H.263, data partitioning, temporal, SNR, spatial, and hybrid scalability are supported as optional modes. Unlike MPEG-2, the scalability in H.263 is not used for distribution purpose, but as a layered coding technique. By using unequal error protection to the base layer as well as error resilience techniques, the robustness of H.263 is further improved.  In H.263, the data partitioning mode is performed to put important data ahead of other data. This is to reduce the inﬂuence of channel errors on variable-length encoded data, since between two resynchronization markers, symbols that appear earlier in the bitstream are less inﬂuenced by errors than those that appear later, due to the cumulative impact of variable-length coding on the decoding of the subsequent data.  The scalability discussed so far is also applicable to MPEG-4. But due to the object- based coding, scalability of MPEG-4 can be different. In MPEG-4, SNR scalability is replaced by the ﬁne granularity scalability  FGS . The basic layer is coded in a way similar to that of an SNR scalable coder, but the difference between the original DCT coefﬁcients and the quantized coefﬁcients are represented in bit planes, as opposed to being quantized with a ﬁner quantizer step size as in the SNR scalable coder. In MPEG-4, object-based scalability is also supported, where scalability is applied to individual objects rather than the entire frame. The object-based temporal scalability is of particular interest. It increases the frame rate of an object such that the object has a smoother motion than the other objects in the frame.  17.10.7 Integer DCT transform  In earlier MPEG or H-26x standards, the 8× 8 ﬂoating-point precision DCT transform was employed. In practical implementation, the ﬂoating-point number is implemented with a      744   cid:2   Source coding II: image and video coding  ﬁnite precision. Thus, a mismatch in DCT and IDCT arises. Approximated 8 × 8 DCT transforms can also be implemented to save computational complexity [6]. H.264 is a unique standard codec that uses the integer transform to replace the DCT transform. H.264 speciﬁes a 4 × 4 integer DCT as an approximation to the regular 4 × 4 DCT. In the one-dimension case, the integer transform of length 4, T4, and the DCT of length 4, TDCT, are given by  ⎡⎢⎢⎣ 1  T4 =  1 2 1 −1 −1 1 −2  1 1 1 −1 −2 1 2 −1  ⎤⎥⎥⎦ , TDCT =  ⎡⎢⎢⎣ 1  1 1 0.54 −0.54 −1.3 1.3 −1 1 1 0.54 −1.3 −0.54  1 −1 1.3  ⎤⎥⎥⎦ .   17.29   Like the integer transform for color space transform, the integer DCT has an exact inverse transform, and there is no mismatch between the encoder and decoder. The use of smaller block size reduces the blocking artifacts. Also, the use of integer numbers signiﬁcantly improves the computation speed, since the multiplication by two can be simply imple- mented by bit shift. Two-dimensional integer transform can be derived in the same way as 2-D DCT.  H.264 also gives an optional integer transform of length 8, which is also an approxima- tion to the DCT of length 8. The elements in the transform matrix are not powers of two, and some multiplications are required. This optional mode is called adaptive block trans- form, since the block size can be selected as either 4× 4, 4× 8, 8× 4, or 8× 8, depending on the texture of the image. Adaptive block transform is implemented by applying  A = TvBTT  h  where A and B are the frequency and spatial blocks of the transform, and Tv and Th can be either T4 or T8. T8 is given by  ⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣  T8 =  13  13 15 7 3  13 13 13 13 13 13 −3 −9 −15 −19 19 9 3 −7 −17 −17 −7 17 7 17 −3 −9 −19 −15 9 15 19 13 −13 −13 13 −13 −13 13 13 15 −19 −3 −9 19 −15 9 3 7 −17 17 −17 −7 −7 7 17 19 −15 3 −9 15 −19 −3 9   17.30    17.31   ⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ .  This transform can be implemented with an efﬁcient fast algorithm given in [35].  17.10.8 Shape coding  Shape can be coded as either binary or grayscale shape. The binary shape is encoded using content-adaptive encoding, while the grayscale shape is encoded using the SA-DCT. SA- DCT is applied to 8 × 8 blocks that are located on the object boundary of an arbitrarily      745   cid:2   17.10 Video data compression  Column  DCT  Row DCT   cid:2 Figure 17.17  Operation of shape adaptive DCT.  shaped video object plane  VOP . SA-DCT applies one-dimensional DCT vertically and horizontally according to the number of active pixels in the row and column of the block, respectively. The size of each vertical DCT is the same as the number of active pixels in that column. After vertical DCTs are performed, the dc coefﬁcients of all vertical DCTs are lined up in the ﬁrst row, the ﬁrst-order coefﬁcients are lined up in the second row, and this rule applies for coefﬁcients of all orders. Horizontal DCT is then applied to each row, and the coefﬁcients from the horizontal DCTs are then lined up in rows. The ﬁnal coefﬁcients of SA-DCT are concentrated into the upper-left corner of the block. This is illustrated in Fig. 17.17. In SA-DCT, the active  opaque  pixels in the boundary 8 × 8 are encoded without padding, leading to the number of DCT coefﬁcients equal to the number of opaque pix- els. At the encoder, shape adaptive IDCT  SA-IDCT  can be applied to reconstruct the pixels. The regular zigzag scan is modiﬁed according to the SA-DCT coefﬁcients for RLE. For a block of 8× 8 active pixels, SA-DCT reduces to the regular 8× 8 DCT. All SA-DCT coefﬁcients are quantized and coded in the same way as regular DCT coefﬁcients by using the same quantizers and variable-length code tables.  SA-DCT is more complex than regular 2-D DCT, but it improves coding efﬁciency for  boundary mainblocks. SA-DCT is used in MPEG-4.  17.10.9 Object-based coding and sprite coding  MPEG-4 relies on a content-based visual data representation of scenes. A scene is viewed as a composition of video objects  VOs  that have shape, motion, and texture. A VO is an area of the video scene that may occupy an arbitrary-shaped region for an arbitrary period. At a particular time, we have a VOP. The video frames are deﬁned as layers of VOPs. The background is represented by VOP0, and the objects of interest are represented as VOP1 to VOPn. The VOPs can be constructed beforehand or be deﬁned by segmentation of the video frames. The VOP of an arbitrary shape is encapsulated into a bounding rectangle that has the minimum number of macroblocks.  In MPEG-4, the compression efﬁciency can be signiﬁcantly improved by not coding the video background. The coding of the background does not need to be exact since viewers do not pay attention to the background. The background can be efﬁciently encoded by using a global motion model, which can be motion compensation with the spatial transform.      746   cid:2   Source coding II: image and video coding  Global motion compensation is based on the transmission of a static sprite panorama, which is a still image describing the background over all frames in the sequence. The panorama sprite is transmitted to the receiver only once and for each following frame, only the camera parameters relevant to the background are transmitted to the decoder. The sprite can be encoded and transmitted as the ﬁrst frame of a sequence or in a progressive manner. The moving foreground is transmitted separately as VOPs.  After deﬁning the VOPs, the encoder then sends the VOPs, as well as the information of when and where each VOP will be displayed. At the decoder, the chosen VOPs are extracted to a single bitstream, and the output video composed for display. The encoder for the VOPs consists of a shape encoder and a traditional motion texture encoder  as used in H.263 .  MPEG-4 uses the motion-compensated DCT for color texture coding, but augments this by an explicit compressed representation of the shape of arbitrary VOs [7]. The com- pression technology associated with the normative shape representation is block-based CABAC, where the symbol probability is calculated from the context of the neighboring pixels.  The object-based functionalities of MPEG-4 require segmentation algorithms for seg- menting a video scene into objects. Image segmentation can be performed by using the watershed transform algorithm and region motion estimation [32].  17.10.10 Rate control  Rate control is necessary for maximizing the visual quality at a given target average bit rate by controlling the allocation of the bits. Rate control algorithms take into account the constraints of the decoder buffer. Various rate control schemes have been applied in MPEG-2 Test Model, MPEG-4 Veriﬁcation Model  VM , and H.264 AVC Joint Model.  In MPEG-2, the TM5  Test Model 5  rate control consists of three steps: target bit allo- cation, rate control, and adaptive quantization. Target bit allocation is the picture-level bit allocation. The bit estimate is based on a linear model between the bit budget and the reciprocal of the quantization step. The second step, rate control, is the macro-level bit allocation, which ensures that no buffer overﬂow and underﬂow occur. Based on the macro-level bit allocation, a quantizer step is implemented. Adaptive quantization mod- ulates the quantization step from the previous step by increasing it for active areas and reducing it for smooth areas, that is, more bits are used in smooth areas and fewer bits for active areas. This is because the eye is not sensitive to the quantization noise in active areas, but is sensitive to quantization noise in smooth areas.  Unlike the linear model used in MPEG-2 TM5 rate control, MPEG-4 VM uses a quadratic model for rate control. The basic H.264 AVC rate control is similar to MPEG-4 VM rate control, and uses the quadratic rate distortion model. For H.264 AVC, the rate control algorithm consists of GOP-level rate control, picture-level rate control, and the optional basic unit level rate control. The GOP-level rate control calculates the total num- ber of bits for the remaining pictures in the GOP, and also computes the initial quantization parameter of instantaneous decoding refresh  IDR  picture. The picture-level rate control      747   cid:2   17.11 Introduction to video standards  has two stages: pre-encoding and post-encoding. Pre-encoding computes the quantization parameter for each frame, while post-encoding updates the parameter sets and adds the gen- erated bits to the buffer. The basic unit is deﬁned as a group of continuous macroblocks. The basic unit rate control is similar to picture-level rate control, and it is used to deter- mine the quantization parameters for all basic units so that the total generated bits satisfy the picture target bits.  17.11 Introduction to video standards  The MPEG  Moving Pictures Experts Group, ISO IEC JTC1 SC29 WG11  is a joint ISO IEC group for developing audio-visual coding standards.17The MPEG standards involve the compression of digital images and sound, as well as their synchronization. MPEG is based on JPEG, but has additional features of motion compensation and vari- able length coding. MPEG uses block-based DCT and quantization, block-based motion estimation and compression, and lossless compression using entropy coding for motion vectors and the quantized DCT coefﬁcients.  ITU-T also has developed its H-series video standards by its Video Coding Experts Group  VCEG, ITU-T SG16 Q.6 .18Since members of VCEG also participated in MPEG, standards generated by the two groups are similar in many aspects. MPEG and VCEG also set up the Joint Video Team  JVT  for the development of H.264 MPEG-4 Part 10, which is entitled Advanced Video Coding  AVC .  Currently, the wavelet technique has not been used in ITU or MPEG video stan- dards. This is because the DCT-based block-coding technique can effectively make use of motion compensation. DWT-based image coding does not ﬁt well with block-based motion compensation.  The ITU-T video standards are used for telecommunications, and a fast encoder and decoder may be required. In MPEG, the decoder must be fast for real-time operation, but the encoder can be slow. These standards typically specify the format for the bitstream and the decoder speciﬁcations, but not the encoder.  All MPEG standards give the syntax for combining audio, video, and data into a single bitstream. A packet structure is deﬁned for multiplexing coded audio and video into one stream and keeping them synchronized. Data can also be multiplexed into the packet. MPEG provides reference software modules which are in C or C++ language.  ITU-T H.120, issued in 1984, is the ﬁrst international standard for video coding. H.120 was targeted for videoconferencing applications at 1.544 Mbits s and 2.048 Mbits s. It uses the conditional replenishment or motion compensation technique for interframe coding and DPCM for intraframe encoding. H.120 was commercially unsuccessful. In the following, special features of other ITU-T and MPEG video standards are described.  17 http:  www.mpeg.org 18 http:  www.itu.int      748   cid:2   Source coding II: image and video coding  H.261  The ITU-T H.261 standard was completed in 1990. It was intended for visual telephony or videoconference over the integrated services digital networks  ISDNs . It achieves a variable bit rate of p×64 kbits s, where p is an integer between 1 and 30. H.261 is normally used for head-and-shoulders pictures with a CIF or QCIF spatial resolution. In H.261, both the encoder and the decoder must be fast enough for real-time operation. In H.261, motion compensation is optional. H.261 uses only I-pictures and P-pictures, but not B-pictures. H.261 uses a single quantization coefﬁcient instead of an 8× 8 table of quantized coefﬁcients. Coarse quantization of the coefﬁcients causes loss of high frequency components. This artifact can be reduced by using a loop ﬁlter  ⎡⎣ 1 2 1  2 4 2 1 2 1  ⎤⎦ .  h x, y  = 1 16   17.32   The loop ﬁlter has a picture blurring effect, and should be activated only for macroblocks with motion. The loop ﬁlter is only deﬁned in H.261. The loop ﬁlter is switched on only at bits rate lower than 6 × 64 kbits s = 386 kbits s. At a higher bit rate, it does not improve the subjective quality of a picture [13].  MPEG-1  MPEG-1  IS11172-2 , completed in 1991, was intended for intermediate data rate, with a bit rate of 1.5 Mbits s. MPEG-1 is an extension of H.261, with many features being the same, but their bitstreams are incompatible. MPEG-1 is used to code CIF or QCIF spatial resolution. It is used for storing visual information on storage media such as CD-ROM. MPEG-1 is used in consumer applications such as Video CD  VCD .  MPEG-2 H.262  MPEG-2  ISO IEC 13812-2 , also referred to as H.262, is a generic video codec, jointly developed by ISO IEC and ITU-T. MPEG-2 was completed in 1994, and was intended for video transmission over the broadband ISDNs  B-ISBNs  using asynchronous transfer mode  ATM  transport that has a bit rate of at least 10 Mbits s. MPEG-3 was intended for HDTV with a target bit rate of 40 Mbits s, but was ﬁnally merged into MPEG-2. MPEG-2 can be used for a wide range of applications including DAB, SDTV  standard-deﬁnition television , HDTV broadcast, cable TV distribution, as well as consumer applications such as Super VCD  SVCD  and DVD-Video.  MPEG-2 deﬁnes two types of streams: the program stream and the transport stream. The program stream is similar to the MPEG-1 stream. The MPEG-2 decoder is required to be capable of decoding MPEG-1 bitstream. The program stream is intended for an error-free environment such as digital storage. The transport stream is intended for transmission, where channel errors may occur. The transport stream offers error resilience, and has the ability to assemble multiple program streams into a single bitstream. The basic data      749   cid:2   17.11 Introduction to video standards  structure for both the program and transport streams is the packetized elementary stream  PES  packet.  In MPEG-1, frames are noninterlaced  progressive . But in MPEG-2, most frames are interlaced. The simple nonscalable mode of MPEG-2 is the direct extension of MPEG- 1 that accommodates interlaced video coding. For interlaced video, a macroblock can be split into two 16 × 8 ﬁeld blocks, and interpicture prediction can be performed between the ﬁelds, since they are close to each other. Field prediction is similar to frame prediction, except that the pixels of the target macroblock belong to the same ﬁeld. MPEG-2 has the scalability function.  H.263  H.263, approved in 1996, is intended for video communications via telephony, Internet or mobile networks, with a much lower bit rate. H.263 is based on H.261, and includes the functionalites of H.261, with some improvements. H.263 has a target bit rate on the order of 24 kbits s. H.263 provides error protection, robustness and resilience for wireless trans- missions. H.263+  approved in 1998  and H.263++  approved in 2000  are enhancements to H.263. These enhancements are intended to develop video coding at bit rates less than 64 kbits s and more speciﬁcally at less than 24 kbits s. H.263+ and H.263++ can be used for real-time applications. H.26L is a further enhancement of H.263, which later evolved into H.264.  Like H.261 and MPEG-1, H.263 employs source images of the CIF family with 4:2:0 chroma format. The source encoder operates on noninterlaced pictures at approximately 29.97 frames per second. The pictures can be one of the ﬁve members of the CIF family. The picture layer of H.263 contains the picture header, the GOB header, various coding decisions on the macroblocks in a GOB, and the coded transform coefﬁcients. This struc- ture is also used in H.261, MPEG-1, and MPEG-2. H.263 differs from the other codecs by deﬁning the type information called PTYPE in the header that gives information of the whole picture.  B-frames are important for low-bit-rate applications. At very low bit rates, the blocks of pixels are mainly made of low frequency DCT coefﬁcients, and the blocking arti- facts are obvious. In H.263, the overlapped block matching motion compensation is an optional advanced prediction mode, which has four motion vectors per macroblock, and this technique can reduce the blocking artifacts to a certain extent. H.263 recommends the deblocking of the picture by the block edge ﬁlter.  In normal mode of H.263, Huffman coding is employed. H.263 has an optional syntax- based binary arithmetic coding mode. Reversible variable-length codes are used to reduce the inﬂuence of the channel errors. H.263 also speciﬁes the optional advanced intra inter variable-length coding modes to improve encoding efﬁciency.  In H.263, the error correction code is a BCH  511,493 . H.263 also implements error concealment, which replaces the damaged pixels with pixels from parts of the same frame  by interpolation  or previous frame  by controlling the motion vector  that have maximum resemblance. These are known as intraframe and interframe error concealment. Loss of packet is also concealed in H.263.      750   cid:2   Source coding II: image and video coding  MPEG-4  is an open ISO standard for rich MPEG-4  ISO IEC 14496 , completed in 2000, multimedia compression and interactivity. MPEG-4 deﬁnes all aspects of an end- to-end multimedia solution. MPEG-4 provides a framework for digital rights man- agement and protection. It offers high quality images at data rates from below 64 kbits s up to around 1,200 Mbits s. MPEG-4 also supports synthetic images and still images.  MPEG-4 is organized as tools, proﬁles, and levels. It has system tools, visual tools, audio tools, and other tools. A tool is a subset of coding functions to support a speciﬁc feature. Major visual tools are video compression tools, robustness in error-prone environments, ﬁne grain scalability, shape and alpha channel coding, face and body animation, coding of 2D meshes, and coding of 3D meshes. The video compression tools are video compression algorithms for bit rates between 5 kbits s and 1 Gbits s and for resolution from subQCIF to studio resolution  4k × 4 k pixels . A proﬁle is a set of VO types that a codec is targeted for handling, and it deﬁnes a subset of coding tools, since a VO is coded using one or more tools. A proﬁle in MPEG-4 is similar to a set of annexes in H.263. Proﬁles are a mechanism for interoperability between codecs. Within a proﬁle, there are levels that deﬁne constraints on the parameters of the bitstream.  The MPEG-4 Visual’s Simple proﬁle is for low-cost applications, such as video over mobile and Internet. Baseline H.263 was adopted as the core of this proﬁle. There are three levels that deﬁne bit rates of 64, 128, and 384 kbits s. It supports most optionalities  annexes  of H.263, and can decode a bitstream generated by the core H.263. In the Sim- ple proﬁle, to avoid the disadvantage of Huffman coding, pre-calculated Huffman-based coding is applied. A variable-length code table of codewords for its  run, level, last  combi- nations is pre-calculated, based on the probability distributions of generic video material. A total of 102 speciﬁc combinations of  run, level, last  have variable-length codes assigned to them. This method is also applied to variable-length coding of the differentially coded motion vectors. In the Advanced Coding Efﬁciency proﬁle, SA-DCT is applied to 8 × 8 blocks that are located on the boundary of an arbitrarily shaped VOP. Sprite coding is supported in MPEG-4 Main proﬁle. MPEG-4 allows optionally the use of wavelets.  MPEG-4 and H.324 are multimedia standards compatible with the 3GPP standard, as their required processing power is affordable. Note that H.324 is composed of H.263 and the G.723.1 speech codec.  H.264 AVC  H.264 AVC, or MPEG-4 Part 10, is a joint ITU-T and ISO IEC standard  ISO IEC 14496-10 , published in 2003 [19]. It achieves a signiﬁcant improvement in compression efﬁciency over existing standards such as MPEG-2, and a substantial superiority of video quality over that of H.263 and MPEG-4 [13]. Compared with H.263+ and MPEG-4 Simple proﬁle, H.264 allows up to 50 per cent in bit rate saving for a similar degree of encoder optimization [13]. H.264 is expected to overtake MPEG-2 H.262 in common use, and to be      751   cid:2   17.11 Introduction to video standards  an important part of wireless multimedia services. It covers all common video applications ranging from mobile services, video-conferencing to IPTV, HDTV, and high-deﬁnition video storage.  H.264 provides functionality similar to that provided by H. 263+ and MPEG-4 Simple proﬁle, but with much better compression and more reliable transmission. Some optional modes in H.263, such as high precision spatial accuracy for motion estimation, data par- titioning, multiple previous reference pictures for prediction, and the deblocking ﬁlter in motion compensation, have become a part of the core of H.264. H.264 deﬁnes a set of three proﬁles. The Baseline proﬁle supports intra- inter-coding and entropy coding with CAVLC, and is targeted for videotelephony, videoconferencing, and wireless communica- tions. The Main proﬁle supports CABAC, and can be used for television broadcasting and video storage. The Extended proﬁle provides improved error resilience, and is suitable for streaming media applications.  For application like video streaming, H.264 introduces a new type of picture, called switching or secondary picture  S-picture , for transition from one bitstream to another. S-pictures are generated by the server at the time of switching, and are transmitted as the ﬁrst frame after the switching. This effectively solves the picture drift problem of other techniques. In MPEG codecs, random access is based on the regular spaced I-frames. This is not viable in the low bit rate H.264. H.264 employs a method that creates S-pictures at the time of access.  H.264 is the unique standard that employs the integer transform instead of the ﬂoating- point DCT transform. All integer transforms in H.264 as well as their inverse transforms can be implemented using only shift and add operations in  8 + b -bit arithmetic pre- cision for b-bit input video. The transform coefﬁcients are then quantized and entropy coded. Like H.263, H.264 uses a UQ-DZ and zigzag scanning of the quantized coef- ﬁcients. In H.263 there are 32 quantization levels, while in H.264 there are 52 levels. In the Baseline proﬁle, the quantized coefﬁcients are entropy coded using CAVLC, and all other syntax elements are coded using ﬁxed-length or exponential-Golomb variable- length codes. In the Main proﬁle, a CABAC is used, which is up to 10% better than Huffman coding in terms of bit saving [13]. The decoder complexity of H.264 is about four times that of MPEG-2 and two times that of MPEG-4 Visual Simple proﬁle.  Another important feature of H.264 is the separation of the video coding layer  VCL  from the network adaptation layer  NAL , where the VCL gives the format of the video content and speciﬁcation of the NAL depends on the type of the trans- port network. The VCL is based on conventional block-based motion-compensated hybrid video coding, used in prior video coding standards such as MPEG-2 or H.263, but has a substantially higher degree of diversiﬁcation, sophistication, and adaptability.  H.264 Baseline was targeted for royalty-free use. Microsoft’s proprietary Windows Media format will also be a main contender to MPEG-4 and H.264. Source code of the H.264 reference model is available in C language.19  19 http:  iphome.hhi.de suehring tml       752   cid:2   Source coding II: image and video coding  MPEG-7  MPEG-7, called multimedia content-based description standard, speciﬁes a standard set of descriptors for describing various types of multimedia information coded with the standard codecs. MPEG-7 does not specify how to extract features, nor how to search for them. Most fundamental descriptors are color descriptors, texture descriptors, shape descriptors, motion descriptors, and localization descriptors. Retrieval can be based on the features of each of these descriptors.  To describe audio-visual events, the visual features are ﬁrst extracted as shape, size, tex- ture, color, movement, and their positions in a frame; then the audio features are extracted as key, mood, tempo, tempo changes, and their positions in time domain. These low lev- els of abstraction can be performed automatically. Higher level abstraction requires human intervention to deﬁne the semantic relations between the lower level features. Informa- tion about the multimedia data, such as copyright information, is also required to be included.  All applications that make use of multimedia will beneﬁt from MPEG-7. The features are indexed and are used for retrieval purpose. For example, the face recognition descriptor can be used for retrieval of face images from a video.  MPEG-21  MPEG-21 deﬁnes a multimedia framework that enables transparent and augmented uses of multimedia resources across various networks and devices, i.e., the delivery and con- sumption of video contents. It provides interfaces and protocols that enable creation, identiﬁcation, description, management, protection, manipulation, search, access, stor- age, delivery and consumption of the contents, across the whole content-creation and consumption chain.  MPEG-21 provides solutions for universal multimedia access, based on digital item adaptation. A digital item is a structured digital object, and is a fundamental unit of distribu- tion and transaction with the MPEG-21 framework. Video transcoding or scalable coding is used to maintain the interoperability between different video formats such as MPEG-2 and MPEG-4.  Problems  17.1 For a window of 2K + 1 samples, the median ﬁlter is expressed by ˆy m  = median{x m − K , . . . , x m , . . . , x m + K }.  Select an image, add some impulse noise, and then denoise it by using the median ﬁlter. 17.2 Evaluate the transform matrix CN, deﬁned by  13.145 , for a 4 × 4 DCT. Calculate the dc component of the 4 × 4 block:      753   cid:2   ⎡⎢⎢⎣ 1  2 3 5  ⎤⎥⎥⎦ .  Problems  1 4 9 11  5 12 15 22  5 8 12 8  ⎤⎦ ; ⎡⎣ −1 −1 −1 ⎡⎣ +2 +1 ⎤⎦ and ⎡⎣ +1 +2 +1  −1 −9 −1 −1 −1 −1 0 +1 0 −1 0 −1 +2  ⎤⎦ ; ⎡⎣ +1  17.3 Evaluate Problem 17.1 using the integer transform, deﬁned by  17.29 . Find the difference between the transform outputs. 17.4 Given an input array: 3, 0, 0, −2, 5, 0, 0, 0, −14, 0, 0, 0, 7, . . .. Encode the sequence in RLE of the  run, level  pairs.  17.5 Many image processing operations are implemented using convolution of the image with a kernel. Implement the following operations on an image.   a  Sharpening using the Laplacian kernel  ⎤⎦   b  Embossing using a directional derivative kernel   c  Edge extraction using the Sobel kernels  0 −1 0 −2 0 −1 for vertical and horizontal derivatives. The edge corresponds to the gradient magnitude.  0 0 −1 −2 −1  +2 +1  0  17.6 Select an image, and add “salt-and-pepper noise” to simulate an extreme case of locked or dead pixels in a camera. Apply a 3 × 3 median ﬁlter to remove the noise. 17.7 Implement a delta and variable-length coding method for compression of grayscale images. Compare the size of the compressed image to the theoretical limit deﬁned by the image entropy.  17.8 Given seven eight-bit resolution luminance samples: 20, 34, 60, 243, 200, 49, 89.  a  Perform DPCM encoding.  b  Use the three-bit quantizer  ⎧⎪⎪⎨⎪⎪⎩  ±2, ±5, ±12, ±40,  y =  x ≤ 5 5 < x ≤ 12 12 < x ≤ 40 else  to quantize the DPCM data, and ﬁnd the reconstructed samples.  c  Calculate the PSNR of the reconstructed samples. 17.9 Generate the DCT coefﬁcients for an 8 × 8 pixel block  luminance  using random numbers between -50 and 800, and then apply quantization using Table 17.1. Find the quantization indices for the baseline JPEG with a quality factor of 50%.  17.10 Conduct a project to encode an image using JPEG with sequential coding and progressive coding. Compare the performance of the two modes.      754   cid:2   Source coding II: image and video coding  17.11 Download the MATLAB toolbox jpegtool from http:  www.dms.auburn. edu compression download.html. Install and test the program. Select any picture, experiment JPEG encoding by different choices of quantizer and block size to smooth the blocking artifacts. Compare the input and output images, and report the compression ratio.  17.12 Download the Independent JPEG Group JPEG software from http:  www. ijg.org . Read the manual. Write your own program to call the API functions.  17.13 Find the bit rate for the following video formats:  a  ITU-R BT.601 625, 4:2:2.  b  SIF 525, 4:2:0.  c  CIF.  d  SIF 525, 4:2:2.  e subQCIF, 15 Hz.  17.14 An MPEG-2 video with its associated audio and channel coding has a bit rate of 6 Mbits s. With 16QAM modulation, how many such videos can be transmitted over a 8-MHz channel in the UHF band? Assume that each modulated symbol occupies 1.25 MHz and each channel contains a 2 MHz guard band.  17.15 Download the H.264 AVC JM reference software from http:  iphome.hhi. de suehring tml . Install it. Learn the JM reference software manual. Experiment raw videos in RGB or YUV format by encoding decoding with different options.  References  [1] N. Ahmed, T. Natarajan & K. R. Rao, Discrete cosine transform. IEEE Trans.  [2] B. Bhatt, D. Birks & D. Hermreck, Digital television: making it work. IEEE Spectrum,  Comput., 23:1  1974 , 90–93.  34:10  1997 , 19–28.  [3] M. I. H. Bhuiyan, M. O. Ahmad & M. N. S. Swamy, Spatially adaptive wavelet-based methods using the Cauchy prior for despeckling SAR images. IEEE Trans. Circ. Syst. Video Tech., 17:4  2007 , 500–507.  [4] M. I. H. Bhuiyan, M. O. Ahmad & M. N. S. Swamy, Wavelet-based image denois- ing with the normal inverse Gaussian prior and linear minimum mean squared error estimator. IET Image Process., 2:4  2008 , 203–217.  [5] M. I. H. Bhuiyan, M. O. Ahmad & M. N. S. Swamy, Spatially-adaptive thresholding in wavelet domain for despeckling of ultrasound images. IET Image Process., 3:3  2009 . [6] S. Bouguezel, M. O. Ahmad & M. N. S. Swamy, Low-complexity 8× 8 transform for  image compression. Electron. Lett., 44:21  2008 , 1249–1250.  [7] N. Brady, MPEG-4 Standardized methods for  the compression of arbitrar- ily shaped video objects. IEEE Trans. Circ. Syst. Video Technol., 9:8  1999 , 1170–1189.  [8] W.-H. Chen & W. K. Pratt, Scene adaptive coder. IEEE Trans. Commun., 32:3  1984 ,  225–232.  [9] I. Daubechies, The wavelet transform, time frequency localization and signal analysis.  IEEE Trans. Inf. Theory, 36:5  1990 , 961–1005.      755   cid:2   References  [10] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [11] C. J. Duanmu, M. O. Ahmad & M. N. S. Swamy, A vector based fast block motion estimation algorithm for implementation on SIMD architectures. In Proc. IEEE ISCAS, Phoenix, AZ, May 2002, 4, 337–340.  [12] C. J. Duanmu, M. O. Ahmad & M. N. S. Swamy, Fast block motion estimation with eight-bit partial sums using SIMD architecture. IEEE Trans. Circ. Syst. Video Tech., 17:8  2007 , 1041–1053.  [13] M. Ghanbari, Standard Codecs: Image Compression to Advanced Video Coding   London: IEE Press, 2003 .  [14] N. Gupta, M. N. S. Swamy & E. I. Plotkin, Despeckling of medical ultrasound images using data and rate adaptive lossy compression. IEEE Trans. Medical Imaging, 24:6  2005 , 743–754.  [15] N. Gupta, M. N. S. Swamy & E.I. Plotkin, Wavelet domain based video noise reduction using temporal DCT and hierarchically-adapted thresholding. IET Image Process., 1:1  2007 , 2–12.  [16] ITU-R, Studio Encoding Parameters of Digital Television for Standard 4:3 and Wide-  screen 16:9 Aspect Ratios, ITU-R Rec. BT.601-5, Geneva, 1995.  [17] J. R. Jain & A. K. Jain, Displacement measurement and its application in interframe  image coding. IEEE Trans. Commun., 29:12  1981 , 1799–1808.  [18] T. Koga, K. Iinuma, A. Hirano, Y. Iijima & T. Ishiguro, Motion-compensated inter- frame coding for video conferencing. In Proc. National Telecommun. Conf.  NTC’81 , New Orleans, LA, Dec 1981, G5.3.1–G5.3.5.  [19] A. Luthra, G. J. Sullivan & T. Wiegand, eds., Special Issue on the H.264 AVC Video  Coding Standard. IEEE Trans. Circ. Syst. Video Technol., 13:7  2003 .  [20] M. Nelson, The Data Compression Book  New York: M&T Books, 1992 . [21] S. M. M. Rahman, M. N. S. Swamy & M. O. Ahmad, Video denoising based on inter- frame statistical modeling of wavelet coefﬁcients. IEEE Trans. Circ. Syst. Video Tech., 17:2  2007 , 187–198.  [22] S. M. M. Rehman, M. O. Ahmad & M. N. S. Swamy, Bayesian wavelet-based image denoising using the Gauss-Hermite expansion. IEEE Trans. Image Process., 17:10  2008 , 1755–1771.  [23] K. D. Rao, M. N. S. Swamy & E. I. Plotkin, Adaptive ﬁltering approaches for colour image and video restoration. IEE Proc. Vis. Image Signal Process., 150:3  2003 , 168–177.  [24] A. Said & W. A. Pearlman, A new, fast and efﬁcient image codec based on set par- titioning in hierarchical trees. IEEE Trans. Circ. Syst. Video Technol., 6:3  1996 , 243–250.  [25] K. Sayood, Introduction to Data Compression, 2nd edn  San Mateo, CA: Morgan  Kaufmann, 2000 .  2003 .  [26] K. Sayood  ed , Lossless Compression Handbook  San Diego, CA: Academic Press,  [27] D. Sen, M. N. S. Swamy & M. O. Ahmad, Unbiased homomorphic system and its application in reducing multiplicative noise. IEE Proc. Vis. Image Signal Process., 153:5  2006 , 521–537.      756   cid:2   Source coding II: image and video coding  [28] J. M. Shapiro, Embedded image coding using zero-trees of wavelet coefﬁcients. IEEE  Trans. Signal Process., 41:12  1993 , 3445–3462.  [29] D. Santa-Cruz, R. Grosbois & T. Ebrahimi, JPEG 2000 performance evaluation and  assessment. Signal Process.: Image Commun., 17:1  2002 , 113–130.  [30] D. Sen, M. N. S. Swamy & M.O. Ahmad, Computationally fast techniques to reduce AWGN and speckle in Videos. IEE Proc. Vis. Image Signal Process., 1:4  2007 , 319–334.  [31] M. Sonka, V. Hlavac & R. Boyle, Image Processing, Analysis, and Machine Vision,  3rd edn  Toronto, Canada: Thomson Learning, 2008 .  [32] C. K. Tan & M. Ghanbari, Using non-linear diffusion and motion information for  video segmentation. In Proc. IEEE ICIP, New York, Sep 2002, 2, 769–772.  [33] D. Taubman & A. Zakhor, Multirate 3-D subband coding of video. IEEE Trans. Image  Process., 3:5  1994 , 572–588.  [34] D. Taubman, High performance scalable image compression with EBCOT. IEEE  Trans. Image Process., 9:7  2000 , 1158–1170.  [35] M. Wien, Variable block-size transforms for H.264 AVC. IEEE Trans. Circ. Syst.  Video Technol., 13:7  2003 , 604–613.  [36] J. Zan, M. O. Ahmad & M. N. S. Swamy, New techniques for multi-resolution motion  estimation. IEEE Trans. Circ. Syst. Video Tech., 12:9  2002 , 793–802.  [37] J. Zan, M. O. Ahmad & M. N. S. Swamy, Pyramidal motion estimation techniques exploiting intra-level motion correlation. IEEE Trans. Circ. Syst. II, 50:2  2003 , 83–93.  [38] J. Zan, M. O. Ahmad & M. N. S. Swamy, Multiplicationless Burt and Adelson’s pyramids for motion estimation. IEEE Trans. Circ. Syst. Video Tech., 14:1  2004 , 136–141.  [39] J. Zan, M. O. Ahmad & M. N. S. Swamy, A multiresolution motion estimation tech-  nique with indexing. IEEE Trans. Circ. Syst. Video Technol., 16:2  2006 , 157–165.  [40] J. Zan, M. O. Ahmad & M. N. S. Swamy, Comparison of wavelets for multiresolution  motion estimation. IEEE Trans. Circ. Syst. Video Tech., 16:3  2006 , 439–446.  [41] Y.-Q. Zhang & S. Zafar, Motion-compensated wavelet transform coding for color  video compression. IEEE Trans. Circ. Syst. Video Technol., 2:3  1992 , 285–296.  [42] J. Zhang, M. O. Ahmad & M. N. S. Swamy, Feature-bit-plane matching technique  for estimation of motion vectors. Electron. Lett., 34:11  1998 , 1090–1091.  [43] J. Zhang, M. O. Ahmad, and M. N. S. Swamy, Quadtree structured region-wise motion compensation for video compression. IEEE Trans. Circ. Syst. Video Technol., 9:5  1999 , 808–822.  [44] Y. Zhao & M. N. S. Swamy, Technique for designing biorthogonal wavelet ﬁlters with an application to image compression. Electron. Lett., 35:12  1999 , 1530–1532. [45] Y. Zhao & M. N. S. Swamy, New technique for designing nearly orthogonal wavelet ﬁlter banks with linear phase. IEE Proc.-Vis. Image Signal Process., 147:6  2000 , 527–533.      18  Multiple antennas: smart antenna systems  18.1 Introduction  Wireless channels suffer from time-varying impairments such as multipath fading, interfer- ence, and noise. Diversity, such as time, frequency, space, polarization, or angle diversity, is typically used to mitigate these impairments. Diversity gain is achieved by receiving independent-fading replicas of the signal.  The multiple antenna system employs multiple antennas at either the transmitter or the receiver, and it can be either multiple-input single-output  MISO  for beamforming or transmit diversity at the transmitter, single-input multiple-output  SIMO  for diversity combining at the receiver, or MIMO, depending on the numbers of transmit and receive antennas. The MISO, SIMO, and MIMO channel models can be generated by using the angle-delay scattering function.  Multiple antenna systems are generally grouped as smart antenna systems and MIMO systems. A smart antenna system is a subsystem that contains multiple antennas; based on the spatial diversity and signal processing, it signiﬁcantly increases the performance of wireless communication systems. Direction-ﬁnding and beamforming are the two most fundamental topics of smart antennas. Direction-ﬁnding is used to estimate the number of emitting sources and their DoAs, while beamforming is used to estimate the signal-of- interest  SOI  in the presence of interference.  A MIMO system consists of multiple antennas at both the transmitter and the receiver. They are typically used for transmit diversity and spatial multiplexing. Spatial multiplexing can maximize the system capacity by transmitting at each transmit antenna a different bitstream. MISO, SIMO, and MIMO can be collectively treated as MIMO, and thus the smart antenna system can be regarded as a special case of the MIMO system.  For implementation of multiple antenna systems, a major problem is the knowledge of the channel at the transmitter as well as the receiver. The situation may be such that CSI is available at both the receiver and the transmitter, CSI is available at the receiver alone, or no CSI is available. The performance can be improved if more CSI is available. Multiple antennas are difﬁcult to implement on the MS due to the size and power restrictions.  18.1.1 The concept of smart antennas  Research on the topics of smart antennas started in the 1960s. Smart antennas are gener- ally used for spatial ﬁltering for interference reduction  SFIR  or SDMA. For SFIR, a BS      758   cid:2   Multiple antennas: smart antenna systems  steers its radiation pattern towards the desired MS, and this generates little interference to other users. SFIR is similar to sectorization. The average CCI can be reduced, and thus the reuse distance D can be decreased, leading to an increase in the capacity. SDMA achieves simultaneous communications with two or more users in the same cell that use the same frequency, time, and code. The BS creates many beams, each directed towards one user. Even if these beams are separated by an angle, the surrounding scatters may lead to mul- tipath, which may arrive in the directions of other beams. In both the SFIR and SDMA cases, for an array of Na elements, the maximum number of users or interfering sources it can support is Na.  Based on the space diversity of an antenna array and digital signal processing tech- niques, a smart antenna system dynamically adjusts the beamforming weights so as to steer the main lobe of the beampattern toward the desired user on the transmit path. This considerably reduces interference to other users, when compared to the beampattern of a conventional omnidirectional antenna. This transmit beamforming function corresponds to a MISO channel. Transmit beamforming is also known as transmit diversity combining.  On the uplink, the BS nulliﬁes the interference signals to maximize the SINR for the desired signal. Consequently, use of smart antennas can signiﬁcantly reduce the overall interference in a cell and hence, improve the capacity of the system. This corresponds to a SIMO channel, and the function of the smart antenna system is known as receive beam- forming. When there is only the desired signal and no interfering sources, this function is known as diversity combining.  Both types of smart antenna systems make use of the antenna diversity to improve the system performance. The beamforming function leads to an array gain, while diversity combining yields a diversity gain. The concept of smart antennas is illustrated by Fig. 18.1.  18.1.2 Smart antennas in mobile communications  Smart antenna technology can considerably reduce radiation hazards, and it becomes an effective method in controlling RF power levels. For a simulated network with four antennas, the capacity of a CDMA network with power control is increased by four to ﬁve times, compared with the same system using one antenna [1].  Smart antenna systems can increase the system capacity in a number of ways [29]. In a TDMA FDMA system, they can be used to decrease the reuse distance by reducing the  Desired signal  Interfering signals   cid:2 Figure 18.1  Schematic of a smart antenna system.      759   cid:2   18.2 Direction-ﬁnding  interference, thus decreasing the cluster size for frequency reuse. An alternative solution is to keep the cluster size unchanged, and increase the number of users within a cell. Multiple users are served on the same time frequency slot, and they are distinguished by the BS using their different spatial signatures.  Smart antenna technology signiﬁcantly improves the spectral efﬁciency and QoS. Smart antenna technology is not a core requirement for 3G mobile communications, due to the very expensive computation involved. Even though smart antenna technology is not mandatory in WCDMA and CDMA2000, many vendors have already introduced their smart antenna BSs. TD-SCDMA is the only 3G standard that speciﬁes smart antenna tech- nology using a uniform circular array with eight elements at the BS. Future-generation wireless systems may adopt smart antenna technology as an integral part of the system.  In [4], a smart-antenna based on a combined DoA and joint channel estimation scheme has been investigated for UTRA-TDD applying MUD at the uplink receiver. A user- speciﬁc training sequence is used for a combined DoA and joint channel estimation. The number of impinging DoAs is estimated according to a modiﬁed minimum descrip- tion length criterion for centro-symmetric array conﬁgurations [42]. Smart antennas using uniform circular arrays have been examined for DoA estimation and beamforming in [26]. For IS-95 CDMA that has strict power control, due to the processing gain G, the power  of a desired user, Pd, is related to the power of an interfering user, Pi, by  Pd = GPi.   18.1   Application of an array of Na elements can increase Pd by a factor of Na. Assuming a threshold of SIR for deciding the number of admissible users in the cell, the adoption of an antenna array at the BS can increase the number of admissible users by a factor of Na. Beamforming for narrowband CDMA BS receivers has been discussed in [38], where a comparison of the beam steering and the eigenﬁlter methods has also been made.  For 3G CDMA systems, a high-data rate user has a low spreading factor, and thus becomes a more severe interferer. In this case, the interference can be suppressed by placing a null in that direction. Downlink beamforming for WCDMA has been discussed in [30]. Within one logical cell with three sectors using standard panel antennas, user- speciﬁc and ﬁxed beamforming modes can be used. User-speciﬁc beamforming generates individual beams to each MS without any restriction on the selection of the weight vec- tors. On the other hand, ﬁxed beamforming synthesizes a ﬁnite set of beams at the BS and multiple MSs may receive signals transmitted under the same beam. Beamforming is not allowed on all channels; some channels only support ﬁxed beamforming, while user-speciﬁc beamforming is optional.  18.2 Direction-ﬁnding  For a uniform linear array, as shown in Fig. 18.2, there is a time delay τn between the signal at element n and the reference element n = 1: τn =  n − 1    18.2   sin θ,  d c      760   cid:2   Multiple antennas: smart antenna systems   cid:2 Figure 18.2  x1 t   θ  xNa t   d  sin θ  x2 t   d  Time delays for a uniform linear array.  where d is the inter-element spacing, c is free-space speed of light, and θ is the angle of the incident signal, −90  ◦ ◦ < θ < 90 . Thus xn t  = x1 t − τn .  This model is also applicable for the case of the transmitter.  The phase differences for all the array elements are denoted by the steering vector  d = cid:7   d1, . . . , dNa   cid:8 T ,  where Na is the number of the array elements and di = e  −j2πf τi.  18.2.1 Pseudospectrums  The DoAs of incident signals are traditionally obtained by using a pseudospectrum method, which deﬁnes a function P θ  that gives an indication of the DoAs at the maxima. DoAs can be easily obtained by using the Fourier transform of the signal vector x. This produces the DoAs θi with a resolution of 2π Na. The angular spectrum is given by  P θ  = dH θ Rxxd θ  dH θ d θ   ,   cid:19    cid:20   where the superscript H denotes conjugate transpose, d θ  is the steering vector in the direction θ, and Rxx = E Capon’s method [6] is a minimum variance distortionless response  MVDR  technique, also known as the ML technique. After the weight is estimated by using the MVDR beamforming algorithm, the pseudospectrum is derived as  . This spectrum, however, has too low a resolution.  xxH  PCapon θ  =  1 −1 dH θ R xx d θ   .  This method introduces poor resolution when the sources are highly correlated, as in the case of the MVDR beamformer. The method provides a reasonable resolution, but suffers from bias. In [14], a pseudospectrum that has a form similar to that of Capon’s pseu- dospectrum is obtained from a single snapshot of array measurement; the main lobes on the pseudospectrum correspond to the DoAs of the sources.  Some of the popular high-resolution direction-ﬁnding algorithms are MUSIC  MUlti- ple SIgnal Classiﬁcations  [35], ESPRIT  Estimation of Signal Parameters via Rotational Invariance Techniques  [32, 39], and the minimum-norm method. MUSIC is the most   18.3    18.4    18.5    18.6       761   cid:2   18.2 Direction-ﬁnding  popular method and is applicable for arbitrary arrays, and is introduced in Section 18.2.2. The minimum-norm method is only suitable for a uniform linear array. Most high- resolution direction-ﬁnding algorithms including ML and MUSIC have an inherent, computationally expensive search procedure over d. ESPRIT eliminates this search pro- cedure, but demands multiple identical arrays called doublets, which are separate arrays or two subarrays of one larger array. A thorough review of direction-ﬁnding methods is given in [24], and a good introduction to these algorithms is given in [25].  ESPRIT and MUSIC perform poorly in the presence of highly correlated multipath sig- nals, which frequently occur in urban environments. In this case, the simple conventional beamformer spectrum can be used  P θ  = dH θ Rxxd θ .   18.7   The maximum of P θ  corresponds to the direction of the sources.  For an antenna array of Na elements and Ns sources, the observed data vector is given by  where D = cid:19    cid:20   , s t  = cid:7   x t  = D θ s t  + n t ,  s1 t , s2 t , . . . , sNs t    cid:8 T, and n is an Na-dimensional   18.8   d1d2 . . .dNs  noise vector with variance σ 2.  The autocorrelation of x t  is thus given by   cid:19    cid:20   where Rss = E  ssH  .  Rxx = DRssDH + σ 2 n I,   18.9   18.2.2 MUSIC  MUSIC is an eigenstructure method. It provides unbiased estimates of the number of sig- nals, the DoAs, and the strengths of the signals. Given the number of sources Ns, the number of noise eigenvalues and eigenvectors is Na − Ns. MUSIC exploits the eigenvector subspace, and thus is a subspace method.  By eigendecomposition of Rxx, we have  4  RxxE = E cid:8 ,  λ1, . . . , λNa  where  cid:8  = diag eigenvectors. The ﬁrst Ns signiﬁcant eigenvalues correspond to the Ns sources. The Na − Ns noise eigenvectors are given by eNs+1   cid:4  cid:4  . . .eNa  .  5 , and E =  cid:19  EN = cid:19    cid:20  e1 . . .eNa  cid:20   is the matrix comprising all the  For uncorrelated signals, the smallest eigenvalues are equal to the variance of the noise.  The noise subspace eigenvectors are orthogonal to the steering vector at the DoAs of the  sources, thus at these DoAs   18.10    18.11    18.12   dH θ ENEH  N d θ  = 0.      762   cid:2   Multiple antennas: smart antenna systems  0  −10  −20  −30  −40        B d       θ   C I S U M P d e z i l a m r o N      cid:2 Figure 18.3  −50  −40  −30  −20  −10  0  10  20  30  40  θ  degrees   Pseudospectrums of the MUSIC algorithm: for Na = 8 and Ns = 3.  Ideal 100 samples 1000 samples  Accordingly, the angular spectrum for the MUSIC algorithm can be deﬁned by  PMUSIC θ  =  1  dH θ ENEH  N d θ   .   18.13   At the DoAs, there are peaks in the spectrum.  Example 18.1: For a uniform linear array of Na = 8 elements with element spacing d = λ 2, given three uncorrelated sources with amplitudes a1 = a2 = a3 = 1 impinging = 0.1, Figure 18.3 plots the angular spectrums from directions −10 ◦ of the MUSIC algorithm. The three curves in the ﬁgure correspond to the case when Rxx is obtained by the ideal signal and noise statistics, by averaging over 100 samples, and by averaging over 1000 samples, respectively.  ◦ and 10  , and σ 2 n  ◦ , 5  MUSIC achieves very high resolution when the noise variance for all the elements are identical and the signals are completely uncorrelated. Otherwise, the resolution will dimin- ish. MUSIC is applicable to an arbitrary array. The root-MUSIC algorithm developed for a uniform linear array in [3] reduces the complexity of MUSIC by ﬁnding the roots of a polynomial instead of plotting the pseudospectrum and searching for the peaks. For a uni- form linear array, the same strategy has been applied to the min-norm algorithm, leading to the root-min-norm solution.  Most modulated communication signals have the cyclostationary property [16, 22]. Cyclic MUSIC is a direction-ﬁnding algorithm that exploits the cyclostationary property of the signal by replacing the correlation Rxx by the cyclic or conjugate cyclic correlation xx and Rα Rα xx∗ [34]. Cyclic MUSIC provides a much better performance when the sepa- ration between two DoAs is very small, but performs worse when the signals are farther apart. Cyclic MUSIC is valid, independent of the number of signals and the nature of      763   cid:2   18.3 Beamforming  noise, as long as the number of signals having the speciﬁed cycle frequency is less than the number of array elements Na. However, cyclic MUSIC requires information of the cyclic frequency.  DoA estimation under coherent signal conditions  The performance of MUSIC degrades severely in a coherent or highly correlated signal environment, as in the case of multipath propagation. For this purpose, various modiﬁca- tions to MUSIC have been proposed by modifying the covariance matrix through spatial smoothing [28]. Spatial smoothing imposes restrictions on the type and structure of the array. In [19], a uniform linear array with Na antennas is divided into overlapping forward subarrays, and then the subarray covariance matrices are averaged. As long as the number of subarrays L is greater than or equal to the number of sources Ns  L ≥ Ns , the modiﬁed covariance matrix of the signals obtained is always nonsingular regardless of the coherence of the signals [31]. The forward averaging spatial smoothing scheme can detect only Na 2 coherent signals, as opposed to M − 1 noncoherent signals by using conventional MUSIC. By using a set of forward and conjugate backward subarrays simultaneously, up to 2Na 3 coherent signals can be detected.  18.3 Beamforming  Beamforming, also known as spatial ﬁltering or spatial diversity combining, combines signals from an array of antennas to form an output. The signals corresponding to each antenna are multiplied by a complex weight and the output is formed for the receiver or the transmitter. For an optimal SNR performance, the receiver must always know the channel. Assuming that the received signals at an antenna array are xi, i = 1, . . . , Na, as shown in Fig. 18.4, the output of the beamformer is given by   18.14  where wi is the beamforming weight at the ith antenna, ∗ denotes conjugation, and  i  w = cid:7    cid:8 T.  w1, w2, . . . , wNa  y = Na cid:26   i xi = wHx, w∗  * w1  * w2  * wNa  x1  x2  xNa  y   cid:2 Figure 18.4  Beamforming for an antenna array of Na elements.      764   cid:2   Multiple antennas: smart antenna systems  In the SDR architecture, the beamforming block is the ﬁrst block  for receiver  and the last block  for transmitter  in the baseband processing module. The calculated weight can be fed to the analog part of the circuit to adjust the gain at the analog part.  The performance of the beamformer is measured by the output SINR, deﬁned by  SINR = wHdRssdHw wHRIw   18.15  where the autocorrelation Rss is the average power of the desired signal s t , Rss = E[s t s t ], d is the steering vector of the desired signal, and RI is the autocorrelation of the interference-plus-noise.  ,  18.3.1 Blind source separation  Blind source separation consists of extracting the source signals from instantaneous mix- tures of source signals. The source signals can be obtained by using a set of linear beamformers. The antenna measurements can be described by  x k  = Hs k  + n,   18.16   where x k  is a vector comprising the Na antenna measurements at discrete time k, s k  is a vector comprising Ns source signals, H characterizes the channel, and n is AWGN.  A beamformer is used to ﬁnd a weight matrix W so that the beamformer output y k   approximates s k   y k  = WHx k .  ers with weight vectors w1, . . . , wNs, that is, W =  cid:19   Note that the beamformer with weight matrix W is composed of a set of vector beamform- . The pseudoinverse solution is WHH = I. In a typical case, both W and H are unknown. This is a blind source separation problem [15]. In order to solve for the signal s k  based only on the output x k , the sources must be assumed to be independent and non-Gaussian. This is an independent component analysis  ICA  problem. A well-known ICA algorithm is the FastICA; many blind source separation algorithms are discussed in [15].  w1w2 . . .wNs   18.17    cid:20   18.3.2 ZF, MRC, and Wiener beamformers  ZF beamformer  The beamforming problem can be characterized by the same equations as given by  18.16  and  18.17 . The difference between beamforming and blind source separation lies in that the structure of the antenna array or signals can be used. When H is known, the pseudoinverse solution is the simplest  W = H†,   18.18       765   cid:2   18.3 Beamforming  wMRC = hH cid:21   cid:15 h cid:15 2  F  .  where H† is the pseudoinverse of H. The pseudoinverse solution is also known as the ZF beamformer, since all the interfering sources are cancelled but the noise is not cancelled. A transmit ZF beamformer places nulls in the direction of the interfering sources, thus all the CCIs are eliminated and the ZF beamformer maximizes the SIR at the output.  when the BS has the knowledge of the channel h =  cid:7   MRC beamformer  When there are no interferers, the weights are just the MRC weights. In a MISO system,   cid:8 T to its user, the  h1, h2, . . . , hNa  transmit-MRC technique can be used as the beamforming algorithm   18.19    18.20    18.21   This is also applicable for receive-MRC in the case of a SIMO system.  The BER for receive-MRC is bounded by [40] Pb ≤  1 + γ    −Nr ,  where γ is the SNR and Nr is the number of receive antennas. A receiver using ZF com- bining with Nr antennas and Ns− 1 interferers has the same performance as a receiver with Nr − Ns+ 1 antennas and no interferences [40]. Thus, a ZF beamformer can null out Ns− 1 interferers with a diversity order of Nr − Ns + 1.  When the objective is to minimize the difference between the output signal vector and the desired signal vector s k , for all k, in the MSE sense, we have  MMSE beamformer  W = ˆR −1 xx HH.  This is the linear MMSE or Wiener receiver.  The MMSE receiver maximizes the output SINR. Typically, there are many more inter- ferers than the number of antennas, but only one or two are dominant interferers; in this case, the MMSE combiner provides a substantial increase in the performance. The MMSE combiner has the same performance as the MRC in the absence of any interference, but performs much better in the case of a strong interference, such as in interference-limited cellular systems.  18.3.3 Switched-beam antennas  Beamforming can be either based on switched-beam or adaptive beamforming systems. This subsection describes switched-beam beamforming systems, and adaptive antenna arrays are described in next section.  Switched-beam antenna arrays are an extension to the cellular sectorization scheme obtained by subdividing the sectors into multiple microsectors. Each microsector      766   cid:2   Multiple antennas: smart antenna systems  corresponds to a predetermined beam pattern. The antenna system switches between the beams so that the it always receives the strongest signal. The switched-beam approach is very simple, and only a single signal is selected and downconverted for baseband process- ing. Due to the ﬁxed beams, it cannot null signals in an arbitrary direction. The Butler matrix [18] and the Blass matrix [5] are two common realizations of the ﬁxed beams.  The Butler matrix is applied for an array of 2n elements, performs a spatial FFT, and provides 2n orthogonal beams, which are linearly independent combinations of the array element patterns. For a linear array, the Butler matrix produces beams that overlap at 3.9 dB below the maxima. Depending on the element patterns and the spacing, the array can cover ◦ hybrids, crossovers, and . The conventional Butler Matrix is realized using 3-dB 90 360 phase shifters. For a linear array of Na = 2n elements, the array factor can be derived as  ◦  AF θ  = sin  λ sin θ − lπ λ sin θ − lπ  Naπ d Naπ d  2 , . . . ,± Na−1  2 ,± 3 ◦ ≤ θ ≤ 90 ◦   18.22  . If d = λ 2, the beams are evenly distributed over the full  where l = ± 1 range of −90 The Butler matrix is easy to implement. The loss involved is very small. However, in a Butler matrix, the beamwidth and the beam angles vary with frequency, causing the beam to squint with frequency. For large matrices, the crossovers make interconnections complex.  2  ,  .   cid:18    cid:17   Example 18.2: The array factor, given by  18.22 , has been plotted in Fig. 18.5 for Na = 8 and d = λ 2. It is seen that for different phase shifts  different l  the main lobes almost equally divide the angle span of θ. When d > 0.5λ, the beams span over an ever decreas- ing interval of angles. By controlling the phase shift l, one can switch from one beam to another.  l = −3.5 −2.5 −1.5 −0.5 0.5 1.5  2.5  l = 3.5  F A  1  0.8  0.6  0.4  0.2  0   cid:2 Figure 18.5  Beams generated by using the Butler matrix approach: for Na = 8.  −50  0  θ  degrees   50      767   cid:2   18.4 Adaptive beamforming  The Blass matrix forms beams using transmission lines and directional couplers via time delays, and thus is more suitable for broadband operation. It can be used for any number of elements. It is simple but has a low performance due to the loss arising from the resistive terminations. Although it has simpler interconnections compared to the Butler matrix since no crossover is involved, it requires more components, thus making it more expensive and heavier. Beam squinting with frequency does not arise.  18.4 Adaptive beamforming  Unlike switched-beam antenna arrays, adaptive antenna arrays can adaptively steer beams towards the desired signals and null the interfering signals. Various beamforming algo- rithms have been developed; they are derived by optimizing a certain criterion such as maximizing the output SNR or minimizing the output interference [12, 24]. A beamformer with Na antenna elements can suppress up to Na − 1 interferers, or achieve an increase in SNR by a factor of Na. The beamformer can create Na − 1 nulls in the directions of the interference sources, thus achieving a diversity gain of Na.  An adaptive beamforming algorithm usually extracts an output, compares it with a known criterion or training sequence, and adjusts the beamforming weights based on the differences. Adjustment of the weights can be deﬁned based on some optimum criterion, such as ML or MMSE.  18.4.1 DoA-based beamforming  The ﬁrst class of beamforming algorithms is the spatial reference algorithms. The antenna array forms a beam that has a maximum in the main DoA of the desired signal and nulls in the DoAs of the multipath components of the interferers.  The approach typically works in three steps. It ﬁrst uses a direction-ﬁnding algorithm such as MUSIC or ESPRIT to ﬁnd the DoAs of all the signals. These DoAs are then associated with speciﬁc users. This identiﬁcation problem is then solved using a training sequence or some user-speciﬁc properties. Finally, a beamforming algorithm such as the MVDR or the generalized sidelobe canceller algorithm is applied to extract the desired signal, or to form the beam for transmitting toward the desirable user.  No reference signal is required. Due to the limited number of degrees of freedom, this method requires the number of sources to be less than the number of antenna elements. This method is not applicable to small cell and non-LOS environments.  Beam steering  The simplest beamforming is the delay-and-sum beamformer which makes all weights equivalent in amplitude but the phases are selected to steer the main beam in the desired direction θ0 [24]      768   cid:2   Multiple antennas: smart antenna systems  w = 1 Na  d  θ0  .  This requires the knowledge of the desired signal DoA.  This method is suitable only when there is no dominant interference. The SNR at the  output of the beamformer is deﬁned by   18.23    18.24    18.25    18.26    18.27    18.28   where P is the mean output power.  SNR = wHdRssdHw wHRnnw  = NaP σ 2 n  ,  MVDR beamformer  MVDR is one of the most popular beamforming methods. The MVDR beamformer [7] minimizes the array output power subject to speciﬁc gain in the desired signal direction. This leads to the minimization of the contributions due to noise and interference  min σ 2  MV  = wHRuuw,  subject to wHd = 1,  where d is the steering vector of the desired signal, and Ruu is the autocorrelation of the interference-plus-noise signal:  The method assumes that the desired and unwanted signals have zero mean.  By applying the Lagrange multiplier method, the optimum weight is derived as  The MVDR method requires only the direction of the desired signal. It creates a mainlobe in the direction of the desired signal, while creating nulls in the directions of the interfering sources, thus maximizing the SIR.  When there is only one desired source and the noise,  18.27  reduces to  This is the ML solution, and can be derived from the ML approach.  Example 18.3: Given four sources of equal amplitudes, impinging from −50 ◦ ◦ , 10 , , respectively, and a uniform linear array of Na = 8 antennas with a spacing of λ 2, ◦ 40 = 0.1. The source from −20 ◦ σ 2 is selected as the desired source. The beam patterns of n the MVDR algorithm are shown in Fig. 18.6. In the ideal case, Rxx is diagonal, and there are deep nulls in the directions of the interfering sources. However, when Rxx is calculated over a ﬁnite number of samples, correlation is introduced and Rxx is not diagonal, and those nulls at the interfering directions become shallower or diminished, leading to a degradation of the MVDR algorithm. Figure 18.6 shows the degradation when Rxx is calculated over 100 and 500 samples.  , −20 ◦  Ruu = Rii + Rnn.  wMV = R−1 uu d −1 uu d  dHR  .  wML = R−1 nn d −1 nn d  dHR  .      769   cid:2   18.4 Adaptive beamforming  Ideal 100 samples 500 samples     B d        θ   F A    0  −5  −10  −15  −20  −25   cid:2 Figure 18.6  Beam patterns of the MVDR method: Na = 8 and d = λ 2.  −50  0  θ  degrees   50  LCMV beamformer  The MVDR applies only one constraint. When there are multiple constraints given by  wHDc = c,   18.29  where Dc = [d θ1  . . .d θL ] is the spatial constraint matrix consisting of the steering vectors corresponding to the DoAs of the multipaths associated with the desired source, and c is a gain vector, which can be set to unity for EGC, or alternatively it can be optimized for MRC combining. θi’s can also be speciﬁed as the DoAs of the interfering signals to null out the interference, and in this case, the corresponding components in c should be set to zero.  The optimal weight vector, referred to as the linearly constrained minimum variance   LCMV  beamformer, is given by [20] wLCMV = R −1 uu Dc   cid:17    cid:18 −1  −1 uu Dc  DH  c R  c.   18.30   The LCMV beamformer can perfectly cancel up to Na − 1 interferers. Closed-form expressions for the outage probability of wireless systems with LCMV beamforming that cancels a number of dominant interferers using a uniform linear array have been derived in [27], for scenarios with a Rayleigh, Ricean, or Nakagami faded signal and Rayleigh faded interferers. The outage probability is shown to be very sensitive to the directions of the dominant interferers.  Beam-space processing  Most beamforming algorithms are based on element-space processing, where signals derived from each element are weighted and summed to produce the array output. Beam- space processing consists of ﬁrst taking the array signals as input and generating a set of      770   cid:2   Multiple antennas: smart antenna systems  beams in different directions by using ﬁxed weighting of the array signals. These patterns are then adaptively weighted and summed to produce the array output. For an Na-element array, beam-space processing produces a main beam steered in the direction of the desired signal and a set of up to Na−1 secondary  auxiliary  beams. The weighted output of the secondary beams is subtracted from the main beam to remove the interference, where the weights are adjusted to produce an estimate of the interference in the main beam. The beam-space processors have different names such as Howells- Applebaum array, generalized sidelobe canceller, post-beamformer interference canceller, and multiple-beam antennas [24]. These arrays are more useful when the number of sources Ns − 1 is less than the number of array elements Na, Ns < Na. In this case, only Ns − 2 weights are adjusted, as compared to Na weights in the case of the element-space proces- sor. When the number of beams is equal to Na, these arrays are fully adaptive and have the same capabilities as those of the element-space array. In the absence of errors, both processing schemes produce identical results.  18.4.2 Training-based beamforming  Another class of methods is temporal reference beamforming, which requires a training sequence in the transmitted packets. The beamforming weights w are adapted by the crite- rion that the deviation of the combiner output from the training sequence is minimized. The criterion can be based on SIR, MMSE, or BER during the training period. This requires an adaptive algorithm such as the LMS, RLS, or the direct matrix inversion algorithm. This approach is computationally effective, but it consumes some spectrum. The major difﬁculty of this approach lies in the implementation of the prior carrier and signal recovery.  The most popular MMSE criterion is not optimal in terms of the bit error probability of the system. Adaptive beamforming algorithms have been derived by minimizing the BER cost function directly, such as the stochastic gradient [8], gradient Newton [10], and block-Shanno minimum BER [33] algorithms.  For noncoherent multipaths, both the DoA-based and training-based beamforming have the ability to overcome ISI, since the correlation of two different symbols of the same user will look like noise. However, for some systems such as the GSM system, the training sequence is not unique for each user; when there is CCI, errors may occur. For CDMA systems, since each user has a unique spreading code, training can extract the signal of each user. This feature is used in the least-squares despread-respread multitarget array  LS-DRMTA  algorithm [28], where the beamformer output is ﬁrst despread by the desired user’s code and then respread for the weight calculation.  The MMSE beamformer is derived by minimizing the MSE between the desired or reference signal d t  and the output of the beamformer   18.31   MMSE beamformer   cid:19    cid:20   MSE = E  ∗  e t e   t   ,      771   cid:2   where the error signal  18.4 Adaptive beamforming  e t  = d t  − wHx t .  This leads to the optimum Wiener solution wopt = R −1  cid:19  xx r,   cid:20   where  r = E  ∗  d   t x t   .   18.32    18.33    18.34    18.35   When the interference is orthogonal to the desired signal, we have  wopt = KMMSER −1 nn Dc,  where KMMSE is a scaling factor. The MMSE beamformer requires the knowledge of the desired or reference signal.  Adaptive algorithms  When the DoAs change with time, adaptive algorithms are needed so that the beamforming weights can be updated for each sample or each block of samples. Various adaptation tech- niques can be applied to the optimization criteria deﬁned for beamforming, such as those used in the MMSE beamformer and MVDR beamformer. Popular adaptation techniques are LMS and RLS [25]. Other adaptation techniques are conjugate gradient and Kalman ﬁltering. These techniques are given in detail in [15].  Least mean squares  The MMSE beamformer requires the inversion of Rxx. By applying gradient descent to the MSE criterion  18.31 , we obtain the LMS algorithm  w k + 1  = w k  − 1 μ 2 = w k  + μe ∗  ∂w  k x k ,  ∂MSE w k     18.36   where μ is the step size. Note that in the second equality the expectation operation is replaced by the result for a single sample. The stability of the LMS algorithm is ensured when 0 ≤ μ ≤ 1  , where λmax is the largest eigenvalue of Rxx[15].  2λmax  Direct matrix inversion  Direct matrix inversion, or sample matrix inversion is another method for obtaining the Wiener solution  18.33 . It estimates Rxx and r based on the average of multiple samples, and then by applying matrix inversion. The estimate of Rxx may be updated for each new sample, leading to a new estimate of the weights. The convergence of the direct matrix inversion method is much faster than that for the LMS method, but the correlation matrix + N2 complex multiplications may be ill-conditioned and the matrix inversion requires N3 2 [25]. The direct matrix inversion method can be applied for weight update in the case of two antenna elements.      772   cid:2   Multiple antennas: smart antenna systems  Recursive least squares  The RLS method introduces a forgetting factor α when calculating Rxx k  and r k . By using matrix inversion lemma, Rxx is derived as a recursive equation, thus the matrix inversion operation is avoided. The RLS algorithm is given as [25]  k  − xH k w k − 1    18.37    cid:8   ∗  ,   cid:7  w k  = w k − 1  + g k  d g k  = R −1 xx  k x k , xx  k − 1 x k xH k R−1 xx  k − 1  − α−2R−1 −1 1 + α−1xH k R R  α  xx  k − 1   ,  xx  k − 1 x k  −1  where 0 ≤ α ≤ 1. The RLS algorithm has a convergence speed that is an order of magnitude faster than that of the LMS algorithm, and the selection of step size is avoided. However, the complexity of RLS per sample is of the order of N2, as opposed to the order of N for LMS. More detail on the RLS method is given in [15, 25]. The conjugate gradient method converges to the minimum of an error surface within N iterations for a rank-N matrix equation, and thus is faster than the RLS algorithm [9].   18.38    18.39   xx  k  = 1 −1 R  ◦  = 0.01. The desired signal impinges at 20  Example 18.4: Given a uniform linear array of 8 elements with spacing d = λ 2 and , with a source signal s k  = sin 5πk K . σ 2 , with i1 k  = There are also two time-varying interfering sources at −15 ◦ n 3 cos 4πk K  and i2 k  = exp 2k K N  0, 1 , respectively, where N  0, 1  is a normally distributed random variable with zero mean and unit variance. Comparisons between the LMS and RLS algorithms are made in Figs. 18.7–18.10. For . For the RLS implementation, α = 0.98, and the LMS implementation, μ = xx  0  = 0.01I. From these ﬁgures, it is seen that the RLS can more rapidly track the R−1  ◦ and 40  4∗λmax  1  Desired  LMS  RLS  s l a n g i S  1.5  0.5  1  0  −0.5  −1  −1.5  0   cid:2 Figure 18.7  200  400  600  800  1000  Iterations, k  Acquisition and tracking of the desired signal.      773   cid:2   18.4 Adaptive beamforming  LMS RLS   cid:2 Figure 18.8  10−6  0  200  400  600  Iterations, k  800  1000  The square errors of the LMS and RLS methods.   cid:2 Figure 18.9  The magnitudes of the array weights for the LMS and RLS methods.  200  400  600  800  1000  Iterations, k  LMS RLS  LMS RLS   cid:2 Figure 18.10  −20  −90  −60  −30  30  60  90  0  θ  degrees   Beam patterns created by the LMS and RLS methods.  100  2 e  10−2  10−4    w    0.2  0.4  0.35  0.3  0.25  0.15  0.1  0.05  0  0  5  0  −5  −10  −15     B d           F A    θ      774   cid:2   Multiple antennas: smart antenna systems  desired signal in a time-varying interfering environment. The training-based method does not require information about the source and interfering signals, and it automatically cre- ates nulls in the directions of the interference and has a main lobe in the direction of the desired signal.  18.4.3 Blind beamforming  The third class of beamforming methods belongs to the blind approach based on the sig- nal structure, and exploits the temporal and or spectral properties of the received signals. Blind algorithms make no assumptions about the channel, and do not need any calibra- tion of the antenna array. A training sequence is also not needed. The signal properties that are exploited can be the constant modulus and the cyclostationary properties. Blind beamforming algorithms have more convergence problems, compared to other methods.  The blind approach has the same drawbacks as blind equalization does, and thus limits its industrial application. Most blind algorithms assume that the channel is time-invariant during the period it collects data for determination of the signal statistics, but the sample collection time may be very long. Also, initialization of the estimate is critical for the convergence of the algorithm. For this reason, semi-blind algorithms that use very short training sequences to make the initial estimate can be used.  In a wireless communication environment, multipath propagation almost always takes place. This invalidates all eigendecomposition-based techniques and MVDR. In case of a non-Gaussian desired signal and directional Gaussian interferers, a cumulant-based blind method is used to ﬁrst identify the steering vector of the desired signal and MVDR beam- forming is then applied to remove Gaussian interference components [11]. The method behaves as the optimum beamformer that maximizes the SINR even in the presence of coherence  multipath .  Blind beamforming can also be implemented by using neural networks [12]. Although this method may lead to local minima on the MSE surface in some cases, it is generally robust and is suitable for analog implementation.  Constant modulus algorithms  The constant modulus algorithm has gained widespread popularity for blind source sepa- ration and blind equalization of communication signals. The constant modulus property is retained in most frequency- or phase-modulated signals, such as analog FM and PM, and digital FSK, PSK, MPSK signals. These signals have a constant amplitude s k , and infor- mation is carried in the phase. The constant modulus algorithm tries to ﬁnd a beamformer w so that the output ˆs k  = wHx k  has the same normalized modulus for all k. A simple implementation is minimizing a cost function, such as E[ˆs2 − 1], by using the gradient-descent technique. This gives  w k + 1  = w k  − ηxxHw k    18.40    cid:17  cid:4  cid:4 wH k x   cid:4  cid:4 2 − 1   cid:18   ,  where η is a small step size.      775   cid:2   18.4 Adaptive beamforming  Since the frequency-selective channel destroys the constant modulus property of the signal, in order to use the constant modulus algorithm, the amplitude of the original sig- nal needs to be restored or equalized before applying the constant modulus algorithm. The least-squares-based constant modulus algorithm  LS-CMA  is much faster than the conventional constant modulus algorithm [25].  The constant modulus algorithm is useful for eliminating correlated arrivals and is effec- tive for constant modulated envelope signals. The algorithm, however, is not appropriate for the CDMA system because of the required power control [24].  Cyclostationary beamforming algorithms  Most of the man-made communication signals are cyclostationary and or conjugate cyclo- stationary in nature [16, 22]. Based on this observation, a number of adaptive blind beamforming algorithms have been proposed in the literature [2, 13, 16, 41].  The two spectral self-coherence restoral  SCORE  algorithms, namely LS-SCORE and cross-SCORE, are the earliest successful cyclostationary beamforming algorithms [2]. As long as the cyclic frequency of a signal is available, the signal can always be extracted whatever be the number of interfering signals. The cyclic frequency is dependent on the carrier frequency and or the symbol rate. The complexity of the algorithms for each sample is O   cid:8    cid:7   .  N3 a  The cyclic adaptive beamforming  CAB  algorithm [41] is a simple and fast blind beam- forming algorithm for low interfering environments, and it has a complexity of O  Na . Another cyclostationary beamforming algorithm with a complexity of O  Na  has been proposed in [13].  Five new cyclostationary algorithms, such as the adaptive cross-SCORE  ACS , adap- tive CAB  ACAB , adaptive phase-SCORE  APS , maximally constrained autocorrelation  MCA , and constrained least-squares  CLS  algorithms, have been proposed in [16]. They complex multiplications. The ACS algorithm provides an all have a complexity of O excellent SINR performance in all interference environments, and is a practical one for wireless communications.  N2 a   cid:8    cid:7   For implementation of cyclostationary algorithms, each signal is required to have a unique cycle frequency, which is a linear combination of its carrier frequency and its baud rate. The number of signals that can be extracted by this method is not limited by the spatial resolution provided by the antenna array, i.e., the number of array elements.  The IS-95 CDMA system is used for speech communications. In IS-95, all users occupy the same frequency and have the same baud rate. Thus, cyclostationary beamforming algorithms are not applicable. The 3G and future-generation mobile communications are targeted for mobile multimedia communications, where each user can typically be assigned a different data  baud  rate; thus, cyclostationary beamforming algorithms can be applied in these systems.  In conventional FDMA-based narrowband communication systems, each signal occu- pies a different frequency band. These signals are separated by using many narrowband bandpass ﬁlters, one for each signal. This leads to a considerable system cost in the BS. It is possible to use cyclostationary beamforming algorithms to extract the signal of each      776   cid:2   Multiple antennas: smart antenna systems  user, as long as the frequency of each signal is known to the beamformer; this can be accomplished by using a common pilot channel to broadcast each user’s carrier frequency as well as other information.  18.5 Cyclostationary beamforming  18.5.1 Preliminaries on cyclostationarity  Man-made modulated signals are in general coupled with sinewave carriers, pulse trains, coding, repeating spreading, hopping sequences or cyclic preﬁxes, resulting in built-in periodicity. These modulated signals are characterized as having second-order cyclosta- tionarity if their mean and autocorrelation display periodicity. For cyclostationary signals, nonoverlapping frequency bands are uncorrelated, and further, the inherent periodicity implies some spectral redundancy, which results in correlation between nonoverlapping spectral components separated by some multiple of the cycle frequencies [17, 21].  In the time domain, a second-order cyclostationary process is a random process for which the statistical properties  namely, the mean and autocorrelation  change periodically as functions of time, with a period T [17, 21] mx t  = mx t + T    18.41   18.42  Since Rxx  t1, t2  is periodic, it has a Fourier-series representation. By denoting t1 = t + τ and t2 = t − τ  for all t, Rxx  t1, t2  = Rxx  t1 + T, t2 + T   cid:26   2 , we have a Fourier series of the form  for all t1, t2.   cid:17    cid:18   2  Rxx  t + τ 2  , t − τ 2  =  α  xx τ  e j2π αt, Rα   18.43   where the Fourier coefﬁcient Rα xx τ   is called the cyclic autocorrelation function or spectral correlation function, and α is known as the cycle frequency. A communication signal may have cycle frequencies that are related to the carrier frequency, the symbol rate and its harmonics, the chip rate, guard period, the scrambling code period, and the channel coding scheme.  A scalar waveform x t  is said to be spectrally self-coherent  or conjugate self-coherent  at a frequency α, if the spectral correlation function or the cyclic  or cyclic conjugate  autocorrelation function, that is, the correlation between x t  and x t  shifted in frequency by α, is nonzero for some delay τ [2, 16]  xx ∗  τ   = Rα  t + τ 2  x  x   18.44  where ∗ is the conjugate operator, the optional conjugation  ∗  is applied in the conjugate self-coherence case,  ∞ denotes inﬁnite time-averaging, and α is the cycle  or conju- ∗ ∗ = x. When α = 0, it corresponds to the conventional gate cycle  frequency. Note that  x autocorrelation, as used in the energy detector. If a signal is cyclostationary with period T,  ∞  t − τ 2  −j2π αt e   cid:18 = 0,   cid:18  cid:19    cid:17   ∗ cid:20  ∗   B   cid:17    cid:18   C      777   cid:2   18.5 Cyclostationary beamforming   18.45    18.46    18.47    18.48    18.49   then cyclic autocorrelation has a component at α = 1 T. For stationary signals, Rα xx ∗  for any α  cid:18 = 0. The spectral self-coherence  or conjugate self-coherence  coefﬁcient ρα  = 0  xx ∗  τ   is deﬁned  as [2, 16]  xx ∗  τ   Rxx 0    cid:18 = 0  ρα  xx ∗  τ   = Rα  cid:14  ∞  at some value of τ .  cyclic  autocorrelation  The spectrum cyclic density  SCD  is the Fourier transform of the cyclic  or conjugate  Calculation of Sα number of samples N, the SCD can be estimated by n, f + α 2  ˆSα xx ∗  f   = 1  1 T  XT  N  xx ∗  f   = Sα N−1 cid:26   n=0  xx ∗  τ  e  −j2πf τ dτ .  cid:18  cid:19   cid:17    cid:20  ∗   ∗ X T   cid:18   ,  n, f − α 2  xx ∗  f   can be implemented as FFT plus spectral correlations. For a ﬁxed  where XT n, f   is T-point FFT of x t  around the nth sample −j2πf udu.  XT n, f   =  x u e  −∞ Rα  cid:17   cid:14   n+ T n− T  2  2  For the received signal x t   x t  = h t s t  + w t ,  cid:18   cid:18  cid:19   ∗ cid:20  ∗    cid:17    cid:17   where s t  is the user signal, h t  is the channel impulse response, and w t  is the additive noise. If the signal s and the noise w are uncorrelated, we have  where H f   =  cid:24 ∞  xx ∗  f   = H Sα t=−∞ h t e  H  f + α ww ∗  f  , 2 −j2πft is the spectrum of the channel. Sα  ss ∗  f   + Sα Sα  f − α 2  xx ∗  f   is a two- dimensional complex transform on a support set  f , α . The AWGN is assumed to be a wide-sense stationary process. Since it is not a cyclostationary process and the observation period approaches inﬁnity, Sα differentiates the noise energy from modulated signal energy.  ww ∗  f   = 0 for α  cid:18 = 0. Thus, the spectral correlation function B  The cyclic  or cyclic conjugate  cross-correlation function Rα  sz ∗  τ   of two signals s t   and z t  is deﬁned by   cid:18  cid:22    cid:18    cid:17    cid:17    cid:23 ∗C   18.50   sz ∗  τ   = Rα  s  t + τ 2  z ∗   t − τ 2  e j2π αt  ∞   18.51   and the spectral cross-correlation  or conjugate cross-correlation  coefﬁcient ρα the two signals is deﬁned by  sz ∗  τ   of  sz ∗  τ   =  ρα  Rα √ sz ∗  τ   Rss 0 Rzz 0   .   18.52       778   cid:2   Multiple antennas: smart antenna systems  For the signal vector x, the cyclic  or cyclic conjugate  autocorrelation function is  deﬁned by [2, 16]  B   cid:17    cid:18  cid:7    cid:18   cid:8  ∗  = xT, the superscript T denoting the transpose.  xx ∗  τ   = Rα  t + τ 2  t − τ 2   cid:8  ∗    cid:17   xH  x  −j2π αt e  C  ∞ .   cid:7   Note that  xH   18.53   For most communication signals, the cyclic  or cyclic conjugate  autocorrelation or cross-correlation function becomes nonzero only at discrete periodic cyclic frequencies α [2, 22]. Theoretically, at cyclic  or cyclic conjugate  frequencies, the values of these functions are nonzero for any value of τ [2]. For digital signals, τ is usually taken as mT, where m is a non-negative integer and T is the sampling period. For many communication signals, the maximum self-coherence occurs at τ = 0 [2, 16]. Hence τ = 0 is usually chosen for implementation.  18.5.2 Summary of some algorithms  A reference signal r t  is deﬁned as  where c is a control vector and  r t  = cHu t ,  u t  = x ∗  t − τ  e j2π αt. C  B  y t  − r t 2  LS-SCORE is obtained by minimizing the difference between the beamformer output  y t  and the reference signal r t  [2]   18.56  where  T denotes time-averaging over the period T. By minimizing this difference subject to normalized w and c, that is, wHw = 1 and cHc = 1, the CLS algorithm is derived [16].  min w, c  T  ,  Cross-SCORE is obtained by maximizing the strength of the cross-correlation coefﬁ-  cient between y t  and r t  [2]  CAB is derived by maximizing the strength of the cyclic cross-correlation function [41]  subject to normalized w and c.  of the beamformer output y t  [2]  Auto-SCORE is obtained by maximizing the strength of the self-coherence coefﬁcient  max w, c  yr τ    .   cid:4  cid:4  cid:4 2  cid:4  cid:4  cid:4 2  ,   cid:4  cid:4  cid:4  ˆρα  cid:4  cid:4  cid:4 ˆRyr  cid:4  cid:4  cid:4  ˆρα   cid:4  cid:4  cid:4  .  max w, c  max  w  yy ∗  τ     18.54    18.55    18.57    18.58    18.59       779   cid:2   18.5 Cyclostationary beamforming  Table 18.1. Comparison of the algorithms.  Interference CAB  LS-SCORE ACAB  ACS  CLS  APS  MCA  a+ 4.75N2 4.25Na  a+ 2N2 a+ 2Na  Num. of complex multiplications  Conjugate cyclostationary algorithms  Cyclostationary algorithms  2Na  a+ 4.75N2 2.25Na + Very strong − + + Strong + + + + Medium + + ++ + Weak − Very strong − + + Strong + ++ Medium + + + + Weak  N A  a+ 6.75N2 3N2 4.25Na 2Na + + + − + + + + ++ + + + + + ++ ++ − ++ + + + + ++ ++ + + ++ ++  a+ 5.5N2 3.5Na − − ++ + + ++ ++ − − ++ ++ + + + ++ ++  N A denotes not applicable, Na = Number of antenna elements. Taken from [16]. c cid:2  2008, Springer.  N A  − + ++ + + ++  Phase-SCORE is a special case of auto-SCORE, and is a suboptimum algorithm that is derived for the cyclostationary signal only.  MCA is derived by maximizing the strength of the cyclic autocorrelation function of the  beamformer output y t  [16]   cid:4  cid:4  cid:4 ˆRα   cid:4  cid:4  cid:4  ,  max  w  yy ∗  τ     18.60   subject to the normalized weight w. MCA derived in [16] is valid for the cyclostationary signal only.  Adaptive implementation of these algorithms can signiﬁcantly reduce the complex- ity of these algorithms. The ACS, ACAB, and APS algorithms are derived from the same objective functions as those of the cross-SCORE, CAB, and phase-SCORE algo- rithms, respectively, but they are treated as different algorithms. ACS, ACAB, and APS solve an eigenvalue problem to ﬁnd the dominant mode for all the samples by using the power method, while cross-SCORE and phase-SCORE solve an eigenvalue prob- lem to ﬁnd the dominant mode for each sample. The power method [37] is a simple xx  k  is used, for cross-SCORE, the total number of complex multiplications at each sample is 6.75N2 m, m being the number of iterations needed to solve the eigenvalue to a a speciﬁed accuracy. The value of m may be different at each sample for a speciﬁed iteration accuracy, which also limits a pipeline implementation using DSPs.  method to ﬁnd the dominant mode. For example, if the recursive computation of ˆR−1  cid:7   + 4.25Na   cid:8   Extensive simulations for seven algorithms have been performed in [16], based on a complex signal environment comprising of twelve BPSK or 16QAM signals for different powers, carrier frequencies fc, and baud rates fbaud. The SINR performances of the seven algorithms are compared in Table 18.1 [16]. In this table, “−” denotes that the SINR is sometimes below 5 dB, indicating that the performance of the beamformer is unacceptable,      780   cid:2   Multiple antennas: smart antenna systems  and each “+” represents 10 dB in SINR. ACS has the best SINR performance among all the seven algorithms.  The eigenvalue problem obtained for cross-SCORE is given by [2, 16]  where λ is a positive number.  The scalar λ in  18.61  and  18.62  only affects the gain of the beamformer, and it can  be eliminated in adaptive implementation. The ACS algorithm is given by [16]  18.5.3 ACS algorithm  λw = ˆR ˆRxuc, −1 xx ˆRH λc = ˆR −1 xuw, uu  w k  = ˆR  xx  k  ˆRxu k c k − 1 , −1 w k  = w k   cid:15 w k  cid:15  ,  c k  = ˆR uu  k  ˆRux k w k . −1  This is actually the power method for solving an eigenvalue problem [2, 37], and can very rapidly converge to the dominant mode of the eigenvalue problem in a rank-1 spectral self-coherence environment. For slow fading channels, we have  k  ˆRxx k  = 1  k cid:26  i=1 = k − 1 ˆRxu k  = k − 1  k  k  ˆRux k  = ˆRH     cid:5   cid:5   x i xH i  ˆRxx k − 1  + 1 k − 1 ˆRxu k − 1  + 1 k − 1   cid:6   cid:6   x k xH k   ,  x k uH k   .   cid:22  ˆR   cid:23  ∗   .  ˆR uu  k  = −1  −1 xx  k   xu k ,  Also,  By using the matrix inverse lemma, from  18.66 , we have  ˆR xx  k  = k −1 k − 1  ˆR xx  k − 1  − −1  xx  k − 1 x k xH k  ˆR−1 ˆR−1 xx  k − 1   k − 1  + xH k  ˆR xx  k − 1 x k  −1  .   18.69   D  Example 18.5: We use a uniform linear array of Na = 4 elements with a spacing of half = 0.1, a wavelength of the carrier 2 GHz. We choose the noise variance of the array σ 2 τ = 0, the sampling rate fs = 48 Msamples s, and all the signals are assumed to be at the a,n same noise level σ 2 s,n  = 0.2.   18.61    18.62    18.63    18.64    18.65    18.66    18.67    18.68       18.5 Cyclostationary beamforming  Table 18.2. Impinging signals.  Signal  fc, MHz  SNR, dB  fs fbaud  Modulation  DoA ◦ 20 ◦ 60 ◦ −10 ◦ −30  A B C D  2025 2080 1980 1950  15 10 5 20  10 13 19 23  QAM16 BPSK QAM16 BPSK  20  15  10  5  0     B d      R N I S  CAB ACS ACAB APS  781   cid:2      B d      R N I S  30  25  20  15  10  5  0  −5  101  CAB ACS ACAB APS   cid:2 Figure 18.11 SINR performance.  a  Signal D as SOI  DoA=−30  ◦  , SNR=20 dB .  b  Signal C as SOI  DoA=−10  ◦  ,  104  −5  101  102  103  104  Samples   b   102  103  Samples   a   SNR=5 dB .  Let us assume that there are four digital signals with a 100% cosine roll-off, impinging from different directions, as listed in Table 18.2, where fc is the carrier frequency, fbaud is the baud rate, and DoA is the impinging angle. Simulation is based on the cyclostationarity of the signals, and the cyclostationary frequency is taken as α = fbaud. Four algorithms, namely, the CAB, ACS, ACAB, and APS, are considered in this exam- ple. Figure 18.11 shows the SINR performance of the algorithms. The beampatterns at the 104th sample of a random run are plotted in Fig. 18.12. We simulate for the cases of the strongest signal  signal D  and the weakest signal  signal C  as the SOI. The SINR perfor- mance is computed as an average over 20 independent runs, the average being carried in the sense of geometric mean. For ACS, ACAB, and APS, R−1 with random elements between 0 and 1. Rxu 0  is taken as an Na × Na zero matrix. The SINR performances of ACS and APS are very close to each other. ACS and APS always substantially outperform ACAB and CAB. ACAB and CAB fail to extract the SOI in the case of a strong interference. The beampatterns of ACS and APS almost coincide at the 104th sample. ACS and APS tend to create nulls in the directions of the interfering sources, while ACAB and CAB do not process this property.  xx  0  is taken as 1 Pmax · diag a , where a is an Na vector      782   cid:2   10  0  −10  −20  −30     B d      n r e t t a p    r e w o P  SOI  CAB ACS ACAB APS  DoA  degrees   0   a    DoA=−10 ◦  , SNR=5 dB .  Multiple antennas: smart antenna systems  10  0  −10  −20  −30     B d     n r e t t a p   r e w o P  SOI  CAB ACS ACAB APS  DoA  degrees   0   b   −40  −90  −60  −30  30  60  90  −60  −30  30  60  90  −40  −90   cid:2 Figure 18.12 Beampattern at the 104th sample.  a  Signal D as SOI  DoA=−30  ◦  , SNR=20 dB .  b  Signal C as SOI  18.6 Wideband beamforming  Conventional narrowband beamformers are not suitable for wideband signals. For wide- band signals, the phase at each antenna element for a speciﬁed DoA is a function of the frequency. For the same distance, a lower frequency signal component corresponds to a smaller phase shift. For wideband beam pattern synthesis, a simple method is to perform multiple independent narrowband designs over a range of frequencies. A more popular approach is to employ a tapped-delay-line structure, resulting in an array pattern that scales with temporal frequency. The frequency-invariant synthesis uses FIR ﬁlters to design an array pattern that is the same at all frequencies in a band of interest [36].  18.6.1 Tapped-delay-line structure  For wideband beamforming, a tapped-delay-line is normally used for each antenna ele- ment, and the structure of the beamformer is shown in Fig. 18.13. Each tapped-delay-line serves as an equalizer to make the phase response the same for different frequency com- ponents. This results in a large amount of coefﬁcients, which are usually solved in the frequency domain by using FFT and IFFT. The length of the tapped-delay-lines depends on the bandwidth of the signals. As a result, wideband beamforming uses spatial as well as temporal ﬁltering.  The output of the beamformer is given by  wm,kxm n − k ,   18.70   y n  = Na cid:26   K−1 cid:26   m=1  k=0  where wm,k is a weight.      783   cid:2   18.6 Wideband beamforming  z−1  z−1  w1,0  w1,K−1  x1 n   xNa n   z−1  wNa,0  wNa,1  z−1  wNa,K−1  y n   Σ  w1,1  Σ  Σ   cid:2 Figure 18.13  Tapped delay line structure of length K for an Na-element beamformer.  For wideband or UWB antenna arrays, the antenna spacing d is usually determined by the highest frequency, fh, of the input wave. For the uniform linear array, d can be given by  d = c 2fh  .  P w  = wTRw,  CT w = F,  In order to cancel the directional interferences while having the speciﬁed response in the look direction, the beamformer can be formulated by minimizing the mean output power [24]  subject to   18.73  where w is an MK-dimensional vector, the array correlation matrix R is an MK × MK real matrix whose elements represent the correlation between various tap outputs, F is a K-dimensional vector that speciﬁes the frequency response in the look direction, and C is an MK × K constraint matrix. The solution is given by [24] −1F.  −1C CTR  ˆw = R  −1C    18.74    18.71    18.72   18.6.2 Pure delay-line wideband transmitter beamformer  One simple implementation is the pure delay-line wideband transmitter beamformer, where wm, k = 0 or 1, and the tapped-delay-line degenerates to a time delay. The time delay at the mth antenna is set to be   18.75  To ensure positive Tm, one can select T0 ≥  Na − 1  d c, d being the spacing of the uniform linear array. This beamformer uses no multiplication.  Tm = T0 + τm.      784   cid:2   Multiple antennas: smart antenna systems  In the frequency domain,  the ﬁltering characteristic of the beamformer is given  by [23]  H f , θ  = Y f , θ   cid:22  X f   = A1 θ A2e  cid:22  × sin sin  −j2πf α0e πfNa  c   cid:23  −jπf  Na−1  d  cid:23  .  sin θ0 − sin θ    sin θ0 − sin θ    πf d c  d c   sin θ0−sin θ     18.76    18.77    18.78   where A1 θ  is the angle-dependent gain of an antenna element, A2 is attenuation due to propagation, θ0 is the desired angle, and α0 = T0 + τ0, τ0 being the constant transmis- sion delay of the ﬁrst element. The directional patterns of the beamformer for different frequencies are derived from this equation.  Example 18.6: For an UWB signal with a center frequency of 7 GHz and a bandwidth of 6 GHz, given θ0 = 30 , we use an array of Na = 12 elements and a perfect antenna ◦  A1 θ  = 1 , and A2 = 1. The directional pattern, given by 18.78, is plotted in Fig. 18.14, = 3.75 cm. It is shown that for for the cases of  a  d = λ case  b , the grating lobes are very large and the inter-null beamwidths are reduced as compared to case  a . This conﬁrms that d, given by  18.71 , is reasonable. In this case, a perfect frequency-independence characteristic is obtained only along the desired angle, while the inter-null beamwidth and sidelobe characteristics depend on the frequency of operation.  = 1.5 cm and  b  d = λ  2fh  2fl     B d        θ , f    H    15  10  0  −10  −20  −30  −90  d = 1.5 cm  d = 3.75 cm  15  10  0  −10  −20     B d        θ , f    H    f = 4 GHz f = 6 GHz f = 8 GHz f = 10 GHz  0  θ  degrees    a   f = 4 GHz f = 6 GHz f = 8 GHz f = 10 GHz  0  θ  degrees    b   −60  −30  30  60  90  −60  −30  30  60  90  −30  −90   cid:2 Figure 18.14 Directional patterns of a delay-line beamformer for different frequencies in UWB:  a   d = λ 2fh  = 1.5 cm.  b  d = λ 2fl  = 3.75 cm.      785   cid:2   References  Problems  18.1 Determine the steering vector for a uniform linear array of N isotropic elements along the z-axis. The spacing of adjacent elements is d and the plane wave impinges from the direction  θ, φ .  18.2 Determine the steering vector for a uniform circular array of N isotropic elements on the x-y plane. The radius of the array circle is a and the plane wave impinges from the direction  θ, φ .  ψ  N 2   cid:8   18.3 For an N-element uniform linear array, the elements are fed with currents of equal  cid:7  amplitude and a progressive phase lead of δ. The antenna spacing is d. Selecting the phys- ical center of the array as the reference point,   sin ψ 2 , ψ = βd cos θ + δ.  a  Verify that the array factor is given by AF = sin  b  For N = 8 and d = λ 2, ﬁnd the nulls of the array.  c  To become a broadside array, that is, the main lobe in θ = 90 ◦  d  To become an end-ﬁre array with maximum lobe in θ = 0, ﬁnd δ.  cid:27  ∞ 18.4 According to the results of Problem 18.3, verify that the directivity of the an N-element uniform linear array is:  a  D ≈ 2 L λ  for the broadside array and  b  D ≈ 4 L λ  for the end-ﬁre array. The array length L =  N−1 d. [Hint: −∞ sin x x 2dx = π.]. 18.5 For a uniform planar array of 6 × 6 elements with a spacing of a half-wavelength in both directions, that is, dx = dy = λ 2, determine the DoA for a signal. Assume that the signal is from θ = 30 ◦ 18.6 Derive the LCMV beamformer given by  18.30 .  , how should one select δ?  and φ = 90 ◦  .  18.7 Write a MATLAB program to beamform a uniform linear array of 10 elements with a uniform λ 2 spacing toward the broadside  θ = 0  by using the LMS algorithm. Assume that there are several impinging signals from different directions.  References  [1] 3GPP2, C.S0002 Physical Layer Standard for CDMA 2000 Spread Spectrum Systems,  ver. 3.0, Jun 2001.  [2] B. G. Agee, S. V. Schell & W. A. Gardner, Spectral self-coherence restoral: a new approach to blind adaptive signal extraction using antenna arrays. Proc. IEEE, 78:4  1990 , 753–766.  [3] A. Barabell, Improving the resolution of eigenstructure-based direction-ﬁnding algo-  rithms. In Proc. IEEE ICASSP, Boston, MA, 1983, 336–339.  [4] J. J. Blanz, A. Papathanassiou, M. Haardt, I. Furio & P. W. Baier, Smart antennas for combined DOA and joint channel estimation in time-slotted CDMA mobile radio systems with joint detection. IEEE Trans. Veh. Tech., 49:2  2000 , 293–306.      786   cid:2   Multiple antennas: smart antenna systems  [5] J. Blass, Multidirectional antenna: a new approach to stacked beams. In IRE Int.  Convention Record, New York, Mar 1960, 8, 48–C50.  [6] J. Capon, R. Greenﬁeld & R. Kolker, Multidimensional maximum likelihood process-  ing of a large aperture seismic array. Proc. IEEE, 55:2  1967 , 192–211.  [7] J. Capon, High-resolution frequency-wavenumber spectrum analysis. Proc. IEEE,  57:8  1969 , 1408–1418.  [8] S. Chen, N. N. Ahmad & L. Hanzo, Adaptive minimum bit-error rate beamforming.  IEEE Trans. Wireless Commun., 4:2  2005 , 341–348.  [9] S. Choi & T. K. Sarkar, Adaptive antenna array utilizing the conjugate gradient method for multipath mobile communications. Signal Process., 29:3  1992 , 319–333. [10] R. C. de Lamare & R. Sampaio-Neto, Adaptive multiuser receivers for DS-CDMA using minimum BER gradient-Newton algorithms. In Proc. IEEE PIMRC, Lisboa, Portugal, Sep 2002, 3, 1290–1294.  [11] M. C. Dogan & J. M. Mendel, Cumulant-based blind optimum beamforming. IEEE  Trans. Aerospace Electron. Syst., 30:3  1994 , 722–741.  [12] K.-L. Du, A. K. Y. Lai, K. K. M. Cheng & M. N. S. Swamy, Neural methods for  antenna array signal processing: a review. Signal Process., 82:4  2002 , 547–561.  [13] K.-L. Du & M. N. S. Swamy, Simple practical cyclostationary beamforming algo-  rithm. IEE Proc. Vision Image Signal Process., 151:3  2004 , 175–179.  [14] K.-L. Du & M. N. S. Swamy, A deterministic direction ﬁnding approach using a sin- gle snapshot of array measurement. In Proc. IEEE Canadian Conf. Electr. Computer Eng., Saskatoon, Canada, May 2005, 1188–1193.  [15] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [16] K.-L. Du & M. N. S. Swamy, A class of adaptive cyclostationary beamforming  algorithms. Circ. Syst. Signal Process., 27:1  2008 , 35–63.  [17] K.-L. Du & W. H. Mow, Exploiting Multiple Antennas for Spectrum Sensing in  Cognitive Radio Networks, U. S. Patent Application, 2009.  [18] J. Butler & R. Lowe, Beam-forming matrix simpliﬁes design of electrically scanned  antennas. Electron. Design, 9  1961 , 170–173.  [19] J. E. Evans, J. R. Johnson & D. F. Sun, High Resolution Angular Spectrum Estima- tion Techniques for Terrain Scattering Analysis and Angles of Arrival Estimation in ATC Navigaton and Surveillance System, MIT Lincoln Lab, Lexington, MA, Report 582, 1982.  [20] O. L. Frost, An algorithm for linearly constrained adaptive array processing. Proc.  [21] W. A. Gardner, Statistical Spectral Analysis: An Nonprobabilistic Theory  Englewood  IEEE, 60:8  1972 , 926–935.  Cliffs, NJ: Prentice-Hall, 1987 .  [22] W. A. Gardner, Exploitation of spectral redundancy in cyclostationary signals. IEEE  Signal Process. Mag., 8:2  1991 , 14–36.  [23] M. Ghavami, L.B. Michael & R. Kohno, Ultra Wideband: Signals and Systems in  Communication Engineering, 2nd edn  Chichester, UK: Wiley, 2007 .  [24] L. C. Godara, Application of antenna arrays to mobile communications, Part II: beam- forming and direction-of-arrival considerations. Proc. IEEE, 85:8  1997 , 1195–1245.      787   cid:2   References  [25] F. Gross, Smart Antennas for Wireless Communications  New York: McGraw-Hill,  2005 .  [26] P. Ioannides & C. A. Balanis, Uniform circular arrays for smart antennas. IEEE Anten.  Propagat. Mag., 47:4  2005 , 192–206.  [27] H. Li, Y.-D. Yao & J. Yu, Outage probabilities of wireless systems with LCMV  beamforming. IEEE Trans. Wireless Commun., 6:10  2007 , 3515–3523.  [28] J. Liberti & T. Rappaport, Smart Antenna for Wireless Communications  Englewood  Cliffs, NJ: Prentice Hall, 1999 .  [29] A. F. Molisch, Wireless Communications  Chichester, UK: Wiley-IEEE, 2005 . [30] K. I. Pedersen, P. E. Mogensen & J. Ramiro-Moreno, Application and performance of downlink beamforming techniques in UMTS. IEEE Commun. Mag., 41:10  2003 , 134–143.  [31] S. U. Pillai & B. H. Kwon, Forward backward spatial smoothing techniques for coher- ent signal identiﬁcation. IEEE Trans. Acoust. Speech Signal Process., 37:1  1989 , 8–15.  [32] R. Roy & T. Kailath, ESPRIT – estimation of signal parameters via rotational invariance techniques. IEEE Trans. Acoust. Speech Signal Process., 37:7  1989 , 984–995.  [33] T. A. Samir, S. Elnoubi & A. Elnashar, Block-Shanno minimum bit error rate  beamforming. IEEE Trans. Veh. Tech., 57:5  2008 , 2981–2990.  [34] S. V. Schell, Performance analysis of the cyclic MUSIC method of direction esti- mation for cyclostationary signals. IEEE Trans. Signal Process., 42:11  1994 , 3043–3050.  [35] R. Schmidt, Multiple emitter location and signal parameter estimation. IEEE Trans.  Anten. Propagat., 34:2  1986 , 276–280.  [36] D. P. Scholnik & J. O. Coleman, Optimal array-pattern synthesis for wideband digital  transmit arrays. IEEE J. Sel. Topics Signal Process., 1:4  2007 , 660–677.  [37] G. W. Stewart, Introduction to Matrix Computations  New York: Academic Press,  1973 .  [38] J. S. Thompson, P. M. Grant & B. Mulgrew, Smart antenna arrays for CDMA systems.  IEEE Pers. Commun., 3:5  1996 , 16–25.  [39] F. Wan, W.-P. Zhu & M. N. S. Swamy, A spatial extrapolation-based blind DOA esti- mation approach for closely spaced sources. IEEE Trans. Aerospace Electron. Syst., 45  2009 .  [40] J. H. Winters, J. Salz & R. D. Gitlin, The impact of antenna diversity on the capacity of wireless communication systems. IEEE Trans. Commun., 42:2–4  1994 , 1740–1750. [41] Q. Wu & K. M. Wong, Blind adaptive beamforming for cyclostationary signals. IEEE  Trans. Signal Process., 44:11  1996 , 2757–2767.  [42] G. Xu, R. H. Roy & T. Kailath, Detection of number of sources via exploitation of the  centro-symmetry property. IEEE Trans. Signal Process., 42:1  1994 , 102–112.      19  Multiple antennas: MIMO systems  19.1 Introduction  MIMO systems are wireless systems with multiple antenna elements at both ends of the link. MIMO systems can be used for beamforming, diversity combining, or spatial mul- tiplexing. The ﬁrst two applications are the same as for the smart antennas, while spatial multiplexing is the transmission of multiple data streams on multiple antennas in parallel, leading to a substantial increase in capacity. MIMO technology and turbo coding are the two most prominent recent breakthroughs in wireless communications. MIMO technology promises a signiﬁcant increase in capacity.  MIMO systems have the ability to exploit, rather than combat, multipath propagation. The separability of the MIMO channel relies on the presence of rich multipath, which makes the channel spatially selective. Thus, MIMO effectively exploits multipath. In con- trast, some smart antenna systems perform better in the LOS case, and their optimization criteria are based on the DoA DoD. Although some smart antenna systems generate good results in the non-LOS channel, they mitigate multipath rather than exploit it.  The maximum spatial diversity obtained for a non-frequency-selective fading MIMO channel is proportional to the product of the numbers of receive and transmit antennas. In the uncorrelated Rayleigh fading channel, the MIMO channel capacity throughput limit grows linearly with the number of transmit or receive antennas, whichever is smaller – i.e., min  Nt, Nr  [40]. According to the analysis and simulation performed in [40], MIMO can provide a spectral efﬁciency as high as 20–40 bits s Hz.  MIMO and OFDM are commonly thought to be the key techniques for next-generation wireless LAN and 4G mobile communications. MIMO-OFDM is used in IEEE 802.11n, IEEE 802.16m, and LTE.  19.2 MIMO system  19.2.1 MIMO system model  can be described by an Nr × Nt matrix H = cid:19   Narrowband MIMO systems with Nt transmit and Nr receive antennas have a channel that , where hij represents the channel transfer function from the jth transmitter to the ith receiver. H is modeled as a random matrix   cid:20   hij      789   cid:2   19.2 MIMO system     Nt cid:26   i=1  Es Nt     Es Nt  characterized by an uncorrelated or correlated Rayleigh fading channel, or an uncorrelated or correlated Ricean fading channel.  Assuming that each transmit antenna has an energy for each input symbol as Es Nt, Es being the total energy transmitted from all antennas per input symbol, the received signal at antenna j is given by  yj k  =  hjixi k  + nj k ,   19.1   where nj’s are the i.i.d. additive zero-mean circularly symmetric complex Gaussian  ZMC- SCG  variables with two-sided PSD N0 2, and hji is the ﬂat-fading channel gain from transmit antenna i to receive antenna j, hji being also a ZMCSCG variable in the non-LOS case.  In matrix form, we have  y k  =  H k x k  + n k ,   19.2   where y, an Nr-dimensional vector, corresponds to the output signals at the receiver anten- nas, x is an Nt-dimensional vector, whose element xj denotes the signal transmitted from the jth transmitter, and n is the additive ZMCSCG noise vector with covariance matrix Rw at the receive antennas. The SNR at each receive antenna is Es N0.  MIMO implementation relies on the rich scattering about the transmitter and receiver antennas. Insufﬁcient scattering frequently occurs when the channel is approximately LOS, or when beamforming or directional antennas are used for interference reduction or long- range transmission.  For space-time codeword of block length Nst, Nst receive vector symbols in the codeword can be stacked together in a matrix form and be processed together. For the frequency- selective channel, the channel H can be represented as H l , l = 0, 1, . . . , L − 1, where L is the maximum channel length; in this case, multiple continuous received vector samples can be stacked to solve H l , l = 0, 1, . . ., L − 1.  19.2.2 Spatial correlation and MIMO channel model  For a MIMO system, the elements of H are usually assumed to be statistically independent of one another. This assumption is not always accurate, since correlation may exist due to the propagation environment  such as the presence of LOS component , the polarization of antenna elements, and the spacing between antenna elements. The fading correlation associated with H can be decomposed into two independent components [74]  H = R1 2  r HwR1 2  t  ,   19.3   where Rr and Rt are called receive correlation and transmit correlation matrices, respec- tively, Hw is a matrix with independent Gaussian elements and unity variance, and the superscript 1 2 denotes the Hermitian square root of a matrix. Rr determines the correla- tion between the rows of H, independent of the transmit antennas. Similarly, Rt determines      790   cid:2   Multiple antennas: MIMO systems  the covariance of the columns of H, independent of the receive antennas. This model is widely used in MIMO implementation, and it has been adopted by IEEE 802.11n and IEEE 802.20 as a MIMO channel model.  The correlation matrices Rr and Rt can be measured, or be computed by assuming the scattering distribution around the receive and transmit antennas. For uniform linear arrays at the transmitter and the receiver, the correlation matrices Rr and Rt can be calculated according to two different methods given in [87, 160]. From [160], we have  ⎡⎢⎢⎢⎢⎢⎢⎢⎢⎣  1  ρ  ρ4 ...  ρ N−1 2  Rr, Rt =  ρ  1  ρ ... ···  ρ4  ρ  1 ... ρ4  ··· ... ... ... ρ  ⎤⎥⎥⎥⎥⎥⎥⎥⎥⎦ ,  ρ N−1 2  ... ρ4  ρ 1  where N is equal to Nr or Nt, corresponding to the receive or transmit antenna array, and ρ is the fading correlation between two adjacent receive or transmit antenna elements, which can be approximated by   19.4    19.5   ρ d  ≈ e  −23 cid:18 2d2,  with  cid:18  being the angular spread and d the inter-element distance. Note that for small r d , the higher-order terms are negligible and the correlation matrices take the form of triagonal matrices.  In practical cases, the degenerate channel phenomena called keyholes may arise, where the antenna elements at both the transmitter and the receiver have very low correlation, yet the channel matrix H has only a single degree of freedom, yielding a single mode of communication [6, 23, 43, 124]. This phenomenon is very similar to the case when rich-scattering transmit and receive antennas are separated by a screen with the wave pass- ing through a keyhole. This model also applies for indoor propagation through hallways, narrow tunnels or waveguides. Relay channels in the amplify-and-forward mode can be treated as keyhole channels. Thus, low correlation is not a guarantee for achieving high capacity. For outdoor environments, roof edge diffraction is perceived as a keyhole by a vertical base array, whereas the keyhole effect may be avoided by employing a horizon- tally oriented transmitter array [23]. Instantaneous SNR and outage capacity distributions of spatially correlated keyhole MIMO channels has been investigated in [77].  A double-scattering MIMO channel model that includes both the fading correlation and rank deﬁciency was introduced in [43]. The multikeyhole channel is analyzed in [77]. For a large number of antennas, the capacity of a multikeyhole channel is a normally distributed sum of the capacities of single keyhole channels.  The correlation between antennas is typically not a problem for MIMO systems with well designed antennas. This is due to the fact that even for the worst case the correlation rarely exceeds 0.7, and this yields a degradation of less than 1 dB with MRC [62] and even less with the MMSE combiner. The capacity achievable with isotropic inputs is lowered by antenna correlation, while for nonisotropic inputs correlation may not be detrimental      791   cid:2   19.2 MIMO system  [88]. For example, transmit correlation may be advantageous for small SNR and for Nt > Nr [88].  The impact of channel correlation on the capacity of a MIMO system is negligible when d cos φ , d being the inter-element distance the two-element array beamwidth, deﬁned as and φ the mean DoA, is smaller than the angular spread of the incoming multipath sig- nals [87]. Fully correlated fading destroys diversity gain, but array gain is retained. LOS component stabilizes the link, improving the SER performance, but it reduces the MIMO system capacity. These have been discussed in [103].  λ  3GPP 3GPP2 have deﬁned a cross-polarized channel model for MIMO systems [2]. The 3GPP cross-polarized channel model neglects the elevation spectrum. A composite channel impulse model for the cross-polarized channel that takes into account both the azimuth and elevation spectrums has been proposed in [121], based on which closed-form expressions for the spatial correlation have been derived and the impact of the various factors on the mutual information of the system has also been studied.  19.2.3 MIMO decoding     88888y −  Es Nt  88888 ,  The optimum ML detector estimates x by ˆx = arg min x∈BNt   19.6  where each element of x can select one of the M symbol constellations in B. There are altogether MNt possible values of x. The optimum ML decoding has an exponential complexity.  Hx  For a group of Nst vectors, we have Y =  Es  19.7  Nt where X = [x 0 x 1 ···x  Nst − 1 ] is an Nt × Nst matrix, and Y and N are deﬁned in the same manner, but have dimension Nr × Nst. For  19.7 , the ML decoding yields  HX + N,        888888Y −  8888882  F  Es Nt  HX  ,  ˆX = arg min X∈BNt×Nst  where Es is the average symbol energy over the block.  19.2.4 MIMO channel decomposition  The channel H can be decomposed by using SVD, H = U cid:27 VH,   19.8    19.9       792   cid:2   Multiple antennas: MIMO systems  where U,  cid:27 , and V are, respectively, of size Nr × Nr, Nr × Nt, and Nt × Nt. U and V are unitary matrices, and  cid:27  = diag  σi . The rank of the channel matrix H, rH, must satisfy rH ≤ min  Mt, Mr . When H is of full rank, the channel is a rich-scattering environment, and  The squared Frobenius norm of H is the total power gain of the channel, and it is  given by  rH = min  Mt, Mr  .   cid:7   = tr  HHH   cid:8  = Nr cid:26   i=1  λi,  F   cid:15 H cid:15 2  cid:15   λi =  σ 2 i , 0,  i = 1, 2, . . . , rH i = rH + 1, . . . , Nr.   19.10    19.11    19.12   where λi’s are the eigenvalues of HHH,  F is also a random variable. The statistics of  cid:15 H cid:15 2  The value  cid:15 H cid:15 2 performance. For the i.i.d.  spatially white  channel, H = Hw, the pdf of  cid:15 H cid:15 2 distribution with k = 2NtNr degrees of freedom [103], −x, e  x ≥ 0.  p x  = xNtNr−1  NtNr − 1  !  F determine the diversity F is a χ 2   19.13   The MIMO system is capable of achieving very high spectral efﬁciency and reliabil- ity in rich-scattering environments. However, when there exists spatial correlation arising from closely spaced antennas or limited angular spread in the MIMO channel, performance degrades signiﬁcantly. A precoder can be used to enhance the capacity or performance of the MIMO system in a fading channel, when instantaneous or long-term CSI is available at the transmitter. In particular, a precoder using long-term CSI is favorable for correlated MIMO systems with low-rate feedback [10, 128].  19.2.5 Channel estimation  Like the single-antenna case, channel estimation for MIMO can be implemented based on training sequences or by using a blind technique. In the MIMO system, there are more channel parameters to be estimated. It is desirable to keep the training sequences from the multiple transmit antennas mutually orthogonal in some form  time, frequency, or code  to enhance estimation accuracy. The training sequences should typically have good auto- and cross-correlation properties. The number of required training samples should be Ntr ≥ Nt × L. There are many transmission schemes over MISO or MIMO channels in the literature. These schemes rely on certain CSI available at the transmitter and or receiver side. CSI at the receiver can be easily estimated using a training-based or blind technique. CSI at the transmitter can be obtained by feedback of the receiver’s channel estimation based on the      793   cid:2   19.2 MIMO system  downlink training data  e.g., in TDD mode , or from the use of training or pilot data in the uplink  e.g. in FDD mode . Feedback usually causes some delay δD, and this delay should be insigniﬁcant compared to the coherent time Tc, δD  cid:5  Tc. In a fast changing channel, frequent channel estimation and feedback is required; in order to reduce the overhead on the reverse link, the slowly changing statistics or partial information of the channel can be fed back over the channel.  When full CSI is available at the transmitter, the transmitter can employ the eigenvector steering technique to approach the full capacity of the MIMO channel. The availability of CSI at the receiver is assumed by most multi-user MIMO methods.  The CSI is estimated by using training sequences. During the training phase, training sequences of Lt symbols long are transmitted from all the transmitting antennas, from which an estimate of the channel, ˆH, is calculated. Data sequences are then transmitted  and jointly detected.  Channel estimation methods  Coherent space-time decoding always requires knowledge of the MIMO channel as well as timing and frequency synchronization at the receiver. A timing offset introduces a pure delay convolutional channel; thus, timing synchronization can be lumped into channel estimation. Frequency synchronization requires separate implementation.  Preamble-based channel estimation is the most fundamental channel estimation method. A number of training or pilot symbols that are known to both the transmitter and the receiver are placed at the start of a frame. These symbols are known as the preamble. Assuming perfect frequency synchronization, for a frequency-ﬂat MIMO channel, in the input-output relationship  19.7 , the Nt × Nst matrix X is known at the receiver, and Y is also known at the receiver by measurement. Thus, the channel H can be estimated. In the same manner, channel estimation can be performed for frequency- or time-selective, single- and multi-carrier systems. LS and linear MMSE estimators can be obtained in a manner we have discussed in Chapter 9. Optimal training sequence design must consider the constraints of transmit power and the rate resources between training and information symbols.  The decision-directed channel estimation method begins with channel estimation using the preamble. Using the estimated channel, symbols are then decoded for a block within the coherent interval of the channel. These decoded symbols are used as the training sym- bols, and a reﬁned channel estimation is obtained. The decision-directed method is valid for slowly varying channels, at least for high SNR. The semiblind channel estimation approach can improve spectrum efﬁciency by exploiting the signal properties as well as the preamble [150].  For channel estimation, perfect synchronization is assumed. Frame and frequency syn- chronization for single-antenna OFDM has been studied in Chapter 9. For the ﬂat-fading MIMO channel, timing offset estimators have been proposed and their MSE performance studied in [156]. The CRB achieved by the ML estimator is inversely proportional to Nr, but does not depend on Nt [156].      794   cid:2   Multiple antennas: MIMO systems  19.2.6 CSI or partial CSI at the transmitter  Typical MIMO systems including the space-time coding and spatial multiplexing schemes are open-loop MIMO systems, where the transmit matrix X is designed independent of the channel conditions. Closed-loop MIMO systems make use of the adaptive nature of the channel, and the transmit matrix X is designed as a function of the channel conditions. In a coherent MIMO system, the receiver has an estimate of the forward link channel H for decoding purposes, and this CSI can be fed back to the transmitter. This leads to an improved error performance, better spectral efﬁciency, and simpliﬁed decoding [103]. The linear precoding technique is a closed-loop MIMO technique.  CSI at the transmitter can be obtained by either feedback from the receiver or channel estimation at the transmitter. Since channel estimation is always performed at the receiver, CSI feedback from the receiver is a simple solution.  Viability of CSI feedback  The viability of feedback is based on the reciprocity principle, which asserts that the for- ward and reverse channels are the same only if the used time, frequency, and antennas for both the channels are the same. Due to the duplexing operation, the two channels must have some difference in time, frequency, or antenna to reduce interference [103].   In TDD mode, the duplexing time delay, δt, between the forward time slot and the back- ward time slot must satisfy δt  cid:5  Tc so that the forward and reverse channels can be very close to each other.   In FDD mode, the reverse channel can be approximated by the forward channel only when the duplexing frequency difference, δf , between the forward and reverse channels satisﬁes δf  cid:5  Bc. This usually cannot be satisﬁed in FDD, since δf is typically 5% of the carrier frequency fc.   In antenna division duplex  ADD  mode, the same frequency and time are used on the forward and reverse channels, but a different antenna on each channel is used. The duplexing location difference, δd, is deﬁned as the separation between the forward antenna and the reverse antenna. Similarly, to ensure the forward and reverse channels to be close to each other, δd  cid:5  Dc. ADD is rarely used as a duplexing scheme, since there is not sufﬁcient isolation between the forward and reverse links and the requirement δd  cid:5  Dc may be difﬁcult to meet when Dc is as small as half the carrier wavelength, λc 2.  Thus, among the various reciprocity methods, only pure TDD mode is suitable for channel estimation at the transmitter.  Partial CSI at the transmitter  Partial CSI at the transmitter is the more common situation for channel-adaptive trans- mission systems. The partial CSI is obtained by feedback from the receiver. Partial CSI contains typically a few bits fed back from the receiver to the transmitter. The partial CSI      795   cid:2   19.3 Capacity in i.i.d. slow fading channels  can take the form of a mean vector or a covariance matrix of the channel, or other channel parameters that do not change fast.  In TDD mode, the transmitter and the receiver can obtain the channel statistics directly and no feedback is necessary, since the forward and reverse links share the same physical channel. For ﬁnite-rate CSI, the system design must be based on how the MIMO channel is best characterized by a ﬁnite number of bits and what criterion is used for optimization. The ﬁrst question requires a vector quantizer, while the second requires a criterion for the error probability, average capacity, or transmission rate [44].  Limited feedback is implemented by quantizing the channel vector  or the precoder  based on a predetermined codebook known at both the BS and the MS. Only the index is sent from the receiver to the transmitter. The channel matrix H is ﬁrst transformed into an Nt × Nr-dimensional complex vector by stacking the columns of H, and a VQ algo- rithm is then applied to quantize this high-dimensional vector. VQ has been introduced in Section 16.2.2, and has been described in detail in [31]. The LBG or generalized Lloyd algorithm is a popular VQ algorithm. The minimum codebook size for quantized precoding has been discussed in [83].  Structured codebooks based on QAM and PSK sequences are used for limited feed- back of beamforming weights in [113]. Such codebooks perform arbitrarily close to the random, numerically derived codebooks as M → ∞, in terms of average SNR, BER and outage probability. The codebooks achieve the full diversity order. The QAM codebooks are used for quantizing the MRC vector, and the PSK codebooks are used for quantizing the EGC vector since PSK symbols have equal envelope. Since there is simple bits-to- symbol mapping for QAM and PSK constellations, no codebook storage is required at either the transmitter or receiver. These codebooks can be searched with complexity orders of magnitude smaller than an exhaustive search.  Quantized precoding for MIMO-OFDM with limited feedback has been adopted as an option in IEEE 802.16e, 3GPP LTE, 3GPP2 UWB, and IEEE 802.11n. A broad overview of limited feedback wireless communications is given in [84].  19.3 Capacity in i.i.d. slow fading channels  It is well-known that a real or complex zero-mean Gaussian random variable  or vector  has the entropy-maximizing property [27, 74, 141]. For two random vectors x and y, mutual information is deﬁned by  I y, x  = H y  − H yx ,   cid:19    cid:20   where the conditional entropy  H xy  = −E For a linear complex model with channel H  log2 p xy    .  y = Hx + e,   19.14    19.15    19.16       796   cid:2   Multiple antennas: MIMO systems  where x has a zero mean and a covariance matrix P, and e is a ZMCSCG vector with n I. Thus, y has a zero mean and the covariance matrix HPHH + σ 2 covariance matrix σ 2 n I. The mutual information is derived as [74]  I y, xH  = log2 det 4  5  I + 1  σ 2 n  HPHH  .  For a given channel H, the Shannon capacity is given by the maximum mutual information and the transmitted vectors {xn}. Only when x is zero- between the received vectors mean Gaussian, the mutual information reaches its maximum. Thus, the channel capacity is given as [74, 141]  yn   cid:2    cid:2    cid:3    cid:3   C H  = B log2 det  I + 1  σ 2 n  HPHH  ,  where B is the bandwidth of the channel, and the total transmit power Ptot = tr P . For a fading channel, the channel H itself is a random variable, and thus the channel capacity C H  is also a random variable. The ergodic capacity is the average capacity EH[C H ]. When H is a random Gaussian matrix with i.i.d elements, the maximum ergodic capacity subject to a power constraint tr P  ≤ P is achieved at [141]  Thus, the average capacity is maximized when each antenna transmits an uncorrelated stream with the same average power. This result can be used when the transmitter does not have the CSI.  When full transmitter CSI and receiver CSI are available, the capacity reaches its  maximum. The capacity of the MIMO system in a nonfading channel is given by [40]  P = P Nt  I.  C = rH cid:26   i=1   cid:2    cid:3   log2  1 + Pi  σ 2 n  σ 2 i  ,   19.17    19.18    19.19    19.20   where rH is the rank of H, σi is the ith singular value of H, Pi is the power allocated to the ith eigenmode, and σ 2  n is the noise variance.  Assuming that all the transmit antennas are subject to a total power P, an equivalent  expression for the capacity is given by [141]   cid:5    cid:2   + γ Nt   cid:3  cid:6   log2  det  INr  HRxxHH  ,   19.21   xxH  where INr is the Nr × Nr identity matrix, γ = Es N0 is the mean SNR of each receiver branch, and Rxx = E Distribution of power among the different antennas is dependent on the amount of CSI at the transmitter. Assuming that the receiver has perfect CSI, the capacity increases linearly with min  Nt, Nr, Ns , Ns being the number of scatters [40]. When Ns is sufﬁciently large, the capacity increases linearly with min  Nr, Nt , whether the transmitter has the CSI or not.  is the correlation matrix of the transmit data.  C = max tr Rxx =Nt  cid:19    cid:20       797   cid:2   19.3 Capacity in i.i.d. slow fading channels  19.3.1 No CSI at the transmitter  When there is full CSI at the receiver but no CSI at the transmitter, the reasonable solution is to assign equal transmit power to all the transmitter antennas and use uncorrelated data streams [141]. In this case, Rxx in  19.21  is an identity matrix, and   cid:3  cid:6    cid:5    cid:2   cid:2   det  C = log2  = rH cid:26   log2  i=1  + γ Nt   cid:3   HHH  λi  .  INr 1 + γ Nt   19.22   Thus, the capacity of the MIMO channel is expressed as the sum of the capacities of rH SISO channels, each having power gain λi.  Case 1. SIMO: Nt = 1 and Nr > 1  In this case, λ = Nr, and  CSIMO = log2  1 + γ Nr  > CAWGN,   19.23   where CAWGN is the scalar channel capacity. The CSI at the transmitter does not affect the SIMO channel capacity.  Case 2. MISO: Nt > 1 and Nr = 1  In this case, λ = Nt, and  CMISO = log2  1 + γ   = CAWGN.   19.24   The reason for CSIMO > CMISO is that the transmitter in the MISO case cannot exploit the antenna array gain since it has no CSI.  Case 3. Nr > 1 and Nt is large For  cid:15 H cid:15 2 = 1, applying the strong law of large number leads to  Thus  HHH → NrINr ,  1 Nt  almost surely  a.s. .   19.25   C ≈ Nr log2 1 + γ   = NrCAWGN.   19.26   The capacity is Nr times the scalar channel capacity.      798   cid:2   Multiple antennas: MIMO systems  19.3.2 CSI known at the transmitter  When there is full CSI at both the transmitter and the receiver, the channel H, decomposed using SVD, is given by  19.9 , which for convenience is repeated below  Precoding can be applied to both the transmitter and the receiver, by pre-multiplying the signal vector to be transmitted, ˜x, by V at the transmitter,  and left-multiplying the received signal vector y by UH,  This is shown in Fig. 19.1.  In this way, the MIMO channel H is decomposed into rH parallel scalar channels  H = U cid:27 VH.  x = V˜x  ˜y = UHy.  rH cid:26  rH cid:26   i=1  i=1  Ei = Nt,     ˜yi =  Es Nt   cid:25  λi˜si + ˜ni,  i = 1, 2, . . . , rH,   cid:2    cid:3   C = max cid:24 rH i=1 Ei=Nt  log2  1 + γ Nt  Eiλi  subject to   cid:20    cid:19 xi2  where Ei = E Optimal power allocation can be derived through the water-ﬁlling technique [27, 99,  .  119, 141]. The optimal capacity is achieved when the energy is allocated as  ⎧⎨⎩ N0  σ 2 i  + Es Ei = 0,  Nt  Ei = μ,  < μ  ≥ μ  N0 σ 2 i N0 σ 2 i  where λi = σ 2 i , σi =  cid:27 i,i. For i.i.d. Rayleigh fading channels, H is usually of full rank, and thus rH = min{Nt, Nr}. The maximum capacity can be obtained by maximizing the sum of the individual scalar channel capacities subject to the total energy constraint:   19.27    19.28    19.29    19.30    19.31    19.32   Transmitter  Channel  Receiver  ~ x  V  x  H  UH  ~ y  n  y   cid:2 Figure 19.1  Precoder for MIMO when full CSI is known at both the transmitter and the receiver.      799   cid:2   19.3 Capacity in i.i.d. slow fading channels  power  μ  EE i  Nt s  σ i 2 N    0   cid:2 Figure 19.2  1  2  r H  channels  Illustration of the water-ﬁlling power-allocation technique.  or equivalently   cid:2   Ei =  μNt Es  − Nt γ λi   cid:3 +  ,   19.33    19.34    19.35   where μ is chosen so as to satisfy the power constraint.  This can be visualized through a water-ﬁlling illustration, as shown in Fig. 19.2. Treating the noise power as sediment of a container, the available energy for each channel corre- sponds to the height from the surface to the sediment. Note that water-ﬁlling can achieve the optimum power distribution for Gaussian input signals, but for discrete symbols such as PSK or QAM symbols, the problem of optimum power distribution has not yet been solved [73].  In practice, the optimal power allocation is estimated by iteration [103]. At each itera- tion, the constant μ is obtained from the power constraint, and then the power allocated to each mode is calculated. If the power allocated to a mode is negative, this mode is dropped, and the power allocated to the other modes is recalculated. This process continues until the power allocated to each mode is nonnegative.  At low SNR, the water-ﬁlling algorithm  19.33  reduces to allocating all the power to  the dominant eigenmode. Thus, the ergodic capacity is given by  When H = Hw, we get from  19.34  the following result [99]   cid:20    cid:19  log2  1 + γ λmax  C = E ≈ γ E [λmax] log2 e.  cid:17 √  cid:18 2 N + √  rH  C ≈ γ  rH N  log2 e,  where N = max{Nt, Nr}. At high SNR, the water-ﬁlling solution approaches an equal power allocation to all the nonzero eigenmodes. The capacity for an equal power allocation has been discussed in Section 19.3.1. At high SNR, the capacity can be approximated by [99]   cid:2    cid:3   ⎛⎝ N1 cid:26   N2−k cid:26   ⎞⎠ ,  C ≈ N1 log2  γ N1  + 1 ln 2   19.36  where N1 = min  Nt, Nr , N2 = max  Nt, Nr , and γE ≈ 0.57721566 is Euler’s constant.  p=1  k=1  − N1γE  1 p      800   cid:2   Multiple antennas: MIMO systems  19.3.3 Channel capacities for transmitter with versus without CSI  When the CSI is available at the transmitter, a higher capacity can be expected than the case when no CSI is available at the transmitter, since the transmitter with CSI can optimize its transmit covariance matrix for a given channel. For a system with Nr ≥ Nt, when SNR = P → ∞, the capacity for a transmitter with CSI approaches that for a transmitter without CSI, as the water-ﬁlling solution approaches equipower [12, 74]  σ 2 n  When Nt > Nr, CSI at the transmitter increases the capacity even at high SNR, with an  incremental capacity gain [147]  CCSI Cno-CSI   cid:15   → 1.  cid:2   Nt Nr   cid:3    cid:16   , 0  .  G = max  Nr log2   19.37    19.38    cid:7    cid:7    cid:8   cid:8  ,  This gain increases nearly linearly with Nr if Nt > Nr. This result is accurate for high SNR, but is optimistic at low SNR.  At low SNR, only the strongest channel eigenmode is used, yielding [147]  CCSI Cno-CSI  ≈ Nt  λmax tr  HHH  HHH   19.39  where λmax ·  takes the maximum eigenvalue of the matrix within, and tr ·  is the trace of a matrix. Thus, the CSI at the transmitter is more important for low SNR. For example, for an MISO system with Nt transmit antennas and one receive antenna, HHH is a scalar, and the right-hand side of  19.39  reduces to Nt, and we have for low SNR CCSI Cno-CSI For the i.i.d. Rayleigh fading channel, the capacity ratio at low SNR, in the limit of a large number of antennas  Nt, Nr → ∞ , is given by [147]  ≈ Nt.   cid:12       cid:13 2  CCSI Cno-CSI  →  1 +  Nt Nr  This ratio can be signiﬁcant when Nt > Nr.  > 1   Rayleigh fading .   19.40   Capacity gain due to correlation CSI  The capacity gain due to statistical CSI at the transmitter is also given in [147]. Consider the correlation CSI at the transmitter with a known transmit antenna correlation Rt and Rr = I. Such CSI suggests transmission along the eigenvectors of Rt, with a water-ﬁlling-type power allocation. For Nt ≤ Nr, if Rt is of full-rank, this capacity gain diminishes at high SNR. In this case, the incremental capacity gain at high SNR is given by [147]   cid:15    cid:16   G = max  rt log2  , 0  ,  Nt rt   19.41   where rt is the rank of Rt.      801   cid:2   19.4 Capacity in i.i.d. fast fading channels  For Nt > Nr, full-rank correlation CSI at the transmitter still increases the capacity. When Rt is rank-deﬁcient, the correlation CSI helps to increase the capacity at all SNRs for all antenna conﬁgurations. If the receive correlation Rr  cid:18 = I, both the receive and transmit antenna correlations generally reduce the channel ergodic capacity at high SNR, compared to an i.i.d. channel [147]. A stronger channel correlation, measured by the condition number of the correla- tion matrix, yields a larger precoding gain from the correlation CSI. However, a strong correlation usually reduces the channel capacity [147].  At low SNR, transmit correlation helps to increase capacity [147]. At low SNR,  Ccorr-CSI Cno-CSI  = Ntλmax  Rt   .  tr  Rt    19.42   For the rank-one correlated Rayleigh fading channel, this ratio equals Nt.  19.4 Capacity in i.i.d. fast fading channels  For i.i.d. fast fading channels, the capacity C H  is a random variable, which is a function of the random channel H. As a random variable, C H  can be characterized by its pdf. The outage capacity Cout and the ergodic capacity C are two measures of C H .  19.4.1 Outage and ergodic capacities  Here, we discuss the case of ﬂat Rayleigh fading. The case of correlated Rayleigh fading channels has been considered in [66].  Outage capacity  The capacity outage probability Pout is the probability that the conditional channel capacity C H  drops below a certain rate R  Pout = Pr C H  < R .   19.43   This is the cdf of the random variable C H . An exact expression of Pout is derived in [44, 153]. The pdf of C H  can be approximated by that of a Gaussian random variable, with mean μC and variance σ 2 C. The mean and variance of the pdf of C H  increase with SNR. If N1 = min  Nt, Nr  is sufﬁciently large, μC  cid:7  σ 2 C, and channel hardening occurs; that is, the capacity behaves more like a deterministic quantity, for large N1. Given an outage probability Pout, the outage rate can be correspondingly determined.      802   cid:2   Multiple antennas: MIMO systems  where  The ergodic capacity is deﬁned as  For i.i.d. Rayleigh fading channels, H can be modeled as a spatial white matrix Hw. The  ergodic capacity is given by [141]  Ergodic capacity   cid:20   C H   .   cid:19    cid:22   C = EH  cid:3    cid:2    cid:14  ∞ × N1−1 cid:26   0  k=0  log2  1 + γ Nt  γ  k!   k + N2 − N1  !  C =   cid:23 2  γ N2−N1e  cid:18   k   γ    LN2−N1  cid:17  −γ γ n+k e k + n k − l   cid:3   γ l l!  k γ   = 1 Ln   cid:2  eγ γ −n dk dγ k   −1 l  k!  = k cid:26   l=0  −γ dγ ,   19.45    19.44    19.46   is the Laguerre polynomial of order k, N1 = min  Nt, Nr , and N2 = max  Nt, Nr . The expression  19.45  can be numerically evaluated. Simulations show the follow-  ing [44]:   For a ﬁxed  Nt + Nr , the ergodic capacity is higher for a balanced Nt and Nr, that is, N1 = min  Nt, Nr  as large as possible.   For a ﬁxed N1 = min  Nt, Nr , it is always better to have Nr > Nt. The ﬁrst conclusion can be justiﬁed as N1 = rank H  corresponds to the number of inde- pendent parallel channels between the transmitter and the receiver. The second conclusion is reasonable, since for a ﬁxed Nt the total transmit power remains constant and more power can be collected by using more receive antennas.  Inserting  19.46  into  19.45 , we also have [11, 124]  N1 cid:26   μ=0  N1−1 cid:26   cid:3   l=0  Nt γ  ,  e  Nt γ   cid:2   Ep+1  C = log2 e   N1!   N2 − 1  !  p=0  × l+μ+N2−N1 cid:26   cid:3  cid:2   cid:3  cid:2   N2 − 1 N1 − 1 − l N2 − 1 N1 − 1 − l  where   cid:2   cid:2   Alμ = =   −1 l+μ  l + μ + N2 − N1  !  Alμ  l! μ!  −   cid:3    cid:2  N1 − μ  N2 − 1 N1 − 2 − l N2 − N1 + μ + 1   cid:3   cid:3  cid:2  N2 N1 − μ − N1 − l − 1 N2 − N1 + l + 1   cid:3   N2   cid:3  cid:2  N1 − 1 − μ N2 N1 − μ   19.47    19.48       803   cid:2   and  19.4 Capacity in i.i.d. fast fading channels   cid:14  ∞  1  Ek x  =  −xyy e  −kdy   19.49   is the exponential integral function of order k.  From  19.45  or  19.47 , some insights are obtained for the following special cases.  This reduces to the single-antenna system transmitting over the ﬂat Rayleigh fading channel. This has been treated in Section 14.6.1.  We have  C =  On the other hand, for Nr = 1, H becomes a row vector h =  cid:7    Nt − 1  !  −γ dγ .  log2  1  γ  0  h1, . . . , hNt   19.21 , we have  Case 1. Nt = Nr = 1  Case 2. Nt > Nr = 1  cid:3   cid:14  ∞   cid:2   1 + γ Nt Nt cid:26   i=1  γ Nt−1e  cid:13   hi2  .   cid:12  C h  = log2 1 + γ Nt Nt cid:26   hi2 → 1.  1 Nt  i=1  C ≈ log2 1 + γ   = CAWGN.  By the law of large numbers, for large Nt  Thus, for large Nt, we have   19.50    cid:8 T. From   19.51    19.52    19.53   That is, for large Nt, the effect of fading diminishes asymptotically.  Example 19.1: For Nr = 1, the capacity versus Nt, given by  19.50 , is plotted in Fig. 19.3, for different SNRs. It is seen that for Nt ≥ 4, the ergodic capacity C is sufﬁ- ciently close to CAWGN. Thus, for the single receive antenna case, four transmit antennas are sufﬁcient for achieving the ergodic capacity.  Case 3. Nr > Nt = 1  cid:14  ∞  We have  log2  1 + γ γ   γ Nr−1e In a way similar to the derivation of  19.53 , we have, for large Nr   Nr − 1  !  C =  1  0  −γ dγ .   19.54       804   cid:2   Multiple antennas: MIMO systems  0  2  4  6  8  10  12  14   cid:2 Figure 19.3  Ergodic capacity C for Nt > 1 and Nr = 1. The dotted lines correspond to the AWGN capacity.    z H   s   s t i b           C y t i c a p a c   c i d o g r E  7  6  5  4  3  2  1  0      z H   s   s t i b         C y t i c a p a c   c i d o g r E  12  10  8  6  4  2  0  0  20 dB  15 dB  10 dB  5 dB  0 dB  Nt  20 dB  15 dB  10 dB  5 dB 0 dB  Nr   cid:2 Figure 19.4  Ergodic capacity C for Nt = 1 and Nr > 1. The dotted lines correspond to the AWGN capacity.  2  4  6  8  10  12  14  C ≈ log2  1 + Nrγ   > CAWGN.   19.55   Thus, by using multiple receiver antennas, it is possible to achieve a channel capacity beyond CAWGN.  Example 19.2: For Nt = 1, the capacity versus Nr, given by  19.54 , is plotted in Fig. 19.4, for different SNRs.  From  19.21 , we have  Case 4. Nr  cid:7  Nt > 1  HHH → INt  1 Nr   19.56       805   cid:2   and thus  γ  > NtCAWGN.   19.57   19.4 Capacity in i.i.d. fast fading channels   cid:2    cid:3   C ≈ Nt log2  1 + Nr Nt  Case 5. Nt  cid:7  Nr > 1  HHH → INr  1 Nt  C ≈ Nr log2  1 + γ   = NrCAWGN.  From  19.21 , we have  and thus   19.58    19.59    19.60    19.61    19.62    19.63   Capacity is calculated from  19.47  by setting Nt = Nr = N1 = N2 = N −γ dγ . e  C =   cid:23 2  γ  L0 k γ    log2  Case 6. Nt = Nr > 1  cid:3  N−1 cid:26   cid:2   cid:22   1 + γ N  An approximation of the capacity for this case has been derived as [124]   cid:5  C ≈e1 γ log2 e E1  +  N − 1   2 log2  1 + cid:25   4γ + 1  − log2 e   4γ   cid:17  cid:25  4γ + 1 − 1   cid:18 2 − 2   cid:6   .  k=0   cid:18    cid:14  ∞  cid:2   0  1 ρ   cid:3   cid:17   Again for large N, applying the law of large numbers, we have  HHH → IN.  1 N  From  19.21 , we have  C ≈ N log2  1 + γ   = NCAWGN.  This shows that for large N, the ergodic capacity C increases linearly with N. This is the most powerful reason for deploying MIMO for high data rates.  Example 19.3: The ergodic capacity versus Nt = Nr = N, given by  19.60 , is plotted in Fig. 19.5, for different SNRs.  In [124], a tight upper bound for the ergodic capacity of spatially correlated double- scattering MIMO channels has also been obtained. A closed-form capacity formula for the  keyhole MIMO channel has also been derived as C  Nt, Nr  ≤ log2  1 + Nrγ  .      806   cid:2   Multiple antennas: MIMO systems    z H   s   s t i b           C y t i c a p a c   c i d o g r E  40  35  30  25  20  15  10  5  0  0  15 dB  10 dB   5 dB   0 dB   cid:2 Figure 19.5  Ergodic capacity C for N = Nt = Nr. The dotted lines correspond to the AWGN capacity.  2  4  6 Nt = Nr = N  8  10  At high SNR, approximated by [144]  the ergodic capacity of an i.i.d. ﬂat fading MIMO channel can be  Case 7. At High SNR   cid:3   cid:3   + N1 cid:26   i=1  +   cid:2   cid:2   γ Nt  γ Nt   cid:3    cid:20   cid:22   log2 λ  E   cid:19  N2 cid:26  ⎛⎝ N1 cid:26   N2−k cid:26   k=1  p=1  C ≈ N1 log2  = N1 log2  cid:2   C ≈ N1 log2  γ Nt  + 1 ln 2  − N1γE  1 p  E  log2 χ 2 2i  .  i=Nt−Nr+1   cid:23   ⎞⎠ .  Another approximation is given by [99, 101]  The capacity in the i.i.d. slow fading channels, Cslow, is always higher than the ergodic capacity in the fast fading case, Cfast, for given Nt, Nr, and SNR. As SNR increases, the gap decreases. At high SNR, the gap between Cslow, given by  19.36 , and Cfast, given by  19.64  is  Cslow − Cfast = N1 log2   cid:2    cid:3   Nt N1  ,  which is close to zero for Nr ≥ Nt, and is greater than zero for Nr < Nt.  Case 8. At Low SNR  When there is no CSI at the transmitter, equal power allocation is usually implemented at  the transmit antennas. By using the approximation log2 1 + x  ≈ x log2 e for small x, we  have   19.64    19.65    19.66       807   cid:2   19.4 Capacity in i.i.d. fast fading channels   cid:3  cid:6   1 + γ Nt  λi  E [λi] log2 e   cid:8  cid:20   tr  HHH  log2 e   cid:2    cid:7   log2   cid:5   E  i=1  C = N1 cid:26  ≈ N1 cid:26  N1 cid:26   cid:19  i=1 = γ Nt = Ntγ log2 e.  γ Nt  i=1  E  Thus, at low SNR, a capacity or power gain of Nr over a single antenna system is obtained, since a receiver beamforming can be applied. Without CSI at the transmitter, multiple transmit antennas do not improve the capacity at low SNR, since transmit diversity cannot be achieved.   19.67   19.4.2 Capacity bounds   cid:23   In the ﬂat-fading MIMO channel, fading is independent on each channel, thus the channel matrix H is most probably of full rank, and the eigenvalues are close to one another. From  19.20 , capacity increases linearly with the number of antenna ele- ments. Thus, existence of heavy multipath, with many multipath components of similar strength, is very beneﬁcial to the MIMO system. This is opposed to most conventional systems.   cid:4  cid:4 2 is chi-squared variate but normalized with  For a Rayleigh fading channel, = 1. When there is perfect CSI at the receiver but no CSI at the transmitter, E the capacity distribution has upper and lower bounds, for Nt ≥ Nr, and these are given Nt cid:26  by [40]   cid:4  cid:4 hij  cid:3  ≤ C ≤ Nt cid:26    cid:22  cid:4  cid:4 hij   cid:4  cid:4 2   19.68    cid:3    cid:2    cid:2   χ 2  ,  log2  log2  k=1  1 + γ Nt  2Nr  1 + γ Nt  χ 2 2k  k=Nt−Nr+1  where χ 2 2k is a chi-squared-distributed random variable with 2k degrees of freedom. The ergodic capacity is obtained by taking the mean over the χ 2 variables. Note that a χ 2- distributed random variable is related to a Gaussian random variable: given a Gaussian random variable X, then Y = X2 has a chi-squared distribution. When X has zero mean, it is central chi-squared distributed, otherwise it is noncentral chi-squared distributed. Rayleigh and Rice an distributions can be derived from central and noncentral chi-squared distributions.  The lower bound in  19.68  is improved in [101] as  C ≥ N1 cid:26   k=1  ⎛⎝1 + γ  log2  exp  Nt  ⎛⎝N2−k cid:26   p=1  ⎞⎠⎞⎠ .  − γE  1 p   19.69       808   cid:2   Multiple antennas: MIMO systems   cid:12    cid:12   NtNr−1 cid:26    cid:13  cid:13   1 + γ Nt  An improved lower bound at low SNR is derived as [101] − γE  C ≥ log2  exp  .  k=1   19.70  In the case when CSI is available at both the transmitter and the receiver, if Nt = Nr, the capacity gain by water-ﬁlling is small compared with the equal-power distribution case. When Nt > Nr, water-ﬁlling can achieve a better gain. Since the transmitter has CSI, it can perform beamforming and steer the beam toward the receive array, and this can increase the SNR and thus, the capacity. Thus, a larger Nt leads to a larger capacity.  1 k  Another pair of MIMO capacity bounds for the Rayleigh fading channel is given in [127]. Assuming that no CSI is available at the transmitter and Nt < Nr. H can be modeled as spatial white matrix Hw. Implementing QR decomposition [31], we have Hw = QR, where Q is a unitary matrix and R is an upper-triangular matrix. The elements of R above the main diagonal entries are statistically independent, each having a Gaussian distribution with zero mean and unit variance, while the magnitude squares of the diagonal elements, Rll2, are χ 2-distributed with 2  Nr − l + 1  degrees of freedom. After some manipulation, we have   cid:3  cid:6    cid:5    cid:2   det  Rll2  HHH  I + P Nt  cid:3   ≤ C ≤ Nt cid:26   log2  l=1   cid:3  cid:6   .  det  = log2   cid:5  ⎛⎝1 + p  Nt  RRH  I + P Nt   cid:2  ⎛⎝Rll2 + Nt cid:26   m=l+1  Rlm2  C = log2  cid:2   1 + p Nt  Nt cid:26   l=1  log2   19.71   ⎞⎠⎞⎠ .  19.72   Finally, the lower and upper bounds can be obtained as [127]  The capacity is lower-bounded by the sum of the capacities of Nt independent subchan- nels whose power gains are χ 2-distributed with degrees of freedom 2Nr, 2  Nr − 1 , . . ., 2  Nr − Nt + 1 , and is upper-bounded by the sum of the capacities of Nt independent sub- channels whose power gains are χ 2-distributed with degrees of freedom 2  Nr + Nt − 1 , 2  Nr + Nt − 3 , . . ., 2  Nr − Nt + 1 . The difference between the mean values of the upper and lower bounds is less than 1 bit s Hz per spatial dimension.  A dynamic model for CSI at the transmitter that takes into account channel temporal variation was constructed in [147]. The dynamic model covers smoothly from perfect CSI to statistical CSI at the transmitter. The capacity gains and the optimal input with dynamic CSI are analyzed asymptotically at low and high SNRs, and summarized in [148].  19.4.3 Ricean channels  The Ricean MIMO channel HRicean can be modeled as the sum of a constant HLOS and a variable Rayleigh component caused by scattering, HRayleigh [103]        HRicean =  e jφ0HLOS +  Kr Kr + 1  1  Kr + 1  HRayleigh,   19.73       809   cid:2   19.5 Space-time coding  Transmitter  α  Receiver  d θ Nr−     −2 θ   cid:2 Figure 19.6  Geometry of a MIMO channel with transmit and receive linear antenna arrays.  R  where Kr is the Ricean factor, φ0 is the phase shift of the signal due to propagation from a transmit antenna element to a receive antenna element, and HRayleigh = Hw. Given a MIMO system with a uniform linear array of Nt transmit antennas and a uniform linear array of Nr receive antennas, as shown in Fig. 19.6, when the distance R between the two arrays are very large, the HLOS matrix can be derived as  ⎡⎢⎢⎢⎢⎣  HLOS = drdT  t  =  1 −jθ e ...  e jθ  1 ...  −j Nr−1 θ e  −j Nr−2 θ e  ··· ··· ... ···  e j Nt−1 θ  ... e jθ 1  ⎤⎥⎥⎥⎥⎦ ,   19.74   where dr and dt are the transmit and receive steering vectors, and θ is the phase shift between two adjacent array elements. The second equality holds only when the transmit and receive antennas are almost parallel. It is easily seen that rank HLOS  = 1. When the angle α between the two arrays is very small and R  cid:7  d, θ is very small and we get HLOS with all the elements as unity, denoted H 1 .  For the Ricean MIMO channel with i.i.d. Rayleigh part, the exact ergodic mutual infor- mation with equal power allocation has been given in [67]. The existence of a Ricean component reduces the multipath richness. For a given SNR, the Ricean channel has a capacity lower than that of the Rayleigh fading channel, but is higher than that of the AWGN channel; it approximates the capacity of the Rayleigh fading channel as Kr → 0, and that of the AWGN channel as Kr → ∞. However, for a given transmit power, the Ricean channel introduces a higher SNR, since there are no obstructions. For Nt = Nr = 1, the capacity increases monotonically with Kr. For the multiple-antenna case, depending on the singular values of HLOS, there are instances where the capacity is either improved or degraded by the LOS component [88]. The upper bound on ergodic capacity for correlated and well separated dual-polarized antennas in a Ricean channel is given in [98, 99].  19.5 Space-time coding  CSI at the transmitter can be avoided by applying space-time coding. Space-time coding is specially designed for use with multiple transmit antennas. Space-time codes introduce temporal and spatial correlation into signals that are transmitted by different antennas      810   cid:2   Multiple antennas: MIMO systems  c1 k   H  y1 k   s k       Space-time  encoder  cNt k   yNr k   Receiver  s k    cid:2 Figure 19.7  Space-time coding system.  to provide diversity and coding gain without sacriﬁcing the bandwidth. Most space-time codes are designed for quasi-static channels, where the channel is constant over a block of Nst symbol times and the channel is unknown at the transmitter. A block of Nst symbols is encoded together.  Space-time coding is illustrated in Fig. 19.7. The information symbol s k  is encoded into Nt code symbols c1 k , c2 k , . . ., cNt k , each code symbol being transmitted simul- taneously from a different antenna. The Nt code symbols are encoded in such a way that both the coding gain and the diversity gain at the receiver are maximized.  Space-time coding increases redundancy over space and time, since each antenna trans- mits the same, but differently encoded signal. Space-time coding thus maximizes the diversity gain. Space-time coding techniques can be classiﬁed into space-time block codes  STBCs  and space-time trellis codes  STTCs , following the well-known convention in coding theory. For space-time diversity codes such as STTCs and STBCs, which extract full diversity order, the spatial rate rs ≤ 1. Typical STBCs are linear codes over the ﬁeld of complex numbers, which are sym- bols in two-dimensional modulation constellation points, while STTCs are not linear over  cid:7  complex numbers, since they are functions of the encoded bits. STTCs introduce memory and achieve a better performance than OSTBCs do, typically by about 2 dB. However, the , where M is the constellation size, decoding complexity of STTCs scales as O as opposed to O  min{Nt, Nr}  for OSTBCs.  Mmin{Nt,Nr} cid:8   19.5.1 Performance analysis of space-time codes  The MIMO model can be rewritten as  where x k  =  cid:7  where X = cid:19   x 0   y k  = Hx k  + n k ,   cid:8 T is the unnormalized signal vector. The channel coefﬁ-   19.75   x1 k , . . . , xNt k   cients are assumed to be constant during one encoded frame. For a group of Nst vectors, we have   cid:4  cid:4 x 1    cid:4  cid:4 ··· cid:4  cid:4 x  Nst − 1    cid:20  Y = HX + N,  19.76  is an Nt × Nst matrix, and Y and N are deﬁned in  a similar manner but have dimension Nr × Nst.      811   cid:2   19.5 Space-time coding  Slow fading MIMO channels For ML decoding and known CSI H at the receiver, the conditional pairwise error probability for two competing codewords X and ˜X is given by   cid:17   X → ˜X  Pr   cid:18    cid:4  cid:4 H  ⎞⎟⎟⎟⎠  ⎛⎜⎜⎜⎝  cid:28  cid:29  cid:29  cid:29  cid:30 888HX − H ˜X 8882  cid:12  888H  cid:18 8882  cid:17   B − ˜B  4σ 2 N  F   cid:13   Es 4N0  F  ,  = 1 2  erfc  = 1 2  erfc  where the last equality is obtained by normalizing the space-time codewords to  and inserting σ 2 n  = N0 T for complex-valued signals, T being the symbol period.  After some manipulation, the following bound is obtained [73, 138]   cid:17   B → ˜B  Pr  ,  B = X√ Es T  cid:18   ˜B =  cid:22   cid:17   cid:12  = EH r! ≤ 1 ⎡⎣ Es 2  ν=1  Pr  <  1 2  4N0  Es T  ˜X√  cid:18  cid:23   cid:4  cid:4 H  cid:13 Nr B → ˜B ⎤⎦−rNr 1  cid:13 1 r  cid:12  1 + λν r!  cid:18   cid:17   cid:18 H ∈ CNt×Nt,  B − ˜B  ν=1  Es 4N0  λν  ,  r = rank   cid:18   = rank  cid:17    cid:18  cid:17    cid:18  =  B − ˜B  B − ˜B  where  ,   19.79   and λν is a nonzero eigenvalue of  cid:18 . The last inequality is obtained by dropping the 1 in the denominator of the ﬁrst inequality, at large SNR.  The exponent rNr in  19.79  is known as the diversity gain, Gd. In order to achieve the maximum diversity gain, the minimum rank r of all pairwise differences should be maximized  Rank and Determinant Criteria   cid:17    cid:18   B − ˜B  .  Gd = Nr min cid:17  B,˜B   cid:18  rank   19.77    19.78    19.80    19.81    19.82       812   cid:2   The coding gain leads to a horizontal shift of the error rate curve, and is given by  Multiple antennas: MIMO systems   cid:12  Gc = min cid:17   cid:18  B,˜B   For full rank B − ˜B, i.e., r = Nt, we have  cid:18  cid:17  Gc = min cid:17  B,˜B  det   cid:13 1 r  r!  .  λν   cid:17   cid:18  cid:18 1 Nt  ν=1 λv = det r ν=1 B − ˜B   cid:17   .   cid:18   B − ˜B  , and   19.83    19.84   At high SNR, the pairwise error probability can be characterized by Gc and Gd. They  affect the BER in different ways on a log-log scale, as shown in Fig. 5.2.  From  19.82  and  19.84 , two criteria, namely the rank criterion and determinant cri- terion, can be obtained for space-time codeword design. The rank criterion optimizes the spatial diversity, while the determinant criterion optimizes the coding gain [138]. From the two criteria, space-time codes should be designed such that  cid:18  has full rank for any X  cid:18 = X cid:14  ∈ X , and such that the minimum value of det  cid:18   for any X  cid:18 = X cid:14  ∈ X is maximized. Note that the rank-determinant criterion is valid at high SNR.  At low SNR or when Nr is large, the pairwise error probability can be derived as a function of the trace of  cid:18  [19]. The determinant criterion turns the trace criterion, and maximizes the minimum trace of the error matrix  cid:18  over all pairs of codewords  Rank and Trace Criteria   cid:17  de = min B,˜BB cid:18 =˜B   cid:18  tr{ cid:18 }.  In i.i.d. fast Rayleigh fading channels, an upper bound of the average pairwise error probability is derived as [99, 138]  Fast fading MIMO channels   cid:17   X → ˜X  Pr   cid:18    cid:2   cid:3 −NrLX, ˜X  1 + 1 4N0  ≤ Nst−1!  cid:2   k=0  ≤  1 4N0   cid:3 −Nr   cid:15 x k  − ˜xk cid:15 2 LX, ˜X!  k=1   cid:15 x k  − ˜xk cid:15 −2Nr ,  where LX, ˜X is the effective length of the pair of codewords X and ˜X, and deﬁned as the size of the set of time instants, 1 ≤ k ≤ Nst, such that x k   cid:18 = ˜x k . The second inequality is obtained for high SNR.   19.85    19.86       813   cid:2   19.5 Space-time coding  Distance-Product Criterion  ; At high SNR, the distance-product criterion is derived from  19.86 :   Distance criterion. The minimum effective length of the code over all pairs of codewords  <  X, ˜X  is maximized  Lmin =  ;  < L{X, ˜X}.    Product criterion. The minimum product distance of the code over all pairs of codewords is maximized   19.87    19.88   ;  dp = min X, ˜XX cid:18 = ˜X   cid:15 x k  − ˜xk cid:15 2 .  X, ˜X  min   cid:4  cid:4 X cid:18 = ˜X < Lmin!  k=1  From  19.86 , it is seen that the use of multiple antennas at the transmitter does not change the achievable diversity gain, but it increases the coding gain [138].  19.5.2 Orthogonal space-time block codes  The OSTBC [5, 97, 139] provides the full diversity order and a simple decoding process, but no beamforming gain or coding gain. The OSTBC uses orthogonal design  achieving orthogonal H  to separate signals from different transmit antennas, and achieves full diver- sity by using a simple linear ML decoder. The MIMO ML decoding process is decoupled into several SIMO ML decoding processes. The OSTBC introduces considerable loss in bandwidth efﬁciency, for Nt > 2 with complex constellations. The OSTBC is a linear space-time code.  The signal bits are ﬁrst mapped onto symbols sl. The space-time block encoder collects   cid:8 T, and encodes them as a sequence of Nx  cid:8 T, k = 0, 1, . . . , Nx − 1. The code rate is  a block of Ns symbols, s =  cid:7  consecutive vectors x k  =  cid:7   Rc = Ns Nx. For the OSTBC, given two information blocks s and s cid:14  has full rank, achieving full diversity order. The most popular OSTBC is the Alamouti code that is designed for two transmit anten- nas, Nt = 2 [5]. Transmit diversity using the Alamouti code achieves full diversity order of 2Nr, and has been introduced in Section 5.3. The whole codeword is arranged in space and time as  , the error matrix  cid:18   s1, s2, . . . , sNs x1 k , . . . , xNt k   X2 = cid:19    cid:4  cid:4  x 2k + 1    cid:20  = 1√  x 2k    19.89  where s1 and s2 are the two symbols in the blocks of Ns = 2, and Nx = 2. So Rc = 1. The factor 1√  is used to normalize the average transmit power to Es T.  2  ,  In WCDMA, the Alamouti code is implemented in a different form  2  s1 −s ∗ ∗ 2 s s2 1   cid:5    cid:5    cid:6    cid:6   X2 = cid:19   x[2k]   cid:4  cid:4  x[2k + 1]   cid:20  = 1√  s1 −s ∗ 2  s2 ∗ s 1  .  2   19.90       814   cid:2   Multiple antennas: MIMO systems  Thus, the original symbols s1 and s2 are transmitted over the same antenna. The ﬁrst antenna is used in the same way as in the single antenna case, and adding a second antenna does not inﬂuence the transmission of the ﬁrst antenna.  The OSTBC [139] extends the Alamouti scheme to Nt > 2 based on orthogonality and unitarity principles, and it achieves the full diversity order of NtNr. For rate-1 real modula- tion, codes have been found for any number of transmit antennas, while a rate-1 complex modulation code only exists for Nt = 2. The series of rate-1 real modulation schemes can be extended to a series of rate-1 2 complex modulation schemes [139], and this doubles the delay. Thus, half-rate codes exist for an arbitrary number of transmit antennas [139]. Several orthogonal codes have been found with lower rates [139].   cid:8 T, the OSTBC matrix Xo s  is an Nt × Nx  s1, s2, . . . , sNs  XoXH o  = PINt,  n=1   19.91  sn2 is used to normalize the transmit power. In the generalized OSTBC, all the rows of Xo are also orthogonal but the norms are different. The generalized OSTBC enjoys full spatial diversity and very simple ML detection exactly as OSTBCs do [135]. According to  19.91 , the case of Nt = 2 is given by  19.89  by dropping the factor 1√ For Nt = 3 and 4, Xo takes the form  2  .  For a block of symbols s =  cid:7  where P = cid:24 Ns  matrix, which must satisfy  ⎡⎣ s1 −s ⎡⎢⎢⎣ s1 −s  s2 s3  s2 s3 0  ∗ ∗ 2 s 1 0  −s ∗ 0 0 −s ∗ 3 ∗ ∗ 3 s s 1 2 −s ∗ ∗ 0 0 −s ∗ ∗ 2 3 s ∗ ∗ 1 3 0 s s s3 −s2 2 1 s1  Xo =  Xo =  ⎤⎦  Nt = 3 , ⎤⎥⎥⎦  Nt = 4  .   19.92    19.93   Since Ns symbols are transmitted over Nx time slots, the code rate of OSTBCs is  ηOSTBC = Ns Nx   symbols per channel use .   19.94  Thus, for general complex constellations, we have ηOSTBC = 1 for Nt = 2, and ηOSTBC = 3 4 for Nt = 3 and 4. The OSTBC also exists for Nt > 4 but the code rate ηOSTBC = 1 2 [139]. For real constellations, ηOSTBC = 1 can be achieved for all Nt ≥ 2. The OSTBC can be decoded by linear ML decoding. ML decoding of s from Y can be transformed into Ns independent serial transmissions of its entry sn over a ﬂat channel with coefﬁcient  cid:15 H cid:15 2 σ 2 n [116]. The effective SNR at the decision point is given by  F and noise variance  cid:15 H cid:15 2 γ =  cid:15 H cid:15 2  F  F  γ .  Nt   19.95   Based on this and the modulation type, the BER performance of the OSTBC system can be calculated.      815   cid:2   19.5 Space-time coding  Some special STBCs  Quasi-orthogonal STBC  The quasi-orthogonal STBC  QO-STBC  trades diversity and decoding simplicity of the OSTBC for transmission rate enhancement [61]. The QO-STBC uses lower-dimensional OSTBCs as the building blocks of a higher-dimensional code. The major drawback of the QO-STBC is its low achievable diversity. Full diversity can be achieved by signal rotations which expand the constellation, thus leading to the rotated QO-STBC [122].  Modiﬁed OSTBC  A modiﬁed OSTBC for combating time selectivity has been proposed in [146]. It is sys- tematically constructible for any number of antennas. The modiﬁed OSTBC has exactly the same complexity as the OSTBC, but is less subject to the performance degradation caused by symbol-by-symbol channel variation.  Perfect STBC  The perfect  n × n  STBCs [100] are a class of linear dispersion space-time codes that have full-rate, full-diversity, nonvanishing constant minimum determinant, uniform aver- age transmitted energy per antenna, and good shaping for increasing spectral efﬁciency. These lead to optimality in terms of the diversity-multiplexing tradeoff, as well as excellent low SNR performance. These codes thus maximize the diversity and coding advantages for a MIMO system. Construction of perfect STBCs has been discussed for 2, 3, 4, and 6 antennas in [100]. In [34], perfect codes are constructed for any channel dimension, and the notion of perfect code is extended to the rectangular case.  Diversity embedded code  In transmitting over an unknown channel, a conservative strategy is to design for the worst channel for a given reliability  outage . Another strategy is an opportunistic one where information is embedded in such a manner as to deliver part of the information if the channel is bad, but more information when the channel is good. Diversity embed- ded codes are high-rate space-time codes that have a high-diversity code embedded within them. Diversity embedded codes [28, 29] allow multiple levels of reliabilities for different messages. This is desirable as wireless networks need to support applications with very different QoS requirements. Diversity embedded codes provide unequal error protection  UEP  with respect to the diversity metric suitable for fading channels [29]. They allow a form of communication where the high-rate code opportunistically takes advantage of good channel realizations while the embedded high-diversity code guarantees that at least part of the information is received reliably. In terms of unequal error protection, rate oppor- tunism, and packet delay optimization, diversity-embedded codes are shown to have the potential to outperform the traditional single-layer codes in moderate SNR regimes [29]. Diversity-embedded codes provide a means of provisioning queues with different priorities      816   cid:2   Multiple antennas: MIMO systems   reliabilities . A HARQ scheme that uses feedback to schedule information over these pri- oritized queues has been proposed in [29]. Code designs [29] and fundamental limits of performance for such codes have been developed. In [33], these ideas are summarized in a uniﬁed framework.  Capacity and error probability of the OSTBC   cid:2    cid:3   The capacity achieved by the OSTBC, COSTBC H , is given by [116]  COSTBC H  = ηOSTBC log2  1 + γ Nt   cid:15 H cid:15 2  F   bits per channel use .   19.96   The difference from the channel capacity C H , given in  19.20 , always satisﬁes [116]   cid:18 C = C H  − COSTBC H  ≥ 0.   19.97  The equality holds only when Nt = 2 and rank HHH  = 1. Thus, the OSTBC with Nr > 1 will almost surely cause a capacity loss [44, 116]. Only in the case of the Alamouti code with Nt = 2 and a single receive antenna  Nr = 1  can the channel capacity be achieved. The BER performance of OSTBCs in various MIMO channels has been studied. In [68], closed-form BER expressions of OSTBCs are derived for MPAM, MQAM, and MPSK constellations in a correlated Rayleigh MIMO channel, and the BER is also ana- lyzed for correlated shadowed Ricean MIMO channels. The upper bounds on the BERs of OSTBCs in a correlated Rayleigh channel are given in [63]. Closed-form BER expres- sions of OSTBCs are derived for correlated Nakagami-fading channels in [37]. In [157], closed-form expressions for symbol error probabilities of OSTBCs that use MPSK and MQAM modulations over Ricean–Nakagami channels, are given. The symbol error and outage probabilities for OSTBCs in correlated Ricean fading have been studied in [96]. Closed-form exact BER expressions of the generalized OSTBCs for MQAM and MPSK constellations in both spatially white and correlated Rayleigh MIMO channels are derived in [69].  Closed-form expressions for the error probability of OSTBCs as well as diversity gains of keyhole MIMO channels are derived in [48]. The maximum spatial diversity gain of a  cid:18 = Nr, and the achievable diversity gain keyhole MIMO channel is min Nt, Nr  when Nt is less than Nr but higher than Nr − 1 when Nt = Nr [43, 48, 115]. For a 2 × 2 OSTBC system in keyhole MIMO channels, closed-form expressions have been derived for the average SEP for several modulation schemes, outage probability, amount of fading and ergodic capacity in [106], and used to study the performance of the system.  Applications of the OSTBC  Although orthogonal codes do not provide coding gain, their decoding simply requires some linear combinations of the received symbols, and they provide full diversity degree. The use of the OSTBC generally reduces the capacity of the MIMO channel. Thus, the OSTBC should be a good choice for improving the performance of a single antenna system      817   cid:2   19.5 Space-time coding  by adding an extra transmission antenna, but it is argued that it is less attractive in terms of channel capacity for multiple antenna systems [74].  The Alamouti code has been adopted in WCDMA, CDMA2000, and IEEE 802.16d e. The Alamouti code is known as space-time transmit diversity  STTD  in WCDMA. In CDMA2000, the space-time spreading  STS  scheme is used, where Alamouti-coded symbols are separated by using two orthogonal codes instead of two time slots. The Alamouti code can be extended. When each of the two antennas has two polariza- tions, this leads to Nt = 4. This is possible for use in future wireless systems. In order to use the Alamouti code in case of 2N transmit antennas, one can group them into N two-antenna space-time encoders. Double-STTD  DSTTD , which consists of two parallel Alamouti STBC units and transmits with 4 transmit antennas, is adopted in 3GPP [1] and IEEE 802.11n. The Alamouti code scheme is generalized to the OSTBC that achieves a full diversity order with an arbitrary number of transmit antennas [139].  STBC, STBC design, and more discussion of multiple antenna techniques are given in  detail in [74, 99].  19.5.3 Space-time trellis codes  The STTC is an extension of the conventional trellis code to the MIMO system [138]. The technique extends Ungerbock’s TCM scheme to the spatial domain. Like the STBC, the STTC provides a full diversity order of NtNr, but it also provides a coding gain. The cod- ing gain increases with the number of states as well as the number of receive antennas. This leads to an improved error performance, since the error performance depends on both the diversity order and coding gain. The STTC provides a coding gain by increasing the minimum distance between the code sequences. Each STTC can be represented by a trellis. At time l, a vector d l  =  d1 l , . . . , dK l  T is fed into a linear shift register consisting of Lc blocks, each having K bits, Lc being the constraint length. The total length of the register is LcK bits. The major difference from the binary convolutional code is the way the register content is combined to generate the outputs for different antennas. The Viterbi algorithm can be used for decoding.  A simple STTC is illustrated in Fig. 19.8 for a vector modulation consisting of two QPSK symbols. Two transmit antennas are used, and the transmission achieves 2 bits s Hz. The four possible symbols {1, j,−1,−j} are, respectively, labeled as {0, 1, 2, 3}. The cor- responding space-time trellis has four incoming and four outgoing branches per state. As common practice, the space-time trellis is always initialized and ended at the zero state. At time t, a transition branch is selected according to the state of the encoder and the input bits. At time t, one symbol or two bits is transmitted at an antenna, depending on which state transition is made. The symbol transmitted at the other antenna is chosen according to the previous state, and the two antennas select their symbols for transmission based on the alternating state. A number of STTCs are described in the literature [44, 73, 138]. Design criteria for codes that are robust to the keyhole condition are given in [115]. It is reported that for the case of Nt ≤ Nr, the design criteria in the keyhole condition is the same as that under rich scattering, but for Nt > Nr the design criteria are indeed affected.      818   cid:2   Multiple antennas: MIMO systems  2  0  1  3  State  00  01  02  03  10  11  12  13  20  21  22  23  30  31  32  33   cid:2 Figure 19.8  Trellis of a four-state QPSK STTC for the delay diversity code.  Delay diversity codes  The simplest coherent space-time code is the delay diversity code. The delay diversity code is capable of achieving the maximum possible diversity gain for any Nt and for any signal   cid:8 T ∈ CNs×1, a simplest delay scheme of one  constellation. For a block s = cid:7   s1, s2, . . . , sNs  symbol per antenna corresponds to the space-time code matrix  ⎡⎢⎢⎢⎣ s1  0 ... 0  XDD =  ··· s2 ... 0  s2 s1 ... ···  sNs ··· ... s1  0 sNs ... s2  ··· ··· ... ···  0 0 ... sNs  ⎤⎥⎥⎥⎦ ∈ CNt× Ns+Nt−1 ,   19.98   where the zeros correspond to no data transmissions. The time span of the space-time code matrix is Nx = Ns + Nt − 1, leading to a code rate of η = Ns   Ns + Nt − 1  symbols per channel use. For any two different symbol blocks s  cid:18 = s cid:14  , the error matrix  cid:18  always has full rank Nt. Decoding can be based on the Viterbi algorithm. The delay diversity code can be treated as a special case of STTCs.  Viterbi decoding of STTCs  m n  = Nr cid:26   j=1      cid:4  cid:4  cid:4  cid:4  cid:4 yj n  − Nt cid:26   i=1  γ Nt   cid:4  cid:4  cid:4  cid:4  cid:4 2  The only difference between a space-time trellis and a trellis for the single-antenna case is that each branch of a space-time trellis has Nt labels instead of one. The Viterbi algorithm can be applied by choosing the branch metric as  hjixi n   .   19.99    cid:24 Nx  n=1 m n . At For Nx symbols, the Viterbi algorithm ﬁnds the shortest path that minimizes any time instant, the number of branches to be computed is Nstate × 2Rst, where the number of states Nstate = M and the transmission rate Rst = ηst log2 M for M-ary modulation, with ηst = Ns Nx as the code rate, when Ns symbols are transmitted in Nx time slots. The STTC requires a multidimensional Viterbi algorithm for decoding. The complexity for decoding increases exponentially with the number of states, which is a major obstacle for its application in practical systems. A number of STTCs have been compared by simu- lation in [73]. It is concluded that the coding gain of the STTC promised by the determinant      819   cid:2   19.6 Spatial multiplexing  criterion cannot be achieved in general. The coding gain is visible only for high diversity degrees [73].  19.5.4 Differential space-time coding  Motivated by differential modulation and detection described in Section 7.11, differen- tial space-time coding has also been proposed in [57, 60]. The space-time code matrix constructed must be unitary, and thus this differential space-time scheme is often called differential unitary space-time coding.  Differential space-time coded systems do not require the knowledge of the MIMO channel. By using ML decoding, the error performance of differential unitary space- time decoding is 3 dB inferior to its coherent counterpart. Design of the group of unitary space-time code matrices follows the same criteria as the design of the coherent space- time coding, that is, to maximize both the diversity and coding gains. Design of unitary space-time matrices can be implemented by using the Cayley transform [44].  A differential version of the Alamouti code is also available [140]. It retains most of the advantages of the Alamouti code, but does not require any channel knowledge for decoding. It achieves a higher transmission rate at a lower decoding complexity, when compared to the differential unitary space-time code for Nt = 2. The differential Alamouti code has been extended to the differential OSTBC in [41].  19.6 Spatial multiplexing  Unlike space-time coding, spatial multiplexing aims at maximizing the data rate. Spatial multiplexing is also referred to as information MIMO, while space-time coding is referred to as diversity MIMO. Spatial multiplexing multiplexes multiple spatial channels to send as many independent data as possible over different antennas for a given error rate. The anten- nas transmit parallel data streams termed layers, and spatial multiplexing is also called the layered space-time scheme. Spatial multiplexing with no coding can be treated as a space-time code with spatial rate rs = Nt and diversity order Nr. In general, in order to implement spatial multiplexing, it is required that Nr ≥ Nt. The MIMO receiver for spatial multiplexing has to deal with multistream interference.  Generally, the space-time coding technique can provide a better QoS due to antenna diversity; on the other hand, spatial multiplexing can provide a high bandwidth efﬁciency, but due to lack of antenna diversity the poor link-level error performance may decrease the throughput, especially at low SNR. One compromise between diversity and data rate is to use linear space-time precoding decoding with Nt greater than the number of data substreams [114]. In order to achieve spectral efﬁciency that is similar to that of spatial multiplexing techniques, space-time codes need to use higher modulation orders.  The linear dispersion code is a uniﬁed description of space-time coding and spatial multiplexing transmission [54]. The method enables a tradeoff between diversity and      820   cid:2   Multiple antennas: MIMO systems  multiplexing gain [56]. The linear dispersion code can be efﬁciently decoded using a sphere decoder, which has a polynomial decoding complexity for a wide range of SNR. Compared to the OSTBC, the linear dispersion code achieves a higher rate, but at the cost of signal constellation expansion and not guaranteeing the maximum diversity gain.  Recently, spatial modulation has been proposed as an alternative MIMO transmission scheme to space-time coding and spatial multiplexing [91]. In the spatial modulation scheme, a block of information bits is jointly encoded by symbol constellation and the transmit antenna number, and only one transmit antenna is active at any instant. At the receiver, MRC is used to retrieve the transmitted block of information bits. Spatial modu- lation increases the overall spectral efﬁciency by log2 Nt, as compared to a linear increase for the V-BLAST system. For the same spectral efﬁciency of MIMO-OFDM systems, spa- tial modulation results in a substantial reduction in receiver complexity as compared to V-BLAST and nearly the same receiver complexity as the Alamouti scheme. Spatial mod- ulation achieves better BER performance, as compared with the other two techniques [91].  19.6.1 Layered space-time receiver structures  The layered space-time schemes, known as the Bell Laboratories layered space-time  BLAST  schemes, were developed by Foschini and coworkers at Bell Labs. These are the ﬁrst practical schemes to achieve transmission rates above one symbol per channel use. Coded BLAST can approach the fundamental limit provided by the ergodic capacity of the MIMO channel. The BLAST schemes do not incur any mutual information loss relative to the capacity of the MIMO channel [40].  Horizontal BLAST  Horizontal encoding BLAST  H-BLAST  [39] is the simplest layered space-time receiver structure. The data stream is ﬁrst converted into Nt parallel substreams, each being encoded separately  temporal coding, interleaving, and symbol mapping , and then submitted to a different transmit antenna. The arrangement of the layers is shown in Fig. 19.9. The H-BLAST code matrix employs the same number of transmit antennas and layers Nt = Nl, and is given by  t   [  ]  1x   n  [  ] x   n  2  [  ] x   n  3   [  ] x   n  4   cid:2 Figure 19.9  H-BLAST  D-BLAST  VE-BLAST  The layers of the H-BLAST, D-BLAST and V-BLAST schemes, for Nt = 4. Sub-blocks of the same gray level constitute a substream.      821   cid:2   19.6 Spatial multiplexing  ⎡⎢⎢⎢⎣ x1 1   x2 1  ...  xNt 1   X =  ⎤⎥⎥⎥⎦ ,  ··· ··· ... ···  x1  Nx  x2  Nx   ...  Nx   xNt   19.100   where xl n , l = 1, 2, . . . , Nt, is the nth symbol of the lth layer. Each xl n  can be either an uncoded symbol or an entry of codeword. The code rate for the uncoded case is given as  ηH-BLAST = Nt   symbols per channel use .   19.101   Joint ML decoding can be applied on each column, comprising of Nt symbols. This leads to a complexity that is exponential in Nt. This complexity can be further decreased by using the DFE decoder for MIMO, called the nulling canceling decoder. The maximum diversity order is at most Nr. At the receiver side, these data streams are separated by keeping one data stream and suppressing all other data stream based on optimum combining. This requires Nr ≥ Nt to suppress all Nt − 1 interfering data streams. H-BLAST can at most achieve a diversity order of Nr. An array gain of Nr is also achievable.  The data streams are then detected in a serial order. The procedure is very similar to MUD: For different streams coming from different users, H-BLAST is actually an ordered serial  successive  interference cancellation  OSIC  receiver. To mitigate the error propaga- tion problem, the receiver should ﬁrst decode the streams in a descending order of SINR. In addition, the H-BLAST receiver has been shown to be equivalent to a ZF or MMSE generalized DFE, depending on the criterion used for interference reduction [45].  Diagonal BLAST  H-BLAST [39] does not provide diversity: The ﬁrst substream dominates the performance at high SNR. The diagonal BLAST  D-BLAST  scheme is a better solution. D-BLAST is similar to H-BLAST, the only difference being that the generated Nt substreams are subjected to a stream interleaver. Each substream is subdivided into many sub-blocks, and these sub-blocks are transmitted by different antennas according to a round-robin schedule by padding some antennas with zeros. Decoding is performed substream by substream: Each decoded sub-block is subtracted from the signals at the other antenna elements, and thus the quality of the residual signal is enhanced. The layers of D-BLAST are shown in Fig. 19.9  The space–time code matrix of D-BLAST is given by  ⎡⎢⎢⎢⎣ x1 1   X =  x2 1  x1 2   ··· x2 2  ...  xNl 1  ···  x1 Nt   xNl 2  ... x2 Nt   ···  xNl Nt   ⎤⎥⎥⎥⎦ ,   19.102   where xl n  is the nth symbol of the lth layer transmitted by the nth antenna, Nl is the number of layers, and the blank spaces are ﬁlled with zeros, representing no transmission. Each xl n  can be an uncoded symbol or a codeword entry. This space-time code matrix      822   cid:2   Multiple antennas: MIMO systems  resembles that of the delay diversity code matrix, instead of repeating the same symbol per delay diversity layer. From the space-time code matrix, D-BLAST transmits Nl layers carrying Nt symbols per layer over Nl + Nt − 1 time slots; thus the code rate of uncoded D-BLAST is given by  ηD−BLAST =  NtNl  Nl + Nt − 1   symbols per channel use .   19.103    cid:7    cid:8   This code rate is Nt times that of the delay diversity code. As Nl grows, the code rate approaches Nt symbols per channel use.  ML decoding of D-BLAST can collect a diversity order of NtNr, and the complexity is MNtNl for M-ary modulation. Linear ZF or MMSE equalization can be used to reduce O the complexity to cubic order, but at the expense of the error performance. A compromise is to use DFE. The ZF and MMSE versions of DFE, known as SIC and PIC, have been discussed for MUD of CDMA systems. The nulling canceling decoder requires Nr ≥ Nt; it is computationally attractive, but only collects the receiver diversity Nr. The diversity order of D-BLAST is between Nr and NtNr.  The data stream is detected in the order of the antenna elements, as in the H-BLAST case. Since each data stream sees all the transmit antennas, it alternatively experiences good or bad SINR, as the amount of the contribution of the other streams having already been subtracted varies. Thus, each stream experiences full diversity order of NtNr. An array gain of Nr can be achieved. D-BLAST achieves the lower bound of capacity given in  19.68  [7]. For Nt = Nr, the data streams alternatively see a channel with diversity order of 1, diversity order of 2, until diversity order of Nt. Note for a channel with diversity order k, its SNR has a pdf that is a chi-squared distribution with 2k degrees of freedom, χ 2 2k.  Vertical BLAST  In vertical encoding BLAST  V-BLAST  [46], the bitstream is ﬁrst temporally encoded, interleaved, and symbol mapped. The resulting Ns symbols are then demultiplexed into Nt substreams, and these symbols are then transmitted over the antennas. V-BLAST can split each information bit across more than one antenna, and thus can achieve a diversity order of more than Nr; but, it requires joint decoding of the substream and thus, can be very complex. An array gain of Nr can be achieved. The layer arrangement of V-BLAST is shown in Fig. 19.9.  Detection of V-BLAST is simpler than that in the diagonal architecture. Detection and estimation of the transmitted symbols is performed on a vector-by-vector basis, and the detection can be performed using interference cancellation with SNR reordering.  19.6.2 Space-time receivers  Popular space-time receivers are the conventional MUD receivers such as the ZF, MMSE, optimum ML, and SIC receivers. For all these receivers, the number of receive antennas      823   cid:2   19.6 Spatial multiplexing  Nr is assumed to be not less than the number of transmitted data streams Nt, Nr ≥ Nt; otherwise, the channel is ill-conditioned and the data may not be correctly decoded. The effects of the ratio Nt Nr on the spectral efﬁciency for the ZF and MMSE receivers are compared in [103] for the case of H-BLAST.  Linear ZF receiver  y = Hx + n.  The ZF receiver is also known as decorrelator or interference nulling receiver. Given MIMO transmission   19.104    19.106   A linear receiver is deﬁned by   19.105  The ZF receiver is obtained by setting AH = I in  19.105 , that is, by eliminating all the nondiagonal elements of AH  ˜y = Ay = AHx + An.  ˜y = H†y,  ˜y = x + H†n,  cid:3   cid:22   + NtE  γ Nt   cid:2   where H† is the Moore-Penrose pseudoinverse of H. This yields   19.107  which leads to noise enhancement. The ZF receiver has a diversity gain limited to Nr − Nt + 1 [99, 103]. The system is underdetermined if Nt > Nr. At high SNR, the maximum achievable rate for the ZF receiver can be derived as [144]  RZF ≈ N1 log2  log2 χ 2  2 Nr−Nt+1   .   19.108    cid:23   Comparing  19.108  to the MIMO channel capacity given by  19.64 , the ﬁrst term is the same, thus the ZF receiver can fully harness the spatial degrees of freedom of the MIMO channel. However, the ZF receiver introduces a performance degradation in view of the second term [144].  In the multiuser system, scheduling can be exploited to overcome the drawback of noise enhancement of the ZF receiver by avoiding a poor channel [4, 55]. In this case, the per- formance of the ZF receiver approaches that of the optimal receiver, when K, the number of users, is large [55]. As K approaches inﬁnity, the capacity achieved by the ZF receiver together with multiuser diversity scales identically compared to that of MIMO broadcast channels [4]. In [22], the sum-rate capacity of the multiuser MIMO system that employs spatial multiplexing and ZF receiver with a number of scheduling algorithms is given by closed-form expressions.  The MMSE receiver minimizes the joint effects of the off-diagonal elements of AH and of the ﬁltered noise An:   19.109   Linear MMSE receiver   cid:22    cid:23   min E   cid:15 Ay − x cid:15 2  F  .      824   cid:2   This gives  Multiple antennas: MIMO systems   cid:2    cid:3 −1  ˜y =  HHH + N0 Es  INt  HHy,   19.110   where Es is the average energy of each component of x  a transmitted symbol , and N0 is the noise variance.  Linear receivers have low complexity, but the performance is lower than that of the more complex ML receiver and BLAST. The ZF receiver decomposes the MIMO channel into Nt parallel channels with enhanced additive noise. At low SNR, the MMSE receiver approximates a matched ﬁlter and outperforms the ZF receiver, while at high SNR it is close to the ZF receiver. For the simple H-BLAST, both ZF and MMSE realize a diversity order of Nr − Nt + 1 [103]. Linear receivers have a complexity that is cubic with the dimensions of the H, O  , where N = max  Nr, Nt .   cid:8    cid:7   N3  SIC receiver   cid:7    cid:8   N3  N4   cid:7    cid:8   The SIC receiver successively decodes the symbol streams, and subtracts the decoded sym- bol streams layer by layer. It can be ZF or MMSE-based. The complexity is of the fourth order of the dimension of H, that is, O . The complexity of the SIC receiver can be by using the square-root algorithm proposed in [53]. SIC has a diversity reduced to O order of Nr − Nt + 1. It suffers from error propagation. In order to reduce the inﬂuence of error propagation, OSIC selects the stream with the  cid:7  highest SINR for peeling at the beginning of each stage. This is the method used in H- , plus BLAST [39]. The complexity of OSIC is the same as that of SIC, that is, O for a set of k elements. Due to the complexity of the ordering operation, which is O the ordering operation, the diversity order collected by the OSIC receiver is greater than Nr − Nt + 1, but still lower than Nr. The OSIC receiver reduces the block error by a factor of about ten compared to a purely linear receiver, or equivalently, decreases the required SNR by about 4 dB [46]. By using OSIC, the V-BLAST prototypes have exhibited spectral efﬁciencies above 20 bits s Hz [46].   cid:8    cid:8    cid:7   N4  k3  For spatial multiplexing with equal power allocation in i.i.d. fast Rayleigh fading MIMO channels, the ZF-SIC receiver achieves the ergodic MIMO capacity at asymptotically high SNR. At high SNR, the maximum achievable rate for the ZF-SIC receiver can be derived as[144]  RZF-SIC ≈ N1 log2  E  log2 χ 2  2 Nr−Nt+k   .   19.111    cid:22    cid:2    cid:3   γ Nt  + Nt cid:26   k=1   cid:23   Comparing  19.111  to the MIMO channel capacity given by  19.64 , it is seen that the achievable capacity of the ZF receiver is exactly equal to the channel capacity.  The MMSE-SIC receiver achieves the ergodic capacity of the MIMO channel for all SNRs [99, 144, 145]. Assuming that the SINR and the rate for stream k are SINRk and log2  1 + SINRk  respectively, for any given H, the sum rate is equal to the channel  capacity      825   cid:2   19.6 Spatial multiplexing  RMMSE−SIC = Nt cid:26   log2  1 + SINRk  = I y, xH ,   19.112  where I y, xH  is the mutual information of the channel H, given by  19.17 . Thus, the MMSE-SIC receiver is optimal.  k=1  The LLR-ordered SIC scheme is analyzed in multiuser multimode MIMO systems in which each user may choose between spatial multiplexing and beamforming [24]. The main idea is to detect and cancel the user signal in the order of LLR which provides a- posteriori information about the reliability of detection. LLR-ordered SIC provides 1–3 dB gain over the conventional SNR-ordered SIC in a multiuser MIMO system and the gain increases with the number of users [24]. However, for a channel that changes every L symbol intervals, the LLR-ordered SIC is about L times more complex than the SNR- ordered SIC.  Outage and error probability performance of the ordered ZF V-BLAST have been eval- uated for i.i.d. Rayleigh fading channels in [85, 86]. The results are applicable to uncoded D-BLAST and the MUD system with SIC.  ML receiver  Spatial multiplexing with equal power allocation achieves the ergodic capacity of i.i.d. fast Rayleigh fading channels. The joint encoding of the data streams to be transmitted from different antenna elements, in conjunction with ML detection, is the optimum solution that approximates the capacity of a MIMO system. This method is only useful for a small num- ber of antenna elements and a small modulation alphabet such as BPSK, and is complex for most practical cases. The ML receiver is optimal, and it achieves a diversity order of Nr. For a constellation of size M, ML decoding needs to search over MNt possible solutions.  Sphere decoding has been extended for near-ML decoding of MIMO systems [44, 94]. It can be used for decoding of space-time block and layered coded MIMO systems. The average decoding complexity is a polynomial function of Nt when Nr ≥ Nt. The ZF or nulling canceling solution can be used for calculating the initial radius for searching. Sphere decoding may fail to return the ML solution in polynomial time for very large Nt, or large constellation size, or low SNR, or Nr < Nt [44].  A number of improved versions of the sphere decoding algorithm, with improved error performance and or reduced complexity compared to that of the basic sphere decoding algorithm, are available [44, 79, 93, 94]. List sphere decoding can generate bit-level soft information for use in capacity-approaching iterative MIMO decoders, and has been applied to turbo-coded V-BLAST systems [59]. A soft-sphere decoding algorithm for demodulating a MIMO system with Nt = Nr = 4, which achieves a transmission rate of 38.8 Mbits s over a 5-MHz band, has been implemented for use in HSDPA [42].  K-best Schnorr-Euchner  KSE  decoding is a low complexity MIMO decoding scheme that approaches near-ML performance for MIMO detection [51]. KSE decoders have been implemented for 4× 4 16QAM MIMO detection in CMOS technology, achieving a decod- ing throughput of up to 53.3 Mbits s for the hard-output decoder, and more than 100 Mbits s for the soft-output decoder.      826   cid:2   Multiple antennas: MIMO systems  Remarks  Practical systems employ coded BLAST structure, which breaks the demodulation process into multiple, separate, low-complexity pieces. The H-BLAST architecture is a popular spatial multiplexing scheme for its simple implementation. All the above receivers can be used for H-BLAST.  In the H-BLAST structure, if the MMSE receiver is used, the Nt streams are ﬁrst sep- arated and then decoded independently. If the OSIC receiver is used, the streams are separated layer by layer and at each layer they are ordered, and then the MMSE algorithm and optimal decoding are applied. OSIC signiﬁcantly outperforms the MMSE receiver, but with a much higher complexity.  19.6.3 Spatial precoding  The BLAST structure, as a capacity-achieving technique, is a layered receiver-centric tech- nique for spatial multiplexing. Despite its satisfactory performance in laboratories [46], the BLAST structure is not practical in cellular environments, since it depends highly on high SNR for joint decoding of the various streams, or else catastrophic error propagation will occur. Another capacity-achieving approach to spatial multiplexing is the transmitter- centric spatial precoding technique, which allows multiple data stream to be transmitted to different users.  The spatial precoding technique is motivated by the concept known as writing on dirty paper [26]. The principle of dirty paper coding  DPC  states that the effect of the inter- ference can be canceled by proper coding at the transmitter and the resulting capacity is the same as that of a channel without interference, but with the same power constraint. Speciﬁcally, assume that a received signal is given by y = s + i + n,   19.113   where s is the transmitted signal, i is the interference known deterministically to the transmitter, and n is AWGN. The capacity of the system is the same as if there were no interference, no matter how strong the interference is and whether it is known to the receiver.  In case of spatial precoding for the multi-user MIMO channel, the CSI and the transmit- ted signals are known at the transmitter, thus the transmitter knows how a signal designed for one user interferes with the other users and compensates for this.  SVD precoding  From Section 19.2.4, parallel decomposition of a channel can be deﬁned by deﬁning a linear transformation on the channel input x and output y, known as transmit precoding and receiver shaping. Linear precoding serves as a beamformer with one or more beams with per-beam power allocation.      827   cid:2   19.6 Spatial multiplexing  1x   k~      x   k2   ~  x    k~      rH  σ  1  σ  2  σ  rH  ~ n1  ~ n2  ~ n rH  1y   k~      y   k2   ~  ~ y     k      rH   cid:2 Figure 19.10  The MIMO channel is decomposed into rH parallel scalar Gaussian channels through SVD.  In case of transmit precoding, as shown in Fig. 19.1, the antenna output is given by x = V˜x, where ˜x is the input vector, while at receiver shaping the channel output is given by ˜y = UHy, where y is the measurement at the receive antennas. Transmit precoding and receiver shaping transform the MIMO channel into rH parallel scalar channels with input ˜x and output ˜y  ˜y =  cid:27 ˜x + ˜n,   19.114  where ˜n = UHn. Since U is a unitary matrix, n and ˜n are identically distributed AWGN vectors. The rH parallel scalar channels are illustrated in Fig. 19.10.  From  19.114 , the MIMO channel is decomposed into rH parallel Gaussian channels. Each channel has a power of σ 2 i . The rH parallel channels do not interfere with one another. By sending independent data over each of the parallel channels, MIMO can sup- port a capacity increase by a factor RH. However, the capacity of each of the channels is dependent on its gain σi. if Nr ≥ Nt, and a relatively accurate channel matrix is fed back. SVD precoding does not introduce noise enhancement, as does the open-loop linear detectors. Nonetheless, the closed-loop spatial multiplex- ing can achieve high performance, but at much lower decoding complexity than the ML detector in open-loop spatial multiplexing.  The complexity for SVD of the channel H is at O  NrN2 t   cid:8    cid:7   Linear precoding  Linear precoding based on ZF beamforming achieves a large fraction of dirty paper coding capacity while exhibiting reduced complexity. A ZF beamforming strategy can achieve the same asymptotic sum capacity as that of dirty paper coding, as the number of users goes to inﬁnity. Based on the user grouping, the round-robin and proportional-fair scheduling schemes provide this asymptotic result [159].  More generally, linear precoding at the transmitter and postcoding at the receiver can be jointly designed by optimizing such criteria as the information capacity, BER, received SNR, or detection MSE [132]. The joint precoding postcoding method can always decom- pose the MIMO channel into a set of parallel subchannels. A linear precoder that optimizes the sum capacity is given in [133]. A transceiver architecture based on ZF beamforming      828   cid:2   Multiple antennas: MIMO systems  and linear receiver combining was proposed in [143]. The receiver combining and quan- tization for CSI feedback are jointly designed in order to maximize the expected SINR for each user. A design methodology for generating tree-structure codebooks tailored for arbitrary spatial correlation statistics is proposed in [143].  The linear precoder in fact decouples the input signal into orthogonal signal modes in the form of eigen-beams, each being allocated a power that is based on the CSI at the transmitter. In the case of perfect CSI, the precoded orthogonal spatial modes match the channel eigen-directions, and there is no interference between these signal streams. With partial CSI, precoder design must reduce the interference among signals sent on these beams. Exploiting the CSI available at the transmitter – perfect CSI, correlation CSI, mean CSI, and mean plus correlation CSI – precoder design can be based on such cri- teria as the ergodic capacity, error exponent, pairwise error probability, and detection MSE [147]. Optimal power allocation can be implemented by water-ﬁlling, based on the design criterion.  Precoding has been incorporated in IEEE 802.16e as a closed-loop MIMO scheme. An open-loop precoding proposal based on the reciprocity principle is also being considered by IEEE 802.11n. 3GPP uses a closed-loop beamforming technique, and precoding is being considered in its HSDPA. For precoding implementation, channel sounding may be used for channel estimation.  Precoding exploits the CSI at the transmitter to add an array gain. For perfect CSI at the transmitter, a diversity gain can also be delivered. In addition, precoding allows parallel channel transmissions, which reduce receiver complexity for high spatial rates. Linear space-time precoding schemes for downlink transmission in a MISO CDMA sys- tem have been treated in [110]. Spatial Tomlinson-Harashima precoding is a nonlinear pre-equalization technique for the MIMO system [38].  19.6.4 Other closed-loop MIMO schemes  Orthogonalized spatial multiplexing achieves orthogonality between transmitted symbols by applying phase rotation at the transmitter [70, 76]. It is a closed-loop MIMO system. By applying rotation operations to the transmitted symbols, orthogonalized spatial multi- plexing allows a simple symbol decodable ML decoder at the receiver. It requires only one phase feedback value for the transmitter. Orthogonalized spatial multiplexing exhibits a performance that is almost the same as that of the optimum closed-loop system, but signif- icantly reduces the processing complexity at both the transmitter and the receiver as well as the feedback overhead does.  The closed-loop V-BLAST scheme has been proposed for the MIMO-OFDM block- fading channel in [162]. It is the V-BLAST scheme with per-antenna-based power and rate feedback. The receiver jointly optimizes the power and rate assignments for all trans- mit antennas, and then returns them to the transmitter via a low-rate feedback channel. The power and rate optimization minimizes the total transmit power for support of an aggregate transmission rate during each fading block. The per-antenna-based power and rate control can be readily modiﬁed to combine with linear MIMO transmit precoding as an efﬁcient and capacity-approaching partial-CSI-feedback scheme. The closed-loop      829   cid:2   19.6 Spatial multiplexing  V-BLAST approaches closely the MIMO-OFDM channel capacity assuming perfect CSI at both the transmitter and the receiver [162].  TAS MRC  Another closed-loop MIMO scheme that combines single transmit antenna selection  TAS  and receiver MRC is referred to as the TAS MRC scheme. A single transmit antenna, which maximizes the total received signal power at the receiver, is selected for transmis- sion at any time, and all the other transmit antennas are inactive. This requires a low-rate feedback channel. The error performance of the TAS MRC scheme has been analyzed in [18, 20, 21, 112].  The average SNR gain of the TAS MRC in slow Rayleigh fading is quantiﬁed and com- pared with those of receiver MRC and STBCs in [20]. The TAS MRC scheme outperforms some more complex STBCs of the same spectral efﬁciency. The diversity order is NtNr at high SNR, and channel estimation errors based on pilot symbols have no impact on the diversity order [20]. In [18], the performance of the TAS MRC scheme is investigated for ﬂat Nakagami-m fading channels with arbitrary real-valued m. The outage probability, the asymptotic BER expressions for BPSK modulation, and the exact SER expressions for MPSK and MQAM have been derived. The asymptotic SER expressions reveal a diversity order of mNtNr.  The TAS system with MRC or EGC in Nakagami fading is analyzed in [112], and exact expressions for the SNR statistics as well as the average BER and SER of several modulation techniques are derived.  The performance of multiuser diversity in multiuser point-to-multipoint TAS MRC sys- tems over slow, ﬂat Rayleigh fading channels has been analyzed in [21]. With ideal CSI feedback, tight closed-form expressions of outage capacity and average SEP for the multiuser TAS MRC system have been derived. The outage capacity increases with the increase of mean of effective average SNR achieved from K users and decreases with the increase of variance of the effective SNR. In order to obtain a higher outage capacity, it is necessary to have Nr ≤ Nt. From the SEP performance, the multiuser TAS MRC system achieves a diversity order of approximately KNtNr − KNt + 1, or approximately KNtNr for large Nr. In the multiuser TAS MRC system, users can be equivalent to virtual transmit antennas, which is the source of the multiuser diversity.  19.6.5 Beamspace MIMO  Parasitic arrays such as switched parasitic arrays and the electronically steerable passive array radiator  ESPAR  antenna [136] are alternatives to antenna arrays, but they require only one RF branch. They provide a compact, cost-effective solution for beamforming [107, 136], diversity [117, 120], and MIMO STBC [154] applications. Hence, they make it possible to integrate multiple-antenna technology into small wireless devices.  Beamspace MIMO achieves capacity gain in rich-scattering environments by using a single RF front end and a parasitic array capable of changing its radiation pattern on each symbol period [65]. Diverse symbol streams are mapped onto orthogonal bases  radiation      830   cid:2   Multiple antennas: MIMO systems  patterns  deﬁned in the beamspace domain of the transmitting array far-ﬁeld region. The diverse symbol streams are then simultaneously transmitted towards different angles of departure. In rich-scattering environments, these symbol streams experience multipath fad- ing in a manner similar to the conventional MIMO transmission. Using a traditional MIMO receiver it is then feasible to retrieve the transmitted information at a rate that is equal to that of comparable conventional MIMO systems. Beamspace MIMO can be implemented in both STBC or spatial multiplexing mode [65].  19.7 Diversity, beamforming, versus spatial multiplexing  19.7.1 Diversity, beamforming, and spatial multiplexing gains  The MIMO technology can be used for spatial multiplexing, diversity and or beamform- ing, but all these goals at full scale cannot be achieved at the same time. These goals are contradictory to one another. When a MIMO system is used in a LOS environment, the achievable beamforming gain is NtNr, with Nt at the transmitter and Nr at the receiver; however, there is no diversity gain since there is no fading. In a heavy scattering environ- ment, the diversity order is NtNr, but the maximum beamforming gain is upper-limited by plementary techniques. The ﬁrst provides diversity with no array gain, while the second provides array gain with no diversity.   cid:8 2 [92]. In addition, the transmit diversity and beamforming are two com-   cid:7 √ Nt + √  Nr  The gain of spatial multiplexing can be deﬁned as [163]  Gsm = lim γ→∞  Cout γ   log2 γ  ,  where Cout is the outage capacity in bits s Hz.  Similarly, the diversity gain is deﬁned by  5.3 . The diversity gain Gd can be obtained  by approximating Pe or Pout at high SNR Pe ≈ γ −Gd  or Pout ≈ γ −Gd .  For the scalar slow fading Rayleigh channel, the diversity-multiplexing tradeoff for the PAM, QAM, and the channel itself are given by [144]  Scalar Rayleigh channel   cid:5    cid:6   Gd = 1 − 2Gsm, Gsm ∈ 1 0, 2 Gd = 1 − Gsm, Gsm ∈ [0, 1] Gd = 1 − Gsm, Gsm ∈ [0, 1]   PAM ,   QAM ,   channel .  Thus, the uncoded QAM scheme trades off diversity and multiplexing gains optimally.   19.115    19.116    19.117    19.118    19.119       831   cid:2   19.7 Diversity, beamforming, versus spatial multiplexing  For example,  19.119  can be derived as follows. For the slow Rayleigh channel, the   cid:18  outage probability at R = Cout = Gsm log2 γ is 1 + h2γ γ Gsm − 1   cid:17   cid:2    cid:17    cid:3   Pout = Pr log2 h2 < = Pr ≈ γ − 1−Gsm   γ   cid:18   < Gsm log2 γ   cid:7 h2 <  cid:21    cid:8  ≈  cid:21  for small  cid:21  in   19.120   at high SNR. The last approximation is obtained by using Pr Rayleigh fading. Thus, the diversity-multiplexing tradeoff  19.119  is obtained.  ISI channel  From a diversity perspective, ISI can be exploited by averaging the ﬂuctuations in the channel gains across the different signal paths. The optimal diversity-multiplexing tradeoff curve for the ISI channel is [50] ∗ G d  = L 1 − Gsm    ISI channel ,   19.121   where L is the number of taps corresponding to the ISI channel.  Analysis shows that the MLSE and linear DFE equalizers achieve the optimal diversity- multiplexing tradeoff without coding, but the ZF and MMSE equalizers do not [50]. However, if each transmission block is ended with a period of silence lasting the coherence time of the channel, both the ZF and MMSE equalizers achieve the optimal diversity- multiplexing tradeoff; thus, at high SNR, a simple precoding strategy can facilitate reliable communication with low complexity [50]. This avoids the use of the complex MLSE or linear DFE receiver. Besides, the OFDM system utilizes a preﬁx to obtain the optimal diversity-multiplexing tradeoff as the block length tends to inﬁnity, and it also requires an additional linear encoding architecture at the transmitter.  The diversity-multiplexing tradeoff for a V-BLAST OSIC receiver with ZF or MMSE processing at each stage is analyzed in [161]. It is veriﬁed that under general settings the optimal ordering rule for a V-BLAST SIC receiver will not improve its performance regarding diversity-multiplexing tradeoff in point-to-point channels. Particularly, when the rates of data streams are ﬁxed, the diversity order is not improved by user ordering.  Parallel and MISO Rayleigh channel  The optimal diversity-multiplexing tradeoff for the parallel channel with L diversity branches or the MISO channel with Nt = L can be derived as [144]  channel .  Gd = L  1 − Gsm  , Gsm ∈ [0, 1]   19.122   When transmitting the same QAM symbol over the L subchannels, the tradeoff is given by [144]  Gd = L  1 − LGsm  , Gsm ∈   QAM, repetition .   19.123    cid:5    cid:6   0,  1 L      832   cid:2   Multiple antennas: MIMO systems  MIMO Rayleigh channel  Based on the deﬁnitions of Gsm and Gd, a tradeoff between Gsm and Gd has been proposed in [163]. For a MIMO system with i.i.d. Rayleigh fading channels, if the space-time code matrix has a time span Nx ≥ Nt + Nr − 1, the optimal diversity achieved over all schemes for a given Gsm is given by [163]  Gd  Gsm  =  Nt − Gsm   Nr − Gsm    channel    19.124  for Gsm = 0, 1, . . . , min  Nt, Nr . The maximum diversity order NtNr and the maxi- mum rate min  Nt, Nr  cannot be achieved simultaneously [163]. Note that at Gsm,max = min  Nt, Nr , we have Gd,min = 0. This is unreasonable since no channel provides zero diversity. This problem arises from the deﬁnition of the metric Gsm, which has no physi- cal interpretation over ﬁnite SNR. At the other extreme, zero spatial multiplexing gain is achieved when Gd reaches it maximum NtNr.  The diversity-multiplexing tradeoff for many space-time coding spatial multiplexing structures with different receivers  e.g. ZF, MMSE, ML, SIC  are described in [99]. The diversity-multiplexing tradeoff and outage performance for Ricean MIMO channels is ana- lyzed in [126]. The diversity-multiplexing tradeoff characteristics of Rayleigh and Ricean channels are shown to be identical. In a high SNR regime, the outage probability versus SNR curve for a Ricean channel is a shifted version of that for the corresponding Rayleigh channel.  Diversity of the space-time-frequency selective fading channel  The diversity of a space-time-frequency selective fading channel is determined by the codeword dimensions and coherent parameters. Given a codeword duration T, the avail- able diversity can be up to T Tc; for a bandwidth B, the independent frequency diversity branches can be up to B Bc. For space diversity, the number of antennas Nt and Nr and their topology determine the diversity orders to be Nt Pt and Nr Pr, Pt and Pr being, respec- tively, the packing factors of the receive and transmit arrays, where the packing factor is the number of coherent distances occupied by at least one antenna. To achieve the maximum space diversity, the antenna arrays at both the receiver and the transmitter should be spaced Dc apart. The maximum available diversity is thus given by [103, 118]  Gd = T Tc  · B Bc  · Nt Pt  · Nr Pr  .   19.125   19.7.2 Error probabilities for MIMO systems  SIMO  For a SIMO channel, assuming a rich-scattering environment and the separation between the antennas at the receiver to be greater than the coherent distance Dc, the average probability of symbol error in Rayleigh fading for MRC is given by [103]      833   cid:2   19.7 Diversity, beamforming, versus spatial multiplexing   cid:12   Pe ≤ Ne  1 + γ d2 min 4   cid:12    cid:13 −Nr ≈ Ne  γ d2 min 4   cid:13 −Nr  ,   19.126   where Ne and dmin are the number of nearest neighbors and the minimum distance of sep- aration of the constellation, respectively. The approximation on the RHS is for high SNR γ . The method achieves full diversity gain Nr and array gain Nr, but may have limitations when it is deployed in MSs.  MISO with no CSI at the transmitter  For a MISO or MIMO channel, transmit antenna diversity can be used. When the channel is unknown to the transmitter, the Alamouti scheme [5] can be used for a two transmit antenna MISO or MIMO system; in this case, at high SNR, Pe is upper-bounded by [103]   cid:12    cid:13 −2  .  Pe ≤ Ne  γ d2 min 8   19.127   This achieves a full diversity order of 2. Space-time spreading is similar to the Alamouti scheme [58], and is used in CDMA2000. Due to no CSI available at the transmitter, array gain is not allowed at the transmitter. From  19.126 , if Nr = 2, for the same Pe, SNR for transmit diversity is twice, or 3 dB above, that for receive diversity, since the array gain of 2 is achieved in the receive diversity scheme.  MISO with CSI at the transmitter  For a MISO with known channel at the transmitter, the signal at the transmitter can be ﬁrst combined by a beamforming weight w so that the SNR is maximized at the receiver. The beamforming weight vector w has the same value as the weight vector for MRC diver- sity combining, and so this scheme is known as transmit-MRC [81]. In a rich-scattering environment, the average probability of symbol errors at high SNR is upper-bounded by  Pe ≤ Ne  γ d2 min 4   19.128   The MISO system using transmit-MRC has the same error performance as the SIMO system using receive-MRC.  MIMO with no CSI at the transmitter  For MIMO with no CSI at the transmitter, the Alamouti scheme can be used. For a two- transmit two-receive MIMO, the average symbol error probability at high SNR is upper- bounded by [103]  Pe ≤ Ne  γ d2 min 8   19.129    cid:12    cid:12    cid:13 −Nt  .   cid:13 −4  .      834   cid:2   Multiple antennas: MIMO systems  Table 19.1. Array gain and diversity order for multiple antenna systems.  Conﬁguration  CSI at transmitter Array gain Diversity order  SIMO MISO, Alamouti OSTBC MISO, transmit-MRC MIMO, Alamouti OSTBC MIMO, Dominant eigenmode  yes or no no yes no yes  Nr 1 Nt Nr E[λmax]  Nr Nt Nt NtNr NrNt  Thus, a full diversity order of NtNr = 4 is achieved. Only receive array gain of Nr = 2 is achieved. The Alamouti scheme can be used for a MIMO system with two transmit antennas and any Nr receive antennas; this leads to a diversity order of 2Nr and an array gain of Nr.  MIMO with CSI at the transmitter  When CSI is known at the transmitter, spatial diversity of the MIMO system can be extracted through the dominant-eigenmode transmission technique. The array gain in this case is given by E [λmax], where λmax = σ 2 max is the maximum eigenvalue of HHH. In the rich-scattering MIMO, [103]  max  Nt, Nr  ≤ λmax ≤ NtNr.   19.130   Thus, the array gain is greater than or equal to that for no CSI at the transmitter. Accordingly, by approximating the ML detection error in the Q-function by using the Chernoff bound, Q x  ≤ e −x2 2, which is a closed bound for large x, the SER at high SNR  cid:12  can be derived as [103]   cid:12    cid:13 −NtNr   cid:13 −NtNr ≤ Pe ≤ Ne  .   19.131   γ d2  min  4 min  Nt, Nr   Ne  γ d2 min 4  In summary, the diversity order and the array gain that are achievable for different multiple antenna systems are summarized in Table 19.1.  Example 19.4: A comparison of SER for the above schemes is given in Fig. 19.11, for different combinations of  Nt, Nr , where BPSK modulation is employed. From the ﬁg- ure, it is seen that the transmit-MRC and the receive-MRC achieve the same result for Nt = Nr, and that the transmit-MRC achieves a gain of 3 dB compared to the Alam- outi scheme for transmit diversity. For MIMO, although the Alamouti scheme and the dominant-eigenmode transmission achieve the same SER upper bound when Nt = Nr = 2, the dominant-eigenmode transmission achieves an array gain that is greater than or equal to that for the Alamouti scheme.      835   cid:2   19.7 Diversity, beamforming, versus spatial multiplexing     100  10−2  R E S  10−4  10−6  10−8    0  Nt = 1, Nr = 1, No diversity Nt = 1, Nr = 2, Receive−MRC Nt = 2, Nr = 1, Alamouti Nt = 2, Nr = 1, Transmit−MRC Nt = 2, Nr = 2, Alamouti Nt = 2, Nr = 2, Dominant Nt = 2, Nr = 3, Dominant   cid:2 Figure 19.11  2  4  6  8  10  12  SNR  dB   Comparison of various diversity schemes.  In addition, a MIMO system in a double-scattering channel with Ns effective scatters has been shown to achieve a diversity order of NtNsNr  max Nt, Ns, Nr  by using OSTBCs [125]. This implies that the full spatial order diversity of NtNr can be achieved when Ns ≥ max{Nt, Nr}.  MIMO with imperfect CSI at the transmitter  In [9], error performance has been analyzed for a MIMO ZF receiver with power adapta- tion at the transmitter in the presence of both imperfect CSI and feedback delay over an i.i.d. Rayleigh ﬂat-fading channel. The power allocation strategy is to maximize a weighted sum of the SNRs of all the substreams subject to a total transmit power constraint. Closed- form approximate upper bounds on BER are derived for MPSK and MQAM. These upper bounds are functions of the channel estimation error, the feedback delay, the constella- tion size, and the receive diversity order. The presence of channel estimation error and or feedback delay cause an error ﬂoor, as the noise variance approaches zero.  Under the assumptions of equal power allocation at the transmitter and Gaussian dis- tributed CCI, exact closed-form expressions for the BER of the SVD-based MIMO system using MPSK and MQAM with optimal detection in the presence of imperfect CSI at the transmitter are given in [8]. Similarly, imperfect CSI introduces CCI, and hence an error ﬂoor of BER.  19.7.3 MIMO beamforming  When multiple antennas are used to obtain beamforming or diversity gain instead of capac- ity gain, the same symbol, which is weighted by a complex scale factor, is sent over each transmit antenna, thereby leading to an input covariance matrix with unit rank. This is      836   cid:2   Multiple antennas: MIMO systems  known as MIMO beamforming or transmit beamforming. By transmitting in the direction of the eigenvector corresponding to the largest eigenvalue of the channel, the output SNR after MRC at the receiver is maximized. The full diversity gain provided by a MIMO channel can be achieved by transmit beamforming and receive combining. The beamforming strategy corresponds to transmitter precoding and receiver shaping with V = v and U = u, where u and v are the normalized transmit and receive weight vectors,  cid:15 u cid:15  =  cid:15 v cid:15  = 1. The received signal is given by [47]  y = uHHvx + uHn.   19.132    19.133   When H is known, u and v can be selected as the ﬁrst columns of U and V, which correspond to the maximum singular value of H, σ1 = σmax. In this case, the capacity corresponds to that of a scalar channel with channel power gain σ 2  max   cid:17    cid:18   C = B log2  1 + σ 2  maxP σ 2 n  .  In this case, the array gain of beamforming is between max  Mt, Mr  and MrMt, and the  diversity gain is MtMr [47].  The performance of BER and outage probability of transmit beamforming is analyzed in [49] for uncoded binary transmission over MIMO channels for ﬂat Rayleigh fading channels. In [90], closed-form expressions have been derived for the outage probability and ergodic capacity of transmit-beamforming MIMO MRC systems under Rayleigh fading.  Implementation of transmit beamforming requires CSI at the transmitter. One solution is quantized beamforming. Instead of sending the quantized CSI to the transmitter, the receiver quantizes the beamforming vector using a ﬁxed codebook available at both the transmitter and the receiver. The quantized index is then sent to the transmitter. Systematic codebook design has been performed for the uncorrelated Rayleigh fading channels in [83, 95] and for correlated Rayleigh fading channels in [108].  WCDMA contains explicit support for closed-loop transmit diversity. The CSI is esti- mated from the two common pilot channels  CPICHs , and is then fed back to the transmitter to control the beamforming weights at different transmitting antennas. Even a crude feedback signaling can be extremely useful in improving the downlink performance. When CSI is not available at the transmitter, the Alamouti or STBC scheme can be used to obtain full diversity gain and array gain.  19.8 MIMO for frequency- or time-selective fading channels  For frequency-selective fading MIMO channels, ISI occurs. Space-time channel equalizers can be used, but the complexity is too high. A more popular method is to use the OFDM technique to convert the frequency-selective fading MIMO channel into many ﬂat-fading channels. This leads to a parallel set of narrowband MIMO channels.  The capacity of a frequency-selective fading MIMO channel can be calculated by divid- ing the band into multiple narrow, frequency-ﬂat subchannels, and then summing the capacities of the frequency-ﬂat subchannels. This has been discussed in Section 14.6.3.      837   cid:2   19.8 MIMO for frequency- or time-selective fading channels  19.8.1 MIMO-SC  For a MIMO-SC  MIMO single-carrier  system with a frequency-selective but time-ﬂat fading channel, the channel input-output relationship is given by H l x k − l  + n k ,    L cid:26   cid:20  ∈ CNr×Nt. When L = 0, it reduces to the ﬂat MIMO   19.134  where L is the channel order, y k  ∈ CNr , x k  ∈ CNt, and w k  ∈ CNr is an AWGN vector,  and for each tap l, H l  =  cid:19   y k  =  Es Nt  l=0  hij l   model.  For a group of Nx vectors, we have  Deﬁne a group of Nt ×  Nx + L  matrices  X = [x 0  x 1  . . . x  Nx − 1 ] ∈ CNt×Nx.   19.135   X 0  =  cid:19  X 1  =  cid:19  X L  =  cid:19   ...   cid:20   ⎫⎪⎪⎪⎬⎪⎪⎪⎭ .  X, 0Nt×L 0Nt×1, X, 0Nt× L−1   0Nt×L, X   cid:20   cid:20     cid:20  =  L cid:26   l=0  Es Nt  Y = cid:19   The received space-time matrix is given by y 0  ···  y  Nx + L     Equation  19.137  can be rewritten as Y =  where N is obtained in the same manner as Y.  where  Heq = cid:19   H 0 ··· H L   Es Nt  HeqXeq + N,  cid:20   , Xeq =  ⎤⎥⎥⎥⎦ .  ⎡⎢⎢⎢⎣ X 0   X 1  ... X L    19.136    19.138    19.139   H l X l  + N,   19.137   Thus, the space-time code matrix Xeq can be viewed as being transmitted from Nt L + 1  antennas over a ﬂat fading channel. In rich-scattering environments, the maximum diver- sity achievable has been proved to be NtNr L + 1 , for a suitably designed space-time code matrix X [44]. The space-time code should be carefully designed to achieve the maximum diversity. The Alamouti scheme has been extended to the MIMO-SC case with Nt = 2 [78]. SC-FDE systems equipped with multiple receive antennas have been discussed in [25] using either the LMS or RLS algorithm. Two hybrid time-frequency DFE receivers for MIMO-SC systems, namely, the MIMO-DFE and the layered space-time  LST  DFE  LST- DFE , have been introduced in [64]. LST-DFE generally outperforms the MIMO-DFE.      838   cid:2   Multiple antennas: MIMO systems  A comparison with different MIMO-OFDM receivers shows that the MIMO-SC receivers are superior to the MIMO-OFDM receivers in terms of BER and throughput, but at a higher complexity [64].  MIMO-CDMA  MIMO can be overlaid on the spread-spectrum model, yielding MIMO-SS  MIMO spread spectrum  modulation or MIMO-CDMA. MIMO-SS for diversity transmission now becomes part of the WCDMA standard, where the BS supports Alamouti scheme-based transmit diversity [58]. A MIMO space-division, code-division multiple-access  MIMO- SCDMA  scheme, where each user is distinguished jointly by its spreading code signature and its unique spatial signature, has been investigated in [158].  For a single-user MIMO channel, coordination among all the transmitters or receivers is not a problem. In the multi-user channel, there is no coordination between users. In the uplink, the BS needs to separate the signals from different users. This can be done by using a rake receiver or by using MUD. In the downlink, the BS can synchronize the data transmission for all the users, and the MS can use MUD to overcome MAI. A cheaper solution is to mitigate MAI at the transmitter by beamforming, based on CSI available at the transmitter. The rake receiver is also generalized as the ST-rake or a 2-D rake for the SIMO system, and the transmit analog of the ST-rake is a ST pre-rake [35].  Popular space-time processing receivers include the ST-MMSE and ST-ML receivers. The ST-ML receiver mitigates CCI and ISI, with the best performance, but it has a high complexity and also requires the knowledge of the interfering channels. The ST-ML pro- vides a space diversity order of Nr and a multipath diversity order of L, and thus a total diversity order of NrL. The ST-MMSE receiver has a diversity order that is slightly less than NrL due to the loss arising from CCI.  MIMO-UWB  The UWB applications are typically in a rich-scattering indoor environment, which is espe- cially suitable for MIMO implementation. The GHz center frequency of the UWB signal enables a compact antenna array. Thus, the combination of UWB and MIMO provides a viable and inexpensive solution to very high data rate for future-generation wireless PANs. Space-time-coded pulsed UWB systems with TH-BPPM, TH-BPSK, and DS-BPSK are described in [129, 130]. Simulation results show that a DS space-time system can support the same number of users, but with a lower BER than that of the TH system [130]. The block diagram of a MIMO-CDMA or a multiuser MIMO-UWB system is illustrated in Fig. 19.12.  19.8.2 MIMO-OFDM  A frequency-selective MIMO channel has to use an ML or a suboptimal equalization, which has a complexity that grows exponentially with the product of the bandwidth      19.8 MIMO for frequency- or time-selective fading channels  839   cid:2   User 1 data   Channel encoder  ST  encoder  CDMA or UWB modulator  User K  data  Channel encoder  ST  encoder  CDMA or UWB modulator   a   1  2  Nt  1  Nr  Rake  receiver  Rake  receiver  Maximum -likelihood  decoder  Data for all users   b    cid:2 Figure 19.12 Block diagram of an Nt × Nr MIMO-CDMA or multiuser MIMO-UWB system.  a  Transmitter.  b   Receiver.  Bitstream  Channel encoder  ST  encoder  ST  decoder  Channel decoder  Bitstream  OFDM  modulator 1  OFDM  modulator 2  OFDM  modulator Nt  OFDM  demodulator 1  OFDM  demodulator 2  OFDM  demodulator Nr   a    b    cid:2 Figure 19.13  Block diagram of an Nt × Nr MIMO-OFDM system.  a  Transmitter.  b  Receiver.  and the delay spread. OFDM modulation can transform a frequency-selective fading channel of bandwidth B into N orthogonal ﬂat fading channels, which can be efﬁciently calculated using IFFT. MIMO-OFDM is based on the same idea: it converts a frequency- selective MIMO channel into multiple ﬂat fading MIMO channels using the OFDM technique. MIMO-OFDM is preferred over MIMO-SC in recent wireless communica- tion standards, such as HSPA+, 3GPP LTE, 3GPP2 UMB, IEEE 802.16e m, and IEEE 802.11n.  As in MC-CDMA, where CDMA is overlaid on OFDM, MIMO can also easily be overlaid on OFDM for diversity transmission or spatial multiplexing [15]. Unlike the sin- gle antenna OFDM case, the MIMO delay-spread channel, in general, provides both a higher diversity gain and a higher multiplexing gain than the MIMO ﬂat-fading channel does [15]. The bitstream is ﬁrst demultiplexed into a few substreams. Each of the sub- streams is then further OFDM-modulated and transmitted from an antenna. This procedure is reversed at the receiver. The resulting MIMO-OFDM system is shown in Fig. 19.13. A MIMO-OFDM receiver must perform time synchronization, frequency offset estimation and correction, and parameter estimation, by using a preamble consisting of one or more training sequences. These have been discussed in detail in [134].  MIMO-OFDM can be implemented as space-time coded OFDM  ST-OFDM , space-frequency coded OFDM  SF-OFDM , and space-time-frequency coded OFDM  STF-OFDM . ST-OFDM enables only a space diversity of NtNr, while SF-OFDM and      840   cid:2   Multiple antennas: MIMO systems  STF-OFDM can usually achieve the maximum diversity order of  L + 1 NtNr, L being the number of multipaths [44, 130]. For this reason, the SF-OFDM is the most popular coding technique in MIMO-OFDM. Note that, for SF-OFDM, the maximum achievable diversity is derived as Gd = min   L + 1 NtNr, NNr  =  L + 1 NtNr, where N is the number of OFDM subcarriers and typically N >  L + 1 Nt [130]. If space-time coding is employed in OFDM, the STBC is implemented over two OFDM symbols. Since the OFDM symbol duration is quite long, the channel should be constant over the subsequent OFDM symbols. For the space-frequency block code  SFBC  [14], adjacent subcarriers are coded over in an identical way as for the STBC. This assumes the adjacent subcarriers to have the same amplitude and phase, which is approximately true in practice. SFBC is used in 3GPP LTE.  For the full MIMO-OFDM system, the LDPC-based space-time coding signiﬁcantly outperforms the STTC in system performance and outperforms the turbo-code-based space-time coding scheme by exhibiting a lower receiver complexity and a more ﬂexible scalability [89]. The optimal power and subchannel allocation for MIMO-OFDMA and MIMO-MC-CDMA has been discussed in [82].  For the MIMO MB-OFDM UWB scheme, due to the band hopping, K OFDM sym- bols in each STF codeword are sent over different sub-bands. The maximum achievable diversity is K times the case without the band hopping [130] Gd = min  KLNtNr, KNNr  .   19.140   An improved V-BLAST receiver which takes the decision errors into account was intro- duced in [75], based on the MMSE criterion. An iterative detection and decoding scheme for coded, layered space-time architectures in MIMO-OFDM systems is presented in [75]. The iterative scheme combined with the improved V-BLAST performs almost as well as the near-optimal turbo-MIMO approach does, while providing tremendous savings in complexity.  Blind channel estimation algorithms have been proposed for estimating MIMO-OFDM channels using the cyclostationary statistics [16] or the constant-modulus property [80]. In [123], a subspace-based blind channel estimation technique that exploits virtual carriers with no or insufﬁcient cyclic preﬁx has been proposed for MIMO-OFDM. Training-based semiblind algorithms for MIMO-OFDM channel estimation can be found in [149, 151]. In [44], a hopping-pilot-based method and a kurtosis-based blind method are described for frequency-offset estimation of MIMO-OFDM.  AMC for MIMO-OFDM systems in a slow fading channel was investigated in [137]. Based on the EXIT analysis, an accurate packet error-rate prediction with channel esti- mation errors is given. The link adaptation algorithm is based on searching and selecting the best modulation and coding scheme. The performance of the proposed link adaptation algorithm was evaluated for the IEEE 802.11n MIMO-OFDM system, and good system throughput is achieved compared to the SNR-based algorithm.  Based on the IEEE 802.11a standard, an FPGA prototype for a full 4-stream MIMO- OFDM transceiver is implemented in [52]. It is capable of transmitting 216 Mbits s in 20-MHz bandwidth, which is four times the peak data rate of 54 Mbits s for IEEE 802.11a.      841   cid:2   19.9 Space-time processing  In [13], an efﬁcient MMSE iterative receiver for 4 × 4 MIMO-OFDM systems has been integrated in a FPGA testbench.  19.8.3 MIMO for time-selective channels  In case of time-varying MIMO channels, the space-time Doppler  STDO  code is designed to provide joint STDO diversity. Based on the time-frequency duality, the space-time code for the time-selective or doubly-selective MIMO channel can be obtained by map- ping from the corresponding space-time code designed for the frequency-selective MIMO channel [44].  In the deterministic basis expansion model, the doubly-selective fading channel is given  by [44]  hq l e jωqn,  l = 0, 1, . . . , L,   19.141   h n; l  = Q cid:26   cid:18   q=0   cid:17   2  q − Q  where ωq = 2π  N, during each block of N symbols. For the time-selective, frequency-ﬂat fading channel, L = 0. For the time-selective fading channel with Q+ 1 bases, if the channel coefﬁcients hq are complex Gaussian distributed, the maximum diversity order is Q + 1. For the doubly- selective channel with Gaussian distributed channel coefﬁcients hq l , the maximum diversity order is  L + 1  Q + 1 . STDO code design is described in detail in [44].  19.9 Space-time processing  We ﬁrst describe the space-time channel model. Assume that there is an Nt×Nr MIMO sys- tem. For transmit antenna i, the Nr-dimensional vector representing the complex baseband outputs of the receive array is  ri t  =  silhi t − lT  + ni t ,   cid:26   cid:8 T is the impulse response from the transmit antenna i   19.142   l  where sil is the complex-valued data symbol transmitted at time lT from the transmit  antenna i, hi t  =  cid:7   h1i, . . . , hNri  to the receive array, and ni t  is a vector representing the additive noise. hi t  is also called the spatial-temporal signature of the radio link from the transmitter i to the receive array.  For Nt transmitters  r t  = Nt cid:26    cid:26   where H t  =  cid:19  sl = cid:7   s1l, . . . , sNtl  H t − lT sl + n t ,  ri =  cid:20  i=1 h1 t h1 t ···hNt t    cid:8 T, and ni t  is the corresponding AWGN vector.   19.143  is the Nr × Nt channel impulse response matrix,  l      842   cid:2   Multiple antennas: MIMO systems  r1   t  r2   t     trN     twk * ,1     twk * ,2     twk * ,N  Σ  yk,n  t = nT  Output   cid:2 Figure 19.14  Architecture of a general linear space-time receiver.  19.9.1 Linear space-time processing model  Space-time processing combines the merits of both the spatial and temporal diversities. Temporal processing uses temporal taps for ISI mitigation, but it cannot provide a gain against CCI or thermal noise. Spatial processing uses spatial taps  antennas  for CCI mit- igation, and can also eliminate MAI and noise. Space-time processing can use the spatial diversity to suppress CCI signals with DoAs different from that of a desired user, and use temporal diversity to remove CCI with a DoA which is the same as that of the desired signal.  A general linear space-time processor has an architecture as shown in Fig. 19.14.  cid:7  The space-time processor ﬁrst processes the receive-antenna measurements r t  by convolving with linear ﬁlters represented by a vector impulse response of wk t  = wk1 t , . . . , wkNr  t  sion making is performed to obtain the original symbols. The sampled output for user k at time t = nT is given by   cid:8 T. The output of the combiner for user k, yk t , is sampled, and deci-  where r t  = cid:7   r1, r2, . . . , rNr  yk,n =   cid:14  ∞ −∞ wk τ  Hr nT − τ  dτ ,  cid:8 T, rj = Nt cid:26   si t  ∗ hji t  + nj t ,   19.145  where si t  is the complex data symbol transmitted at time t from antenna i, i = 1, 2, . . . , Nr, and nj t  is the additive noise on receive antenna j.  i=0   19.144   19.9.2 ZF and MMSE receivers  ZF receiver  To obtain the original symbols, yk,n should contain no CCI and ISI. This is the ZF criterion. Based on the ZF criterion, a relation between wk t  and H t  is established      843   cid:2    cid:14  ∞  19.9 Space-time processing  k  τ  H nT − τ  dτ =  −∞ wH  n = 0 n  cid:18 = 0  ,  ek, 0,   cid:15    19.146   where ek is a vector with the kth entry as 1 and all other entries as 0, and 0 is an all- zeros vector. By using the Fourier transform, the relation in the frequency domain can be established as a set of linear equations. This method can completely suppress ISI and CCI up to the limits imposed by the bandwidth, the number of antenna elements, and the number of interfering signals. The ZF receiver suffers from noise enhancement and adaptation problems [36].  MMSE receiver  user k is given by  Space-time processing can be based on the ST-MLSE or ST-MMSE method, depend- ing on its optimization criterion. For the TDMA system, ST-MMSE is more suitable for eliminating CCI, while ST-MLSE is well suited when ISI is more severe than CCI.   cid:22  cid:4  cid:4 yk,n − sk,n  The MMSE criterion is suitable for adaptation and evaluation at each step. The MSE for   cid:23   cid:4  cid:4 2 , where sk,n is the complex data symbol of user k at t = nT. Practical linear equalizers based on the transversal ﬁlter that follows ﬁxed antialiasing ﬁlters operate at a sampling rate that equals the symbol rate or a multiple of the symbol rate. For Nr antennas and user k, the equalizer with 2M + 1 taps per antenna element is given by  JMSE = E   19.147   Thus, wk is a  2M + 1 Nr-dimensional vector. For a sampling rate of 1  cid:18 , the linear space-time combiner output for user k is given by  where the channel output sample vector  ⎤⎥⎦ .  ⎡⎢⎣ wk,−M  ... wk,M  wk =  yk iT  = wH  ˜ri,  k  ⎡⎢⎣ r iT + M cid:18    r iT − M cid:18    ...  ⎤⎥⎦  ˜ri =  is a  2M + 1 Nr-dimensional vector. The MMSE solution for user k is given by [36] wk,MMSE = R  cid:22   where   cid:23   R = E  ˜ri˜rH  i  ,  v = E  −1v,   cid:19 ˜ris   cid:20   ∗ k,i  .   19.148    19.149    19.150    19.151    19.152       844   cid:2   Multiple antennas: MIMO systems  The MMSE is given by  At the MMSE, the SINR is maximized  JMMSE = 1 − vHR  −1v.  SINRmax = 1 − JMMSE  .  JMMSE  Ps ≤ e  − 1  JMMSE ,  A simple and useful Chernoff-type upper bound on the symbol error rate is given by  [36, 155]   19.153    19.154    19.155   where JMMSE, given by  19.153 , applies for unit data symbol variance.  19.10 Space-time processing for CDMA systems  Combination of the MUD technique with antenna arrays represents the direction for future- generation CDMA mobile communications. Space-time MUD  ST-MUD  algorithms for CDMA systems have been proposed in a number of papers [30, 32, 102, 111, 152]. A combination of an adaptive antenna array in the spatial domain and an adaptive interfer- ence canceller in the temporal domain are also given in [71, 72]. In [17], some algorithms that combine multiantenna beamforming and temporal processing have been reviewed. A practical space-time receiver for CDMA is the 2-D rake receiver that uses the training- based MMSE beamforming for each path, followed by a conventional rake receiver. Blind adaptive algorithms for ST-MUD have also been given in [102, 111, 152].  MMSE-based ST-MUD can signiﬁcantly increase the capacity of the CDMA system. The method is based on the MMSE between the data stream and the linear combiner out- put. Several MMSE-based ST-MUD algorithms for DS-CDMA are available [30, 32, 102]; these algorithms have been proved to be equivalent, and thus their theoretical BER per- formances are the same. Due to different implementation, their performances are actually different. Most remarkably, the ST-MUD algorithm proposed in [30, 32] does not require explicit estimation of channel and signaling information. This avoids any channel esti- mation error, and the method is thus more robust and provides a performance better than that provided by other ST-MUD algorithms in adaptive implementation. Adaptation of the ST-MUD algorithms is implemented by using training sequences.  19.10.1 Signal model  For a DS-CDMA system with K cochannel users, signals are spread by a random binary spreading sequence of length N and the short code is used, that is, Gp = N. There are Lk, k = 1, . . . , K, resolvable multipath components for the received signal of the kth user.      845   cid:2   19.10 Space-time processing for CDMA systems  The receiver at the BS is equipped with Nr antenna elements. The received signal at the pth element during a given symbol period can be modeled as  rp = SDpAb + np,   cid:17  cid:24    cid:18    19.156   where rp is a complex N-dimensional vector, S is an N-by-  spreading code -by-K steering matrix for all the users at the pth element, A = matrix, Dp is a diag  a1, . . . , aK   is a real K × K diagonal matrix of the amplitudes, b =  b1, . . . , bK  T is a complex K-dimensional vector of the input data symbols at a given instant t, and np is a zero-mean complex Gaussian noise vector with power spectral density σ 2.  K k=1 Lk  K k=1 Lk  The spreading code matrix S is given by   cid:17  cid:24    cid:18   S = cid:19   s1,1, . . . , s1,L1; s2,1, . . . , s2,L2; . . . , sK,1, . . . , sK,LK  .   19.157    cid:20   Each user is assigned a unique normalized spreading code  signature waveform  sk, an N- dimensional vector, k = 1, . . . , K, and sk,l, l = 1, . . . , Lk, is the delay of sk corresponding to the lth multipath. Thus, the Euclidean norm  for all k, l.   19.158   The normalized signature waveform of the kth user can be written as 0 ≤ t ≤ T,   19.159  where the symbol interval T = NTc, Tc is the chip interval, {ck n n = 0, 1, N − 1} is the spreading sequence for user k, uTc is a unit-height rectangular waveform of duration Tc. Mathematically,  sk t  = 1√ N   t − nTc  ,  ck n uTc  n=0  k t dt = 1. s2 Note that sk is the discrete-time vector version of sk t .  T  The steering matrix for all the users at the pth element, Dp, is given by  88 = 1,   cid:15 sk cid:15  =88sk,l N−1 cid:26   0   cid:14  ⎡⎢⎣ dp,1,1  ...  dp,1,L1  ⎛⎜⎝  ⎤⎥⎦ ,··· ,  ⎡⎢⎣ dp,K,1  ...  ⎤⎥⎦  ⎞⎟⎠ ,  dp,K,LK  Dp = blockdiag  where dp,k,l is the steering response of the kth user to the pth element via the lth multipath component.  For all the array elements, we have   cid:17    cid:18 H  where r =  rH 1 , . . . , rH Nr  r = ˜SDAb + n,  D = cid:19   is an NrN-dimensional vector,  ···  DH   DH   cid:20 H  DH 1  2  Nr   19.160    19.161    19.162    19.163       846   cid:2    cid:17  cid:24    cid:18   Multiple antennas: MIMO systems  is a  K k=1 Lk  Nr-by-K steering matrix,   cid:17  cid:24    cid:18  ˜S = INr×Nr K k=1 Lk   cid:18 H   cid:17   is an NrN-by-  nH 1  . . . nH Nr  is an NrN-dimensional vector.  ⊗ S = blockdiag S,··· , S Nr×Nr   19.164  Nr matrix, ⊗ being the Kronecker product, and n =  19.10.2 Space-time detection algorithms  The spreading codes have good mutual orthogonality and autocorrelation properties. By using these properties, we deﬁne a sufﬁcient statistic for further processing   cid:17   2 , . . . , xH Nr  where x = xH 1 , xH noise term, and  cid:17  cid:24    cid:18   is a  K k=1 Lk  Nr-by-  is a   cid:18    cid:17  cid:24   cid:18 H x = ˜STr = ˜ST˜SDAb + nx,  cid:8   cid:17  cid:24  ˜ST ˜S = blockdiag K k=1 Lk  STS,··· , STS  K k=1 Lk   cid:18    cid:7   Nr vector, nx = ˜STn is the corresponding   19.165   Nr×Nr   19.166   Nr matrix, which is close to a diagonal matrix.  The single-user space-time matched ﬁlter  ST-MF  is given as [102]   19.167  where ny = DHnx is the noise vector, y is a K vector, and M, a K-by-K matrix, is the space-time correlation matrix  DH p STSDp.   19.168   Under strict power control, M is close to a diagonal matrix, with positive diagonal elements [30]  Space-time matched ﬁlter  y = DHx = MAb + ny = Qyb + ny,  p=1  M = DH ˜ST ˜SD = Nr cid:26  ⎛⎝ Nr cid:26  L1 cid:26   cid:4  cid:4 2 ,··· ,  cid:4  cid:4 dp,1,l ⎡⎣aK ⎤⎦ b1,··· ,   cid:4  cid:4 2  P cid:26   p=1  l=1  ⎞⎠ ,  cid:4  cid:4 dp,K,l  cid:4  cid:4 2 ⎞⎠T ⎤⎦ bK   cid:4  cid:4 2  Nr cid:26   LK cid:26   p=1  l=1  LK cid:26    cid:4  cid:4 dp,K,l  p=1  l=1  M " diag  ⎛⎝⎡⎣a1  y "  P cid:26   L1 cid:26   p=1  l=1   cid:4  cid:4 dp,1,l  where the nondiagonal elements of M are quantities that are small relative to Thus,  88sk,l   19.169   882 = 1.  .   19.170   In this case, the ST-MF detector gives a satisfactory result.      847   cid:2   19.10 Space-time processing for CDMA systems  The output of the ST-MF detector can be demodulated according to the signal constella-  tion. For BPSK signals, the demodulated symbols are given by  ˆb = sgn  cid:19  y  ,   19.171   where sgn ·  is the signum function. MAI is not accounted for by the ST-MF detector.  ST-MUD algorithm I  where E[·] is the expectation operator. The standard Wiener solution is given as [102]  Both x in  19.165  and the ST-MF output y in  19.167  can be used as sufﬁcient statis- tics for MUD. When applying a linear transformation to y and then minimizing the MSE between the resulting vector and the data vector b, we have an MMSE-based ST-MUD that satisﬁes [102]  E  ;   cid:23 <  cid:22 88UHy − b 882  cid:18 −1 MA2M + σ 2M where UH is a K × K matrix. We denote it as ST-MUD-I. The MUD output is given as  U = arg min  cid:17  z = UHy = cid:7   UH = AM  UHMA  b + UHny.   cid:8   U  ,  ,  When x is used to synthesize the multiuser detector, the MMSE-based ST-MUD is deﬁned by [102]  Likewise, we have [102],  where VH is a K-by- identity matrix. We identify it as ST-MUD-II.  K k=1 Lk  Nr matrix and I is the  The MUD output for demodulating the data bits of the K users is given as   cid:18    cid:17  cid:24    19.176    cid:18   K k=1 Lk  Nr-by-  K k=1 Lk  Nr  ST-MUD algorithm II  .  E   cid:23 <  cid:22 88VHx − b ; 882  cid:18 −1  cid:17 ˜ST ˜SDA2DH + σ 2I  cid:17  cid:24   cid:17    cid:18   VH ˜ST˜SDA  b + VHnx.  ,  V = arg min  V   cid:17  cid:24   VH = ADH   cid:18   z = VHx =  ST-MUD algorithm III  ;   cid:22 88WHr − b  882   cid:23 <  .  W = arg min  E  W  If we use r to synthesize the multiuser detector, the MMSE-based ST-MUD is deﬁned by [30, 32]   19.172    19.173    19.174    19.175    19.177    19.178       848   cid:2   The standard Wiener solution is derived as  WH = E  Multiple antennas: MIMO systems  E  rrH   cid:20  cid:8 −1   cid:19   cid:20  cid:7   cid:19   cid:17 ˜SDA2DH ˜ST + σ 2I brH = ADH ˜ST  cid:17    cid:18   z = WHr =  WH ˜SDA  b + WHn.   cid:18 −1  ,   19.179    19.180   where WH is a K-by-PN matrix, and I is the PN-by-PN identity matrix. We denote this as ST-MUD-III.  The MUD output is given as  Architectures for ST-MUD-I II III  k = 1, . . . , K, lk = 1, . . . , Lk. The correlation  = cid:27   The architectures of the three ST-MUD algorithms are depicted in Fig. 19.15. Note that between rp and xp, there are a bank of matched ﬁlters, each having a time delay τk,lk, T 0 x t y t dt, or denotes the inner  product for vectors.  be expressed as  The MUD output z for ST-MUD-I II III, given by  19.174 ,  19.177 , and  19.180 , can   19.181  where Qz is the K × K transfer matrix between the transmitted data b and the detected data z, and nz is the noise.  z = Qzb + nz,  r1  rNr  r  x1  d1,1,1  d1,1,  L  K  d1,   ,1 K  d 1,   ,K  L K  dN   ,1,1 r  dN   ,1,   L r  K  dN   ,   ,1 r  K  dN L   ,   ,   r K  K  <  s  1,1  ,  >  <  s  , 1, L1  >  <  s   ,1K  ,  >  <  s   ,K  , LK  >  < s  1,1  ,  >  <  s 1,  L >  ,  1  < s   ,1K  ,  >  <  s    , K  LK  ,  >  xP  b1  bK  Σ  y  1  Σ  yK  y  U  V  W  z   cid:2 Figure 19.15  Architecture of the ST-MUD algorithms.      849   cid:2   19.10 Space-time processing for CDMA systems  Symbol estimate can be made from z  ˆb = dec z  = [dec  z1  ,··· , dec  zK  ]T ,  that is, ˆb contains the alphabet symbols closest to the entries of z. For BPSK signals, bit  estimate is given by a hard limiter   19.182    19.183   ˆb = sgn  cid:19  z  .  ST-MUD-III does not require any information on the signaling waves ˜S and the chan- nel D. ST-MUD-II does not require channel information but needs to know the signaling waves ˜S. ST-MUD-I requires both the signaling waves ˜S and the channel D. Although in CDMA systems, the signaling waveforms of the users, S, are usually available at the receiver, estimation of multipaths and multipath delays is still difﬁcult. ST-MUD-III pro- vides an attractive way to circumvent such limitations. Explicit estimation of the channel and the signaling waves is not necessary, since it is implicit in the training sequences or the properties of signals. Thus, ST-MUD-III has a BER performance better than that of ST- MUD-I II in practical implementation, since it avoids the computation load as well as the error arising from estimating the signaling waves and the channel. Numerical results have shown that ST-MUD-III provides a BER performance superior to that of ST-MUD-I II and ST-MF [32].  Equivalence of ST-MUD-I II III  The ST-MUD-I II III algorithms are equivalent to one another, for both asynchronous and synchronous CDMA systems, and there exist relations [30]  VH = UHDH, WH = VH ˜ST.   19.184    19.185    19.186    19.187   The equivalence of the three algorithms is given in [30]. The three ST-MUD algorithms differ in the size of the linear weight matrices.  Since the three ST-MUD algorithms are essentially equivalent, Qz and nz in  19.181  are  the same  Qz = WH ˜SDA = VH ˜ST ˜SDA = UHMA, nz = WHn = VH ˜STn = UHDHSTn.  Theoretical BER performance for ST-MUD-I II III  The theoretical BER performance is the same for ST-MUD-I II III. For BPSK signals, the γk , where γk is the received BER performance for user k can be approximated by Q  SNR of user k.  √  Conditioned on the users’ bits, the covariance of z is  cov z  = σ 2WHW = σ 2UH ˜ST ˜SU = σ 2VHMV,   19.188       850   cid:2   Multiple antennas: MIMO systems  which is equivalent to the covariance of the noise cov  nz , where σ 2 is the variance of n. The BER of user k is thus given by [30, 102]  ⎛⎝ cid:28  cid:29  cid:29  cid:30    cid:19   ⎞⎠ = Q  ⎛⎝  cid:4  cid:4 VHMAb  cid:21  cid:19    cid:4  cid:4   cid:20   k  ⎞⎠ ,  σ  VHMV  k,k   cid:20   z2 k  cov  nz   k,k  Pk = Q  where [·]k,k and [·]k denote the kth diagonal element of a square matrix and the kth element of a vector, respectively.  For the conventional ST-MF detector, V in  19.189  reduces to the identity matrix I;   19.189   thus, its BER performance is given by  The single-user lower bound  SULB  for the BER performance of any MUD algorithm is obtained by eliminating MAI, i.e., Qy and M are diagonal matrices. Thus   cid:12    cid:13   .   cid:13   σ   cid:25  MAbk Mk,k  cid:25   Ak  Mk,k σ  .  Pk = Q  cid:12   Pk = Q   19.190    19.191   The theoretical BER performances for ST-MF, MMSE-based ST-MUD, and SULB have been given, and simulated for correlated and uncorrelated models of the channel in [30, 102]. ST-MUD signiﬁcantly outperforms ST-MF for all the scenarios of multipath sep- aration. The theoretical BER performance of ST-MUD is much closer to the lower bound than that of ST-MF. The use of antenna arrays has proved to be an effective measure to improve the BER performance of ST-MF and ST-MUD. Antenna gain, diversity gain, and processing gain contribute to the BER performance of ST-MUD, making it signiﬁcantly superior to that of ST-MF under different scenarios of multipath azimuthal separations. Thus, ST-MUD signiﬁcantly enhances the system capacity.  19.10.3 Adaptive implementation of ST-MUD  The stochastic gradient method is usually applied in adaptive implementation of algo- rithms, since it is simple and fast. In the case of MUD, typical values for K, Lk, k = 1, . . . , K, P, and N in a cellular environment may result in a large number of coefﬁcients in UH, VH, and WH. ST-MUD can be obtained adaptively by using the MMSE criterion  19.175 ,  19.172  or  19.178    cid:22    cid:23   J = arg min  F J  = E   cid:15 z i  − b i  cid:15 2  ,  J  where J = U, V, and W,   19.192    19.193   z i  = JH i g i   is the K-by-1 combiner output at the ith iteration, and g i  corresponds to x, y, and r, respectively.      851   cid:2   19.10 Space-time processing for CDMA systems  The corresponding gradient-based algorithm is given as  J i + 1  = J i  − μ i + 1 g i [z i  − b i ]H,   19.194   where μ is the step size. The problem with the gradient-based method is the difﬁculty in selecting a suitable step size [31]. Usually, μ is selected as a small positive constant. Actually, when μ is too large, J may be erratic and the algorithm unstable. On the contrary, when μ is too small, convergence is so slow that the algorithm cannot satisfy the real-time requirement. A fast converging algorithm is usually obtained by forcing the a-posteriori error to be zero after each iteration, that is,  JH i + 1 g i  = b i .  From this, a variable step size is obtained as μ i + 1  =  1 cid:15 g i  cid:15 2 .  Thus, in the training mode, a normalized LMS algorithm is given as  J i + 1  = J i  − g i    cid:15 g i  cid:15 2 [z i  − b i ]H.  cid:20 H ,   cid:19   After training, algorithm  19.197  can be switched to decision-directed mode and  continue adapting J i    19.198   J i + 1  = J i  − g i   cid:15 g i  cid:15 2  cid:17  cid:24   b i  − ˆz i   cid:18   where ˆb i  = dec z i   contains the alphabet symbols closest to the entries of z i . If the step  size is suitably selected, both the algorithms given by  19.194  and  19.197  will converge to the vicinity of the MMSE solution. The sizes of UH, VH, and WH are K×K, K× Nr, and K×NrN, respectively; thus, the less the information required before applying an ST-MUD algorithm, the more the  cid:17  parameters required to be estimated, and accordingly the computational complexity is also increased. The computational as well as the storage complexity is O for ST-MUD-I, for ST-MUD-II, and O  KNrN  for ST-MUD-III. O   cid:24   K k=1 Lk   cid:18   KNr   cid:8    cid:7   K2  K k=1 Lk   19.195    19.196    19.197   Example 19.5: We conduct simulations of the adaptive implementations of the ST-MF and the three ST-MUD algorithms. A uniform linear array with an antenna spacing of half the carrier wavelength is selected. The lth resolvable multipath of the kth user impinge from direction θk,l, thus the channel coefﬁcient dp, k, l = qk, le jπ p−1  sin θk, l, where qk, l is the complex channel coefﬁcient of this component and is in the Rayleigh distribution.  For asynchronous CDMA systems, the multipaths of a user signal are assumed to have random phases. To simplify the simulation, we assume that the multipath delays are of integer chip intervals, and the multipath spread of any user signal is limited to at most one symbol interval; in this case, an equalizer is not necessary. For adaptive implementation, knowledge of some of the channel parameters, including the fading coefﬁcients, multipath      852   cid:2   Multiple antennas: MIMO systems  DoAs, spreading codes, and array response parameters may be not required, depending on the speciﬁc algorithm. We still need to assume knowledge of the timing of the users. Gold codes of length N = 63 are used as the PN sequences. Assume that the interference power from other cells is 30% of the in-cell interference power. Thus, the variance σ 2, the total power of the interference, is 0.3 K − 1 a2  N, where a0 is the nominal amplitude of a user signal. Let us assume the number of active users K = 20 and the number of elements Nr = 3. All the signals are spread BPSK signals. The signal of user k has Lk Rayleigh-fading paths, where Lk is a random integer from 1 to 7. The direction θk,l is randomly distributed in ◦ ◦ , 75  . For loose power control, different users are subject to the same total average  75 = 1. This cannot eliminate the instantaneous ﬂuctuation of the fading, E total power of any of the users. For strict power control, different users are assumed to have the same total power, is totally removed.  882 = 1, at any given instant, thus the near-far effect   cid:22  cid:24 Lk  88qk,l  88qk,l   cid:24 Lk  882  l=1  l=1   cid:23   0  Given a random run of the three adaptive ST-MUD algorithms, the evolutions of the rms error between the MUD outputs and the input data symbols for asynchronous, strict or loose power control, CDMA systems are similar. The adaptive ST-MUD algorithms are run in the training mode for 200 iterations, and are then switched to the decision-directed mode for 2000 iterations. The power of each user is randomly selected within the range of ±5 dB of the nominal power. As a typical illustration of the error evolutions, a random run of the algorithms for an asynchronous CDMA system using loose power control is given in Fig. 19.16.  For a random run, the amplitudes of the elements of matrices Qz and Qy are shown in Fig. 19.17. It is seen that Qz and Qy are close to diagonal matrices, where the diag- onal elements correspond to the eigenvalues of the matrices. The eigenvalue spread of Qz or Qy is a measure of the output MAI. From Fig. 19.17, we ﬁnd that the three ST- MUD algorithms achieve similar eigenvalue spreads, which are very close to unity. For     ST−MUD1 ST−MUD2 ST−MUD3  100  10−0.2  10−0.4  r o r r E  10−0.6  10−0.8      cid:2 Figure 19.16 Error performance of the ST-MUD algorithms for an asynchronous CDMA system using loose power  control: Nr = 3, K = 20, and a training sequence of 200 bits.  500  1000  1500  2000  Number of bits      19.10 Space-time processing for CDMA systems  Spread of the diagonals of Q: max{diag Q } min{diag Q }  Qz, ST-MUD1 Qz, ST-MUD2 Qz, ST-MUD3 Qy, ST-MF  Syn. strict Asyn. strict Syn. loose Asyn. loose  1.1077 1.0986 1.0837 1.0736  1.0881 1.0843 1.0743 1.0783  1.0765 1.0748 1.0624 1.0633  1.3206 1.2852 3.3630 2.7982  z  Q  0.5  1  0 20  853   cid:2   r o r r E   e g a r e v A  0.8  0.6  0.4  0.2  0    0  y  Q  5  10  0 20  20     0.8  r o r r E   e g a r e v A  0.6  0.4  0.2  0    0  10  K  10  K  0  0  a   10  K  0  0  b   10  K   cid:2 Figure 19.17 Eigenvalue spread of Qy and Qz for asynchronous CDMA system using loose strict power control,  from a random run: Nr = 3, K = 20, Lk = 1, . . . , 7, and a training sequence of 200 bits.  20     ST−MUD1 ST−MUD2 ST−MUD3  ST−MUD1 ST−MUD2 ST−MUD3  10  20  40  50  60  10  20  40  50  60  30 K   a  Loose  30 K   b  Strict   cid:2 Figure 19.18 Average error versus K for the ST-MUD algorithms: uniform DoAs, Nr = 3, Lk = 1, . . . , 7, and a  training sequence of 200 bits.  ST-MF, the eigenvalue spread is relatively large and it is sensitive to the method of power control.  Monte Carlo simulations are used to analyze the BER performance. The DoAs of all the ◦ sector. Given the number of users users’ multipaths are randomly distributed in the 150 K, the number of runs is taken as 2500 K, which is used to guarantee the resolution for BER calculation to be 1.0 × 10 −7. For a training sequence of 200 bits, the average error in the rms sense for estimating each bit versus K is shown in Fig. 19.18, and the average BER Pb versus K is shown Fig. 19.19.      ST−MF ST−MUD1 ST−MUD2 ST−MUD3 ST−MF Theo ST−MUD Theo SULB Theo  854   cid:2   10−2  R E B  10−4  10−6     Multiple antennas: MIMO systems     ST−MF ST−MUD1 ST−MUD2 ST−MUD3 ST−MF Theo ST−MUD Theo SULB Theo     10−2  R E B  10−4  10−6     10  20  40  50  60  10  20  40  50  60  30 K   a  Loose  30 K   b  Strict   cid:2 Figure 19.19 BER versus K for the ST-MF and ST-MUD algorithms: uniform random DoAs, Nr = 3, Lk = 1, . . . , 7,  and a training sequence of 200 bits.  From Fig. 19.18 it is seen that ST-MUD-I performs signiﬁcantly worse than ST-MUD-II and ST-MUD-III in terms of the estimation error, while the performance of ST-MUD-III is slightly better than that of ST-MUD-II. Accordingly, the BER performance of ST-MUD-I is signiﬁcantly worse than that of ST-MUD-II III, and ST-MUD-III has a BER performance better than that of the ST-MUD-II.  From Fig. 19.19, it is noted that the BER performance of ST-MF is better than that of ST-MUD-I, when loose power control is applied. This is because ST-MF does not need any training sequence, while the performance of the ST-MUD algorithms is dependent on the length of the training sequences. A training sequence of 200 bits is not sufﬁcient to estimate the algorithmic parameters for ST-MUD-I, but it is still sufﬁcient for ST-MUD-II III for loose strict power control, asynchronous CDMA systems. By increasing the length of the training sequence, the BER performance of ST-MUDs can be signiﬁcantly improved. For example, when the length of the training sequences is increased to 500 bits, the average error versus K is signiﬁcantly reduced for ST-MUD-I, but slightly reduced for ST-MUD- II III. The BER performance is shown in Fig. 19.20. In this case, the BER performance of ST-MUD-I is better than that of ST-MF. Now, if we limit the number of users to K = 20 and assume the interfering power to be 0.01x K − 1 a2  N, where x is variable between 661.587 and 2.634, then the SNR for each user changes between −3 and 21 dB. The simulation result for asynchronous CDMAs under loose and strict power controls are shown in Fig. 19.21. From the ﬁgure, we see that when x < 59, the performance of the ST-MUD algorithms are signiﬁcantly better than that of ST-MF.  0  Based on all the simulations, ST-MUD-III has a BER performance that is slightly bet- ter than that of ST-MUD-II, and both provide a BER performance much better than that of ST-MUD-I. ST-MUD-II III typically performs better than ST-MF. ST-MUD-I is more sensitive to the length of training sequences: With a short training sequence it may provide a BER performance worse than that of ST-MF. ST-MUD-I approximates the performance      855   cid:2   10−2  R E B  10−4  10−6     100  10−2  R E B  10−4  10−6     ST−MF ST−MUD1 ST−MUD2 ST−MUD3 ST−MF Theo ST−MUD Theo SULB Theo  19.11 MIMO in wireless standards  ST−MF ST−MUD1 ST−MUD2 ST−MUD3 ST−MF Theo ST−MUD Theo SULB Theo     10−2  R E B  10−4  10−6     10  20  40  50  60  10  20  40  50  60  30 K   a  Loose  30 K   b  Strict   cid:2 Figure 19.20 BER versus K for the ST-MF and ST-MUD algorithms: uniform random DoAs, Nr = 3, Lk = 1, . . . , 7,  and a training sequence of 500 bits.        ST −MF ST −MUD1 ST −MUD2 ST −MUD3 Theo ST −MF Theo ST −MUD SULB  ST−MF ST−MUD1 ST−MUD2 ST−MUD3 Theo ST −MF Theo ST −MUD SULB     100  10−2  R E B  10−4  10−6     0  5  15  20  0  5  15  20  10  SNR  dB    a  Loose  10  SNR  dB    b  Strict   cid:2 Figure 19.21 BER versus SNR for the ST-MF and ST-MUD algorithms: uniform random DoAs, Nr = 3, K = 20,  Lk = 1, . . . , 7, and a training sequence of 500 bits.  of ST-MUD-II III, only when the training sequence is sufﬁciently long and strict power control is applied. The theoretical BER for ST-MUD is very close to that of the single-user lower bound  SULB .  19.11 MIMO in wireless standards  MIMO promises high spectral efﬁciencies to wireless systems, and as high as 20 to 40 bit s Hz has been reported in [46]. In contrast, current cellular systems typically operate      856   cid:2   Multiple antennas: MIMO systems  with a spectral efﬁciency of 0.05 to 2 bits s Hz. MIMO has been implemented in WCDMA, CDMA2000, IEEE 802.16e and IEEE 802.11n. It will be the enabling technique for 4G.  In the WCDMA standard released in 1999, two-antenna open-loop and closed-loop transmit diversities have been speciﬁed at the BS. The open-loop transmit diversity is called STTD, which is based on the Alamouti code. The closed-loop transmit diversity makes use of feedback from the MS, and it is similar to transmit beamforming. The weights are so selected that the signals from the two antennas arrive coherently at the receiver. Thus, the scheme provides a two-fold diversity as well as 3 dB beamforming gain. 3GPP also extends the speciﬁcation of diversity MIMO to the case of more than two transmit antennas, and considers spatial multiplexing MIMO for WCDMA HSDPA in Release 6. Within 3GPP technology, in Release 7, 2 × 1 and 4 × 2 MIMO conﬁgurations are used, whereas in Release 8, 2×2 and 4×4 conﬁgurations are used. HSDPA supports two-antenna open-loop and closed-loop transmit diversities. The open-loop scheme typically provides no additional gain for HSPDA at low to moderate moving speeds for MSs, if proportional fairness scheduling is employed [109]. However, it does provide a capacity gain of 10% to 20%, when a round-robin scheduler is employed, or when the MSs are moving very fast so that the proportional fairness scheduler cannot track the fast fading radio channel [109]. The closed-loop scheme provides higher gain, but requires an associated dedicated transport channel. Many MIMO algorithms for HSDPA have been proposed within 3GPP [3]. These algorithms employ either a space-time coding or a linear precoding scheme.  In an environment of small angular spread, downlink beamforming yields an array gain which dominates diversity gain, and transmit beamforming improves the downlink capacity in WCDMA and HSDPA more signiﬁcantly than transmit diversity. A capacity gain of 150% can be achieved by forming a grid of ﬁxed beams for an antenna array of four elements [104]. Multiple scrambling codes can be introduced in each BS to assign each beam with a different code. This increases the code space. The beamforming introduces a capacity gain over single-antenna transmission for HSDPA of 2.5 for four antennas and 4.7 for eight antennas, respectively [105]. In addition, beamforming also helps to improve the uplink performance. However, transmit beamforming loses its good performance when the angle spread is large, since the beams cannot be accurately steered to users any more. On the other hand, receive beamforming is not necessarily the best solution for the uplink due to the lack of diversity gain [142]. For this reason, STBCs are adopted by 3GPP as an open-loop STTD method.  CDMA2000 provides two kinds of transmit diversity: STS and orthogonal transmit diversity  OTD . STS is an extension of the Alamouti code [5], obtained by multiplying two Walsh codes. STS achieves diversity at the symbol level. OTD transmits alternative bits over spatially separated or orthogonally polarized antennas, each antenna using a dif- ferent Walsh code. OTD achieves diversity in the Viterbi decoding path metrics, but has no symbol-level diversity. For a single antenna receiver, the Viterbi path metrics have large variations for slow speeds, but are less variable due to interleaving for high speeds. With OTD, interleaving across antennas allows for diversity in the path metrics even at low speeds. However, the diversity achieved with OTD is not as high as that achieved by STS [131]. The diversity gain achieved by OTD depends on the decoding process, but for STS this is not the case.      857   cid:2   Problems  IEEE 802.16e  WiMAX  supports transmit diversity using the Alamouti code, beam- forming at both the uplink and the downlink, and spatial multiplexing. IEEE 802.16e also deﬁnes an optional transmit diversity mode, known as the frequency-hopping diver- sity code, which uses two antennas to encode in the space and frequency domains. In the frequency-hopping diversity code, the ﬁrst antenna transmits the OFDM symbols with- out any encoding, as in a single-antenna transmission; the second antenna transmits the OFDM symbol by encoding over two consecutive subchannels using the Alamouti matrix. Unlike transmit diversity and transmit beamforming, spatial multiplexing is employed only under good SINR conditions. Both open-loop and closed-loop spatial multiplexing are deﬁned in IEEE 802.16e. Antenna selection for the closed-loop MIMO is also deﬁned in IEEE 802.16e. As an optional scheme for MIMO channel feedback mechanism in IEEE 802.16e, the BS can instruct the MS to perform channel sounding over allowed subcarri- ers. This method is most bandwidth intensive, but it provides the BS with the most accurate downlink channel estimate. The 4 × 4 MIMO conﬁguration is also supported. A 2 × 2 MIMO scheme is the baseline conﬁguration for LTE downlink. Conﬁgurations with 4 antennas are also being considered. Different MIMO modes are envisaged, the selec- tion between spatial multiplexing and transmit diversity depends on the channel condition. Precoding on the transmitter side is used to support spatial multiplexing. Transmit diversity is used when the selected number of streams  rank  is one. Cyclic delay diversity can be used in conjunction with spatial multiplexing in LTE. IEEE 802.11n deﬁnes transmitter beamforming, transmitter diversity using STBC, DSTTD, and spatial multiplexing. Several MIMO conﬁgurations, including 2 × 2, 2 × 3, 3× 3, and 4× 4 are deﬁned in IEEE 802.11n. IEEE 802.11n uses a 802.11a legacy packet, but its preamble also includes MIMO training sequences, followed by payload. MIMO is also being considered for IEEE 802.20 and IEEE 802.22. For example, the 625k-MC mode of IEEE 802.20 supports adaptive antenna arrays.  Problems  y = Hx + w,  cid:7    cid:8  = 0.  19.1 Consider the ﬂat fading MIMO channel  where y ∈ Rn, the channel H is of dimension n×m, and the input x is m-dimensional Gaus- sian N  x, Rx . Derive the MMSE  Wiener  estimate of ˆx. Prove the following orthogonality principle:   x − ˆx , y 19.2 Given a deterministic 3 × 4 MIMO channel  cov  ⎡⎣ 0.4 + 0.6j  −0.8 0.6j  H =  j 0.4 + 0.2j −0.7  2  1.5 − 0.6j −0.1 + 1.1j  −0.8 + j  0.9 0.6  ⎤⎦ ,      858   cid:2   Multiple antennas: MIMO systems   a  Find all the nonzero singular values of H and the eigenvalues of HHH.  b  Give an equivalent representation with parallel channels.  c  When the transmitter allocates all its power to the strongest channel, this is known as transmitter beamforming [103]. Find the beamforming weights V for the antennas.  d  Plot the channel capacity obtained by equal power allocation, beamforming, and optimal water-ﬁlling.  19.3 Assuming that the same channel deﬁned in Problem 19.2 is given and that no CSI is available at the transmitter, implement Monte Carlo simulations to estimate the achievable information capacity for:  a  BPSK input and  b  QPSK input.  19.4 For a MISO slow fading channel, prove that the transmit-diversity scheme radiates energy in an isotropic manner if, and only if, the signals transmitted are uncorrelated with the same power. Show that the Alamouti code scheme radiates energy isotropically. 19.5 Show that the capacity of an N1 × N2 MIMO channel with channel matrix H is the same as that of an N2 × N1 MIMO channel with channel matrix H∗ and the same power constraint.  19.6 Find the capacity and optimal power allocation for the MIMO channel deﬁned in Problem 19.2. Assume that P σ 2 n  = 20 dB and B = 1 Hz.  19.7 Consider a ﬂat fading channel [144]  y i  = h i x i  + n i ,  i = 0, 1, . . . ,  where h i  is Gaussian with zero mean and unit variance, x ∈ {−a, a}, and n i  is AWGN with zero mean and unit variance. The signal is encoded as xA =  a, 0 T for a and xB =  cid:2   cid:3   0, a T for −a. Detection of x is based on the block output +   cid:2    cid:3    cid:3    cid:2   =  y =  n i  n i + 1   .  y 0  y 1    a  Derive Pr y 0 xA , Pr y 1 xA , Pr y 0 xB , and Pr y 1 xB .  b  Verify the LLR function  h i x 0  h i + 1 x 1   cid:3    cid:2    cid:8  y  = ln  p yxA  p yxB   =  y2 0  − y2 1  a2  1 + a2  .   c  Give the ML detection rule.  Hint: xA when  cid:8  y  ≥ 0, and xB when  cid:8  y  < 0.   d  Derive the error probability Pe of the ML detection. 19.8 Find the outage capacity for a 3× 3 MIMO channel at 5% outage for P σ 2 and B = 1 MHz. 19.9 Find the diversity orders of the following MIMO systems over full scattering chan- nels with quasi-static fading:  a  Nt = 2, Nr = 1, number of delays L = 2, Alamouti scheme with ML decoding.  b  Nt = 3, Nr = 2, L = 2, VBLAST scheme with optimal decoding.  = 10 dB  n      859   cid:2   References   cid:5    cid:6   1 r  r 1  19.10 For a 2 × Nr MIMO system over an ergodic Rayleigh fading channel, the transmit correlation matrix is Rt = . Plot the ergodic channel capacity for r = 0, 0.5, 0.75, 0.9 for the following two cases when there is no CSI at the transmitter:  a  Nr = 2, the receive correlation Rr = Rt.  b  Nr = 1. 19.11 Derive the ergodic channel capacity for the keyhole channel as a function of Nt = Nr = n. Plot the relation for different SNRs. 19.12 Given the linear dispersion code  ⎡⎢⎢⎣ x1  x3 −x −x ∗ ∗ x8 −x7 −x6 2 4 −x ∗ ∗ x 7 5  x2 ∗ x 1 −x  ∗ 8  x4 ∗ x 3 x5 ∗ x 6  ⎤⎥⎥⎦ ,   a  Determine the rate of the code in symbols per channel use.  b  Find the diversity orders offered by the code by using the rank criterion.  19.13 Design a MIMO-OFDM system to provide a raw data rate of 40 Mbits s over a bandwidth of 10 MHz. Assume that Nt = 2, multipath spread τmax = 0.5 ms, and the Doppler spread is fD = 5 Hz. Specify the following design parameters: the number of carriers, OFDM symbol duration, the length of the cyclic preﬁx, and the modulation scheme.  References  [1] 3GPP, Double-STTD Scheme for HSDPA Systems with Four Transmit Antennas: Link Level Simulation Results, 3GPP TSG RAN WG1 document, TSGR121 01 -0701, Jun 2001.  [2] 3GPP, Spatial Channel Model for Multiple Input Multiple Output MIMO Simula-  tions, TR 25.996, Ver. 6.1.0, Sep 2003.  [3] 3GPP, Multiple-input Multiple-output in UTRA, TR 25.876 Ver. 1.5.1, May 2004. [4] M. Airy, R. W. Heath, Jr. & S. Shakkottai, Multi-user diversity for the multi- ple antenna broadcast channel with linear receivers: asymptotic analysis. In Proc. Asilomar Conf. Signals Syst. Computers, Paciﬁc Grove, CA, Nov 2004, 1, 886–890. [5] S. M. Alamouti, A simple transmit diversity technique for wireless communications.  IEEE J. Sel. Areas Commun., 16:8  1998 , 1451–1458.  [6] P. Almers, F. Tufvensson & A. F. Molisch, Measurements of keyhole effect in a wireless multiple-input multiple-output  MIMO  channel. IEEE Commun. Lett., 7:8  2003 , 373–375.  [7] S. L. Ariyavisitakul, Turbo space-time processing to improve wireless channel  capacity. IEEE Trans. Commun., 48:8  2000 , 1347–1359      860   cid:2   Multiple antennas: MIMO systems  [8] E. K. S. Au & W. H. Mow Exact bit error rate for SVD-based MIMO sys- tems with channel estimation errors. In Proc. IEEE ISIT, Seattle, USA, Jul 2006, 2289–2293.  [9] E. K. S. Au, C. Wang, S. Sfar, R. D. Murch, W. H. Mow, V. K. N. Lau, R. S. Cheng & K. B. Letaief, Error probability for MIMO zero-forcing receiver with adaptive power allocation in the presence of imperfect channel state information. IEEE Trans. Wireless Comun., 6:4  2007 , 1523–1529.  [10] H. R. Bahrami, T. Le-Ngoc, A. M. N. Nasrabadi & S. H. Jamali, Precoder design based on correlation matrices for MIMO systems communications. In Proc. IEEE ICC, Seoul, Korea, May 2005, 3, 2001–2005.  [11] E. Biglieri & G. Taricco, Fundamentals of MIMO channel capacity. In H. Bolcskei, D. Gesbert, C.B. Papadias & A.-J. van der Veen, eds., Space-Time Wireless Systems: From Array Processing to MIMO Communications  Cambridge, UK: Cambridge University Press, 2006 , pp. 66–86.  [12] D. W. Bliss, K. W. Forsythe, A. O. Hero, III & A. F. Yegulalp, Environmental issues  for MIMO capacities. IEEE Trans. Signal Process., 50:9  2002 , 2128–2142.  [13] L. Boher, R. Rabineau & M. Helard, FPGA implementation of an iterative receiver for MIMO-OFDM systems. IEEE J. Sel. Areas Commun., 26:6  2008 , 857–866.  [14] H. Bolcskei & A. J. Paulraj, Space-frequency coded broadband OFDM systems. In  Proc. IEEE WCNC, Chicago, IL, Sep 2000, 1–6.  [15] H. Bolcskei, D. Gesbert & A. J. Paulraj, On the capacity of OFDM based spatial  multiplexing systems. IEEE Trans. Commun., 50:2  2002 , 225–234.  [16] H. Bolcskei, R. W. Heath, Jr. & A. J. Paulraj, Blind channel identiﬁcation and equal- ization in OFDM-based multiantenna systems. IEEE Trans. Signal Process., 50:1  2002 , 96–108.  [17] A. O. Boukalov & S.-G. Haggman, System aspects of smart-antenna technology in cellular wireless communications – an overview. IEEE Trans. Microwave Theory Tech., 48:6  2000 , 919–929.  [18] Z. Chen, Z. Chi, Y. Li & B. Vucetic, Error performance of maximal-ratio combining with transmit antenna selection in ﬂat Nakagami-m fading channels. IEEE Trans. Wireless Commun., 8:1  2009 , 424–431.  [19] Z. Chen, J. Yuan & B. Vucetic, Improved space-time trellis coded modu- lation scheme slow Rayleigh fading channels. Electron. Lett., 37:7  2001 , 440–441.  [20] Z. Chen, J. Yuan & B. Vucetic, Analysis of transmit antenna selection maximal- ratio combining in Rayleigh fading channels. IEEE Trans. Veh. Tech., 54:4  2005 , 1312–1321.  [21] X. Zhang, Z. Lv & W. Wang, Performance analysis of multiuser diversity in MIMO systems with antenna selection. IEEE Trans. Wireless Commun., 7:1  2008 , 15–21.  [22] C.-J. Chen & L.-C. Wang, Performance analysis of scheduling in multiuser MIMO systems with zero-forcing receivers. IEEE J. Sel. Areas Commun., 25:7  2007 , 1435–1445.      861   cid:2   References  [23] D. Chizhik, G. J. Foschini, M. J. Gans & R. A. Valenzuela, Keyhole, correlations, and capacities of multielement transmit and receive antennas. IEEE Trans. Wireless Commun., 1:2  2002 , 361–368.  [24] Y. J. Chun & S. W. Kim, Log-likelihood-ratio ordered successive interference can- cellation in multi-user, multi-mode MIMO systems. IEEE Commun. Lett., 12:11  2008 , 837–839.  [25] M. V. Clark, Adaptive frequency-domain equalization and diversity combining for broadband wireless communications. IEEE J. Sel. Areas Commun., 16:8  1998 , 1385–1395.  [26] M. H. N. Costa, Writing on dirty paper. IEEE Trans. Inf. Theory, 29:3  1983 , 439–  [27] T. M. Cover & J. A. Thomas, Elements of Information Theory  Hoboken, NJ: Wiley,  441.  2006 .  [28] S. N. Diggavi, N. Al-Dhahir & A. R. Calderbank, Diversity embedded space-time  codes. In Proc. IEEE Globecom, San Francisco, CA, Dec 2003, 1909–1914.  [29] S. N. Diggavi, A. R. Calderbank, S. Dusad & N. Al-Dhahir, Diversity embedded  space-time codes. IEEE Trans. Inf. Theory, 54:1  2008 , 33–50.  [30] K.-L. Du & M. N. S. Swamy, Performance of multiuser detection schemes for CDMA systems using antenna arrays. In Proc. World Wireless Congress  WWC’04 , San Francisco, CA, May 2004, 433–438.  [31] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [32] K.-L. Du & M. N. S. Swamy, An adaptive space-time multiuser detection algorithm  for CDMA systems. In Proc. IEEE WiCOM, Wuhan, China, Sep 2006, 1–5.  [33] S. Dusad, S. N. Diggavi, N. Al-Dhahir & A. R. Calderbank, Diversity embed- ded codes: theory and practice. IEEE J. Sel. Topics Signal Process., 2:2  2008 , 202–219.  [34] P. Elia, B. A. Sethuraman & P. V. Kumar, Perfect space-time codes for any number  of antennas. IEEE Trans. Inf. Theory, 53:11  2007 , 3853–3868.  [35] R. Esmailzadeh & M. Nakagawa, Prerake diversity combination for direct sequence spread spectrum mobile communication systems. IEICE Trans. Comm., E76-B:8  1993 , 1008–1015.  [36] D. Falconer, Spatial-temporal signal processing for broadband wireless systems. In M. Shaﬁ, S. Ogose & T. Hattori, eds, Wireless Communications in the 21st Century  New York: IEEE Press, 2002 .  [37] G. Fememias, BER performance of linear STBC from orthogonal design over MIMO correlated Nakagami-m channels. IEEE Trans. Veh. Technol., 53:2  2004 , 307–317.  [38] R. F. H. Fischer, C. Windpassinger, A. Lampe & J. B. Huber, MIMO precoding for decentralized receivers. In Proc. IEEE ISIT, Lausanne, Switzerland, Jun–Jul 2002, 496.  [39] G. J. Foschini & M. J. Gans, Layered space-time architecture for wireless commu- nication in a fading environment when using multiple antennas. Bell Labs Tech. J., 1:2  1996 , 41–59.      862   cid:2   Multiple antennas: MIMO systems  [40] G. J. Foschini & M. J. Gans, On limits of wireless communications in a fading environment when using multiple antennas. Wireless Pers. Commun., 6:3  1998 , 311–335.  [41] G. Ganesan & P. Stoica, Differential modulation using space-time block codes. IEEE  Signal Process. Lett., 9:2  2002 , 57–60.  [42] D. Garrett, L. Davis., S. ten Brink, B. Hochwald & G. Knagge, Silicon complexity for maximum likelihood MIMO detection using spherical decoding. IEEE J. Solid- State Circ., 39:9  2004 , 1544–1552.  [43] D. Gesbert, H. Bolcskei, D. A. Gore & A. J. Paulraj, Outdoor MIMO wireless channels: models and performance prediction. IEEE Trans. Commun., 50:12  2002 , 1926–1934.  [44] G. B. Giannakis, Z. Liu, X. Ma & S. Zhou, Space-Time Coding for Broadband  Wireless Communications  Hoboken, NJ: Wiley, 2007 .  [45] G. Ginis & J. Ciofﬁ, On the relation between V-BLAST and the GDFE. IEEE  Commun. Lett., 15:9  2001 , 364–366.  [46] G. D. Golden, G. J. Foschini, R. A. Valenzuela & P. W. Wolbiansky, Detection algo- rithm and initial laboratory results using the V-BLAST space-time communication architecture. Electron. Lett., 35:1  1999 , 14–16.  [47] A. Goldsmith, Wireless Communications  Cambridge, UK: Cambridge University  Press, 2005 .  [48] Y. Gong & K. B. Letaief, On the error probability of orthogonal space-time block codes over keyhole MIMO channels. IEEE Trans. Wireless Commun., 6:9  2007 , 3402–3409.  [49] A. J. Grant, Performance Analysis of Transmit Beamforming. IEEE Trans. Com-  mun., 53:4  2005 , 738–744.  [50] L. H. Grokop & D. N. C. Tse, Diversity-multiplexing tradeoff in ISI channels. IEEE  Trans. Inf. Theory, 55:1  2009 , 109–135.  [51] Z. Guo & P. Nilsson, Algorithm and implementation of the K-best sphere decoding for MIMO detection. IEEE J. Sel. Areas Commun., 24:3  2006 , 491–503.  [52] S. Haene, D. Perels & A. Burg, A real-time 4-stream MIMO-OFDM transceiver: system design, FPGA implementation, and characterization. IEEE J. Sel. Areas Commun., 26:6  2008 , 877–889.  [53] B. Hassibi, An efﬁcient square-root algorithm for BLAST. In Proc. IEEE ICASSP,  Istanbul, Turkey, Jun 2000, 2, 737–740.  [54] B. Hassibi & B. Hochwald, High rate codes that are linear in space and time. IEEE  Trans. Inf. Theory, 48:7  2002 , 1804–1824.  [55] R. W. Heath, Jr., M. Airy & A. J. Paulraj, Multiuser diversity for MIMO wireless sys- tems with linear receivers. In Proc. Asilomar Conf. Signals Syst. Computers, Paciﬁc Grove, CA, Nov 2001, 2, 1194–1199.  [56] R. W. Heath, Jr. & A. J. Paulraj, Linear dispersion codes for MIMO systems based  on frame theory. IEEE Trans. Signal Process., 50:10  2002 , 2429–2441.  [57] B. Hochwald & W. Sweldens, Differential unitary space-time modulation. IEEE  Trans. Commun., 48:12  2000 , 2040–2052.      863   cid:2   References  [58] B. Hochwald, T. L. Marzetta & C. B. Papadias. A transmitter diversity scheme for wideband CDMA systems based on space-time spreading. IEEE J. Sel. Areas Commun., 19:1  2001 , 48–60.  [59] B. M. Hochwald & S. ten Brink, Achieving near-capacity on a multiple-antenna  channel. IEEE Trans. Commun., 51:3  2003 , 389–399.  [60] B. L. Hughes, Differential space-time modulation. IEEE Trans. Inf. Theory, 46:7  [61] H. Jafarkhani, A quasi-orthogonal space-time block code. IEEE Commun. Lett., 49:1   2000 , 2567–2578.   2001 , 1–4.  [62] W. C. Jakes, Jr., ed., Microwave Mobile Communications  New York: Wiley, 1974 . [63] E. A. Jorswieck & A. Sezgin, Impact of spatial correlation on the perfor- mance of orthogonal space-time block codes. IEEE Commun. Lett., 8:1  2004 , 21–23.  [64] R. Kalbasi, D. D. Falconer, A. H. Banihashemi & R. Dinis, A comparison of frequency-domain block MIMO transmission systems. IEEE Trans. Veh. Tech., 58:1  2009 , 165–175.  [65] A. Kalis, A. G. Kanatas & C. B. Papadias, A novel approach to MIMO transmission  using a single RF front end. IEEE J. Sel. Areas Commun., 26:6  2008 , 972–980.  [66] M. Kang & M. S. Alouini, Capacity of correlated MIMO Rayleigh channels. IEEE  Trans. Wireless Commun., 5:1  2006 , 143–155.  [67] M. Kang & M. S. Alouini, Capacity of MIMO Rician channels. IEEE Trans. Wireless  Commun., 5:1  2006 , 112–122.  [68] I.-M. Kim, Exact BER analysis of OSTBCs in spatially correlated MIMO channels.  IEEE Trans. Commun., 54:8  2006 , 1365–1373.  [69] I.-M. Kim & D. Kim, Closed-form exact BER and optimization of generalized  orthogonal STBCs. IEEE Trans. Wireless Commun., 7:9  2008 , 3323–3328  [70] Y.-T. Kim, H. Lee, S. Park & I. Lee, Optimal precoding for orthogonalized spa- tial multiplexing in closed-loop MIMO systems. IEEE J. Sel. Areas Commun., 26:8  2008 , 1556–1566.  [71] R. Kohno, H. Imai, M. Hatori & S. Pasupathy, Combination of an adaptive array antenna and a canceller of interference for direct-sequence spread-spectrum multiple-access system. IEEE J. Sel. Areas Commun., 8:4  1990 , 675–682.  [72] R. Kohno, Interference cancellation and multiuser detection. In M. Shaﬁ, S. Ogose & T. Hattori, eds., Wireless Communications in the 21st Century  New York: IEEE Press, 2002 .  [73] V. Kuhn, Wireless Communications over MIMO Channels: Applications to CDMA  and Multiple Antenna Systems  Chichester, UK: Wiley, 2006 .  [74] E. G. Larsson & P. Stoica, Space-Time Block Coding for Wireless Communications   Cambridge, UK: Cambridge University Press, 2003 .  [75] H. Lee, B. Lee & I. Lee, Iterative detection and decoding with an improved V-BLAST for MIMO-OFDM systems. IEEE J. Sel. Areas Commun., 24:3  2006 , 504–513.  [76] H. Lee, S. Park & I. Lee, Orthogonalized spatial multiplexing for closed-loop MIMO  systems. IEEE Trans. Commun., 55:5  2007 , 1044–1052.      864   cid:2   Multiple antennas: MIMO systems  [77] G. Levin & S. Loyka, On the outage capacity distribution of correlated keyhole  MIMO channels. IEEE Trans. Inf. Theory, 54:7  2008 , 3232–3245.  [78] E. Lindskog & A. J. Paulraj, A transmit diversity scheme for channels with intersymbol interference. In Proc. IEEE ICC, New Orleans, LA, Jun 2000, 1, 307–311.  [79] C. Ling, W. H. Mow, K. H. Li & A. C. Kot, Multiple-antenna differential lattice  decoding. IEEE J. Sel. Areas Commun., 23:9  2005 , 1821–1829.  [80] Z. Liu, G. B. Giannakis, S. Barbarossa & A. Scaglione, Transmit-antennae space- time block coding for generalized OFDM in the presence of unknown multipath. IEEE J. Sel. Areas Commun., 19:7  2001 , 1352–1364.  [81] T. Lo, Maximal ratio transmission. IEEE Trans. Comm., 47:10  1999 , 1458–1461. [82] E. S. Lo, P. W. C. Chan, V. K. N. Lau, R. S. Cheng, K. B. Letaief, R. D. Murch & W. H. Mow, Adaptive resource allocation and capacity comparison of downlink mul- tiuser MIMO-MC-CDMA and MIMO-OFDMA. IEEE Trans. Wireless Commun., 6:3  2007 , 1083–1093.  [83] D. J. Love, R. W. Heath, Jr. & T. Strohmer, Grassmannian beamforming for multiple- input multiple-output wireless systems. IEEE Trans. Inf. Theory, 49:10  2003 , 2735–2747.  [84] D. J. Love, R. W. Heath Jr, V. K. N. Lau, D. Gesbert, B. D. Rao & M. Andrews, An overview of limited feedback in wireless communication systems. IEEE Sel. Areas Commun., 26:8  2008 , 1341–1365.  [85] S. Loyka & F. Gagnon, Performance analysis of the V-BLAST algorithm: an  analytical approach. IEEE Trans. Wireless Commun., 3:4  2004 , 1326–1337.  [86] S. Loyka & F. Gagnon, On outage and error rate analysis of the ordered V-BLAST.  IEEE Trans. Wireless Commun., 7:10  2008 , 3679–3685.  [87] S. Loyka & G. Tsoulos, Estimating MIMO system performance using the correlation  matrix approach. IEEE Commun. Lett., 6:1  2002 , 19–21.  [88] A. Lozano, A. M. Tulino & S. Verdu, Multiantenna capacity: myths and realities. In H. Bolcskei, D. Gesbert, C. B. Papadias & A.-J. van der Veen, eds., Space-Time Wireless Systems: From Array Processing to MIMO Communications  Cambridge, UK: Cambridge University Press, 2006 , pp. 87–107.  [89] B. Lu, X. Wang & K. Narayanan, LDPC-based space-time coded OFDM systems over correlated fading channels: performance analysis and receiver design. IEEE Trans. Commun., 50:1  2002 , 74–88.  [90] A. Maaref & S. Aissa, Closed-form expressions for the outage and ergodic Shannon capacity of MIMO MRC systems. IEEE Trans. Commun., 53:7  2005 , 1092–1095.  [91] R. Y. Mesleh, H. Haas, S. Sinanovic, C. W. Ahn & S. Yun, Spatial modulation. IEEE  Trans. Veh. Tech., 57:4  2008 , 2228–2241  [92] A. F. Molisch, Wireless Communications  Chichester, UK: Wiley-IEEE, 2005 . [93] W. H. Mow, Maximum likelihood sequence estimation from the lattice viewpoint.  IEEE Trans. Inf. Theory, 40:5  1994 , 1591–1600.  [94] W. H. Mow, Universal lattice decoding: principle and recent advances. Wireless  Commun. Mobile Comput., 3:5  2003 , 553–569.      865   cid:2   References  [95] K. K. Mukkavilli, A. Sabharwal, E. Erkip & B. Aazhang, On beamforming with ﬁnite rate feedback in multiple antenna systems. IEEE Trans. Inf. Theory, 49:10  2003 , 2562–2579.  [96] R. U. Nabar, H. Bolcskei & A. J. Paulraj, Diversity and outage performance in space-time block coded Ricean MIMO channel. IEEE Trans. Wireless Commun., 4:5  2005 , 2519–2532.  [97] A. Naguib, N. Seshadri & A. R. Calderbank, Space-time coding and signal process- ing for high data rate wireless communications. IEEE Signal Process. Mag., 17:3  2000 , 76–92. [98] C. Oestges, Mutual information of non-Kronecker structured dual-polarized 2 × 2  channels. IEEE Trans. Veh. Tech., 56:1  2006 , 410–413.  [99] C. Oestges & B. Cerckx, MIMO Wireless Communications: From Real-World  Propagation to Space-Time Code Design  Oxford, UK: Academic Press, 2007 .  [100] F. Oggier, G. Rekaya, J.-C. Belﬁore & E. Viterbo, Perfect space-time block codes.  IEEE Trans. Inf. Theory, 52:9  2006 , 3885–3902.  [101] O. Oyman, R. U. Nabar, H. Boelcskei & A. J. Paulraj, Characterizing the statistical properties of mutual information in MIMO channels. IEEE Trans. Signal Process., 51:11  2003 , 2784–2795.  [102] C. B. Papadias & H. Huang, Linear space-time multiuser detection for multipath  CDMA channels. IEEE J. Sel. Areas Commun., 19:2  2001 , 254–265.  [103] A. Paulraj, R. Nabar & D. Gore, Introduction to Space–Time Wireless Communica-  tions  Cambridge, UK: Cambridge University Press, 2003 .  [104] K. I. Pedersen, P. E. Mogensen & J. Ramiro-Moreno, Application and performance of downlink beamforming techniques in UMTS. IEEE Commun. Mag., 41:10  2003 , 134–143.  [105] K. I. Pedersen & P. E. Mogensen, Performance of WCDMA HSDPA in a beamform- ing environment under code constraints. In Proc. IEEE VTC, Orlando, FL, Oct 2003, 2, 995–999.  [106] K. Peppas & A. Maras, Performance evaluation of space-time block codes over  keyhole Weibull fading channels. Wireless Pers. Commun., 46:4  2008 , 385–395.  [107] S. L. Preston, D. V. Thiel, J. W. Lu, S. G. O’Keefe & T. S. Bird. Electronic beam  steering using switched parasitic patch elements. Electron. Lett., 33:1  1997 , 7–8.  [108] V. Raghavan, R. W. Heath, Jr. & A. M. Sayeed, Systematic codebook designs for quantized beamforming in correlated MIMO channels. IEEE J. Sel. Areas Commun., 25:7  2007 , 1298–1310.  [109] J. Ramiro-Moreno, K. I. Pedersen & P. E. Mogensen, Network performance of transmit and receive antenna diversity in HSPDA under different packet scheduling strategies. In Proc. IEEE VTC, Jeju, Korea, Apr 2003, 2, 1454–1458.  [110] S. M. Razavizadeh, A. K. Khandani, V. T. Vakili & W. Tong, Space-time precoding for downlink transmission in multiple antenna CDMA systems. IEEE Trans. Veh. Tech., 56:5  2007 , 2590–2602.  [111] D. Reynolds, X. Wang & H. V. Poor, Blind adaptive space–time multiuser detection with multiple transmitter and receiver antennas. IEEE Trans. Signal Process., 50:6  2002 , 1261–1276.      866   cid:2   Multiple antennas: MIMO systems  [112] J. M. Romero-Jerez & A. J. Goldsmith, Performance of multichannel reception with transmit antenna selection in arbitrarily distributed Nagakami fading channels. IEEE Trans. Wireless Commun., 8:4  2009 , 2006–2013.  [113] D. J. Ryan, I. V. L. Clarkson, I. B. Collings, D. Guo & M. L. Honig, QAM and PSK codebooks for limited feedback MIMO beamforming. IEEE Trans. Commun., 57:4  2009 , 1184–1196.  [114] H. Sampath, P. Stoica & A. Paulraj, Generalized linear precoder and decoder design for MIMO channel using the weighted MMSE criterion. IEEE Trans. Commun., 49:12  2001 , 2198–2206.  [115] S. Sanayei, A. Hedayat & A. Nosratinia, Space time codes in keyhole channels:  analysis and design. IEEE Trans. Wireless Commun., 6:6  2007 , 2006–2011.  [116] S. Sandhu & A. Paulraj, Space-time block codes: a capacity perspective. IEEE  Commun. Lett., 4:12  2000 , 384–386.  [117] T. Sawaya, K. Iigusa, M. Taromaru & T. Ohira, Reactance diversity: proof-of- concept experiments in an indoor multipath-fading environment with a 5-GHz prototype planar ESPAR antenna. In Proc. IEEE CCNC, Las Vegas, NV, Jan 2004, 678–680.  [118] A. Sayeed & V. Veeravalli, The essential degrees of  freedom in space- time fading channels. In Proc. IEEE PIMRC, Lisbon, Portugal, Sep 2002, 4, 1512–1516.  [119] C. B. Schlegel & L. C. Perez, Trellis and Turbo Coding  Piscataway, NJ: IEEE Press,  2004 .  [120] N. L. Scott, O.-L. Taylor & R. G. Vaughan, Diversity gain from a single-port adap- tive antenna using switched parasitic elements illustrated with a wire and monopole prototype. IEEE Trans. Anten. Propagat., 47:6  1999 , 1066–1070.  [121] M. Shaﬁ, M. Zhang, A. L. Moustakas, P. J. Smith, A. F. Molisch, F. Tufvesson & S. H. Simon, Polarized MIMO channels in 3-D: models, measurements and mutual information. IEEE J. Sel. Areas Commun., 24:3  2006 , 514–527.  [122] N. Sharma & C. B. Papadias, Improved quasi-orthogonal codes through constellation  rotation. IEEE Trans. Commun., 51:3  2003 , 332–335.  [123] C. Shin, R. W. Heath, Jr. & E. J. Powers, Blind channel estimation for MIMO-OFDM  systems. IEEE Trans. Veh. Tech., 56:2  2007 , 670–685.  [124] H. Shin & J. H. Lee, Capacity of multiple-antenna fading channels: spatial fading correlation, double scattering and keyhole. IEEE Trans. Inf. Theory, 49:10  2003 , 2636–2647.  [125] H. Shin & M. Z. Win, MIMO diversity in the presence of double scattering. IEEE  Trans. Inf. Theory, 54:7  2008 , 2976–2996.  [126] W.-Y. Shin, S.-Y. Chung & Y. H. Lee, Diversity-multiplexing tradeoff and outage performance for Rician MIMO channels. IEEE Trans. Inf. Theory, 54:3  2008 , 1186–1196.  [127] D.-S. Shiu, G. J. Foschini, M. J. Gans & J. M. Kahn, Fading correlation and its effect on the capacity of multielement antenna system. IEEE Trans. Commnun., 48:3  2000 , 502–513.      867   cid:2   References  [128] O. Simeone, Y. Bar-Ness & U. Spagnolini, Linear and nonlinear preequal- ization equalization for MIMO systems with long-term channel state infor- IEEE Trans. Wireless Commun., 3:2  2004 , mation at 373–377.  the transmitter.  [129] W. P. Siriwongpairat, M. Olfat & K. J. R. Liu, On the performance evaluation of the TH and DS UWB MIMO systems. In Proc. IEEE WCNC, Atlanta, GA, Mar 2004, 3, 1800–1805.  [130] W. P. Siriwongpairat & K. J. R. Liu, Ultra-Wideband Communications Systems:  Multiband OFDM Approach  Piscataway, NJ: Wiley-IEEE, 2008 .  [131] R. A. Soni & R. M. Buehrer, On the performance of open loop transmit diver- sity techniques for IS-2000 systems: a comparative study. IEEE Trans. Wireless Commun., 3:5  2004 , 1602–1615.  [132] Q. H. Spencer, J. W. Wallace, C. B. Peel, T. Svantesson, A. L. Swindlehurst, H. Lee & A. Gumalla, Performance of multi-user spatial multiplexing with measured chan- nel data. In G. Tsoulos, ed., MIMO System Technology for Wireless Communications  Boca Raton, FL: CRC Press, 2006 , pp. 175–205.  [133] M. Stojnic, H. Vikalo & B. Hassibi, Rate maximization in multi-antenna broadcast channels with linear preprocessing. In Proc. IEEE Globecom, Dallas, TX, Nov–Dec 2004, 3957–3961  [134] G. L. Stuber, J. R. Barry, S. W. McLaughlin, Y. G. Li, M. A. Ingram & T. G. Pratt, Broadband MIMO-OFDM wireless communications. Proc. IEEE, 92:2  2004 , 271– 294.  [135] W. Su & X.-G. Xia, Two generalized complex orthogonal spacetime block codes of rates 7 11 and 3 5 for 5 and 6 transmit antennas. IEEE Trans. Inf. Theory, 49:1  2003 , 313–316.  [136] C. Sun, A. Hirata, T. Ohira & N. C. Karmakar, Fast Beamforming of electroni- cally steerable parasitic array radiator antennas: theory and experiment. IEEE Trans. Anten. Propagat., 52:7  2004 , 1819–1832.  [137] P. H. Tan, Y. Wu & S. Sun, Link adaptation based on adaptive modulation and cod- ing for multiple-antenna OFDM system. IEEE J. Sel. Areas Commun., 26:8  2008 , 1599–1606.  [138] V. Tarokh, N. Seshadri & R. A. Calderbank, Space-time codes for high data rate wireless communication: Performance criterion and code construction. IEEE Trans. Inf. Theory, 44:2  1998 , 744–765.  [139] V. Tarokh, H. Jafarkhani & A. R. Calderbank, Space-time block codes from  orthogonal designs. IEEE Trans. Inf. Theory, 45:5  1999 , 1456–1467.  [140] V. Tarokh & H. Jafarkhani, A differential detection scheme for transmit diversity.  IEEE J. Sel. Areas Commun., 18:7  2000 , 1169–1174.  [141] I. E. Telatar, Capacity of multi-antenna Gaussian channels. Euro. Trans. Telecom.,  10:6  1999 , 585–595.  [142] E. Tiirola & J. Ylitalo, Comparison of beam-forming and diversity techniques in terms of UTRA FDD uplink capacity. In Proc. Nordic Radio Symp., Oulu, Finland, Aug 2004.      868   cid:2   Multiple antennas: MIMO systems  [143] M. Trivellato, F. Boccardi & H. Huang, On transceiver design and channel quanti- zation for downlink multiuser MIMO systems with limited feedback. IEEE J. Sel. Areas Commun., 26:8  2008 , 1494–1504.  [144] D. Tse & P. Viswanath, Fundamentals of Wireless Communications  Cambridge,  UK: Cambridge University Press, 2005 .  [145] M. K. Varanasi & T. Guess, Optimum decision feedback multiuser equalization with successive decoding achieves the total capacity of the Gaussian multiple-access channel. In Proc. Asilomar Conf. Signals, Systems, Computers, Montery, CA, Nov 1997, 2, 1405–1409.  [146] G. P. Villardi, G. T. F. De Abreu, & R. Kohno, Modiﬁed orthogonal space-time block codes for time-selective fading channels. IEEE Trans. Veh. Tech., 57:6  2008 , 3921–3927.  [147] M. Vu, Precoding design. In E. Biglieri, R. Calderbank, A. Constantinides, A. Gold- smith, A. Paulraj & H. V. Poor, eds., MIMO Wireless Communications  Cambridge, UK: Cambridge University Press, 2007 , pp. 88–139.  [148] M. Vu & A. Paulraj, On the capacity of MIMO wireless channels with dynamic  CSIT. IEEE J. Sel. Areas Commun., 25:7  2007 , 1269–1283.  [149] F. Wan, W.-P. Zhu & M. N. S. Swamy, A semiblind channel estimation approach for MIMO-OFDM systems. IEEE Trans. Signal Process., 56:7  2008 , 2821–2834.  [150] F. Wan, W.-P. Zhu & M. N. S. Swamy, A signal-perturbation-free whitening-rotation- based approach for MIMO channel estimation. IEEE Trans. Signal Process., 57:8  2009 , 3154–3166.  [151] F. Wan, W.-P. Zhu & M. N. S. Swamy, Frequency-domain semi-blind channel estimation for MIMO-OFDM systems. Submitted to IEEE Trans. Wireless Commun. [152] X. Wang & H. V. Poor, Space-time multiuser detection in multipath CDMA  channels. IEEE Trans. Signal Process., 47:9  1999 , 2356–2374.  [153] Z. Wang & G. B. Giannakis, Outage mutual information of space-time MIMO  channels. IEEE Trans. Inf. Theory, 50:4  2004 , 657–662.  [154] M. Wennstrom & T. Svantesson, An antenna solution for MIMO channels: The switched parasitic antenna. In Proc. IEEE PIMRC, San Diego, CA, Sep 2001, 1, A-159–A-163.  [155] J. H. Winters, J. Salz & R. D. Gitlin, The impact of antenna diversity on the capacity of wireless communication systems. IEEE Trans. Commun., 42:2–4  1994 , 1740– 1750.  [156] Y. C. Wu, S.-C. Chan & E. Serpedin, Symbol-timing estimation in space-time coding systems based on orthogonal training sequences. IEEE Trans. Wireless Commun., 4:2  2005 , 603–613  [157] F. Xu, D.-W. Yue, F. C. M. Lau & Q. F Zhou, Closed-form expressions for sym- bol error probability of orthogonal space-time block codes over Rician-Nakagami channels. IET Commun., 1:4  2007 , 655–661.  [158] L.-L. Yang, MIMO-assisted space-code-division multiple-access: linear detectors and performance over multipath fading channels. IEEE J. Sel. Areas Commun., 24:1  2006 , 121–131.      869   cid:2   References  [159] T. Yoo & A. Goldsmith, On the optimality of multiantenna broadcast schedul- ing using zero-forcing beamforming. IEEE J. Sel. Areas Commun., 24:3  2006 , 528–541.  [160] A. van Zelst & J. S. Hammerschmidt, A single coefﬁcient spatial correlation mod- els for multiple-input multiple-output  MIMO  radio channels. In Proc. URSI 27th General Assembly, Maastricht, Netherlands, 2002, 657–660.  [161] H. Zhang, H. Dai & B. L. Hughes, Analysis on the diversity-multiplexing tradeoff  for ordered MIMO SIC receivers. IEEE Trans. Commun., 57:1  2009 , 125–133.  [162] R. Zhang, Y.-C. Liang, R. Narasimhan & J. M. Ciofﬁ, Approaching MIMO-OFDM capacity with per-antenna power and rate feedback. IEEE J. Sel. Areas Commun., 25:7  2007 , 1284–1297.  [163] L. Zheng & D. L. C. Tse, Diversity and multiplexing: a fundamental tradeoff in  multiple-antenna channels. IEEE Trans. Inf. Theory, 49:5  2003 , 1073–1096.      20  Ultra wideband communications  20.1 Introduction  UWB technology, also known as impulse radio, was ﬁrst used to transmit Morse codes by Marconi in 1900 through the transatlantic telegraph. Modern UWB technology has been used for radar and communications since the 1960s. Like CDMA systems, early UWB sys- tems were designed for military covert radar and communications. The early applications of UWB technology were primarily related to radar, driven by the ﬁne-ranging resolu- tion that comes with large bandwidth. UWB technology for wireless communications was pioneered by Scholtz [48]. With the intent of operating UWB in an unlicensed mode that overlaps licensed bands, the FCC issued rules under the FCC Rules and Regulations Part 15 for UWB operation in February 2002.  The FCC deﬁned a UWB transmitter as “an intentional radiator that, at any point in time, has a fractional bandwidth equal to or greater than 0.20, or has a UWB bandwidth equal to or greater than 500 MHz, regardless of the fractional bandwidth”. “The UWB bandwidth is the frequency band bounded by the points that are 10 dB below the highest radiated emission, as based on the complete transmission system including the antenna.”  According to the FCC regulations, the transmitter sends pulses with a bandwidth of at least 500 MHz that is within the band 3.1 to 10.6 GHz, for output power densities below −41.25 dBm MHz. The FCC Part 15 limit of 500 μV m at 3 meters is equivalent to an effective isotropic radiated power  EIRP  of −41.25 dBm MHz. The FCC spectrum masks for indoor and outdoor commercial UWB systems are plotted in Fig. 20.1. In Europe, the ETSI TG31 deﬁned its UWB spectrum emission mask speciﬁcation based on the FCC regulation. Many other countries proposed their UWB frequency allocations based on the FCC regulation.  Features of UWB technology  Due to its wideband nature, UWB is suitable for short-range ground- and tree-penetrating imaging. Some advantages of UWB communications are   Extremely simple radio, and thus low cost. This arises from the carrier-free nature of signal transmission: the UWB signal spans a wide frequency spectrum, and RF mixing circuitry is not required. Thus, the entire UWB transceiver can be implemented as a single CMOS chip, enabling small size, low cost, and low power.   High data rates. The wide bandwidth enables very high capacity at short distances.      871   cid:2   20.1 Introduction     1.99  3.1  10. 6     0.96 100  1.61  Frequency  GHz   Indoor Outdoor  101   cid:2 Figure 20.1  FCC spectrum masks for indoor and outdoor commercial UWB systems.  −40  −45  −50  −55  −60  −65  −70  −75     m B d     P R I E B W U       Multipath immunity. The wide bandwidth provides frequency diversity to overcome mul- tipath fading. The ﬁne delay resolution property makes UWB radio a viable candidate for communications in dense multipath environments.   Large processing gain in presence of narrowband interference.   Easy implementation of location. The ﬁne time resolution provides this capability at the centimeter level.   Long battery life. UWB communications are mainly in rich-scattering indoor environment, which is desired for MIMO implementation. The GHz center frequency of UWB radio relaxes the requirements on the antenna spacing. As a result, UWB-MIMO, the combination of UWB and MIMO technology is a viable solution for achieving very high data-rate, short-range wireless communication.  The difﬁculties in implementation are multipath energy capture, ISI, and the need for high-sampling-rate ADCs. The difﬁculty in multipath energy capture is due to the extremely low PSD of the UWB signals. This low PSD allows them to share the spec- trum with existing RF devices. If a rake receiver is used to collect the multipath energy, a large number of ﬁngers is needed due to the large number of multipath components.  DSSS has a slightly better BER performance than UWB for the same number of users, given the same frequency bandwidth constraint [22]. However, signal processing for CDMA is most difﬁcult due to the very short chip period, and UWB offers a much cheaper solution. For the UWB bandwidth of several gigahertz, a solution using DSSS is impossible.  Detection and avoidance  UWB shares the frequency bands with other standards such as the WiMAX  3.4–3.8 GHz  and IEEE 802.11g  5 GHz . The detection and avoidance  DAA  technique is used for      872   cid:2   Ultra wideband communications  solving the interference issues. The UWB transmitter ﬁrst detects the presence of another active device as well as its likelihood of interference, and avoids that speciﬁc band. This allows the UWB system to operate across a continuous range of spectrum. The detection is based on FFT. After a potential interfering signal is detected, a number of techniques can be used to reduce interference – transmit power control, frequency notching, and more advanced techniques. Transmit power control transmits the lowest possible power for reception.  Applications of UWB  UWB technology can be viewed as a kind of spread spectrum technology. Initial research on UWB radio is based on time-hopping spread spectrum  THSS . THSS can be implemented as a multiple access technology. Time-hopping UWB  TH-UWB  is the traditional UWB scheme, and it is an example of impulse radio UWB or pulsed UWB. TH-UWB has strict restriction on synchronization. TH-UWB can be imple- mented in analog or digital form. Impulse radio represents each symbol by one or a sequence of short pulses. DS-UWB is another pulsed UWB scheme that is based on DS-CDMA. Another popular UWB scheme is OFDM-UWB, which is based on OFDM modulation.  Pulsed UWB is a form of bandpass communications. Due to its broad bandwidth, UWB enables both high-data-rate short-range wireless PAN connectivity and longer-range, low- data-rate applications such as sensor, positioning, and identiﬁcation networks. In addition to its applications in wireless PANs, UWB technology can be used for wireless LANs, wireless sensor networks, radar imaging, vehicular radar systems, location and tracking. FCC has speciﬁed a spectral mask for UWB systems for each of these applications. It can also be delivered over wire lines and cables without affecting the existing ser- vices, but needs double the bandwidth. UWB technology has now aroused worldwide interest.  Due to the characteristics of low power, high data rate, and limited range, UWB is positioned for the market of high-speed wireless PANs. UWB is now targeted at in-home multimedia applications, such as IEEE 802.15.3a. IEEE 802.15.3a is an initial implemen- tation of UWB with a short range  less than 10 m  and a data rate above 100 Mbits s. The DS-UWB and MB-OFDM schemes are two major proposals for IEEE 802.15.3a. In its spectrum band, UWB may interfere with, or be interfered with by, wireless LANs at the 5-GHz band. Interference from the 5-GHz wireless LAN band can be removed by using a notch ﬁlter or using multiband. In addition, DS-UWB is used in the baseline IEEE 802.15.4a standard.  UWB is an enabling technology for evolution to high-speed Wireless USB, Wireless 1394, Bluetooth 3.0, and ECMA-368 369. Wireless USB is the wireless evolution of the most widespread wired USB  Universal Serial Bus  2.0 standard, and Wireless 1394 is the wireless evolution of IEEE 1394. Wireless USB is being developed by the USB Implementer’s Forum and Wireless 1394 by the 1394 Trade Association. ECMA-368 369  ISO IEC 26907 26908  is speciﬁed by ECMA  European Computer Manufacturers Asso- ciation  International, an ISO-accredited international standards body, for high-speed and      873   cid:2   20.2 UWB indoor channel  short-range wireless PANs. All these standards employ the MB-OFDM UWB technology standardized by the WiMedia Alliance, and utilize all or part of the spectrum between 3.1 and 10.6 GHz with peripheral device interconnections at up to 480 Mbits s. ECMA is also developing its TC32-TG20 standard for wireless PAN, which targets at 2 to 10 Gbits s data transport at the 60-GHz band.  UWB is believed to have its most wide perspective for interfacing consumer electronics and computer peripherals. Both the WiMedia Alliance and the UWB Forum try to sup- port Certiﬁed Wireless USB, wireless streaming video, Wireless 1394, and Bluetooth over UWB in their standard activities. UWB is also very promising for use in wireless BAN due to the very low power consumption.  20.2 UWB indoor channel  The power spectrums of a narrowband signal, a DS-CDMA signal, and a UWB signal are compared in Fig. 20.2. For a given transmit power, the UWB has the lowest PSD.  The IEEE 802.15.3a Task Group recommended a channel model in November 2002 [15], which is basically a modiﬁed version of the Saleh-Valenzuela model. Model parame- ters corresponding to several ranges are provided for both LOS and NLOS scenarios. The IEEE 802.15.3a Task Group developed four UWB indoor channel models to support its evaluation of the proposed UWB standards [34]. The IEEE 802.15.3a UWB model could provide reasonably accurate simulation results for UWB channels channels in vehicular environments  within a vehicle and outdoors in proximity to the vehicle  [42].  The UWB radio channel around the human body in a typical indoor environment has been measured and modeled in [16]. The body area channel consists of an initial clus- ter of components diffracting around the body and subsequent clusters of components reﬂecting from surrounding objects. Components diffracting around the body are well described by a high path loss exponent and correlated lognormal variables. Subsequent clusters have a more complex structure that can be described by a modiﬁed Saleh- Valenzuela model. Based on the measurements, a simple statistical channel model is given in [16].      S f  Narrowband  CDMA  UWB  f   cid:2 Figure 20.2  Power spectrums of narrowband, CDMA, and UWB signals.      874   cid:2   Ultra wideband communications  Large-scale channel model  In indoor environments, measurements show that shadowing dominates the channel. At a given distance d, the received signal has a path loss that is log-normally distributed about the mean [23]  PL d  = PLfs + 10α log10  + Xσ   dB ,   20.1    cid:2    cid:3   d d0  where d0 is the reference distance, α is the exponent of path loss, Xσ is a zero-mean log- normally distributed random variable with standard deviation σ dB, and PLfs is the free- space path loss.  For UWB communications, the frequency-dependence of the propagation loss may be signiﬁcant, and this can be considered in the UWB path loss model by multiplying the distance-dependent PLfs d  term by a factor that is associated with frequency PLf   f   [52]. frequency fc = √ In the channel model adopted in IEEE 802.15.3a, PLfs is calculated by using the center fHfL, where fH and fL are obtained at the −10 dB edges of the spectrum; Xσ  dB  has a zero-mean normal distribution with σ = 3. Some results for the in-home channel such as path loss parameters, the number of multipath components, mean excess delay, and rms delay spread are given in [21].  Measurements show that some LOS environments provide better path loss than free space  that is, α < 2 . This is due to the additional power collected via reﬂections in indoor channels with an LOS path, and the received signal power is greater than that in free space [5]. This phenomenon has also been demonstrated for narrowband channels [41].  Small-scale fading model  The small-scale fading of the UWB channel is very different from that of the narrowband channel. The two major differences are [52]   The number of multipath components received at the receiver within the period of an UWB waveform is very small. Thus, channel fading is not as severe as that in the narrow- band channel, and a large number of resolvable multipath components can be observed at the receiver.   Due to the ﬁne time resolution, the time of arrival of the multipath components will not be continuous, but is in clusters. This is different from the continuous case for the narrowband channel.  IEEE 802.15.3a Task Group considered three main indoor channel models for UWB systems [15]: the tapped-delay-line fading model [7], the  cid:18 -K model [24], and the Saleh- Valenzuela model [47]. The tapped-delay-line fading model allows frequency selectivity of the UWB channel to be taken into consideration, but the clustering characteristic of the UWB channel is not reﬂected. This clustering property is considered in the  cid:18 -K and Saleh-Valenzuela models. The Saleh-Valenzuela model was introduced in Section 3.1.7.      875   cid:2   20.2 UWB indoor channel  Table 20.1. Channel model parameters adopted in IEEE 802.15.3a.  Parameters   cid:8   1 ns  λ  1 ns   cid:9  γ  CM1  0.0233 2.5 7.1 4.3  CM2  0.4 0.5 5.5 6.7  CM3  0.0667 2.1 14 7.9  CM4  0.0667 2.1 24 12  Standard UWB channel model  Based on the log-normal path loss distribution and the Saleh-Valenzuela fading channel model, four sets of channel model  CM  parameters for different measurement envi- ronments are adopted in IEEE 802.15.3a, namely CM1, CM2, CM3, and CM4, for 3.1–10.6 GHz. CM1 and CM2 are, respectively, for the LOS and non-LOS scenarios with the distance between the transmitter and receiver being less than 4 m. CM3 is for a non- LOS scenario for a distance of 4 to 10 m. CM4 is deﬁned for an environment with a strong delay dispersion, which has a delay spread of 25 ns. The model parameters for the four standard models are listed in Table 20.1 [8, 52]. IEEE 802.15.3c uses the 57–64 GHz unlicenced band, and channel parameters for some environments are given in [59].  A low-frequency channel model for the band of 300–800 MHz was proposed in [7], based on a measurement campaign performed in a typical ofﬁce environment using base- band 1-ns pulses. It characterizes the shape of the PDP using a tapped-delay-line model. The low-frequency model has been accepted in IEEE 802.15.4a for performance evalu- ation of UWB systems operating below 1 GHz for indoor ofﬁce-type environments [35]. A modiﬁed Saleh-Valenzuela channel model for low-data-rate UWB communications has also been formulated in IEEE 802.15.4a, and channel parameters are speciﬁed for CM- 1 through CM-9, corresponding to indoor residential  LOS and non-LOS , indoor ofﬁce  LOS and non-LOS , industrial  LOS and non-LOS , outdoor  LOS and non-LOS , and open outdoor  non-LOS  environments [35].  IEEE 802.15.4a also speciﬁes a channel model for UWB BAN at 2 to 6 GHz [35]. As the model is based on FDTD simulations with 2 GHz bandwidth, it is not applicable to systems with larger bandwidth. FDTD simulations indicate that in the 2-6 GHz range, no energy is penetrating through the body.  The high-frequency  i.e., 3.1–10.6 GHz  and low-frequency channel models differ mainly in the arrival statistics and the amplitude distributions of multipath components [8]. The high-frequency model is sparse, i.e., there are resolvable delay bins that do not carry signiﬁcant power. The amplitude distribution is lognormal for the high-frequency model while it is Nakagami-m for the low-frequency model. The variance of the log- normal distribution is assumed to be independent of delay, whereas the m-parameter of the Nakagami distribution decreases with delay. The pdf of the high-frequency model is generally non-monotonic and sparse, and the direct path is not necessarily the strongest one.      876   cid:2   Ultra wideband communications  20.3 UWB capacity  For link budget analysis, the narrowband Friis transmission formula is not applicable, since it applies only to the power in continuous-wave  CW  sinusoidal signals and does not account for pulse distortion effects at either the transmit or receive antenna or even the type of waveform. Pulse radio transmission differentiates from a narrowband continuous- wave system in the distortion introduced by practical transmit and receive antennas. However, the narrowband model can be used to approximate the path loss for a UWB system [22].  Given the 7.5 GHz UWB band, the operating bandwidth can be estimated by link bud- get analysis. Assuming that the transmitted PSD is ﬂat, the received signal power PRX is given by   cid:12    cid:13   PRX = −41.25 + 10 log10   fU − fL  − 20 log10  4πf c  − 10α log10 d   dBm ,   20.2   where fL and fU are the lower and upper frequencies in the UWB band as per the FCC rules, f is the geometric mean of fL and fU, d is the distance in meters, α is the exponent of the path loss, and c = 3 × 108 m s is the speed of light. According to this equation, given fL = 3.1 GHz and a distance of 10 m, the received power increases as fU increases. The SNR at the receiver can be determined as  γ = PRX − L − N0 − 6  dB ,   20.3  where L is an additional implementation loss, N0 = −114 dBm MHz is the standard thermal noise PSD, and a noise ﬁgure of 6 dB is applied.  The Shannon capacity for a single user in the AWGN channel is given by  C d  = B log2 1 + γ     bits s .   20.4     s   s t i b G          C y t i c a p a C  25  20  15  10  5  0  0   cid:2 Figure 20.3  5  10  15  20  25  30  Distance d  m    UWB capacity versus distance.      877   cid:2   20.4 Pulsed UWB  Example 20.1: The capacity of the UWB system, given by  20.4 , is shown in Fig. 20.3, for fL = 3.1 GHz, fU = 10.6 GHz, the path loss exponent α = 3 and L = 35 dB.  20.4 Pulsed UWB  UWB has the attractive features of the time-domain nature of signal transmission. The UWB system can be designed as a single-band or multiband system, with each sub-band greater than 500 MHz. A single sub-band can occupy up to 7,500 MHz UWB spectrum. These schemes generate different performance tradeoffs and design challenges. Early single-band UWB systems generate simple, short pulses with wide spectral occupation. Multiband UWB systems use high-order modulation on constrained bandwidth to enable channelization.  The single-band approach is commonly treated as pulsed or carrier-free communica- tions. Information is directly modulated into a sequence of impulse-like waveforms that occupy a bandwidth of up to 7.5 GHz. The single-band approach is the traditional method for UWB implementation.  20.4.1 Pulse shape  A typical pulse shape for UWB is the Gaussian doublet. This waveform can be easily gen- erated from a square pulse by exploiting pulse shaping and ﬁltering effects of the transmit and receive antennas [22]. The fast switching on and off at nanosecond order or shorter for square pulse generation actually generates a Gaussian-like pulse shape that approximates a Gaussian function  G x  =  1√ 2π σ 2  − x2√ e  2σ 2 .   20.5   This waveform is known as a Gaussian pulse. The transmit antenna has the highpass ﬁlter- ing effect of a derivative operation, and the transmitted waveform is known as a Gaussian monocycle. The receive antenna has the same effect as a derivative operation, and thus the received second-derivative of the Gaussian pulse is known as a Gaussian doublet. These pulses are illustrated in Fig. 20.4. In addition, free-space propagation produces a lowpass ﬁltering or integration effect on the transmitted UWB signal [22].  The basic Gaussian pulse is represented by  yGP t  = K1e  −  t  τ  2  ,   20.6   where τ is the time-scaling factor and K1 is a constant. Derivative of the equation is similar to highpass ﬁltering the Gaussian pulse.      878   cid:2   Ultra wideband communications  t  t  t  t   cid:2 Figure 20.4  Pulse generation for the TH-UWB system.  a  Square pulse.  b  Gaussian pulse.  c  Gaussian monocycle.  d  Gaussian doublet.   a    b    c    d   Taking the ﬁrst- and second-order derivatives of the Gaussian pulse, we have the  Gaussian monocycle and the Gaussian doublet yGM t  = K2  cid:2  −2  yGD t  = K3  −2t τ 2 e  −  t  τ  2  ,   cid:3   1 − 2t2  τ 2  −  t e  τ  2  ,  τ 2  where K2 and K3 are constants.  E, that is,  The constants K1, K2, and K3 can be determined by the energy of the transmitted pulse,  E =   cid:14  ∞ −∞ y2 t dt,    τ E√ π 2  where y corresponds to yGP, yGM, or yGD. Accordingly, [22] , K3 = τ  , K2 =  K1 =  √ E π 2  τ  √ τ E π 2  .  3        The frequency spectrums of these pulses are, respectively, obtained by applying the  Fourier transform to these pulses  YGP = K1τ √ YGM = K2τ √ YGD = K3τ  √  − π τ f  2,  πe  π  j2πf  e  π  j2πf  2e  − π τ f  2, − π τ f  2.   20.7    20.8    20.9    20.10    20.11    20.12    20.13   Example 20.2: The waveforms of the pulses given by  20.6 – 20.8  and their frequency spectrums for τ = 0.1 ns and E = 1 are shown in Fig. 20.5. From the ﬁgure, we notice that the 3-dB bandwidth of each waveform is around 3 GHz. The Gaussian doublet has the best 3-dB bandwidth, which is 3.68 GHz. These UWB waveforms are almost uniformly distributed in a wide frequency spectrum, and thus they are similar to noise.      879   cid:2   x 105  1  0.5     t   y    0  −0.5  −1   −0.4   cid:2 Figure 20.5     20.4 Pulsed UWB     10−4     t   y    10−6  10−8  yGP yGM yGD  yGP yGM yGD  −0.2  0  t  ns   a   0.2  0.4  10−10    0  2  4  6  f  GHz    b   8  10  Gaussian pulse, monocycle, and doublet.  a  Time domain.  b  Frequency domain.  A UWB waveform may not cover the speciﬁed band. For example, the Gaussian pulse covers the frequency band from zero upwards, and the dc component is undesirable. A UWB waveform can be moved to a speciﬁed band with center frequency fc by mul- tiplying it by a sinusoid cos  2πfct . This method also eliminates the dc component in the Gaussian pulse.  Other useful UWB waveforms are orthogonal Hermite pulses and orthogonal prolate spheroidal wave functions  PSWFs  [22]. A set of PSWF pulses can be generated using a single-source signal, and they are suitable for M-ary communications; PSWF pulses of different orders are orthogonal to one another, and they have the same pulse width and the same bandwidth. In [30], the Rayleigh monocycle, Laplacian monocycle, cubic monocycle are also proposed as UWB waveforms. In order for the UWB waveforms to comply with the FCC’s spectrum mask, both ﬁltering and up-conversion have to be performed.  Generally, the spectrum bandwidth is the inverse of the pulse duration in the time domain, which is determined by the time scale factor τ in the case of Gaussian wave- forms. UWB pulses can be generated by using avalanche transistors, tunnel diodes, and step-recovery diodes [54].  20.4.2 Modulation and multiple access for pulsed UWB  Modulation  The modulation technique used in the pulsed UWB system is usually selected from PAM, PPM, OOK, or biphase modulation. These modulation techniques are illustrated in Fig. 20.6. Biphase modulation is usually treated as BPSK.  In binary PPM signaling, ‘1’ and ‘0’ are represented by a pulse without any delay and by a pulse with a delay relative to the time reference, respectively. For the M-ary PPM system, the set of time shifts for representing different symbols is speciﬁed. The orthogonal PPM      880   cid:2   Ultra wideband communications  Pulse interval  Time reference  PAM BPSK  Time shift  PPM  OOK   cid:2 Figure 20.6  ‘1’  ‘0’  Modulation techniques for pulsed UWB.  scheme uses UWB pulse shape that is orthogonal to its time-shifted version. These time shifts depend on the UWB pulse.  PAM modulates the bits using different amplitudes, OOK represents bits by the presence of a pulse, while biphase modulation denotes the bits using the pulse polarity. Orthogonal pulse modulation requires special pulse shapes that are orthogonal to one another.  PPM and biphase modulation are the most common techniques. Orthogonal pulse mod- ulation is useful for multiple access. PAM and OOK are rarely used. For PAM, a signal with smaller amplitude is more susceptible to noise interference than its larger amplitude counterpart, and also more power is required to transmit the higher amplitude pulse. For OOK, the presence of multipaths makes the determination of the absence of a pulse very difﬁcult. Also, OOK, like biphase modulation, cannot be extended to M-ary modulation.  Biphase modulation and binary PPM have similar performance, but OOK is inferior in error performance. However, the OOK signal can be detected by a simple energy detection scheme. On the other hand, PAM inherently provides smoother PSD than OOK and PPM, both generating discrete spectrum lines, which may become severe interference to existing narrowband radios.  Multiple access  Duty-cycled DSSS systems achieve the wideband capacity as long as the number of independently faded resolvable paths increases sublinearly with the bandwidth, whereas duty-cycled PPM systems can achieve this capacity only if the number of paths increases sublogarithmically [40]. The difference arises from the fact that DSSS is spectrally more efﬁcient than PPM and hence allows more bursty transmission.  For pulsed UWB, TH and DS spreading are two good multiple-access techniques. TH- UWB [48] utilizes low-duty-cycle pulses, where the time spreading between the pulses is used to provide time multiplexing of users. Typically, the pulses in TH-UWB have a duty cycle of about 1%. DS-UWB [14] utilizes high-duty-cycle pulses, whose polarities follow PN sequences.  Both TH- and DS-UWB techniques assign each user with a different PN sequence to encode the pulses in either position  for PPM  or polarity  for biphase modulation . Each bit is represented by using Nc pulses. Channelization is based on the codes. The spreading      881   cid:2   20.4 Pulsed UWB  leads to a processing gain Gp, which increases the effective SNR as the UWB signal is pro- cessed by a correlating receiver based on matched ﬁltering. For TH-UWB, the processing gain is given by [22]  Gp = Nc Tp Tf  ,   20.14   where Tp Tf is the duty cycle, Tp is the period of the pulse and Tf is the frame period.  TH-UWB works in a way very similar to PPM. It is actually a kind of PPM where a code sequence determines the times for the transmitter to key on and off. The major difference between PPM and TH-UWB lies in the fact that the former employs pulse position patterns to represent the data symbols, whereas the latter denotes a code sequence which is further used for decoding the data information.  The TH and DS multiple-access schemes have been compared for single-antenna sys- tems in [53]. It is shown that the TH-UWB system is suitable for analysis, but DS-UWB is more suitable for single-carrier UWB communications [52, 53]. THSS is not as popular as DSSS and FHSS, and this is due to the implementation difﬁculty in generating narrow impulses at nanosecond scale and providing very good timing accuracy.  Due to the technical difﬁculties associated with carrier sensing in UWB systems, CSMA is not effective for random access MAC. Slotted ALOHA may be used for UWB, but its inefﬁciency makes it unsuitable for high-speed data transmission. A channel-partition MAC such as hybrid TMDA CDMA is better suited for high-data-rate UWB networks. For control signaling, random access schemes such as slotted ALOHA can be used.  UWB technology is capable of accurate positioning, and this enhances the UWB MAC  performance as routing and power control can be simpliﬁed.  20.4.3 Time-hopping and direct-sequence UWB signals  A single pulse does not represent much information. Data needs to be modulated onto a sequence of pulses called a pulse train. A pulse train s t  can be written as   cid:7   ∞ cid:26   k=−∞  s t  =  t − kTf  p  ,   cid:8    20.15   where Tf is the pulse repetition or frame period, and p t  is the pulse shape. The resulting , k = 0, 1, 2, . . .. These spectrum lines spectrum contains spectrum lines at frequencies k Tf are called comb lines. Increasing the pulse rate 1 leads to an increase in the amplitude of Tf the frequency spectrum.  The pulsed-UWB system depends on the pulse train, since it is modulated in the time domain. Spectral lines occur for both PPM and time hopping. The spectral lines either violate the regulations, or require a power backoff. The powers of the comb lines can be reduced by dithering, which changes the regular pulse time of each pulse by a small random offset. When the offset is cyclic according to a known PN code {c k k = 0, 1, . . . , Nc − 1}, we get a TH-UWB system, where TH is also used for multiple access purpose. The frame interval Tf is divided into Nc segments of period Tc, and NcTs ≤ Tf .      882   cid:2   Ultra wideband communications  Randomization of the polarity of the transmitted symbols or pulses eliminates the spec- tral lines [36]. The use of long TH sequences makes synchronization more difﬁcult. Randomizing the polarity of each transmitted pulse without changing the pulse positions can solve this disadvantage. A polarity randomization sequence is used for this purpose. The symbol waveform is the combination of a TH sequence and a polarity randomization sequence.  The TH pulse train is written as x t  =  TH-UWB signals  ∞ cid:26    cid:7   t − kTf − c k Tc   cid:8    20.16  In a synchronous network, orthogonal TH sequences satisfy cu k   cid:18 = cu cid:14  k  for any two users u and u  to avoid collision.  k=−∞  p   cid:14   .  The TH pulse train can be combined with PAM, PSK, or PPM modulation to generate a  TH-UWB signal. With MPAM modulation, we have the TH-UWB signal  ∞ cid:26   x t  =   cid:7   t − kTf − c k Tc  am k p   20.17  where am k , m ∈ {0, 1, . . . , M − 1}, is the amplitude of the pulse carrying information m k . For BPSK modulation, am k  = ±1. With M-ary PPM modulation, the information is carried by the positions of the pulses  k=−∞  ,  x t  =  t − kTf − c k Tc − m k Td  ,  p   20.18    cid:8    cid:8    cid:7   ∞ cid:26   k=−∞  where Td is the modulation delay for PPM, and MTd ≤ Tf . TH impulse radio can be treated as a DS-CDMA system, where the spreading sequence has a large number of 0s and a small number of 1s. In comparison, the conventional DS-CDMA system uses spreading sequences that have an almost equal number of +1s or −1s. Due to this similarity, many results for DS-CDMA such as MUD can be applied to TH-UWB.  The processing gain of TH-UWB is very high. This offers an excellent multipath immu- nity since the high time resolution allows the separation and combination of all multipath components coherently at the receiver. The high processing gain ensures a low PSD, reducing interference to other existing systems.  DS-UWB signals   cid:7   4  In DS-UWB with BPSK modulation, transmitted over the kth frame interval c nc p   cid:8 nc = 0, 1, . . . , Nc − 1  t − kTf − ncTc  5 the binary symbol b k ∈{−1, 1} to be is spread by a sequence of Nc pulses, , where the polarities of the pulses are      883   cid:2   20.4 Pulsed UWB  determined by the spreading sequence {c nc  ∈ {−1, 1}nc = 0, 1, Nc − 1}, which is unique for each user.  The signal of DS-UWB with BPSK modulation can be written as [14] t − nTf − ncTc  c  nc  p  b n   ,  x t  = 1√ Nc  ∞ cid:26   n=−∞  Nc−1 cid:26   nc=0   cid:7    cid:8    20.19   where the hop period Tc is greater than the pulse period Tp  As in TH-UWB, modulation techniques such as PAM, OOK, and PSM can be used in DS-UWB. DS-UWB performs in a way similar to the DS-CDMA system. In the DS-UWB system, the ternary code is desirable, where the chips may take on a zero value, that is, a pulse may be absent. Ternary codes have more different codes available, leading to better code correlation properties.  The Ipatov ternary sequence has perfect periodic autocorrelation [26]: The periodic autocorrelation function is a train of equally spaced, equal amplitude impulses. Unlike the m-sequence that exists only for length 2m − 1, the Ipatov ternary sequence exists for many more lengths: 7, 13, 21, 31, 57, 63, 73, 91, 127, 133, 183, 273, 307, 341, 364, 381, 511, ··· . The lengths are typically of the form N2 − N + 1, but not all numbers of this type are represented. The Ipatov ternary sequence can be generated from cyclic difference sets [25].  In the DS-UWB proposal by UWB Forum for IEEE 802.15.3a, the modulation scheme is either BPSK or 4-ary biorthogonal keying  4-BOK . The ternary code is used in DS-UWB for acquisition.  A large family of UWB signals, including TH and DS signaling with pulse position, interval, and amplitude modulations, can be modeled by shot noise processes [43]. The exact power spectrum can be evaluated using shot noise spectral theory. Different features of the signal model contribute clearly and separately to the resulting spectral expressions.  20.4.4 Pulsed-UWB transceivers  Pulsed-UWB uses baseband pulse shapes having rise and fall times at the sub-nanosecond level. Such pulses have a broadband spectrum, ranging from near-dc to several gigahertz. The pulse shape is applied directly to a transmit antenna, without using upconversion. Spectral shaping can be performed by tuning the shape of the ultra-short duration pulse, or by tuning the loading parameters of the transmit antenna. Pulsed-UWB transmitters that are compatible with CMOS and other IC technology are described in [54].  The most attractive feature of pulsed-UWB technology is its low complexity and low cost. The simplest TH-UWB transmitter may just contain a pulse generator, a timing cir- cuit, and an antenna. The low complexity enables its inclusion in consumer electronics. For M-ary systems, a bit-to-symbol mapper is also required, and the symbols rather than bits are mapped to pulses. Precise timing circuitry is required, and is especially restricted for PPM. Pulses may be ampliﬁed before transmitting. FEC schemes may also be included in the system.      884   cid:2   Ultra wideband communications  LNA  AGC  ADC  Correlator  Demodulator  Output  DSP  Control  Clock  generator  DAC   cid:2 Figure 20.7  Block diagram of a digital pulsed-UWB receiver.  The block diagram of a general digital pulsed-UWB receiver is shown in Fig. 20.7. The correlator and control circuitry is used for acquisition and tracking of the required pulses among the other signals. The correlation receiver, also known as matched ﬁlter, is the optimal receiving technique. The correlator multiplies the received pulse by a template waveform, and then integrates the output over the duration of the pulse to generate a single dc voltage, from which the relative time positions are estimated for PPM. The template waveform is generated by using the pulse generator. For a multipath indoor channel, the matched ﬁlter receiver becomes the rake receiver.  The DS-UWB receiver has a structure similar to that of the general pulsed-UWB struc- ture shown in Fig. 20.7, except that a code correlator, followed by Viterbi decoder and descrambler, is implemented in the demodulator block. The channel correlator  matched ﬁlter  and the code correlator are two linear operations, and their order can be swapped. This results in a modiﬁcation of the other components.  Since the noise signal has zero correlation after pulse integration, the UWB receiver can acquire, track, and demodulate UWB signals that are signiﬁcantly below the noise ﬂoor. The demodulator performs pulse-to-symbol mapping, and a symbol-to-bit mapper may be required for M-ary systems. The matched ﬁlter is often implemented as a rake receiver for multipath demodulation. A bandpass ﬁlter is usually used ahead of the LNA to remove any out-of-band interference.  Intel’s pulsed-UWB proposal for IEEE 802.15.3a considers a bandwidth of 7.26 GHz. Its PPM transceiver has direct RF sampling and a 20-GHz 1-bit ADC with 1,280 parallel digital matched ﬁlters. Tunable notch ﬁlters are used for pulse shaping at the transmitter [2]. XtremeSpectrum  now a part of Freescale Semiconductor  proposed the DS-UWB sys- tem for IEEE 802.15.3a in May 2003 [56]. The Ipatov ternary sequence is used in the proposal. The DS-UWB transmitter ﬁrst scrambles the transmit data to remove any cor- relation between adjacent bits. These scrambled bits are then coded with a convolutional code. The coded bits are then mapped into symbols, which are fed into the pulse generator to generates chips. If a chip is positive, a pulse is transmitted; for a zero chip, no pulse is transmitted; for a negative chip, a negative pulse is transmitted. The pulse has a spectral shape close to the desired ﬁnal shape. The generated pulse train is subject to a bandpass ﬁlter to ﬁne-tune the spectral shape, and is then passed to the antenna.  Pulsed UWB such as TH-UWB and DS-UWB spreads each information bit across the whole bandwidth in use, thus high attenuation at some frequencies is not very detrimental.      885   cid:2   20.4 Pulsed UWB  The high processing gain also helps to alleviate this problem, and it enables great immunity to distortion and noise. The noise can be a large quantization noise, which in turn allows a relatively low precision of the receiver’s ADC. DS-UWB has a lot in common with TH-UWB.  A comprehensive introduction of various UWB receiver architectures designed for  different modulation formats and signaling schemes is given in [2].  20.4.5 Challenges for pulsed UWB systems  The pulsed UWB signal can be detected by using conventional receivers. The rake receiver and the matched ﬁlter receiver require channel estimation. Differential detection [9], trans- mitted reference  TR  receivers [9, 17, 44], and differential TR receivers [9] do not need channel estimation. A matched ﬁlter is equivalent to a rake receiver with inﬁnite ﬁngers and perfect channel estimation. For differential detection systems, the symbols are differ- entially encoded, and each received data pulse is correlated with the previous one. Each pulse serves as a template for the next. Whatever the receiver architecture, a synchroniza- tion circuit must provide accurate information on the arrival times of the incoming pulses. This poses a serious challenge to UWB radios.  Single-band pulsed UWB has an inﬂexible spectrum mask. It also requires very wide- band circuitry that introduces difﬁculties in implementation, especially in RF-CMOS implementation, and high sampling rates in DACs and ADCs. As with DS-CDMA, a strong interferer may block the wanted signal. The single-band system is more sensitive to ISI. Multiband UWB is a better choice. Multiband UWB can be implemented as a pulsed multi- band or an MB-OFDM UWB. The multiband system needs an FH strategy for interference avoidance.  For a given data rate, the thermal noise of the single-band system, which is calculated  by N = −174+ 10 log10 B dBm with B being the bandwidth, is several dB higher than that  of the multiband system. The signal power is increased by the same amount, and thus the SNR is the same. In the single-band system, this has to be performed by using notch ﬁlters which, however, increase the noise ﬁgure of the receiver. The notch ﬁlter adds cost to the unit, and is not easily tunable. The multiband system can adaptively select sub-bands to provide good interference rejection, and thus is easier to implement.  An optimum UWB receiver is a matched ﬁlter plus the optimum MLSE detector  Viterbi algorithm . When implementing matched ﬁltering, it is most difﬁcult to generate exact pulses at the exact time at the receiver. A train of wider rectangular pulses coded with the same PN sequence is usually used as the template signal. A suboptimum receiver uses a generalized rake receiver structure, plus suboptimum equalizers such as zero-forcing equalizers. For example, the DS-UWB proposal of IEEE 802.15.3a adopts a rake receiver structure plus MMSE equalizer.  There are critical requirements on the ADC for the single-band pulsed-UWB system. The ADC must have a sampling rate of a few gigasamples s. For a mimimal bandwidth of 500 MHz, the ADC must support a sampling rate at gigahertz level. As the received UWB signals are commonly immersed in noise or interference, an ADC with a few bits      886   cid:2   Ultra wideband communications  is sufﬁcient [37]. However, the ADC needs a resolution greater than 4 bits to resolve sig- nals from narrowband radios [46]. A typical solution is an interleaved ﬂash ADC [13], where each channel is based on a ﬂash converter; such an ADC consumes power at a scale that increases exponentially with bit precision. precision. MAXIM-Dallas provides the MAX108 chip, which is an 8-bit ADC with a sampling rate of 1.5 Gsamples s, and the MAX19693, which is a 12-bit, 4.0 Gsamples s DAC.  Synchronization and timing are extremely important for almost all of the pulsed-UWB receiver techniques  with the exception of the threshold detector receiver . Particularly, with synchronization error, correlation-based receivers will have a dramatic drop in the SNR at the receiver output. Most synchronizers are based on the ML principle that requires a clean template of the received pulse. However, the clean template is not avail- able when the multipath channel is unknown. Dirty template based algorithms exploit the unique maximum of the cross-correlation of dirty templates extracted from the received waveform [58]. Relying on symbol-rate samples and integrate-and-dump operations, the algorithms ensure rapid synchronization by collecting multipath energy without knowl- edge of the channel. Compared to the nondata-aided mode, the data-aided mode expedites the synchronization and also enables timing in a multiuser environment. Dirty template synchronization algorithms have been developed for multiaccess PAM-UWB systems [58] and multiaccess PPM-UWB systems [57].  For implementation of single-band UWB, transmitter pulse shaping may have to be per- formed by purely analog ﬁltering, since the computational complexity is daunting for using digital ﬁltering. However, analog ﬁltering reduces the available accuracy and repeatability of the transmitted pulse shape.  An additional constraint on the input impedance is placed on the LNA. It is in gen- eral difﬁcult to design the LNA to minimize the effective noise ﬁgure subject to the input impedance requirement across the entire frequency band. Recent UWB LNAs that are based on CMOS technology can provide about 10–15 dB power gain with power consumption of around 10 mW over the speciﬁed UWB bandwidths [46].  The performance of the UWB antenna is also important for the UWB system. The antenna induces dispersion, which is often due to frequency dependence of material param- eters such as permittivity. The antenna is a major source of distortion for time-domain pulses. Pulse distortion can be compensated by equalization.  20.4.6 Rake receivers  The rake receiver is a popular coherent receiver for pulsed UWB systems. The rake receiver needs to collect the rich multipath diversity: It needs to estimate the arrival time, the amplitude, and the phase of each multipath component. The detection performance critically depends on accurate estimation of channel tap coefﬁcients and time delays. Syn- chronization becomes extremely difﬁcult. The total number of multipath components for a UWB channel is signiﬁcantly greater than that for a narrowband channel in a typical indoor environment, due to the large bandwidth of UWB. In an indoor environment, each pulse generates hundreds of resolvable multipath echoes, and this requires a large number      887   cid:2   20.4 Pulsed UWB  of ﬁngers to capture a signiﬁcant part of the signal energy [33], causing a formidable complexity.  The very large bandwidth also leads to the high power consumption of an ADC which, following the Nyquist theorem, must operate at a rate of several Gsamples s. It also causes the distortion that each path undergoes due to the frequency selectivity of the propagation environment. The channel estimation can be data-aided or non-data-aided by using an ML approach [33].  In typical UWB scenarios, the available number of MPCs at the receiver is often more than 100 [7]. Typically, 20 or more rake ﬁngers are necessary to get a satisfactory per- formance. This places strong restriction on the equalizer and the rake receiver, since the complexity of a rake receiver increases exponentially with the number of multipath components. A reduced complexity rake receiver can be used by [7, 8]:   Maximum selection. Select the L instantaneously strongest paths of L1 resolvable paths.   Partial selection. Select the ﬁrst L nonzero arriving paths.   Threshold selection. Select the ﬁrst L paths the magnitudes of the gains of which are greater than a threshold.  This reduction in implementation complexity is achieved at the price of performance loss. For dense channels, the simpler partial selection rake scheme is almost as good as the maximum selection rake scheme in terms of bit error probability, even for a small number of ﬁngers. In sparse channels, however, the maximum selection rake outperforms the partial selection rake signiﬁcantly [8].  A pilot-channel-assisted LLR selective combining  PCA-LLR-SC  scheme for UWB rake receivers was proposed in [11] for long-range low-rate applications targeted by the IEEE 802.15.4a. The pilot and data channels are constructed using quadrature sinu- soidal bursts that have the same Gaussian envelope. The system parameters are optimized through jointly minimizing the channel estimation mean square error and maximizing the receiver output SNR. The PCA-LLR-SC scheme is capable of providing robust low-rate UWB communications in fast-fading multipath channels and in the presence of multi-user interference.  20.4.7 Transmitted-reference receivers  TR system model  The TR system was originally proposed for spread-spectrum communications [9, 17, 44], but it did not gain popularity, since accurate channel estimation can be achieved by using rake receivers [17]. The TR receiver is a noncoherent receiver, and channel estimation is not required. It is regaining popularity in UWB communications, as accurate channel estimation is very challenging in this case.  In the TR scheme, a reference pulse, which is known to the receiver, is sent prior to each data pulse for channel sounding. This is based on the assumption of a constant channel over the symbol duration. The channel response to the former is exploited as a template for the latter. At the receiver, the received reference pulse is used as signal template for the      888   cid:2   Ultra wideband communications  data demodulation using correlation. Using an autocorrelation receiver, the total energy of all the multipath components is gathered to detect the signal. TR receivers collect full multipath diversity without channel estimation, and are robust to small timing offsets. A single sample may be sufﬁcient to detect one data symbol. The mechanism can be improved by averaging the channel responses from several reference pulses [9, 17]. TR systems are robust to pulse distortions.  The TR receiver is a correlation receiver employing template signals, which are a noisy  version of the channel response, followed by thresholding. The estimated symbol is   cid:17    cid:18   ˆaj = sgn  ˆhj  rT j  ,  j = Nt, . . . , Ns − 1,   20.20   where ˆhj and rj are, respectively, the template signal and the vector of received samples for  the jth data symbol.     Nt−1 cid:26   Training-based TR systems construct their template signal by combining only the  received signal corresponding to the training symbols  ˆhTB = ˆhj =  Nf EtNt   20.21  where Ei is the energy of the ith symbol, {ai} are the information symbols taking values ±1 with equal probability, Nf is the number of frames per symbol, Nt is the number of training symbols, and Ns is the number of symbols.  i=0  airi,  The TR receiver has to face noise enhancement. Since both the reference and data pulses experience the same noisy channel, the correlating operation over the full frame or symbol period accumulates  and colors  the noise. To improve the tradeoff between energy capture and noise accumulation, oversampling can be applied to take multiple samples per frame by speeding up the integrate and dump operation. Sparse channel responses with large delay spreads that are typical of UWB signals necessitate a long correlator integration time, lead- ing to the collection of more noise energy. The TR scheme suffers from MAI and a data rate loss. Transmission of the reference symbol causes a power penalty of 3 dB. Large timing errors need to be compensated prior to transmit reference detection. A statistical analysis of the narrowband interference to the TR scheme has been made in [1]. The interference signals can be efﬁciently suppressed by using linear LS and MMSE combiners [1].  The TR scheme is often considered a low-data-rate scheme because of implicit assump- tions that the pulse spacing D in a doublet should be longer than the channel length Th to prevent inter-pulse interference, and the frame period Tf should be chosen such that there is no inter-frame interference, leading to Tf > 3Th [12]. A TR scheme that uses integrate and dump with oversampling was proposed in [12] to enable higher data rates in a multiuser context. Multiple reference delays are used to further improve the system performance similar to the role of multiple antennas in communication systems.  The performance of the TR scheme in the UWB channel has been derived in [39], where the fading of each resolvable multipath component is characterized by Nakagami distribution. Based on the derivation of exact and approximated expressions for the pdf of the output SNR, closed-form expressions for average SNR, amount of fading, out- age probability, and average BEP of the receiver are given. In [29], the SEP analysis of      889   cid:2   20.4 Pulsed UWB  multiuser TH-UWB systems employing M-ary PPM and a correlation receiver in the pres- ence of MAI and timing jitter is performed by using the Gaussian quadrature rules  GQR  method.  Two timing recovery algorithms for UWB communications have been proposed in [6]. The algorithms exploit the samples of the received signal to estimate frame timing and symbol timing. Channel estimation comes out as a by-product and can be used for coher- ent matched ﬁlter detection. Both algorithms require sampling rates in the order of the inverse of the pulse duration. In [19], a semiblind ML-based synchronization scheme for recovering both symbol and frame timing has been developed. The proposed algorithm performs joint timing and channel estimation, and the impact of a low resolution ADC is shown to be marginal.  A balanced TR signaling scheme that combines the dual pulse with M-ary orthogonal encoding is designed in [27]. This approach mitigates both the inter-pulse interference and the MAI by increasing the frame time without sacriﬁcing the data rate. A closed-form expression for the averaged SINR is derived for such systems in a realistic and standard UWB channel in [28].  Signals designed for both coherent and TR receivers  The TR signal can be demodulated with a coherent receiver, by simply throwing away the reference pulses. This, however, causes a 3-dB signal energy penalty compared to a sig- nal that is designed for coherent receivers only. On the other hand, signals designed for coherent receivers cannot be demodulated by a TR receiver. A hybrid modulation method proposed in [60] enables coherent rake receivers and TR receivers in the same wireless net- work to simultaneously receive the signal. The key idea is to embed information into the reference pulse, without modifying the phase relationship between the reference pulse and the data pulse, since this phase relationship is critical for the TR receiver operation. This makes sure that the energy in the reference pulse is not wasted for the coherent receiver, and recovers the 3-dB loss by the normal TR receiver. Furthermore, we let the information in the reference pulse depend on the previous information symbol. The proposed signal- ing scheme is applicable not only to pulsed UWB systems, but also to narrowband or conventional spread spectrum systems.  Generalized TR receivers  To reduce this power penalty due to the reference symbol, a block of symbols that con- tains fewer reference symbols than data symbols can be transmitted, giving the generalized TR receiver [10, 18]. ML- and generalized likelihood ratio test  GLRT -based receivers for UWB systems operating in a dense multipath channel exploiting training signals are derived in [18]. Performance gains of 3 and 4 dB for the ML and GLRT schemes in com- parison to the training-based receiver have been observed. A 4-bit ADC in combination with an optimal choice for the AGC gain can provide a performance close to that of an inﬁnite resolution ADC for the classical training-based receiver and the GLRT receiver, whereas an ADC with less than 3 bits introduces a substantial performance degradation      890   cid:2   Ultra wideband communications  [20]. In [10], three simple generalized TR receivers are derived by optimally combining the channel estimates using the reference symbols, the data decisions and the data symbols. These receivers outperform the receivers proposed in [18].  20.5 Multiband UWB  The traditional TH-UWB scheme faces a number of difﬁculties for implementation. On the other hand, due to the technical maturity of DS-CDMA and OFDM, the DS-UWB and MB-OFDM UWB schemes are more popular. For UWB communications, DS-UWB is preferred for low-data-rate systems, while MB-OFDM UWB is preferred for high-data-rate systems. For example, IEEE 802.15.4a employs the DS-UWB scheme; IEEE 802.15.3a has an MB-OFDM UWB proposal and a DS-UWB proposal, but favors the MB-OFDM scheme. For location purpose, short pulsed UWB is preferred. PulsON is a UWB chipset developed by Time Domain Corporation to enable precise location services.  In the UWB system, there is ISI caused by multipath delays. For DS-UWB, inter- path interference may be caused by multipath components received within the observation window of a particular symbol. There is a high probability of collision for TH-UWB.  Multiband UWB enables digital ﬁltering for transmitter pulse shaping, although the computation load is still very high. Information can be processed over a much smaller bandwidth, reducing the complexity of design and the power consumption, and improving spectral ﬂexibility and worldwide compliance. Multiband UWB also allows the transmit power in each sub-band to be independently managed. The multiband approach can deal with both in-band and out-of-band interference rejection.  Multiband schemes for IEEE 802.15.3a  IEEE 802.15.3a employs a multiband UWB scheme for spectrum ﬂexibility and easy implementation. It can be either a pulsed multiband DS-UWB scheme or an MB-OFDM scheme.  The IEEE 802.15.3a Task Group consolidated 26 UWB PHY speciﬁcations into two pro- posals: MB-OFDM UWB, supported by the WiMedia Alliance, and DS-UWB, supported by the UWB Forum. Due to the conﬂiction between the two different industrial alliances, IEEE 802.15.3a project authorization request  PAR  was withdrawn on January 19, 2006. Pulsed multiband UWB transmission is actually composed of many single-band UWB transmissions. The receiver structures for single-band UWB pulses are also applicable to these single-band UWB transmissions on the sub-bands. The pulsed multiband approach has a small design complexity and reduced power consumption, but it has the difﬁculties of collecting signiﬁcant multipath energy using a single RF chain, sensitivity of group delay variations introduced by the analog front-end components, and stringent frequency- switching time requirements.  MB-OFDM UWB [3] uses OFDM symbols to convey the information on each of the sub-bands and interleaves them across all the sub-bands. MB-OFDM UWB avoids the      891   cid:2   20.5 Multiband UWB  disadvantages of pulsed multiband UWB: it has the ability to capture multipath energy using a single RF chain, it is insensitive to group delay variations, and has a relaxed frequency-switching time requirement. Compared to the pulsed multiband approach, the MB-OFDM approach has a slightly more complex transmitter due to the inverse DFT operation, and a higher PAPR.  A dual-antenna UWB CMOS transceiver for the MB-OFDM proposal of IEEE 802.15.3a was developed by Tzero Technologies [49]. XtremeSpectrum, which is now a part of Freescale Semiconductor, developed the XS100 TRINITY chipset for the DS-UWB proposal of IEEE 802.15.3a. Many other vendors including Intel also produce their standard-based UWB solutions. In addition, Pulse∼LINK provides its proprietary CWave solution, which achieves data rates up to 1 Gbits s over coax and wireless networks from the same chipset based on continuous pulse UWB technology.  20.5.1 Modulation of pulsed multiband UWB  For pulsed multiband UWB modulation, the UWB pulse must be shaped to the speciﬁed bandwidth of each sub-band. The pulses must be modulated to each band with different center frequencies. Multiple UWB pulses on different sub-bands can be transmitted at the same time. Modulation to sub-band i with carrier fi can be achieved by mixing a sinusoidal signal  2yGP t  cos  2πfit  .  The Fourier transform is given by Si  f   = 1√ 2  YGP   f − fi  + TGP   f + fi   .   cid:20   si t  = √  cid:19    20.22    20.23   By removing the unwanted band, we get the modulated pulsed UWB signal. When signals at many different bands are transmitted simultaneously, we have  s t  = NB cid:26   i=1  si t  = √  NB cid:26   i=1  2yGP t   cos  2πfit  ,   20.24   where NB is the number of bands. The resulting spectrum is spread over the full frequency band. When a band is interfered by other sources, that band is just not used. This leads to a null in the spectrum.  20.5.2 MB-OFDM UWB  MB-OFDM is now the leading technology for use in high-speed wireless UWB communi- cations. It is supported by WiMedia and ECMA. In the ECMA standard, the 7.5 GHz UWB spectrum is divided into 14 sub-bands, each having a bandwidth of 528 MHz. This is also applicable for the MB-OFDM proposal of IEEE 802.15.3a. For each sub-band of 528 MHz, OFDM is applied with 128 subcarriers. Among the 128 subcarriers, 100 are used for data transmission, 12 as pilot subcarriers, 10 as guard subcarriers, and 6 are unused by setting      892   cid:2   Ultra wideband communications  them to zero. The subcarrier bandwidth in each sub-band is  cid:18 f = 528 128 = 4.125 MHz, and the FFT period is 1  cid:18  = 242.42 ns. The guard interval is 9.5 ns, and the preﬁx length is 60.6 ns. This yields an OFDM symbol length of 242.42 + 9.5 + 60.6 = 312.5 ns. QPSK is used to modulate the symbols to be transmitted at each subcarrier. The use of QPSK is due to the limitation of the transmitter power, which must be lower than −41.3 dBm MHz. The MB-OFDM proposal for IEEE 802.15.3a suggests the use of only three sub-bands below the 5-GHz band as a mandatory mode. This mandatory mode supports eight dif- ferent data rates ranging from 53.3 to 480 Mbits s, which are obtained by using different channel coding rate, frequency spreading gain, or time spreading gain. Depending on the data rate, QPSK or dual-carrier modulation  DCM  constellation is used. The BER of the MB-OFDM UWB system is analyzed and simulated in [52]. Multiple access is achieved by using different preambles and time-frequency codes  associated with sub-bands  for differ- ent users [3]. For zero-padded MB-OFDM UWB systems, preamble-based low complexity algorithms for synchronization, channel estimation and equalization have been presented in [32].  For simple UWB transceiver, the MB-OFDM proposal for IEEE 802.15.3a assumes that there is no bit loading and that power is equally distributed across subcarriers within each sub-band. A sub-band assignment and power allocation algorithm is given for power- controlled channel allocation [51, 52]. Based on the IEEE 802.15.3a UWB channel models, performance analysis of MB-OFDM UWB systems is performed in [31], with considerations of imperfect frequency and timing synchronizations and the effect of ISI.  The MB-OFDM solution is very similar to the conventional wireless OFDM scheme, but with many measures that reduce the implementation complexity. A time-frequency code is used to transmit different OFDM symbols on different bands. This provides frequency diversity, but also enables multiple access between piconets operating in the same vicinity [4]. OFDM is used to modulate the information in each sub-band so as to capture the mul- tipath energy efﬁciently. The smaller bandwidth of each sub-band eases the requirement on the sampling rate of the ADC.  The channel characteristics in the conventional OFDM system and in the MB-OFDM UWB one are quite different. Channels in the conventional OFDM system are less dis- persive than those in the MB-OFDM UWB system, since the latter has a much larger bandwidth. Multipath channel coefﬁcients in the conventional OFDM system are Rayleigh distributed, while those in the MB-OFDM UWB system are independent log-normally distributed [15].  Antenna dispersion faced by pulsed-UWB is not a problem for OFDM-based UWB. In the MB-OFDM UWB system, the linearity of the phase response over the entire UWB band is not important as long as the bandwidth of each subchannel is sufﬁciently small. Also, OFDM is normally used in multipath environments, where the multipath delay spread is much higher than any time delays created by the antennas.  For the purpose of detection and avoidance  DAA , at the MB-OFDM transmitter, the most common technique for frequency notching is to zero out tones that overlap the inter- fering bands at the FFT stage to achieve notches in the transmit spectrum. There is no increase in the transmitter complexity. At the receiver, tones carrying no information show a deep frequency notch. To achieve a desired notch depth, multiple tones have to be zeroed      893   cid:2   Problems  out. A deeper notch can be obtained by inserting data-speciﬁc dummy tones that are subject to a constraint on the amount of energy on either side of the interfering band; this method sacriﬁces fewer tones in order to achieve a notch-speciﬁc depth [4].  Pulsed-OFDM is an enhancement to an MB-OFDM system by combining some of the beneﬁts of the pulsed UWB systems with those of the OFDM UWB systems [45]. It has a performance superior or comparable to MB-OFDM in multipath fading channels, and also has intrinsic low-complexity and power consumption advantages compared with MB-OFDM.  In [50], the performance of the MB-OFDM MIMO UWB system is analyzed in case of Nakagami frequency-selective fading channels. The maximum achievable diversity is shown to be the product of the numbers of transmit  Nt  and receive  Nr  antennas, the number of multipath components L, and the number of jointly encoded OFDM symbols [50]. In [55], a general STFC MB-OFDM UWB model is proposed, and is analyzed in case of the log-normally distributed multipath channel coefﬁcients. The maximum achievable diversity order is found to be the product of Nt, Nr, and the FFT size.  Impact of timing jitter  Nonideal sampling clocks in OFDM-based UWB systems introduce random timing jitter, which results in ICI. For OFDM-based UWB systems, the ICI for a system with white timing jitter is bounded by [38] π 2 BσJ 2   cid:6    cid:5   1 − 3π 2 BσJ 2  10  ≤ PJ σ 2 s  ≤ π 2 3   BσJ 2,  3   20.25   where PJ is the average ICI power caused by timing jitter, σ 2 s is the variance of the symbol transmitted on each subcarrier, B is the bandwidth of a sub-band of at least of 500 MHz, and σ 2  J is the variance of the timing jitter. σJ is typically 10 to 150 ps.  For correlated jitters, the ICI power is in general subcarrier-dependent, but the average  ICI power over all subcarriers is given by [38] = 1 3  PJ σ 2 s  π 2 BσJ 2   20.26   which is independent of the correlation coefﬁcients of the timing jitters. Therefore, the correlation between timing jitters does not change the overall ICI power.  A universal upper bound on the ICI power due to colored timing jitter is given in [38]. The impact of timing jitter can be reduced by oversampling. In case of uncorrelated jitters, oversampling by M can reduce the ICI power by a factor of M [38].  Problems  20.1 Using  20.24 , plot the spectrum when six different frequencies, 4, 5, 6, 7, 8, 9 GHz, are utilized for modulating Gaussian pulses, where τ = 0.5 ns. Also, plot the spectrum if      894   cid:2   Ultra wideband communications  20.2 Consider a UWB signal s t  = cid:24 ∞  the frequency of 5 GHz is not used. In order to create a deep null at 5 GHz, one can select a proper value of τ and divide the UWB band into more sub-bands. Show this by illustration.  i=−∞ akp t−kTf  , where p t  is the Gaussian pulse given by  20.6 , the frame period Tf is larger than the pulse width, and ak is uniformly ran- domly distributed on {−1,+1}. Calculate the average PSD. For τ = 0.4 ns, Tf = 100 ns, calculate the maximum value of K1 in  20.6  such that the average PSD of s t  is less than −41.25 dBm Hz. 20.3 The average ICI power for an OFDM-based UWB system is given by  20.25  for white timing jitters and by  20.26  for correlated jitters. Assume that σJ is 80 ps, and B = 528 MHz. Plot the average ICI power as a function of BσJ.  References  [1] Y. D. Alemseged & K. Witrisal, Modeling and mitigation of narrowband interfer- ence for transmitted-reference UWB systems. IEEE J. Sel. Topics Signal Process., 1:3  2007 , 456–469.  [2] A. Annamalai, S. Muthuswamy, D. Sweeney, R. M. Buehrer, J.  Ibrahim, C. R. Anderson & D. S. Ha, Receiver design principles. In J. H. Reed, ed., An Intro- duction to Ultra Wideband Communication Systems  Upper Saddle River, NJ: Prentice Hall, 2005 , 253–377.  [3] A. Batra et al, Multi-band OFDM Physical Layer Proposal for IEEE 802.15 Task  Group 3a, IEEE P802.15-03 268r2, Nov 2003.  [4] J. Balakrishnan & A. Batra, Multiband OFDM. In R. Aiello & A. Batra, eds., Ultra  Wideband Systems  Oxford, UK: Elsevier, 2006 , 211–247.  [5] R. M. Buehrer, Channel Modeling. In J. H. Reed, ed., An Introduction to Ultra Wideband Communication Systems  Upper Saddle River, NJ: Prentice Hall PTR, 2005 .  [6] C. Carbonelli & U. Mengali, Synchronization algorithms for UWB signals. IEEE  Trans. Commun., 54:2  2006 , 329–338.  [7] D. Cassioli, M. Z. Win & A. F. Molisch, The ultra-wide bandwidth indoor chan- nel: from statistical model to simulations. IEEE J. Sel. Areas Commun., 20:6  2002 , 1247–1257.  [8] D. Cassioli, M. Z. Win, F. Vatalaro & A. F. Molisch, Low complexity rake receivers  in ultra-wideband channels. IEEE Trans. Wireless Commun., 6:4  2007 , 2007.  [9] Y.-L. Chao & R. Scholtz, Optimal and suboptimal receivers for ultra-wideband trans- mitted reference systems. In Proc. IEEE GLOBECOM, San Francisco, CA, Dec 2003, 6, 759–763.  [10] Y. Chen & N. C. Beaulieu, Improved receivers for generalized UWB transmitted  reference systems. IEEE Trans. Wireless Commun., 7:2  2008 , 500–504.  [11] X. Chu, R. Murch, J. Liu & M. Ghavami, Selective rake combining for low-rate ultra-  wideband communications. IEEE Trans. Commun., 56:8  2008 , 1313–1323.      895   cid:2   References  [12] Q. H. Dang & A.-J. van der Veen, A decorrelating multiuser  for transmit-reference UWB systems. IEEE J. Sel. Topics Signal Process., 1:3  2007 , 431–442.  receiver  [13] W. Ellersick, C. K. K. Yang, W. Horowitz & W. Dally, GAD: a 12GS s CMOS 4-bit A D converter for an equalized multi-level link. In Proc. IEEE Symp. VLSI Circ., Kyoto, Japan, Jun 1999, 49–52.  [14] J. R. Foerster, The performance of a direct-sequence spread ultrawideband system in the presence of multipath, narrowband interference, and multiuser interference. In Proc. IEEE UWBST, Baltimore, MD, May 2002, 87–91.  [15] J. R. Foerster, Channel Modeling Sub-committee Final Report, IEEE P802.15-  02 490r1-SG3a, IEEE P802.15 Working Group for WPAN, Oct 2005.  [16] A. Fort, J. Ryckaert, C. Desset, P. De Doncker, P. Wambacq & L. Van Biesen, Ultra- wideband channel model for communication around the human body. IEEE J. Sel. Areas Commun., 24:4  2006 , 927–933.  [17] S. Franz & U. Mitra, On optimal data detection for UWB transmitted ref- erence systems. In Proc. IEEE Globecom, San Francisco, CA, Dec 2003, 2, 744–748.  [18] S. Franz & U. Mitra, Generalized UWB transmitted reference systems. IEEE J. Sel.  Areas Commun., 24:4  2006 , 780–786.  [19] S. Franz, C. Carbonelli & U. Mitra, Joint semi-blind channel and timing estimation for generalized UWB transmitted reference systems. IEEE Trans. Wireless Commun., 6:1  2007 , 180–191.  [20] S. Franz & U. Mitra, Quantized UWB transmitted reference systems. IEEE Trans.  Wireless Commun., 6:7  2007 , 2540–2550.  [21] S. S. Ghassemzadeh, R. Jana, C. W. Rice, W. Turin & V. Tarokh, A statistical path loss model for in-home UWB channels. In Proc. IEEE UWBST, Baltimore, MD, May 2002, 71–74.  [22] M. Ghavami, L.B. Michael & R. Kohno, Ultra Wideband: Signals and Systems in  Communication Engineering, 2nd edn  Chichester, UK: Wiley, 2007 .  [23] S. Glisic, Advanced Wireless Communications: 4G Technologies, 2nd edn   Chichester, UK: Wiley-IEEE, 2007 .  [24] H. Hashemi, Impulse response modeling of indoor radio propagation channels. IEEE  J. Sel. Areas Commun., 11:7  1993 , 967–978.  [25] T. Hoholdt & J. Justesen, Ternary sequences with perfect periodic autocorrelation.  IEEE Trans. Inf. Theory, 29:4  1983 , 597–600.  [26] V. P. Ipatov, Ternary sequences with ideal autocorrelation properties. Radio Eng.  Electron. Phys., 24  1979 , 75–79.  [27] D. I. Kim & T. Jia, M-ary orthogonal coded balanced ultra-wideband transmitted-  reference systems in multipath. IEEE Trans. Commun., 56:1  2008 , 102–111.  [28] D. I. Kim, Multiuser performance of M-ary orthogonal coded balanced UWB  transmitted-reference systems. IEEE Trans. Commun., 57:4  2009 , 1013–1024.  [29] N. V. Kokkalis, P. T. Mathiopoulos, G. K. Karagiannidis, and C. S. Koukourlis, Perfor- mance analysis of M-ary PPM TH-UWB systems in the presence of MUI and timing jitter. IEEE J. Sel. Areas Commun., 24:4  2006 , 822–828.      896   cid:2   Ultra wideband communications  [30] C. J. Le Martret & G. B. Giannakis, All-digital PAM impulse radio for multiple-access through frequency-selective multipath. In Proc. IEEE Globecom, San Francisco, CA, Nov–Dec 2000, 1, 77–81.  [31] H.-Q. Lai, W. P. Siriwongpairat & K. J. R. Liu, Performance analysis of multiband OFDM UWB systems with imperfect synchronization and intersymbol interference. IEEE J. Sel. Topics Signal Process., 1:3  2007 , 521–534.  [32] Y. Li, H. Minn & R. M. A. P. Rajatheva, Synchronization, channel estimation, and equalization in MB-OFDM systems. IEEE Trans. Wireless Commun., 7:11  2008 , 4341–4352.  [33] V. Lottici, A. N. D’Andrea & U. Mengali, Channel estimation for ultra-wideband  communications. IEEE J. Sel. Areas Commun., 20:12  2002 , 1638–1645.  [34] A. F. Molisch, J. R. Foerster & M. Pendergrass, Channel models for ultrawideband  personal area networks. IEEE Wireless Commun., 10:6  2003 , 14–21.  [35] A. F. Molisch et al., Status of Models for UWB Propagation Channel, IEEE 802.15.4a  Channel Model  Final Report , 2005, IEEE doc: IEEE 802.15-04-0662-02-004a.  [36] Y.-P. Nakache & A. F. Molisch, Spectral shaping of UWB signals for time-hopping  impulse radio. IEEE J. Sel. Areas Commun., 24:4  2006 , 738–744.  [37] P. P. Newaskar, R. Blazquez & A. P. Chandrakasan, A D precision requirements for an ultra-wideband radio receiver. In Proc IEEE SIPS, San Diego, CA, Oct 2002, 270–275.  [38] U. Onunkwo, Y. G. Li & A. Swami, Effect of timing jitter on OFDM-based UWB  systems. IEEE J. Sel. Areas Commun., 24:4  2006 , 787–793.  [39] M. Pausini & G. J. M. Janssen, Performance analysis of UWB autocorrelation receivers over Nakagami-fading channels. IEEE J. Sel. Topics Signal Process., 1:3  2007 , 443–455.  [40] D. Porrat, D. N. C. Tse & S. Nacu, Channel uncertainty in ultra-wideband communi-  cation systems. IEEE Trans. Inf. Theory, 53:1  2007 , 194–208.  [41] T. S. Rappaport, Wireless Communications: Principles & Practice, 2nd edn  Upper  Saddle River, NJ: Prentice Hall, 2002 .  [42] P. C. Richardson, W. Xiang & W. Stark, Modeling of ultra-wideband channels within  vehicles. IEEE J. Sel. Areas Commun., 24:4  2006 , 906–912.  [43] A. Ridolﬁ & M. Z. Win, Ultrawide bandwidth signals as shot noise: a unifying  approach. IEEE J. Sel. Areas Commun., 24:4  2006 , 899–905.  [44] C. K. Rushforth, Transmitted-reference techniques for random or unknown channels.  IEEE Trans. Inf. Theory, 10:1  1964 , 39–42.  [45] E. Saberinia, J. Tang, A. H. Tewﬁk & K. K. Parhi, Pulsed-OFDM modula- tion for ultrawideband communications. IEEE Trans. Veh. Tech., 58:2  2009 , 720–726.  [46] Z. Sahinoglu, S. Gezici & I. Guvenc, Ultra-wideband Positioning Systems   Cambridge, UK: Cambridge University Press, 2008 .  [47] A. A. M. Saleh & R. A. Valenzuela, A statistical model for indoor multipath  propagation. IEEE J. Sel. Areas Commun., 5:2  1987 , 128C-137.  [48] R. A. Scholtz, Multiple access with time-hopping impulse modulation. In Proc. IEEE  MILCOM, Boston, MA, Oct 1993, 447–450.      897   cid:2   References  [49] I. Sever, S. Lo, S.-P. Ma, P. Jang, A. Zou, C. Arnott, K. Ghatak, A. Schwartz, L. Huynh & T. Nguyen, A dual-antenna phase-array ultra-wideband CMOS transceiver. IEEE Commun. Mag., 44:8  2006 , 102–110.  [50] W. P. Siriwongpairat, W. Su, M. Olfat & K. J. R. Liu, Multiband-OFDM MIMO cod- ing framework for UWB communication systems. IEEE Trans. Signal Process., 54:1  2006 , 214–224.  [51] W. P. Siriwongpairat, Z. Han & K. J. R. Liu, Power controlled channel allocation for multiuser multiband UWB systems. IEEE Trans. Wireless Commun., 6:2  2007 , 583–592.  [52] W. P. Siriwongpairat & K. J. R. Liu, Ultra-Wideband Communications Systems:  Multiband OFDM Approach  Piscataway, NJ: Wiley-IEEE, 2008 .  [53] V. S. Somayazulu, Multiple access performance in UWB systems using time hopping  vs. direct sequence spreading. In Proc. IEEE WCNC, Mar 2002, 2, 522–525.  [54] D. Sweeney, D. S. Ha, A. Annamalai & S. Muthuswamy, Transmitter design. In J. H. Reed, ed., An Introduction to Ultra Wideband Communication Systems  Upper Saddle River, NJ: Prentice Hall, 2005 , pp. 213–251.  [55] L. C. Tran & A. Mertins, Space-time-frequency code implementation in MB-OFDM UWB communications: design criteria and performance. IEEE Trans. Wireless Commun., 8:2  2009 , 701–713.  [56] M. Welborn, M. M. Laughlin & R. Kohno, DS-CDMA Proposal for IEEE 802.15.3a, IEEE P802.15-03 334r3-TG3a, IEEE P802.15 Working Group for Wireless Personal Area Networks  WPANs , May 2003.  [57] L. Yang, Timing PPM-UWB signals in ad hoc multiaccess. IEEE J. Sel. Areas  Commun., 24:4  2006 , 794–800.  [58] L. Yang & G. B. Giannakis, Timing ultra-wideband signals with dirty templates. IEEE  [59] S. -K. Yong, TG3c Channel Modeling Sub-committee Final Report, IEEE WPAN  Trans. Commun., 53:11  2005 , 1952–1963.  TG3, IEEE 15-07-0584-00-003c, Mar 2007.  [60] S. Zhao, P. Orlik, A. F. Molisch, H. Liu & J. Zhang, Hybrid ultrawideband modu- lations compatible for both coherent and transmit-reference receivers. IEEE Trans. Wireless Commun., 6:7  2007 , 2551–2559.      21  Cognitive radios  21.1 Conception of software-deﬁned radio  Conception of software-deﬁned radio  SDR  started in the early 1990s, and has now become a core technology for future-generation wireless communications. In 1997, the U.S. DoD recommended replacing its 200 families of radio systems with a single family of SDRs in the programmable modular communications system  PMCS  guideline document [45]. An architecture outlined in this document includes a list of radio functions, hardware and software component categories, and design rules [45]. The ultimate objective of SDR is to conﬁgure a radio platform like a freely programmable computer so that it can adapt to any typical air interface by using an appropriate programming interface. SDR is targeted to implement all kinds of air interfaces and signal processing functions using software in one device. It is the basis of the 3G and 4G wireless communications.  Proliferation of wireless standards has created the dramatic need for an MS architecture that supports multiband, multimode, and multistandard low-power radio communications and wireless networking. SDR has become the best solution. By using a uniﬁed hardware platform, the user needs only to download software of a radio and run it, and immediately shift to a new radio standard for a different environment. The download of the software can be over the air or via a smart card. For example, several wireless LAN standards, including IEEE 802.11, IEEE 802.15, Bluetooth, and HomeRF, use the 2.4 GHz ISM band, and they can be implemented in one SDR system [25].  The programmable chips used in SDR are typically general-purpose DSPs or FPGAs. The internal blocks of SDR hardware must also have adequate calibration and pro- gramming capacities so as to adapt for optimum performance. Tunable RF preselect ﬁlters are an enabling technique, but are still being developed by using the MEMS technology.  SDR is versatile, based on a simple, uniﬁed hardware platform. The downloadable software packages are wireless standards. The versatility of signal processing algorithms enables high frequency usage and more extensive services to users. SDR can even adap- tively change the appropriate access scheme according to user’s QoS such as transmission rate, tolerable BER or delay. Based on SDR, it is easy to realize a multimode, multiband MS. There are also solutions using adaptive RF circuits, where some components such as LNAs and VCOs have adaptivity in performance.  Multiple-antenna techniques are usually incorporated into SDRs. They can increase system capacity. In a wireless system, the use of multiple antennas makes the MAC protocol more complicated. MAC protocol must cope with impairments arising from      899   cid:2   21.2 Hardware software architecture of software-deﬁned radio  shadowing, multipath delay spread, and CCI. Training ﬁelds are needed in a radio burst for channel estimation.  In the literature, there are many software realizations for various radio systems such as GSM [44] and DS-CDMA indoor system [4, 37]. The software realization of the GSM BS implements each GSM function block between the RF signal and the source speech signal in software. A uniﬁed SDR receiver is described in [24]. A SDR testbed for a 2× 2 MIMO space-time-coded OFDM wireless LAN is described in [48].  21.2 Hardware software architecture of software-deﬁned radio  Hardware architecture  For SDRs, the architecture is featured by wideband antenna, wideband A D and D A conversions, and digital baseband signal processing modules. For multimode SDR, a recon- ﬁgurable baseband digital signal processing stage and a multiband or broadband analog RF stage are necessary.  Ideally, the A D and D A conversions are applied directly at radio frequency. This requires ADCs of an extremely wide band, and thus is not practical. More practical SDRs have an RF circuit sitting between the antenna and the digital part, as shown in Fig. 21.1. The RF circuit contains ﬁlters, LNA power ampliﬁer, as well as IF modules. Signals are ampliﬁed after each ﬁltering. A D and D A conversions are applied on the IF signals rather than on baseband signals. DSPs are used for digital processing, and down-conversion can be done based on an NCO. This scheme can be called a low-IF architecture. SDR exercises strict restriction on the ADC: It must have a sampling frequency of at least the Nyquist frequency of the radio signal and have sufﬁcient resolution.  For the current CDMA-based 3G systems, the baseband processing functions are divided into chip-rate processing functions, such as the path searcher, access detection and rake receiver, and symbol-rate processing functions. On the transmit path, the baseband pro- cessing module receives data from the link layer. The data is spread and modulated, multiplexed, and then sent to the DAC. On the receive path, the data from the ADC is sub- ject to demultiplexing, channel selection, despreading, demodulation, channel decoding, and then is passed to the link layer.  Filter  LNA PA IF stages  RF circuitry  ADC DAC  A  D  SDR library  modulation demodulation signal process.  DSP  data  signaling interface   cid:2 Figure 21.1  SDR architecture      900   cid:2   Cognitive radios  For wideband wireless communications, various function blocks for baseband signal processing may consume many millions of multiply-accumulate  MMAC  operations that may be equivalent to the processing power of dozens of the most recent DSPs. For example, even a BS of the WCDMA system requires at least hundreds of thou- sands of MIPS, and today the best DSPs can only provide ten thousand MIPS. Multiple DSPs can be connected in series or parallel to provide more MIPS. Thus, using multiple DSPs in the design may be very costly. For this reason, SDR is more easily deployed in handsets.  FPGA-based hardware implementation would be much cheaper since only one single FPGA device can provide a computational capability of dozens of such DSPs. FPGAs now are the more realistic choice than the DSP-based solution.  In CDMA-based SDR, the chip-rate functions are typically much more MIPS-intensive than the symbol-rate functions. A desirable solution is to partition the chip-rate and symbol-rate functions so that chip-rate processing is mainly assigned to a reconﬁgurable processor such as an FPGA, while symbol-rate processing is mainly assigned to a DSP. Processing at symbol level can also be performed in microcontroller units  MCUs . Higher- layer protocols are handled in MCUs. For the non-CDMA based narrowband 2G systems, the entire baseband processing can be implemented in only one DSP.  For different standards, the sampled data must be decimated by a different scale so as to adapt the digitalization rate with the symbol rate of that particular standard. For this pur- pose, one can use a cascade of multistage decimation ﬁlters that progressively remove the out-of-band signal. Finally, a postﬁlter is used to precisely delimit the channel of interest and attenuate the interference.  Today, vendors such as ADI and National Semiconductors supply high-performance ADCs that are suitable for SDR. Vendors such as TI and ADI supply high-performance DSPs for wideband radio communications. Xilinx and Alterra are the two major vendors for FPGAs.  Software architecture  A SDR system is a system that uses a wideband hardware platform and different software components for different radios. Object-oriented design is ideal since each radio standard can be encapsulated into one class, and the code can be reused.  The software for the digital subsystem is divided into DSP software, FPGA software, and MCU software. There are some organizations dedicated to software standardization for SDR, such as the United States Joint Tactical Radio System  JTRS  Joint Program Ofﬁce and the SDR Forum. The architectures proposed by both organizations are object-oriented, and described by using Uniﬁed Modeling Language  UML  notation. Each of the archi- tectures deﬁnes an operating environment and its services and interfaces. They employ a POSIX-based operating system; noncore components are abstracted away from the hard- ware, and are all connected by using common object request broker architecture  CORBA . The core framework, as part of the operating environment, is the core set of open applica- tion layer interfaces and services, which provide an abstraction of the underlying software and hardware layers for application software design.      901   cid:2   21.3 Conception of cognitive radio  The Object Management Group  OMG  deﬁnes the open speciﬁcations Uniﬁed Modeling Language  UML , CORBA and Interface Deﬁnition Language  IDL . These speciﬁcations are popular in the deﬁnition of the software architecture of SDR. The OMG also has a special interest group  SIG  for SDR.  SpectruCell, developed by Advanced Communications Technologies, is a SDR platform for application development. It is targeted to the 3G BS as well as other wireless systems. SpectruCell provides application developers with a platform of hardware and middleware for implementing 2G and 3G air interfaces. It is broadly compliant with the Software- Deﬁned Radio Forum or JTRS speciﬁcations. AdapDev, developed by Mercury Computer, is another SDR platform compliant with the JTRS speciﬁcation. They are suitable for the development of SDR applications. Alcatel and Eurocom have also proposed their 3G SDR testbeds.  21.3 Conception of cognitive radio  Many licensed frequency bands are actually unused. Meanwhile, some frequency bands are overcrowded due to high-speed data services. For the frequency band up to 100 GHz, at any instant, only 5 to 10% of the spectrum is being used. In 2002, the FCC Spectrum Policy Task Force proposed spectrum policy reform, which allows secondary users to utilize those unused frequency bands licensed to the primary users. The FCC introduces the proposal of dynamic spectrum licensing, and cognitive radio is the enabling technology for this purpose. Cognitive radios will drive next-generation wireless networks.  The concept of cognitive radio was also introduced by Mitola [31]. A cognitive radio extends the functionality of SDR by adapting intelligently to its environment. Cognitive radio, also known as smart radio and spectrum-agile radio, can dynamically change its spectrum to an unused band to avoid interference by sensing its environment. A cognitive radio can make decisions on the network, frequency selection, modulation, coding, and all other parameters for ﬂexible spectrum use according to its environment. The use of the idle frequency spectrum is purely on an opportunity-driven basis. Cognitive radio can use any idle spectrum, but must stop using it the instant the primary user of the spectrum begins to use it.  The FCC permits unlicensed devices to temporarily borrow spectrum from licensed holders as long as no excess interference is sensed by the primary user. The unlicensed devices are required to identify unused frequency bands before transmission by using dynamic frequency selection and incumbent proﬁle detection. Basic cognitive radio tech- niques, such as dynamic frequency selection and transmit power control, have been used in some unlicensed devices.  Cognitive cycle  Cognitive radio transforms radio nodes from blind execution of predeﬁned protocols to radio-domain-aware intelligent agents that provide a means to deliver the services that      902   cid:2   Signal  environment   cid:2 Figure 21.2  Cognitive radios  Policy database  Configuration  database  Spectrum sensing  Learning and  reasoning  Control action  Reconfigurable  radio  Transmission  System information and needs  The cognitive radio cycle.  a user desires. To be successful, these radios must passively learn user preferences and program themselves. Cognitive capability and reconﬁgurability are two major characteris- tics of cognitive radio.  The cognitive cycle consists of three major components in its transceiver [22, 31]:  a  RF or spectrum sensing, such as radio-scene analysis and channel identiﬁcation, at the receiv- ing module,  b  cognition management, such as dynamic spectrum management, routing, and QoS provisioning, at the transmitting module, and  c  control action, such as transmit power control, AMC, and rate control, at the transmitting module. The receiver that com- municates with the cognitive radio needs also to feed back the spectrum information and quantized channel capacity to the transmitter. The cognitive cycle is illustrated in Fig. 21.2 The spectrum sensing functionality in cognitive radio systems can be divided into two subtasks: occupancy sensing and identity sensing. Spectrum sensing is addressed as a cross-layer design problem, where the physical layer implements sensing, cognition, and adaptation, whereas the MAC layer implements cooperation [12].  21.3.1 Topics in cognitive radio  Modulation and primary user recognition  For radio signal analysis, modulation recognition and bitstream analysis are applied to identify whether an alarm corresponds to a primary user, or a secondary user, or noise  false alarm . Modulation recognition is an intermediate step between signal detection and demodulation. Knowledge of the types of service operating on a channel can assist in the decision of jumping channels in a way that minimizes overhead to the cognitive radio and its impact on the primary users of the spectrum. A cognitive radio should be able to recognize other cognitive radios on the link channel to prevent them sensing one another as primary users and jumping channels.  Modulation recognition can be likelihood-based or feature-based [9]. The former is based on the likelihood function of the received signal and the decision is made by com- paring the likelihood ratio against a threshold. The likelihood-based algorithms are optimal in the Bayesian sense: they minimize the probability of false classiﬁcation, but suffer from high computational complexity. The feature-based approach makes decisions based on      903   cid:2   21.3 Conception of cognitive radio  the observed values of typically, several features. In general, modulation recognition is a challenging task, especially in a noncooperative environment, where no prior knowledge of the incoming signal is available.  A number of features can be extracted to identify the type of the primary users from the received data using signal processing techniques. These features can be frequency- domain features  e.g., bandwidth, center frequency, single carrier versus multi-carrier , or time-domain features  e.g., the variance of the centered normalized signal amplitude, the variance of the zero-crossing interval, maximum duration of a signal, multiple-access technique, duplexing technique, frame duration, spreading codes or hopping patterns , or its statistical properties  e.g., moments, cumulants, cyclic cumulants . Some or all of the features can be extracted from the received data and used for classiﬁcation. The primary users are identiﬁed by using the a-priori information about their transmission parameters. The classiﬁer can be a neural network classiﬁer [10]. The classiﬁer can be trained off- line, but the recognition process must be performed online on the incoming signal at an affordable complexity.  Spectrum management  Spectrum management functions address four major challenges: spectrum sensing, spec- trum decision, spectrum sharing, and spectrum mobility. Spectrum mobility allows a cognitive radio to exchange its frequency of operation in a dynamic manner by allowing the cognitive radios to operate in the best available frequency band seamlessly. Spectrum sharing deals with fair spectrum scheduling, which is a MAC functionality. A cognitive radio needs to maintain an up-to-date list of available channels within a band. The channel usage database can also be used to avoid the occupied licensed channels, and a secondary user estimates its position and checks a database to ﬁnd out which channels are vacant in its vicinity.  Erasure correction codes  A secondary user selects a set of subchannels from the primary user band to establish a secondary user link that adapts itself in accordance with the primary user spectral activity on that band. The secondary user is required to vacate a subchannel as soon as a primary user becomes active on that subchannel. This causes a secondary user to lose packets on that subchannel. In order to compensate for this loss, a class of erasure correction codes called LT  Luby transform  codes or Fountain codes [30] can be used for packet-based channels with erasures before transmitting secondary user packets on these subchannels. This provides packet-level protection at the transport layer or higher, augmenting the bit- level protection that may be provided by the MAC and physical layers.  Spectrum awareness  Spectrum awareness over an entire operating bandwidth of interest is a basic and crucial task of a cognitive radio. Cognitive radio sensitivity is required to outperform the primary      904   cid:2   Cognitive radios  user receiver by a large margin in order to prevent the hidden terminal problem. This makes spectrum sensing, or spectrum awareness, a very challenging research problem. For cog- nitive radios, a cross-layer design approach is desirable since the process delay is required to be small.  Spectrum awareness can be either passive or active awareness. In passive awareness, the spectrum use pattern is obtained not by sensing by the secondary system itself, but by negotiating with primary users, or from a server or database. The passive awareness approach results in considerable signaling for distribution of frequency information. In active awareness, the secondary user actively senses the frequency spectrum to obtain the spectrum use pattern. Active spectrum awareness can be performed in a nonco- operative or cooperative manner. Cooperation helps to cope with the hidden terminal problem.  Active spectrum awareness can be either reactive or proactive, depending on how white spaces  unused frequency bands  are searched. Reactive schemes operate on an on-demand basis, where a cognitive radio starts to sense the spectrum only when it has data to send. Proactive schemes, on the other hand, minimize the delay of secondary users by ﬁnding an idle band through maintaining a list of licensed bands currently available for opportunistic access through periodic spectrum sensing.  Cognitive radio as relay  When the direct channel on the primary link to the destination is weak compared to the channel from the primary transmitter to the cognitive radio, the cognitive radio can act as a relay. Packets from the primary link may not be received correctly at the destination, but they might be decoded successfully at the cognitive radio. The latter can queue and for- ward these packets to the intended receiver. In this case, packet relaying by the cognitive radio helps to empty the queue of the primary transmitter, thus also creating transmitting opportunities for the cognitive radio. According to the cognitive principle, the primary transmitter is unaware of the presence of a secondary node. Relaying by the cognitive radio has been analyzed in an information-theoretic framework in [6]. In a scenario with two single-user links, a primary and a cognitive link, the maximum stable throughput of the cognitive link is derived in [40] for a ﬁxed throughput of the primary link. When the cog- nitive radio is allowed to act as a transparent relay for the primary link, a stable throughput of the cognitive link with relaying is also derived in [40]. The beneﬁts of relaying depend highly on the topology of the network.  21.3.2 Cognitive radio in wireless standards  Cognitive radio will be a component of many future radio systems and networks. Many radios have to include an ability to coexist with other radios using different protocols in the same bands, and cognitive radio is a solution to coexistence. IEEE 802.19 creates rules for fostering coexistence within IEEE 802 standards operating in unlicensed bands. The      905   cid:2   21.4 Spectrum sensing  Software-Deﬁned Radio Forum, ITU-R, and the IEEE are involved in the standardization of cognitive radio.  IEEE SCC41  Standards Coordinating Committee 41 ,1 Dynamic Spectrum Access Networks  DySPAN , formerly known as the IEEE 1900 Standards Group, was initially established in 2005, and reorganized to the current form in March 2007. IEEE SCC41 focuses on dynamic spectrum access among 3G 4G, WiFi, and WiMAX networks.  The CSMA used in IEEE 802.3 standard is somewhat similar to cognitive radio: both systems sense before transmission. Cognitive radio also bears some resemblance to dynamic channel selection allocation. Frequency-hopping techniques used in GSM and Bluetooth are kinds of cognitive radios for interference avoidance.  The IEEE 802.11h standard, which was approved in September 2004, has incorpo- rated dynamic frequency selection and transmit power control for IEEE 802.11a to solve interference with satellites and radar using the same 5 GHz frequency band. IEEE 802.22  Wi-TV  is now being developed based on cognitive radio. WiMAX is also trying to reuse the UHF VHF band based on cognitive radio. Spectrum sensing using energy detection is chosen in IEEE 802.11y for shared IEEE 802.11 operation with other users in the 3.6 GHz band. IEEE 802.16h is a provision for cognitive radios to avoid interference with other WiMAX devices.  The FCC also approved UWB as another solution for improving spectrum efﬁciency in 2002. For communications, the FCC allows UWB to overlay the band 3.1–10.6 GHz with existing spectrum users by limiting the transmit power to a sufﬁciently low level so that it does not impact the existing spectrum users.  21.4 Spectrum sensing  21.4.1 Secondary user-based local spectrum sensing  Approach to active spectrum sensing  The most effective way for spectrum sensing is to detect the primary users that are receiving data within the secondary user communication range. A wireless device typically senses the presence of a primary user by using one of the three active spectrum sensing techniques: energy detection, matched ﬁltering, and feature detection [12].   When there is no prior information of the primary users, energy detection using FFT is a simple, general approach. This method is valid only if the energy detected is above a certain threshold. The energy detector technique has some drawbacks such as difﬁculty in setting the threshold due to the changing background noise and interference level, incapability of differentiating between modulated signals, noise and interference, and the method is invalid for spread-spectrum signals. The performance of the method also  1 http:  www.scc41.org       906   cid:2   Cognitive radios  degrades in a fading environment and when the secondary user needs to cooperate with other nodes for spectrum sensing.   A matched ﬁlter is optimum for signal detection in communication systems. This requires demodulation of a primary user signal. Thus, cognitive radio is required to have a-priori knowledge of a primary user signal at both physical and MAC layers  e.g., modulation type and order, pulse shaping, packet format , and then it implements coher- ent demodulation by performing timing and carrier synchronization, and even channel equalization.   Feature detection, most typically cyclostationary feature detection, improves the detec- tion performance by exploiting standards speciﬁcs. A signal with strong cyclostationary properties can be detected at very low SNR. Cyclostationary feature detection has the highest complexity among the three techniques.  The biggest challenge for spectrum sensing is in developing blind sensing techniques that are capable of detecting very weak primary user signals while being sufﬁciently fast and low cost to implement.  As energy detection has far lower complexity than feature detection does, feature detection is performed only after a predeﬁned number of consecutive energy detec- tion alarms are issued [26]. This effectively avoids feature detection in case of false alarms.  A fourth approach, cyclostationary beamforming-based spectrum sensing, is proposed in [12]. The idea is to use the ACS algorithm [11] to extract the desired signal at a unique cycle frequency from the measurement of an antenna array. Based on the spectrum analysis of the extracted signal, one can judge whether a speciﬁed channel is occupied by a primary user or a secondary user, or it is vacant. The complexity of this method runs between those of the energy detection and cyclic spectrum analysis methods. In contrast, energy detection can only detect whether the channel is occupied, but it cannot identify whether the received signal is a primary user or a secondary user signal. The energy detector is also unable to identify the existence of a user signal that is buried in noise, but cyclostationarity-based techniques can.  In order to avoid interference from the cognitive radio network itself, a cognitive radio usually does not access the spectrum during spectrum detection; this period is called the quiet period. In most existing spectrum sensing techniques, in-band sens- ing performs measurement during the speciﬁed quiet periods. There are some in-band sensing techniques without a quiet period proposed for OFDM-based IEEE 802.22. Another in-band sensing approach utilizes the complementary adjacent OFDM symbols in the preambles or in the pilots to eliminate the effect of channel and self-signal of the network, and to perform power detection [29]. These methods are customized for OFDM signals by using the training sequence. The cyclostationary beamforming-based spectrum sensing approach also eliminates the need for quiet periods [12]. In [12], a secondary user can measure while it is simultaneously transmitting, as long as its trans- mitted signal does not have the same cycle frequency; the method is simple, and is suitable for all kinds of communication signals, compared to existing in-band sensing techniques.      907   cid:2   21.4 Spectrum sensing  Occupancy: binary hypothesis test  Detection of whether the spectrum is currently occupied by a primary user can be stated by a binary hypothesis test. A null hypothesis H0 corresponds to the absence of a signal, and a hypothesis H1 corresponds to the presence of a signal. The signal received at the cognitive radio is given by   cid:15  H0 w t , hs t  + w t , H1  ,  x t  =  where s t  is the primary user signal, h is the amplitude gain of the channel, and w t  is AWGN with zero mean and variance σ 2 n . Given a decision statistic d, the probabilities of detection Pd, false alarm Pfa, and missed alarm Pm are, respectively, given by  Pd = E [Pr  H1H1 ] = Pr  d > dthH1  , Pfa = E [Pr  H1H0 ] = Pr  d > dthH0  , Pm = E [Pr  H0H1 ] = 1 − Pd,  where dth is a threshold level, which can be calculated from a speciﬁed Pfa [3]. Naturally, Pfa is independent of the SNR, since under the H0 hypothesis there is no primary user signal present. Conversely, Pd is dependent on the SNR of the received signal as well as the channel conditions. These probabilities are illustrated in Fig. 21.3. From the incumbent protection point of view, a higher Pfa is more tolerable than a lower Pd. In IEEE 802.22, Pd = 0.9 is chosen at a SNR of −20 dB. Note that if the primary user requires 100% protection in its frequency band, it is not allowed for the secondary usage in that frequency band.  For energy detection, a popular decision statistic is deﬁned by   21.1    21.2   21.3   21.4    21.5   d = N cid:26   n=1  x n 2 .  Under hypothesis H0, the test statistic d is a random variable whose pdf p0 x  is a χ 2 distribution with 2N degrees of freedom for the complex-valued case, or with N degrees of freedom for the real-valued case. The minimum required number N of samples is derived as a function of Pfa, Pd, and SNR γ [3]. In case of the energy detector, at low SNR  γ  cid:5  1 , N scales as O ; Pfa, Pd,  1 γ 2   cid:7    cid:8   p  Signal not present  Signal present   cid:2 Figure 21.3  Pm  d  th  Pfa  d  Probabilities of detections, missed alarms and false alarms.      908   cid:2   Cognitive radios  Pm are given as functions of the energy threshold and the SNR [12, 28]. Complementary receiver operating characteristic  ROC  curves  Pm versus Pfa  of the energy detection method can thus be plotted.   cid:8    cid:7   A matched ﬁlter requires O 1 γ   samples to meet a predetermined probability of error  Pe  constraint [3]. When the transmitter transmits random Gaussian noise, the optimal detector becomes an energy detector. The optimal detector for a zero-mean constellation is proved to behave like an energy detector in the limit of low SNR, and thus zero-mean signals are difﬁcult to detect at low SNR, even with knowledge of the modulation scheme samples are required to meet a Pe constraint. This number of [38]. In this case, O samples is signiﬁcant and it imposes a limit on the frequency agility of a cognitive radio: Short duration gaps cannot be exploited in band usage. When exploiting the cyclostationary property, spectrum sensing can be formulated as hypotheses testing on the received signal x t : Under hypothesis H0, x t  is  wide-sense  stationary and the band is treated as vacant; under hypothesis H1, x t  is cyclostationary and the band is judged occupied.  1 γ 2  Wideband spectrum sensing is conventionally performed by using a tunable narrowband bandpass ﬁlter to sense one narrowband at a time. Multiband joint detection detects the signal energy levels over multiple frequency bands at a time, by jointly optimizing a bank of multiple narrowband detectors, in order to improve the opportunistic throughput capac- ity of cognitive radios and reduce their interference to primary users [36]. By applying a wavelet transform of the PSD function of the received wideband signal, the singularities of the PSD, which correspond to the discontinuities between sub-bands, can be located and thus the unoccupied sub-bands can be identiﬁed [43]. This method, however, does not work for spread spectrum signals.  The average Pd for energy-detector-based spectrum sensing over Rayleigh, Nakagami, and Ricean fading channels is derived in closed form in [7]. The performances of EGC, selection combining, and switch combining are investigated for energy detector-based spectrum sensing under Rayleigh fading. The EGC approach provides the highest gain in terms of Pm over the no-diversity case.  21.4.2 Cooperative spectrum sensing  Local spectrum sensing cannot avoid the hidden terminal problem. In wireless LAN, this problem can be solved by a four-way handshake using Request-To-Send Clear-To-Send. However, it is impossible to implement the handshake in cognitive radio networks, as the primary users will not add additional resources for handshake. The spectrum sensing per- formance can be improved, and the hidden terminal problem can be avoided if cooperative spectrum sensing is applied. Cooperative sensing allows to mitigate the multipath fading and shadowing effects, and improves the detection probability. It provides signiﬁcantly higher spectrum capacity gains than local sensing. This, however, introduces complexity, trafﬁc overhead, and the need for a control channel.  An alternative technique is external sensing, where an external agent performs sensing and broadcasts the channel occupancy information to the cognitive radios. This overcomes      909   cid:2   21.4 Spectrum sensing  the hidden primary user problem as well as the uncertainty due to shadowing and fading. Further, as the cognitive radios do not spend time for sensing and thus do not need sens- ing ability, spectrum efﬁciency is increased. The hidden terminal problem can be solved by employing a sufﬁcient number of external sensing devices in the cognitive radio net- works [21]. External sensing is among the spectrum-sensing methods proposed for the IEEE 802.22 standard.  In cooperative spectrum sensing, information from different cognitive radios is com- bined to make a decision on the presence or absence of the primary user. Cooperative spectrum sensing can be in centralized or distributed form. In general, centralized cooper- ative sensing is performed as follows. Each cognitive radio makes a binary decision based on its local measurement, and then forwards one bit of the decision to the common receiver, where all one-bit decisions are fused according to an OR logic or according to the voting rule. An alternative scheme is that each cognitive radio just forwards its measurement to the common receiver. A hard decision approach can perform almost as well as a soft deci- sion one in terms of detection performance, but it needs a low bandwidth control channel [28]. To reduce the overhead due to sending the decisions, censoring can be applied by not sending the uncertain decisions. When the common receiver makes a ﬁnal decision on the K binary decisions using an OR rule, we have [28]  Pfa = Pr  H1H0  = 1 − Pr  H0H0  = 1 − K! Pm = Pr  H0H1  = K!  Pm,i,  i=1   cid:7    cid:8   1 − Pfa,i  ,  i=1   21.6    21.7   where Pfa,i and Pm,i denote the false alarm and miss probabilities of the ith cogni- tive radio in its local spectrum sensing, respectively. If each cognitive radio achieves the same Pfa,0 and Pm,0, we have Pm = PK m,0; in this case, K is treated as the sens- ing diversity order, which is provided by the space diversity of the multiple cognitive radios.  In the case of distributed sensing, cognitive nodes share information among one another, but they make their own decisions as to which part of the spectrum they can use. When a cognitive radio is far from a primary user, cooperative spectrum sensing allows two secondary users to cooperate by treating the secondary user that is close to the pri- mary user as a relay. This achieves a diversity gain arising from the relay protocol. One of the cognitive radios acts as a relay for the other, resulting in lower outage prob- abilities. This effectively combats shadowing and the hidden terminal problem. When two cognitive radios are in close proximity, they can be used as a virtual antenna array; that is, the measurements of the two cognitive radios are exchanged, and the two cognitive radios then jointly transmit using the Alamouti space-time code to combat fading [39].  Multiuser diversity is a form of selection diversity in which the user with the highest SNR is chosen as the transmission link. Multiuser diversity can be exploited in cooperative spectrum sensing to relay the sensing decision of each cognitive radio to the common receiver. This helps to reduce the reporting error probability [28].      910   cid:2   Cognitive radios  21.5 Spectrum sensing using cyclostationary property  Tc  + n  The cycle  or conjugate cycle  frequencies of conventional modulated signals are listed in [1]. Spread-spectrum and OFDM signals are also important, as they are used in 3G and 4G wireless systems, respectively. For spread-spectrum signals with a spreading code or hopping sequence of period N, the spectrum cyclic density  SCD  function exhibits cycle frequencies at α = k NT , for integer k and data symbol period T [17]. In [16], a general class of continuous-time DSSS signals is shown to exhibit cyclostationarity at cycle frequencies that are sums or differences of multiples of the symbol rate and the chip rate, that is, α = m , where T0 is the bit interval, Tc is the chip period, and m, n are integers. The T0 discrete-time signal obtained by uniformly sampling a continuous-time long-code DSSS signal exhibits cyclostationarity, provided that at least two samples per chip are taken. When α  cid:18 = 0, the degree of cyclostatioarity is very weak. OFDM signals may be represented as a composite of N statistically independent sub- channel QAM signals. Without a cyclic preﬁx, subcarrier orthogonality destroys the cyclostationarity of the individual QAM signals. The inclusion of a cyclic preﬁx causes a loss of subcarrier orthogonality, but allows inherent QAM signal features to be detected [46]. Cyclic-preﬁx OFDM signaling is cyclostationary with the OFDM symbol period T, and thus exhibits nonconjugate cyclostationarity at cycle frequencies α = k T, k = 0,±1, . . ., and potentially other frequencies depending on the coding scheme, where T = Ts + Tcp, Ts being the length of the useful symbol data and Tcp the length of the cyclic preﬁx [23, 35, 46]. The cyclic autocorrelation function for α = k T peaks at τ = ±Ts [35].  21.5.1 Spectrum-cyclic-analysis-based spectrum sensing  The SCD function allows for modulation recognition based on the pattern of the cycle  or conjugate cycle  frequencies. The performance of the feature detector also depends on how much energy a feature contains, and different modulation schemes have features with different energy patterns. Cyclostationary feature detection estimates the peaks on the SCD function. The SCD function can be calculated by combining FFT and spectral correlation, as shown in Fig. 21.4.  The sufﬁcient statistic can be deﬁned for single or multiple cycle frequencies by  Z N  =  ∗ˆSα xx  f  df ,  Sα xx  f     21.8    cid:26    cid:14  fs  2  − fs  2  α  x t   Bandpass  filter  cid:2 Figure 21.4  A D  N-pt FFT  N-pt spectral correlation  Average over T   Z N   Feature detection  Cyclostationary feature detection.      911   cid:2   21.5 Spectrum sensing using cyclostationary property   cid:7    cid:8   where fs is the sampling frequency and Sα xx  f   is the SCD function. If Z N  is above a threshold, a signal is judged to be existing. Cyclostationary feature detection has a for a speciﬁed α, which is much larger computational complexity of O than that of energy detection using FFT, namely, O  N2 + N  2 log2 N   cid:7    cid:8   .  N 2 log2 N  The detection of multiple cycle frequencies requires the calculation of a large fraction of the SCD function over a wide range of cyclic frequencies, followed by ﬁnding the peaks. This results in an intensive computational complexity and typically long observation times. The cycle frequency is required to have a much ﬁner resolution than the spectral resolution,  cid:18 α  cid:5   cid:18 f ≈ 1 T [17]. This provides an improved detector performance and facilitates dichotomizing among the primary user and secondary user signals and different waveforms used.  Cyclostationary signatures provide an effective mechanism for overcoming the complexity of the SCD-based approach while maintaining the key advantages of spectrum cyclic analysis. By manipulating the IFFT frequency bins used for OFDM signal generation, correlation patterns can be artiﬁcially introduced in the power spec- trum of that signal to form a cyclostationary signature, which is then used to aid the detection and classiﬁcation of the OFDM-based signals in dynamic spectrum access networks [41, 42].  Cyclostationary feature detection is very attractive, as it does not require coherency and synchronization. It can also distinguish various signal properties and can work at low SNR. Spectrum cyclic analysis allows the detection and classiﬁcation of signals with a performance approaching those of optimal coherent schemes [18], while maintaining the generality of other noncoherent approaches.  An OFDM radio is easy to integrate with spectrum-cyclic-analysis-based spectrum sens- ing, since both of them use FFT cores. When there are non-contiguous holes after the determination of the spectrum occupancy, the OFDM radio is the natural solution. This spectrum sensing approach has been widely used, and it has been also used for IEEE 802.22 cognitive radio.  21.5.2 Cyclostationary beamforming-based spectrum sensing  We have described signal cyclostationarity and cyclostationary beamforming in Sec- tion 18.5. In [12], spectrum sensing based on cyclostationary beamforming has been proposed. The approach exploits an antenna array, which can be installed on a ﬁxed agent or on cognitive radios, to detect the occupancy of all the primary user and secondary user channels. If an antenna array is installed on a ﬁxed agent, it is an external sensing method; the occupancy information is then broadcast to all the secondary users by using a control channel.  For a typical cognitive radio application, modulation parameters such as the carrier fre- quencies, data rates, and bandwidths of the possible channels for primary user signals are deﬁned in a standard and are known by all the cognitive radios. The cycle frequencies for each primary user or secondary user mode on each channel are known and usually are designed to be unique, if the channel is occupied by a primary user or a cognitive radio.      912   cid:2   Cognitive radios   cid:2    cid:3   Each class of cognitive radios may also know such modulation parameters of the other classes. The carrier frequencies of transmission channels are typically speciﬁed as  fc,n = f0 +  n − 1 2  n = 1, 2, . . . , N,  B,   21.9   where f0 is the start frequency of the band, B is the bandwidth of each channel, and N speciﬁes the number of channels. This is also applicable for OFDM signals. One or more cochannel signals may be present on each channel, as in the spread-spectrun communication scenarios.  A cognitive radio is required to scan the channels to ﬁnd a vacant channel before access- ing the network. A cognitive radio can test all the channels for the presence of transmission. In order to differentiate between primary user and secondary user signal types, their respec- tive cycle or conjugate cycle frequencies must be selected to be different. Cyclostationary beamforming-based spectrum sensing ﬁrst uses the ACS algorithm [11] to extract a sig- nal of a speciﬁed α from the antenna array measurement. Based on the spectrum of the extracted signal, one can judge whether a channel is occupied by a primary user, a secondary user, or is vacant.  Cyclostationary beamforming-based spectrum sensing is advantageous over the spec- trum cyclic analysis-based detection approach, since the latter has a much higher com- plexity. Search for the peaks on the SCD function is also computationally complex. The cyclostationary beamforming-based technique, however, has a complexity that is higher than that of the energy detector. At low SNR, the minimum number of required samples for reliable sensing is signiﬁcantly less than that required for the energy detector.  The ACS algorithm has a performance superior to that of several other cyclostationary beamforming algorithms [11]. From the experiments given in [12], the ACS algorithm gen- erally converges at around 2000 samples when the SIR γ is −20 dB or less. The number of samples required, N, should scale at between O 1 γ   and O 1 γ 2 . That is, the minimum number of required samples is less than that required for the energy detector.  Example 21.1:  To examine the performance of the cyclostationary beamforming-based spectrum- sensing algorithm, we perform a few simulations in this example. We assume that the entire spectrum is divided into a ﬁxed number of six channels at carrier frequencies 2001.2, 2002.2, . . ., 2010.2 MHz. A uniform linear array with n = 8 antenna elements is used. The spacing between adjacent elements is half the wavelength at the carrier frequency of 2 GHz. = 0.1. The signal environment for The standard deviation of the noise at the array is σ 2 n benchmarking is shown in Table 21.1: There are 5 primary user signals representing a pri- mary service, and 2 secondary user signals representing different cognitive radio modes. The sampling rate fs at the receiver is chosen to be 20 Msps, and all signals are at the same noise power level σ 2 . The s signals are BPSK or 16QAM signals, which are raised-cosine ﬁltered with a roll-off factor of 0.22.  = 0.01, and the signal power can be obtained from SNR = Ps  σ 2 s      913   cid:2   21.5 Spectrum sensing using cyclostationary property  Table 21.1. Signals for benchmarking.  Signal Carrier  MHz   fbaud   fs 20  Modulation DoA SNR  dB   A B C D E  F G  2001.2 2002.2 2003.2 2006.2 2008.2  2005.2 2009.2  1 5 1 5 1 5 1 5 1 5  1 3 1 11  BPSK BPSK BPSK BPSK BPSK  16QAM 16QAM  ◦ ◦  ◦ 35 ◦ 20 −10 −35 ◦ 60 ◦ -40 ◦ 15  15 25 30 10 20  15 5  Primary secondary user  Primary user Primary user Primary user Primary user Primary user  Secondary user Secondary user  For these modulations, the maximum self-coherence occurs at τ = 0 [1], and we select τ = 0 here. The BPSK signal has conjugate cycle frequencies at α = ±2fc + mfbaud, m = 0,±1, . . ., and has cycle frequencies at α = mfbaud, m = ±1,±2, . . . [1, 11]. In a multiple signal environment, we needs to design the signals so that their selected cycle frequencies should have a least common multiple that is as large as possible [11]. The 16QAM signal has only nonconjugate cyclostationarity with cycle frequencies at α = mfbaud, m = ±1,±2, . . .. The ACS algorithm can be implemented equally well for both nonconjugate and conjugate cyclostationary signals, depending on the properties of the desired signals.  The assignment of carrier frequencies and the selection of  conjugate  cycle frequencies  must be very carefully done and some guidelines are given in [11]. We now implement spectrum sensing using Monte Carlo simulation. After applying the conjugate cyclostationarity-based ACS at α = 2fc + fbaud at fc, if there is a spectrum sidelobe at the channel, it may be either a primary user or a secondary user. We can test whether it is a secondary user mode by testing all the possible secondary user data rates using the cyclostationarity-based ACS algorithm until a spectrum mainlobe at the channel occurs; otherwise, it is not a secondary user and can be judged as a primary user sig- nal or a hole. The threshold for spectrum occupancy can be lowered to 3 times the mean power in the band. The result is shown in Fig. 21.5. For this example, we assume that the possible secondary user signals are of type 16QAM with baud rates 1 7 fs 20, and 1 11 fs 20.  3 fs 20, 1  Energy detection is a simple and popular technique for spectrum sensing. This method cannot discriminate between primary user and secondary user signals. It cannot detect a signal if it is buried in noise. When we set the detection threshold as 6 times the mean power in each channel, the result is shown in Fig. 21.6. Note that for the energy detection approach only one antenna is used and σ 2 a is the noise power at the single antenna. Compared to the result obtained by the proposed approach  see Fig. 21.5 , for a similar correct detection probability of channel occupancy  primary user plus secondary user , the probability of correct detection of spectrum holes is relatively lower in the energy detection approach; this corresponds to lower spectrum efﬁciency. By decreasing the detection threshold, the      100  σ a  2  2 σ  s  101  0.2      10−1  100  σ a  2  2 σ  s  101  914   cid:2   0.6  0.4  0.2  y t i l i b a b o r P  0 10−1  1  0.8  0.6  0.4  0.2  y t i l i b a b o r P  0.7  0.6  0.5  0.4  0.3  0.2  0.1  y t i l i b a b o r P  HOLE detected  HOLE missed False alarm  SU detected  SU missed False alarm  HOLE detected HOLE missed False alarm     102        Cognitive radios     102     y t i l i b a b o r P  y t i l i b a b o r P  1  0.8  0.6  0.4  1  0.8  0.6  0.4  0.2     1  0.8  0.6  0.4  0.2  y t i l i b a b o r P  PU detected  PU missed False alarm  PU+SU detected  PU+SU missed False alarm  PU+SU detected PU+SU missed False alarm    0 10−1   cid:2 Figure 21.5  100  σ a  2  2 σ  s  101  102    0 10−1  100  σ a  2  2 σ  s  101  102  Detection probabilities at different noise levels: Conjugate cyclostationarity-based ACS at α = 2fc + fbaud is used to extract the primary user signals, cyclostationarity-based ACS at α = fbaud to extract the secondary user signals. σ 2  s is used to characterize the SNR.  a  σ 2    0 10−1   cid:2 Figure 21.6  100  101  σ a  2  2 σ  s  102    0 10−1  100  101  σ a  2  2 σ  s  102  Detection probabilities of channel occupancy at different noise levels: energy detection.      915   cid:2   21.6 Dynamic spectrum access  probability of correct detection of occupied channels is made more close to 100%; this, however, further reduces the probability of correct detection of spectrum holes, and hence the spectrum efﬁciency.  The beamforming-based approach has the capability of correctly identifying primary user and secondary user signals. In Fig. 21.5, the probability of correctly identifying the secondary user signal is quite far from 100%; this is because one of the two secondary users  signal G  is too weak. Another advantage is that the beamforming-based method can extract and sense all the cochannel signals on the same channel  fc , as long as they have different α values or cyclostationarity properties. This property can be applied to spread- spectrum signals, but it requires each signal to have a different data rate or coding scheme.  21.6 Dynamic spectrum access  Spectrum sensing and dynamic spectrum access are two critical aspects for cognitive radio networks. Network protocols in general exhibit some form of implicit cooperation, which leads to fairness and good performance for the entire network. Dynamic spectrum access of the secondary users can be formulated as a constraint optimization problem, which can be solved by using water-ﬁlling or game theory.  21.6.1 Water-ﬁlling for dynamic spectrum access  Water-ﬁlling is the traditional approach to dynamic spectrum access. In [8], a near optimal scheme with linear complexity has been designed for jointly allocating channels and power levels among cognitive radios. The proposed iterative water-ﬁlling scheme maximizes the sum capacity subject to individual constraints on users’ power budgets. In [13], a more general formulation for dynamic spectrum access is given, and an iterative water-ﬁlling algorithm is derived.  In this section, we describe a dynamic spectrum access solution proposed in [13]. The dynamic spectrum access problem is formulated as maximizing the sum channel capac- ity while satisfying the power budgets of individual cognitive radios as well as the SINR constraints on both the secondary and primary users.  Consider N available channels and K contending cognitive radios in a cognitive radio network. We can maximize the sum capacity of the network while each cognitive radio has the constraints on BER, power, and channel usage, that is,  cn, k, Pn, k = arg max C = K cid:26   N cid:26   = K cid:26   k=1  n=1  k=1  cn, kB log2  N cid:26   Ck = K cid:26   cid:7   k=1  n=1 1 + Pn, kgn, k   cid:8    cid:2    cid:3   cn, kB log2  1 + Pn, kgn, k N0B   21.10       916   cid:2   subject to  Cognitive radios  K cid:26  cn, k = 1, k=1 N cid:26  cn, k ∈ {0, 1}, n=1 Pn, k ≥ 0,  for all n,  for all n, k,  Pn, k ≤ Pk, max,  for all n,   21.11    21.12    21.13    21.15    21.16   for all n, k,   21.14  where n runs from 1 to N, k runs from 1 to K, cn, k ∈ {0, 1} indicates the assignment of channel n to cognitive radio k, gn, k is the channel power gain on channel n for cognitive radio k, gn, k = gn, k N0B , N0 is the one-sided noise PSD, B is the bandwidth of each channel, and Pk, max is the maximum power of cognitive radio k. Equation  21.11  states that each channel can only be assigned to one cognitive radio, and  21.13  speciﬁes the maximum power of each cognitive radio. In  21.10 , C can be replaced by its normalized version C = C B. Since each channel admits only one cognitive radio, the SINR of each cognitive radio k  on channel n should be constrained by a threshold  It can be written as  γn, k = gn, kPn, k ≥ γth,k.  Pn, k ≥ γth,k gn, k  = Pn, k, min.  In a conservative design, the system allows one or more cognitive radios to coexist with a primary user, but the received SINR constraint at each primary user must be ensured. If the BS for the primary users transmits with power PT at a distance of dB, i from primary user i and there is one cognitive radio on the same channel n, the received SINR at primary user i should be above a threshold [8] γPU,i =  ≥ γ0,   21.17   −r B, i + N  PTd −r k, i   cid:14  0B  Pn, kd  where Pn, k is the transmit power of cognitive radio k on channel n, dk, i is the distance between cognitive radio k and primary user i, and r is the exponent of propagation loss. This constraint is equivalent to   cid:2    cid:3 −r − N   cid:14  0B −r k, i  d  Pn, k ≤ PT γ0  dB, i dk, i  = Pn, k, max,   21.18   where N   cid:14  0B is the noise power of a primary user.  Solving using Karush-Kuhn-Tucker theorem  The above problem is a mixed-integer nonlinear programming problem. The discreteness of cn, k endows the problem with analytical and algorithmic intractabilities. In order to solve      917   cid:2   21.6 Dynamic spectrum access  it using nonlinear programming, one can convert the discrete variable cn, k ∈ {0, 1} into a continuous variable. In [8], cn, k is treated as a continuous variable in the interval [0, 1], and its ﬁnal result is quantized to 0 or 1. This result is suboptimal, since cn, k’s usually stay in n, k, where m ≥ 1 the middle part of the interval. In [13], cn, k in  21.10  is changed to cm is a fuzziﬁer. By selecting a large m, the optimization process will force one of the cn, k’s, k = 1, . . . , K, approximates unity, while all the other cn, k’s approach zero, since otherwise cm n, k’s will be very small for all k. With primary user protection, the problem can be reformulated as  cn, k, Pn, k = arg max C = K cid:26   N cid:26    cid:7    cid:7    cid:8 m log2  cn, k  k=1  n=1   cid:8   1 + Pn, kgn, k  ,   21.19   subject to  for all n,  cn, k = 1,  K cid:26  k=1 N cid:26  cn, k 1 − cn, k  = 0, Pn, k ≤ Pk, max, n=1 Pn, k ≥ cn, kPn, k, min, Pn, k ≤ cn, kPn, k, max,  for all n, k,  for all n,  for all n, k, for all n, k,   21.20    21.21    21.22    21.23   21.24    21.25    21.26    21.27   where cn, k in  21.23  identiﬁes that there is no SINR constraint for Pn, k if channel n is not assigned to cognitive radio k.  This is a constrained convex optimization problem. To solve this problem using the  Karush-Kuhn-Tucker theorem, the Lagrangian is deﬁned as   cid:8   1 + Pn, kgn, k   cid:7   cn, k  k=1  n=1  N cid:26  L Pn, k, cn, k, λk, βn, μn, k  = K cid:26   cid:7   cid:8 m log2  cid:13   cid:12  + N cid:26  K cid:26  K cid:26  + N cid:26  n, kcn, k 1 − cn, k  β cid:14   cid:12   cid:13  + N cid:26  Pk, max − N cid:26  + K cid:26  K cid:26  K cid:26  + N cid:26   cid:7   cid:8   n=1 cn, kPn, k, max − Pn, k  cn, k − 1  n=1  n=1  n=1  k=1  k=1  k=1  k=1  μn, k  Pn, k  μ cid:14    cid:7   βn  λk  .  n, k  n=1  k=1   cid:8   Pn, k − cn, kPn, k, min  The Karush-Kuhn-Tucker conditions are derived as  μn, k ≥ 0, μ cid:14  ∂L ∂Pn, k  ≥ 0, = 0 →  cn, k m 1 ln 2  n, k  λk ≥ 0,  1 + gn, kPn, k   gn, k  − λk + μn, k − μ cid:14   n, k  = 0,      918   cid:2   Cognitive radios  n, kPn, k, max = 0,  ∂L ∂cn, k  = 0 → m cn, k m−1 log2 1 + gn, kPn, k  + βn n, k 1 − 2cn, k  − μn, kPn, k, min + μ cid:14  + β cid:14   cid:13  K cid:26  K cid:26  N cid:26  N cid:26  K cid:26    cid:12  Pk, max − N cid:26   cid:7  Pn, k − cn, kPn, k, min  cid:7   = 0,  n=1  n=1  k=1  k=1  μn, k  Pn, k  λk  μ cid:14   n, k  cn, kPn, k, max − Pn, k   cid:8  = 0,  cid:8  = 0.  n=1  k=1   21.28    21.29    21.30    21.31   Since there are too many parameters to solve from the Karush-Kuhn-Tucker conditions, it is difﬁcult to obtain the optimum solution. Iterative water-ﬁlling can be employed.  From  21.27 , we can derive Pn, k as a water-ﬁlling solution  Pn, k =  cn, k m     =  P0 n, k 0, = λk − μn, k + μ cid:14   1 λ cid:14  k ln 2 = 1 λ cid:14  k ln 2  − 1 gn, k − 1 gn, k  ,  ln 2 , cn, k = 1,  < gn, k  if λ cid:14  otherwise  k   21.32   λ cid:14   =  Pk, max + cid:24   Nk 1  where λ cid:14  Substituting  21.32  into  21.22 , and assuming λk is constant relative to n  that is, assuming μn, k − μ cid:14   = constant relative to n , we have  n, k.  k  n, k  ln 2 n∈Nk  ,  k  min   cid:17    cid:17    cid:18   1 gn, k   21.33  where  ·  denotes the cardinal of the set within, and Nk is the set of channels that are assigned to user k, that is, cn, k = 1, for all n ∈ Nk.  cid:18  We now consider the power constraints  21.23  and  21.24 . After estimating the power  by  21.32 , we then force the estimated power to satisfy the power constraints if cn, k = 1.  Pn, k = max  cid:24  Accordingly, λ cid:14  k must be updated by replacing Pk, max in the denominator of  21.33  by n∈Nk Pn, k, max . min Pk, max,  P0 n, k, Pn, k, max  Iterative water-ﬁlling is implemented at a centralized node of the network. The node collects all the channel gains gn, k’s, calculates the channel and power allocation, and then broadcasts the result to the cognitive radios. The algorithm assigns each channel to a user with a maximal capacity for that channel, subject to the power constraints. Given a channel, if the power constraints cannot be satisﬁed for any of the users, the channel is not assigned so as to save the power of the user batteries. An iterative water- ﬁlling algorithm for the above joint power and channel allocation scheme is given in detail in [13], and the algorithm converges to the ﬁnal solution within a few iterations.  , Pn, k, min   21.34   ,      919   cid:2   21.6 Dynamic spectrum access  The complexity of the algorithm is O NKm , where m is the number of iterations. This algorithm is of a general-purpose nature, and additional constraints can be easily inserted into the algorithm. Simulation results demonstrate that there is a substantial capacity gap between the nonconservative and conservative designs.  Example 21.2:  We now give an example to demonstrate the performance of the iterative water-ﬁlling algorithm. All the cognitive radios are assumed to have the same maximum power Pk, max = 200 mwatt, i = 1, . . . , K. Set the SINR threshold for a cognitive radio γth,k = 5 dB, the noise power at a cognitive radio N0B = 0.1 dBm. For the constraint  21.18 , the transmit power at the BS of the primary user network PT = 3 watts, the noise power at a 0B = 0.2 dBm, the distance from the ith primary user to its BS dB, i = 20 m,  cid:14  primary user N the distance from the kth cognitive radio to the ith primary user dk, i = 5 m, the propagation exponent r = 2.5, and the SINR threshold for the primary user γ0 = 5 dB. To begin with, we assume that N = 6 channels are assigned to K = 4 cognitive radios. Assume that the gain vectors gn, n = 1, . . . , N, are generated by gn =  n N 3a, a being a random vector with entries uniformly distributed in  0, 1 . For a random run with nonconservative design, we have  ⎡⎢⎢⎢⎢⎢⎢⎢⎣   cid:19   gn, k   cid:20  =  ⎡⎢⎢⎢⎢⎢⎢⎢⎣  ⎡⎢⎢⎢⎢⎢⎢⎢⎣   cid:19   cn, k   cid:20  =  0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0  0.0030 0.0247 0.1126 0.2542 0.3486 0.6945  0.0011 0.0021 0.0879 0.2867 0.1662 0.3422  ⎤⎥⎥⎥⎥⎥⎥⎥⎦ , P = ⎡⎢⎢⎢⎢⎢⎢⎢⎣ ⎤⎥⎥⎥⎥⎥⎥⎥⎦ , P =  ⎡⎢⎢⎢⎢⎢⎢⎢⎣  The algorithm generates the channel assignment C = [cn, k] and the corresponding power allocation P as  0.2000   cid:19    cid:20  =  0 0  cn, k  0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0  0 0 0 0 0 and Pn, k, max = Pk, max = 0.2. The sum capacity is 41.4935 bits s Hz. When the constraint for conservative design is applied,  0.0999 0.1001  0.0996 0.1004  0 0 0 0  0 0  ⎤⎥⎥⎥⎥⎥⎥⎥⎦  0.2000  0  0 0 0 0  ⎤⎥⎥⎥⎥⎥⎥⎥⎦  0 0  0  0.0180  0.0185 0.0185  0 0 0  0 0  0.0185  0 0 0 0 0 0  0 0 0 0 0 0  ⎤⎥⎥⎥⎥⎥⎥⎥⎦ .  0.0033 0.0199 0.0700 0.1447 0.1218 0.3643  0.0045 0.0323 0.0423 0.1557 0.0088 0.1634      920   cid:2    cid:2 Figure 21.7  The capacity for different values of N and K, with conservative design.  0    0  10  20  30  40  50  K        Cognitive radios  conserv., N = 10 conserv., N = 40 conserv., N = 100 nonconserv., N = 10 nonconserv., N = 40 nonconserv., N = 100  conserv., N = 40, K = 20 nonconserv., N = 40, K = 20 conserv., N = 80, K = 60 nonconserv., N = 80, K = 60 conserv., N = 20, K = 40 nonconserv., N = 20, K = 40  800  600  400  200    z H   s   s t i b         C y t i c a p a C  800  700  600  500  400  300  200  100    z H   s   s t i b         C y t i c a p a C   cid:2 Figure 21.8  0    0  5  10  15 20 Pk,max  dBm   25  30  35  The sum capacity versus Pk, max.  and Pn, k, max = 0.0185  cid:5  Pk, max = 0.2. The sum capacity is 23.2102 bits s Hz. Note that the ﬁrst channel is not assigned in the conservative design due to poor channel quality.  The convergence of the iterative water-ﬁlling algorithm is very fast, usually needing 2 to 4 iterations for the algorithm to converge. For different values of N and K as well as conservative and nonconservative designs, the sum capacity as a function of K is plotted in Fig. 21.7. For different N and K values, the sum capacity as a function of Pk, max is plotted in Fig. 21.8. It is seen that when Pk, max > Pn, k, max, the sum capacity tends to saturate rapidly for conservative design, while it increases at a logarithmic rate for nonconservative design. For this example, it is seen that the conservative design substantially reduces the sum capacity.      921   cid:2   21.6 Dynamic spectrum access  21.6.2 Basic game theory  Game theory resolves situations in which people’s interests conﬂict. Here we describe basic game theory using the notations given in [32, 50]. A learning automaton is an object that can choose from a ﬁnite number of actions according to its random environment. The learning automaton is capable of improving its performance with time while operating in an 5 4Si, ri, Ti, pi unknown environment. In a multiple-automata game, as illustrated in Fig. 21.9, N automata  players , A1, A2, . . ., AN, participate in a game. Each automaton Ai is represented by a to each player, pi k  =  cid:7  , where Si is a ﬁnite set of actions or pure strategies, with a cardinality 4-tuple mi, ri ∈ [0, 1] is the random payoff to player i and the result of each play is a random payoff   cid:8 T is the action choice probability distribution  cid:7  vector of player i at time k, pil k  being the probability with which player i chooses the lth pure strategy, and Ti is the stochastic learning algorithm for updating pi k  pi k + 1  = Ti ai ∈ Si being the action selected by player i. The expected payoff or utility function of player i is deﬁned as di  a1, . . . , aN   = E   cid:4  cid:4 player j chooses action aj, aj ∈ Sj, j = 1, . . . , N  pi1 k , . . . , pimi k   pi k , ai k , ri k    21.35    21.36    cid:8    cid:20    cid:19   ri  .  ,  The objective of each player is to maximize its expected payoff.  The learning algorithm for updating the action probabilities pi k  can be a reinforce- ment learning scheme, such as the linear reward-penalty  LR-P  scheme [32]. The learning automata Ai’s are updated as follows.  Algorithm 21.1  Learning Automata   1. Initialization.  Choose ai ∈ Si, i = 1, . . . , N, at random, with random pi 0 . 2. do while k = k + 1. for i = 1 to N  for all the N players   Apply ai, and observe the response ri from the environment. Update pi k  by  21.35 .  end for  until a stopping criterion is reached or pi converges.  Environment i {                    } d    a  , ..., a                       N  1  r   k      1       1a   k  A 1  A N       r   k N       a    k N   cid:2 Figure 21.9  The automata game block diagram.      922   cid:2   Cognitive radios  Given the probabilistic strategy for player i, pi, the expected payoff for player i is   cid:7   gi  p1, . . . , pN   cid:4  cid:4 player j employs strategy pj, j = 1, . . . , N   cid:20    cid:8  = E  cid:19   cid:26   di  =  j1,..., jN  N!  s=1  di   j1, . . . , jN    psjs.   21.37   In order to map a multiple-agent problem, such as a wireless network, to a game, we need to deﬁne three components of a game: players, strategy, and utility function. The players are the nodes in the network. The strategy is the action related to the functionality being investigated, and the utility function is a performance metric.   cid:7    cid:8   Nash equilibrium  is said to be a Nash equilibrium, if for each i, i =  The N-tuple of strategies 1, . . . , N, we have  1, . . . , p0 p0 N   cid:17  p0 1, . . . , p0 gi ≥ gi   cid:17    cid:18    cid:18   i−1, p0  i , p0  i+1, . . . , p0 N  p0 1, . . . , p0  i−1, pi, p0  i+1, . . . , p0 N  , for any pi ∈ [0, 1]mi.   21.38   i is a unit probability vector. The components of p0  The vector pi is a pure strategy if it is a unit probability vector, which has only one com- ponent being unity and all other components being zeros. A Nash equilibrium is said to be in pure strategies, if each p0 i have a sum of unity and are in one-to-one correspondence with the pure strategies of player i. If more than one pure strategy is assigned positive probabilities, p0 is a mixed strategy, and the i corresponding Nash equilibrium is a nondegenerated mixed Nash equilibrium. In general, each p0 i may be a mixed strategy and the Nash equilibrium deﬁned by  21.38  is in mixed strategies. It is well known that every ﬁnite strategic game has a mixed-strategy Nash equi- librium [15, 32]. Correlated equilibrium is Nash equilibrium of an expanded game with a correlating device. Like Nash equilibria, correlated equilibria also exist in ﬁnite games.  The central concept in noncooperative game theory is an equilibrium under certain conditions, such as common knowledge of rationality. A powerful way of ﬁnding Nash  cid:14  equilibria of games is to eliminate dominated strategies. Given two strategies pi and p i for  cid:14  i is said to be strictly  or weakly  dominated by pi if, for player i in a normal form game, p every choice of strategies of the other players, player i’s payoff from choosing pi is strictly  cid:14  greater than  or at least as great as  player i’s payoff from choosing p i. A practical method to compute the Nash equilibrium would be to use the sequential play where each player maximizes its own utility function sequentially while other players’ strategies are ﬁxed. A game can be solved by using an iterative process of elimination for strictly dominated strategies for all players.  A stochastic learning-based distributed solution is simple and efﬁcient. It is used to learn pi’s by considering the history of play. The learning automata algorithm needs less information and control signaling to operate than the sequential play, but it converges much more slowly than the sequential play.      923   cid:2   21.6 Dynamic spectrum access  In an N-player environment, there are a lot of Pareto solutions: there is no better solution in which all players simultaneously do better. Bargaining theory can be used for ﬁnding a good Pareto solution. Through cooperation, another outcome, which is better than the noncooperative outcome  called the threatpoint , is obtained. For solving the cooperation by using a noncooperative game theory, the most commonly used incentives are pricing and reputation.  In a cooperative game, players cooperate by forming a coalition, described by a sin- gle payoff. The share of the payoff received by all players in the coalition is a payoff vector.  Potential games  A potential game is such a game that any change in the utility function of any player due to a unilateral deviation by that player is correspondingly reﬂected in a global function, referred to as the potential function. The existence of a potential function is desirable, since it makes analysis very easy and it maximizes a global utility by only trying to maximize a player’s own utility. Exact and ordinal potential games possess a useful convergence property: players of the game are guaranteed to converge to a Nash equilibrium by playing their best response.  Repeated games  Many wireless systems co-exist with the same set of competing systems over a long period of time. This scenario can be modeled as a repeated  or dynamic  game, where the play- ers play multiple rounds, remembering their past experience in the choice of the power allocation for the next round. At the end of each stage, all the players can observe the out- come of the stage game and can use the complete history of the play to decide on the future action. A strategy in the repeated game is a complete plan of action. For the repeated game, sequences of strategy proﬁles that form a Nash equilibrium in the stage game form a Nash equilibrium in the dynamic game. The dynamic game also allows for a much richer set of Nash equilibria. The players can agree through a standardization process to operate in any Nash equilibrium of the dynamic game. This provides more ﬂexibility in obtaining a fair and efﬁcient resource allocation. By considering a repeated game, cooperation decisions are made based on the long-term payoff of each cooperating partner. Speciﬁcally, the over- all utility function is chosen to be the weighted sum of the individual utility from current cooperation period and over the next K − 1 cooperation periods.  Auction games  The auction game belongs to a special class of game with incomplete information. In an auction game, a principal  auctioneer  conditions his auctions on some information that is privately known by the other players, called agents  bidders . According to an explicit set of rules, the principle determines resource allocation and prices on the basis of bids from the agents.      924   cid:2   Cognitive radios  For example, in the pricing game for routing in the MANET, the source can be viewed as the principal, who attempts to buy the forwarding services from the candidate nodes that forward routes. The possible forwarding nodes are the bidders who compete with each other for serving the source node, by which they may gain extra payments for future use. In order to maximize their own interests, the selﬁsh forwarding nodes will not reveal their actual forwarding costs. They compete for the forwarding request by eliciting their will- ingness of the payments in the form of bids. Thus, the sender is able to lower its forwarding payment by the competition among the candidate routing nodes based on the auction rules.  21.6.3 Four persona models  Selﬁsh behavior by players may lead to a Nash equilibrium that is socially undesirable and is a suboptimal equilibrium. Therefore, it is imperative to make the network robust to selﬁsh behavior, by punishing selﬁsh behavior, or by credit-exchange-based and reputation- based incentive mechanisms.  The conventional representation of the human actor, the so-called rational actor model or Homo economicus model, is adopted in game theory. The players choose their actions independently, but their choice impacts on all the players in the network. The players are rational: they act in their best interest by maximizing their own utility. In a noncooperative game, players act selﬁshly such that their actions maximize their own utilities. Cooperation of such users can be implemented by using coalitional game theory or by designing cooper- ative protocols based on a noncooperative game, for which the selﬁsh utility of each player is modiﬁed by a pricing function to enable cooperation. For coalitional games, players cooperate by forming coalitions, each coalition having a single payoff. Rational learning does not converge to Nash equilibrium in general [20]. No-regret learning is able to learn and converge to mixed strategy equilibria in games, and also to converge to a pure strategy Nash equilibrium if it exists for a given game [20]. The no-regret learning formulation is particularly useful to accommodate selﬁsh users. The method replaces explicit opponent modeling with an implicit regret matrix, θ l  n, for player l at time n.  In the rational actor model, people behave like self-interested, outcome-oriented actors with anonymous, nonstrategic interactions. Here, we discuss a common pool resource game. For a group of n players, each player i is expected to invest so as to control the probability pi of damaging the system. The more player i invests, the lower pi is expect to be. Each player is selﬁsh, and tries to maximize its own utility, but does not consider the overall condition of the system. In this case, the payoff for player i can be deﬁned as [19]   cid:13    cid:12  1 − 1 n  n cid:26   i=1  − cp2 i ,  pi  ui   pi  = pi   21.39   where c > 0 is a cost for not investing. If no player invests, ui is close to zero. This is an example of the “tragedy of the commons”. On the other hand, if most players invest a sufﬁcient amount, then the payoff of player i is nearly pi. The unique Nash equilibrium in ∗ this game is p i  , and [19]  =  1  1+2c+ 1  n      925   cid:2   21.6 Dynamic spectrum access  ui =  c + 1  1 + 2c + 1 n  2  n  .   21.40   Three other persona models are usually considered in game theory in case of strategic interactions [19]. The Homo reciprocans model pays importance on reciprocity in strate- gic interaction. The persona Homo reciprocans exhibits strong reciprocity, which tends to cooperate and share with others similarly disposed, to punish those who violate coopera- tive norms, even at personal cost and even with no future rewards from so doing. Homo reciprocans is an altruist in the sense that he improves the welfare of a group of unrelated individuals at the expense of his personal welfare. In contrast, the conventional Homo eco- nomicus cooperates and punishes only if it is in his long-term interest. The persona Homo egualis may be willing to reduce his own payoff to increase the equality in the group when on top, but is displeased and exhibits a strong urge to reduce inequality when on the bot- tom. The persona Homo parochius divides the world into insiders and outsiders, and values insiders more highly than outsiders, and partially suppresses personal goals in favor of the goals of the group of insiders.  The Homo egualis society, as a distributed model, can be modeled by the utility function  of player i in an n-player game [19]   cid:26    cid:7   xj>xi   cid:8  − βi  n − 1   cid:26    cid:7   xj<xi   cid:8   xi − xj  ,  ui = xi − αi n − 1  xj − xi   21.41   where xi, . . . , xj are the payoffs for the players, and 0 ≤ βi < αi ≤ 1. Homo egualis exhibits a weak urge to increase inequality when doing better than the others and a strong urge to reduce inequality when doing worse than the others, that is, the Homo egualis agents have the inequality aversion property, which is especially desirable for dealing with fairness.  21.6.4 Game-theoretic models for dynamic resources allocation  The most popular tool for analyzing wireless networks is game theory. A cognitive radio network can be regarded as a chaotic game, trying to ﬁnd the equilibrium of conﬂicting actions that meet the nodes’ operational goals across different network layers in a speciﬁc environment. From game theory, if the cognitive radios do not cooperate, there is a unique Nash equilibrium. At this point, the achievable rate is bounded by a constant, regardless of the available transmit power [27].  Game theory is especially useful for dynamic resource allocation, routing, cross-layer protocol design of a wireless network, including cognitive networks and wireless ad hoc sensor networks. In a game-theoretic framework, the players of the game are the network nodes, such as cognitive radios or sensor nodes, their actions are their choices of transmission parameters  e.g., transmission powers, access probability, backoff inter- val, relaying nodes , and their utilities are their deﬁned performance measures, such as their generic QoS metrics, which can be a combination of throughput, delay, energy, interference-related measures  e.g., SIR or SINR, or equivalent BER requirement , etc.      926   cid:2   Cognitive radios  Cooperation in wireless networks can improve the performance by exploiting some form of multiuser diversity. In a cooperative spectrum sensing strategy, all cognitive radios collaborate by sharing their decisions regarding spectrum occupancy of the pri- mary users. Cooperative detection can be exploited to relax the requirements on the detectors of the individual cognitive radios or to improve the agility of the entire network.  Game theory has been applied to a wireless network at the physical layer  for distributed power control and waveform adaptation , link layer  for channel assignment , and network layer  for packet forwarding, throughput management .  A game-theoretic model to obtain the optimal pricing for dynamic spectrum sharing in cognitive radio networks has been proposed in [34], where multiple primary services com- pete to offer spectrum access opportunities to the secondary service and the ﬁrms adjust their prices dynamically to gain the highest proﬁt. In [2], a pricing policy was introduced for voice services in a wireless LAN environment considering both QoS performance and users’ willingness-to-pay.  In [50], stochastic learning-based techniques were exploited to discover the equilibrium solution. Let λ and μ represent the arrival and service rates of a cognitive radio type, respectively. Each cognitive radio only contends for the spectrum with probability pi, so the actual trafﬁc load to the system can be approximated by piλi. To obtain the optimum pi, from the Markov model for general trafﬁc load, all the λi’s and μi’s are required and this, however, is impractical in a real access scenario. A more practical scheme is to learn pi with only local information.  In [33], distributed adaptive channel allocation is described with the assumption that the cognitive radios can measure the local interference temperature on different frequencies and can adjust it by optimizing the information transmission rate. Targeting at a BER or an equivalent SIR requirement, the channel allocation problem is modeled as a potential game which converges to a deterministic Nash equilibrium point. No-regret learning is applied with cooperation on the potential game.  Pricing and resource allocation are closely related, as a service provider wants to max- imize its revenue and the user desires to maximize his satisfaction in terms of QoS performance and price. A joint power channel allocation scheme that uses a distributed pricing strategy has been proposed in [47]. The proposed price-based iterative water- ﬁlling algorithm enables cognitive radios to reach a good Nash equilibrium. The algorithm can be implemented distributively, with cognitive radios repeatedly negotiating their best transmission powers and spectrum.  The auction mechanism can be used for resource allocation in wireless networks. In [5], a bandwidth allocation algorithm has been proposed for wireless ad hoc networks, in which ﬂows are bidding for resources. It is a distributed, QoS-aware, price-based allo- cation algorithm that allocates bandwidth to ﬂows based on information that is locally available. In [51], a sensor network is constructed with a mix of mobile and static sensors to achieve a balance between sensor coverage and sensor cost. Bidding protocols are used to guide the movement of mobile sensors to increase the coverage. In the protocols, static sensors detect coverage holes locally by using Voronoi diagrams and bid mobile sensors to move.      927   cid:2   21.6 Dynamic spectrum access  Fairness and efﬁciency  Efﬁciency and fairness are the main goals of a spectrum etiquette. An important metric for dynamic spectrum access is the average airtime per cognitive radio system. Airtime is the ratio of allocation time per cognitive radio to the reference time. Fairness can be achieved by cooperation. For perfect fairness and maximal airtime for each cognitive radio, there is an access probability vector that no cognitive radio system can do better in terms of airtime share without harming the other cognitive radio systems [49, 50]. When fairness is not considered, the most spectrum-efﬁcient access is that all users compete for the spectrum greedily; this may, however, always block some cognitive radios from spectrum access.  In practice, the trafﬁc loads of different cognitive radio systems and the operator’s pol- icy for the purpose of revenue must also be considered. This requires the deﬁnition of weighted fairness, that is, the airtime tair for each cognitive radio over the product of the priority parameter θi and the trafﬁc load λi, that is, , is the same for all the cognitive radios. Efﬁciency is achieved if each cognitive radio is subject to the weighted fairness. The airtime can be replaced by the average cumulative on-spectrum time per cognitive radio tonair, and the payoff xi = tonair , where λi can be estimated by historical usage records of cognitive radio i.  tair θiλi  θiλi  In a noncooperative strategy, an access technique inspired by the Homo egualis model can be used for achieving fairness in spectrum access. Each cognitive radio can update its access probability pi by [50]  ⎛⎝0, min  ⎛⎝1, pi + αi  n − 1   cid:2    cid:26   xj≥xi   cid:3   xj − xi xj  − βi n − 1   cid:3 ⎞⎠⎞⎠ ,   cid:2    cid:26  xj − xi xj for all j  cid:18 = i,  xj<xi   21.42  where initially pi = 1, and n is the number of cognitive radios. The average cumulative on-spectrum times of the cognitive radios that use the same spectrum block are needed. This can be done by book-keeping the busy time of the required spectrum based on period- ical spectrum scanning and cognitive radio detection technologies. Thus, each cognitive radio can access the spectrum based only on its own book-keeping and its own local measurement.  The blocking probability of each cognitive radio is another important metric, and it is determined by all the state probabilities πj and the trafﬁc loads for different cognitive radios λj [49]. By modeling the arrival trafﬁc as a Poisson’s process, all the cognitive radios have almost the same airtime share and blocking probability by using this access scheme; this is fairness [49, 50].  pi = max  QoS and interference temperature constraints  When revenue is treated as the primary concern, we may also consider the QoS and inter- ference temperature constraints. For secondary spectrum sharing among spread spectrum users, the interference temperature constraint decides the SINR  or equivalently, BER  of each user and it is translated to a total received power threshold Pth at the measuring point. The QoS constraint deﬁnes different priorities or throughputs, which are related to the      928   cid:2   Cognitive radios   cid:24   payments of the secondary users. Assuming ai to be the priority parameter for link i, the i ai, operator problem can be formulated as maximization of the network revenue, max subject to the constraints on SIR, interference temperature, and transmission power of the ith link that transmits. The priority parameter ai increases with the price ci. In particular, one can select ai = cα i , 0 ≤ α ≤ 1; that is, a small α allows more active secondary links, while a large α guarantees services to users that pay higher price.  In this game, each cognitive radio maximizes its utility function ui by its choice of being active or not. The system will reach an operating point where the network revenue is maximized while satisfying QoS and interference temperature constraints. A stochastic learning algorithm for the operator problem has been given in [50], where the probabilities are updated using the linear reward-inaction  LR-I  reinforcement learning. It is composed of two phases. The coordination process controls the optimal set of active secondary links that access the spectrum, and the power control phase ensures the minimum target link SIRs given the set of active links.  When multiple cognitive radios access  or overlay on  the same channel  e.g., in a MC- CDMA system , one needs to minimize the total power consumption for all the K users while satisfying the data rate  or SINR  requirement of each user. Assuming that Pi and γth,i, i = 1, . . . , K, are the transmit power and the corresponding SINR threshold for cog- nitive radio i, respectively, the received SINR at cognitive radio i should satisfy the data rate constraint   cid:24   γi =  αiiPi αjiPj + Ni  j cid:18 =i  ≥ γth,i,  where αji is the channel gain between the jth transmitter and the ith receiver, and Ni is the noise power at the ith receiver. A simple iterative distributed power control algorithm to solve  21.43  subject to the power constraint Pi ≤ Pi,max, which achieves the optimal power allocation, is given by [14]   21.43    21.44   Pi k + 1  = γth,i γi k   Pi k .  Problems  21.1 Brieﬂy describe the salient features of MCUs, DSPs, FPGAs, and ASICs. Give the trade-offs in using these chips.  21.2 Assume a cognitive radio system that needs to identify BPSK, QPSK, and GMSK modulation formats. Which parameters can effectively differentiate them? Design a classiﬁer for this purpose.  21.3 Deﬁne a noncooperative game to solve the DSA problem described in Section 21.6.1. Give your utility function.  21.4 For Problem 21.3, solve the deﬁned game. Compare the sum capacity with that obtained in Example 21.2.      929   cid:2   References  References  [1] B. G. Agee, S. V. Schell & W. A. Gardner, Spectral self-coherence restoral: A new approach to blind adaptive signal extraction using antenna arrays. Proc. IEEE, 78:4  1990 , 753–766.  [2] L. Badia, S. Merlin, A. Zanella & M. Zorzi, Pricing VoWLAN services through a  micro-economic framework. IEEE Wireless Commun., 13:1  2006 , 6–13.  [3] D. Cabric & R. Brodersen, Robust spectrum sensing techniques for cognitive radio networks. In F. H. P. Fitzek & M. D. Katz, eds., Cognitive Wireless Networks  Dordrecht, The Netherlands: Springer, 2007 , 373–394.  [4] K. Chapman, P. Hardy, A. Miller & M. George, CDMA Matched Filter Implementa-  tion in Virtex Devices, Xilinx XAPP212  v1.0 , 2000.  [5] C. Curescu & S. Nadjm-Tehrani, A bidding algorithm for optimized utility-based resource allocation in ad hoc networks. IEEE Trans. Mobile Comput., 7:12  2008 , 1397–1414.  [6] N. Devroye, P. Mitran & V. Tarokh, Achievable rates in cognitive radio. IEEE Trans.  Inf. Theory, 52:5  2006 , 1813–1827.  [7] F. F. Digham, M.-S. Alouini & M. K. Simon, On the energy detection of unknown signals over fading channels. In Proc. IEEE ICC, Seattle, WA, May 2003, 5, 3575– 3579.  [8] F. F. Digham, Joint power and channel allocation for cognitive radios. In Proc. IEEE  WCNC, Las Vegas, NV, Mar–Apr 2008, 882–887.  [9] O. A. Dobre, A. Abdi, Y. Bar-Ness & W. Su, Survey of automatic modulation classi- ﬁcation techniques: classical approaches and new trends. IET Commun., 1:2  2007 , 137–156.  [10] K.-L. Du & M. N. S. Swamy, Neural Networks in a Softcomputing Framework   London: Springer, 2006 .  [11] K.-L. Du & M. N. S. Swamy, A class of adaptive cyclostationary beamforming  algorithms. Circ. Syst. Signal Process., 27:1  2008 , 35–63.  [12] K.-L. Du & W. H. Mow, Exploiting Multiple Antennas for Spectrum Sensing in  Cognitive Radio Networks, U. S. Patent Application, 2009.  [13] K. -L. Du, M.N. S. Swamy & Q. Ni, A dynamic spectrum access scheme for cognitive  radio networks. In Proc. IEEE CCECE, St. John’s, Canada, May 2009.  [14] G. J. Foschini & Z. Miljanic, A simple distributed autonomous power con- IEEE Trans. Veh. Tech., 42:4  1993 ,  trol algorithm and its convergence. 641–646.  [15] D. Fudenberg & J. Tirole, Game Theory  Cambridge, MA: The MIT Press, 1992 . [16] T. Fusco, L. Izzo, A. Napolitano & M. Tanda, On the second-order cyclostationarity properties of long-code DS-SS signals. IEEE Trans. Commun., 54:10  2006 , 1741– 1746.  [17] W. A. Gardner, Statistical Spectral Analysis: An Nonprobabilistic Theory  Englewood  Cliffs, NJ: Prentice-Hall, 1987 .      930   cid:2   Cognitive radios  [18] W. A. Gardner, Signal interception: a unifying theoretical framework for feature  detection. IEEE Trans. Commun., 36:8  1988 , 897–906.  [19] H. Gintis, Game theory Evolving: A Problem-Centered Introduction to Modeling  Strategic Behavior  Princeton, NJ: Princeton University Press, 2000 .  [20] A. Greenwald & A. Jafari, A general class of no-regret algorithms and game-theoretic equilibria. In Proc. 16th Ann. Conf. Learning Theory  COLT , Washington, DC, Aug 2003, 1–11.  [21] Z. Han & H. Jiang, Replacement of spectrum sensing and avoidance of hidden ter- minal for cognitive radio. In Proc. IEEE WCNC, Las Vegas, NV, Mar–Apr 2008, 1448–1452.  [22] S. Haykin, Cognitive radio: brain-empowered wireless communications. IEEE J. Sel.  Areas Commun., 23:12  2005 , 201–220.  [23] R. W. Heath, Jr. & G. B. Giannakis, Exploiting input cyclostationarity for blind channel identiﬁcation in OFDM systems. IEEE Trans. Signal Process., 47:3  1999 , 848–856.  [24] X. H. Huang, K.-L. Du, A. K. Y. Lai & K. K. M. Cheng, A uniﬁed software radio  architecture. In Proc. IEEE SPAWC, Taoyuan, Taiwan, Mar 2001, 330–333.  [25] A. Jamin, P. Mahonen & Z. Shelby, Software radio implementability of wireless LANs. In E. Del Re, ed., Software Radio: Technologies and Services  London: Springer, 2001 .  [26] W. S. Jeon, D. G. Jeong, J. A. Han, G. Ko & M. S. Song, An efﬁcient quiet period management scheme for cognitive radio systems. IEEE Trans. Wireless Commun., 7:2  2008 , 505–509.  [27] E. G. Larsson & E. A. Jorswieck, The MISO interference channel: competition versus collaboration. In Proc. Allerton Conf. Commun., Control, and Computing, Monticello, AR, Sep 2007.  [28] K. B. Letaief & W. Zhang, Cooperative spectrum sensing. In E. Hossain & V. Bhar- gava, eds., Cognitive Wireless Communication Networks  Berlin: Springer, 2007 , pp. 115–138.  [29] T. Li, W. H. Mow, V. K. N. Lau, M. Siu, R. S. Cheng & R. D. Murch, Robust joint interference detection and decoding for OFDM-based cognitive radio systems with unknown interference. IEEE J. Sel. Areas Commun., 25:3  2007 , 566–575.  [30] M. Luby, LT codes. In Proc. IEEE FOCS, Vancouver, Canada, Nov 2002, 271–282. [31] J. Mitola III & G. Q. Maguire, Jr., Cognitive radio: making software radios more  personal. IEEE Pers. Commun., Aug 1999, 13–18.  [32] K. Narendra & M. A. L. Thathachar, Learning Automata: An Introduction  Engle-  wood cliffs, NJ: Prentice Hall, 1989 .  [33] N. Nie & C. Comaniciu, Adaptive channel allocation spectrum etiquette for cognitive  radio networks. In Proc. IEEE DySPAN, Baltimore, MD, Nov 2005, 269–278.  [34] D. Niyato & E. Hossain, Competitive pricing for spectrum sharing in cognitive radio networks: Dynamic game, inefﬁciency of Nash equilibrium, and collusion. IEEE J. Sel. Areas Commun., 26:1  2008 , 192–202.  [35] M. Oner & F. Jondral, Air interface recognition for a software radio system exploiting cyclostationarity. In Proc. IEEE PIMRC, Barcelona, Spain, Sep 2004, 3, 1947–1951.      931   cid:2   References  [36] Z. Quan, S. Cui, A. H. Sayed & H. V. Poor, Wideband spectrum sensing in cognitive  radio networks. In Proc. IEEE ICC, Beijing, China, May 2008, 901–906.  [37] X. Reves, A. Gelonch & F. Casadevall, Software radio implementation of a DS- CDMA indoor subsystem based on FPGA devices. In Proc. IEEE PIMRC, San Diego, CA, Sep–Oct 2001, 1, D-86–D-90.  [38] A. Sahai, N. Hoven & R. Tandra, Some fundamental limits on cognitive radio. In Proc. 42nd Allerton Conf. Commun. Contr. and Comput. Monticello, IL, Oct 2004., 1–11.  [39] A. Sendonaris, E. Erkip & B. Aazhang, User cooperation diversity – part I: system description; part II: implementation aspects and performance analysis. IEEE Trans. Commun., 51:11  2003 , 1927–1948.  [40] O. Simeone, Y. Bar-Ness & U. Spagnolini, Stable throughput of cognitive radios with  and without relaying capability. IEEE Trans. Commun., 55:12  2007 , 2351–2360.  [41] P. D. Sutton, K. E. Nolan & L. E. Doyle, Cyclostationary signatures for rendezvous in OFDM-based dynamic spectrum access networks. In Proc. IEEE DySPAN, Dublin, Ireland, Apr 2007, 220–231.  [42] P. D. Sutton, K. E. Nolan, and L. E. Doyle, Cyclostationary signatures in practical  cognitive radio applications. IEEE J. Sel. Areas Commun., 26:1  2008 , 13–24.  [43] Z. Tian and G. B. Giannakis, A wavelet approach to wideband spectrum sensing for cognitive radios. In Proc. IEEE 1st Int. Conf. Cognitive Radio Oriented Wireless Networks and Commun., Greece, Jun 2006, 1–5.  [44] T. Turlett, H. J. Bentzen & D. Tennenhouse, Toward the software realization of a GSM  base station. IEEE J. Sel. Areas Commun., 17:4  1999 , 603–612.  [45] US DoD, Programmable Modular Communications System  PMCS  Guidance Doc-  ument, US Department of Defense, Washington DC, Jul 31, 1997.  [46] D. Z. Vucic, M. M. Obradovic & D. M. Obradovic, Spectral correlation of OFDM signals related to their PLC applications. In Proc. 6th Int. Symp. Power-Line Comm. and Its Appl.  ISPLC , Athens, Greece, Mar 2002, 1–4.  [47] F. Wang, M. Krunz & S. Cui, Price-based spectrum management in cognitive radio  networks. IEEE J. Sel. Topics Signal Process., 2:1  2008 , 74–87.  [48] W. Xiang, T. Pratt & X. Wang, A software radio testbed for two-transmitter two- receiver space-time coding OFDM wireless LAN. IEEE Commun. Mag., 42:6  2004 , S20–S28.  [49] Y. Xing, R. Chandramouli, S. Mangold & S. Shankar N, Dynamic spectrum access in open spectrum wireless networks. IEEE J. Sel. Areas Commun., 24:3  2006 , 626– 637.  [50] Y. Xing, H. Kushwaha, K. P. Subbalakshmi & R. Chandramouli, Codes and games for dynamic spectrum access. In H. Arslan, ed., Cognitive Radio, Software Deﬁned Radio, and Adaptive Wireless Systems  Berlin: Springer, 2007 , pp. 161–187.  [51] G. G. Wang, G. Cao, P. Berman & T. F. La Porta, Bidding protocols for deploying  mobile sensors. IEEE Trans. Mobile Comput., 6:5  2007 , 515–528.      22  Wireless ad hoc and sensor networks  22.1 Introduction  A wireless ad hoc network is an autonomous, self-organized, distributed, peer-to-peer net- work of ﬁxed, nomadic, or mobile users that communicate over bandwidth-constrained wireless links. There is no preexisting infrastructure. Wireless ad hoc networks can be relay, mesh, or star networks comprising special cases. When the nodes are connected in mesh topology, the network is also known as a wireless mesh network. It is known as a mobile ad hoc network  MANET , when the nodes are mobile.  A wireless ad hoc network has a mutlihop relaying of packets, as shown in Fig. 22.1. It can be easily and rapidly deployed, and expensive infrastructures can be avoided. With- out an infrastructure, the nodes handle the necessary control and networking tasks by themselves, generally by distributed control. Typical applications are wireless PANs for emergency operations, civilian, and military use. The wireless ad hoc network is playing an increasing role in wireless networks, and wireless ad hoc networking mode has been or is being standardized in most IEEE families of wireless networks.  MANETs and wireless sensor networks  WSNs  are the two major types of wireless ad hoc networks. They both are distributed, multi-hop systems. A MANET is an autonomous collection of mobile routers  and associated hosts  connected by wireless links. Each node is an information appliance, such as a personal digital assistant  PDA , equipped with a radio transceiver. The nodes are fully mobile. A WSN is a special kind of wireless ad hoc network with distributed sensing and processing capability. There may be densely distributed sensors that are equipped with low-power wireless transceivers, memory, and batteries. In both MANETs and WSNs the nodes act both as hosts and as routers. WSNs are distinguished from MANETs by processing the data gathered by sensors. The goal of WSNs is the detection estimation of some events of interest, and not just communication. MANETs employ a node-centric communication model.  22.1.1 Wireless sensor networks  WSNs are an emerging technology that has the potential to revolutionize many aspects of our life. A WSN consists of a number of self-powered nodes with built-in computing power and sensors for acquiring data from the environment, as well as wireless communi- cation capability. Many WSNs require little power and could potentially be deployed for a number of years. Attaching sensors to RFID tags or wireless nodes adds awareness to      933   cid:2   22.1 Introduction   cid:2 Figure 22.1  Wireless ad hoc network.  Internet or  other networks  Sink  C  D  B  A  Management  node   cid:2 Figure 22.2  WSN illustration.  ubiquitous networks. This awareness means that the network can detect and respond to the environment, without human interaction.  A WSN is illustrated in Fig. 22.2. Sensed information at the nodes is relayed to a sink node  BS  by using multihop communication. The sink node has gateway functions to link to external networks such as the Internet. Typical receiver sensitivities are between −85 and −110 dBm. Unlike a general ad hoc network, the WSN has the features of application-speciﬁcity, environment interaction, simplicity and scalability, energy-efﬁciency, self conﬁgurability, QoS, and data-centricity. More speciﬁcally, [5, 55]   The number of sensor nodes in a WSN can be huge.   Sensor nodes are densely deployed.   Sensor nodes are prone to failures, or may die.   The topology of a sensor network changes very frequently.   Sensor nodes mainly communicate by broadcast, whereas most ad hoc networks are based on point-to-point communications.   Information exchange between end-to-end nodes is rare in WSNs.      934   cid:2   Wireless ad hoc and sensor networks    Sensor nodes are limited in resources, such as power, computational resources, and bandwidth. A sensor node  or mote  is powered by a battery, which it is often unfea- sible to recharge. Thus, energy efﬁciency is the primary concern in WSN design. Due to power restriction, computation is preferred over the network, rather than at the node.   Each node has its own identiﬁer, but may not have global identiﬁcation  ID  because of the large amount of overhead and large number of sensors.  WSNs are similar to the MANETs, but have several major differences: WSNs involve little or low mobility, and they have much tighter computation and communication constraints.  Some application examples of WSNs are given below.   Environmental monitoring: habitat monitoring, integrated biology, structural monitor- ing, forest wildﬁre monitoring, ﬂood detection, volcano monitoring, disaster detection, monitoring of drinking water, monitoring of air pollution, smart environments, climate and weather forecasting.   Healthcare: telemonitoring of human physiological data, tracking and monitoring of doctors and patients, machine health monitoring, remote virus monitoring.   Military: battleﬁeld surveillance, reconnaissance of enemy forces, monitoring and handling of nuclear, biological and chemical attacks, asset monitoring and management.   Home applications: intrusion detection, home automation, high-security smart homes, building comfort, climate control in large buildings, remote metering.   Interactive and control: pursuer-evader, industrial automation.   Warehouse management: tracking of goods in retailer stores, tracking of articles in warehouse.   Commercial applications: monitoring of material fatigue, monitoring of product quality, bridge monitoring, vehicle-based trafﬁc monitoring.   Precision agriculture: crop and livestock management, precise control of fertilizer concentrations.   Public security and surveillance: tracking, identiﬁcations, and personalization.   Scientiﬁc exploration: exploration of outer space and deep oceans.  In addition, mobile WSNs that use robots to carry sensors are also used for hazard processing. A mobile sensor network is a multi-robot system.  IEEE 802.15.4  ZigBee  and 802.15.4a are most promising for WSNs. IEEE 1451 is the standard for smart sensor networks. IEEE 1451 makes it easier for different manufac- turers to develop smart sensors and to interface those devices to networks. IEEE 802.15.4  ZigBee  is especially suited to WSNs. It uses CSMA CA and optional time-slotting pro- tocol. While IEEE 802.15.1  Bluetooth  supports moderate duty cycle with short battery life, but with a very high QoS and low latency, ZigBee supports very low duty cycle with an optional low latency and long battery life. However, Bluetooth Piconet supports a maximum number of eight nodes, whereas ZigBee supports up to 254 nodes in its network.      935   cid:2   22.2 Routing  22.2 Routing  Multihop communication in a WSN can effectively overcome shadowing and path loss effects. Routing of wireless ad hoc networks faces severe challenges, such as securing broadcast wireless communication in an untrusted environment as well as ﬁnding the route itself. Routing is more difﬁcult in MANETs due to the dynamic network topology. Enforc- ing collaboration is an important aspect in designing a secure and reliable wireless ad hoc network.  The traditional routing problems of unicast, multicast, anycast, and convergecast routing exist in wireless ad hoc networks for various purposes. Anycast refers to the case where a message is sent to an object name that has potentially multiple instantiations in the network, and any of these will do. Convergecast describes the notion of collecting data from several sources at a central point.  Flooding is a simple approach in which all nodes other than the target node forward a transmitted packet at least once. Flooding guarantees deliverability even if there are mali- cious nodes, as long as at least one adversary-free path exits. A node sends the received data or the management packets to its neighbors by broadcasting, unless a maximum number of hops for the packets is reached or the destination is gained. Flooding is not energy-  resource-aware, and it also introduces overlapping of measuring region and implosion of data.  In the gossiping protocol [25], each node forwards the incoming data packets to a ran- domly selected neighbor node  including the neighbor sending to it . Gossiping can save energy, and solve the implosion problem, but it still cannot avoid overlapping. Gossip- ing causes delays in propagation of data through the nodes. Alternatively, location-based routing protocols utilize positional information to make routing decisions.  While ﬂooding and gossiping are simple approaches that combine routing and data transmission, they cause huge network trafﬁc. Many other routing protocols divide com- munication into routing operations  route discovery and route maintenance  and data communication. Once a route is selected, multiple data packets can be transmitted along the same route during the route lifetime. This reduces the trafﬁc overhead, since only the nodes on the route retransmit the packet. Routing protocols that take this two-step strategy are classiﬁed as proactive, reactive, and hybrid.  Proactive routing protocols, also known as table-driven routing protocols, utilize tables to determine the next hop to reach the required destination. Each node maintains cur- rent routing information regarding the connectivity of every node to all other nodes that participate in the network. Every node has information on the network topology by propagating periodic updates. All nodes are able to make immediate decisions on the for- warding of a speciﬁc packet, thus the session establishment time is greatly reduced. This causes a constant amount of signaling trafﬁc in the network for keeping routes up-to-date. Early proactive routing schemes were based on distance-vector routing  DVR  protocols that exploit the distributed Bellman-Ford  DBF  algorithm for computing. The shortest path in a weighted graph represents the network. Destination-sequenced distance-vector  DSDV  routing [53] is a DBF-algorithm-based routing protocol for ad hoc networks.      936   cid:2   Wireless ad hoc and sensor networks  Optimized-link-state routing  OLSR  [32] is a proactive MANET routing protocol that is based on the link-state algorithm.  Reactive routing is a source-initiated on-demand approach. A route is created only when the source node requires a route to a speciﬁc destination. Reactive route discov- ery is usually based on a query reply exchange, where ﬂooding is used to reach the desired destination. Once the route discovery is completed and a path is established, the buffered data packets are sent. An established route is maintained depending on whether it is required or not. Reactive routing avoids the potential wastage of channel capacity and energy. However, a discovery delay is incurred at the time of transmission. The dynamic-source-routing  DSR  protocol [36] and ad hoc on-demand distance-vector  AODV  routing [54] are two well-known reactive routing protocols, and they are, respec- tively, standardized for routing Internet packets over MANETs and other wireless ad-hoc networks in IETF RFCs 4728 and 3561. AODV tries to improve DSR by maintaining routing tables at the nodes, so that the data packets do not contain the source-destination path.  An example of hybrid routing protocols is the zone-routing protocol  ZRP  [24]. The network is divided into zones, where every zone is a r-hop neighborhood of a node. The intra-zone routing protocol is a proactive routing protocol, while the inter-zone routing protocol is a reactive routing protocol.  QoS guarantees are required by most multimedia and other applications. Due to unreli- able wireless channel, node mobility, lack of centralized control, channel contention, and limited node resources, QoS guarantees in MANETs are most challenging. The QoS rout- ing protocol is required for any QoS solution since it selects the nodes, if any, to serve the requirements of the applications. Consequently, it plays a crucial role in data session admission control. In this case, both routes and QoS states are required to be discovered. Hybrid route discovery state discovery schemes are feasible. One solution is to discover the routes proactively, but the QoS state is only sought for a QoS-constrained data ses- sion. Another solution is the QoS state discovery following the proactive reactive route discovery.  Routing protocols for MANETs can also be classiﬁed into topological routing and geographic routing. A hybrid routing protocol can take advantage of both schemes by exploiting topological information, geographic information, and hierarchy information at the same time.  22.3 Security  22.3.1 Security problems  Security for wired and wireless communications provides the functions of:   Conﬁdentiality. Data is only revealed to the intended user. Conﬁdentiality refers to data privacy, which is typically achieved via cryptographic mechanisms.      937   cid:2   22.3 Security    Integrity. Data cannot be modiﬁed during the transmission. Integrity protects against data tampering, typically achieved through message authentication codes or by one-way hash functions.   Authentication. An entity must pass the identiﬁcation before getting served. Authentica- tion can be considered a special integrity class, known as origin integrity.   Authorization. An entity must get authorization before it takes action.   Access control. Ensures that only authorized actions can be performed.   Nonrepudiation. Prevents an entity from denying its actions. There is safeguard to prevent a node from denying that it signed a given message.   Availability. Ensures that authorized actions can take place. For example, routes retuned by routing protocols must remain functional.  Security also needs to protect the privacy of users. The security problems for wireless ad hoc networks are basically the same as those for other wireless networks.  Security is implemented on multiple layers. At the link layer, strong encryption should be used to prevent over-the-air eavesdropping, and access control is applied to prevent unauthorized users from using the precious wireless channels. Authentication and autho- rization can be implemented by using AAA  authentication, authorization, and accounting  protocols and some other schemes such as IPsec and ﬁrewalls, at the network layer in the IP stack. At the transport layer, TLS  Transport Layer Security  is employed by using the certiﬁcate architecture. At the application layer, a number of schemes can be selected, such as digital signature and certiﬁcates, to provide both privacy and authentication.  In addition to providing conﬁdentiality and data integrity between source and des- tination, cryptographic mechanisms are an essential requirement for MANET routing operations. Secure routing schemes rely on authentication  digital signatures or keyed MACs  to ensure only trusted insiders make up the routes.  Attacks in wireless ad hoc networks  Two kinds of security attacks on a wireless ad hoc network may take place: active attacks and passive attacks. An active attack is a deliberate disruption of network activity. Some examples of active attacks are:   Denial-of-service attack. An attacker excludes legitimate users from network services by ﬂooding, or by occupying valuable network resources, or destroying conﬁguration information.   Wormhole attack. An attacker connects two distant wormhole nodes using a private wormhole link. Due to tunneling, routing between the two regions tends to use the shortcut wormhole link, and the two wormhole nodes may drop packets, or selectively forward packets to avoid detection, or spy on the packets going through.   Blackhole or sinkhole attack. This is suction of packets towards a malicious node by advertising itself as having the shortest path to all nodes in the network. The attacker then drops all the received packets, or performs selective forwarding, or alters the data passing through it, or can monitor and analyze the trafﬁc.      938   cid:2   Wireless ad hoc and sensor networks    Grayhole attack. An attacker drops all data packets but lets control messages route through it. This makes the detection of the attack more difﬁcult.   Man-in-the-middle attack. The attacker impersonates the receiver with respect to the sender, and the sender with respect to the receiver.   Sybil attack. Launched by a malicious node that illegally acquires multiple identities.   Blackmail attack. The attacker causes false identiﬁcation of a legitimate node as a malicious node. An attacker may blackmail a good node and tell other nodes in the network to add that node to their blacklists, thus avoiding the victim node in future routes.   Routing table poisoning. A malicious node sends false routing updates, resulting in suboptimal routing, network congestion, or network partition.   Misrouting attack. A malicious node sends a data packet to the wrong destination by modifying the ﬁnal destination address of the data packet or by forwarding a data packet to the wrong next hop in the route to the destination.   Sleep deprivation. An attacker prevents victim nodes from sleeping by bombarding them with legitimate requests, or making requests to the victims only as often as necessary to keep them awake. This makes the nodes soon run out of energy.   Detour attack. An attacker adds some virtual nodes into a route during the route dis- covery phase so as to divert the trafﬁc to other routes that appear to be shorter and might contain malicious nodes which could create other attacks. This attack is speciﬁc to source routing protocols.   Rushing attack. A malicious node attempts to tamper with RouteRequest packets, modify the node list, and hurry its packet to the next node.  A passive attack can be a selﬁsh node attack or eavesdropping. It may drop packets so as to prioritize its own trafﬁc or conserve its energy, and this does not cause any intentional damage to the network. In order to stimulate cooperation between nodes, collab- oration schemes are proposed based on credit, reputation, game theory, and other measures. Countermeasures to many security problems are discussed in [15].  Key management has remained a challenging issue in wireless ad hoc networks. This is especially true for WSNs due to the constraints of node resources. Before a network can exchange data securely, encryption keys must be established among nodes. Key distribution refers to the distribution of multiple keys among the nodes. Key management includes the processes of key setup, the initial distribution of keys, and key revocation.  Intrusion detection attempts to identify those systems or users who are trying to break into and misuse a system without authorization and those who have authorization, but are abusing their privileges. Intrusion detection can be formulated as a pattern classiﬁcation problem, in which observed activities are classiﬁed as normal or intrusive.  22.3.2 Encryption  Encryption changes the plaintext  a stream or block of data to be protected  into cipher- text by using an encryption key, to combat eavesdropping. The receiver can decrypt the      939   cid:2   22.3 Security  ciphertext to extract the plaintext by using the same or a different key, and the two cases are known as symmetric key encryption and asymmetric key encryption.  The theoretical framework for symmetric key-based cryptography was also established by Shannon in 1949 [59]. At the transmission end, there are two sources, namely, a message source and a key source. The key source is transmitted to the receiving end by some means, which are supposed to be not interceptible. The message source is enciphered by using the key, and the resulting ciphertext is transmitted to the receiving end by possibly interceptible means. The receiving end deciphers the received ciphertext to recover the message. The encipher and decipher algorithms may be known to the public.  WEP  Wired Equivalent Privacy  is a symmetrical key encryption algorithm. A block of plaintext is bitwise XORed with a pseudorandom key sequence of equal length. The key is generated by the WEP algorithm. WEP is used in the IEEE 802.11 family of standards. WEP has some security problems, and in October 2002, the Wi-Fi Alliance announced WPA  Wi-Fi Protected Access  to supercede WEP. WPA is designed to work with existing 802.11-based products and has forward compatibility with IEEE 802.11i. It addresses all the known shortcomings of WEP.  The AES  Advanced Encryption Standard  algorithm, which became effective as a U.S. government standard in May, 2002 to replace its predecessor, the DES  Data Encryption Standard , which became a U.S. government standard in 1976. AES is a symmetric key, block-ciphering encryption system. It is speciﬁed as a link-layer encryption method. It operates on a data block of 128 bits, which is organized in a 4 × 4 array of bytes called a state. The size of the encryption key can be 128, 192, or 256 bits long. It has strong cryptographic properties and is easy to implement in hardware or software, and thus has gained widespread adoption. Triple DES  3DES  is a block cipher formed from a DES cipher by using it three times.  Symmetric key encryption has the problem of secure key distribution over the network. Asymmetric key encryption solves this problem by using two keys, a public key, which is disclosed to the public, and a private key, which is kept secret. When a ciphertext is encrypted using one key, it can be decrypted only by the other key. Both keys are simultane- ously generated by using the RSA  Rivest-Shamir-Adleman  algorithm [56]. For example, user A can send data to user B by encrypting the data using the public key of user B, and only user B can decrypt the data using his private key. This approach is widely used on the Internet for authentication, nonrepudiation and message integrity, and digital certiﬁ- cates. A Pretty Good Privacy  PGP  version of RSA is available in the public domain for noncommercial use on the Internet. Key management is a difﬁcult problem in multihop communications, such as for wireless ad hoc or sensor networks, since most centralized secure protocols cannot be directly applied in distributed wireless networks.  AES is used for both authentication and encryption of the secure payload in Wi-Fi and WiMedia. For Wi-Fi, the security features are enhanced by IEEE 802.11i, which relies on the AES. HiperLAN 2 uses the DES or 3DES algorithm to secure the data. In IEEE 802.16 family, the DES, 3DES, AES, and RSA algorithms are used for the encryption services in the MAC security sublayer.  A hash function maps a long message to a ﬁxed-length bit string, called the digest of the message. Hash functions are extensively used in cryptographic protocols such as in digital      940   cid:2   Wireless ad hoc and sensor networks  signature protocols. To prevent attack, a message digest is required to be at least 128 bits long. Construction of secure hash functions can be based on the Merkle-Damgard  MD  algorithm [57]. Some practical hash function families are MD, SHA, and RIPEMD.  Due to multihop wireless communications and physical exposure of the nodes, the secu- rity of wireless ad hoc networks is much more challenging. The nodes may belong to different authorities, and this introduces the cooperation of nodes and trust management. Attacks may be external and internal, and the internal attacks are not easy to prevent.  22.4 Technical overview for wireless ad hoc networks  As MANET and WSN nodes are energy-constrained devices, power consumption is a major consideration for a wireless ad hoc network. Power consumption is divided into two parts: the idle mode and the transmit receive mode. Power-aware routing is targeted to maximize the lifetime of the network. It is formulated as an NP-complete problem.  Standards for wireless ad hoc networks  Ad hoc or mesh mode is now being supported by more and more IEEE 802 standards, including 802.11, 802.15, 802.16, and 802.20. The IEEE 802.11s ESS  extended ser- vice set  Mesh Task Group was formed in May 2004 to address the need for wireless mesh in wireless LANs. The standard, which is now underway, promises to be a highly interoperable wireless LAN mesh standard for wireless ad hoc networks.  The IEEE 802.16a standard incorporates the mesh mode in addition to the point-to- multiple-points  PMP  mode deﬁned in the baseline IEEE 802.16. The IEEE 802.16a mesh mode targets only ﬁxed broadband applications, and is not compatible with the exist- ing PMP mode. The IEEE 802.16 working group established the Mobile Multihop Relay  MMR  study group in July 2005 to study the possibility for extending the PMP mode to support MSs by using multihop relaying techniques. Two mechanisms for scheduling data transmission in mesh mode are deﬁned in IEEE 802.16: centralized and distributed scheduling. In centralized scheduling, the BS works like a clusterhead and arranges user nodes to share the channel in different time slots. In distributed scheduling, every node competes for channel access using a pseudo-random election algorithm based on the scheduling information of its two-hop neighbors. Data subframes are then allocated using a request-grant-conﬁrm three-way handshaking protocol.  The IEEE 802.15.5 task group, initiated in May 2004, is currently working to provide a framework for interoperable, stable, and scalable wireless mesh topologies for wireless PAN devices. ZigBee  IEEE 802.15.4  is now a market-ready wireless mesh standard.  Capacity regions  Capacity regions for wireless ad hoc networks have been studied in [60]. These regions describe the set of achievable rate combinations between all source–destination pairs      941   cid:2   22.4 Technical overview for wireless ad hoc networks  in the network under various transmission strategies, such as variable-rate transmission, single-hop or multihop routing, power control, and SIC. Numerical results indicate that multihop routing, the ability for concurrent transmissions, and SIC signiﬁcantly increase the capacity of ad hoc and multihop cellular networks. On the other hand, gains from power control are signiﬁcant only when variable-rate transmission is not used. Also, time- varying ﬂat-fading and node mobility actually improve the capacity. Finally, multihop routing greatly improves the performance of energy-constraint networks.  Flat or hierarchical architecture  A multihop ad hoc network can have a ﬂat or hierarchical architecture. A ﬂat structure of a large number of nodes leads to a number of challenges in terms of network organization, gathering of the information, throughput, routing, and energy management; that is, a ﬂat structure leads to low scalability and a complex network-wide coordination.  Hierarchical architectures can solve the scalability problem. Clustering enables in- network data aggregation: Nodes transmit their information to their clusterheads, and the clusterheads aggregate the received information and forward it to the destination. A clustering scheme can be either identiﬁer-based clustering, topology-based clustering, or energy-based clustering. Periodic re-clustering is applied to select nodes with higher residual energy as clusterheads. The clustering hierarchy is illustrated in Fig. 22.3.  LEACH  low-energy adaptive clustering hierarchy  [26] is a clustering scheme that uses randomized rotation of the clusterheads and the corresponding clusters to distribute the work load evenly among nodes in the network. In LEACH, relay is not used, and each clusterhead directly reports to the sink. The chain scheme further improves the energy efﬁciency in such a way that each node transmits only to its closest neighbor. In a tree-based network, nodes are organized into a tree, and data aggregation is performed at intermediate nodes along the tree until it reaches the root node.  Coverage  One fundamental issue in wireless ad hoc networks is the coverage problem. Coverage is the spatial sensing range of a node. It has to be coordinated among nodes to avoid  BS  A  D  B  C   cid:2 Figure 22.3  A clustering hierarchy. Nodes A, B, C, D are clustering heads. Nodes in each cluster transmit their data to their cluster heads. Each cluster head transmit its aggregated data to the destination using other cluster heads as relays.      942   cid:2   Wireless ad hoc and sensor networks  redundancy, by considering communication distance and other characteristics of sensing tasks. Sensor node placement and dispatch are two important deployment problems in WSNs [63].  The target ﬁeld may have coverage holes, that is, areas not covered by any node, due to random spatial deployment, presence of obstructions, or node failures. Routing holes, areas devoid of any nodes, may also occur in the deployed topology. A wireless ad hoc network may fail if some of the nodes cannot sense or relay the data.  Adversaries may deliberately damage wireless ad hoc networks by setting malicious nodes to jam the communication, yielding jamming holes, or to overwhelm regions in the ad hoc network by denial-of-service attacks to hinder their operation, which is normally based on trust [2]. Wireless ad hoc networks are highly susceptible to denial-of-service attacks due to their inherent limited resources coupled with use of insecure wireless channels [2].  QoS for wireless ad hoc networks  QoS support in ad hoc networks involves QoS model, QoS resource reservation signaling, QoS routing, and QoS MAC. A QoS mode speciﬁes an architecture. QoS signaling coor- dinates the behavior of QoS routing, QoS MAC, and other components. The QoS routing process [11] searches for a path with enough resources but does not reserve resources, and thus, resources can be assured when QoS signaling needs to reserve resources. All upper-layer QoS components are dependent on and coordinate with the QoS MAC pro- tocol. Trustworthiness-based QoS routing is a secure routing protocol with QoS support, which includes secure route discovery, secure route setup, and trustworthiness-based QoS routing metrics [68].  QoS for wireless ad hoc networks can be application-speciﬁc QoS or network QoS. For application-speciﬁc QoS  such as in WSNs , QoS parameters can be selected as coverage, exposure, measurement errors, and optimum number of active sensors. For network QoS  such as MANET , we consider how the underlying communication network can deliver the QoS-constrained data while efﬁciently utilizing network resources.  Congestion control  Congestion not only causes packet loss, but also leads to excessive energy consumption. In addition, congestion control is necessary to improve fairness and provide better QoS in case of wireless multimedia networks [65].  Two types of congestion could occur in wireless ad hoc networks. Node-level con- gestion, caused by buffer overﬂow in the node, is common in conventional networks. For wireless networks that are based on CSMA-like protocols, link-level congestion may arise: Collisions occur when multiple nodes access the channel at the same increased delay, and decrease of both time. Congestion can result the link utilization and the overall throughput. Retransmissions consume additional energy, which is critical to WSNs. Congestion has a direct impact on energy-efﬁciency and QoS.  in packet  loss,      943   cid:2   22.5 Technical overview for wireless sensor networks  Congestion control can be implemented through network resource management and trafﬁc control. The ﬁrst approach increases network resource when congestion occurs. In a wireless network, power control and multiple radio interfaces can increase the bandwidth and weaken congestion. Trafﬁc control adjusts trafﬁc at source nodes or intermediate nodes for congestion control. This approach is helpful in saving network resource. Trafﬁc control can be on an end-to-end or on a hop-by-hop basis.  Network capacity  √  With only ﬁxed rate point-to-point communications, ﬁnite bandwidth and large power, the nA, where n is the node density and A transport capacity of planar networks scales like is the area occupied by the network, and the per-node throughput capacity is a decreas- ing function of n [20]. This result has been extended to three dimensions in [19]. Under minimal conditions on the attenuation, and for networks with constant n, the rate per com- munication pair in a wireless ad hoc network is shown to tend to zero as the number of users gets large [43]. For an UWB wireless ad hoc network with a power constraint and the explicit use of link adaptation, the uniform throughput per node is shown to increase as a function of n [49], and this is in contrast to the decreasing per-node throughput given in [20]. This capacity advantage justiﬁes the promise of UWB technology for wireless ad-hoc networks.  The transmission capacity of a wireless ad hoc network is deﬁned as the maximum spa- tial intensity of successful transmissions below a speciﬁed outage probability. Upper and lower bounds for the transmission capacity of wireless ad hoc networks with SIC receivers are developed in [64], for both perfect and imperfect SIC. Any imperfections in the inter- ference cancellation rapidly degrade its usefulness. Only a few, often just one, interfering nodes need to be canceled in order to get the majority of the available performance gain.  22.5 Technical overview for wireless sensor networks  In additions to the common features of wireless ad hoc networks, WSNs have their own speciﬁc features. Many routing, power management, and data dissemination protocols have been designed for WSNs to support various unique requirements and constraints to make WSNs practically useful and operable. Power management is of critical impor- tance. It is targeted at the twofold goal: minimizing the total energy consumption of all nodes in the network  to extend the lifetime of each node  and achieving a homoge- neous consumption of energy throughout the network  to maximize the lifetime of the network .  For WSN design, energy-efﬁciency is treated as the top priority. The design should also be scalable for large networks. Latency and bandwidth efﬁciency are of secondary concern, while per-node fairness is usually not considered.      944   cid:2   Wireless ad hoc and sensor networks  e n a l p    t n e m e g a n a m k s a T     e n a l p    t n e m e g a n a m y t i l i b o M       e n a l p    t n e m e g a n a m    r e w o P  Application layer   Transport layer  Network layer  Data link layer  Physical layer   cid:2 Figure 22.4  The WSN protocol stack.  Protocol stack  The architecture of protocol stack [5] at the sink and sensor nodes is shown in Fig. 22.4. The protocol stack integrates energy-aware routing, data aggregation, power efﬁciency, and cooperation of sensor nodes. This protocol stack is made up of ﬁve layers  physical, data link, network, transport, and application layers , and three planes  power management, mobility management, and task management planes .  The physical layer addresses the needs of robust modulation, transmission and reception. The management of time and time-related operations in WSNs is essential to timing events and network synchronization operations. The 915 MHz ISM band has been suggested for WSNs. Due to the hardware, power, and cost constraints, binary modulation and UWB technique are attractive for baseband transmission.  The data link layer is responsible for the multiplexing of data streams, data frame detection, medium access and error control. It ensures reliable point-to-point and point- to-multipoint connections in a communication network. It can be decomposed into MAC and LLC sublayers. Collision avoidance is the basic task of all MAC protocols. The MAC protocol for a multihop self-organizing WSN must achieve two goals, namely, the creation of the network infrastructure and the fair and efﬁcient sharing of communications resources between sensor nodes. For error control, ARQ is limited by the retransmission energy cost and overhead in multihop WSNs, and simple FEC is preferred.  The transport layer is necessary when the sensor network is accessed via Internet or other external networks. The transport layer helps to maintain the ﬂow of data if the application requires it. TCP can be used at the sink for interface to the Internet, but special transport layer protocol can be used between the sink node and the sensor nodes. A UDP-type pro- tocol can be used between the sink and sensor nodes, since each sensor node is restricted by resources, and is not based on global addressing.  The network layer is in charge of routing the data supplied by the transport layer. The network layer shares some commonalities with that for ad hoc networking, but has new features to meet the more stringent requirements on scalability, energy efﬁciency and      945   cid:2   22.5 Technical overview for wireless sensor networks  data-centricness. Finally, the application layer is dependent on the sensing tasks, such as a sensor management protocol.  Flow control through a WSN can be separated into two problems: routing and conges- tion control. Routing can be addressed as a discrete optimization problem with optimality criteria deﬁned in terms of distance, energy consumed, time delay through the network, and bandwidth maximization. It is similar to an NP-hard traveling salesman problem as it aims to select data routes  hops  with minimal cost between the wireless nodes forming a graph. Congestion control ﬁnds and regulates the optimal ﬂow rates between the network nodes subject to network capacity constraints. Priority-based Congestion Control Protocol  PCCP  is an upstream congestion control protocol for WSNs [62]. Based on the conges- tion degree and node priority index, PCCP utilizes a cross-layer optimization and imposes a hop-by-hop approach to control congestion.  The power management plane manages the power consumption among the three oper- ations  sensing, computation, and wireless communications . The mobility management plane detects and registers the movement mobility of sensor nodes as a network control primitive. The task management plane balances and schedules the events’ sensing and detecting tasks from a speciﬁc area by cooperation of sensor nodes.  As WSNs are highly task-speciﬁc, and most often stand-alone implementations, they do not need to follow the strictly layered design, and a revolutionary approach to cross-layer design can be applied.  MAC protocols  The MAC determines when and how a node can access the medium and send its data. Design of MAC protocols in WSNs needs to consider collision avoidance, energy efﬁ- ciency, scalability in node density, latency, fairness, throughput, and bandwidth utilization. Although many MAC protocols and algorithms are available for wireless ad hoc networks, they are not well suited to WSNs.  Energy is the primary concern for MAC design for WSNs. Collision is a ﬁrst source of energy waste. Idle listening and overhearing are two other sources of energy waste. Overhearing occurs when a node receives packets that are destined to other nodes. Another major source is control packet overhead. Two techniques that have been explored for MAC to enable multihop routing while powering down radios for power conservation are:   Adaptive duty-cycling. The set of nodes whose radios are powered down is care- fully chosen such that a network backbone is continually maintained, while radios of nonbackbone nodes can be put to sleep. To balance the load, the active subset of nodes are adaptively cycled, based on parameters such as available energy and radio coverage.   Wakeup on demand. This technique uses nodes with multiple radios: A low-power radio is used exclusively to wake up the high power radio, when the need arises. This is much like a paging channel in cellular networks. Such a technique is especially use- ful when bandwidths and data rates are higher, and this warrants the use of multiple radios.      946   cid:2   Wireless ad hoc and sensor networks  Sensor-MAC  S-MAC  is a well-known MAC for WSNs [66]. The main goal of S-MAC is to reduce energy consumption caused by idle listening, collisions, overhearing, and control overhead. Since most of the time a wireless node is in idle listening, S-MAC turns off the node’s transceiver periodically. This introduces some latency. Fairness among nodes can be tolerable as all the nodes are expected to serve the same application. Collision avoidance in S-MAC is similar to the distributed coordinated function  DCF  for 802.11 ad hoc mode. ZigBee  IEEE 802.15.4  also has a MAC that is suited to WSNs. Receiver sensitivities for ZigBee are −85 dBm for 2.4 GHz and −92 dBm for 868 915 MHz. ZigBee allows up to 254 nodes. In ZigBee, the MAC layer deﬁnes two types of nodes: reduced function devices and full function devices. Full function devices are equipped with a full set of MAC layer functions, which enables them to act as a network coordinator or a network end-device.  Operating systems and databases  A sensor node is an embedded system, and an embedded operating system can be used. Middleware is often used to bridge the gap between the operating system and the applica- tion. This eases the development of distributed applications. Due to resource constraints, unreliability of wireless networks, and diversity, middleware for WSN presents a number of new challenges.  TinyOS was the ﬁrst operating system speciﬁcally designed for WSNs [27]. TinyDB is an inquiry processing system for WSNs that operates on TinyOS by using a data-centric approach [46]. Both TinyOS and TinyDB were initially developed at the University of California, Berkeley, in cooperation with Intel Research. TinyOS is now being developed by a consortium, the TinyOS Alliance, and is open source, making it easy for developers to customize it as required.1 It has the largest user base and is the benchmark for other operating systems. TinyOS is an event-driven operating system designed for sensor nodes that have very limited resources. The core requires 400 bytes of code and data memory, combined. A series of components is supplied to program conveniently, to easily acquire, and to process data acquired by sensors.  In a data-centric approach, each node keeps its data, and nodes execute retrieval and aggregation, with on-demand based operation to deliver the data to external applications. TinyDB supports a data aggregation function via SQL query, which supports selection, projection, determining sampling rate, group aggregation, user-deﬁned aggregation, event trigger, lifetime query, setting storing point and simple joining.  Time synchronization  Time synchronization is necessary to provide temporal coordination among all the nodes engaged in a collaborative and distributed interaction. This can be achieved by send- ing timing messages to the target sensors. Approaches to time synchronization can be categorized as sender-receiver synchronization, receiver-receiver synchronization, and  1 http:  www.tinyos.net       947   cid:2   22.5 Technical overview for wireless sensor networks  receive-only synchronization [52]. Sender-receiver synchronization is based on two-way message exchanges between a pair of nodes. In receiver-receiver synchronization, the nodes receive a beacon packet from a common sender, and then compare among them  excluding the common sender  their relative clock offset based on their receiving times of the beacon packet. Receive-only synchronization minimizes the use of timing messages for the purpose of saving energy. Many time synchronization protocols are introduced in [52].  Location  To be context-aware, location tracking is a major concern in WSNs. Localization is nec- essary for assigning geographic coordinates to each node in the WSN. This is necessary for monitoring the roaming path of a moving object and determining from which location a measurement came. Location discovery in WSNs poses signiﬁcant design challenges. Because of constraints in size and cost, it is impractical to use GPS receivers at the sensor nodes. Moreover, WSNs may be deployed in regions where satellite signals may not be available.  Approaches to WSN location typically deploy a few known nodes called beacons or anchors, which are aware of their own locations. Due to the cost constraint of the sensor nodes, localization utilizing RSSI measurement is practical [71]. Many IEEE 802.x wireless standards, e.g. IEEE 802.15.4, support RSSI measurement to evaluate link quality. Tracking multiple interacting targets is more challenging due to the curse of dimensionality.  Security  The security of large, densely deployed WSNs requires efﬁcient key distribution and man- agement mechanisms. Security requirements in WSNs are similar to those for ad hoc networks. In addition, WSNs have two speciﬁc requirements:   Survivability: ability to provide a minimum level of service in the presence of power exhaustion, failures or attacks;   Degradation of security services: ability to change security level according to resource availability.  The security problems may be physical or logical in nature. Physical security problems can be caused by damaged or stolen nodes, inaccurate measurement, jamming, battery exhaustion attacks, as well as malicious nodes. Logical security problems can be due to eavesdropping, injection, attacks to protocols from external or internal nodes, as well as identity and instruction integrity.  TinySec is the ﬁrst fully implemented, minimal protocol for link-layer cryptography in WSNs [37]. It is feasible to implement acceptable cryptographic protection for WSNs entirely in software. TinySec is a research platform that is easily extensible and has been incorporated into higher-level protocols.      948   cid:2   Wireless ad hoc and sensor networks  Battery technologies  Battery technologies are important for WSNs. Sensor node lifetime is mainly dependent on the battery lifetime. There are three common battery technologies for WSNs — alkaline, lithium, and nickel metal hydride. The AA alkaline battery provides a cheap, high capacity energy source, but it has a wide voltage range and a large physical size. In addition, lifetime beyond ﬁve years is not possible due to battery self-discharge. Lithium batteries provide a very compact power source. They also provide a constant voltage supply that decays lit- tle as the battery is drained. Unlike alkaline batteries, lithium batteries are able to operate at temperatures down to −40 ◦ C. Nickel metal hydride batteries are easily rechargeable, but they have a signiﬁcant decrease in energy density. If there is no energy-harvesting source, a nonrechargeable battery is a good choice since it has higher energy density. Some designs try to harvest energy from the ambient energy in the form of electromagnetic radiation, heat, or mechanical energy [4]. Energy harvesting techniques are now becom- ing mature, and both TI and Intel have solar energy harvesting solutions for powering WSNs.  22.6 Data aggregation and routing for WSNs  22.6.1 Data aggregation  Data or in-network aggregation is tightly coupled with how data is gathered at the sensor nodes as well as how packets are routed through the network, and has a signiﬁcant impact on overall network efﬁciency. Sensor nodes may generate signiﬁcant redundant data. Sim- ilar packets from a single or multiple nodes can be aggregated  fused  at intermediate nodes with the objective of reducing the number of transmissions and improving the detec- tion performance, thereby reducing resource consumption and increasing network lifetime. Data aggregation can take two forms. The ﬁrst one leads to a size reduction by com- bining and compressing data coming from different nodes and then sending the reduced data to save node resources. The second form merges packets from different sources into one packet without data processing to reduce the overhead: These packets from different sources may carry different physical quantities. Data fusion requires the transmission of data and control messages. Data aggregation can be based on a certain aggregation func- tion  e.g., duplicate suppression, minima, maxima, and average . This technique has been used in a number of routing protocols. Data aggregation is performed at a sink, and it may require some form of synchronization among nodes.  Sensor data collection can be event-driven or demand-driven. In the event-driven case, when one or more sensor nodes have detected an event, the nodes report the data to the monitoring station. In the demand-driven case, the monitoring station enquires the sensor nodes, and the sensor nodes send their data in response to an explicit request. For exam- ple, a damage monitoring system is event-driven, whereas an inventory control system is demand-driven. A hybrid system can be both event- and demand-driven.      949   cid:2   22.6 Data aggregation and routing for WSNs  In ﬂat networks, all sensor nodes play the same role and are equipped with approximately the same battery power. Data aggregation is accomplished by data-centric routing, and the sink usually transmits a query message to the sensors. A ﬂat network causes excessive communication and computation burdens at the sink node. This will deplete the battery power at the sink node rapidly, causing a breakdown of the network. Hierarchical data aggregation performs better in view of scalability and energy efﬁciency. This approach conducts data fusion at some nodes to reduce the trafﬁc to the sink.  The LEACH protocol [26] organizes the sensor nodes into clusters for data fusion. The sensor nodes transmit data to a designated node  clusterhead , where data aggregation is performed. The clusterhead in each cluster transmits the fused data from several sensors in its cluster to the sink.  Sensor network with mobile access  SENMA  [47] is a hierarchical architecture in which sensors are orchestrated by a few powerful mobile access points. By allowing sensors to propagate data directly to mobile access points over multiaccess channels, SENMA relieves sensors from energy-consuming network functions; this improves energy efﬁ- ciency over the multihop ad hoc architecture by orders of magnitude. Mobile access points retrieve the data from the sensors and deliver it to a remote control center. In SENMA, sen- sors are driven by mobile access points; the presence of a strong beacon from the mobile access point signiﬁcantly simpliﬁes timing recovery and synchronization.  The common static sink strategy does not scale with the network size and increases the network congestion. Moreover, it may limit the network lifetime as the one-hop neigh- bors of the sink are the bottleneck of the network; in this sense, mobile sinks are more energy-effective, thus enhancing the network lifetime. Also, sink mobility makes security attack more difﬁcult, and it may improve the network connectivity. There are several data dissemination protocols with mobile sinks available [22].  22.6.2 Routing  Data aggregation requires a different forwarding paradigm than classical routing. Classical routing protocols typically forward data along the shortest path to the destination in terms of some speciﬁed metric. In order to aggregate data to minimize energy expenditure, nodes should route packets based on packet content and choose the next hop in order to promote in-network aggregation. This type of data forwarding is often referred to as data-centric routing.  Many routing, power management, and data dissemination protocols are designed for WSNs, with energy-awareness as a primary concern. Routing protocols in WSNs may depend on the application and network architecture. Routing in WSNs is very challeng- ing as WSNs are inherently distinguished from other wireless networks like MANETs or cellular networks.  Geographic routing and data-centric routing are present in WSNs. Geographic routing uses a region rather than a node identiﬁer as the target of a packet; any node within the region can be accepted as a destination node and can receive and process a message. Geo- graphic routing is important for WSNs when requesting sensor data from a region  e.g.,      950   cid:2   Wireless ad hoc and sensor networks  request temperature in a room . Data-centric routing is a core abstraction of WSNs, and it ﬁnds routes from multiple sources to a single destination, which allows in-network data aggregation.  In addition to the basic routing techniques, such as ﬂooding and gossiping, for general wireless ad hoc networks, other most well-known routing protocols for WSNs are SPIN [40], directed diffusion [31], and rumor routing [8].  SPIN  SPIN  Sensor Protocols for Information via Negotiation  [40] is a family of adaptive proto- cols  e.g., SPIN-1 and SPIN-2  for WSNs. It is a data-centric routing scheme. SPIN avoids the drawbacks of ﬂooding by utilizing meta-data negotiation and resource-adaptive algo- rithms. Energy efﬁciency is achieved by sending meta-data  processed sensor data . Also, each node has its own resource manager that keeps track of energy resource consump- tion and is polled by the nodes before data transmission to extend its lifetime. Topological changes are localized, since each node needs to know only its single-hop neighbors. In SPIN, sensors advertise the availability of data, allowing interested nodes to query that data. This data negotiation mechanism eliminates the redundant data transmission. How- ever, SPIN does not establish any path for data transmission, and thus, it does not guarantee the delivery of data.  Directed diffusion  Directed diffusion [31] is a popular data aggregation data-centric routing paradigm for WSNs. All data generated by sensor nodes are characterized by attribute-value pairs. The data coming from different sources are combined en route to minimize the number of transmissions. All sensor nodes are application-aware, which allows energy savings by selecting empirically good paths, and by caching and processing data in the network.  At the beginning, the sink sends out its interest or task description to all nodes. The interest entry contains a timestamp ﬁeld and several gradient ﬁelds. Each node then stores the interest entry in its cache. As the interest is propagated throughout the WSN, the gradients from the source back to the sink are set up. When the source has data sat- isfying the interest, it sends the data along the interest’s gradient path, and at the same time the sink refreshes and reinforces the interest when it starts to receive data from the source.  In directed diffusion, the sink queries the sensor nodes if a speciﬁc data is available by ﬂooding some tasks. Since it is data-centric, all communication is neighbor-to-neighbor with no need for node addressing. The on-demand nature as well as no need for main- taining global network topology makes direct diffusion highly energy-efﬁcient. As it is based on a query-driven data delivery model, directed diffusion is not a good choice as a routing protocol for applications such as environmental monitoring, where continuous data delivery to the sink is required.  REEP  Reliable and Energy Efﬁcient Protocol  is a data-centric, energy-aware routing protocol that is based on directed diffusion [70]. REEP is an interactive on-demand      951   cid:2   22.7 Relay, user cooperation, and MIMO relay networks  protocol, in which path establishment can be done based on the choice of any user or an application. Each node maintains an energy threshold and participates in path setup with adequate energy. REEP uses the request priority queue for loop prevention and alternate path setup in case of failed path, without invoking periodic ﬂooding. The performance of REEP is superior to directed diffusion [70].  Rumor routing  Directed diffusion uses initial ﬂooding to discover good paths between the sources and sinks. If only a small amount of data is requested from the nodes, the use of ﬂooding is unnecessary. Rumor routing [8] is a variation of directed diffusion and is mainly intended for applications where geographic routing is not feasible, because a coordinate system is not available or the phenomenon of interest is not geographically correlated. The idea is to route the queries to the nodes that have observed a particular event to retrieve information about the occurring events. Rumor routing maintains only one path between the source and destination.  Routing for ﬂat and hierarchical architectures  For each class of architecture, the routing protocols are different. Flat routing protocols are similar to the conventional multihop ad hoc routing protocols, where each sensor node determines its parent node s  to forward data packets. Using this approach, all the nodes can reach the BS irrespective of their position.  For hierarchical  tree-based or cluster-based  architecture, the nodes are organized in hierarchical form. Aggregation trees  clusters  have the robustness problems, since each node has to send the partial result of its aggregation to a single parent or clusterhead. Many routing protocols are based on clustering. Such algorithms work well in relatively static networks. An alternative solution is that each node can send the data to its  possibly  multiple neighbors, and hence, data may ﬂow from the sources to the sinks along multiple paths and aggregation may be performed by each node.  22.7 Relay, user cooperation, and MIMO relay networks  Relay is closely related with routing. It is a fundamental technique for wireless ad hoc net- works. Relay is also being considered for cellular coverage enhancement through efforts like IEEE 802.16j  Multihop Relay Speciﬁcation for 802.16  to incorporate relay capabili- ties in mobile WiMAX  IEEE 802.16e . IEEE 802.16j will be fully compatible with IEEE 802.16e mobile and subscriber stations, but a BS speciﬁc to 802.16j will be required for relays to operate. Multihop communications is one of the enabling techniques for 4G, and it is being standardized for IEEE 802.16m and LTE-Advanced.  In wireless ad hoc networks, cooperation among nodes can be exploited to improve sys- tem performance. The fundamental ideas behind cooperation can be found in the literature      952   cid:2   Wireless ad hoc and sensor networks  on the relay channel [13]. The cooperative relaying transmission results in cooperative diversity, and it is deﬁnitely an option for the future-generation wireless networks.  22.7.1 Relay  Basic relay schemes are amplify-and-forward  AF  , decode-and-forward  DF  , and compress-and-forward  CF  protocols [42]. In the AF scheme, the receiver receives repeated codes from two separate transmitters, except that the relay transmitter ampli- ﬁes its own receiver noise. The destination can decode its received signal by using a diversity combining technique. In the DF scheme, the relay may decode the entire source codeword or perform symbol-by-symbol decoding, forward the data possibly using a different code, and let the destination perform full decoding, depending on the resources available at the relay. Again, the destination can perform diversity combining. In the CF scheme, the relay forwards the quantized compressed estimated version of its observations.  The transmitter cooperative channel model is illustrated in Fig. 22.5, where S stands for source, R for relay, and D for destination. In the receiver cooperative case, the relay is close to the receiver.  DF assumes that the source-relay channel is outage-free so that the relay always retrieves the source packet correctly. However, practical wireless channels experience fading from time to time, and this results in a drastic performance degradation. DF is limited by direct transmission between the source and relay. When the channel between the source and the relay, hs,r, is very poor, the source simply continues its transmission to the destination, by using repetition or more powerful codes. Selection relaying schemes can be used to select among several relay or repetition coding schemes so as to adapt to channel measurements between the cooperating nodes [42]. A single bit of feedback from destination to relay to indicate the success failure of the source transmission to the destination allows DF to achieve the full diversity available in the single-antenna relay channel [42].  AF can better resolve the problem of poor source-relay channel, but sampling, ampli- fying, and retransmitting have certain complexity; in addition, the destination may receive transmissions that are too noisy from the source and the relay due to the use of analog signals. In the low SNR and low outage probability regime, AF performs very poorly, whereas the bursty AF protocol is optimal and achieves the outage capacity of the network [6]. Moreover, bursty AF can achieve this performance without a-priori channel knowledge at the receivers. In contrast, DF is strictly suboptimal in this regime.  D  S  R   cid:2 Figure 22.5  The transmitter cooperative channel model.      953   cid:2   22.7 Relay, user cooperation, and MIMO relay networks  CF can be a better solution to fading, but DF generally outperforms CF when the source- relay channel is in good condition [39]. DF approaches capacity when the relay is near the transmitter, whereas CF is close to optimum when the relay is near the receiver [39]. Therefore, in [51], DF is used in transmitter cooperation, while CF is used in receiver cooperation.  Wyner-Ziv cooperation [28] is a practical CF scheme. It exploits Wyner-Ziv codes in wireless user cooperation to help combat inter-user outage. The encoder of a Wyner-Ziv system usually consists of two parts: quantizer and index encoder. The relay, after perform- ing channel decoding, stores soft reliability information. The direct source copy from the source to the destination is viewed as the decoder side information, and the relay can bor- row ideas from Wyner-Ziv coding to process and transmit the soft reliability information. Wyner-Ziv cooperation is most useful when the noisy copy retrieved at the relay has a high correlation with the original source. In [21], the SISO decoder at the relay decodes the received signal and generates various a-posteriori probabilities, and then forwards the soft information to the destination. At the destination, the soft information is used as extrinsic information for iterative decoding. Compared to AF or DF with MRC, the use of soft value as a-priori information affects the decoding behavior and improves the performance with less overhead [21], since in MRC a large amount of information is exchanged in order to combine the paths. Similar soft relaying schemes are given in [9, 16].  For high data rates, incremental relaying protocols can be used. Limited feedback, which indicates the success failure of the direct transmission, is transmitted from the destination [42]. This feedback information can be broadcast to both the source and the relay. If the source-destination channel is sufﬁciently good, the feedback indicates that direct transmis- sion is successful and the relay does nothing; otherwise, the relay forwards what it received from the source. In the latter case, the destination will combine the two transmissions. This results in gains over AF by increasing the rate for good source-relay conditions [42]. Incremental relaying protocols can be viewed as extensions of incremental redundancy, or HARQ. Performance for various cooperative diversity schemes can be accordingly derived [17].  For the DF strategy, a low-complexity coherent demodulator at the destination has been derived in [61]. The coherent demodulator is in the form of a weighted combiner, termed cooperative MRC. The weights are selected adaptively to account for the quality of both the source-relay-destination and source-destination links. The coherent demodulator achieves the maximum possible diversity, regardless of the underlying constellation. Its error perfor- mance tightly bounds that of ML demodulation with DF relaying. Multihop, multibranch cooperative diversity is also considered. The cooperative MRC can achieve almost the same performance as the optimum ML detector does, but with a much lower complexity [61].  For a ﬁxed rate of transmission, increased power savings can be achieved by using the feedback for power control. Only a few bits of feedback are sufﬁcient to achieve most of the gains of the optimal power control with CSI at the transmitter. The ﬁnite-rate feed- back results are given for the low-complexity, full-diversity AF protocol in [3]. When no CSI is available at the transmitters, transmitting with equal power at the source and relay is close to optimal, especially for relays positioned close to the source [3]. The outage probability for AF with one-bit feedback has at least a fourth-order diversity [3]. To obtain      954   cid:2   Wireless ad hoc and sensor networks  large performance improvements over constant power transmission, it is imperative to have feedback for CSI to allow for temporal power control [3]. Maximizing the diversity order over a fading relay channel by using DF with quantized CSI feedback has been investigated in [38].  Opportunity-driven multiple access  ODMA  is a misnomer as it is not a true multiple access, but a relaying protocol. ODMA breaks the path into smaller hops, and makes use of other MS in the cell to relay the signal. The optimum routing tries to achieve the min- imum total path loss for the transmission. It is shown in [23] that a relaying system with distributed intelligence can exhibit an average reduction of 21 dB in transmission power. Multihop relaying routing protocols have been investigated for CDMA air interface in con- ventional cellular scenarios [23]. The ODMA protocol utilizes the path loss between the terminals as the metric to determine the routing [1, 23]. ODMA was once proposed for UTRA-TDD [1], but was ﬁnally dropped due to implementation problems.  In addition, joint source-channel coding for cooperative relay networks is shown to sig- niﬁcantly improve the performance compared to the conventional scheme of source coding followed by cooperative channel coding [18].  22.7.2 User cooperation  Multiple antennas can provide spatial diversity. However, it is not easy to implement this in a mobile unit due to size restriction. Another form of spatial diversity can be achieved by the cooperation of the in-cell users. When two users have their data to send, this is not a simple relay problem. The user cooperative diversity improves the achievable rate region and reduces the outage probability, and a user with more fading beneﬁts most from the cooperation [17, 58].  Two-user cooperation model  Assuming that two users, denoted U1 and U2, have their own data to send. They cooperate with a target to send this information to the receiver with an increased rate. The receiver can be a BS or another MS in an ad hoc network, and here we denote it as BS to differentiate it from the two partners. Each MS receives an attenuated version of the partner’s transmitted signal and combines it with its own data to construct its transmit signal. The channel model is illustrated in Fig. 22.6. User cooperation is a method of transmit diversity for mobile users. Each user has information of his own to send rather than simply act as the other user’s relay.  BS  U1  U2   cid:2 Figure 22.6  The cooperative channel model.      955   cid:2   22.7 Relay, user cooperation, and MIMO relay networks  Information-theoretic analysis shows that the achievable rate region with user coop- eration is always larger than the noncooperative region, implying that there is always a cooperative strategy in which both users beneﬁt from cooperation [58]. The MS with the better channel can help the other MS achieve some acceptable level of performance while sacriﬁcing only a small fraction of its own data rate. A simple, modiﬁed MRC detector, referred to as λ-MRC, is given in [58].  The channel is described as [58]  Y0 t  = h10X1 t  + h20X2 t  + n0 t , Y1 t  = h21X2 t  + n1 t , Y2 t  = h12X1 t  + n2 t ,   22.1   22.2   22.3   where Y0 t , Y1 t , and Y2 t  are the received baseband signals at the BS, user 1 and user 2, respectively, during one symbol period, Xi, i = 1, 2, is the signal transmitted by user i, ni’s, i = 0, 1, 2, are the zero-mean white complex Gaussian noises with variance σ 2 i at the BS, user 1, and user 2, respectively, and the fading coefﬁcients hij’s are zero-mean complex Gaussian random variables with Rayleigh distributed variance, which remain constant over at least one symbol period. To eliminate the direct effect of Xi on Yi, i = 1, 2, it is necessary to isolate the transmitted signal from the received one. This may be achieved by using two separate channels or two colocated antennas. The channels hij can be estimated by the corresponding receiver, and h21 = h12 due to the reciprocity of the channel. In the two-user cooperative system, each node acts as a data source as well as a relay, and each node operates under overall  source + relay  power and bandwidth constraints. The Alamouti code is used to achieve transmit diversity. This is a distributed space-time coding scheme. A source ﬁrst broadcasts to its destination and all potential relays. The relays then forward the information to the destination. The system can provide a diversity order of 2, and it can even provide multiplexing gain.  All the two-user orthogonal cooperative diversity protocols, including AF, selection relaying, and incremental relaying, achieve full diversity of 2, though at a loss of spec- tral efﬁciency due to half-duplex operation and possibly at the cost of additional receiver hardware [42].  Two-user coded cooperation  In the two-user cooperation, typically, if an error is detected within the received packet, a user transmits his own data to BS instead of relaying the other user’s data. Transmit diver- sity cannot be obtained. In the two-user coded cooperation scheme [33], each user tries to transmit incremental redundancy for his partner. Whenever that is not possible, the users automatically revert back to a noncooperative mode. Coded cooperation is managed auto- matically through code design, and feedback between users is not needed. The codeword of each user is partitioned into two portions: One partition is transmitted by the user, and the other by the partner. By allowing different code rates and partitions, coded cooperation provides a great degree of ﬂexibility to adapt to channel conditions. RCPC, turbo [72] and LDPC [10, 29] codes can be used for coded cooperation.      956   cid:2   Wireless ad hoc and sensor networks  In the two-user coded-cooperation scheme [30, 33], each block is encoded with an FEC code, so that for an overall rate R, we have N total coded symbols allocated for each source block. The two users cooperate by dividing the transmission of their coded source blocks into two successive time segments, called frames. In the ﬁrst frame, each user transmits a rate-R1 codeword  R1 > R  with N1 symbols. This itself is a valid codeword which can be decoded to obtain the original information. If the user successfully decodes the partner’s ﬁrst-frame transmission, the user computes and transmits N2 additional parity symbols for the partner’s data in the second frame, where N1 + N2 = N. These additional parities are selected such that they can be combined with the ﬁrst-frame codeword to produce a more powerful rate-R codeword. If the user does not successfully decode the partner, N2 additional parity bits for his own data are transmitted. Each user always transmits a total of N bits per source block over the two frames, and the users only transmit in their own orthogonal multiple-access channels.  The two users act independently in the second frame, with no knowledge of whether their own ﬁrst frame was correctly decoded by their partner. In other words, no feedback is assumed between the cooperating partners. As a result, there are four possible cooperative cases for the transmission of the second frame based on the ﬁrst frame decoding results at the two users, and different protocols are designed. Outage expressions conﬁrm that full diversity is achieved by coded cooperation [30]. An alternative cooperative method is given in [16]: If the CRC decoder detects error within the received packet, a user transmits a soft decision symbol which is obtained from the decoded data. Thus, transmit diversity always can be achieved.  Coded cooperation achieves full diversity when both users cooperate and gives impres- sive gains in BER for the case of slow fading. Space-time cooperation aims to capture space-time diversity in fast fading by applying space-time coding principles to coded coop- eration. When a source initiates transmission to its destination, many relays potentially receive the transmission. Those MSs that can fully decode the transmission utilize a space- time code to cooperatively relay to the destination. Repetition-based and space-time-coded cooperative diversities in nonergodic, multipath fading have been analyzed in terms of out- age probability in [41]. Both the algorithms can provide full spatial diversity in the number of cooperating MSs, and the effective coding or SNR gain loss can be characterized as a function of the interterminal average SNRs. Space-time-coded cooperation offers higher diversity order and higher spectral efﬁciencies than repetition-based algorithms.  22.7.3 MIMO relay networks  Virtual MIMO schemes can be used to improve communication performance of wireless ad hoc networks. Virtual MIMO is a network-based approach. Different nodes in the network can act as elements of an antenna array. As the array elements are not physically connected, a large amount of information must be sent to the combining nodes. In this approach, multiple individual single-antenna nodes cooperate for energy-efﬁcient communications. Examples of virtual MIMO schemes are an Alamouti-encoded scheme for single-hop transmissions [58], a STBC-encoded scheme without perfect synchronization [44], and a      957   cid:2   22.7 Relay, user cooperation, and MIMO relay networks  clustered topology-based, time-division, DF multirelay, space-time coded MIMO channel for multihop transmissions [12].  Clustered relaying  A wireless network with fading and a single source-destination pair is considered in [7]. The information reaches the destination via multiple hops through a sequence of layers of single-antenna relays. Each layer of relays can be treated as virtual MIMO. At high SNR, AF is optimal in terms of degrees of freedom, as it achieves the degrees of free- dom equal to that of a point-to-point MIMO system. Hence, lack of coordination in relay nodes does not reduce the achievable degrees of freedom. The performance of this AF strategy degrades with increasing network size. This phenomenon is analyzed by ﬁnding the tradeoffs between network size, rate, and diversity.  A multihop WSN with nodes grouped in cooperative clusters that exploits transmit and receive cooperation among cluster nodes is proposed in [14]. Multihop transmission is carried out by concatenating single cluster-to-cluster hops, where every cluster-to-cluster link is a cooperative distributed MIMO channel. Transmit diversity is exploited through a DF scheme using two time slots: the intracluster slot for data sharing within the cluster and the intercluster slot for transmission between clusters. At the receiver side, a distributed reception protocol is devised based on selection diversity. The multihop cooperative WSN is designed for minimum end-to-end outage probability by deriving the optimum time and power allocated on the intracluster and intercluster slots of every single hop, subject to a per-link energy constraint. The scheme achieves a diversity equal to that of the equivalent MIMO system. The cluster-based strategy limits cooperation inside the clusters, and this reduces synchronization and resource management complexity. A cluster-based cooperative strategy using incremental redundancy cooperative coding for slow Rayleigh fading is proposed in [45]. The collaborative cluster consists of M − 1 nodes between the sender and the destination. The transmitted message is encoded using a mother code which is partitioned into M blocks, each assigned to one of the M transmission slots. In the ﬁrst slot, the sender broadcasts its information by transmitting the ﬁrst block, and its helpers attempt to decode this message. In the remaining slots, each of the next M − 1 blocks is sent either through a helper which has successfully decoded the message or directly by the sender where a dynamic schedule is based on the ACK-based feedback from the cluster. An average frame-error rate upper bound and its asymptotic version are derived as a function of the average fading channel SNRs and the code threshold. Based on the asymptotic bound, diversity, coding, and transmission energy gains in both the high and moderate SNR regimes have been investigated for three different scenarios: transmitter clustering, receiver clustering, and cluster hopping [45].  Distributed STBCs  Distributed space-time coding achieves cooperative diversity without CSI at the relays. Using this scheme, antennas of the distributive relays work as transmit antennas of the sender and generate a space-time code at the receiver. It achieves the maximal      958   cid:2   Wireless ad hoc and sensor networks  diversity when the transmit power is inﬁnitely large. OSTBCs are particularly suitable for transmission in the network setting using distributed space-time coding, where each node transmits a different column of the OSTBC matrix [41]. Distributed space-time cod- ing achieves higher diversity than selection DF using the same orthogonal designs, when there is more than one relay [35].  Distributed STBCs are designed for wireless networks that have a large set of single- antenna relay nodes, but only a small, a-priori unknown subset of nodes is active at any given time [67]. The signal transmitted by an active relay node is the product of an information-carrying code matrix and a unique node signature vector of length Nc. This approach allows convenient exploitation of existing coherent, differential, and non- coherent STBCs originally designed for Nc co-located antennas, and accordingly allows for low-complexity coherent, differential, and noncoherent detection. Existing STBCs designed for Nc > 2 co-located antennas are favorable choices for the code matrix, guaranteeing a diversity order of d = min{Ns, Nc} in case of Ns active nodes. The perfor- mance loss entailed by the distributed implementation for Ns > Nc has been analytically characterized.  Transmitter and receiver cooperations  In [50], capacity improvement from transmitter and receiver cooperations is investigated in a two-transmitter, two-receiver network with phase fading and full CSI available at all nodes. The transmitters cooperate by ﬁrst exchanging messages over an orthogonal trans- mitter cooperation channel, then encoding jointly with dirty-paper coding. The receivers cooperate by using Wyner-Ziv CF over an analogous orthogonal receiver cooperation chan- nel. Transmitter cooperation outperforms receiver cooperation and improves capacity over noncooperative transmission under most operating conditions when the cooperation chan- nel is strong. However, a weak cooperation channel limits the transmitter cooperation rate; in this case, receiver cooperation is more advantageous. Transmitter-and-receiver cooperation, i.e., a scheme that uses transmitter cooperation as well as receiver coop- eration, offers sizable additional capacity gain over transmitter-only cooperation at low SNR, whereas at high SNR transmitter cooperation alone captures most of the cooperative capacity improvement.  Under quasi-static channels, when all the nodes have equal average transmit power along with full CSI, transmitter cooperation outperforms receiver cooperation, whereas the oppo- site is true when power is optimally allocated among the cooperating nodes but CSI is only available at the receiver [51]. When the system is under optimal power allocation with full CSI, DF transmitter cooperation outperforms CF receiver cooperation in terms of capacity. Similar conclusions follow under Rayleigh fading in the high-SNR regime. In a large cluster of M cooperating nodes, transmitter cooperation without CSI at the transmit- ter, or receiver cooperation under equal power allocation, provides no capacity gain in a static channel, and at most a constant capacity gain that fails to grow with M in a fading channel.  A virtual MIMO architecture with V-BLAST receiver has been proposed for WSNs in [34]. The scheme does not require transmitter-side cooperation. The energy and delay      959   cid:2   Problems  efﬁciencies are derived for networks with both single- and multiple-antenna data gathering nodes.  In [48], a group of receivers collaborating to decode a message that none of the receivers can individually decode is considered. Improved least-reliable bits  I-LRB  collabora- tive decoding is applied for user cooperation in bandwidth-limited scenarios. Collaborative decoding utilizes reliability information and information about competing paths in SISO decoders. The cooperating nodes iterate between a process of information exchange and decoding. The approach offers a signiﬁcant performance advantage over a constrained- overhead, incremental form of MRC. Collaborative decoding may be considered a CF scheme.  Diversity-multiplexing tradeoff  A general multiple-antenna network with multiple sources, multiple destinations, and mul- tiple relays is considered in [69] in terms of the diversity-multiplexing tradeoff. In case of a full-duplex relay, while DF achieves optimal diversity-multiplexing tradeoff when each of the nodes has one antenna, it may not maintain its good performance when the degrees of freedom in the direct link are increased, whereas CF continues to perform optimally. For a half-duplex relay, CF achieves optimal diversity-multiplexing tradeoff as well. For a sys- tem with multiple relays, each node with a single antenna, even under the ideal assumption of full-duplex relays and a clustered network, this virtual MIMO system can never fully mimic a real MIMO diversity-multiplexing tradeoff.  Problems  22.1 For a source and destination, show how the multi-hop network provides a signiﬁcant energy saving over a single-hop network for the same distance. [Hint: The N-hop transmis- = Nγ−1, where γ sion has a power advantage over a single-hop transmission: η = PN−hop NP1−hop is the propagation exponent. ]  22.2 WSNs use multiple sensors. Increasing the sensor density by a factor of n, show the SNR is improved by 10 log10 n dB. 22.3 For a power metric dγ with the propagation exponent γ ≥ 2 and d is the distance between the sender and the receiver, show that relay trafﬁc along an intermediate collinear node is always a better choice. When the power metric is dγ + a, with constant a > 0, is the proposition true?  22.4 Consider a geographical region of 100 square meters. Assume that N nodes are dis- tributed in this region according to a uniformly random distribution and that each node can communicate for a distance of R meters. Find the average number of nodes E[N] as a function of R, for 1 ≤ R ≤ 10, if the network is fully connected. Note that E[N] can be calculated by averaging.      960   cid:2   Wireless ad hoc and sensor networks  References  [1] 3GPP, Physical layer items not for inclusion in Release’99, Tech. Report TR 25.833  V1.1.0, ETSI, Apr 2000.  [2] N. Ahmed, S. S. Kanhere & S. Jha, The holes problem in wireless sensor networks: a  survey. ACM Mobile Comput. & Commun. Rev., 1:2  2005 , 1–14.  [3] N. Ahmed, M. A. A. Khojastepour, A. Sabharwal & B. Aazhang, Outage minimiza- tion with limited feedback for the fading relay channel. IEEE Trans. Commun., 54:4  2006 , 659–669.  [4] Y. Ammar, A. Buhrig, M. Marzencki, B. Charlot, S. Basrour, K. Matou & M. Renaudin, Wireless sensor network node with asynchronous architecture and vibra- tion harvesting micro power generator. In Proc. Joint sOc-EUSAI Conf., Grenoble, Oct 2005, 1–6.  [5] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam & E. Cayirci, A survey on sensor  networks. IEEE Commun. Mag., 40:8  2002 , 102–114.  [6] A. S. Avestimehr & D. N. C. Tse, Outage capacity of the fading relay channel in the  low-SNR regime. IEEE Trans. Inf. Theory, 53:4  2007 , 1401–1415.  [7] S. Borade, L. Zheng & R. Gallager, Amplify-and-forward in wireless relay net- works: rate, diversity, and network size. IEEE Trans. Inf. Theory, 53:10  2007 , 3302–3318.  [8] D. Braginsk & D. Estrin, Rumor routing algorithm for sensor networks. In Proc. ACM  WSNA, Atlanta, GA, Sep 2002, 22–31.  [9] T. Bui & J. Yuan, A decode and forward cooperation scheme with soft relaying in  wireless communication. In Proc. IEEE SPAWC, Helsinki, Finland, Jun 2007, 1–5.  [10] A. Chakrabarti, A. de Baynast, A. Sabharwal & B. Aazhang, Low density parity check  codes for the relay channel. IEEE J. Sel. Areas Commun., 25:2  2007 , 280–291.  [11] S. Chakrabarti & A. Mishra, QoS issues in ad hoc wireless networks. IEEE Commun.  Mag., 39:2  2001 , 142–148.  [12] A. D. Coso, S. Savazzi, U. Spagnolini & C. Ibars, Virtual MIMO channels in coop- erative multi-hop wireless sensor networks. In Proc. 40th Ann. Conf. Inf. Sci. Syst.  CISS , Princeton, NJ, Mar 2006, 75–80.  [13] T. M. Cover & A. A. El Gamal, Capacity theorems for the relay channel. IEEE Trans.  Inf. Theory, 25 :5  1979 , 572–584.  [14] A. del Coso, U. Spagnolini & C. Ibars, Cooperative distributed MIMO chan- nels in wireless sensor networks. IEEE J. Sel. Areas Commun., 25:2  2007 , 402–414.  [15] R. Falk, C.-T. Huang, F. Kohlmayer & A.-F. Sui, Security in wireless mesh networks. In Y. Zhang, J. Luo & H. Hu, eds., Wireless Mesh Networking  Boca Raton, FL: Auerbach, 2007 , pp. 183–223.  [16] Y. Fukuyama, O. Takyu, K. Adachi & M. Nakagawa, Relay method of schedul- ing soft decision symbol based on the result of error detecting code in cooperative communication. IEICE Trans. Fundamentals, E90-A:11  2007 , 2404– 2412.      961   cid:2   References  [17] S. Glisic, Advanced Wireless Communications: 4G Technologies, 2nd edn  Chich-  ester, UK: Wiley-IEEE, 2007 .  [18] D. Gunduz & E. Erkip, Source and channel coding for cooperative relaying. IEEE  Trans. Inf. Theory, 53:10  2007 , 3454–3475.  [19] P. Gupta & P. R. Kumar, Internets in the sky: the capacity of three dimensional  wireless networks. Commun. Inf. Syst., 1:1  2001 , 33–50.  [20] P. Gupta & P. R. Kumar, The capacity of wireless networks. IEEE Trans. Inf. Theory,  46:2  2000 , 388–404.  [21] Y. Hairej, A. Darmawan, H. Morikawa, Cooperative Diversity using Soft Decision and Distributed Decoding. In Proc. 16th IST Mobile Wireless Commun. Summit, Budapest, Hungary, Jul 2007, 1–5.  [22] E. B. Hamida & G. Chelius, Strategies for data dissemination to mobile IEEE Wireless Commun., 15:6  2008 ,  sensor networks.  in wireless  sinks 31–37.  [23] T. J. Harrold & A. R. Nix, Intelligent relaying for future personal communications systems. In IEE Colloquium on Capacity & Range Enhancement Techniques for 3G, London, UK, Feb 2000, 9 1–9 5.  [24] Z. J. Haas, The routing algorithm for the reconﬁgurable wireless networks. In Proc.  IEEE ICUPC, San Diego, CA, Oct 1997, 2, 562–566.  [25] S. M. Hedetniemi & A. Liestman, A survey of gossiping and broadcasting in  communication networks. Networks, 18:4  1988 , 319–349.  [26] W. R. Heinzelman, A. Chandrakasan & H. Balakrishnan, Energy-efﬁcient communi- cation protocol for wireless microsensor networks. In Proc. IEEE HICSS, Maui, HI, Jan 2000, 3005–3014.  [27] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. Culler & K. Pister, System archi- tecture directions for networked sensors. ACM SIGPLAN Notices, 35:11  2000 , 93–104.  [28] R. Hu & J. T. Li, Practical compress-forward in user cooperation: Wyner-Ziv  cooperation. In Proc. IEEE ISIT, Seattle, WA, Jul 2006, 489–493.  [29] J. Hu & T. M. Duman, Low density parity check codes over wireless relay channels.  IEEE Trans. Wireless Commun., 6:9  2007 , 3384–3394.  [30] T. E. Hunter, S. Sanayei & A. Nosratinia, Outage analysis of coded cooperation. IEEE  Trans. Inf. Theory, 52:2  2006 , 375–391.  [31] C. Intanagonwiwat, R. Govindan & D. Estrin, Direct diffusion: A scalable and robust communication paradigm for sensor networks. In Proc. ACM MobiCom, Boston, MA, Aug 2000, 56–67.  [32] P. Jacquet, P. Muhlethaler, T. Clausen, A. Laouiti, A. Qayyum & L. Viennot, Opti- mized link state routing protocol for ad hoc networks. In Proc. IEEE INMIC, Lahore, Pakistan, Dec 2001, 62–68.  [33] M. Janani, A. Hedayat, T. E. Hunter & A. Nosratinia, Coded cooperation in wireless communications: space-time transmission and iterative decoding. IEEE Trans. Signal Process., 52:2  2004 , 362–371.  [34] S. K. Jayaweera, V-BLAST-based virtual MIMO for distributed wireless sensor  networks. IEEE Trans. Commun., 55:10  2007 , 1867–1872.      962   cid:2   Wireless ad hoc and sensor networks  [35] Y. Jing and H. Jafarkhani, Using orthogonal and quasi-orthogonal designs in wireless  relay networks. IEEE Trans. Inf. Theory, 53:11  2007 , 4106–4118.  [36] D. B. Johnson & D. A. Maltz, Dynamic source routing in ad hoc wireless networks.  Mobile Comput., 353  1996 , 153–181  [37] C. Karlof, N. Sastry & D. Wanger, TinySec: a link layer security architecture for wireless sensor networks. In Proc. ACM SenSys, Baltimore, MD, Nov 2004, 162–175.  [38] T. T. Kim, G. Caire & M. Skoglund, Decode-and-forward Relaying with quantized channel state feedback: an outage exponent analysis. IEEE Trans. Inf. Theory, 54:10  2008 , 4548–4564.  [39] G. Kramer, M. Gastpar & P. Gupta, Cooperative strategies and capacity theorems for  relay networks. IEEE Trans. Inf. Theory, 51:9  2005 , 3037–3063.  [40] J. Kulik, W. R. Heinzelman & H. Balakrishnan, Negotiation base protocols for disseminating information in wireless sensor networks. Wireless Netw., 8  2002 , 169–185.  [41] J. N. Laneman & G. W. Wornell, Distributed space–time-coded protocols for exploit- ing cooperative diversity in wireless networks. IEEE Trans. Inf. Theory, 49:10  2003 , 2415–2425.  [42] J. N. Laneman, D. N. C. Tse & G. W. Wornell, Cooperative diversity in wireless networks: efﬁcient protocols and outage behavior. IEEE Trans. Inf. Theory, 50:12  2004 , 3062–3080.  [43] O. Leveque & I. E. Telatar, Information-theoretic upper bounds on the capacity of large extended ad hoc wireless networks. IEEE Trans. Inf. Theory, 51:3  2005 , 858– 865.  [44] X. Li, M. Chen & W. Liu, Application of STBC-encoded cooperative transmissions  in wireless sensor networks. IEEE Signal Process. Lett., 12:2  2005 , 134–137.  [45] R. Liu, P. Spasojevic & E. Soljanin, Incremental redundancy cooperative coding for wireless networks: cooperative diversity, coding, and transmission energy gains. IEEE Trans. Inf. Theory, 54:3  2008 , 1207–1224.  [46] S. R. Madden, M. J. Franklin, J. M. Hellerstein & W. Hong, TinyDB: an acquisi- tional query processing system for sensor networks. ACM Trans. Database Syst., 30:1  2005 , 122–173.  [47] G. Mergen, Q. Zhao & L. Tong, Sensor networks with mobile access: energy and  capacity considerations. IEEE Trans. Commun., 54:11  2006 , 2033–2044.  [48] A. ’Nayagam, J. M. Shea & T. F. Wong, Collaborative decoding in bandwidth-  constrained environments. IEEE J. Sel. Areas Commun., 25:2  2007 , 434–446.  [49] R. Negi & A. Rajeswaran, Capacity of ultra wide band wireless ad hoc networks.  IEEE Trans. Wireless Commun., 6:10  2007 , 3816–3824.  [50] C. T. K. Ng, N. Jindal, A. J. Goldsmith & U. Mitra, Capacity gain from two- transmitter and two-receiver cooperation. IEEE Trans. Inf. Theory, 53:10  2007 , 3822–3827.  [51] C. T. K. Ng & A. J. Goldsmith, The impact of CSI and power allocation on relay channel capacity and cooperation strategies. IEEE Trans. Wireless Commun., 7:12  2008 , 5380–5389.      963   cid:2   References  [52] K.-L. Noh, Y.-C. Wu, K. Qaraqe & E. Serpedin, Time synchronization for wireless sensor networks. In M. Ibnkahla, ed., Adaptive Signal Processing in Wireless Communications  Boca Raton, FL: CRC Press, 2009 , pp. 373–410.  [53] C. E. Perkins & P. Bhagwat, Highly dynamic destination-sequenced distance-vector routing  DSDV  for mobile computers. In Proc. ACM SIGCOMM, London, UK, Aug 1994, 234–44.  [54] C. E. Perkins & E. M. Royer, Ad-hoc on-demand distance vector routing. In Proc  IEEE WMCSA, New Orleans, LA, Feb 1999, 90–100  [55] C. E. Perkins, ed., Ad Hoc Networking  Reading, MA: Addison-Wesley, 2000 . [56] R. Rivest, A. Shamir & L. Adleman, A method for obtaining digital signatures and  public-key cryptosystems. Commun. ACM, 21:2  1978 , 120–126.  [57] P. Sarkar, Overview of cryptographic primitives for secure communication. In N. Sklavos, X. Zhang, eds., Wireless Security and Cryptography  Boca Raton, FL: CRC Press, 2007 .  [58] A. Sendonaris, E. Erkip & B. Aazhang, User cooperation diversity – part I: system description; part II: implementation aspects and performance analysis. IEEE Trans. Commun., 51:11  2003 , 1927–1948.  [59] C. E. Shannon, Communication theory of secrecy systems. Bell Syst. Tech. J., 28   1949 , 656–715.  [60] S. Toumpis & A. J. Goldsmith, Capacity regions for wireless ad hoc networks. IEEE  Trans. Wireless Commun., 2:4  2003 , 736–748.  [61] T. Wang, A. Cano, G. B. Giannakis & J. N. Laneman, High-performance cooperative demodulation with decode-and-forward relays. IEEE Trans. Commun., 55:7  2007 , 1427–1438.  [62] C. Wang, B. Li, K. Sohraby, M. Daneshmand & Y. Hu, Upstream congestion control in wireless sensor networks through cross-layer optimization. IEEE J. Sel. Areas Commun., 25:4  2007 , 786–795.  [63] Y.-C. Wang, C.-C. Hu & Y.-C. Tseng, Efﬁcient placement and dispatch of sensors in  a wireless sensor network. IEEE Trans. Mobile Comput., 7:2  2008 , 262–274.  [64] S. P. Weber, J. G. Andrews, X. Yang & G. de Veciana, Transmission capacity of wireless ad hoc networks with successive interference cancellation. IEEE Trans. Inf. Theory, 53:8  2007 , 2799–2814.  [65] G. Xie, M. N. S. Swamy & M. O. Ahmad, Joint optimal multipath routing and rate control for multidescription coded video streaming in ad hoc networks. IEEE Trans. Multimedia, 10:8  2008 , 1687–1697.  [66] W. Ye, J. Heidemann & D. Estrin, An energy-efﬁcient MAC protocol for wireless  sensor networks. In Proc. InfoCom, New York, Jun 2002, 3, 3–12.  [67] S. Yiu, R. Schober & L. Lampe, Distributed space-time block coding. IEEE Trans.  Commun., 54:7  2006 , 1195–1206.  [68] M. Yu & K. K. Leung, A trustworthiness-based QoS routing protocol for wireless ad  hoc networks. IEEE Trans. Wireless Commun., 8:4  2009 , 1888–1898.  [69] M. Yuksel & E. Erkip, Multiple-antenna cooperative wireless systems: a diversity- Inf. Theory, 53:10  2007 ,  IEEE Trans.  multiplexing tradeoff perspective. 3371–3393.      964   cid:2   Wireless ad hoc and sensor networks  [70] F. Zabin, S. Misra, I. Woungang, H. F. Rashvand, N.-W. Ma & M. Ahsan Ali, REEP: data-centric, energy-efﬁcient and reliable routing protocol for wireless sensor networks. IET Commun., 2:8  2008 , 995–1008  [71] R. Zemek, D. Anzai, S. Hara, K. Yanagihara & K. Kitayama, RSSI-based localization without a prior knowledge of channel model parameters. Int J. Wireless Inf. Netw., 15:3 4  2008 , 128–136.  [72] Z. Zhang & T. M. Duman, Capacity approaching turbo coding and iterative decoding  for relay channels. IEEE Trans. Commun., 53:11  2005 , 1895–1905.      Appendix A The Q-function  Computation of probabilities that involves a Gaussian process requires the calculation of the integral of the Gaussian pdf  The probability of a Gaussian random variable x exceeding x0 is given by  −  x−m 2 e 2σ 2  .  p x dx.  σ  p x  = 1 √ 2π   cid:14  ∞ Pr x ≥ x0  =  cid:3   cid:14  ∞  x0 − m  x0  =  Pr  y >  σ  1√ 2π  x0−m  σ  −y2 2dy, e  Substituting y = x−m  σ , we have   cid:2    cid:14  ∞  where the kernel of the integral is the normalized Gaussian pdf with zero mean and unit variance.  The Q-function is deﬁned as  Q x  =  −y2 2dy, e  1√ 2π  x   A.7  which is the complementary Gaussian cdf Pr y ≥ x  for the pdf of the zero-mean, unit- variance Gaussian random variable. There is no closed-form solution for Q x . Some analysis results for the Q-function are listed here [1]:  cid:2  Q x  + Q −x  = 1, √ −x2 2, 1 e 2π  Q x  >  x > 1,   cid:3    A.8    A.9   x  1 − 1 x2 −x2 2, e  Q x  <  x  √ 1 2π Q x  ≤ 1 −x2 2, e 2 Q x  ≤ e −x2 2, √ Q x  ≤ 1 −x 2 π , e 2  x > 0,  x ≥ 0, x ≥ 0, x ≥ 0,   A.4    A.5    A.6    A.10    A.11    A.12    A.13       966   cid:2   Appendix A The Q-function  Q x  = 1  π  −x2  2 sin2 θ , e  x ≥ 0,   cid:14  π 2  cid:2   0   cid:3   Q x  = 1 2 Q x  = e x   cid:2   − 1√ 2π −x2 2 √  2π  x − x3 2  1 − 1 x2  + x5 2 · 4 + 1 · 3  − x7 2 · 4 · 8 − 1 · 3 · 5  x4  x6  + ···  ,   cid:3   + ···  ,  where  A.9  and  A.10  are very tight lower and upper bounds, obtained from  A.16 . Equation  A.12  is the well-known Chernoff bound.  The error function erf x  and the complementary error function erfc x  are sometimes  used. They are deﬁned as  erfc x  = 2√  π  They relate to the Q-function by   cid:14   z  −x2dx, e  π  0  z   cid:14  ∞ −x2dx, e erf x  = 1 − erfc x .  cid:3   cid:18   erfc x  = 2√  cid:2   cid:17   Q x  = 1 2  x√ 2 √  erfc  ,  erfc x  = 2Q  x  2  .  MATLAB provides the erfc and erf functions for numerical evaluation of these functions.  Reference  [1] S. Verdu, Multiuser Detection  Cambridge, UK: Cambridge University Press, 1998 .   A.14    A.15    A.16    A.17    A.18    A.19    A.20       Appendix B Wirtinger calculus  The optimization of system parameters depends on the deﬁnition of certain criterion functions. An analytical optimum solution can be derived by setting the derivatives with respective to the adjustable system parameters to zero. In digital communications, signals and systems are typically represented in complex form. The Wirtinger calculus is deﬁned for deriving the derivative of the criteria with respect to the complex parameters.  The complex derivative of a complex function f  z , f notion in complex analysis. If f holomorphic in X . In order for f  z  to be holomorphic,  dz , is a very fundamental exists in a region X ⊂ C, f  z  is said to be analytic or   cid:14    cid:14    z  = df  z   f  z  = u x, y  + jv x, y , the Cauchy-Riemann equations must be satisﬁed  z = x + jy,  ∂u x, y   ∂x  = ∂v x, y   ,  ∂y  ∂v x, y   ∂x  = − ∂u x, y   .  ∂y   cid:14   Then, f   z  can be expressed by [1]  df  z  dz  = ∂u x, y   + j  ∂v x, y   .  ∂x  ∂x  In digital communications, we face the problem of optimization of a real function with respect to complex parameters. Optimization based on complex cost functions makes no sense, since no ordering operation is deﬁned for complex numbers. The real function f  z  is not holomorphic, unless it is a real constant. The optimization of a real function of a complex variable, f  z  = u x, y , can be imple- mented as optimizing u x, y  with respect to two real variables x and y. The Wirtinger calculus is based on this idea, but gives a compact notation.  Deﬁnition  Wirtinger Calculus : Given a  complex  function f  z  of a complex variable z = x + jy ∈ C, x, y ∈ R, its ∗ derivatives with respect to z and z   cid:2    cid:3   ∂f ∂z  = 1 2  ∂f ∂x  are deﬁned, respectively, as + j − j  ∂z∗ = 1  ∂f ∂x  ∂f ∂y  ∂f  2  ,  ∂f ∂y   cid:2    cid:3   .  Based on the above deﬁnition, we have the following important results:  f  z  = cz ⇒ ∂f ∂z  = c,  ∂f  ∂z∗ = 0,   B.21    B.22    B.23    B.24    B.25       968   cid:2   Appendix B Wirtinger calculus  f  z  = cz  ∗ ⇒ ∂f ∂z  = 0,  ∂f  ∂f  ∂z∗ = c, ∂z∗ = z.  cid:13   cid:8   = 1 2  These results can be very easily veriﬁed. For example, for f  z  = zz  ∗  f  z  = zz  cid:12   cid:7   ∂  ∗ ⇒ ∂f ∂z   cid:8   ∗  ,  = z  cid:7   x2 + y2 ∂x  ∂  + j  x2 + y2 ∂y   cid:7   zz  ∗ cid:8  = 1  2  ∂f  ∂z∗ = ∂ ∂z∗  , ∂f ∂z∗ can be derived as   2x + j2y  = z.   B.28   Differentiation using the Wirtinger calculus is similar to that with real functions with real ∗ is treated as constant when differentiating with respect to z and vice variables. Note that z versa. It can be veriﬁed that the sum, product, quotient, and chain rules for the derivatives of a real function still hold for Wirtinger calculus differentiation. For the product rule,  cid:19  given f  z  = f1 z f2 z , we have  f2 z  + f1 z  For the chain rule, given f  z  = h g z  , g z  ∈ C, we have [1]  f1 z f2 z   ∂ ∂z  ∂z  ∂f2 z   .  ∂z   cid:20  = ∂f1 z    B.29   ∂f  z  ∂z  = ∂h w   ∂w  · ∂g z  ∂z  + ∂h w  ∂w∗  w=g z   w=g z   ∂f  z   ∂z∗ = ∂h w   ∂w  · ∂g z  ∂z∗ + ∂h w  ∂w∗  w=g z   w=g z   ∗ · ∂g ∂z   z   ,  ∗ · ∂g  z  ∂z∗ .   cid:4  cid:4  cid:4  cid:4   cid:4  cid:4  cid:4  cid:4   Unlike the complex derivative of a complex function, the Wirtinger derivative exists for all functions. For holomorphic function f  z , the Wirtinger derivative with respect to z agrees with the ordinary derivative of a complex function. For multiple complex variable systems, z =  z1, z2,··· , zn T ∈ Cn, and we have f  z  ∈ R. The gradient can be deﬁned as   cid:4  cid:4  cid:4  cid:4   cid:4  cid:4  cid:4  cid:4   ⎡⎢⎢⎢⎢⎢⎣  ⎤⎥⎥⎥⎥⎥⎦ ,  ∂f ∂z1 ∂f ∂z2  ...  ∂f ∂zn  ⎤⎥⎥⎥⎥⎥⎦ .  ⎡⎢⎢⎢⎢⎢⎣  ∂f ∗ ∂z 1 ∂f ∗ ∂z 2  ... ∂f ∂z∗ n  =  ∂f ∂z  ∂f  ∂z∗ =  f  z  = cTz = zTc ⇒ ∂f  z  ∂z ∗ = zHc ⇒ ∂f  z  ∂z  f  z  = cTz  = c,  = 0,  ∂f  z   ∂z∗ = 0, ∂z∗ = c,  ∂f  z    B.26    B.27    B.30    B.31    B.32    B.33    B.34   At the optimum, these gradients are equal to zero vector. The following Wirtinger derivatives are important:      969   cid:2   Reference  f  z  = zHMz = zTMz  ∗ ⇒ ∂f  z  ∂z  = MTz ∗  ,  ∂f  z   ∂z∗ = Mz,  where c =  c1, c2,··· , cn T ∈ Cn. The gradient of a real function that has complex variables is usually deﬁned as   B.35   ⎛⎜⎜⎜⎜⎜⎝  ∇ =  ⎞⎟⎟⎟⎟⎟⎠ .  ∂y1  ∂y2  + j ∂ + j ∂ ... + j ∂  ∂yn  ∂ ∂x1 ∂ ∂x2  ∂ ∂xn  ∇f  z  = 2   ∇f  z  ∗ = 2  ∂f  z  ∂z∗ , ∂f  z  ∂z  .  Reference   B.36    B.37    B.38   Thus,  The gradient representation is not elegant, since it introduces a factor of 2. The Wirtinger Calculus is more elegant since it has clearer arithmetic rules.  [1] R. F. H. Fischer, C. Windpassinger, A. Lampe & J. B. Huber, MIMO precoding for decentralized receivers. In Proc. IEEE ISIT, Lausanne, Switzerland, Jun-Jul 2002, 496.      Index  ACTS system, 213 ad hoc on-demand distance vector  AODV  routing,  A-law PCM, 673 C-means algorithm, 662 K-best Schnorr-Euchner  KSE  decoding, 825 M-algorithm, 616 M-ary PPM, 879 M-band maximally decimated analysis synthesis  system, 538  Mth band ﬁlter, 527 Mth-power loop, 227 N× EV-DO, 16 Q-function, 59, 187 S-parameters, 387  cid:18 -K model, 874 μ-law  mu-law  PCM, 673 π 4-DQPSK, 12, 205 π 4-QPSK, 14, 205 p-persistent CSMA, 111 s-random interleaver, 638 z-transform, 491 a posteriori probability  APP  algorithm, 627 1-dB compression point, 411 1-persistant CSMA, 111 16QAM, 15 1G, 11 2-D IDCT, 529 2-D isotropic scattering, 64 2G, 12 3.5G, 15 3.9G, 18 3DES, 939 3G, 14 3GPP LTE, 17 3GPP channel model, 47 4G, 18  A D conversion, 4 A D converter, 4 AAA  authentication, authorization, and accounting ,  937  AAC, 701 absorbing boundary condition  ABC , 340 ac coefﬁcient, 720 access channel, 118 access network  AN , 22 ACELP, 678, 693 ACF, 60, 65, 248 ACI, 97 acknowledgment  ACK , 649 ACLR, 414 ACPR, 413 acquisition or coarse synchronization, 318  936  adaptive beamforming, 767 adaptive binary optimization  ABO , 733 adaptive block transform, 744 adaptive CAB  ACAB , 775 adaptive cross-SCORE  ACS , 775, 780 adaptive duty-cycling, 945 adaptive equalizer, 165 adaptive ﬁlter, 513 adaptive full-rate  AFS , 694 adaptive Huffman coding, 559 adaptive PCM, 659 adaptive phase-SCORE  APS , 775 ADC, 464 additive color matching, 710 adjacent channel selectivity, 374 admittance matrix, 385 ADPCM, 661, 681 AES, 939 AF, 952 AFC, 228 AGC, 224, 449 Alamouti code, 813, 856 Alamouti’s space-time diversity scheme, 149 aliasing, 466 all-digital PLL, 520 all-transistor technique, 452 ALOHA, 108 alternate horizontal scan, 740 alternate scan, 740 alternate vertical scan, 740 AM, 180 AMC, 19, 646 ampliﬁer, 428 amplitude clipping, 306 amplitude clipping or companding, 308 amplitude modulation  AM , 1 AMPS, 11 AMR, 684, 693 AMR-WB, 697 analog modulation, 180 analog or digital predistorter, 429 analog reconstruction, 473 analysis bank, 536 analysis by synthesis, 688 anchor, 947 angle spread, 71 angular diversity, 132 antenna array, 360      971   cid:2   Index  antenna dispersion, 892 antenna ﬁeld zones, 343 antenna gain, 344 antenna temperature, 346 antialiasing, 466 antialiasing preﬁlter, 467 aperture-coupled microstrip-patch antenna, 365 application layer, 37 area spectral efﬁciency  ASE , 574 arithmetic coding, 560 ARQ, 19, 591, 649 array factor, 361 articulation index  AI , 671 ASIC, 4 ASK, 34, 184 asymmetric key encryption, 939 asymptotic equipartition property  AEP , 576 attack, 937 attenuator, 424 auction game, 923 audio coding, 697 authentication center  AuC , 22 autocorrelation-based method, 687 AVC, 747 average duration of fades, 63, 64, 144 axial ratio  AR , 359 axial-mode helical antenna, 364 axis ratio, 74  bad urban  BU , 68, 82 balanced ampliﬁer, 437 balun, 355 bandpass sampling theorem, 468 BARITT diode, 417 Barker sequence, 255 Barkhausen criteria, 438 base layer, 728, 742 battery exhaustion attack, 947 battery technology, 948 Bayes’s rule, 551, 628 Bayesian network, 645 BCH code, 603 BCJR algorithm, 617, 627 beacon, 947 beam area, 342 beam steering, 767 beam-space processing, 769 beamforming, 25, 763 beamforming gain, 360, 830 beamspace MIMO, 829 beamwidth between the ﬁrst nulls  FNBW , 342 beehive pattern, 92 belief or probability propagation, 645 BEP, 185, 190 Bessel ﬁlter, 400 best-effort service, 122 Bethe hole coupler, 396 BFSK, 187, 207 BICM, 620 biconical dipole antenna, 364 biconical vee antenna, 364 bidirectional predicted picture  B , 734 bilinear transformation method, 511  binary arithmetic coding  tier 1 coding , 728 binary symmetric channel  BSC , 571 binomial or Butterworth ﬁlter, 398 binomial transformer, 389 biorthogonal, 723 biphase modulation, 879 bipolar transistor, 417 bit loading, 324 bit plane coding, 728 bit plane quantization, 728 bit-ﬂipping algorithm, 645 bitstream organization  tier 2 coding , 728 BJT, 418 blackhole or sinkhole attack, 937 blackmail attack, 938 Blass matrix, 767 BLAST, 820 BLAST scheme, 271 blind, 160, 840 blind beamforming, 774 blind channel estimation, 160 blind equalizer, 171 blind source separation, 764 block, 717, 739 block error rate  BLER , 651 block matching algorithm, 735 block turbo code, 624, 639 block-type pilot arrangement, 302 Boltzmann’s constant, 346 boundary element method  BEM , 339 BPSK, 14, 195 BRAN, 26 branch metric, 614 branch-line hybrid, 396 Brewster angle, 74 broadband ampliﬁer, 437 broadband ﬁxed wireless access, 30 broadband microstrip antenna, 358 broadband reconﬁgurable antenna, 365 broadband wireless access, 19 broadcast channel, 101 BS-CDMA, 276 Bussgang theorem, 308 Butler matrix, 766 buzziness problem, 686  CAB algorithm, 775 CABAC, 728 capacity region, 940 care-of address  CoA , 24, 101 carrier frequency synchronization, 228 carrier phase recovery, 227 carrier synchronization, 227, 320 carrier-to-interference ratio  CIR , 107 Carson’s rule, 183 causality, 492 CAVLC, 563 CCF, 248 CCI, 92, 96 CCK, 25 CCSDS, 624 CDMA, 4, 12, 105 CDMA2000, 15, 278      972   cid:2   Index  CDMA2000 1x  Phase 1 , 15 CDMA2000 1xEV-DO, 15 CDMA2000 1xEV-DV, 15 CDMAOne, 13 CDPD, 13 cell planning, 93 cell-sectoring, 96 cell-splitting, 95 cellular concept, 92 CELP, 660, 689 cepstral distance  CD , 671 cepstrum method, 687 CF, 952 channel assignment, 98 channel capacity, 567 channel coding theorem, 568 channel coherence bandwidth, 69 channel coherence time, 70 channel equalization, 160 channel estimation, 158, 301 channel inversion, 579 channel sounding, 82 channel structure, 117 chase combining, 651 Chase-II algorithm, 624 Chebyshev optimal method, 509 Chebyshev transformer, 389 Chernoff bound, 187 chi-squared distribution, 807 chip-rate processing, 899 chrominance, 711 CIC ﬁlter, 525 CIF, 734 CIR, 379 circuit switching, 22 circularly polarized microstrip antenna, 359 circulator, 394 Clarke or Jakes model, 60 class A ampliﬁer, 306, 430 class AB ampliﬁer, 431 class B ampliﬁer, 431 class C ampliﬁer, 431 class D ampliﬁer, 432 class E ampliﬁer, 432 class F ampliﬁer, 432 class F class S ampliﬁer, 432 classical Doppler or Jakes spectrum, 60 clock jitter, 477 closed-loop MIMO scheme, 828 closed-loop MIMO system, 794 closed-loop power control, 98, 264 closed-loop transmit diversity, 856 cluster size, 92 clusterhead, 941 CNR, 379 coaxial cavity resonator ﬁlter, 407 codebook, 661 coded cooperation, 955 codeword, 661 coding gain, 618 cognitive radio, 901 coherent distance, 72  −1  inverted class F  ampliﬁer, 432  color decorrelation, 729 color space, 710 comb line, 881 comb-type pilot arrangement, 302 combine bandpass ﬁlter, 405 comfort noise generation, 683 companding  compressing-expanding , 673 complementary code, 255 complex orthogonal sequence, 327 computational electromagnetics, 338 Comvik, 12 conditional entropy, 552 conditional joint entropy, 555 conditional self-information, 552 congestion control, 942 conical monopole, 364 conjugate matching, 437 conjugate-gradient method, 338 constant modulus algorithm, 171, 774 constitutive relation, 337 constrained least-squares  CLS , 775 constraint length, 607 content-adaptive encoding, 744 control channel, 117 convolutional code, 607 cooperative diversity, 133 cooperative spectrum sensing, 908 CORBA, 900 CORDIC  Coordinate Rotation Digital Computer ,  516, 529  cordless telephone, 13 core network  CN , 22 COST-231-Hata model, 42 COST-231-Walﬁsch-Ikegami  COST-WI  model, 43 COST-259, 46 COST-273, 47 Costas loop, 228 coupled line bandpass ﬁlter, 403 coupled line coupler, 396 coverage, 941 coverage hole, 942 CP-CDMA, 276 CPFSK, 211 CPM, 217 CQF, 532, 540 CRC, 596 CRLB, 124, 159, 322, 585 cross-layer design, 120 cross-SCORE, 775 CRSC code, 625 cryogenic cooling, 428 crystal resonator, 441 CS-ACELP, 693 CSI, 103 CSI known at the transmitter, 798 CSMA, 109 CSMA CA, 26, 110 CSMA CD, 109 CT2, 13 CT2+, 13 CT3, 13 CVSDM, 659, 681 cycle frequency, 776      973   cid:2   Index  cyclic  or cyclic conjugate  autocorrelation function,  cyclic  or cyclic conjugate  cross-correlation function,  776  777  cyclic or CRC code, 600 cyclic preﬁx, 294 cyclic-preﬁx OFDM  CP-OFDM , 296 cyclostationary beamforming, 776  DiffServ  differential services , 122 digest, 939 digital broadcasting, 33 digital down-conversion, 516 digital phase shifter, 409 digital PLL, 444 digital sense multiple access  DSMA , 113 digital up-conversion, 516 dipole antenna, 353 direct frequency synthesis, 448 direct-conversion or zero-IF system, 5 directed diffusion, 950 direction-ﬁnding, 759 directional coupler, 393, 395 directivity, 344 Dirichlet boundary condition, 338 dirty paper coding  DPC , 580, 826 discontinuous transmission, 683 discrete Hartley transform, 498 discrete memoryless source  DMS , 556 discrete sine transform  DST , 530 distance spectrum analysis, 636 distance vector routing  DVR , 935 distance-product criterion, 813 distortion-rate function, 567 distributed ampliﬁer, 437 distributed antenna, 362 distributed Bellman-Ford  DBF  algorithm, 935 distributed contention, 113 distributed coordinated function  DCF , 946 distributed STBC, 957 distributed technique, 452 distribution-preserving precoding, 172 dithering, 477 diversity, 130 diversity combining, 758 diversity gain, 811, 830 diversity MIMO, 819 diversity reception, 239 diversity set, 100 diversity-multiplexing tradeoff, 830, 959 divided-by-M device, 228 DjVu, 733 DM, 481, 659, 681 DMB, 33 DMPSK, 201 DNL, 475 DoA positioning, 123 DoA-based beamforming, 767 Dolby AC-3 or Dolby Digital, 698 Doppler effect, 60 Doppler fading, 60 Doppler power spectral density, 70 Doppler spectrum, 60 Doppler spread, 60, 70 double-balanced diode mixer, 427 double-balanced mixer, 427 double-scattering MIMO channel model, 790 double-sideband  DSB  AM, 180 double-stub tuner, 388 doubly-selective fading channel, 841 DPCM, 659, 680, 681, 708, 713 DQPSK, 204  D-AMPS  Digital-AMPS , 12 D-BLAST, 821 D-frame, 735 D A converter, 4 DAB, 33 DAC, 464 data aggregation, 948 data link layer, 35, 944 data partitioning, 742 data-centric routing, 949 database, 946 Daubechies wavelet ﬁlter, 723 DBPSK, 196 dc coefﬁcient, 720 dc offset, 4, 5 DCT, 527, 683, 717 DDCR, 228 DDS, 443, 518 DEBPSK, 196 decimation, 468, 520, 524 decimation ﬁlter, 524 decision-directed channel estimation, 793 decision-directed estimation, 229 decision-directed PLL, 227 decorrelation or ZF receiver, 268 DECT, 13, 16 delay dispersion, 239 delay diversity code, 818 DEMPSK, 201 denial-of-service attack, 937 deployment of cell size, 94 DEQPSK, 203 DES, 939 destination-sequenced distance vector  DSDV   routing, 935  detection and avoidance  DAA , 871 detour attack, 938 Deygout’s method, 78 DF, 952 DF multirelay, 957 DFE, 160, 166 DFT, 495, 498 diagnostic acceptability measure  DAM , 669 diagnostic rhyme test  DRT , 669 diamond cell, 92 dictionary-based coding, 563 differential Alamouti code, 819 differential entropy, 553 differential FET mixer, 427 differential modulation, 231 differential OSTBC, 819 differential space–time coding, 819 differential unitary space–time code, 819 diffraction, 76      974   cid:2   Index  DR, 393 DR ﬁlter, 407 DR oscillator, 442 DS, 246 DS-CDMA, 105 DS-CDMA model, 257 DS-UWB, 27 DS-UWB signal, 882 DSB modulation, 426 DSB-LC, 181 DSB-SC, 181 DSCQS method, 712 DSP, 4 DSSS, 25, 126, 256 DSTTD, 817 DTFT, 494 DTWT, 532 dual-gate FET mixer, 427 DVB-H, 33 DVB-RCL, 30 DVB-RCS, 628 DVB-S, 21 DVB-S2, 33 DVB-T2, 33 dwell time, 281 DWT, 532, 730 dyadic wavelet transform, 532 dynamic channel assignment, 99 dynamic channel selection, 99 dynamic frequency selection, 901 dynamic source routing  DSR , 936 dynamic spectrum access, 915 DySPAN, 905  E-911, 123 E-UTRA, 17 E-UTRAN, 17 early-late gate synchronizer, 229 earth’s magnetic ﬁeld, 81 EBCOT, 726 ECMA International, 872 EDGE, 13, 16 effective area, 345 effective height, 345 EFR, 678 EGC, 133, 143 electromagnetic compatibility, 374 electromagnetic interference, 374 elliptic  or Cauer  function ﬁlter, 399 encoder state diagram, 611 encryption, 938 end-of-block  EOB  codeword, 721 enhancement layer, 728, 742 ENOB, 477 entropy, 550 environmental noise, 98 EPC, 34 Epstein-Peterson method, 78 equal ripple ﬁlter, 399 erasure correction code, 903 Erceg model, 47 ergodic capacity, 802 Erlang B equation, 114  Erlang C equation, 115 Erlang capacity, 114 ERMES, 32 error detection correction coding, 591 error ﬂoor region, 635 error weighting ﬁlter, 691 ESPAR antenna, 361, 829 ESPRIT, 760 estimation theory, 585 EV-DO Multicarrier, 16 even discrete cosine transform II  EDCT-II , 530 EVRC, 695 EVRC-B, 695 EVRC-WB, 695 EXIT analysis, 638 exosphere, 78 Exp-Golomb code, 559 exponential-Golomb  Exp-Golomb  variable-length  code, 718, 751  exposed terminal problem, 111 extended CELP, 696 extended Clarke’s model, 61 extended rtPS  ErtPS , 122 extended Saleh-Valenzuela model, 45, 47 EZW, 724  factor graph, 643 Fano algorithm, 615 far ﬁeld or Fraunhofer zone, 343 Faraday rotation, 81 Faraday’s law, 337 fast 2-D DCT, 529 fast block motion estimation, 737 fast cell selection, 100 fast DCT, 528 fast frequency hopping, 282 fast frequency shift keying  FFSK , 213 FastICA, 764 FBSS, 100 FDD, 102 FDE, 170, 312 FDMA, 4, 11, 104 FDTD method, 339 FEC, 591 feedback model, 438 feedforward linearization, 429, 434 FEM, 340 ferrite phase shifter, 409 FET, 418 FET switch, 422 FFT, 499 FH, 246 FH-CDMA, 106 FH-CDMA or FH-SSMA, 283 FHSS, 25, 280 ﬁlter bank, 535 ﬁlter coefﬁcient or ﬁlter tap, 501 ﬁnite or Galois ﬁeld, 592 ﬁnite state machine, 170, 444, 611 FIR ﬁlter, 502 Fisher information matrix, 586 ﬁxed channel assignment, 98 ﬁxed channel assignment with borrowing, 99      975   cid:2   Index  ﬂat architecture, 941 ﬂat-plane bow-tie dipole antenna, 364 FLEX, 32 ﬂexible channel assignment, 99 ﬂexible precoding, 172 ﬂicker  1 f   noise, 5 ﬂicker or 1 f noise, 5, 377 ﬂooding, 935 FM, 182 formant, 665 forward channel, 101 forward-backward algorithm, 627 Fountain code, 903 four-port network, 395 Fourier code, 327 Fourier series, 489 Fourier transform, 489 fourth-power loop, 228 FR, 689 fractional bandwidth  FBW , 364 fractional out-of-band power, 189 fractional pitch period detection, 687 frame timing, 230 Frank code, 327 free Hamming distance, 613 free Hamming weight, 613 free-space loss, 39 frequency coherence, 69 frequency diversity, 131 frequency divider, 446 frequency masking, 667 frequency modulation  FM , 1 frequency multiplier, 445 frequency offset, 314 frequency pulling, 5 frequency sampling method, 509 frequency synthesis, 443 frequency-domain coding, 538 frequency-hopping diversity code, 857 frequency-independent antenna, 349 Fresnel cosine and sine integrals, 77 Fresnel reﬂection and transmission coefﬁcients, 74 Fresnel-Kirchoff diffraction parameter, 77 Friis noise formula, 378 Friis power transmission equation, 39 Friis transmission formula, 341 FSK, 11, 184, 207 full-search method, 735 full-wave EM solver, 406 FWT, 532  game theory, 921 Gamma distribution, 58 gaseous absorption, 79 gateway MSC, 22 Gauss’s electric law, 337 Gauss’s magnetic law, 337 Gaussian doublet, 877 Gaussian ﬁlter, 215, 400 Gaussian monocycle, 877 Gaussian pulse, 877 generalized Lloyd algorithm, 662 generalized multi-carrier  GMC , 539  generalized sidelobe canceller, 767, 770 generator polynomial, 601 genetic algorithm, 267 GEO, 21 geometrical optics, 46, 338 geometrical theory of diffraction, 76 GFSK, 14 Gibbs phenomenon, 509, 660 GIF  Graphics Interchange Format , 564 Gilbert-cell mixer, 427 global motion compensation, 746 Globalstar, 21 GMSK, 12, 215 go-back-N ARQ, 649 Golay code, 603 Golay complementary sequence, 255, 307 Gold sequence, 252 GoS, 114 gossiping, 935 GPS, 21, 125 gradient-descent algorithm, 515 Gram-Schmidt orthogonalization, 184 Gray coding, 187 grayhole attack, 938 group of pictures  GOP , 735, 739 GRPS, 13 GSC paging system, 32 GSM, 12 Guaranteed Time Slots  GTS , 28 Gunn diode, 416  H-BLAST, 820 H-S EGC, 143 H-S MRC, 143 H.261, 748 H.263, 749 H.264 AVC, 750 half-band ﬁlter, 526 half-power beamwidth  HPBW , 342 Hamming code, 595 Hamming distance, 593 Hamming weight, 593 Hamming window, 496 handoff, 99 handoff management, 101 HAPS, 21 hard decision decoding, 598 hard handoff, 100 harmonic and individual lines plus noise  HILN , 702 harmonic oscillator, 441 harmonic vector excitation coding  HVXC , 701 HARQ, 19, 592, 953 Hartley, Clapp and Colpitts oscillators, 440 hash function, 939 HBT, 418 hearing or auditory system, 665 hearing threshold, 666 helical antenna, 350 HEMT, 420 Hertzian electric dipole, 351 heterostructure FET  HFET , 428 hidden terminal problem, 110 hierarchical architecture, 941      976   cid:2   Index  hierarchical encoding, 717 high-order statistics, 172 high-temperature superconductor  HTS , 397 HiperACCESS, 29 HiperLAN, 25 HiperLAN 1, 26 HiperLAN 2, 26 HiperMAN, 19, 29 HiSWAN, 25 hold interpolator, 523 home address  HoA , 101 home agent, 24 home location register  HLR , 22 HomeRF, 26 Homo economicus model, 924 Homo egualis, 925 Homo parochius, 925 Homo reciprocans, 925 homodyne system, 5 hop interval, 281 Howells-Applebaum array, 770 HSCSD, 13 HSDPA, 15 HSPA, 15 HSUPA, 15 HTS ﬁlter, 407 Huffman Coding, 557 Huffman coding, 556 human visual system, 709 Huygen’s principle, 76 hybrid coupler, 396 hybrid scalability, 743 hybrid-ARQ  HARQ , 651  I Q matching, 4 I Q mismatch, 5, 7 ICI, 97, 312 ideal reconstructor, 474 identity transform, 536 idle signal casting multiple access  ISMA , 111 IDMA, 276 IDWT, 532 IEEE 1451, 934 IEEE 802.11, 25 IEEE 802.11a, 25 IEEE 802.11b, 25 IEEE 802.11g, 25 IEEE 802.15.1  Bluetooth , 27 IEEE 802.15.3, 27 IEEE 802.15.3c, 27 IEEE 802.15.4  ZigBee , 28 IEEE 802.15.4a, 28 IEEE 802.16  WiMAX , 28 IEEE 802.16a d e  WiMAX , 29 IEEE 802.16e, 17 IEEE 802.20, 18 IEEE 802.22  Wi-TV , 30 IF, 4 IIR ﬁlter, 501 Ikegami model, 44 image problem, 5 image processing, 708 image rejection mixer, 427  IMDCT, 542 IMPATT diode, 416 impedance  K  or admittance  J  inverter, 403 impedance matching, 388, 456 impedance matrix, 385 impulse noise, 709 impulse radio, 870 impulse radio UWB, 872 IMT-2000, 14 in-band distortion, 306 incremental redundancy, 651, 953 incremental relaying, 953 incumbent proﬁle detection, 901 independent component analysis  ICA , 764 indoor propagation model, 45 information, 550 information MIMO, 819 infrared, 25 INL, 475 input impedance, 382 insertion loss  IL , 383 insertion loss  IL  method, 397 integer DCT transform, 743 intelligent network  IN , 22 interdigital capacitor, 455 interdigital transducer, 408 interference-free window  IFW , 256 interference-to-noise ratio  INR , 147 intermodulation distortion  IMD , 411 intermodulation interference, 97 intermodulation product, 411 interpath interference, 890 interpolation, 520, 521 interpolation ﬁlter, 522 intersymbol interference  ISI , 52 intra-picture  I , 734 intraframe quantization table, 740 IntServ  integrated services , 122 inverse z-transform, 493 inverse DCT  IDCT , 528 inverse DTFT, 494 inverse ﬁlter, 503 inverse Fourier transform, 489 inverse Laplace transform, 490 ionosphere, 78 ionospheric effects, 80 IOWEF  input-output weight enumeration function ,  622 IP, 22 Ipatov ternary sequence, 883 IPSec protocol, 24 IPv4, 24, 101 IPv6, 18, 24 Iridium, 20 irregular LDPC code, 642 irreversible color transform, 729 IS-136, 12 IS-2000, 15 IS-54, 12 IS-856, 15 IS-95, 12, 278 IS-95A, 13 IS-95B, 13      977   cid:2   Index  ISI, 97 iterative soft-decision decoding, 643 ITU channel models, 47 ITU empirical model, 78 ITU V.34 voiced-band modem, 172  jamming hole, 942 Johnson noise, 376 joint detection, 266 joint entropy, 552, 554 joint information, 552 joint source-channel coding, 954 JPEG standard, 716 JPEG-LS, 731 JPEG2000 standard, 729 JTACS, 11  Kaiser window, 496 Kalman estimation, 514 Kalman ﬁltering, 159 Karhunen-Loève transform, 529, 683, 715 Karush-Kuhn-Tucker theorem, 916 Kasami sequence, 252 key management, 938 keyhole, 790 klystron power ampliﬁer, 435 knife-edge or half-plane diffraction, 76 Kuroda’s identities, 402  L-match circuit, 457 ladder network, 400 Laguerre polynomial of order k, 802 Lange coupler, 396 Laplace transform, 490 large area  LA  code, 256 large set of Kasami sequences, 253 large-scaled space diversity, 132 LAS code family, 256 layered space-time scheme, 819 layered video coding, 742 LBG, 662 LCMV beamformer, 769 LCR, 63, 144 LD-CELP, 691, 694 LDPC, 25 LDPC code, 641 LDPC decoder, 644 LDPC encoder, 644 LEACH, 941, 949 learning automaton, 921 Lee’s model, 43 Leeson’s model, 439 LEO, 20 Levinson-Durbin algorithm, 676 LHCP, 346 LINC, 429 line code, 188 linear block code, 592 linear dispersion code, 819 linear equalization, 160 linear equalizer, 162 linear interpolator, 523 linear phase ﬁlter, 400  linear precoding, 827 linear prediction analysis, 674 linear prediction synthesis, 674, 679 linear preequalization, 172 linear reward-penalty  LR-P  scheme, 921 linear transconductor cell, 456 linearization technique, 433 link budget analysis, 379, 876 list sphere decoding, 825 LLC sublayer, 35, 944 Lloyd-Max algorithm, 661 LLR, 628 LLR-ordered SIC, 825 LMDS, 29 LMS algorithm, 159, 515 LNA, 4 LO, 437 LO leakage, 4, 5, 7 LO pulling, 7 LO pulling leakage, 5 loaded-line phase shifter, 409 local oscillator  LO , 4 location, 947 location management, 101 location registration, 101 log area ratio  LAR , 676 log-FFT, 500 log-MAP, 634 log-normal shadowing, 48 log-periodic dipole array, 364 logarithmic PCM coding, 673 logical channel, 117 long code, 248 long-channel MOSFET, 456 long-term linear prediction analysis, 678 long-term or pitch synthesis ﬁlter, 680 long-term predictor, 679 loop ﬁlter, 446 loosely synchronized  LS  code, 256 LOS, 25 lossless compression, 555, 707 lossy compression, 708 lost call clearing  LCC , 114 lost call hold  LCH , 114 LOT, 538, 721 loudness, 666 low-IF scheme, 5 lowpass ﬁlter prototype, 401 lowpass sampling, 466 LPC, 660, 684 LS-SCORE, 775 LSB, 475 LT  Luby transform  code, 903 LTCC, 375 LU-factorization, 338 luminance, 711 lumped capacitor, 454 lumped inductor, 454 lumped-element technique, 452 LZ77, 563 LZ78, 564 LZSS, 563 LZW coding, 564, 708      978   cid:2   Index  MAC, 26 MAC layer design, 119 MAC protocol, 945 MAC sublayer, 35, 944 macroblock, 735, 739 macrodiversity, 132 magic-T, 396 magnitude difference function  MDF  method, 687 MAHO, 99 majority-logic decoding, 616 man-in-the-middle attack, 938 MANET, 32, 932 MAP algorithm, 630 MAP detector, 185 MAP sequence detection, 161 mapping by set partitioning, 621 MASK, 191 masking phenomenon, 667 matched ﬁlter, 225, 261, 884 matched ﬁltering criterion, 225 max-log-MAP, 635 maximally constrained autocorrelation  MCA , 775 maximally ﬂat ﬁlter, 398 maximum fairness algorithm, 123 maximum-likelihood path, 616 maximum-phase system, 504 Maxwell’s equations, 337 Maxwell–Ampere law, 337 MB-OFDM, 27 MB-OFDM UWB, 891 MC-CDMA, 276, 326 MD algorithm, 940 MDCT, 542 MDHO, 100 MDS, 410 mean opinion score  MOS , 668 medium-earth-orbit  MEO , 21 MELP, 660 MEMS, 358 MEMS phase shifter, 409 MEMS switch, 423 MESFET, 418 mesosphere, 78 message-passing, 645 metal-insulator-metal  MIM  capacitor, 454 method of moments  MoM , 339 Mexican hat wavelet, 531 MFSK, 211 MIC, 451 microcell, 95 microscrip antenna, 357 microwave network analysis, 385 microwave resonator, 390 middleware, 946 midrise quantizer, 471 midtread quantizer, 471 MIME  Multipurpose Internet Mail Extensions   format, 37  MIMO, 15, 301, 757 MIMO beamforming, 835 MIMO channel decomposition, 791 MIMO relay network, 956 MIMO system model, 788  MIMO-CDMA, 838 MIMO-OFDM, 25, 838 MIMO-SC, 837 MIMO-SS, 838 MIMO-UWB, 838 minimum distance, 594 minimum free distance, 618 minimum frequency-shift keying, 213 minimum-norm method, 760 minimum-phase system, 504 MISO, 757 misrouting attack, 938 mixed boundary condition, 338 mixed-multiband excitation  MMBE , 686 mixed-phase system, 504 mixer, 425 ML, 158 ML detection, 186 ML detector, 185 ML estimation, 229 ML receiver, 825 MLSE, 160, 161, 614 MLSE equalizer, 167 MLSR, 249 MLSR or m-sequence, 249 MMDS, 29 MMIC, 375, 451 MMSE, 159 MMSE beamformer, 765, 770 MMSE equalizer, 164 MMSE receiver, 269, 823, 843 MMSE-DFE, 167 mobile broadband wireless access, 18 mobile IP, 101 mobile switching center  MSC , 22 mobile TV, 33 mobile WiMAX, 17 mobile-based location, 125 Mobile-Fi, 18 MobileMan, 121 mobility management, 101 mobility management plane, 945 model-based coding, 660 modiﬁed Bessel function of the ﬁrst kind and zero  order, 57  modiﬁed DFT, 538 modulated lapped transform  MLT , 696 modulation index, 183 modulation recognition, 902 moment-generating function, 237 monopole, 356 Morlet or modiﬁed Gaussian wavelet, 530 MOSFET or MOS FET, 420 mother wavelet, 530 motion compensation, 735 motion estimation, 735 motion estimation with fractional pixel accuracy, 738 motion JPEG, 733 motion vector, 735 MP-MLQ, 678 MP3 ﬁle format, 699 MPAM, 185 MPE model, 689      979   cid:2   Index  MPEG Audio, 699 MPEG-1, 748 MPEG-2 H.262, 748 MPEG-21, 752 MPEG-4, 750 MPEG-4 general audio coding, 702 MPEG-4 T F coder, 702 MPEG-4 VTC, 730 MPEG-7, 752 MPLS  multiprotocol label switching , 122 MPSK, 184, 197 MQAM, 184 MQAM constellation, 219 MRC, 133, 137 MRC beamformer, 765 MSK, 187, 213 MUD, 265 multi-h CPM, 218 multi-rate orthogonal Gold code, 255 multi-user equalization, 266 multiband UWB, 890 multicarrier modulation  MCM , 290 multihop relaying, 940 multimedia content-based description standard, 752 multiple access channel, 102 multiple-symbol MAP detection, 162 multiple-symbol ML detection, 162 multiplying DAC, 484 multipulse LPC, 660 multirate CDMA system, 279 multiresolution analysis, 533 multiresolution analysis equation, 534 multiresolution motion estimation, 738 multisection matching transformer, 389 multistage design, 523 multistage VQ, 662, 678 multistream interference, 819 multiuser diversity, 150 MUSIC, 760 mutual coupling, 362 mutual information, 551, 555 MVDR, 760 MVDR beamformer, 768  N-AMPS, 11 NADC, 12 Nakagami distribution, 58 Nakagami fading, 58 Nash equilibrium, 922 natural sampling, 466 NCO, 5, 517 near ﬁeld or Fresnel zone, 343 near-far effect, 97, 263, 266, 580 near-ML decoding, 624 nearest-neighbor approximation, 187 NEC, 32 NEC-2, 339 negative acknowledgment  NACK , 649 negative-resistance model, 438 network layer, 36, 944 network-based wireless location, 125 network-controlled multimode coder, 694 Neumann boundary condition, 338  neural networks, 406 NMT, 11 Noble identities, 536 noise, 376 noise ﬁgure, 373, 378 noise ﬂoor, 410 non-real-time polling service  nrtPS , 122 nonpersistent CSMA, 111 nonresonant antenna, 349 nonreturn-to-zero  NRZ , 188 notch ﬁlter, 505 NTACS, 11 NTSC  National Television System Committee , 711 NTT, 11 nulling canceling decoder, 821 Nyquist criterion, 173 Nyquist ﬁltering, 173  O&M  operation and management  signaling, 5 object-based coding, 745 OCC, 255 octave band decomposition, 532 oddly-stacked TDAC  OTDAC , 542 OFDM, 15, 106, 290 OFDMA, 17, 106, 323 off or accumulation mode, 420 Okumura-Hata model, 41 Olsen-Segal model, 43 on or inversion mode, 420 on-chip resistor, 453 OOK, 192, 880 open-loop MIMO system, 794 open-loop power control, 98, 264 open-loop transmit diversity, 856 operating system, 946 opportunistic beamforming, 153 opportunistic scheduling, 150 opportunity-driven multiple access  ODMA , 954 optimized link state routing  OLSR , 936 optimum combining, 145 optimum DBPSK, 196 optimum multiuser detector, 267 OQPSK, 13, 204 orthogonal Gold code, 252 orthogonal Hermite pulse, 879 orthogonal prolate spheroidal wave function  PSWF ,  879  orthogonal pulse modulation, 880 orthogonal transmit diversity  OTD , 856 oscillator, 437 OSI reference model, 24, 34 OSIC receiver, 821, 824 OSTBC, 149, 813 outage capacity, 578, 580, 801 outage probability, 58, 116 oversampling, 468 OVSF code, 254  PABX, 13 packet radio, 23, 108 packet switching, 22 packet-reservation multiple access  PRMA , 113 PACS, 13      980   cid:2   Index  PAE, 428 paging, 32 paging channel, 117 pairwise error probability, 811 PAL, 711 PAM, 191, 880 PAPR, 305 parasitic array antennas, 361 Parks-McClellan method, 510 Parseval’s theorem, 495 partial CSI at the transmitter, 794 partial differential equation  PDE , 338 patch antenna, 356 patch antenna with switchable slot  PASS , 358 PCCC, 625 PCM code, 188 PCS, 13 PDC, 12 PDF, 708 PDP, 67 peak factor, 305 peak factor reduction, 306 peaking  comb  ﬁlter, 505 PEAQ, 671 percentage of coverage area, 49 perceptual noise substitution, 702 perceptual noise-shaping ﬁlter, 691 perfect reconstruction, 537 perfectly matched layer  PML , 340 PESQ, 672 phase adjustments method, 307 phase detector, 444 phase noise, 439 phase of arrival  PoA , 125 phase shifter, 408 phase-frequency discriminator, 444 phoneme, 665 PHS, 13 physical channel, 117 physical layer, 35, 944 physical layer design, 118, 119 physical optics, 338 PIC, 266, 271 piconet, 27 pilot channel, 118 pilot-assisted method, 301 PIN diode, 415 PIN switch, 422 pitch, 665 pitch period estimation, 686 pitch picker, 686 planar inverted-F antenna, 351 planar log-spiral antenna, 364 planar UWB antenna, 366 plane earth loss model, 39 PLL, 5, 443 PM, 182 PN diode, 414 PN sequence, 249 POCSAG, 32 Poisson’s distribution, 108 polarization, 346 polarization diversity, 132  polarization-agile antenna, 359 polyphase Barker sequence, 255 polyphase ﬁlter, 522 polyphase Golay complementary sequence, 307 post compression rate distortion  PCRD   optimization, 728  post-beamformer interference canceller, 770 post-image ﬁlter, 521 postﬁlter, 691 potential game, 923 power ampliﬁer, 5 power combining, 433 power control, 98, 263 power delay-angular proﬁle, 72 power divider, 393, 394 power management plane, 945 PPM, 187, 879 preamble-based channel estimation, 793 precoding, 172 predicted-picture  P , 734 prediction gain, 680 predictive coding, 680 predictive VQ, 678 predistortion linearization, 434 presentation layer, 37 Pretty Good Privacy  PGP , 939 principal component analysis  PCA , 683 private key, 939 proactive routing, 935 probabilistic decoder, 628 probabilistic uniform interleaver model, 638 product code, 624, 639 programmable modular communications system   PMCS , 898  progressive encoding, 717 propagation mechanism, 73 proportional fairness scheduling, 123, 151, 856 protocol stack, 34, 944 prototype pitch period  PPP , 695 prototype waveform interpolation  PWI , 686 prototyping, 400 PSD, 189, 192, 196, 200, 247 pseudo-QMF ﬁlter bank, 538, 541 pseudorandom block interleaver, 626 pseudorandom interleaver, 636 pseudospectrum, 760 PSI-CELP, 692 PSK, 184, 195 PSNR, 713 PSTN, 13 psychoacoustics, 665 public key, 939 pulse generator, 884 pulse shaping, 172 pulse time modulation, 190 pulse train, 881 pulsed multiband UWB, 891 pulsed or carrier-free communications, 877 pulsed UWB, 872, 877 punctured convolutional code, 620 pure ALOHA, 108 pure delay-line wideband transmitter beamformer, 783      981   cid:2   Index  PVQ-MA  predictive VQ with moving average , 678 PWM, 190, 432  Q2PSK, 204 QAM, 184, 218 QCELP, 695 QMF, 532, 538, 539 QO-STBC, 815 QoS, 18, 121 QoS model, 942 QoS routing, 936, 942 QPSK, 14, 202 QS-CDMA, 256 quadrature hybrid, 396 quadriphase Barker sequence, 255 quantization, 470, 661, 718, 730 quarter-wave transformer, 389 quasi-Barker sequence, 255 quasi-optical ampliﬁer, 428 quasi-optical power combining, 433  radiation intensity, 343 radiation pattern, 342 radio access technology  RAT , 19 RadioCom, 12 radix-4 FFT, 499 rain fading, 80 raised-cosine ﬁltering, 173 rake receiver, 260, 887 random FM, 55 random multiple access, 108 rank and determinant criteria, 811 rank and trace criteria, 812 rate control, 746 rate-distortion function, 565 rate-distortion theorem, 565 ray-tracing, 46 Rayleigh criterion, 76 Rayleigh distribution, 50 Rayleigh fading, 50, 232 Rayleigh-Jean approximation, 376 RCELP, 691 RCPC code, 621 RDS, 32 reactive routing, 936 real-time polling service  rtPS , 122 receive beamforming, 758 receive correlation, 789 receiver cooperation, 958 reciprocity principle, 794 reconﬁgurable microstrip antennas, 358 rectangular window, 495 REEP  Reliable and Energy Efﬁcient Protocol , 950 reference frequency, 445 reﬂection, 73 reﬂection coefﬁcient, 381 reﬂection coefﬁcient  RC , 676 reﬂection-type phase shifter, 409 refraction, 73 regular LDPC code, 642 reinforcement learning, 921 relaxation oscillator, 443 relay, 952  RELP, 660 Remez exchange algorithm, 509 repeated game, 923 resonant antenna, 349 resonator-based oscillator, 441 resource reservation protocol  RSVP , 122 resource-allocation technique, 122 return loss  RL , 382 return-to-zero  RZ , 188 reuse distance, 92 reverse channel, 102 reverse water-ﬁlling, 567 reversible color transform, 729 reversible variable-length code, 558 RF CMOS, 455 RF microwave ﬁlter, 397 RFID, 28, 33 RHCP, 346 Rice distribution, 56 Ricean channel, 808 Ricean fading, 56, 235 Richard’s transformation, 402 ring oscillator, 442 ringing effect, 660 RLC resonant circuit, 390 RLE, 555 RLS, 159 RLS algorithm, 515 ROC, 493 Rollett’s stability factor, 436 root raised-cosine ﬁltering, 175 round-robin scheduler, 856 round-robin scheduling  polling , 113 routing, 935, 949 routing hole, 942 routing protocol, 36 routing table poisoning, 938 RPE model, 689 RPE-LTP, 689 RS code, 301, 604 RS-Viterbi code, 607 RSA  Rivest-Shamir-Adleman  algorithm, 939 RSSI, 99 RSSI positioning, 123 RTMS, 12 RTP, 36 rumor routing, 951 Rumsey’s principle, 364 run-length property, 250 rural area  RA   non-hilly , 68 rushing attack, 938  S-DMB  Satellite-DMB , 33 S H operation, 464 SA-DCT, 731, 744 SA-DWT, 731 Saleh-Valenzuela model, 45, 873, 874 sample rate converter, 525 sampling, 464 sampling theorem, 466 sampling-rate conversion, 520 SAR ADC, 480 satellite-based positioning, 125      982   cid:2   Index  SAW, 4 SAW ﬁlter, 408 SC-FDMA, 17 scalability, 742 scalable coding, 752 scalar quantization, 661 scaling function, 533 scattered-type pilot arrangement, 302 scattering, 75 scattering matrix, 386 SCCC, 639 scheduling access, 113 Schottky diode, 416 Schottky junction, 416 SCORE, 1 scrambling, 247 SDMA, 17, 106, 757 SDR, 5 SECAM, 711 security, 936, 947 SEGSNR, 670 selection diversity, 134 selective-repeat ARQ, 650 self-complementary toothed log-periodic antenna, 364 self-mixing phenomenon, 7 self-structuring antenna, 365 semi-blind algorithm, 774 semiblind, 160, 840 sensitivity, 373 Sensor-MAC  S-MAC , 946 SEP, 162, 186 sequential decoding, 615 sequential encoding, 716 serial concatenated block code, 624, 639 session layer, 36 SF-OFDM, 839 SFBC, 840 SFDR, 413, 477 SFIR, 757 Shannon bound, 569 Shannon-Fano coding, 556 shape coding, 744 shape function, 338 Shared Wireless Access Protocol  SWAP , 26 shift-and-add property, 250 short code, 248 short-term or formant synthesis ﬁlter, 680 short-term predictor, 679 short-time Fourier transform, 663 shot noise, 377 SIC, 266, 270 SIC receiver, 824 SICM, 620 sigma-delta ADC, 481 sigma-delta modulator, 481 signal ﬂow graph, 387 signal shaping, 172 signal space diagram, 184 signal-to-interference ratio  SIR , 648 signal-to-jitter-noise ratio  SJNR , 477 silence descriptor  SID , 683 SIMO, 160, 757 simple concatenated code, 622  simple parity check code, 595 SINAD ratio, 475 single-ended diode mixer, 427 single-ended FET mixer, 427 single-user lower bound  SULB , 850 SINR, 145 sinusoidal transform coding, 686 SISO, 277, 959 SISO decoder, 628 skin effect, 381 sleep deprivation, 938 sleeve antenna, 350 slice, 740 slotted ALOHA, 108 slow fading, 48 slow frequency hopping, 282 small set of Kasami sequences, 253 smart antenna, 96, 757 smart radio, 901 Smith chart, 383 SMV, 695 SNDR, 309 Snell’s laws, 74 SNR scalability, 743 soft decision decoding, 599 soft handoff, 100, 264 software-deﬁned radio, 18, 898 SOI, 757 solid-state microwave source, 440 solid-state power ampliﬁer, 435 sound intensity, 666 sound pressure level  SPL , 666 source input format  SIF , 734 source-channel coding theorem, 575 source-channel separation theorem, 575 source-coding theorem, 556 SOVA, 629 space-time coding, 809 space-time processing, 841 space-time processing model, 842 space-time receiver, 822 spatial and SNR scalability, 728 spatial coherence, 71 spatial correlation, 362, 789 spatial diversity, 130 spatial diversity combining, 763 spatial ﬁltering, 763 spatial multiplexing, 819 spatial multiplexing gain, 830 spatial power combining, 433 spatial scalability, 743 spatial Tomlinson-Harashima precoding, 828 spatial-temporal signature, 841 spectral cross-correlation  or conjugate  cross-correlation  coefﬁcient, 777  spectral growth, 306 spectral self-coherence  or conjugate self-coherence   coefﬁcient, 777  spectral spreading, 246 spectrogram, 663 spectrum awareness, 903 spectrum cyclic density  SCD , 777 spectrum sensing, 905      983   cid:2   Index  spectrum shaping, 298 spectrum-agile radio, 901 speech production, 663 speech production modeling, 664 speech audio quality, 668 Speex, 692 sphere decoding algorithm, 168, 825 SPIHT algorithm, 725 SPIN, 950 spiral antenna, 365 split VQ, 678 spreading sequence, 248 sprite coding, 745 SQNR, 471 square-law combining, 133 squaring loop, 228 SS7, 22, 23 SSB AM, 181 SSB modulation, 426 SSL  Secure Sockets Layer , 37 SSMA, 105 ST pre-rake, 838 ST-MF, 846 ST-ML receiver, 838 ST-MMSE receiver, 838 ST-MUD, 844 ST-MUD algorithm I, 847 ST-MUD algorithm II, 847 ST-MUD algorithm III, 847 ST-OFDM, 839 ST-rake, 838 stability, 436, 502 stack algorithm, 615 stack-bucket algorithm, 615 staircase reconstructor, 474 STBC, 25, 301, 810 STDO code, 841 STDO diversity, 841 step-recovery or snap diode, 417 stepped-impedance  Hi-Z-low-Z  lowpass ﬁlter, 402 STF-OFDM, 839 stop-and-go ARQ, 649 stratosphere, 78 STS, 856 STTC, 301, 810, 817 STTD, 856 stub ﬁlter, 401 stub tuners, 388 sub-band, 290 sub-band coding, 538 sub-band decomposition, 721 sub-band-split ADPCM  SB-ADPCM , 696 subcarrier, 290 suboptimum DBPSK, 197 subthreshold or weak inversion region, 420 suburban  SU , 82 successive approximation, 728 SUI channel models, 47 sum of absolute differences or errors  SAD or SAE ,  sum of squared differences or errors  SSD or SSE ,  736  736  sum-product algorithm, 645  Sunde’s FSK, 208 super-audio CD, 698 super-heterodyne transceiver, 4 survivor path, 614 Suzuki model, 58 SVD precoding, 826 Switch, 422 switch diversity, 145 switch-and-stay strategy, 145 switch-mode ampliﬁer, 432 switched-beam antenna array, 765 switched-line phase shifter, 409 switching diversity with feedback, 145 switching or secondary picture  S-picture , 751 Sybil attack, 938 symbol timing recovery, 228 symbol-by-symbol MAP detector, 162 symbol-by-symbol ML detection, 162 symbol-rate processing, 899 symmetric key encryption, 939 synchronization, 263, 314 syndrome decoding, 596 synthesis bank, 536 system-on-chip  SOC , 375 system-on-package  SOP , 375 systematic code, 593, 611 systolic architecture, 530  T-DMB, 33 TACS, 11 tail bit, 615 Tanner graph, 643 tapped-delay-line fading model, 874 tapped-delay-line structure, 782 TAS MRC scheme, 829 task management plane, 945 TCM, 621 TCP, 36, 944 TD-LAS  Large-Area-Synchronous  CDMA, 256 TD-SCDMA, 16 TDAC, 542 TDD, 103 TDMA, 4, 12, 104 TDoA positioning, 123 TDRSS, 252 TEM wave, 343 temporal coherence, 70 temporal diversity, 131 temporal masking, 667 temporal scalability, 743 temporal spreading, 246 terminated trellis, 616 TH, 246 TH-CDMA, 106 TH-UWB, 872 TH-UWB signal, 882 thermal noise, 376 thermosphere, 78 third-order intercept point  IP3 , 411 three-port network  T-junction , 393 three-step search  TSS , 738 THSS, 872 TIFF  Tagged Image File Format , 564      984   cid:2   Index  tiling, 729 time-selective fading, 60 time-selective spread, 60 timing offset, 318 timing synchronization, 320 TinyDB, 946 TinyOS, 946 TinySec, 947 TLS  Transport Layer Security , 37 ToA positioning, 123 Tomlinson-Harashima precoding, 172 total electron content  TEC , 81 tracking or ﬁne synchronization, 318 trafﬁc channel, 118 training-based beamforming, 770 transform coding, 696 transform-domain weighted interleave vector  quantization  TwinVQ , 702  transistor, 417 transmission line, 380 transmission line resonator, 391 transmission matrix, 387 transmit beamforming, 758 transmit correlation, 789 transmit diversity, 148, 954 transmit diversity combining, 758 transmit power control, 901 transmit selection diversity, 150 transmit receive switch, 374 transmitter cooperation, 958 transmitter-and-receiver cooperation, 958 transport channel, 117 transport layer, 36, 944 traveling wave ampliﬁer, 437 traveling wave tube, 434 traveling-wave-tube ampliﬁer, 435 tree decoder, 613 trellis decoder, 613 trellis decoding, 617 trellis diagram, 612 troposphere, 78 tropospheric effects, 79 trunking efﬁciency, 115 turbo cliff region, 635 turbo code, 625 turbo decoder, 627 turbo decoding principle, 639 turbo encoder, 625 turbo trellis coded modulation  turbo-TCM , 622 two-dimensional  2-D  DCT, 529 two-dimensional logarithmic search, 738 type-I  star  QAM constellation, 219 type-I Chebyshev ﬁlter, 399 type-I HARQ, 651 type-II Chebyshev ﬁlter, 399 type-II HARQ, 651 type-II QAM constellation, 219 type-III  square  QAM constellation, 219 typical hilly terrain  HT , 68 typical urban  TU , 68, 82  UD factorization, 516 UDP, 36, 944  UMB, 17 UMTS, 14 uncorrelated scatters, 66 unequal error protecting code, 639 uniform circular array, 360 uniform linear array, 360 uniform PCM, 471 uniform planar array, 360 uniform quantization, 470 uniform theory of diffraction  UTD , 46, 338 universal multimedia access, 752 unsolicited grant service  UGS , 122 UPE, 815 UQ-DZ, 716 user cooperation, 954 user location, 123 UTRA, 14 UTRA-TDD, 16 UWB, 19, 27, 126 UWB antenna, 364, 366 UWB capacity, 876 UWB indoor channel model, 873 UWC-136, 16  V-BLAST, 822 varactor, 454 variable multi-rate wideband  VMR-WB , 697 variable voltage-controlled attenuator, 450 variable-bit-rate  VBR  CELP, 695 variable-length code, 557, 559 VCO, 7, 445 vector excitation coding  VXC , 702 vector network analyzer, 387 vector radix FFT, 499 very-low-bit-rate coding, 685 VGA, 450 video decoder, 740 video encoder, 740 video transcoding, 752 virtual carrier, 302 visitor location register  VLR , 22 visually lossless compression, 710 Viterbi algorithm, 168, 885 Viterbi decoding, 614 Viterbi equalizer, 168 VO, 745 vocoder, 660 voice activity detection, 683 VoIP, 672 voltage-controlled clock  VCC , 229 VOP, 745 VQ, 472, 661, 662 VSELP, 660, 692 VSWR, 382  wakeup on demand, 945 Walﬁsch-Bertoni model, 44 Walsh or Walsh-Hadamard code, 253 WAN, 23 water-ﬁlling, 324, 571, 915 waveform coding, 659 waveguide cavity, 393 wavelet analysis, 533      985   cid:2   Index  wavelet ﬁlter design, 722 wavelet packet analysis, 533 wavelet transform, 530, 721 wavelet-based motion compensation, 738 wavetable synthesis, 520 WCDMA, 14, 279 Weber’s law, 710 weight enumeration analysis, 637 weight enumeration function  WEF , 638 Welch lower bound, 253 Welch-bounded sequence, 275 WEP  Wired Equivalent Privacy , 939 whip antenna, 350 Wi-Fi, 25 WiBro, 19 wide sense stationary, 66 wideband antennas, 364 wideband beamforming, 782 wideband CELP, 697 wideband speech coding, 696 Wiener estimation, 513 Wiener ﬁlter, 515 Wiener-Khinchine theorem, 189 Wilkinson power divider, 394 Wilkinson power splitter combiner, 433 WiMAX, 28 WiMedia, 27 window method, 508 windowing, 495 wireless ad hoc network, 932 wireless BAN, 26, 45, 367 wireless LAN, 24, 25 wireless local loop  WLL , 13 wireless MAN, 17, 28  wireless PAN, 24, 26 wireless RAN, 24, 29 Wireless USB, 27 wireless WAN, 24 Wold decomposition, 684 wormhole attack, 937 WPA  Wi-Fi Protected Access , 939 writing on dirty paper, 826 WSN, 34, 932 WSSUS model, 65, 66 Wyner-Ziv cooperation, 953  XPD, 347  YCbCr, 711 YCbCr sampling, 712 Yule-Walker approximation, 513 YUV, 711  Zadoff-Chu code, 327, 328 ZCR, 63, 136 zero correlation zone  ZCZ , 256 zero-order Bessel function of the ﬁrst kind, 61 zero-outage capacity, 579 zero-padded OFDM, 296 ZF beamformer, 764 ZF equalizer, 163 ZF receiver, 823, 842 ZF-DFE, 167 zigzag scan, 720, 740 zinc-basis function excitation  ZFE  waveform, 686 ZMCSCG variable, 789 zone routing protocol  ZRP , 936

@highlight

This practically-oriented, all-inclusive guide covers all the major enabling techniques for current and next-generation cellular communications and wireless networking systems. Technologies covered include CDMA, OFDM, UWB, turbo and LDPC coding, smart antennas, wireless ad hoc and sensor networks, MIMO, and cognitive radios, providing readers with everything they need to master wireless systems design in a single volume. Uniquely, a detailed introduction to the properties, design, and selection of RF subsystems and antennas is provided, giving readers a clear overview of the whole wireless system. It is also the first textbook to include a complete introduction to speech coders and video coders used in wireless systems. Richly illustrated with over 400 figures, and with a unique emphasis on practical and state-of-the-art techniques in system design, rather than on the mathematical foundations, this book is ideal for graduate students and researchers in wireless communications, as well as for wireless and telecom engineers