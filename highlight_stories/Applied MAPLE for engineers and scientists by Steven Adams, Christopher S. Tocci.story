Applied Maple for  Engineers and Scientists   Applied Maple for  Engineers and Scientists  Chris Tocci   Steve Adams  Artech House  Boston   London   Library of Congress Cataloging-in-Publication Data Tocci, Christopher.  Applied Maple for engineers and scientists   Chris Tocci and Steve Adams.  p.  cm.  Includes bibliographical references and index. ISBN 0-89006-853-4  alk. paper  1. Engineering mathematics—Data processing.  Mathematics—Data processing. 1959– TA345.T63 1996 620’.00285’53—dc20  II. Title.  .  96-19492 CIP  2. Science—  3. Maple  Computer ﬁle   I. Adams, Stephen,  British Library Cataloguing in Publication Data Tocci, Chris  Appled Maple for engineers and scientists 1. Maple  Computer program  2. Algebra—Computer programs 3. Engineering mathematics—Computer programs I. Title II. Adams, Steve, 1959– 620’.00285’5369  ISBN 0-89006-853-4  Cover and text design by Darrell Judd    1996 ARTECH HOUSE, INC. 685 Canton Street Norwood, MA 02062 All rights reserved. Printed and bound in the United States of America. No part of this book may be reproduced or utilized in any form or by any means, electronic or me- chanical, including photocopying, recording, or by any information storage and re- trieval system, without permission in writing from the publisher.  All terms mentioned in this book that are known to be trademarks or service marks  have been appropriately capitalized. Artech House cannot attest to the accuracy of this information. Use of a term in this book should not be regarded as aﬀecting the validity of any trademark or service mark.  International Standard Book Number: 0-89006-853-4 Library of Congress Catalog Card Number: 96-19492  10 9 8 7 6 5 4 3 2 1   To my wife, Mercedes, my dad, Anthony, and the ‘leggy’ Woolﬁe C.T.  To my long suﬀering wife, Fiona, and my daughter, Sophie, who will have to leer at this stuﬀ  S.A.   Applied Maple for Engineers and Scientists  Contents  Foreword 1  Preface 1 Motive for using this book 1 Who needs to use this book 2 Purpose of the book 2 Philosophy of the book 2 Chapter structure and order 2  Chapter 1 Introduction 1  What is a CAS ? 2  Numbers 2 Symbols 3  More about Maple 5 Maple: a tutorial 5  Help 6 Maple as a calculator 9 Maple as a programmable calculator 27  Chapter 2 Active filter design and analysis 39 Case I: analog low-pass ﬁlter design and analysis 40  Use of Laplace transform explained 41 Constituent relationships derived 41 Designing a 1-kHz Butterworth LPF 47 Bode magnitude and phase plots 49 Improvement on the 1-kHz Butterworth LPF 53  vii   Applied Maple for Engineers and Scientists  Butterworth LPF component  sensitivity analysis 55  Unequal resistance values in the Butterworth  LPF topology 57  Butterworth LPF test setup 60 Design iteration of LPFs for newer ﬁltering  requirements 64  Unit step response 68 Conclusion 70  Case II: comb ﬁlter analysis and design 71  Filter derivation and analysis 72 Separating a known signal from an interfering  neighboring background design 81  Cascading comb ﬁlters 87 Conclusion 91  Chapter 3 Curve fitting 93  Introduction 93 Case study: Gaussian peak estimator ﬁlter example with regressive curve ﬁtting 95  Starting the Maple regression session 96 Linear regression using a logarithmic representation of the Gaussian model 96 Problem data set for linear regression 111 Nonlinear regression:  the Levenberg-Marquardt algorithm 115  General polynomial regression 121 High-order polynomial regression ﬁt  problems 126  Quick moral about curve ﬁtting 131 Conclusion 132  viii  Chapter 4 Mathematical models: working with differential equations 133  ODE tools: a tour 134  The dsolve function 134 The DEtools package 137 The diﬀorms package 143  Series methods 144 Modeling dynamic systems 152  A simple shock absorber 152 A twin mass shock absorber 158 A nonlinear system 166  Chapter 5 Continuous control application theory 173  Linear control system analysis 173 Frequency-domain approach 175  Partial fraction expansion 179  Time-domain approach 194  Time-invariant versus time-variant systems 194 Analysis of a time-invariant system: fundamentals 195 The state transition matrix 200  Conclusion 210  Chapter 6 Discrete control applications 213  The pulse transfer function 215  Transforming continuous signals 216 Calculating the time response 234  State space equations and their canonical forms 242   Contents  Transfer function to state space  the controllable canonical form  242 Observable canonical form 247  Chapter 7 Discrete data processing 249  Chapter 8 Switching topologies 301  Steady-state method 302  Pulse width modulator driver 302 Switching power supply 316  Fourier method 330  Maple plots 249 The plot structure 250 Image conversion 252  Togreyscale 260 Normalize 263 Tofalsecolor 269 Conclusion 272 Linear ﬁlters 273 Diﬀerencing 273 Moving average 276 Moving median 282 Exponential ﬁltering 288  Conclusion 296  Appendix A 345  Appendix B 351  Glossary 357  About the authors 391  Index 393  ix   Applied Maple for Engineers and Scientists  Foreword  About 7 years ago, after some 35 years as a computational physi-  cist, I opened up my ﬁrst version of the computer algebra system  CAS , Maple IV. Maple seemed to be an answer to my need for an error-free and fast system to derive long involved algebra and calculus solu- tions. My delight turned to a somber realization that Maple did not replace all the mathematical and applied mathematical skills that I had developed. I still had to think like a computational physicist and to learn how to use Maple as a tool to extend my capabilities to achieve solutions more quickly and with greater accuracy. Maple is not a mathematician in a box!  My usual approach to solving, numerically, physics  and electrical en-  gineering  problems using computers involved developing a sequence of models:  Physics ﬁ Mathematical ﬁ Numerical Analytical ﬁ  Software ﬁ Computer  xi   Applied Maple for Engineers and Scientists  Each of these models represents an approximation to the actual physi- cal process. In fact, the above chain represented the setting up of the prob- lem for a solution. The actual running of the solution on a computer was the trivial part. When I started to use Maple IV to develop ﬁrst  the mathe- matical  and then the software model, I realized I would have to learn a new language to eﬀectively use this tool. I had to rethink the way I solved the problem of a mathematical representation of the physics or engineering process I was trying to solve. However, I had no guide, no handbook, no Morse and Feshbach  Methods of Theoretical Physics , the bible for mathe- matical physicists of my generation! So, I had to learn by trying, by experi- menting. It was a long and diﬃcult process, especially since Maple was continuously being improved and its capabilities extended. After several years, I am still not ﬁnished with this process.  However, Steve Adams and Chris Tocci have made the road much  smoother and more level with this book, Applied Maple for Engineers and Scientists. Set around Maple V, Release 4—the latest version of this software—they show how to solve a variety of problems using Maple as the principal tool. Ranging from linear active ﬁlters through curve ﬁtting to ODEs, they show how to set up the problem using Maple. Most impor- tantly, even if none of the applications covered in the book is germane to the reader’s speciﬁc problems, Adams and Tocci demonstrate how an engi- neer or scientist should to think about a problem when using Maple as a tool.  The authors do not leave the reader hanging if they are not already  proﬁcient in Maple—they include a tutorial on Maple V, Release 4, which contains the principal features of this system. Of equal importance is the discussion of the physics or engineering processes and of the important mathematical functions used in each example. These discussions, plus the plotting of the solutions using the Maple graphic engine, are critical ele- ments in making this book an almost-self-contained reference and teaching text.  Thomas N. Casselman Casselman Computational Consultants  C3  Dublin, CA July 1996  xii   Applied Maple for Engineers and Scientists  Preface  Motive for using this book  Maple is one of the most powerful mathematics computer alge-  bra systems or computer algebra system  CAS  packages on the market today. Considering today’s economic realities, it makes  perfect sense that an initial indepth computer analysis of a quantitative problem could save many person-hours and material resource costs, hence making you and your organization more competitive. Applied Maple for Engineers and Scientists will get readers thinking about their speciﬁc prob- lems by using what the authors call “template” application case studies.  xiii   Applied Maple for Engineers and Scientists  Who needs to use this book The more timely and accurate a professional needs to be about his or her decisions, the more proﬁcient that professional needs to be with a Ma- ple-type software package. Maple aﬀords modern professionals the ability to visualize the dynamics via Maple’s graphics. For students, Maple pro- vides valuable insight into the underlying dynamics, which, in turn, im- parts an important understanding of the process under study not evident before the advent of CAS tools. In previous years, both students and pro- fessionals had to wait hours for batch loading and, later, dumb terminal- type centralized computers to perform what Maple can do very quickly today on the omnipresent PC, PowerPC, or UNIX workstation platforms.  Purpose of the book Applied Maple for Engineers and Scientists was written with the purpose of creating template applications for student and practicing technical  busi- ness professionals. Templating serves the reader and authors by showing diﬀerent examples on how the Maple symbolic and numerical mathematics system can be generally used in solving a very wide range of everyday quan- titative problems. Even though the reader may never need a single one of the speciﬁc examples discussed, the concepts, syntax, and approaches shown to problem solving with Maple can be extremely helpful in getting the user up and running quickly in his or her particular problem area.  Philosophy of the book The text is geared toward technical professionals and students who have an understanding of the technical principles of their respective ﬁelds, but are not cognizant of how a CAS software package such as Maple can be used to facilitate timely and understandable solutions. In no way do the authors pretend that this is a text on any of the engineering, scientiﬁc, or quantitative business disciplines described during any template session. There are references given, as needed, in the individual chapters if the reader is interested in more advanced aspects of the particular application.  Chapter structure and order The chapters have no particular order and this was done by choice. Each chapter is fairly “stand alone” in its content and oﬀers the reader a rein- forcement of software approaches that should become apparent as one wan- ders among the diﬀerent applications. This reinforcement is both within each application and throughout all of them in the form of reiteration of command lines and trying to stay to the more common syntax approaches  xiv   Preface   though at times not the most elegant  used by the Maple engine. Eﬀorts to minimize “exotic” or “highly eﬃcient” hard-to-comprehend coding will keep the reader on-track with the fundamental usage of the Maple lan- guage. This thinking, we believe, will give the new Maple user a more ro- bust ability to develop work sessions more quickly and accurately. Obviously, in time, the user will develop his or her own personal syntax forms and approaches to problem solving with the Maple engine. For this reason also, the authors wanted to minimize their syntax coding “ﬁnger- print” among the applications by keeping the syntax methods very general.  The text contains the following chapters:  Chapter 1: Introduction  Adams  An explanation is given of what a computer algebra system is and how Ma- ple fulﬁlls the requirements of a CAS. A brief tutorial is given to get the nov- ice Maple user up and running along with a description of Maple’s online help ﬁle system.  Chapter 2: Active filter design and analysis  Tocci  A detailed analysis and design approach is discussed that deals with com- mon active ﬁlter circuits. In particular, two separate types of ﬁlters are dealt with in this chapter. The ﬁrst part describes the continuous Butterworth low-pass ﬁlter, and the second deals with a switching or sampled data approach to bandpass ﬁltering using charge-coupled device  CCD  technology.  Chapter 3: Curve fitting  Tocci  One of the most common functions performed by statistical packages is curve ﬁtting of raw experimental data. Maple has a very strong curve-ﬁtting capability and the ﬁrst example used is derived from a real-world situation of peak detection associated with a spectrophotometer. The chapter also gives data sets that can cause severe problems for conventional curve-ﬁtting programs and shows how a Maple nonlinear regression program can ob- tain a reasonable result. Finally, the chapter gives a vivid example of how badly “blind” curve ﬁtting can “lie” if the user is not aware of what he or she is doing when arbitrarily assigning a high-order polynomial to the vari- able set.  Chapter 4: Mathematical models: working with differential equations  Adams  Chapter 4 gets into one of the fundamental aspects of the Maple program, namely, ordinary diﬀerential equations. The chapter gives several basic  xv   Applied Maple for Engineers and Scientists  template applications on Maple’s capability to analyze the dynamic behav- ior of real rotational and translational mechanical systems.  Chapter 5: Continuous control application and theory  Tocci  Chapter 5 describes the basic applied principles of how Maple is applied in continuous control systems. Two approaches are examined, namely, fre- quency  Laplace  and time  state space  domains. For purposes of compari- son, a real-world third-order template controller problem is solved using both approaches.  Chapter 6: Discrete control applications  Adams  Chapter 6 delves into template applications associated with both the pulse and Z-transform methods and comparatively with the discrete time state space techniques for discrete control design and analysis.  Chapter 7: Discrete data processing  Adams  Chapter 7 describes some basic digital signal processing associated with 1-D and 2-D information. The concept of image conversion is described and exempliﬁed as are several approaches using classical linear digital FIR and IIR ﬁlters.  Chapter 8: Switching topologies  Tocci  Chapter 8 shows the reader how Maple can solve rather complex boundary problems associated with periodic signals. One of the most common appli- cations of this analysis is used on a buck-type switching power supply. An associated template application depicts how Maple is used in solving and describing the dynamics involved with a pulse-width modulator  PWM  used for signal acquisition.  As the reader can see, the applications areas are very diverse  ﬁlter,  control, data manipulation, and signal and systems applications  and basic  both continuous and discrete systems  in their importance to most engi- neering and applied science disciplines. Consequently, the reader can jump into any chapter to abstract whatever information is needed to solve their particular problem with Maple. Chapter 1 is for those who are unfa- miliar with Maple and should be looked over and studied. However, if you are an experienced Maple user, you should ﬁnd the application tem- plates useful for any unfamiliar engineering-type problem you encounter. The authors would like to acknowledge the following individuals for  assistance during the development of this manuscript: The technical staﬀ at Waterloo Maple Software, speciﬁcally, Drs. Stan Devitt, Jerome Lang,  xvi   Preface  Tom Lee, and David Pintur for their help during the developmental phases of release 4 and the preparation of the manuscript. The editorial staﬀ at Artech House and particularly Theron Shreve and Kimberly Collignon for their “polite” approach to helping the authors stay fairly timely in the diﬀer- ent stages of manuscript production and delivery.  xvii   Applied Maple for Engineers and Scientists  Chapter1  Introduction  In 1969 the Laboratory of Computer Science at the Massachusetts  Institute of Technology released what is regarded as the first commer- cial computer algebra system  CAS , Macsyma. Since then the number  of computer algebra systems available has grown to include Derive, Re- duce, Theorist, Mathematica, Maple, and others. In this book we will be looking at Maple and how it can be used to help engineers and scientists investigate a diverse set of problems numerically, symbolically, and graphi- cally. The major emphasis of this book is applications and how to eﬀec- tively use Maple as an analysis tool.  The ﬁrst chapter is both a demonstration and a tutorial that shows how Maple functions as a numerical and symbolic calculator, a powerful visuali- zation tool, and a programming language. It is the only portion of the book in which the Maple syntax is discussed for its own sake. Of course, syntax is discussed elsewhere but only as part of the general discussion surround- ing the application being considered. If you are already comfortable with the Maple system, feel free to skip this chapter. We would, however, sug-  1   Applied Maple for Engineers and Scientists  What is a CAS ?  gest that even the most advanced users should give this ﬁrst chapter a cursory glance as a means of introducing the authors’ style. Chapters 2 through 8 concentrate on how to apply Maple to problems in the areas of analog and discrete control theory, analog and digital ﬁltering, ordinary diﬀerential equations, power supply design, and curve ﬁtting to data.  A computer algebra system is just a calculator that does mathematics, but unlike a conventional calculator it does more than just manipulate ﬂoating- point numbers. A CAS can perform numerical computations using either exact or ﬂoating-point arithmetic, and it can manipulate symbolic quanti- ties and display both functions and data graphically. Some, but not all, CASs are also sophisticated programming environments ideally suited for the representation and manipulation of mathematical quantities and objects.  Numbers The majority of modern CASs are not limited to the number of signiﬁcant digits set by the ﬂoating-point hardware so they are capable of providing solutions that are exact or to a user-speciﬁed level of precision. Maple sup- ports arbitrary precision arithmetic, which means that it is capable of stor- ing and using numbers having in excess of 500,000 digits. This is in stark contrast to a normal calculator or spreadsheet that can only support 10 dig- its. Here we calculate the product of the cubes of the ﬁrst 40 odd numbers, 39   2i + 1 3:  I = 0  w product  2*x+1 ^3, x=0..39 ;  507748306245828599556221571230208944802988775653262 350807652219192332706057011255827529763014747456 4870095938232290016243558763746110353766146334154 13352736271917819976806640625  This returns the ﬂoating-point approximation.  2   cid:213   Introduction  w evalf product  2*x+1 ^3, x=0..39  ;  .5077483062 10 177  In the preceding example we have used Maple to calculate a large inte- ger both exactly and approximately, Maple can also represent other mathe- matical quantities exactly:  cid:214  , e, etc. The advantage of being able to manipulate exact quantities is demonstrated below:  ‘ 2 , 1⁄3, g , p  w 1 3 * 3;  w ANS:=evalf 1 3 ;  w ANS * 3;  1  ANS := .3333333333  .9999999999  It is obvious that these results are not equal. This is because the  second expression is merely an approximation of the ﬁrst exact expression. Regardless of how many signiﬁcant digits are used, the second expression will never be equal to the ﬁrst. Although this is a trivial example it is not diﬃcult to imagine a case where such a simple error would be unacceptable.  Symbols A symbol can just as easily represent a known quantity such as p , e, or g as it can an unknown one such as x. The ability to deﬁne and manipulate sym- bolic quantities is where the true power of a CAS such as Maple lies. We can deﬁne mathematical formulas symbolically, operate on them, and then substitute for known values when appropriate. For example, take the ex- pression for compound interest,  interest = principal  cid:215  time  cid:215  rate  100  3  ‘  Applied Maple for Engineers and Scientists  Once we have entered this in our current CAS session, we can manipu-  late it to make the subject of the expression time and hence calculate the time necessary to accrue a target amount of interest given a certain rate and principal. The following is how we would tackle this using Maple. If the syntax does not immediately make sense, do not worry because we will cover it shortly. First we deﬁne the equation relating the amount of interest to the amount of principal, the time, and the prevailing interest rate.  w EQN:= i = p*t*r 100;  EQN := i = 1 100  ptr  In this particular instance we will make time the object of the equation.  We do this with the isolate function. This function is one of many Maple functions that is readlib deﬁned, which means that although it is part of the Maple library the function is not part of the main package and must be loaded explicitly using readlib as shown.  w EQN1:=readlib isolate  EQN, t ;  EQN1 := t = 100  i pr  w subs i=5004 10, p=1000, r=51 5, EQN1 ;  t = 417 85  Here are two more examples of symbolic computation: deﬁning the  volume of a sphere in terms of the radius r and obtaining the Mellin trans- form of the expression ln y e -3y^2 .  w volume_of_a_sphere :=  4*Pi*r^3  3;  volume_of_a_sphere := 4 3  p r3  4   More about Maple  Introduction  w with inttrans,[mellin] :  mellin ln y *exp -3*y^2 , y, s ;   1⁄2 s   - 1 4  1 3  ln 3  G  1 2  s  + 1 4  1 3   1⁄2 s   1 2  s  1 2  s  Maple Vr4 is a comprehensive CAS that can perform numerical, symbolic, and graphical computations on PCs  DOS, Windows, Mac, Amiga, etc.  and workstations  Apollo, HP, Sun, DEC, etc. . It is an interactive, easy-to- use system comprising more than 2500 functions that can be used either on its own or in conjunction with many commonly used numerical analysis and oﬃce applications. It is also its own programming language: 95% of Maple Vr4 is written in Maple, which means that its scope is essentially limitless. If an application area is not initially supported, Maple is quickly extended through the addition of new functions and procedures. It is there- fore hardly surprising that Maple is the ﬁrst choice for many mathemati- cians, engineers, scientists, educators, and others who need an easy-to-use environment in which to perform mathematics.  Maple was ﬁrst conceived late in 1980 at the University of Waterloo as a research project. Since then it has steadily grown to become the largest, most robustly tested general mathematical software system currently avail- able. It consists of three distinct parts: the kernel, the library, and the work- sheet. The worksheet, with its typeset mathematics, text, and graphics support is a natural medium for entering and manipulating mathematical expressions, models, prototypes, and test data. The kernel, which is writ- ten in C, contains the system core functions and accounts for approxi- mately 5% of the Maple Vr4 system. The library, on the other hand, is where the majority of the system resides. Functions held in the library are written in Maple and are user accessible.  Maple: a tutorial  The goal of this tutorial is twofold: First, it introduces you to the Maple syntax and, second, it gives you a quick tour of Maple itself. We should, at this point, reiterate that this tutorial gives only the briefest of introductions to the Maple syntax and may be skipped by the experienced user.  5   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł Y  cid:230   cid:231  Ł  cid:246   cid:247  ł G  cid:230   cid:231  Ł  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  Help Maple’s Help database consists of more than 8 MB of data organized into manual style pages containing examples and hypertext links. Every page has the same basic format: Function, Calling Sequence, Parameters, De- scription, Arguments, Examples, and See Also sections. Sections contain- ing pointers to additional information, for example, the See Also section, contain hyperlinks to other Help pages. This wealth of information is searchable in a variety of ways via the Help menu or the Worksheet—con- tents, topic keyword, or full-text searches from the menu—and the manual pages and hypertext links are directly accessible from the Worksheet. If we access Maple’s Help system from the Help menu we do so via dialog boxes, whereas when using the Worksheet we can use the either the ques- tion mark notation  ?, ??, and ???  or the help function. Either method of accessing the help system will result in a Help Worksheet being dis- played for the topic or keyword used in the search if a match is found. Be- cause the entries in the Help menu are self-explanatory, we will concentrate on how to use the Help system from within the Worksheet. The Help system is accessed from the Worksheet by using the question mark as follows  note that the semicolon terminator is not required :  w ?help  The brackets on the left-hand side of the Worksheet shown in  Figure 1.1 are collapsible regions and the underlined text indicates hyper- text. The requested help page is displayed as an inert Worksheet  the Maple commands cannot be executed  in its own window, which means that all or part of it can be copied into the currently active Worksheet using the normal copy-and-paste procedure. The Examples section of a Help page can be copied separately, without highlighting them beforehand, us- ing the Edit:Copy Examples menu item. The selected items are then copied into the active Worksheet using either Edit:Paste or Edit:Paste Maple Text. The ﬁrst method will result in inclusion of both the Maple input and out- put regions, whereas the second only copies the Maple input regions into the active Worksheet, as shown in Figure 1.2, in which the Examples sec- tion for the Help topic simplify[power] are used as an example.  The Help system will also look for partial matches, so, for example, en-  tering ?A will prompt us by providing pointers to the Maple functions that begin with A.  w ?A  6   -  Function: help - descriptions of syntax, datatypes, and functions Calling Sequence:  ?topic or ?topic,subtopic or ?topic[subtopic] or help topic  or help topic,subtopic  or help topic[subtopic]   -  Description:  introduction to Maple list of all help categories  intro index index[category] list of help files on specific topics topic topic[subtopic] explanation of a subtopic under a topic distribution copyright  for information on how to obtain Maple for information about copyrights  explanation of a specific topic    Note 1: The recommended way to invoke help is to use the question mark.   Note 2: When invoking help using the function call syntax, help topic , Maple keywords  reserved words  must be enclosed in backquotes. For example, help quit  causes a syntax error. Use help `quit`  instead. Note that the string delimiter is the backquote  ` , not the apostrophe  ' , nor the double quote  " . When using the question mark syntax for help, no quotes are required.    Note 3: A command must end with a semicolon, followed by RETURN or ENTER, before  Maple will execute it and display the result. The semicolon can appear on the next line if you forget to end the command with it, but it must appear. There can be multiple commands on one line, separated by semicolons or colons. An exception to this is when a line starts with a question mark in which case help is invoked and no semicolon is required.    To contact Waterloo Maple Software, see distribution. To contact the authors of Maple, see  scg.  -  See Also: keyword, quotes, colon, quit, example, scg, distribution, TEXT, makehelp  Figure 1.1  Figure 1.2  -  Function: sin, cos, ... - The Trigonometric functions  Function: sinh, cosh, ... - The Hyperbolic functions  Calling Sequence:  sin x  cos x  tan x   sec x   csc x  cot x   sinh x  cosh x   tanh x   sech x  csch x coth x   Parameters:  x - an expression  Description:  Examples:  +  +  +  See Also: invtrig, invfunc, inifcns  There are no matching topics. Try one of the following:  AFactor AFactors Airy AngerJ  Introduction  7   Applied Maple for Engineers and Scientists  The inclusion of an Examples section in the manual is a very useful fea-  ture. By using ??? or its functional equivalent example, this section can be accessed for any Maple topic that has a Help page. In the example of Figure 1.3 we get the Examples section for the rand function directly using the ??? but example rand  would produce the same result.  Function: rand - Random Number Generator  +  +  -  Description:  Examples  > rand  ;  427419669081  321110693270  > die := rand 1..6 :  > rand  ;  > die  ;  > die  ;  4  6  > simplify  a^b ^c,power ;  > simplify  a^b ^c,power, symbolic ;  > simplify x^a*x^b, power ;  > simplify exp 5*ln x +1 , power ;  > simplify ln x*y ,power ;  > simplify ln x*y ,power, symbolic ;  Figure 1.3  +  See Also: randpoly, randmatrix, stats[random], combinat, randomize  Similarly, the function description and the calling sequence section can be accessed directly by using ??. In Figure 1.4, we get the function descrip- tion and the calling sequence for the sin and other trigonometric functions.  Figure 1.4  8  Finally, hyperlinks to functions and information related to the current  topic of interest can also be easily obtained using the function related  see Figure 1.5 .   Introduction  w related dsolve[numeric] ;  Function: dsolve numeric - numerical solution of ordinary differential equations  + +  +  +  Description:  Examples:  See Also: dsolve[rkf45], dsolve[dverk78], dsolve[classical], dsolve[gear],  dsolve[mgear], dsolve[lsode], dsolve[taylorseries], plots[odeplot], DEtools[DEplot],  DEtools[DEplot3d], DEtools[PDEplot]  Figure 1.5  Maple as a calculator  Numeric Here we use Maple to perform exact and approximate arithmetic:  w 1234+5678;  w 1 2 - 3 4 + 5 6 - 7 8 + 9 10;  6912  73 120  w 1357^24;  1520254661801097535145921172472595185185444  206728322240792485279153288917601  w 2468*1357^ -1 2 ;  2468 1357  ‘1357  The following examples use the ditto  “  pointer to calculate the ﬂoat-  ing-point approximations to the previous two expressions:  9   cid:214  ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  w evalf “ ;  w evalf “”,25 ;  66.99698076  66.99698076106124289230084  The previous result stack in only three deep so more than three double  quotes have no meaning. We can see that in the ﬁrst case the default number of signiﬁcant digits is used, whereas in the second 25 digits are used. This type of calculation is made possible because Maple supports ar- bitrary precision arithmetic as standard. The default number of digits  10  used in a ﬂoating-point calculation is held in the global variable Digits. If we access some of Maple’s 2,500 standard functions we can easily  perform more complex calculations:  w erf infinity ;  w 120!;  1  668950291344912705758811805409037258675274633313  80298102956713523016355724496298936687416527198 4981308157637893214090552534408589408121859898 4811143896500059649605212569600000000000000000 00000000000  w evalf log Pi exp 1  ,200 ;  .144729885849400174143427351353058711647294812915311  57151362307147213776988482607978362327027548970 77020098122286979891590482055279234565872790810 788102868252763939142663459029024847733588699 3778920313  10   Introduction  w exp 1 ;  w evalf “,40 ;  2.718281828459045235360287471352662497757  w evalf sqrt 3.56*log Pi  *12345.67,5 ;  Complex arithmetic Maple operates over both the real and complex do- mains, I being the complex constant:  cid:214   - 1 .  w  1+7*I    2+I *conjugate -3+5*I  ;  - 46 85  + 3 85  I  Name aliasing is also supported. This means that j, commonly used in  engineering to mean  cid:214   - 1 , can be aliased to I.  w alias I=I,j=sqrt -1  ;  w j*j;  w sin Pi 4 ;  Trigonometric functions Maple supports all of the standard trigonomet- ric and hyperbolic functions:  e  24922.  j  - 1  ‘ 2  1 2  11  ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘  Applied Maple for Engineers and Scientists  w evalf “ ;  w tanh 88.5 ;  w sec -1. ;  .7071067810  1.  1.850815718  w evalf csch exp 3.*Pi   ;  .4750727074 10  - 5381  Symbolic Maple’s great strength lies in its ability to perform symbolic calculations:  w expand  x - 3*y^3 ^5 ;  x5 -  15x4y3 + 90x3y6 -  270x2y9 + 405xy12 -  243y15  w normal 1 a-1 b*1 c ;  - b c + a  a b c  w factor diff  x - 3*y^3 ^5,y  ;  - 45  cid:230   Ł x -  4  3 y3 cid:246   y2  Series, sums, and products Maple can generate series expansions  such as Taylor and power , summations, and products of arbitrary expressions quickly and without error:  12  - ł  Introduction  w series sin x ,x=h,5 ;  sin h  + cos h   x - h  - 1 2  sin h   x - h 2 - 1 6  cos h  x - h 3  + 1 24  sin h   x - h 4 + O cid:230   Ł  x - h 5 cid:246   w series GAMMA x ,x=0,3 ;  - 1 -  g +  x  1 12  p 2 + 1 2  g 2 cid:246   x +  cid:230   - 1 3  z  3  -  p 2 g  1 12  g 3 cid:246   1 6  x2+ O x3   w normal sum 1  1-N ^x,x=1..4  ;  - 4 + 6 N -  4 N 2 + N 3   - 1 + N  4  If no range is speciﬁed, the indeﬁnite form is returned, for example,  here we compute the indeﬁnite product p  w product  1-N ^x  x+1 ,x ;   1 - N x  x + 1  in x:   1 - N   1⁄2 x  x - G  x + 1   1    Constants Maple uses the globally accessible sequence constants to maintain the list of currently recognized constants:  w constants;  false g , ¥  , true, Catalan, E, FAIL, p  w type 123, constant ;  true  13  ł  cid:230   cid:231  Ł  cid:247  ł  cid:231  Ł -  cid:247  ł -  Applied Maple for Engineers and Scientists  w type pi, constant ;  w type A_VARIABLE, constant ;  false  false  true  The list can be added by the user very easily, as shown here:  w constants := constants, A_VARIABLE;  constants := false, g , ¥  , true, Catalan, E, FAIL,  , A_VARIABLE  A constant added to the constants list is treated in the same way as the  initially known constants:  w type 2*A_VARIABLE 3.5, constant ;  Variables A variable can be any name other than a reserved word. Maple treats variables in a way that mimics the normally understood mathematical variable. Maple variables can either have values assigned to them or they can remain unassigned. An assigned variable behaves in the same way as a variable in any other programming language in that it can be viewed, set, reset, and used in calculations. We can set variables and look at them:  w x:=10!:  x;  3628800  Or x can be used in a calculation and be reassigned:  w x:=ifactor x ;  x :=  2 8  3 4  5 2  7   14  p  Introduction  An unassigned variable is treated as a symbol that can be used in calcu-  lations and have a value assigned to it at some later time:  w NOT_ASSIGNED;  NOT_ASSIGNED  Equation solver Maple can be used to investigate the solutions to systems of algebraic and diﬀerential equations.  Numerical solutions  w fsolve cos alpha =alpha^2,{alpha} ;  a =  .8241323123  w solve X^7+X+1=0, X ;  RootOf  cid:230   Ł _Z 7 + _Z + 1 cid:246   Maple has returned the RootOf placeholder as a solution. This and  other placeholders  DESol, Limit, Product, …  are used by Maple to store, manipulate, and display data in a concise way. By using allvalues we force Maple to return the roots of the polynomial.  w allvalues “ ;  .7965443541 .7052980879 +.6376237698 I +.6376237698 I  .9798083845 +  .5166768838 I  .7052980879  Here, by means of a Fehlberg four-ﬁve-order Runga-Kutta solver, we  solve numerically a ﬁrst-order ode. We then plot the result  see Figure 1.6 .  w f:=dsolve {diff y t , t =sin t ^2, y 0 =3}, y t ,  type=numeric ;  f := proc rkf45_x  ... end  15   cid:236   cid:237   cid:238   cid:252   cid:253   cid:254  ł -  Applied Maple for Engineers and Scientists  w plot ‘subs‘ f T , y t  , T=0..5 ;  5.5  4.5  5  4  3.5  3  0  Figure 1.6  1  2  3  4  5  Symbolic solutions Find the points of intersection of a circle of radius r centered at the origin and an ellipse with major and minor axes a and b, respectively:  w circle := x^2 + y^2 = r^2;  ellipse := x^2 a + y^2 b = 1;  circle := x2 + y2 = r2 ellipse := x2 = 1 a  + y2 b  w pts := [solve {circle, ellipse}, {x, y} ];  pts := Ø   cid:238  y = RootOf  cid:230   Ł  - b + a _Z2 + br2 - ab cid:246   1 2  x = RootOf  cid:230   Ł  - b + a _Z2 + ab -  r2a cid:246   We can also investigate systems of inequalities:  16  Œ º  cid:236   cid:237  ł  cid:252   cid:253   cid:254  ø œ ß Ø Œ º  cid:236   cid:237   cid:238  ł  cid:252   cid:253   cid:254  ø œ ß  Introduction  w solve  x^3+x^2-5>5, x  ;  RealRange  Open   134 + 3 cid:214   1 3  ‘1995 1⁄3 + 1 3  1  134 + 3 cid:214   ‘1995 1⁄3  - 1 3  , ¥  Here we solve a second-order ode. The solution contains two con-  stants of integration because no initial conditions are speciﬁed.  w dsolve diff y t , t$2  + y t  = 12*cos t ^2, y t  ;  y t  = - 4 cos t 2 + 4 cos t  + 8 + _C1 cos t  + _C2 sin t   Calculus Maple supports single and multivariate calculus. First let us look at the process of diﬀerentiation:  w diff sin x *x^2, x ;  cos x  x2 + 2 sin x  x  w diff expand  sin x +tan y  ^2 , x, y ; 2 cos x   1 + tan y 2    Both deﬁnite and indeﬁnite integration can be performed. Integration  is performed through a combination of knowledge-based programming, simpliﬁcation, and the application of the Riche algorithm. Numerical inte- gration can be easily performed if a symbolic closed-form solution cannot be found:  w int 1  1-x^3 , x ;  - 1 3  ln x -  1  + 1 6  ln cid:230   Ł x2 + x + 1 cid:246   ł + 1 3  ‘ 3 arctan   2x + 1   cid:214   ‘ 3  1 3  17   cid:230   cid:231  Ł  cid:230   cid:231  Ł ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  w Int 2*x*sin x , x=0..Pi a  = int 2*x*sin x , x=0..Pi a ;  2 sin x  x dx = 2  a  0  a -  sin  a  cos  a  a  In this particular example we use the inert form of the integrate func- tion  Int  with evalf to calculate the numerical solution. By using the inert form Maple does not waste time searching for a symbolic solution, which in this case does not exist.  w evalf Int exp exp exp -x   , x=0..3  ;  13.77323428  Graphics An increasingly important part of any research and development tool is its ability to display data. Maple possesses an expansive set of both two- and three-dimensional plotting functions, tools, and animation routines. The style of a plot can be ﬁlled, point, or wireframe, axes can be included, and labels and a title can be added. All of these options can be set either at the command line or via the graphics menu items. Version Vr4 also illuminates three-dimensional surfaces with user-selectable lighting models. Color functions can be added as a means of adding an extra dimension to any plot. Figures 1.7 and 1.8 give the plots of the following two operations:  w plot  x^3-5*x^2+2*x+8   x^3-3*x^2-25*x+75 , x=-10..10,  discont=true, view=[DEFAULT, -10..10], labels=[‘x’,’f x ’] ;  w t:= x,y  - sqrt x^2+y^2 :  plot3d cos t  x+3 ,  y+3  *Pi *exp -t  x+3 ,   y+3   +3*cos t  x-1 ,  y-1  *Pi *exp -t  x-1 ,  y-1   , x=-3..3, y=-3..3, style=HIDDEN, color=BLACK, numpoints=40^2, orientation=[18, 50] ;  18   cid:242  p  cid:230   cid:231  Ł p  cid:246   cid:247  ł  cid:230   cid:231  Ł p  cid:246   cid:247  ł p  Introduction  - 10  - 5  0  5  10  x  fn x   10  5  0  - 5  - 10  Before leaving plots we should mention that version Vr4 of Maple sup-  ports animation. Animate and animate3d functions are available as a standard sequence of plot structures, hence giving the perception of anima- tion. In Figure 1.9, we animate a bouncing ball using this second method:  19  Figure 1.7  Figure 1.8   Applied Maple for Engineers and Scientists  w path := t -> 5*exp -0.5*Pi*t *abs cos t  :  ball:=  x, y  -> plottools[disc] x, y+1, color=BLACK : seq plots[display] [path x , ball x, path x  ], x=0..5 : plots[display] “, insequence=true ;  5  4  3  2  1  0  5  4  3  2  1  0  5  4  3  2  1  0  3  t  3  t  3  t  0  1  2  4  5  0  1  2  4  5  0  1  2  4  5  0  1  2  4  5  5  4  3  2  1  0  5  4  3  2  1  0  5  4  3  2  1  0  3  t  3  t  3  t  0  1  2  4  5  0  1  2  4  5  Figure 1.9  Data structures Maple can store numeric, symbolic, graphic, or programming data in sets, lists, tables, vectors, arrays, and matrices. This extensive range of data structures allows us to both store and manipulate our data in a way that is appropriate to the speciﬁc problem.  20   Introduction  Lists and sets Lists and sets are common structures used to store and ma- nipulate linear data. The major diﬀerences between the two are  1  a list is ordered whereas a set is not and  2  sets will automatically remove repeated entries. Lists are deﬁned using square brackets […] while sets use curly braces {…}. The elements of either can be any valid Maple expression.  w A_LIST := [1, 2, 4 5, GAMMA, ‘the last element’ ];  A_LIST := Ø  1, 2,  , G  4 5  , the last element  w A_SET:= {1, 2, 4 5, GAMMA, ‘the last element’ };  A_SET  := { 1,  2,  , “the last element”}  Note that the element “the last element” is a string. Strings are denoted  using string quotes ‘…’. These data structures can be easily manipulated using op, nops, subsops, intersect, union, member, and minus.  w THE_LENGTH:=nops A_LIST ;  THE_LENGTH := 5  w THE_2ND_ELEMENT:=op 2, A_SET ;  THE_2ND_ELEMENT := 2  w ELEMENTS_2_TO_4 := op 2..4, A_SET ;  cid:238  2, G  ELEMENTS_2_TO_4 :=  cid:236   , the last element cid:252   w A_SET intersect {4 5, Zeta, ‘the last element’};  the last element,  4 5  21  Œ º ø œ ß G  cid:237   cid:253   cid:254   cid:236   cid:237   cid:238   cid:252   cid:253   cid:254   Applied Maple for Engineers and Scientists  Now remove elements:  w A_SET minus {1, GAMMA};  2, the last element,  4 5  w subsop 3=NULL, A_LIST ; [1, 2, G  , the last element ]  or  w A_LIST[3]:=NULL;  [1, 2, G  , the last element ]  Here we test for list and set membership:  w member Pi, A_LIST ;  w member  ‘the last element’, A_SET ;  false  true  Lists and sets can be joined.  w [op A_LIST , op [‘a’, [‘new’], ‘list’] ];  1, 2,  , the last element, a, [new], list  , G  4 5  w A_SET union { {‘a’}, ‘new’, ‘set’};  1, 2, set, G  , the last element,   cid:238  a cid:252    cid:254  , new,  4 5  22   cid:236   cid:237   cid:238   cid:252   cid:253   cid:254  Ø Œ º ø œ ß  cid:236   cid:237   cid:238   cid:236   cid:237   cid:253   cid:252   cid:253   cid:254   Introduction  Arrays, matrices, and vectors Arrays, matrices, and vectors in Maple mimic their mathematical namesakes. Arrays and matrices are ideally suited to the storage and manipulation of two-dimensional data, whereas one-dimensional data can be manipulated using vectors. The major diﬀer- ence between an array and a matrix is that matrix indices must start at zero, whereas an array can be indexed from any integer starting point.  Here we deﬁne and manipulate some arrays. First we deﬁne an empty  array and then set the element A2,2 equal to four:  w A := array 1..2, 1..3 ;  A := array  1 .. 2, 1 .. 3,  [  ]   w A[2,2]:=4;  A2,2 := 4  To look at the contents of an array we use eval, evalm, or print. This step is necessary because arrays conform to the principle of last name evaluation. This means that for an array printed in the normal way  by en- tering the array name followed by a carriage return , only the array’s name will be printed because it is the last name evaluated. To see the contents of the array, full evaluation needs to be forced:  w A;  w evalm A ;  A  A1, 1 A2, 1  A1, 2 4  A1, 2 A2, 3  Here we deﬁne and operate on some matrices. Maple’s linear algebra tools are grouped together in the Maple package linalg  see ?linalg for more details . All or some of the functions in the linalg package, this goes for Maple’s other packages as well, can be loaded using with. An al- ternative method of accessing a particular function is to use its long name:  23  Ø Œ º ø œ ß  Applied Maple for Engineers and Scientists  package name[function name]. In the following examples, we use the long name method to access a selection of linalg functions.  w B:=linalg[matrix] 2, 2, [a, b, c, d] ;  w C:=linalg[matrix] 2, 2, [[1, 2],[3, 4]] ;  B := Ø  a b  b d  C := Ø  1 3  2 4  w evalm B &* C ;  a + 3b c + 3d  2a + 4b 2c + 4d  In a similar fashion we deﬁne and operate on some vectors:  w linalg[vector] 3 ;  º ?1  ?2  ?3  w linalg[vector] [1, 2, 3] :  d:=linalg[transpose] “ ;  d := transpose  [1 2  3]   The previous result, although correct, is not displayed in the column  form we expected. Maple can manipulate row and column vectors cor- rectly as we will see later.  w e:=linalg[vector] [sin a , Pi, 3] ;  e := [sin a   3]  24  Œ º ø œ ß Œ º ø œ ß Ø Œ º ø œ ß Ø ø ß p  Introduction  w linalg[crossprod] e, linalg[transpose] d  ;  [3 p  6  3 - 3 sin a   2 sin a  -  p]  Tables Maple is capable of storing and manipulating multidimensional data in tables. A table is a generalized form of the more common structures of arrays and matrices. Unlike these specialized structures, a table has some signiﬁcant advantages: A table can be n-dimensional  note that an array with more than two dimensions is automatically cast into a table by Maple  and its index can be any Maple expression.  Here we create a table implicitly by making assignments to an indexed  variable.  -sin x ;  w A_DIFF_TABLE[sin x ]:= cos x ; A_DIFF_TABLE[cos x ]:=  A_DIFF_TABLE sin x  := cos x  A_DIFF_TABLE cos x  := - sin x   Here we deﬁne a two-dimensional table explicitly:  w A_2D_TABLE := table [ -1,-1 =’first row’,  -1,0 =zero,   -1,1 =one,  1,-1 =’second row’,  1,0 =zero,  1,1 =’last entry’] ;  A_2D_TABLE := table [   - 1, 1  = one  1, - 1  = second row  1, 0  = zero  - 1, - 1  = ﬁrst row  - 1, 0  = zero  1, 1  last entry ]   This adds an entry to our ﬁrst table:  25  -  Applied Maple for Engineers and Scientists  w A_DIFF_TABLE[tan x ]:=1 cos x ;  A_DIFF_TABLE tan x  :=  1  cos x   The previous entry is in error so it needs to be altered:  w A_DIFF_TABLE[tan x ]:=1+tan x ^2;  A_DIFF_TABLE tan x  := 1 + tan x 2  We will make one ﬁnal entry in our test table and then we will take a  look at it:  w A_DIFF_TABLE[x^n]:=n*x^ n-1 ;  A_DIFF_TABLE xn := nx   n -  1   w A_DIFF_TABLE;  A_DIFF_TABLE  This is not what we expected but it is correct. Maple evaluates table  names in the same way as it does an array name using last name evaluation. To view the contents of a table, eval or print must be used:  w print A_DIFF_TABLE ;  table  [  cos x  = - sin x  sin x  = cos x  tan x  = 1 + tan x 2 xn = nx n - 1   ]  26   Introduction  Maple as a programmable calculator Maple’s extensive list of functions and procedures makes it a powerful mathematical tool that can be applied easily to problem areas as diverse as virology and cosmology. However, ideas and techniques change and ad- vance—as is true of all ﬁelds of human endeavor—so Maple would soon be- come obsolete if it were not able to adapt. Maple can adapt because in addition to being a CAS it is also a powerful programming language.  Functions A function is a Maple object that performs work, taking arguments as in- puts and returning an answer. The general form of a function deﬁnition is:  tag :=   arg1, arg2, ..., argn   ﬁ  body  where tag is associated with the function deﬁnition, sometimes called the head, arg1, arg2, ..., argn is the list of formal parameters passed to body. The formal parameter names appearing in the argument list on the left-hand side of the arrow match with the corresponding variables in body of the deﬁnition. The body is an expression that yields the value of the function when the formal parameters are replaced with the values of the ac- tual arguments.  The function f x, y, z  is a function of three variables x, y, and z and returns the sum of the ﬁrst two arguments raised to the third argument: f x, y, z  = xz + yz. This simple function is represented in Maple as:  w f :=  x, y, z  -> x^z + y^z;  f :=  x, y, z  ﬁ  xz + yz  The function is invoked as follows:  w f A, 4, Pi ;  Ap + 4  Pure functions The Maple name space contains every function and vari- able name that has had an assignment made to it by either the user or the system. A pure function does not have a tag associated with it and hence re-  27  p  Applied Maple for Engineers and Scientists  duces the loading on the Maple name space. A pure function is deﬁned as follows:    arg1, arg2, ..., argn   ﬁ  body  In the following examples, we see how pure functions, based on map and map2, can be easily used when manipulating data. The functions map and map2 are extremely powerful Maple functions that enable complex op- erations to be performed easily on the elements of data structures like ta- bles, lists, arrays, and matrices. The required operation is mapped onto every element in the target data structure.  w map x -> x^2 , array [[x, x^2], [1+x, x^d]]  ;  x2   1 + x 2  x4  xd  2  w map2  x,y ->x^y, n, {1,2,3} ;  {n, n2, n3}  Unapply Maple expressions can be transformed into functions easily us- ing unapply. In the following example we ﬁnd the closed-form solution for the eigenvalues of a two-by-two matrix and then transform the solution into a Maple function. First we deﬁne an empty array.  w A:=array 1..2, 1..2 ;  A := array  1 .. 2, 1 .. 2,  [  ]   Next we calculate its characteristic equation in l  . We do this by creat-  ing a weighted two-by-two identity matrix using linalg[band], sub- tracting it from the matrix A1, and computing the determinant of the resulting matrix:  w A1 := evalm A - linalg[band] [lambda], 2  ;  A1 :=  A1,1 A2,1  A1,2 A2,2  28  Ø Œ º ø œ ß Ø Œ º - l - l ø œ ß  Introduction  w A2 := linalg[det] A1 ;  A2 := A1, 1A2, 2  - A1, 1  A2, 2  + l 2 - A1, 2A2, 1  This solves the characteristic equation for l.  w SOLS := [solve A2, lambda ];  A1,1  A2,2  A1,12 - 2A1,1A2,2  + A2,22 + 4A1,2 A2,1 ,  1 2  1 2  + 1 2  + 1 2  + 1 2  - 1 2  A1,1  A2,2  ‘ A1,12 - 2A1,1 A2,2  + 4A1,2 A2,1  Here we use unapply to form a function that takes an array as input  and returns a list of eigenvalues:  w E_VALUES := unapply SOLS,A ;  A1,1  E_VALUES := A ﬁ + 1 1 2 2 - 1 2  + 1 2 + 1 2  A2,2  A2,2  A1,1  1 2  A1,12 - 2A1,1A2,2  + A2,22 + 4A1,2 A2,1 ,  ‘ A1,12 - 2A1,1 A2,2  + A2,22 + 4A1,2 A2,1  The eigenvalues can now be calculated for any two-by-two matrix:  w E_VALUES array [[1,2],[3,4]]  ;  5 2  + 1 2  ‘ 33,  5 2  1 2  ‘33  Control statements Maple supports basic control structures to govern the ﬂow of evaluation  if and elif , as well as repetition  for and while . Although it is more usual to use these control structures inside Maple procedures and functions, we will use them interactively in the following examples for clarity.  29  l - l Ø Œ º  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ø œ ß Ø Œ º  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ø œ ß Ø Œ º  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ø œ ß Ø Œ º  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ø œ ß Ø Œ º  cid:214  ‘ ‘ -  cid:214  ‘ ‘ ø œ ß  Applied Maple for Engineers and Scientists  If Here is a simple conditional statement to test an input to see whether it is odd or even.  w x:=4:  if x mod 2 = 0 then print cat x,’ is even’  ; else print cat x,’ is odd’  ; fi;  4 is even  In this and the following example, the inﬁx form of the mod function is used. A function is said to be invoked in inﬁx form when the following syn- tax is used: arg1 function name arg2. Note that not every Maple function has a standard inﬁx form. The inﬁx form of a function is used for this situ- ation: If nested if statements are needed, then the elif statement is used in conjunction with if as shown. Here we extend the above example to test for zero:  w x:=-3:  if x=0 then  print ‘zero entered’   elif x mod 2 = 0 then  print cat x,’ is even’  ;  print cat x,’ is odd’  ;  else  fi;  - 3 is odd  Looping There are two basic repetition constructs, for and while. However, looping can also be accomplished with seq and $.  For The general syntax of the for construct is for count from start by increment to end do body od. Any expres- sion of the form keyword is optional. If omitted they default to unity with the exception of end, which defaults to inﬁnity. The following exam- ples demonstrate how the for-loop operates:  30   Introduction  w ANS:=NULL:  for x to 5 by 2 do ANS:=ANS, sin x  od: ANS;  sin 1 , sin 3 , sin 5   w ANS:=NULL:  for x from -1 to 1 by 0.2 do ANS:=ANS, x^2 od: ANS;  1, .64, .36, .16, .04, 0, .04, .16, .36, .64, 1.00  w ANS:=NULL:  for x from -5 to 5 do ANS:=ANS, x^ 1 2  od: ANS;  - 5 ,  - 4 ,  - 3 ,  - 2 ,  I, 0, 1,  ‘ 2 ,  ‘ 3 ,  ‘ 4 ,  ‘ 5  The for construct does have one other form that is useful when oper-  ating on objects, such as lists or sets of unknown length, the for-in construct.  w ANS:=NULL:  for x in [a, b, c, d, e, f] do ANS:=ANS,  x+1  x od: ANS;  1 + a  1 + b  1 + c  1 + d  1 + e  1 + f  ,  a  ,  b  ,  c  ,  d  ,  e  f  While The while construct is an alternate way of performing repetitive operations and has this basic form: while condition is true do body od.  w ANS:=NULL: x:=1:  while ithprime x  12 do  ANS:=ANS, cat ithprime x <’ is prime’ ; x:=x+1;  od: ANS;  31   cid:214  ‘ ‘ ‘  cid:214  ‘ ‘ ‘  cid:214  ‘ ‘ ‘  cid:214  ‘ ‘ ‘  cid:214  ‘  cid:214  ‘  cid:214  ‘  cid:214  ‘  Applied Maple for Engineers and Scientists  2 is prime, 3 is prime, 5 is prime, 7 is prime, 11 is prime  Seq and $ Maple provides two alternative methods of looping: seq and $. Both of these functions are basically equivalent to: for count from start to end by 1 do .. od. A couple of points, however, should be noted: The variable used as the count will maintain its ﬁnal value on exit and only seq will operate over sets and lists.  w seq n^x, x=0..5 ;  1, n, n2, n3, n4, n5  The count variable x now has a value:  w x;  The function seq also works over the elements of a list:  w seq f^2, f=[1,2,a,b] ;  6  1, 4, a2, b2  Both constructs will operate on ﬂoats, but not on symbolic constants . In such cases evalf is simply used to convert to a ﬂoat. The $  such as p symbol is the inﬁx form of seq and is used as follows:  w n^y$ y=1.1..5.7 ;  n1.1, n2.1, n3.1, n4.1, n5.1  The alternative form of $ can also be used to create variables of the  form a1, a2, …, or copies easily:  w ‘a.n‘$ n=1..3 ;  a1, a2, a3  32   Introduction  w A_COPY$4;  A_COPY, A_COPY, A_COPY, A_COPY  Procedural Procedural programming is deeply entrenched in Maple and is supported by the most popular programming languages and tools such as BASIC, FORTRAN, C, and Pascal.  The general form of a procedure is:  w procedure_name :=proc arg1, arg2, ..., argn    local var1, var2, ..., varn; global var1, var2, ..., varn; options opt1, opt2, ..., optn; body  end;  The formal parameters arg1, arg2, ..., argn correspond to variables found within the body of the procedure with the same names. If no operands are speciﬁed then, like C, the argument list can be any length. In this case the global variables args and nargs are used to retrieve the argument list and its length. In the next example we construct a custom plotting procedure that takes a function and a range and plots the function and its integral. The integral is computed and stored using the local vari- able the_int. It should also be noted that the function op is used to extract the independent variable from the range r.  w MY_PLOT := proc x, r   local the_int; the_int:= int x, op 1, r  ; plot {x, the_int}, r, color=BLACK ;  end:  Next we call the procedure deﬁned above:  w MY_PLOT  sin X  X, X=-10..10 ;  A plot of this procedure is shown in Figure 1.10. For further informa-  tion on procedure options see ?procedure[options].  33   Applied Maple for Engineers and Scientists  - 10  - 5  0  5  10  X  1.5  1  0.5  0  - 0.5  - 1  - 1.5  In the same way that Maple supports pure functions  Pure procedures it also supports pure procedures. A pure procedure is exactly the same in- ternally as a normal procedure but does not have a tag assigned to it. The ﬁrst example uses zip. This function is very useful in many applications where the corresponding elements of two data structures have to be com- bined to produce the result. The lengths of the component data structures do not have to be the same as the example shows. Although in many cases pure procedures and interchangeable with pure functions, these examples show how pure procedures are used.  w zip  proc x, y  x^y end,[tan 1 , cot 2 , coth 3 ],  [a,b], filler ;  º tan 1 a, cot 2 b, coth 3 fillerø  w map  proc  x   x^2 end, [a, b, c]  ;  º a2, b2, c2ø  Figure 1.10  34  Ø ß Ø ß  Introduction  Types Maple strongly types language. The following parameter types are some of the more commonly used ones. For more information see ?type.  ^     *  =  **  +  <  <=  PLOT  PLOT3D  RootOf  algebraic  anything  array  complex  constant  equation  float  fraction  function  indexed  linear  list  listlist  matrix  negative  numeric  positive  procedure  ange  rational  series  set  string  string  vector  Table 1.1  w whattype 2 37 ;  w whattype series exp beta , beta  ;  w type 10!, integer ;  fraction  series  true  true  w type  [ a=1, b=2], [‘name’ = ‘integer’, ‘name’= ‘integer’] ;  Next we use the Maple type-checking routines in conjunction with pro-  cedure deﬁnition. First we perform the check at the top level and then it is carried out within the body of the procedure.  35   Applied Maple for Engineers and Scientists  w A_TEST := proc x: :numeric, y: :{posint, function}   print ‘Parametrs check’  end:  w A_TEST 1, cos x  ;  Parameters check  Error, A_TEST expects its first argument x to be of type  w A_TEST z, cos x  ;  numeric but received z  w A_TEST_2 := proc    if type args, numeric  then print ‘Ok’  else print ‘Error’   fi end:  w A_TEST_2 1234 ;  w A_TEST_2 abcd ;  OK  Error  By comparing the two approaches, we can see that the ﬁrst implemen- tation is the simplest but allows no ability to recover from the error condi- tion. The second implementation, on the other hand, is harder to program but it does give us the ability to recover gracefully from error conditions oc- curring as a result of the use of illegal arguments and to continue process- ing with default values for instance.  RETURN and ERROR Loops and procedures can be terminated in one of two ways: the end con- dition becomes valid or a RETURN or an ERROR can be used. When a RETURN is encountered the current control statement is terminated and control is passed to the next level above. When an ERROR is encountered, on the other hand, control is passed to the top level and the current proc- ess chain is terminated.  36   Introduction  w FOR_TEST := proc x, y  local n, nn;  nn:=NULL: if x=0 and y=0 then ERROR ‘Non-zero entries required’  fi; for n from x to 100 do if n>y then RETURN nn  else nn:=nn,[n,n^3] fi; od;  nn; end:  We can see how this works as follows:  w FOR_TEST 90, 101 ;  [90, 729000], [91, 753571], [92, 778688], [93, 804357],  [94, 830584], [95, 857375], [96, 884736], [97, 912673], [98, 941192], [99, 970299], [100, 1000000]  w FOR_TEST -1, 4 ;  [- 1, - 1], [0, 0,], [1, 1], [2, 8], [3, 27], [4, 64]  w FOR_TEST 0, 0 ;  Error,  in FOR_TEST , Nonzero entries required.  37   Applied Maple for Engineers and Scientists  Chapter 2  Active ﬁlter design and analysis  Filters are designed to reject certain interference signals while al-  lowing certain desired pieces of information to pass unattenuated. Filters can be realized in mechanical, electrical, chemical, and other  applied science applications.  In the first application, we will concentrate on the analysis and synthe-  sis of an electrical low-pass ﬁlter  LPF . In particular, the analog  as op- posed to a digital hardware implementation  active LPF topology will have a Butterworth magnitude response. The Butterworth response is spe- ciﬁcally characterized as having a maximally ﬂat magnitude response. This means that while information is within the ﬁlter’s passband, the signal’s amplitude response will not change until it diminishes to exactly  at least mathematically  0.7071 times its passband gain at the cutoff frequency. The LPF passes information below the cutoﬀ, break, or 3-dB frequency while increasingly attenuating all frequencies above the cutoﬀ frequency. The order of the LPF determines the rate  usually expressed in decibels  39   Applied Maple for Engineers and Scientists  per decade or octave  at which the higher frequencies are attenuated be- yond the cutoﬀ frequency.  The Butterworth LPF’s characteristics are dependent on derived com- ponent values and tolerances and several test simulations are performed to show the reader how Maple can easily emulate certain electronic circuits.  In contrast, the second application is a switching bandpass ﬁlter  BPF  whose ﬁlter properties are dependent for the most part on a digital clocking signal and not on component values. Switching BPFs exhibit some very unique properties that are unavailable in an analog or continuous sense.  Case I: analog low-pass filter design and analysis  One of the most common electronic ﬁlters utilized in electronic design is the LPF. Today, the active resistor-capacitor  RC  ﬁlter is common due to its low cost and the extreme ﬂexibility of its topology.  Figure 2.1 shows a typical second-order LPF whose Butterworth re- sponse is dictated by the passive component values R1, R2, C1, C2. This particular topology uses a noninverting unity gain conﬁgured operational ampliﬁer with one positive feedback connection. Inverting topologies are also useful, but for maximum transfer bandwidth control with good input and output impedance across those frequencies, the topology in Figure 2.1 is about the best. The single application drawback is that the passband gain is ﬁxed at unity.  C1  Vout  +  Vin t   R1  R2  V1 t   C2  Vout t   Figure 2.1 Second-order Butterworth LPF.  40  -  Active ﬁlter design and analysis  As designers, we are allowed to vary any of the passive components  R1, R2, C1, C2  to ensure that we obtain the Butterworth response with the desired cutoﬀ frequency. Consequently, we should ﬁrst determine the overall voltage transfer function associated with Figure 2.1 as  Voltage transfer function = Vout t  Vin t   To determine how each of the components relates to the cutoﬀ fre-  quency and Butterworth amplitude response, we use Maple to derive the necessary constituent relationships to form the symbolic design con- straints. Finally, we take the symbolic expressions and substitute the desired ﬁlter speciﬁcations  i.e., cutoﬀ frequency and Butterworth pass- band characteristics  to ﬁnalize the hardware design.  Use of Laplace transform explained The analysis will be performed in the frequency domain using the Laplace transform. Many suitable engineering texts have been published that ex- plain the use of the Laplace transform for performing nodal and mesh analyses for most linear time invariant  LTI  topologies [1–3]. LTI topolo- gies—electrical, mechanical, chemical, etc.—exhibit constant coeﬃcients associated with their respective dynamic equations. The dynamics could be with respect to any number of physical variables. In the case of the fol- lowing LPF, all coeﬃcients in the describing or constituent nodal equa- tions have coeﬃcients whose values are functions of the passive electronic components from which they are comprised.  Constituent relationships derived The Laplace transform allows the designer to formulate the symbolic ex- pressions describing the LPF’s characteristics in the polynomial, s, deﬁned by the following identity, which transforms a time function, f t , into a fre- quency-domain function, F s   Laplace  cid:236    cid:238  f  t  cid:252   = F  s  ”  f  t e  - st dt  s  0  where  s = jw  41   cid:237   cid:253   cid:254   cid:242   Applied Maple for Engineers and Scientists  Use of the Laplace transform allows the designer to use algebraic  rather than diﬀerential equations to solve the LPF design problem.  First, to ﬁnd the derivation of the constituent relationships via Kirch- hoﬀ’s laws, we state the following two independent node expressions as shown in Figure 2.1  using the Laplace transform :  + V1  - VIN R1  - VOUT R2  currents about the node labeled V1 t  V1  V1 currents about the node labeled Vout t  - V1 VOUT R2  + sC2VOUT  + sC1  = 0  - VOUT    = 0  To arrange the above expressions into matrix algebra form for the un-  knowns V1, VOUT, we rewrite the equations as  1 R1  + 1 R2  + sC1  V1  +  cid:230   1 R2  sC1  VOUT  = VIN R1  1 R2  V1  +  cid:230   1 R2  + sC2  VOUT  = 0  or in matrix formulation  1 R1  + 1 R2  + sC1  1 R2  sC1  1 R2  1 R2  + sC2  V1 VOUT  =  VIN R1  0  or equivalently in the following vector equation [1]:  Ax = y  42   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:231  Ł - -  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:231  Ł  cid:246   cid:247  ł Ø Œ º Œ Œ Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł - -  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ œ œ Ø Œ º ø œ ß Ø Œ º Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ  Active ﬁlter design and analysis  where  1 R1  + 1 R2  + sC1  1 R2  sC1  1 R2  1 R2  + sC2  A ﬁ  x ﬁ  y ﬁ  V1 VOUT  VIN R1  0  then solving for the variables V1, VOUT in vector form yields  x = A  - 1y  or if we expand it into a matrix formulation, we obtain  1 R1  + 1 R2  + sC1  1 R2  - 1  sC1  V1 VOUT  =  1 R2  1 R2  + sC2  VIN R1  0  Solving this last expression in Maple is done by assigning the following expressions:  x ﬁ  V1 VOUT  Maple  Unknown_Variable_Matrix  43  Ø Œ º Œ Œ Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł - -  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ œ œ Ø Œ º ø œ ß Ø Œ º Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ Ø Œ º ø œ ß Ø Œ º Œ Œ Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł - -  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ Ø Œ º ø œ ß  Applied Maple for Engineers and Scientists  Maple  A_Matrix  1 R1  + 1 R2  + sC1  1 R2  - 1  sC1  A ﬁ  y ﬁ  VIN R1  0  1 R2  1 R2  + sC2  Maple  Y_Matrix  and then entering them into a Maple session:  w with  linalg :  A_Matrix := array  [[1 R1+1 R2+s*C1,-1 R2-s*C1],  [-1 R2,1 R2+s*C2]] ;  Y_Matrix := array  [[Vin R1],[0]] ; Unknown_Variable_Matrix := evalm   A_Matrix ^ -1  &*   Y_Matrix  ;  A_Matrix :=  + sC1  1 R1  + 1 R2 1 R2  1 R2 1 R2  sC1 + sC2  Y_Matrix :=  VIN R1  0  Unknown_Variable_Matrix :=   1 + sC2 R2 Vin  1 + sC2 R2 + R1 sC2 + s2C1 R1 R2 C2  Vin  1 + sC2 R2 + R1 sC2 + s2C1 R1 R2 C2  44  Ø Œ º Œ Œ Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł - -  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ  cid:230   cid:231  Ł  cid:246   cid:247  ł ø œ ß œ œ œ œ Ø Œ º Œ Œ - - - ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ Œ Œ ø œ ß œ œ œ œ  Active ﬁlter design and analysis  Incidentally, since either column or row matrices are vectors, the user  could set up the Maple A_Matrix and Unknown_Variable_ Matrix variables as A_Vector and Unknown_Variable_Vector to more clearly represent these variables in a session. However, the single- order vector is only a special case of the multidimensional-order matrix. Note that the matrix multiplication between A_Matrix inverse and  Y_Matrix is performed with the “&*” operation rather than the “*” op- erator. Maple distinguishes between matrix and scalar multiplication with this notation.  Abstracting the variable’s solutions,  w V1 := Unknown_Variable_Matrix[1,1];  Vout := Unknown_Variable_Matrix[2,1];  V1 :=  Vout :=   1 + sC2 R2 Vin  1 + sC2 R2 + R1 sC2 + s2C1 R1 R2 C2  1 + sC2 R2 + R1 sC2 + s2C1 R1 R2 C2  Vin  Since the LPF’s overall voltage transfer function was previously  deﬁned as  LPF_Transfer = VOUT VIN  we appear to have our transfer function with the second equation, thus  w LPF_Transfer := Vout Vin;  LPF_Transfer :=  1 + sC2 R2 + R1 sC2 + s2C1 R1 R2 C2  1  We may rewrite the second-order LPT_Transfer expression as  LPF_Transfer =  1 + 2z  s2 2 N  + 1  N  45  w w  Applied Maple for Engineers and Scientists  where w N and z are the natural frequency and damping factor, respec- tively, of the second-order system [1,2].  Now we must collect this coeﬃcient information from the  LPF_Transfer equation, hence  w LPF_Transfer_Denominator := denom LPF_Transfer :  Second_Order_Coeff := coeff LPF_Transfer_Denominator,s,2 ; First_Order_Coeff := coeff LPF_Transfer_Denominator,s,1 ; Zero_Order_Coeff := coeff LPF_Transfer_Denominator,s,0 ;  Second_Order_Coeﬀ := C1 R1 R2 C2 First_Order_Coeﬀ := C1 R2 + R1 C2 Zero_Order_Coeﬀ := 1  Associating these Maple coeﬃcient extraction values with the general  LPF_Transfer results in the following second-order coeﬃcients having the circuit component values shown in Figure 2.1:  w Natural_Frequency_Radians := 1 sqrt Second_Order_Coeff ;  Damping_Factor :=  Natural_Frequency_Radians 2   *First_Order_Coeff;  Natural_Frequency_Radians :=  1  ‘ C1 R1 R2 C2  Damping_Factor := 1 2  C1 R2 + R1 C2 ‘ C1 R1 R2 C2  Comparing these expressions with any standard control theory text on second-order systems [1–3] shows the following for the natural frequency w N and damping factor z :  =  N  z = C2 2 cid:214   1  ‘ R1R2C1C2  R1 + R2   ‘ R1R2C1C2  46   cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ w  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Active ﬁlter design and analysis  Hence, these Maple symbolically derived expressions agree with the  previously cited texts.  If we want the Natural_Frequency_Radians in hertz, then  To impose a Butterworth or maximally ﬂat amplitude response, or ﬂat  passband gain, we need to impose the following on the damping factor:  =  fN  1  2p  ‘ R1R2C1C2  z = C2 2 cid:214    R1 + R2   ‘ R1R2C1C2  1 ‘ 2  Hence, we have our first design constraint toward the design of a But- terworth LPF. This constraint comes from [1] if the reader is interested in discovering more about ﬁlter and network theory.  Now let’s build ourselves a very common Butterworth ﬁlter with a  1-kHz cutoﬀ frequency.  Designing a 1-kHz Butterworth LPF From the previously derived Natural_Frequency_Hertz and z expressions, we state the following design constraints:  =  fN  1  2p  ‘ R1R2C1C2  = 1,000 Hz  z = C2 2 cid:214    R1   + R2 ‘ R1R2C1C2  =  1 ‘ 2  Now we have four unknowns in two equations, hence we need to re- duce the number of independent variables by two. The most direct way is to impose some initial constraints such as these:  R1  = R2  = R  47   cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ﬁ  cid:214  ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘  Applied Maple for Engineers and Scientists  C1  = b C2  Implementing this in a Maple session,  w Natural_Frequency_Hertz := 1  2*Pi*sqrt R1*R2*C1*C2  :  Damping_Factor := C2* R1+R2   2*sqrt R1*R2*C1*C2  : R1 := R: R2 := R: C1 := beta*C2: Results :=  solve {Natural_Frequency_Hertz=1000, Damping_Factor=1 sqrt 2 },{beta,R} :  Solutions := subs Results,[beta,R] : beta := op 1,Solutions ; R := op 2,Solutions ;  := 2  R :=  1  4000  ‘ 2 C2 p  Now we have two expressions that give us the nice result that the two  capacitors are related by an integer and all resistors are deﬁned once we pick a value for C2.  The fact that the capacitors are related by an integer is especially nice  from the practical standpoint that capacitor values have the added problem of variable geometry  physical size  depending on type  polycarbonate, polypropylene, paper, electrolytic, etc. , voltage rating, and physical mounting conﬁguration  axial or stand-up . Having an integer value for the capacitors allows the designer simply to purchase two, three, or whatever number of capacitors to complete the ﬁlter design. Matching capacitors for a design is not nearly as easy as it is for matching two or more resistors.  At this point we simply try some values to initiate the LPF design. Gen-  erally, a designer starts with some simple resistor and capacitor values. These values might be components that are readily available in the lab or from a vendor. Consequently, we will start by letting R = 10,000W , which forces C2 = 11,253 pF, which we will call .01 m F. Both of these component values are common in most labs, electronic kits, or gutted electronic equip- ment. The complete component value set then becomes  48  b  cid:214  ‘  Active ﬁlter design and analysis  = 10,000W  = R2 = 20,000 pF = 10,000 pF  R1 C1 C2  Let’s use Maple to determine these coeﬃcients’ eﬀect on  LPF_Transfer:  w LPF_Transfer_Complex := subs s=I*w,LPF_Transfer :  LPF_Transfer_Mag := evalc abs LPF_Transfer_Complex  ; LPF_Transfer_Phase :=  arctan evalc Im LPF_Transfer_Complex   Re LPF_Transfer_Complex   ;  LPF_Transfer_Mag  := 1    cid:230   2w2 C1 R1 R2 C2 + w4C12 R12 R22 C22 + w2C22 R22 + 2w2C22 R2 R1 + R12 w2C22  cid:246   Ł 1 - 1 2  +  1⁄2  } cid:246   1 2 1⁄2  LPF_Transfer_Phase := - arctan  wC2 R2 + R1 wC2 1 - w2C1 R1 R2 C2  Bode magnitude and phase plots Bode plots [1–3] are a convenient method for determining the magnitude and phase response of any linear  or nonlinear in special cases  system.  Magnitude response The magnitude response, shown in Figure 2.2, depicts the gain of the But- terworth LPF over any particular frequency range. The Bode magnitude plot will indicate any part of the LPF’s spectral response that is not “ﬂat” or, in other words, that exhibits some kind of ripple or varying gain with frequency. The Butterworth criterion says this must not happen except when uniformly decreasing after the cutoﬀ frequency  which we have de- cided is 1 kHz . The x-axis represents frequency units in hertz and the y-axis represents gain, which is measured in decibels  dB , which can be expressed as  49  ł  cid:230   cid:231  Ł  cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  Decibel  0  - 10  - 20  - 30  - 40  50  2.5  3.5  4  3  Frequency  Figure 2.2 Bode plot for Butterworth LPF  cutoff frequency = 1 kHz, damping factor = 0.7071, y-axis is in decibels, x-axis is in 10N Hz .  dB = 20 log10  Output signal Input signal  Technically speaking, gain is dimensionless; however, when expressed  in decibels, what you are actually expressing on the y-axis is output re- sponse relative to the input excitation.  Phase response The phase response, as shown in Figure 2.3, indicates how a sinusoidal output signal’s phase will vary with respect to the input sinusoidal. Hence, if the input signal is deﬁned as zero phase, then a negative phase response indicates that the output response will lag the input in time or, equiva- lently, phase. Conversely, a positive phase indicates the output signal an-   cid:230   cid:231  Ł  cid:246   cid:247  ł  Active ﬁlter design and analysis  ticipates the input signal. This last case is impossible  how can an output signal appear before the input signal was applied to the ﬁlter?  but can mathematically appear as a result. What this means is that the circuit or sys- tem has slipped a cycle, which might be 90 degrees, 180 degrees, 360 de- grees, or other multiple value of the input sinusoidal phase. Such phase slips are sometimes called Rice clicks in FM  frequency modulated  receiv- ers [4], which use a phase-lock loop  PLL  topology approach to detecting frequency changes from a central carrier frequency.  We plot the logarithmic form of LPF_Transfer_Mag versus fre-  quency  in hertz  as follows:  w with  plots :  readlib log10 : LPF_Transfer_Mag_Subs := subs w=2*Pi*f,R1=10000,  R2=10000,C1=20000*10^ -12 ,C2=10000*10^ -12 , LPF_Transfer_Mag :  LPF_Transfer_Mag_Decibel := 20*log10 LPF_Transfer_Mag_Subs : f := 10^N: plot  LPF_Transfer_Mag_Decibel,N=2..4,axes=boxed,  style=point, symbol= cross ,color=black,labels=[Frequency,Decibel] ;  The reader can see the nicely ﬂat corner frequency at N = 3   x-axis = 10N Hz  or 1 kHz. Further, due to the second order, the response is around 35 to 40 dB below the passband, which is deﬁned as the magni- tude response below the cutoﬀ frequency in a LPF.  Now let’s look at the phase plot over the same frequency range:  w LPF_Transfer_Phase_Subs :=  subs w=2*Pi*f,R1=10000,R2=10000,C1=20000  *10^ -12 ,C2=10000*10^ -12 ,LP   F_ Transfer_Phase :  plot  180 Pi*LPF_Transfer_Phase_Subs,N=2..4,axes=boxed,  color=black,labels=[Frequency,Phase] ;  We can see a slight deviation from the ideal cutoﬀ of 1 kHz in the  Figure 2.3 plot, because the phase shift should be - 90 degrees at N = 3  103 = 1 kHz . Instead, we have a shift slightly less than the ideal - 90 degrees. Making sure that we are close, let’s numerically evaluate the LPF_Transfer_Phase expression at w = 2p  1000  with Maple:  51   Applied Maple for Engineers and Scientists  Phase  0  80  60  40  20  - 20  - 40  - 60  - 80  52  2.5  3  Frequency  3.5  4  Figure 2.3 Phase plot for Butterworth LPF  cutoff frequency = 1 kHz, damping factor = 0.7071, y-axis is in degrees, x-axis is 10N Hz .  w Cutoff_Phase := evalf subs f=1000,180 Pi*  LPF_Transfer_Phase_Subs  ;  Cutoﬀ_Phase := - 80.49366995  This indicates that our cutoﬀ frequency is higher  i.e., 1 kHz  than  originally designed. In fact, using Maple, we can determine the actual half- power point as follows:  w Phase_Cutoff_All := solve LPF_Transfer_Phase_Subs=  Phase_Cutoff_Real_Positive := select type,  -Pi 2.00001,f ;  Phase_Cutoff_All], positive numeric  ;   Active ﬁlter design and analysis  Phase_Cutoﬀ_All := - 1125.401644 , 1125.389145 Phase_Cutoﬀ_Real_Positive := [1125.389145]  Obviously, the positive root is the one of interest, hence with the given  component values, the LPF cutoﬀ is 1125.389145 Hz.  We could have arrived at a similar  though not identical value  actual cutoﬀ frequency by solving the LPF_Transfer_Mag expression for the half-power point or where  LPF_Transfer_Mag = 1 ‘ 2  Therefore  w Value := evalf 1 sqrt 2  :  Mag_Cutoff_All := solve LPF_Transfer_Mag_Subs=Value,f ; Mag_Cutoff_Real_Positive := select type,[Mag_Cutoff_All],  positive numeric  ;  Mag_Cutoﬀ_All := 1125.395395 , - 1125.395395 , 1125.395395 I, - 1125.395395 I Mag_Cutoﬀ_Real_Positive := [1125.395395]  As expected, the cutoﬀ frequency is slightly higher than designed, though by a small amount. Also, the numerical value is slightly diﬀerent than by the phase computations, but well within numerical acceptability.  Improvement on the 1-kHz Butterworth LPF We have seen that we were oﬀ the design cutoﬀ frequency by around 10%. Consequently, for the sake of practicality, we will leave the two capacitors at their current values and adjust the resistive components to trim the cut- oﬀ frequency closer to the desired 1 kHz.  Starting with the following constraints: C1 = .02 m F C2 = .01 m F R1 „ R2  53   cid:214  ‘  Applied Maple for Engineers and Scientists  and further adhering to the Butterworth criterion,  z =  ‘ 2 2  We also use the previous equations describing the Butterworth’s cutoﬀ  frequency and damping factor:  =  fN  2p  z = C2 2 cid:214   1  ‘ R1R2C1C2  R1 + R2   ‘ R1R2C1C2  = 1000  = 1 ‘ 2  We now solve for the resistive values in Maple:  w C1 := .02*10^ -6 : C2 := .01*10^ -6 : Natural_Frequency_Hertz := 1  2*Pi*sqrt R1*R2*C1*C2  : Damping_Factor := C2* R1+R2   2*sqrt R1*R2*C1*C2  : Results :=  fsolve {Natural_Frequency_Hertz=1000,  Damping_Factor=1 sqrt 2 },{R1,R2},co  mplex ; Solutions := subs Results,[R1,R2] : R1 := Re op 1,Solutions  ; R2 := Re op 2,Solutions  ;  Results :=  cid:236    cid:238  R1 = 11253.95394 - .3785358168 I,  cid:238  R2 = 11253.95394 + .3785358168 I  cid:252  R1 := 11253.95394 R2 := 11253.95394  Notice that Maple found complex roots  after invoking the complex argument within the fsolve command  for the resistance values, hence we had to abstract the real values by invoking the Re command on the Solutions operands result. Further, note the relative magnitude diﬀer- ence between the real and imaginary parts of the R1, R2 Result solu- tions. What this indicates is that the solution roots  resistance values  are identical. However, due to round-oﬀ error within Maple’s fsolve engine,  54   cid:214  ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘  cid:237   cid:252   cid:253   cid:254   cid:236   cid:237   cid:253   cid:254   Active ﬁlter design and analysis  the root-ﬁnding algorithm created some negative nonzero radicand value, which, when evaluated numerically, created an imaginary component. Consequently, users should always look at their results and evaluate these ﬁndings within the framework of the deﬁning ﬁlter equations. To prove that the resistance values are valid, let’s substitute these component values back into the Butterworth LPF’s equations. You can easily do this by asking Maple to reiterate the Natural_Frequency_Hertz and Damping_Factor values, since all component values are still in Maple’s memory. Hence,  w Natural_Frequency_Check := evalf Natural_Frequency_Hertz ;  Damping_Factor_Check := evalf Damping_Factor ;  Natural_Frequency_Check := 1000.000001 Damping_Factor_Check  := .7071067814  Not only are the component values numerically correct with easily  found capacitive values, but we have the added bonus that ﬁnding 1% met- al ﬁlm resistors with the required 11.2-kW value is quite easily done. Now let’s put the new 1% metal ﬁlm resistor values into the Butterworth design and see what we obtain for a cutoﬀ frequency and damping factor:  w R1 := 11.2*10^3: R2 := 11.2*10^3: C1 := .02*10^ -6 : C2 := .01*10^ -6 : Natural_Frequency_Hertz :=  evalf 1  2*Pi*sqrt R1*R2*C1*C2   ;  Damping_Factor := C2* R1+R2   2*sqrt R1*R2*C1*C2  ;  Natural_Frequency_Hertz := 1004.817317 Damping_Factor := .7071067810  These component values are much better than our ﬁrst attempt at real-  izing the desired Butterworth LPF design.  Butterworth LPF component sensitivity analysis Now that we have seen  by both phase and magnitude computations  that our designed cutoﬀ frequency is correct, we need to investigate the sensitiv-  55   Applied Maple for Engineers and Scientists  ity of the LPF to component values. Consequently, let’s deﬁne the sensitivity function, SB  A, as  A ” B SB A  ¶ A ¶ B  Simply stated, this function gives the percentage change of function A  with respect to variable B. Consequently, the sensitivity of the cutoﬀ fre- quency and damping factor to each of the component variables comprising the Butterworth topology is given in Table 2.1.  Component  variable   Cutoff frequency sensitivity FN =  1  2p  ‘ R 1R 2C 1C 2  Damping factor sensititivy z = 1 2  C 2 R 1 + R 2  ‘ R 1R 2C 1C 2  R1  R2  C1  C2  Table 2.1 Sensitivity cases of the Butterworth LPF  N ” CASE_1 f SR  N ” CASE_2 f SR  N ” CASE_3 f SC  N ” CASE_4 f SC  1  2  1  2  ” CASE_5  ” CASE_6  ” CASE_7  ” CASE_8  SR  1  SR  2  SC  1  SC  2  We let Maple handle the calculus and algebra for the eight cases:  w N_F := 1  2*Pi*sqrt R1*R2*C1*C2  :  D_F :=  C2* R1+R2    2*sqrt R1*R2*C1*C2  : CASE_1 := simplify  R1 N_F *diff N_F,R1  ; CASE_2 := simplify  R2 N_F *diff N_F,R2  ; CASE_3 := simplify  C1 N_F *diff N_F,C1  ; CASE_4 := simplify  C2 N_F *diff N_F,C2  ; CASE_5 := simplify  R1 D_F *diff D_F,R1  ; CASE_6 := simplify  R2 D_F *diff D_F,R2  ; CASE_7 := simplify  C1 D_F *diff D_F,C1  ; CASE_8 := simplify  C2 D_F *diff D_F,C2  ;  56   cid:230   cid:231  Ł  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:246   cid:247  ł z z z z  Active ﬁlter design and analysis  Then we put the computed results into a tabular form, as shown in  Table 2.2. From Table 2.2, we see that for six out of eight possible cases, the cutoﬀ frequency and or damping factor can exhibit a negative 50% change or shift in cutoﬀ frequency for a unit change in a particular compo- nent’s value. However, cases 5 and 6 indicate that if R1 = R2, then there is a zero component sensitivity for the LPF’s damping factor. This was the initial design exercise for creating the Butterworth LPF. However, after constraining the two capacitors to be integer multiples of each other  a practicality issue , we found that the resistive values still came out equal. Consequently, this ﬁnal design result has the added bonus of having the lowest damping factor change for any change between the two resistor values.  Component  variable   Cutoff frequency sensitivity  Damping factor sensitivity  R1  R2  C1  C2  N ” CASE_1 = - 1 f SR 2  N ” CASE_2 = - 1 f SR 2  N ” CASE_3 = - 1 f SC 2  N ” CASE_4 = - 1 f SC 2  1  2  1  2  R1 R1  R2 R1  - R2 + R2 - R1 + R2  ” CASE_5 = 1 2  SR  1  ” CASE_6 = 1 2  ” CASE_7 = - 1 2  ” CASE_8 = - 1 2  SR  2  SC  1  SC  2  What about situations when the values of the resistors are not equal? Could this happen by design? Is it desirable to have unbalanced resistor values in the Butterworth LPF topology? Let’s take a quick look at this prospect.  Unequal resistance values in the Butterworth LPF topology From Table 2.2, we saw that unequal resistance values certainly increase the cutoﬀ frequency’s sensitivity to resistor component value change. That is certainly not a desirable result. However, for the sake of design interest, let’s force the following constraint:  57  Table 2.2 Maple computer sensitivies  z z z z  Applied Maple for Engineers and Scientists  R1 C1  = a R2 = b C2  , b are real scalars. Remember, we want b  where a for practical reasons  that is, because of the diﬃculty of ﬁnding arbitrarily related capacitor values . Now the Butterworth design equations become  to retain its integer value  1  =  fN  ‘ R1R2C1C2 2p  R1   + R2 z = C2 ‘ R1R2C1C2 2 cid:214   =  1 2p R2C2  a +  = R2C2  2R2C2  = 1000  1   = 1 ‘ 2  Again, we have four unknowns and two equations; therefore, let’s im-  pose the following criteria:  = 12 kW = .01 m F  R2 C2  Solving for a  , b we obtain  w R2 := 12*10^3:  C2 := .01*10^ -6 : Natural_Frequency_Hertz := 1  2*Pi*R2*C2*sqrt alpha*beta  : Damping_Factor :=  R2*C2* alpha+1   2*R2*C2*sqrt alpha*beta  :  Results := solve  {Natural_Frequency_Hertz=1000,  Damping_Factor=1 sqrt 2 },{alpha,beta} ;  Solutions := subs Results,[alpha,beta] : alpha := op 1,Solutions ; beta := op 2,Solutions ;  Results :=  cid:236   b = 2.008828030 , a =  .8756589909  cid:252   := .8756589909 := 2.008828030  58   cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ a b ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ a b  cid:214  ‘  cid:237   cid:238   cid:253   cid:254  a b  Active ﬁlter design and analysis  Consequently, under these constraints there was a unique solution  and we did retain a strongly integer relationship between C1,C2 while ob- taining diﬀerent resistor values. Therefore, the new component values of the Butterworth LPF are as follows: = a R2 = 12 kW = b C2 = .01 m F  = 10.50 kW  = .02 m F  R1 R2 C1 C2  Again, the R1s are easily obtained in a 1% metal thin-ﬁlm-type resistor as are the R2s. However, as shown before in the sensitivity discussion, the damping factor now has a greater resistance component sensitivity. In fact, the sensitivity functions numerically compute to be  SR1  SR2  = 1 2  = 1 2  R1 R1 R1 R1  - R2 + R2 - R2 + R2  = 1 2  = 1 2   10.5 - 12   10.5 + 12   12 - 10.5   10.5 + 12   = -  .033  = + .033  which indicates an approximate 3% variation in the damping factor for every unit variation in the resistance values. Further, since the signs are op- posite and the resistors will have identical temperature coeﬃcients  pro- vided they are the same type and physically close , any resistance change due to temperature variation will be compensated for, causing little to no signiﬁcant eﬀect on the Butterworth’s damping factor.  The capacitors’ sensitivity functions were not changed by this analysis because the sensitivity function for them was independent of their speciﬁc or relative value to each other.  One final cautionary note about the solve and fsolve commands Always view your results  regardless of what type of engineering problem you are analyzing  to see if you have come up with any unexpected imagi- nary terms as a result of Maple’s evaluation. In the previous component evaluation case, we had imaginary terms, hence we needed to use the Re command to abstract the real part of the solution. If we had not bothered to look at the Results evaluation and simply went to abstract them, no output  59  z z  Applied Maple for Engineers and Scientists  would have been produced. This would have led the user to incorrectly be- lieve there are no solutions  which Maple can do if no solutions exist to a set of simultaneous equations . So make sure you always observe the solve or fsolve commands’ results before continuing with your analysis.  Now that we have a realistic 1-kHz Butterworth LPF design, let’s ex- amine some simulations of output responses to some sinusoidal and step functions.  The intent of a LPF is to attenuate frequencies beyond the designed ﬁlter’s cutoﬀ frequency. The question becomes one of how strongly we want to attenuate and, therefore, how close can an interfering signal be to the desired bandwidth before it becomes a problem for a given design.  Butterworth LPF test setup Figure 2.4 represents our test setup for evaluating the Butterworth LPF un- der the following conditions:    Out-of-band signal attenuation;   Step response.  Desired signal  Signal 1  500 Hz   Signal 1  +  Signal 2  C2  C1  R2  R1  Butterworth LPF   1000 Hz   Filtered channel information  Total channel information  Interfering signal  Signal 2  5 KHz   Figure 2.4 Test setup for LPF measurements.  Creating the signal sources in Maple, we get  w F1 := 500: F2 := 5000: Signal_1 := sin 2*Pi*F1*t ;  60  S  Active ﬁlter design and analysis  Signal_2 := sin 2*Pi*F2*t ; Channel_Signal := Signal_1 + Signal_2;  Signal_1 := sin 1000 p Signal_2 := sin 10,000 p Channel_Signal  t  := sin 1000 p  t   t  + sin 10,000 p  t   then taking the Laplace transform of the total channel signal, which is the summed input of the test signals shown in Figure 2.4, we have  w with inttrans :  Channel_Signal_Laplace := expand Laplace   Channel_Signal,t,s  ;  Channel_Signal_Laplace :=  11,000  Ł s2 + 1,000,000 p 2 cid:246   + 110,000,000,000  p s2 Ł s2 + 100,000,000 p 2 cid:246   Ł s2 + 1,000,000 p 2 cid:246   p 3 Ł s2 + 100,000,000 p 2 cid:246   substituting the component values into the LPF_Transfer function pre- viously derived results in the following:  LPF_Transfer =  1 R1R2C1C2s2 +  R1C2  + R2C2    s + 1  and multiplying the channel information by the Butterworth LPF_Transfer function yields the ﬁlter’s output:  w LPF_Transfer := 1  R1*R2*C1*C2*s^2+ R1*C2+R2*C2 *s+1 :  LPF_Transfer_Subs := subs R1=10.5*10^3,R2=12*10^3,  C1=.02*10^ -6 ,C2=.01*10^ -6 ,LPF_Transfer :  Filter_Output_Laplace := Channel_Signal_Laplace*  LPF_Transfer_Subs;  61   cid:230  ł  cid:230  ł  cid:230  ł  cid:230  ł  Applied Maple for Engineers and Scientists  Ł s2 + 1,000,000 p 2 cid:246   Filter_Output_Laplace  := s2 Ł s2 + 1,000,000 p 2 cid:246  p 3 Ł s2 + 100,000,000 p 2 cid:246   + 110,000,000,000  Ł s2 + 1,000,000 p 2 cid:246  - 7 s2 + .0002250000000s + 1 cid:246   Ł .2520000000 10     Performing the inverse Laplace transform yields the time-domain re-  sponse, therefore,  w Filter_Output_Time := evalf simplify invlaplace   Filter_Output_Laplace,s,t   ;  Filter_Output_Time := .7060431942 sin 3141.592654 t  .6642910232 cos 3141.592654 t  .03851414293 sin 31415.92654 t  .01140445884 cos 31415.92654 t   + .4518843917 e + .6756954821 e   - 4464.285714 t   - 4464.285714 t   sin 4444.400154 t  cos 4444.400154 t   The Filter_Output_Time expression exhibits a steady-state and transient output response. The transient aspects are easy to spot. They are the output terms with the decaying exponential coeﬃcients.  Now let’s plot the unﬁltered and ﬁltered information as shown in  Figure 2.4 to compare how well our Butterworth LPF has attenuated the 5-kHz interference signal:  w with plots :  Filtered_Plot :=  plot Filter_Output_Time,t=0..2* 1 500 ,style=line, color=black :  Unfiltered_Plot :=  plot Channel_Signal,t=0..2* 1 500 , linestyle=2,color=black,n umpoints=512 :  display {Filtered_Plot,Unfiltered_Plot},axes=boxed,  labels=[Time,Output] ;  62   cid:230   cid:231  Ł p  cid:230  ł  cid:230  ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:230  ł  cid:230  ł  cid:246   cid:247  ł  cid:230  ł - - -  Active ﬁlter design and analysis  Output  0  2  1  - 1  - 2  0.001  0.003  0.004  0.002  Time  Figure 2.5 Comparison between filtered and unfiltered output, both at 500 Hz  filtered signal, solid line; unfiltered signal, dashed line .  Figure 2.5 indicates that we have greatly attenuated the 5-kHz interfer- ence, which was strongly corrupting our 500-Hz information. To increase ﬁltering, we would need to either lower the cutoﬀ frequency toward the de- sired frequency and or increase the order of the Butterworth LPF. The cur- rent design is attenuating the 5-kHz signal by a factor of  Attenuation »  2  =  fNoise f- 3dB  5000 Hz 1000 Hz  2  = 25  Hence, we have improved signal to noise  SNR  by 20 log10  25  » 28 dB.  63   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  Design iteration of LPFs for newer filtering requirements The question now arises: Is this suﬃcient attenuation for the given ﬁltering application? The answer is that it depends on the speciﬁcation given to the designer. Let’s say the customer looks at our design and realizes the ﬁnal design requires another 5 dB of 5-kHz signal attenuation before the prod- uct is viable. There are two immediate approaches for obtaining the increased 5-kHz signal attenuation:  1. Decrease the cutoﬀ frequency; 2.  Increase the order of the Butterworth LPF.  Solution 2 is viable when most of the passband up to 1 kHz is re-  quired. Using a higher order LPF than the currently designed second-or- der LPF will more rapidly attenuate signals beyond the cutoﬀ frequency without causing excessive attenuation within the 1-kHz passband. How- ever, the higher order ﬁlter will require more hardware, design time, and a higher cost. If, on the other hand, we only need to see the 500-Hz signal, then following solution 1 by reducing the cutoﬀ frequency in the original topology should be suﬃcient to fulﬁll the customer’s requirement.  Consequently, we reiterate the capacitive component restriction,  = .02 m F = .01 m F  C1 C2  also knowing that we now need a total 5-kHz attenuation of  28 dB +  5 dB =  33 dB ﬁ  5 kHz  or about a 45-to-1 attenuation at 5 kHz. Further, we also want the follow- ing criterion to hold true as well:   + R2  R1 ‘ R1R2C1C2  z = C2 2 cid:214   = 1 ‘ 2  in order for the LPF topology to retain the Butterworth response. There- fore, entering these constraints and constants into Maple,  64  ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘  Active ﬁlter design and analysis  w readlib unassign :  unassign  ‘R1’,’R2’ : C1 := .02*10^ -6 : C2 := .01*10^ -6 : freq := 5000: LPF_Transfer := 1  R1*R2*C1*C2*s^2+ R1*C2+R2*C2 *s+1 : LPF_Transfer_Mag := evalc abs subs s=2*Pi*I*freq,  LPF_Transfer   ;  Damping_Factor := C2* R1+R2   2*sqrt R1*R2*C1*C2  ;  LPF_Transfer_Mag := 1    cid:230   .2000000000 10  1 2  +  .0001000000000  p R1 + .0001000000000  Damping_Factor := .3535533907  R1 + R2 ‘R1 R2  2  - 7 R1 R2 p 2 + 1 cid:246  p R2 2 cid:246   1⁄2  Now, working backwards, we solve the LPF_Transfer_Mag equa- tion for the unknown resistors, R1,R2, by invoking the computed ﬁlter’s magnitude response at 5 -kHz and the Damping_Factor constraint for ensuring a Butterworth response:  w Solutions_45db := solve {LPF_Transfer_Mag=1 45,  Damping_Factor=1 sqrt 2 },{R1, R2} ;  Results := subs Solutions_45db,[R1,R2] : R1 := op 1,Results ; R2 := op 2,Results ; Solutions_45db :=  cid:236    cid:238  R1 = 19042.39265 , R2 = 12694.92848  cid:252  R1 := 19042.39265 R2 := 12694.92848  These resistor values correspond to a new cutoﬀ frequency  in hertz  of  w Natural_Frequency_Hertz :=  evalf 1  2*Pi*sqrt R1*R2*C1*C2   ;  Natural_Frequency_Hertz := 723.8177791  65  Ł  cid:230  Ł - ł  cid:246  ł  cid:230   cid:231  Ł  cid:247  ł  cid:214  ‘ ‘ ‘ ‘ ‘  cid:237   cid:253   cid:254   Applied Maple for Engineers and Scientists  which is acceptable, since this does not attenuate the 500-Hz signal, retains the Butterworth response, and produces 5 dB more attenuation at the 5-kHz interference spectral location.  The ﬁnal Butterworth LPF ﬁlter design that incorporates all of the pre-  vious customer requirements is as follows:  1% metal 1% metal  film film  = 19KW = 12.7KW = .02m F = .01m F  R1 R2 C1 C2  Now, let’s use the test setup with these new design values and see what  the output appears as.  w with plots :  with inttrans : F1 := 500: F2 := 5000: Signal_1 := sin 2*Pi*F1*t : Signal_2 := sin 2*Pi*F2*t : Channel_Signal := Signal_1 + Signal_2: Channel_Signal_Laplace := expand laplace   Channel_Signal,t,s  :  LPF_Transfer := 1  R1*R2*C1*C2*s^2+ R1*C2+R2*C2 *s+1 : LPF_Transfer_Subs := subs R1=19*10^3,R2=12.7*10^3,  C1=.02*10^ -6 ,C2=.01*10^ -6 ,LPF_Transfer :  Filter_Output_Laplace := Channel_Signal_Laplace*  LPF_Transfer_Subs:  Filter_Output_Time :=  evalf simplify invlaplace  Filter_Output_Laplace,s,t   :  Filtered_Plot :=  plot Filter_Output_Time,t=0..2* 1 500 , style=line,color=black :  Unfiltered_Plot := plot Channel_Signal,t=0..2* 1 500 ,  linestyle=2,color=black,numpoints=512 :  display {Filtered_Plot,Unfiltered_Plot},axes=boxed,  labels=[Time,Output] ;  66  ﬁ ﬁ  Active ﬁlter design and analysis  Output  0  2  1  -1  -2  0.001  0.003  0.004  0.002  Time  Figure 2.6 Final Butterworth LPF design  filtered signal [500 Hz], solid line; unfiltered signal [500 Hz + 5000 Hz], dashed line .  Compare Figure 2.6 to Figure 2.5 and there are two immediate obser-  vations. First, the ﬁltered output  solid line  is somewhat smoother in Figure 2.6 and, second, there is a slightly greater phase shift between the ﬁltered and unﬁltered signals in Figure 2.6. The extra smoothness in Figure 2.6 is directly attributable to the added ﬁltering  5 dB more  of the 5-kHz interference signal. The added phase shift is again caused by the ex- tra low-pass ﬁltering and should not be a surprise.  In brief, we have gone through two iterations of the Butterworth LPF to improve on the required electronic components and a third iteration to accommodate the added 5 dB at 5-kHz attenuation required in the cus- tomer’s updated requirement.  Unit step response Another important aspect of ﬁltering is the ﬁlter’s step response. This measure indicates how well a ﬁlter allows rapidly changing signals to be re-  67   Applied Maple for Engineers and Scientists  constructed after ﬁltering. Obviously, a low-pass ﬁlter is not going to pass a fast transition very well by deﬁnition; however, with that said, certain step responses are still required of LPFs even when one is trying to suppress high-frequency noise.  Using our previously described Butterworth 1-kHz LPF, let’s intro-  duce the step function:  VIN  =  cid:236   0 1  t < 0 t ‡ 0  The Laplace transform of this is simply  L [VIN  = Unit step] = 1 s  then recomputing the Butterworth LPF’s output with the step input, we get  w with plots :  readlib laplace : R1 := 19*10^3: R2 := 12.7*10^3: C1 := .02*10^ -6 : C2 := .01*10^ -6 : LPF_Transfer := 1  R1*R2*C1*C2*s^2+ R1*C2+R2*C2 *s+1 :  Multiplying by the input step transform yields the output Laplace  expression  w Output_Laplace := LPF_Transfer* 1 s ;  Output_Laplace :=  1  Ł .4826000000 10  - 7 s2 + .0003170000000 s + 1 cid:246   s  and taking the inverse transform gives the ﬁnal equation for the output’s time domain response, Output_Time,  68   cid:237   cid:238   cid:252   cid:253   cid:254   cid:230  ł  Active ﬁlter design and analysis  w Output_Time := invlaplace Output_Laplace,s,t ;  Output_Time := 1. - 1. e  1.042002364 e  - 3284.293411 t    - 3284.293411 t  cos 3151.905911 t   sin 3151.905911 t   Not surprisingly, we have the unit output with two exponentially de-  caying sinusoidals. Plotting this result shows one of the reasons why Butter- worth ﬁlters are not the best for maximally ﬂat transient response.  Unit_Step := 1: Step_Plot := plot Unit_Step,t=0..+.002,linestyle=3,  w with plots :  color=black :  Response_Plot :=  plot Output_Time,t=0..+.002,style=line, color=black :  display {Step_Plot,Response_Plot},axes= boxed,labels=  [Time,Output] ;  Figure 2.7 shows a substantial overshoot at around 0.001 second,  which is caused by the group phase delay associated with any LPF topol- ogy. Butterworth ﬁlters are maximally ﬂat passband magnitude, not phase, ﬁlters. Thompson or Bessel ﬁlters, which have a small amount of passband magnitude ripple, will give much smoother phase response to fast or tran- sient signals. In fact, these ﬁlter topologies are known as maximally ﬂat phase ﬁlters [3,4].  Conclusion In this section, Maple has allowed the us to characterize, analyze, and de- sign the dynamics of the Butterworth LPF in terms of:  1. The overall transfer function; 2. Optimized component values that are physically realizable; 3. 4. 5. Viewing the LPF’s time-domain unit step response.  Altered design values in order to change the LPF’s response;  LPF sensitivity to component values;  69  -  Applied Maple for Engineers and Scientists  Output  1  0.8  0.6  0.4  0.2  0  0  70  0.005  0.0015  0.002  0.001  Time  Figure 2.7 Butterworth LPF step response  cutoff = 723.81 Hz .  Maple has the great ability to exercise any dynamic topology  in  this case, a linear electronic circuit  under any number of interesting condi- tions. In the case of the Butterworth LPF, we chose a rather common appli- cation of interference signal attenuation. We arbitrarily created a desired and undesired signal channel and simulated the Butterworth LPF’s func- tion. Then with Maple’s symbolic, numeric, and graphic capabilities, we were able to see and test the results of our design and how sensitive the de- sign was to real component values. This, in turn, helps the designer realize the eﬃcacy of the chosen LPF, the component values, and the topology’s relative sensitivity to component variations.  Admittedly, we reused many Maple command lines repetitively  throughout this and other sections, but with one speciﬁc purpose in mind. The more the user sees certain command structures, the more those basic structures should become instinctive when used for more advanced and general-purpose applications.   Active ﬁlter design and analysis  Case II: comb filter analysis and design  A very interesting set of ﬁlters has been derived using switched capacitor circuits. These ﬁlters have the desirable property of programmable attrib- utes such as passband gain, cutoﬀ frequency, and other features completely speciﬁed by a simple digital clocking signal. One of the more common im- plementations of this idea uses a charge-coupled device  CCD  technology. This approach is fabricated in silicon and is functionally equivalent to a se- ries of capacitors that moves their respective signal charge via a discrete clocking signal from one end of a serial register to the opposing end as shown in Figure 2.8. The reader should note that Figure 2.8 is only a crude model of how real CCD technology is implemented, but this simple model will suﬃce for our analysis purposes.  Table 2.3 shows the basic description of the switches  S1, S2, S3, ...,  Sn  as a function of the clocking period  1 Fclock .  Upon the nth clock period, the signal is entered into the output buﬀer  by switching to Sn’s “0” state. Consequently, after n clock periods, the CCD register is completely updated with new values introduced by the input buﬀer  provided we have a one translation per clock signal . In essence, you have an analog ﬁrst-in ﬁrst-out register or FIFO. The CCD shift registers come in a variety of sizes starting with as few as 64 cells and increase all the way up to around 16,000 cells as well as some serial-paral- lel combinations for producing serial-in parallel-out protocols.  Signal direction flow  1  0  +  1  0  1  0  +  +  1  0  Output buffer  +  S1  C  S2  C  S3  C  Sn  C  Input buffer  +  Fclock  Sequential logic  Figure 2.8 Basic circuit model of a serial CCD.  All amplifiers have a +1 gain  71   Applied Maple for Engineers and Scientists  Table 2.3 Switch states for CCD model  Clock period  0  1  2  3  n  n_1  where  Switch states  S1  S2  S3  …  Sn  1  0  0  0  0  1  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  Filter derivation and analysis A simple analog model of this delay element can be stated as  f t - T    T = No. of CCD cells  Fclk  Taking the Laplace transform with Maple of this delay element yields  w with inttrans :  t=0..infinity  ;  Time_Delay_Integrate := simplify int f t-T *exp -s*t ,  Time_Delay_Laplac  e := expand laplace F t-T ,t,s  ;  Time_Delay_Integrate :=  cid:242   f t - T   e   - st   dt  0  Time_Delay_Laplace := Laplace  F t - T  , t, s   72  ¥  Active ﬁlter design and analysis  Unfortunately, Maple cannot evaluate this transform with either the deﬁnition form, Time_Delay_Integrate, or through the internal li- brary, Time_Delay_Laplace. Consequently, we need to look it up in a mathematics table, which will show you that the following is a Laplace transform of the general delay function:  L f  t - T    = e  - sT  The comb ﬁlter uses this delay element in a classic feedback topology that is used to create a periodic passband transfer function. Graphically, this control diagram appears as shown in Figure 2.9. In Figure 2.9, the feedback gain, a  , has the adjustable range  0 £  < 1  The feedback cannot be allowed to reach unity due to the generation  of a sustained output with no input  oscillation . However, in some de- signs, this aspect is desired.  Input  S+  Delay element  Output  Figure 2.9 Control diagram of comb filter.  The overall transfer function of Figure 2.9 then becomes  H s  =  e  - sT 1 + a e  - sT  Entering this expression into Maple a  alfa  73  a ﬁ a -  Applied Maple for Engineers and Scientists  w H_Laplace :=  exp -s*T    1+alfa*exp -s*T  ;  H_Laplace :=   - sT  e 1 + alfa e   - sT   upon substituting s = Iw  into the transfer expression, we obtain  w H_JW := subs s=I*w,H_Laplace ;  H_JW :=   - I w T  e 1 + alfa e   - I w T   Taking advantage of Euler’s identity, which states the following:  jw T = cos w T   –  e  j sin w T    and substituting this identity into the H_JW expressions and simplifying, we get these results:  w H_Euler := subs exp -I*w*T =cos w*T -I*sin w*T ,H_JW ;  H_Euler :=  cos wT   -  I sin wT    1 + alfa  cos wT   -  I sin wT     Remembering that Maple uses “I” instead of “j” to represent an imagi-  nary quantity, we evaluate the transfer function’s magnitude response:  w H_Mag := simplify evalc abs H_Euler   ;  H_Mag :=  cid:214   1  1 + 2 alfa cos wT   + alfa2  Determining the maximal responses requires us to substitute a dummy variable for the wT product in the H_Mag expression, then take the deriva- tive with respect to that dummy variable:  74  – ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Active ﬁlter design and analysis  wT = A  d H_Mag   d A   = 0  and then substitute the value of wT into the H_Mag expression. Therefore,  w H_Mag_A := subs w*T=A,H_Mag :  H_Mag_Derivative := diff H_Mag_A,A ;  H_Mag_Derivative :=  alfa sin A   1  alfa2 + 2 alfa cos A  + 1  Ł alfa2 + 2 alfa cos A  + 1 cid:246   2  and solving for the variable A that will gives us zero derivative,  w Solution := solve H_Mag_Derivative=0,A ;  Solution := p  , 0  However, we do not know which value corresponds to the maximum rather than the minimum associated with the valleys between peaks. There- p ] values to fore, we should take a second derivative and substitute the [0, determine which value is referring to the maximum. To facilitate this com- putation, we will arbitrarily assign alfa =.50 so the derivative test func- tions evaluate numerically. This is acceptable, because alfa aﬀects not the location but the heights of the maximal peaks.  w H_Mag_Derivative_2 := diff H_Mag_Derivative,A :  H_Mag_D1 := evalf subs A=0,alfa=.5, H_Mag_Derivative_2  ; H_Mag_D2 := evalf subs A=Pi,alfa=.5, H_Mag_Derivative_2  ;  H_Mag_D1 := .1481481482 H_Mag_D2 := - 4.000000000  75   cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:230  ł  Applied Maple for Engineers and Scientists  Clearly, the second computation, H_Mag_D2, indicates the negative , hence the maximal peaks are at the odd inte-  change when evaluated at p ger multiples of p or A = p A =  2N + 1 p where N = 0, 1, 2, 3, …  , … or  , 3p  , 5p  So now, let’s redeﬁne the H_Mag expression by substituting this peri-  odic function for the dummy variable, A,  w H_Mag := subs A= 2*N+1 *Pi,H_Mag_A ;  H_Mag :=  cid:214   alfa2 + 2 alfa cos  2 N + 1  p  + 1  1  To get a sense of how this ﬁlter’s transfer function behaves, let’s plot  several graphs onto one common plot with various values of alfa:  w with plots : alfa := .25: Plot_1 := plot H_Mag,N=0..2,color=black,style=point,  alfa := .50: Plot_2 := plot H_Mag,N=0..2,color=black,style=point,  symbol=cross :  symbol=diamond :  alfa := .75: Plot_3 := plot H_Mag,N=0..2,color=black,style=point,  symbol=circle :  display {  Plot_1,Plot_2,Plot_3},axes=boxed,  labels=[N_Value,MAG] ;  Figure 2.10 shows each discrete resonant peak whose amplitude or gain function within any peak region is greatly aﬀected by the alfa vari- able. In fact, the peak value is completely determined by this variable.  To get an even larger picture of the comb ﬁlter’s behavior let’s produce a 3-D plot of the transfer function’s response versus alfa and N. First we must redeﬁne alfa as a variable, since this Maple session remembers it as a numerical value  namely, alfa=.75 from Figure 2.10 :  76  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Active ﬁlter design and analysis  3.5  2.5  4  3  2  1.5  1  MAG  0.5  1  1.5  2  N_Value  Figure 2.10 General comb filter response for various values of Alfa  alfa =.75, circles; alfa =.50, diamonds; alfa = .25, crosses .  w alfa := ‘alfa’:  plot3d H_Mag,alfa=.25..+.75,N=0..2,color=black,  style=hidden,axes=boxed,labels=[alfa,N_Value,MAG] ;  Notice that the peak locations in Figure 2.11 do not change with alfa; however, as stated, the magnitude of the peak responses is greatly aﬀected. Also, the general shape about any peak is identical and not a function of lo- cation, but, again, of the variable alfa.  Determining the peak response value for any peak is simply H_Mag  evaluated by any integer value of N, hence,  w H_Mag_Peak_Value := subs cos  2*N+1 *Pi =-1,H_Mag ;  H_Mag_Peak_Value :=  cid:214   alfa2 -  1 2 alfa + 1  77  ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  3.5  2.5  4  3  2  1.5  1  MAG  Figure 2.11 3-D plot of the comb filter’s response.  0  0.5  1  N_Value  1.5  0.6  0.5 alfa  0.7  2  0.5  0.4  Warning: a common pitfall associated with plotting At this point, the author would like to point out a common error associated with deriving graphic results without having some a priori knowledge about the problem.  Let’s replot Figure 2.11, but give it many more peaks, say, N = 10, and  produce the corresponding 3-D plot over the same range of alfa.  w plot3d H_Mag,alfa=.25..+.75,N=0..10,color=black,  style=hidden,axes=boxed,labels=[alfa,N_Value,MAG] ;  Figure 2.12 shows that we have 11 peaks, which is correct  N=0,1, 2,  3, ..., 10 , but the peaks are badly distorted. So what happened? The mathematics are correct, but the graphics are undersampled for the func- tion being plotted. What this means is when you have 11 peaks, we should have a resolution  at least in the N_Value axis  of twice this value  the sam- pling theorem strikes again! . Maple has a default 3-D plotting grid of 25 × 25, which, in this case, was suﬃcient to show the peaks’ existence, but not of suﬃcient quality to depict the equally high and spaced proﬁles we expected. Hence, replotting Figure 2.12 with an increase in the resolu- tion using the grid plotting option should increase the quality of the dis- torted peaks.  78   Active ﬁlter design and analysis  3.5  2.5  4  3  2  1.5  1  MAG  Figure 2.12 3-D plot of comb filter response.  0  0.5  1  N_Value  1.5  0.6  0.5 alfa  2  0.7  0.5  0.4  w plot3d H_Mag,alfa=.25..+.75,N=0..10,color=black,  style=hidden,axes=boxed,labels=[alfa,N_Value,MAG], grid=[50,50] ;  Figure 2.13 deﬁnitely shows higher quality information, but the peaks are still badly distorted because we are not seeing the equally peaked reso- nant peaks associated with the comb ﬁlter. It appears that simply doubling the resolution is not quite good enough resolution to show graphically the 11 peak responses. Hence, we increase the resolution to GRID=[100,100]:  w plot3d H_Mag,alfa=.25..+.75,N=0..10,color=black,  style=hidden,axes=boxed,labels=[alfa,N_Value,MAG], grid=[100,100] ;  Figure 2.14 is much better, but, again, one could come to a false con-  clusion about the ﬁlter’s response over this resonance range.  If we were to increase the 3-D resolution to 200 × 200, we would see  pretty much what is shown in Figure 2.14, but at a much heavier  four times heavier  computational cost to our computer’s resources. The lesson here is simple: Display only what you need to display and have a little a pri- ori knowledge about your problem. These simple rules will keep you from getting erroneous results.  79   Applied Maple for Engineers and Scientists  3.5  2.5  4  3  2  1.5  1  MAG  3.5  4  3  2  1.5  1  2.5  MAG  Figure 2.13 3-D plot of comb filter response with the GRID=[50,50] option.  0  0.5  1  N_Value  1.5  0.6  0.5  alfa  2  0.7  0.5  0.4  0  0.5  1  N_Value  1.5  0.6  0.5  alfa  2  0.7  0.5  0.4  Another approach that is extremely useful is that, because we do not  need high resolution along the alfa axis, we could have speciﬁed a GRID=[200,25] plotting option. This would greatly reduce computa- tional resources  one-eighth that of the 200 × 200 grid plot  and still allow us to visualize graphically the comb ﬁlter’s response.  Figure 2.14 3-D plot of comb filter response with the GRID=[100,100] option.  80   Active ﬁlter design and analysis  Separating a known signal from an interfering neighboring background design Now returning to our comb ﬁlter analysis, suppose we want to examine how much ﬁltering of a signal from an interfering neighboring signal we can derive by using this type of ﬁlter.  Figure 2.15 shows the experimental test setup we are going to emulate  with Maple. Further, let’s deﬁne the input signals as follows:  Signal 1 = sin 2p Signal 2 = sin 2p  100t  200t   Since we want to recover the signal 1 sinusoidal, the comb ﬁlter  should have its peak centered at signal 1’s value. At this point, we need to deﬁne the wT argument as  wT = 2p fT  Signal 1  Signal 2  Comb filter  Signal 1  Figure 2.15 Signal separation application.  Signal 1 = Desired signal Signal 2 = Interfering signal  where, in particular,  w = 2p fi T = No. of CCD cells  fclk  fi fclk  Information frequency CCD clocking frequency  Effective CCD time delay  81  · · ﬁ ﬁ ﬁ S  Applied Maple for Engineers and Scientists  We deﬁned this at the peak response when the sinusoidal argument  was deﬁned by  wT =  2N + 1  p  where N = 0, 1, 2, 3, …  but now we need to implement the variables associated with the physical device.  The variable T is deﬁned as the total delay with the CCD, which is a  function of both clocking speed, fclk, and number of delay cells,  number of CCD cells . Substituting this knowledge into the wT expression results in  wT = 2p fN  Cells fclk  +  2N + 1 p  Therefore, solving for fN yields  = 2N + 1  2T  fN  Further, since the number of CCD delay cells can be made arbitrary without aﬀecting the quality of the analysis, let’s give it an arbitrary value of 1000  actually, most real units have 1024 as a normal cell count . Substi- tuting this fact into the fN expression gives the location  in hertz  of the comb ﬁlter’s peak responses as a function of the clocking rate and peak harmonic, N:   Hz  = 2N + 1  fN  2  2  = 2N + 1  fclk Cells  fclk 1000   2N + 1  fclk  =  2000  82   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  Active ﬁlter design and analysis  Finally, we give the fundamental and harmonic peak centers and the as-  sociated frequencies for this physical design in Table 2.4.  N  fN  Hz   Frequency passed  Hz   Table 2.4 Relationship between fundamental and harmonic peak centers and associated passed signals  based on 1024 cells   0  fundamental   1  third harmonic   2  fifth harmonic   fclk 2000  3fclk 2000  5fclk 2000  100  300  500  From Table 2.4, we see that the following is true if the CCD’s clocking  speed is set to acquire the fundamental  i.e., N = 0 :  fclk 2000 fclk  = 100 or = 200 kHz  Now let’s set up the signals from before and compute the magnitude re-  sponse of the comb ﬁlter:  w with  inttrans :  H :=  cos w*T -I*sin w*T +alfa   alfa^2+2*alfa*cos w*T +1 : H_Mag := simplify evalc abs H   ;  H_Mag :=  cid:214   1  alfa2 + 2 alfa cos w T   + 1  Now we know from Table 2.4 that we need a clocking frequency of  200 kHz to acquire the desired signal  100 Hz  and maximally reject the in- terfering neighbor  200 Hz . Hence, we substitute this value, along with the CCD cell count to arrive at the eﬀective T value or  83  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  T = CCD cell count  =  fclk  100  200 kHz  = .005  also substituting  w = 2p f1  Hence, we put these values into the Maple H_Mag expression:  w H_Mag_General := subs T=.005,w=2*Pi*Fi,H_Mag ;  H_Mag_General  :=  cid:214   1  alfa2 + 2 alfa cos .010 p  Fi  + 1  We then compute the comb ﬁlter’s rejection ratio as deﬁned by  Rejection ratio = Passband response Stopband response  = H_Mag_General  Fi = 100 Hz  H_Mag_General  Fi = 200 Hz   for a given alfa and implement this deﬁnition in Maple:  w H_Mag_General_100 := subs Fi=100,H_Mag_General : H_Mag_General_200 := subs Fi=200,H_Mag_General : Rejection_Ratio := simplify H_Mag_General_100 H_Mag_General_200 ;  Rejection_Ratio =  1  1  alfa2 - 2. alfa + 1  alfa2 + 2. alfa + 1.  Let’s plot this function as a function of alfa to see what kind of values  we need to consider for suﬃcient attenuation of the neighboring signal  200 Hz .  84  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘  Active ﬁlter design and analysis  w plot Rejection_Ratio,alfa=0..+.9,color=black,axes=boxed,  labels=[alfa,RR] ;  It might be easier to replot Figure 2.16 with a log plot, since engineers  usually discuss ratios in terms of decibels  see Figure 2.17 . Hence,  w readlib log10 :  Rejection_Ratio_DB := 20*log10 Rejection_Ratio : plot Rejection_Ratio_DB,alfa=0..+.9,color=black,axes=boxed  labels=[alfa,DB] ;  Therefore, for a given rejection ratio, we can decide how much the neighboring signal needs to be attenuated. If the interfering signal were closer, say, at 120 Hz, we would have to operate much higher values of alfa  i.e., closer to unity , but with the disadvantage of amplitude stability at the desired signal.  RR  10  18  16  14  12  8  6  4  2  0.2  0.6  0.8  0.4  alfa  Figure 2.16 Rejection ratio  RR  between 100- and 200-Hz signals.  85   Applied Maple for Engineers and Scientists  dB  2525  20  15  10  5  0  86  0.2  0.6  0.8  0.4  alfa  Figure 2.17 Log plot of Figure 2.16.  An easier and more often used method for increasing the attenuation of very close signals is by cascading two or more comb ﬁlters. This method al- lows the use of more stable alfa values on a per-stage basis, while greatly increasing the attenuation of the unwanted neighboring frequency.  Cascading comb filters We can quickly look at the passband proﬁle result associated with two ﬁlters that are cascaded, because all of the constituent CCD switching ﬁlter equations are in Maple’s memory, and there is no need to derive any pre- vious relationships because that has already been done for the single ﬁlter case. Therefore, assuming no loading of the ﬁlters  i.e., the output of the ﬁrst ﬁlter does not “see” the input impedance of the second ﬁlter … a valid approximation for real hardware , and identical ﬁlter topologies, the cas- caded transfer function can be simply stated from Figure 2.18.   Active ﬁlter design and analysis  Clocking frequency  Figure 2.18 Cascaded switching filter topology.  Input signal  Switching filter number 1  Switching filter number 2  Output signal  Enter into Maple the transfer function magnitude of the original ﬁlter  transfer function  w with inttrans :  H_Laplace :=  exp -s*T    1+alfa*exp -s*T  :  then obtain the magnitude  w H_JW := subs s=I*w,H_Laplace :  H_Euler := subs exp -I*w*T =cos w*T -I*sin w*T ,H_JW : H_Mag := simplify evalc abs H_Euler   ;  H_Mag :=  cid:214   1 + 2 alfa cos wT   + alfa2  Because this is the magnitude, we need only square the H_Mag and  substitute the sinusoidal argument function, wT =  2N + 1  p expressions, to obtain the two periodic transfer functions. Hence,  , into both  w H_Mag := subs w*T= 2*N+1 *Pi,H_Mag ;  H_Mag_Cascade := subs w*T= 2*N+1 *Pi,H_Mag^2 ;  H_Mag :=  cid:214  H_Mag_Cascade :=  1 + 2 alfa cos  2 N + 1 p  + alfa2  1 + 2 alfa cos  2 N + 1  p  + alfa2  1  1  1  87  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  We will use the same three alfa values as computed and displayed in  Figure 10, hence  w with plots : alfa := .25: Plot_1 := plot H_Mag_Cas- cade,N=0..2,color=black,style=point,symbol=cross : alfa := .50: Plot_2 := plot H_Mag_Cascade,N=0..2,color=black,style=point,  symbol=diamond :  alfa := .75: Plot_3 := plot H_Mag_Cascade,N=0..2,color=black,style=point,  symbol=c ircle :  display {Plot_1,Plot_2,Plot_3},axes=boxed,  labels=[N_Value,MAG] ;  Note the gain goes as the square, hence the selectivity is greater than the single ﬁlter stage. This is evident since the rate of change as you move along the x-axis in Figure 2.19 is greater than that in Figure 2.10. To prove this, let’s evalute the ratio of the two normalized  i.e., both transfers maxi- mized for unity  ﬁlter functions and plot the result as a function of diﬀerent alfas:  w H_Mag_Norm := H_Mag*abs alfa-1 :  H_Mag_Cascade_Norm := H_Mag_Norm^2: H_Mag_Ratio := simplify   subs w*T= 2*N+1 *Pi,H_Mag_Norm H_Mag_Cascade_Norm  ;  H_Mag_Ratio :=  cid:214  Ł 1 -  1 -  2 alfa cos 2 p N  + alfa2  2 alfa cos 2 p N  + alfa2 cid:246   ł     cid:239   alfa -  1  cid:239     1  Now plotting H_Mag_Ratio,  w with plots : alfa := .25: Plot_1 := plot H_Mag_Ratio,N=0..2,color=black,style=point,  symbol=cross  88  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:230   Active ﬁlter design and analysis  16  14  12  10  8  6  4  2  MAG  0  0.5  1.5  2  1  N_Value  Figure 2.19 General cascaded comb filter response for various alfa  alfa = .75, circles; alfa = .50, diamonds; alfa = .25, crosses .  Plot_2 := plot H_Mag_Ratio,N=0..2,color=black,style=point,  symbol=diamo   nd :  alfa := .75: Plot_3 := plot H_Mag_Ratio,N=0..2,color=black,style=point,  symbol=circle  :  display {Plot_1,Plot_2,Plot_3},axes=boxed,  labels=[N_Value,MAG] ;  Figure 2.20 shows that as we vary the alfa value, the ratio is always greater than unity, indicating that the denominator function  normalized cascaded transfer  is less than the numerator  normalized noncascaded transfer . Note further that at the passband peaks  N_Value=0, 1, 2, ... , the ratio must be unity because both functions were normalized for their maximums. Consequently, all values outside the peaks are ratiometrically greater than unity, indicating the cascaded switching ﬁlter has higher selec- tivity for any given alfa.  89   Applied Maple for Engineers and Scientists  MAG  4  7  6  5  3  2  1  0  90  0.5  1.5  2  1  N_Value  Figure 2.20 Ratio of single-to-cascaded transfer functions versus various values of alfa  alfa = .75, circles; alfa = .50, diamonds; alfa = .25, crosses .  Conclusion The idea of controlling the center or pass frequency by adjusting a digital clocking signal has great appeal for those of us involved with computer- controlled processes. Certainly, such a ﬁlter is extremely useful in the tele- communications business where sharp neighborhood signal rejection is important when a company is trying to squeeze as many voice channels onto one line a possible without crosstalk or aliasing taking place within any one isolated information band. Other immediate applications of the switching bandpass ﬁlter can be used in a tracking ﬁlter scheme where an input signal is tracked as the clocking frequency changes to maximize the received input signal. The correction or error signal generated would be fed to a voltage-controlled oscillator  VCO  that clocks the CCD. This, in eﬀect, is what your frequency-modulated  FM  receiver does, though not using CCD technology  primarily due to cost .  Maple allowed us to delve into some of the dynamics of the equations that describe CCD operation. From the manipulation of these equations,   Active ﬁlter design and analysis  we were able to ascertain operating parameters necessary to acquire a cho- sen frequency, while rejecting a close neighboring interfering signal. We were also able to see graphically what was happening in the neighboring spectrum  i.e., the rate of increasing attenuation around the centrally passed frequency .  As to the issue of cascading switching ﬁlters to enhance neighboring  signal attenuation, the basic premise of multiplying transfer function magni- tudes and Maple gave us a quick look into what improvements we can ex- pect without getting the user reinvolved with the constituent relationships. This saved a tremendous amount of time and eﬀort by not having to revisit the basic mathematical structures of the CCD switching ﬁlter.  [1] Tietze, U., and C. Schenk, Advanced Electronic Circuits, New York:  Springer-Verlag, 1978.  [2] Roberge, J. K., Operational Ampliﬁers: Theory and Practice, New  York: John Wiley & Sons, 1975.  [3] Weinberg, L., Network Analysis and Synthesis, New York:  McGraw-Hill Book Co., 1962.  [4] Krauss, H. L., C. W. Bostian, and F. H. Raab, Solid State Radio  Engineering, New York: John Wiley & Sons, 1980.  References:  91   Applied Maple for Engineers and Scientists Curve ﬁtting  Curve ﬁtting  Introduction  Chapter 3  The example we examine in this chapter is a typical situation that  scientists and engineers come in contact with during routine analy- sis of a new piece of equipment, phenomena, or an algorithm de-  velopment. There are two general types of data curve ﬁtting. The ﬁrst is involved with determining the best ﬁt given very few data points  a data- starved problem . The second type is used when there are thousands of data points  a data-rich problem . Generally, abstracting the desired infor- mation from each of these categories can be tedious and full of pitfalls in terms of what the observer believes he or she is getting. Beyond these two classiﬁcations of data ﬁtting, the reader should realize that we are going to talk about interpolators  i.e., estimators  as opposed to extrapolators  i.e., predictors , which could generate several books of information by themselves.  93   Applied Maple for Engineers and Scientists  Another important aspect about regression estimators is the cost func- tion used to determine “goodness of ﬁt” of the observed data to the model. Perhaps the most common is called the least squares error  LSE , which deﬁnes the error as  LSE = min  cid:229   observed - Ł yi  2  estimate cid:246  yi  N  i=1  Conceptually, an algorithm  and there are many  attempts to minimize  diﬀerential or error between the observed  yobserved  and estimated  yestimated  data at successive points along the modeled function. Another common cost or penalty function is deﬁned as the least median squares er- ror  LMSE , which is deﬁned as  LMSE = min  1 N -  N  1  i = 1  2 ø  observed - Ł yi  estimate cid:246  yi  In the LMSE cost function, the algorithm is always trying to minimize  the median or average of the squared error. Contrast this with the LSE, which minimizes the square error. The LMSE cost function gives much better robustness  less variance of error  when a few data points lie rela- tively far away from the majority of the rest. However, in this brief expose, we will use the more common LSE function without any loss of generality as it relates to curve-ﬁtting data. If the reader wants to use a more rigorous cost function, then the following Maple code needs only slight modiﬁca- tion to implement a more aggressive cost function. Several excellent refer- ences exist that give practical and theoretical explanations of what we will investigate in this section [1–3]. These references give typical and ad- vanced examples that the reader can try out on his or her own with Maple. Regardless of which cost function is used, the reader should be able to use the following Maple procedures to apply these principles to whatever he she is required to analyze or use for data design.  94   cid:230  ł Ø Œ º Œ Œ  cid:229   cid:230  ł œ ß œ œ  Case study: Gaussian peak estimator filter example with regressive curve fitting  Curve ﬁtting  Our ﬁrst example is of a data-starved variety in which we are trying to get the best precision possible for a peak intensity reading. Precision means the instrument has the ability to reproduce speciﬁc readings within certain tol- erances given a set of conditions. This aspect is of particular importance when absolutes are not necessary  except when calibrating the instrument at the beginning of an experiment . However, the instrument’s ability to re- produce readings  in this case, peak light intensity at a given wavelength  is crucial to the machine’s functional and economic viability.  The following data are taken from an atomic spectroscopy unit that  can spectrally detect very close wavelengths  excellent optical dispersion  for the purposes of determining what atomic elements exist in a sample mixture. The instrument’s ability to identify what elements are present is a direct function of how well the instrument can decipher and reproduce peak intensity readings.  For the ﬁrst “go through,” let’s take one data set from our new instru-  ment. In this situation, our instrument will only be allowed to obtain 16 peak intensities  it could be less . From these readings, we can assume that the intensity proﬁle is Lorentzian [1], i.e.,  Intensity profile ﬁ  I0[sinc x ]2  but a Gaussian proﬁle  Intensity profile ﬁ  I0ek1 k2 -  m   2  will be close enough to suit our requirements.  By assuming an intensity proﬁle, we can eliminate much of the deci- sion space that must be searched to arrive at the optimal regression coeﬃ- cients for our estimator. This statement says that the more we bias the intensity proﬁle to a known form, the less chance we have of getting ﬁnal re- sults that are far aﬁeld of the observed intensity proﬁle function.  Hence the strategy for us to follow is to determine what speciﬁc Gauss- ian proﬁle best ﬁts the observed intensity data. We do this by applying the general Gaussian proﬁle function:  Estimated intensity = k1ek2 x -  k3 2  95   Applied Maple for Engineers and Scientists  After ﬁnding the k1, k2, k3 coeﬃcients, via a Maple session, we will compare the estimated and actual intensity data to see how well the curve ﬁt worked.  Along with this approach, we will also approximate the Gaussian  proﬁle function with the same data using a nonlinear regression technique called the Levenberg-Marquardt algorithm  LMA . Finally, we will show the reader the more dangerous approach of using a high-order general poly- nomial, i.e.,  Estimated intensity = a0  + a1x + a2x2 + a3x3 + … + aNxN  for approximating the intensity proﬁle from the observed data. This is the most dangerous approach because the results can easily mislead the investi- gator as to the estimation obtained from the observations.  Starting the Maple regression session The very ﬁrst thing we need to do is to initialize Maple with the appropri- ate mathematics libraries required to perform the regression analysis. The libraries are [STATS]  statistics  and [PLOTS]  graphical output plot- ting . Remember that the user only needs to start these libraries once per Maple session. However, during this case study, as in other application chapters, the authors will reiterate the libraries so that the reader will asso- ciate certain Maple libraries with certain approaches used in the template applications.  Linear regression using a logarithmic representation of the Gaussian model  w with  stats : with  plots :  Next, enter the observable intensity data  Yvalues_raw  at uniform and discrete window step positions  Xvalues  into Maple:  w Yvalues_raw :=  [25059,34459,56923,109885,152544,198619,256505,  289850,295849,273272,225068,171780,126180,70684,43297, 25515];  Xvalues := [seq i,i=0..nops Yvalues_raw -1 ];  96   Curve ﬁtting  Yvalues_raw := [25059 , 34459 , 56923 , 109885 , 152544 , 198619 , 256505 , 289850 , 295849 , 273272 , 225068 , 171780 , 126180 , 70684 , 43297 , 25515] Xvalues := [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]  Since the linear regression algorithm cannot not directly deal with the  Gaussian exponential form, we need to convert the model into a linear com- bination of increasing polynomials by converting the raw intensity values  Yvalues_raw  to the natural logarithm form  Yvalues  or  Estimated Intensity = Yvalues_raw = k1ek2 x -  k3 2  Transform  a0  + a1x + a2x2  By taking the natural logarithm of the both sides  1n Yvalues_raw  = 1n  Ł k1ek2 x -  k3 2 cid:246   = 1n k1  + k2 x - = 1n k1  + k2x2 -  k3 2 2k2k3x + k2k32  Equating coeﬃcients from the general quadratic polynomial form gives  =  k2  = 2 k2k3  =  cid:230   a2 a1 a0  Ł k2k33 + 1n k1  cid:246   or grouping like powers of x, we obtain 1n Yvalues_raw  = Yvalues =  k2 x2 + 2 k2k3 x +  cid:230   Ł k2k32 + 1n k1  cid:246   Therefore, by taking the natural logarithm of the raw intensity data, we  perform regression on this data to the aforementioned quadratic polyno- mial. Let’s start by getting Maple to take the logarithm of the intensity data:  97   cid:230  ł ł ł  Applied Maple for Engineers and Scientists  w Yvalues := evalf transform[multiapply[ y -ln y ]]   [Yvalues_raw]  ;  Yvalues := [ 10.12898832  , 10.44752549 , 10.94945476 , 11.60718964 , 11.93520836  , 12.19914370 , 12.45490344 , 12.57711883 , 12.59760447  , 12.51822292 , 12.32415786 , 12.05396987 , 11.74546474  , 11.16597452 , 10.67583863 ,  10.14702179 ]  Now, to perform the least squares regression with the assumed quad- ratic polynomial function  y=a+b*x+c*x^2  and abstract the appropri- ate {a, b, c} regression coeﬃcients, we use the following code:  w eq_fit := fit[leastsquare[[x,y],y=a+b*x+c*x^2]]   [Xvalues,Yvalues] ;  a := coeff rhs eq_fit ,x,0 ; b := coeff rhs eq_fit ,x,1 ; c := coeff rhs eq_fit ,x,2 ;  a := 9.920667962 b := .689997947 c := -  .04516343047  eq_ﬁt := y = 9.920667962 + .689997947 x -  .04516343047 x2  Remembering how we obtained the logarithmic regression form, we  must now substitute these coeﬃcients back into the original Gaussian func- tion. This is accomplished by doing a little “back-of-the-envelope” algebra, which results in the following:  k2 = a2  k3 = a1 2a2  k1 = ea0  2 a2a1 4a2  therefore  therefore  Substituting the regression coeﬃcients back into the original Gaussian  form, we obtain the estimator function  Y_Estimated :  98  -  Curve ﬁtting  w Y_Estimated :=   exp a- b^2  4*c    *  exp c* x+b  2*c  ^2   ;  Y_Estimated := 283815.8695 e   -  .04516343047  x -  7.638900985 2    We can determine the x-value  X_Max_Value  by solving where  the derivative of the estimated intensity function  Y_Estimated_ Derivative  equals zero. Then, knowing this allows us to determine the approximate step position where the peak intensity  Y_Max_Value  ex- ists and its value:  w Y_Estimated_Derivative := diff Y_Estimated,x ;  X_Max_Value := solve Y_Estimated_Derivative=0,x ; Y_Max_Value := evalf subs x=X_Max_Value,Y_Estimated  ;  Y_Estimated_Derivative := 283815.8695  - .09032686094x + .6899979470   e  - X_Max_Value := 7.638900985Y_Max_Value := 283815.8695  .0451634307 x -  7.638900985 2   Plotting the curve fit and residual error Plotting the actual and estimated intensities versus window step position subjectively indicates how close an estimate or “ﬁt” we have accomplished  see Figure 3.1 :  w Data_Set := zip  a,b ->[a,b],Xvalues,Yvalues_raw :  Data_Plot := pointplot Data_Set,style=point,  symbol= circle,color=black :  Estimated_Plot := plot Y_Estimated,x=0..nops Yvalues_raw -1,  style=line,color=black :  display {Estimated_Plot,Data_Plot},axes=boxed,  labels= [Window_Step_Position,Intensity] ;  Now let’s code and plot the residual error between the estimated and  the actual intensity data as shown in Figure 3.2:  99   Applied Maple for Engineers and Scientists  Intensity  300,000  250,000  200,000  150,000  100,000  50,000  100  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.1 Estimated  solid line  and actual  open circles  intensity versus window step position  second-order polynomial Ln form .  w Estimator := y=Y_Estimated:  Transform_Equation := unapply rhs Estimator ,x : Estimated_Data :=  transform[apply[Transform_Equation]] Xvalues :  Residual_Error := transform[multiapply[ x,y ->x-y]]   [Yvalues_raw,Estimated_Data] :  Error_Set := zip  a,b ->[a,b],Xvalues,Residual_Error : Error_1 := pointplot Error_Set,style=line,color=black : Error_2 := pointplot Error_Set,style=point,symbol= circle,  display {Error_1,Error_2},labels=[Window_Step_Position,  color=black :  Intensity],axes=boxed ;   Intensity  10,000  5,000  0  - 5,000  - 10,000  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.2 Residual error between estimated and actual intensity versus window step position.  Now plotting residual error versus window step position as a relative  percentage error at each step, we generate Figure 3.3:  w Percent_Residual_Error := transform[multiapply[ x,y   ->   x-y  x *100]] [Yvalues_raw,Estimated_Data] :  Percent_Error_Set :=  zip  a,b ->[a,b],Xvalues,Percent_Residual_Error :  Percent_Error_1 := pointplot Percent_Error_Set,style=line : Percent_Error_2 :=  pointplot Percent_Error_Set,style=point,symbol=circle, color=black :  display {Percent_Error_1,Percent_Error_2},labels=  [Window_Step_Position,Percent_Error],axes=boxed ;  Curve ﬁtting  101   Applied Maple for Engineers and Scientists  Percent_Error  15  10  5  0  - 5  - 10  - 15  102  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.3 Percent relative residual error versus window step position  second-order fit .  Figure 3.3 indicates a fairly well behaved regression in terms of relative positional error. Notice that residual errors generally show up at the begin- ning and end, while retaining a fairly smooth error variance in the middle of the data set. Simply stated, the regression process is trying to “smooth” the data behavior, but until it gets a few starting pieces of data, it may wildly ﬂy around with a few data points in the beginning. Once the regres- sion has some extra data or trend momentum, it begins to calm down and settle about some mean or averaging process dictated by the cost function. The end of the estimation window exhibits a large excursion because the quadratic function has a certain amount of information bandwidth. Hence, when the data suddenly stop, the quadratic information ﬁlter has a tran- sient response. This fact becomes extremely evident with higher order polynomials and small data sets. The reader will experience this situation when we perform a regression with a high-order polynomial later in this section.   Curve ﬁtting  Obtaining peak intensity RSD by linear regression on multiple data sets If we have a number of runs or data sets of intensity data, we can determine the relative standard deviation  RSD  of the peak intensity associated with the regressive curve ﬁtter. Hence, let’s use a loop to abstract the data from 10 runs and perform the appropriate averaging of peak levels or maxima of the Gaussian-shaped intensity proﬁles.  Again, we initialize Maple for the libraries that are needed to perform  the peak estimator’s synthesis:  w with  plots : with  stats :  w Yvalues_raw 1  :=  To determine the estimator’s RSD capability, we ﬁrst start by entering  the 10 strings of window raw intensity data:  [25059,34459,56923,109885,152544,198619,256505,289850,295849,  273272,225068,171780,126180,70684,43297,25515]:  Yvalues_raw 2  := [16142,23101,37309,82903,123089,161534,223857,267502,294544,  296350,2        64693,226965,181950,119709,79059,52353]:  Yvalues_raw  3  := [23853,34409,54547,107772,147408,190335,253463,284703,293676,  284066,233891,184085,137663,82013,47451,28750]:  Yvalues_raw 4  := [42339,59722,87024,155752,204287,245568,290199,289464,272198,  246212,187953,141533,98621,56186,33778,21203]:  Yvalues_raw 5  := [86172,108518,147092,219739,259478,287404,301906,271885,  232533,18794 8,125513,83811,58396,29801,16991,11355]:  Yvalues_raw 6  := [72548,94368,133371,197988,249126,279774,292374,268231,  243549,200351,138546,94043,62918,32122,18877,12192]:  Yvalues_raw 7  := [48609,65256,94868,151736,203552,244670,289439,295627,282365,  253035,19195        5,140082,102895,54583,31780,19525]:  Yvalues_raw 8  := [16907,24572,39079,79189,121543,165090,225141,272662,295347,  296574,268700,216644,169936,106075,68572,43873]:  Yvalues_raw 9  := [6628,8489,13492,29828,50541,76777,130350,189591,224634,  103   Applied Maple for Engineers and Scientists  255294,288537,280874,270477,210871,163214,119500]:  Yvalues_raw 10  := [6337,8282,12323,27675,46061,71486,125680,173236,215764,  256192,290531,286705,277525,223899,177035,136611]:  Next, we generate a procedure called GaussianEstimator, which  will produce the following quantities  on a per-intensity-run basis  for us once we give the procedure a list of intensity values, Yvalues_raw.    The peak value for the intensity data set;   The data set variance between the estimation and actual data;   The data set standard deviation between the estimation and actual  data;    The residual error for the data set given in list form.  If you look closely, the following procedure is similar to the ﬁrst go  through of the estimator’s program structure. The diﬀerence now is the im- plementation of previous eﬀort into a Maple procedure. This approach is more eﬃcient with Maple’s  and your computer’s  resources than using a subscripted session where each Maple line of code generates a large array. Then by performing a do loop after the data set has been processed by the procedure, we can abstract the appropriate statistical information. This do loop will keep a record of each do loop pass in order to accumulate re- sults for each individual data set. This is necessary to compute averages, standard deviations, variances, and the like for the individual data sets as well as to generate the required database for interdata set analysis.  Yvalues,  eq_fit,  a,  b,  c,  X_Max_Value,  Y_Max_Value,  Estimator,  GaussianEstimator := proc Yvalues_raw    Declaration of local variables used in algorithm...  local Xvalues,   the sequenced window step positions   the logarithmic raw intensity values   least squares equation fit   zero order regression coefficient   first order regression coefficient   second order regression coefficient  Y_Estimated,   estimated intensity function  Y_Estimated_Derivative,   derivative of estimated function   window step position at estimated peak intensity   estimated peak intensity   interim equation  Transform_Equation,   interim equation  Estimated_Data,  Residual_Error,   estimated intensity for given window step position   residual error between estimated and actual intensities  Estimator_Variance,   variance of the residual error  104   Curve ﬁtting  Estimator_Standard_Deviation,  standard deviation of the estimator error  Residual_Error_Set,   residual error data set  indexer;   indexing variable  options ‘Copyright 1995 by Chris Tocci’;   Main Algorithm...  Xvalues := [seq indexer,indexer=0..nops Yvalues_raw -1 ]:  Yvalues := evalf transform[multiapply[ y ->ln y ]] [Yvalues_raw]  :  eq_fit := fit[leastsquare[[x,y],y=a+b*x+c*x^2]] [Xvalues,Yvalues] :  a := coeff rhs eq_fit ,x,0 :  b := coeff rhs eq_fit ,x,1 :  c := coeff rhs eq_fit ,x,2 :  Y_Estimated :=  exp a- b^2  4*c    *  exp c* x+b  2*c  ^2   :  Y_Estimated_Derivative := diff  Y_estimated,x :  X_Max_Value := solve Y_Estimated_Derivative=0,x :  Y_Max_Value := evalf subs x=X_Max_Value,Y_Estimated  :  Estimator := y=Y_Estimated:  Transform_Equation := unapply rhs Estimator ,x :  Estimated_Data := transform[apply[Transform_Equation]] Xvalues :  Residual_Error := transform[multiapply[ x,y ->x-y]] [Yvalues_raw,Estimated_Data] :  Estimator_Variance  := describe[variance] Residual_Error :  Estimator_Standard_Deviation := describe[standarddeviation] Residual_Error :  Residual_Error_Set := zip  a,b -[a,b],Xvalues,Residual_Error :  [Y_Max_Value,Estimator_Variance,Estimator_Standard_Deviation,Residual_Error_Set]:  end:  NOTE that in the last line of the Maple procedure, all of the important informa- tion is put together in a single list:  w [Y_Max_Value,Estimator_Variance,  Estimator_Standard_Deviation,Residual_Error_Set]:  where Y_Max_Value is the peak intensity within any one run, Estimator_Variance is the intensity variance between estimation and actual intensity data, Estimator_Standard_Deviation is the inten- sity standard deviation between estimation and actual intensity data, and Residual_Error_Set is the ordered pairs representing the windows step position and the corresponding intensity value diﬀerential between the estimation and actual.  Now, the do loop is used for abstracting and accumulating   indexing, if you like  the required statistical information from the GaussianEstimator procedure for each data set. We have incorpo- rated some line print commands  lprint  to report these previously men- tioned variables as the program goes through each loop iteration. These line prints can be useful when the user needs to see what is going on inside the loop during execution. Also, line printing, in this case, speciﬁcally  105   Applied Maple for Engineers and Scientists  gives the user important numerical or symbolic insight associated with each of the intensity data sets. This insight might be necessary if things do not make sense at the end of a Maple session. Get in the habit of line print- ing your values in Maple procedures and do loops until you are sure of the veracity of your results.  for n from 1 to 10 do  lprint ‘Intensity Data Set’,n :  Estimated_Yvalues_Peak n  := op 1,GaussianEstimator Yvalues_raw n   :  lprint ‘Estimated Peak is’,op 1,GaussianEstimator Yvalues_raw n    :  lprint ‘Estimator Variance is’,op 2,GaussianEstimator Yvalues_raw n    :  lprint ‘Estimator Standard Deviation is’,op 3,GaussianEstimator Yvalues_raw n    :  lprint ‘Residual Error Data Set for plotting purposes is as follows...’ :  lprint op 4,GaussianEstimator Yvalues_raw n    :  lprint ‘  ______________________________________________’ :  lprint ‘’ :  lprint ‘’ :  od:  Intensity Data Set  1  Estimated Peak is  283815.8723  Estimator Variance is  50163044.16  Estimator Standard Deviation is  7082.587208  Residual Error Data Set for plotting purposes is as follows...  [[0, 4712.42278], [1, -4314.89519], [2, -10585.59134], [3, 2498.3726], [4,  -3523.6542], [5, -8608.3845], [6, 5112.1444], [7, 11218.4699], [8, 13699.5998], [9,  12236.5170], [10, 4424.3144], [11, 1385.7233], [12, 5956.3119], [13, -6815.09532],  [14, -2346.06094], [15, 955.22218]]  ______________________________________________  Intensity Data Set  2  Estimated Peak is  288260.8159  Estimator Variance is  35235193.39  Estimator Standard Deviation is  5935.926132  Residual Error Data Set for plotting purposes is as follows...  [[0, 3011.29849], [1, -2785.20830], [2, -9607.34324], [3, 4730.30757], [4, 3342.9527],  [5, -7098.9760], [6, 5534.2348], [7, 7647.1998], [8, 10204.1923], [9, 10314.5978],  [10, 161.6716], [11, 2054.5480], [12, 6150.6093], [13, -6619.1958], [14, -4397.16492],  [15, 1666.56408]]  ______________________________________________           Intensity Data Set  10  Estimated Peak is  269799.2195  Estimator Variance is  151521708.2  Estimator Standard Deviation is  12309.41440  Residual Error Data Set for plotting purposes is as follows...  [[0, 2064.904548], [1, -566.056479], [2, -4759.16049], [3, -3066.54453], [4,  -5508.93017], [5, -9154.90192], [6, 8135.5349], [7, 13524.2144], [8, 13480.8444], [9,  17372.1348], [10, 27704.5001], [11, 17082.6882], [12, 19696.7633], [13, -5923.7953],  106   Curve ﬁtting  [14, -13925.5693], [15, -11293.8014]]  ______________________________________________  Finally, we compute the statistical information from Maple’s  do loop and computing the overall intensity peak average, Y_Max_Value_Average, the peak value standard deviation, Y_Max_Value_StanDev, and the desired RSD, Y_Max_Value_RSD, for all 10 data sets:  Digits := 4:  Y_Max_Average_Seq := [seq Estimated_Yvalues_Peak n ,n=1..10 ]:  Y_Max_Value_Average := describe[mean] Y_Max_Average_Seq ;  Y_Max_Value_StanDev := describe[standarddeviation] Y_Max_Average_Seq ;  Y_Max_Value_RSD :=  Y_Max_Value_StanDev Y_Max_Value_Average *100;  Y_Max_Value_Average  := 280900. Y_Max_Value_StanDev := 6855 Y_Max_Value_RSD := 2.440  Next, for comparison purposes, we abstract the maximum raw inten- sity values  Yvalues_raw_Max  from the individual data sets and com- pute the data’s RSD over 10 data sets in the same manner. Writing a quick Maple do loop for abstracting the peak intensity values from each of the 10 data sets yields the desired results:  w for m from 1 to 10 do  Yvalues_raw_Peak m  := op nops Yvalues_raw m  ,  sort Yvalues_raw m   :  od: Yvalues_raw_Peak_Seq := [seq Yvalues_raw_Peak m ,m=1..10 ]: Yvalues_raw_Peak_Average := evalf describe[mean]   Yvalues_raw_Peak_Seq  ;  Yvalues_raw_Peak_StanDev :=  evalf describe[standarddeviation]  Yvalues_raw_Peak_Seq  ;  Yvalues_raw_Peak_RSD := evalf  Yvalues_raw_Peak_StanDev   Yvalues_raw_Peak_Average *100 ;  and the output is:  Yvalues_raw_Peak_Average := 294200. Yvalues_raw_Peak_StanDev  := 3735 Yvalues_raw_Peak_RSD := 1.270  107   Applied Maple for Engineers and Scientists  As we can see, the RSD of the curve estimator  Y_Max_Value_RSD   is about half as good as the straightforward peak picking method or ap- proach  Yvalues_raw_Peak_RSD  of 10 successive windows. The rea- son is that the estimator depends on all data presented to the ﬁlter, whereas the simple peak detector approach, depends on only one value within the window.  The drawback to the peak detector method is if any one peak is bad it can signiﬁcantly aﬀect the overall RSD measurement. On the other hand, if any one, two, or even three measured values are bad, they are averaged against others in the window, hence their inﬂuence is reduced signiﬁcantly. Therefore, even though the estimator might not have the best RSD for one time, it will be much more robust under a much wider range of noisy win- dow data than the peak method.  Comparison of peak method versus regression for robustness against outlier data To prove this statement, let’s alter some of the previous data’s peak values to see the comparison of the estimator against the peak method  in other words, we artiﬁcially create outlier data .  First, we alter the ﬁrst two window data sets’ peak values by 10%, say,  make them 10% higher than actually measured, i.e.,  Yvalues_raw 1  peak  = 295849 to 325433.9 +10%  Yvalues_raw 2  peak  = 296350 to 325985.0 +10%   w Yvalues_raw 1  :=  [25059,34459,56923,109885,152544,198619,256505,289850,  325433.9,273272,225068,171780,126180,70684,43297,25515]:  Yvalues_raw 2  := [16142,23101,37309,82903,123089,161534,223857,267502,294544,  325985.0,264693,226965,181950,119709,79059,52353]:  Yvalues_raw 3  := [23853,34409,54547,107772,147408,190335,253463,284703,293676,  284066,233891,184085,137663,82013,47451,28750]:  Yvalues_raw 4  := [42339,59722,87024,155752,204287,245568,290199,289464,272198,  246212,187953, 141533,98621,56186,33778,21203]:  Yvalues_raw 5  := [86172,108518,147092,219739,259478,287404,301906,271885,  232533,187948,125513,83811,58396,29801,16991,11355]:  Yvalues_raw 6  :=  108   Curve ﬁtting  [72548,94368,133371,197988,249126,279774,292374,268231,  243549,200351,138546,94043,62918,32122,18877,12192]:  Yvalues_raw 7  := [48609,65256,94868,151736,203552,244670,289439,295627,282365, 253035,191955,140082,102895,54583,31780,19525]: Yvalues_raw 8  := [16907,24572,39079,79189,121543,165090,225141,272662,295347,  296574,268700,216644,169936,106075,68572,43873]:  Yvalues_raw 9  := [6628,8489,13492,29828,50541,76777,130350,189591,224634,  255294,288537,280874,270477,210871,163214,119500]:  Yvalues_raw 10  := [6337,8282,12323,27675,46061,71486,125680,173236,215764,  256192,290531,286705,277525,223899,177035,136611]:  Performing the same algorithm via the GaussianEstimator proce-  dure for the 10 intensity data sets, we get  Estimated_Yvalues_Peak n  := op 1,GaussianEstimator  w for n from 1 to 10 do   Yvalues_raw n   :  od:  computing the overall intensity average, standard deviation, and RSD of the intensity peaks over the 10 new data sets:  w Digits := 4:  n=1..10 ]:  Y_Max_Average_Seq := [seq Estimated_Yvalues_Peak n ,  Y _Max_Value_Average := describe[mean] Y_Max_Average_Seq ; Y_Max_Value_StanDev := describe[standarddeviation]   Y_Max_Average_Seq ;  Y_Max_Value_RSD :=  Y_Max_Value_StanDev   Y_Max_Value_Average *100;  and the output is:  Y_Max_Value_Average  := 281600. Y_Max_Value_StanDev := 7537. Y_Max_Value_RSD := 2.676  109   Applied Maple for Engineers and Scientists  The RSD value is only slightly higher this time  2.676% versus  2.440%  using the Gaussian estimator. This increase corresponds to an RSD increase of around 9.67%.  Now let’s see what happens when deriving the same measures with  only the peak intensity from each data set:  w for m from 1 to 10 do   Yvalues_raw m   :  Yvalues_raw_Peak m  := op nops Yvalues_raw m  ,sort  od: Yvalues_raw_P eak_Seq := [seq Yvalues_raw_Peak m ,m=1..10 ]: Yvalues_raw_Peak_Average := evalf describe[mean]   Yvalues_raw_Peak_Seq  ;  Yvalues_raw_Peak_StanDev := evalf describe  [standarddeviation]  Yvalues_raw_Peak_Seq  ;  Yvalues_raw_Peak_RSD := evalf  Yvalues_raw_Peak_StanDev   Yvalues_raw_Peak_Average *100 ;  and the result is:  Yvalues_raw_Peak_Average := 300200. Yvalues_raw_Peak_StanDev := 13310. Yvalues_raw_Peak_RSD  := 4.434  While the estimator’s RSD changed about +9.67%, the peak picked RSD changed by about +249.13%! Consequently, the estimator is clearly more dependent on the collective data set, whereas the peak method is de- pendent on one-out-of-N points.  Obviously, had we altered any of the data points around the peak, the  peak method would have shown no RSD change, whereas the estimator would have reﬂected some change. Therefore, the eﬃcacy of an estimator depends on whether the user has a very precise way of obtaining the peak value and how important nonpeak values are to one’s ﬁnal analysis. If the user has limited resources and an excellent peak detection hardware sys- tem, then the much simpler and faster peak detection method should be used. If, on the other hand, one requires peak data under a volatile data ac- quisition environment, then use the estimator approach for a more uniform RSD behavior under a much noisier set of conditions.  110   Curve ﬁtting  Problem data set for linear regression Now let’s look at a data set that can “confuse” an estimator based on the previous approach of taking the logarithm of the raw data values in order to implement a linear polynomial combination.  with  plots :  with  stats :  Yvalues_raw :=  [569322,647595,871287,904318,820139,700099,434252,216687,150058,81671,57118,32746,25717  17639,13063,11527]:  Xvalues := [seq i,i=0..nops Yvalues_raw -1 ]:  Yvalues := evalf transform[multiapply[ y ->ln y ]] [Yvalues_raw]  :  eq_fit := fit[leastsquare[[x,y],y=a+b*x+c*x^2]] [Xvalues,Yvalues] :  a := coeff rhs eq_fit ,x,0 ;  b := coeff rhs eq_fit ,x,1 ;  c := coeff rhs eq_fit ,x,2 ;  ‘—————————————————————————————————’;  ‘—————————————————————————————————’;  k1 := exp a- b^2   4*c  ;  k2 := c;  k3 := b  2*c ;  ‘Original Coefficients prior to performing the Log Conversion’;  ‘—————————————————————————————————’;  Y_Estimated :=  exp a- b^2  4*c    *  exp c* x+b  2*c  ^2   :  Y_Estimated_Derivative := diff Y_Estimated,x :  X_Max_Value := solve Y_Estimated_Derivative=0,x ;  Y_Max_Value := evalf subs x=X_Max_Value,Y_Estimated  ;  Data_Set := zip  a,b ->[a,b],Xvalues,Yvalues_raw :  Data_Plot := pointplot Data_Set,style=point,symbol=circle,color=black :  Estimated_Plot := plot Y_Estimated,x=0..nops Yvalues_raw -1,style=line,color=black :  display {Estimated_Plot,Data_Plot},axes=boxed,labels=[Window_Step_Position,Intensity],  title= ‘Estimated  line  & Actual  point  Intensity versus Window Step Position’ ;  Looking at only the numerical results of the LMS estimator’s output:  a := 13.76022887 b := - .084211727 c := - .01640900803  k1  := .1054179619 107 k2 := - .01640900803 k3 := 2.566021263  111   Applied Maple for Engineers and Scientists  X_Max_Value := - 2.566021263 Y_Max_Value  := .1054179619 107  The reason for this grossly inaccurate estimation is due to the fact that  taking the logarithm of the raw data creates increasingly larger errors for the window extremum. For instance, we can reverse the data sequence and get the same grossly inaccurate estimation, i.e.,  w Yvalues_raw :=  [11527,13063,17639,25717,32746,57118,81671,150058,216687,  43425 2,700099,820139,904318,871287,647595,569322]:  and the output  see Figure 3.4   a := 8.805026173 b :=.576481963 c := - X_Max_Value  := 17.56602143 Y_Max_Value  := .1054179640 107  .01640900774  Notice that the estimator puts the peak value exactly the same amount outside the window  2.566021 = 17.566021 - 15  in this case as it did during the previous estimation   - 2.566021 = 0 - 2.566021  when it esti- mated the peak before the window. Hence, one may deduce that the estima- tion error mechanism is the same and indeed it is.  The reason for the error is twofold: First, by taking the logarithm, you have compressed information, thereby forfeiting resolution of that informa- tion; and, second, after compressing the information, you are only obtain- ing one or two more data points before there is no more window data. This means that the regression mechanism does not have enough or suﬃciently new or updated information about phenomena information before it runs into the end of the data string. Consequently, with lower resolution and fewer pieces of information to compensate against the lower resolution, the regression process begins to become unstable. This type of regression er- ror is especially true of data-starved acquisition systems where the amount of data is so low that “recovering” from a few “wild” points can be nearly impossible. This eﬀect leads to the grossly inaccurate estimates shown previously.  112   Curve ﬁtting  Intensity  800,000  600,000  400,000  200,000  0  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.4 Estimated  solid line  and actual  open circles  intensity versus window step position.  Regression improvement by cheating or data stuffing Let’s prove the preceding statement by artiﬁcially increasing or stuﬃng the amount of information at the end of the window by attempting to follow the Gaussian proﬁle to see if our estimator performance improves.  w with  plots : with  stats : Yvalues_raw_new := [25717,32746,57118,81671,150058,216687,434252,700099,820139,  904318,887802,871287,759441,647595,608458,569322]:  Xvalues := [seq i,i=0..nops Yvalues_raw_new -1 ]: Yvalues := evalf transform[multiapply[ y -ln y ]]   [Yvalues_raw_new]  :  eq_fit := fit[leastsquare[[x,y],y=a+b*x+c*x^2]] [Xvalues,  Yvalues] :  a := coeff rhs eq_fit ,x,0 ; b := coeff rhs eq_fit ,x,1 ; c := coeff rhs eq_fit ,x,2 ;  113   Applied Maple for Engineers and Scientists  Y_Estimated :=   exp a- b^2  4*c    *  exp c* x+b  2*c  ^2   :  Y_Estimated_Derivative := diff Y_Estimated,x : X_Max_Value := solve Y_Estimated_Derivative=0,x ; Y_Max_Value := evalf subs x=X_Max_Value,Y_Estimated  ; Data_Set := zip  a,b ->[a,b],Xvalues,Yvalues_raw_new : Data_Plot := pointplot Data_Set,style=point,symbol=circle,  color=black :  Estimated_Plot := plot Y_Estimated,  x=0..nops Yvalues_raw_new -1, style=line,color=black :  display {Estimated_Plot,Data_Plot},axes=boxed,labels=  [Window_Step_Position,Intensity] ;  a := 9.786117301 b := .709475575 c := -.03230337911 X_Max_Value := 10.98144520 Y_Max_Value  := 874712.7975  Figure 3.5 indicates a better ﬁt; however, it also appears that we have extended the window. Unfortunately, this method is only useful for exem- plifying how sensitive the linear regression is to the initial and ﬁnal data in a data-starved situation. Obviously, one cannot artiﬁcially add data where there are no data without causing an immediate outcry from one’s profes- sional peers.  Fortunately, to circumvent this type of problem with certain data sets, one can use a nonlinear regression technique that does not rely on taking the logarithm or any other trick to convert the regression process into a lin- ear polynomial combination curve ﬁt.  Nonlinear regression: the Levenberg-Marquardt algorithm Rather than altering the original model to ﬁt into a function that can be rep- resented by a linear combinatorial polynomial, nonlinear regression uses the modeled equation  in our case, a Gaussian proﬁle  directly via gradient and diﬀerence equations. Nonlinear regressions move incrementally, con- stantly looking for changes in the residual errors  diﬀerence between the ac- tual and estimated values  and compensating accordingly to keep them at a minimum as deﬁned by some cost function and independent variable s .  114   Curve ﬁtting  900,000  800,000  700,000  600,000  500,000  400,000  300,000  200,000  100,000  Intensity  2  4  6  8  10  12  14  Window_Step_Positon  Figure 3.5 Estimated  solid line  and actual  open circles  intensity versus window step position  data shifting to improve regression curve fit .  In particular, the Levenberg-Marquardt algorithm  LMA  is one of the more commonly used nonlinear regression techniques today. The follow- ing LMA was developed by Dr. Jerome M. Lang at Waterloo Maple Soft- ware, Inc., and incorporates some initial Newtonian line searching to facilitate rapid location of the global optimization region associated with the solution.  For further reading about nonlinear optimization techniques, [1,2] are recommended.   w with  linalg : with  plots : with  stats : Digits := 5: LevenbergMarquardt:=proc expr,vars,initial,epsilon  local d, delta_f_k,  change in function   dimension  115   Applied Maple for Engineers and Scientists   correction vector   gradient function   function to minimize  delta_k, delta_q_k,  change in quadratic approximation to the func- tion f, f_k,  function at current point f_k_delta,  function at trial point g, g_k,  grad function at current point G, G_k,  hessian at current point H_k,  coeff matrix to solve for correction i, Id,  identity matrix loop_no, nu_k, r_k,  accuracy ratio measuring how close is the quadratic   loop number  line-search parameter   hessian function   counter  appx to the exact function   to go from user vars to ours   name of indexed variables to replace vars  var_subs, x, x_k;  current position options ‘Copyright 1994 by Waterloo Maple Software’; d:=nops vars ; var_subs:={seq vars[i]=x[i], i=1..d }; f:=unapply subs var_subs,expr , x ; g:=subs ‘_BODY’=convert linalg[grad] f x ,[x[1],x[2],x[3]] ,’list’ , ‘_PARMS’=x,_PARMS->array _BODY   ; G:=subs ‘_BODY’=convert linalg  [hessian] f x ,[x[1],x[2],x[3]] , ‘listlist’ ,’_PARMS’=x,_PARMS-array _BODY   ;   INITIALIZATION x_k:=linalg[vector] evalf initial  ; nu_k:=1.0; Id:=array identity,1..d,1..d ; r_k:=NULL;  for printing first time through delta_f_k:=infinity; if not nu_k>0  then ERROR ‘nu_k must be positive’  fi; userinfo 2, ‘stats’, ‘loop_no, f_k, delta_f_k, x_k, nu_k, r_k’ ;  MAIN LOOP for loop_no do   step 1  f_k:=f x_k ; g_k:=g x_k ; G_k:=G x_k ;  116   Curve ﬁtting  userinfo 2, ‘stats’, loop_no, f_k, delta_f_k, con-  vert x_k,’list’ ,  nu_k, r_k ;    step 2  do H_k:=linalg[matadd] G_k, Id, 1, nu_k ; if linalg[definite] H_k,’positive_def’  then break; fi; nu_k:=4*nu_k; od;  delta_k:=linalg[linsolve] H_k, linalg[scalarmul] g_k, -1  ;  if linalg[dotprod] delta_k,delta_k <epsilon^2 then break    step 3   STOPPING CONDITION  fi;    step 4  f_k_delta:=f linalg[matadd] x_k,delta_k  ; delta_f_k:=f_k_delta-f_k;  delta_q_k:=linalg[dotprod] g_k,delta_k +1 2*linalg[innerprod]    delta_k, G_k, delta_k  ; r_k:=delta_f_k delta_q_k;    step 5  if r_k< 4 then nu_k:=4*nu_k elif r_k3 4 then nu_k:=nu_k 2 else  nu_k is unchanged fi;    step 6  if r_k>0 then x_k:=linalg[matadd] x_k, delta_k ; else   x_k is unchanged fi;  od; [seq  vars[i]=x_k[i], i = 1..d ]; end: infolevel[stats] := 2;  This line gives the LMA’s output iteration toward the solution.  infolevelstats  := 2  Now with the LMA deﬁned, let’s recast the problem in a slightly diﬀer-  ent way. The LMA simply requires that we deﬁne the diﬀerence between the actual and estimated to be minimal, hence, the cost function to be mini- mized will be:  117   Applied Maple for Engineers and Scientists  Gaussian_Fit_Error_Squared =  k1ek2 x + k3 2 - Yvalues_raw 2  The variables to be varied are:  [k1, k2, k3]  and the initial starting point for these variables can be obtained from the previously performed regression; hence,  k1 initial  = .1054179587  cid:215  107 k2 initial  = - .01640900845 k3 initial  = 2.566021006  or  [.1054179587  cid:215  107, -  .01640900845, 2.566021006]  and an arbitrary error criterion of, say 1% or  .01  But we must ﬁrst get the original estimation form into a compatible  form for the LMA optimization. As stated, we deﬁned the cost function to be minimized as Gaussian_Fit_Error_Squared, which is equal to the diﬀerence squared between the actual and estimated values. The squar- ing prohibits any algebraically added values to create zero error  cost ; i.e., only zero diﬀerentials can contribute zero error.  w Yvalues_raw :=  [569322,647595,871287,904318,820139,700099,434252,216687,  150058,81671,57118,32746,25717,17639,13063,11527]:  Xvalues := [seq i,i=0..nops Yvalues_raw -1 ]: k1_initial := .1054179587*10^7: k2_initial := -.01640900845: k3_initial := 2.566021006: Yvalues_est := transform[multiapply[ x -> k1*exp -k2*   x-k3 ^2  ]] [Xvalues] :  Gaussian_Fit_Error_Squared := transform[multiapply  118   Curve ﬁtting   x,y - x-y ^2]] [Yvalues_raw,Yvalues_est] :  Sum_Gaussian_Fit_Error_Squared := evalf  add i,i=Gaussian_Fit_Error_Squared  :  LMA_Result := LevenbergMarquardt Sum_Gaussian_Fit_Error_  Squared,[k1,k2,k3],[k1_initial,k2_initial,k3_initial],.01 ;  Solutions := subs LMA_Result,[k1,k2,k3] : k1 := Solutions[1]; k2 := Solutions[2]; k3 := Solutions[3];  The output iteration associated with the LMA’s convergence toward  the minimal least squares error of the model with the data is  LevenbergMarquardt:  loop_no,  f_k,  delta_f_k,  x_k,  nu_k,  r_k  LevenbergMarquardt:  .34523e15  infinity  [.10542e7, -.16409e-1, 2.5660]  1.0  LevenbergMarquardt:  .12727e15  -.21796e15  [.10542e7, -.11988e-1, 2.3218]  .14075e15  1.2206  LevenbergMarquardt:  .50500e14  -.76770e14  [.10542e7, -.79964e-2, 2.1712]  .70375e14  1.2449  LevenbergMarquardt:  .21452e14  -.29048e14  [.10542e7, -.40671e-2, 2.0611]  .35188e14  1.2569  LevenbergMarquardt: +  .98006e13  -.11651e14  [.10542e7,  .150e-4,  1.9686]  .17594e14  1.2653  LevenbergMarquardt:  .47928e13  -.50078e13  [.10542e7,  .44776e-2, 1.8785]  .87970e13  1.2726  LevenbergMarquardt: +  7  .24521e13  -.23407e13  [.10542e7,  .96326e-2, 1.7784]  .43985e13  1.2774  LevenbergMarquardt: +  .12708e13  -.11813e13  [.10542e7,  .15893e-1, 1.6624]  .21993e13  1.2751  LevenbergMarquardt:  .68161e12  -.58919e12  [.10542 e7,  .23536e-1, 1.5475]  .10997e13  1.2611  LevenbergMarquardt:  .43731e12  -.24430e12  [.10542e7,  .32202e-1, 1.4993]  .54985e12  1.2504  LevenbergMarquardt:  .34121e12  -.9610e11  [.10542e7,  .42014e-1, 1.6618]  .27493e12  1.2472  LevenbergMarquardt: + 12.  .13940e12  -.20181e12  [.10542e7,  .65746e-1, 2.5901]  .13747e12  LevenbergMarquardt:  .80053e11  -.59347e11  [.10542e7,  .86241e-1, 2.9358]  .68735e11  .92799  .97217  LevenbergMarquardt:  .77059e11  -.2994e10  [.10542e7,  .91583e-1, 2.9134]  .34368e11  1.0506  1  2.  3.  4.  5.  6.  8.  9.  10.  11.  13.  14.  LMA_Result  := Ø  º k1 = .10542 107, k2 = .091583, k3 = 2.9134ø k1 k2 k3  := .10542 107 := .091583 := 2.9134  Now let’s plot this LMA regressed estimation model along with the  original data to see how the ﬁt appears:  w Estimated := k1*exp -k2* x-k3 ^2 :  Actual := zip  a,b -[a,b],Xvalues,Yvalues_raw : Estimated_1 :=  plot Estimated,x=0..nops Yvalues_raw -1,color=black, style=line :  119  ß  Applied Maple for Engineers and Scientists  Actual_1 := pointplot Actual,style=point,symbol=circle,  display {Estimated_1,Actual_1},labels=[Window_Step_Position,  color=black :  Intensity],axes=boxed ;  Figure 3.6 shows that the LMA did a reasonable job at modeling the data proﬁle with the Gaussian function. The primary danger with most nonlinear regression algorithms is one of initiation. Some nonlinear regres- sion techniques take a very long time to converge if they are initialized too far away from the solution region. Other nonlinear regression approaches can yield completely erroneous results if the initial starting points are too far from the solution space. That is why the reader should use a preﬁlter re- gression, even if it is wrong, as we did in this example. In that way, the non- linear regression has an excellent start due to close proximity to the solution space. This will reward the user with reasonably fast convergence and good results.  General polynomial regression  Another approach simply and blindly assumes the estimation can fol-  low a general polynomial form:  yestimate  = a + bx + cx2 + dx3 + ex4 + …  To show how easy this method is, let’s use the previously diﬃcult data  set that we had to curve ﬁt using the LMA:  w with  plots : with  stats : Yvalues := [569322,647595,871287,904318,820139,700099,434252,216687,  150058,81 671,57118,32746,25717,17639,13063,11527]:  Xvalues := [seq i,i=0..nops Yvalues -1 ]: eq_fit := fit[leastsquare[[x,y],  y=a+b*x+c*x^2+d*x^3+e*x^4+f*x^5+g*x^6]]  [Xvalues, Yvalues] :  a := evalf coeff rhs eq_fit ,x,0  : b := evalf coeff rhs eq_fit ,x,1  : c := evalf coeff rhs eq_fit ,x,2  :  120   Curve ﬁtting  Intensity  1e+06  800,000  600,000  400,000  200,000  0  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.6 LMA estimated  solid line  and actual  open circles  intensities versus window step position  residual square error constrained to 1% .  d := evalf coeff rhs eq_fit ,x,3  : e := evalf coeff rhs eq_fit ,x,4  : f := evalf coeff rhs eq_fit ,x,5  : g := evalf coeff rhs eq_fit ,x,6  :  Now that we have the regression coeﬃcients, solve for the multiple  peak values  Y_Max_Values  and their corresponding window step posi- tions  X_Max_Values  associated with the polynomial model:  w Y_Estimated := a+b*x+c*x^2+d*x^3+e*x^4+f*x^5+g*x^6:  Y_Estimated_Derivative := diff Y_Estimated,x : X_Peak_Values := [fsolve Y_Estimated_Derivative=0,x ]; for i from 1 to nops X_Peak_Values   do Y_Estimated_Peak i  := subs x=X_Peak_Values[ i ], Y_Estimated :  od:  121   Applied Maple for Engineers and Scientists  Y_Peak_Values := [seq Y_Estimated_Peak i ,i=1..nops   X_Peak_Values  ];  X_Peak_Values := [- 9.828839319 , 11.64172962 , 14.25935997]  .1370943937 , 2.951874268 ,  Y_Peak_Values := [554151.9313 , 899447.9633 , 36962.397 , 55348.95 , - 22785.75]  Note that some solutions to this sixth order are pure ﬁlter artifact from the regression process. The X_Peak_Values value equal to - .13709… and the Y_Max_Values value equal to - 22785.75 clearly do not repre- sent anything associated with the data set. The X_Max_Values artifact is noise because this ﬁlter is not a predictor  extrapolation , but an estimator  interpolation . The negative Y_Max_Values artifact is noise because there is no such thing as “negative” light  make sure during your modeling that you experience “reality checks” frequently! .  Now that we have the x-y values associated with the polynomial’s extrema, let’s abstract the polynomial’s result for the maximal intensity  Y_Max_Value  and its corresponding window step position  X_Max_Value :  w Zipped_Pairs :=  zip  x,y ->[y,x],X_Peak_Values,Y_Peak_Values :  Boolean_ Condition :=  a,b ->if op 1,a <op 1,b  then true else false fi: Sorted_Ordered_Pairs :=  sort Zipped_Pairs,Boolean_Condition :  XY_Max_Coordinate := op nops Sorted_Ordered_Pairs ,  Sorted_Ordered_Pairs :  Y_Max_Value := op 1,XY_Max_Coordinate ; X_Max_Value := op 2,XY_Max_Coordinate ;  Y_Max_Value  := 899447.9633 X_Max_Value  := 2.951874268  These x-y values graphically correspond to the data set peak fairly well  as shown in Figure 3.7 when we generate a composite curve ﬁt and data plot:  122   Curve ﬁtting  w Data_Set := zip  a,b ->[a,b],Xvalues,Yvalues :  Data_Plot := pointplot Data_Set,style=point,symbol=circle,  color=black :  Estimated_Plot := plot Y_Estimated,x=0..nops Yvalues -1,  style=line,color=black :  display {Es timated_ Plot,Data_Plot},axes=boxed,labels=  [Window_Step_Position,Intensity] ;  In Figure 3.7, note the rippling of the curve ﬁt due to the polynomial. Remember, a curve has N - 1 extrema, where N is the order of the func- tion. In this case, N = 6, hence there are 5 extrema of which 4 are clearly visible within the conﬁnes of the window and the ﬁfth is just starting to show at the window’s entry  i.e., Window_Step_Position =x=0 . By plotting the residual error between the actual and estimated data,  we can see where the interpolation errors are greatest. Also, when the user uses very high order polynomials, the residual error plot  Figure 3.8  will exhibit a large amount of “zigzag” behavior.  Intensity  800,000  600,000  400,000  200,000  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.7 Estimated  solid line  and actual  open circles  intensity versus window step position for general polynomial fit  sixth-order fit .  123   Applied Maple for Engineers and Scientists  Intensity  0  30,000  20,000  10,000  - 10,000  - 20,000  - 30,000  - 40,000  - 50,000  124  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.8 Residual error between estimated  solid line  and actual  open circles  intensity versus window step position  sixth-order fit .  w Estimator := y=Y_Estimated:  Transform_Equation := unapply rhs Estimator ,x : Estimated_Data :=  transform[apply[Transform_Equation]] Xvalues :  Residual_Error := transform[multiapply[ x,y ->x-y]]   [Yvalues, Estimated_Data] :  Error_Set := zip  a,b -[a,b],Xvalues,Residual_Error : Error_1 := pointplot Error_Set,style=line,color=black : Error_2 :=  pointplot Error_Set,style=point,symbol=circle,color=black :  display {Error_1,Error_2},axes=boxed,labels=  [Window_Step_Position,Intensity] ;   Curve ﬁtting  Now we plot residual error versus window step position as a relative  percentage error at each step:  w Percent_Residual_Error := transform[multiapply[ x,y   ->   x-y  x *100]] [Yvalues,Estimated_Data] : Percent_Error_Set := zip  a,b -[a,b],Xvalues,  Percent_Residual_Error :  Percent_Error_1 := pointplot Percent_Error_Set,style=line : Percent_Error_2 :=  pointplot Percent_Error_Set,style=point,symbol=circle, color=black :  display { Percent_Error_1,Percent_Error_2},labels=  [Window_Step_Position,Percent_Er ror],axes=boxed ;  Figure 3.9 shows a relatively large percent error at the end of the sam- pling window. As stated earlier, this eﬀect is typical of simple linear regres- sion type ﬁlters since there is no extra data beyond the window to average into the ﬁnal estimation. This causes a sort of burst or accumulation of er- ror to appear at the end of any simple polynomial regression ﬁt. Compare this plot to Figure 3.3 where a second-order ﬁt was accomplished. Notice that the relative percent error was smaller across the window. Clearly the jagged error eﬀect becomes worse with higher order polynomials and data that vary  whether actually or from measurement error  greatly from the previous few data points. Figure 3.3 showed a large jagged relative error at the beginning of the sampling window as opposed to Figure 3.9. This eﬀect happens because there are no “trend” data to start the regression, hence a rather large initial guess can be very wrong at the beginning of the sampling window. This, in eﬀect, is similar to the transient behavior associ- ated with circuits when they are exposed to any sudden change of the input.  The single biggest problem associated with the general polynomial ﬁt is the model’s ability to become noisy by responding to nearly every data point. What happens, simply, is that the polynomial regression tries to get every point it can within the conﬁnes of the polynomial’s order. For in- stance, if we had a tenth-order polynomial, the estimator curve could have a maximum of nine  10 - 1= 9  extrema. If we had 9 or fewer data points, this regression would nearly hit every point, thereby neutralizing any smoothing or averaging aspect of the estimator. In short, the estimator ﬁlter has too much bandwidth.  125   Applied Maple for Engineers and Scientists  Percent_Error  250  200  150  100  50  0  - 50  - 100  126  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.9 Percent relative residual error versus window step position  sixth-order fit .  High-order polynomial regression fit problems To the pitfall just mentioned that is associated with general polynomial curve ﬁtting, let’s take the last set of data and use an artiﬁcially high polyno- mial order, say, 12. Further, let’s allow one of the data points to be some- what of an outlier to show what happens when the bandwidth of the estimator is too high for useful purposes. We will choose a peak data point  Yvalues = 904318  and cut it in half  Yvalues = 452159  to represent a sin- gle data point that either exhibited a noise or measurement corruption:  w with  plots : with  stats : Yvalues := [569322,647595,871287,452159,820139,700099,434252,216687,  150058,81671,57118,32746,25717,17639,13063,11527]:  Xvalues := [seq i,i=0..nops Yvalues -1 ]:   Curve ﬁtting  eq_fit := fit[least- square[[x,y],y=a+b*x+c*x^2+d*x^3+e*x^4+f*x^5+g*x^6+h*x^7 + i*x^8+j*x^9+k*x^10+l*x^11+m*x^12]] [Xvalues,Yvalues] : a := evalf coeff rhs eq_fit ,x,0  : b := evalf coeff rhs eq_fit ,x,1  : c := evalf coeff rhs eq_fit ,x,2  : d := evalf coeff rhs eq_fit ,x,3  : e := evalf coeff rhs eq_fit ,x,4  : f := evalf coeff rhs eq_fit ,x,5  : g := evalf coeff rhs eq_fit ,x,6  : h := evalf coeff rhs eq_fit ,x,7  : i := evalf coeff rhs eq_fit ,x,8  : j := evalf coeff rhs eq_fit ,x,9  : k := evalf coeff rhs eq_fit ,x,10  : l := evalf coeff rhs eq_fit ,x,11  : m := evalf coeff rhs eq_fit ,x,12  :  Now that we have the regression coeﬃcients, solve for the multiple  peak values  Y_Max_Values  and their corresponding window step posi- tions  X_Max_Values  associated with the polynomial model:  w Y_Estimated :=  a+b*x+c*x^2+d*x^3+e*x^4+f*x^5+g*x^6+h*x^7+i*x^8+j*x^9 + k*x^10+l*x^11+m*x^12:  Y_Estimated_Derivative := diff Y_Estimated,x : X_Peak_Values := [fsolve Y_Estimated_Derivative=0,x ]; for i from 1 to nops X_Peak_Values   do Y_Estimated_Peak i  := subs x=X_Peak_Values[ i ], Y_Estimated :  od: Y_Peak_Values := [seq Y_Estimated_Peak i , i=1..nops X_Peak_Values  ];  X_Peak_Values := [- 11.70881911 , .3224662904 , 1.578737402 , 3.091536358 , 4.687042269 , 7.743771431 , 8.814838531 , 10.86172372 , 12.26584677 , 13.55914242 , 14.68280892 ]  Y_Peak_Values := [.2961197602 1012, 107056.6765 , 899412.4643 , 560382.9827 , 773676.2481 , 112923.53 , 143372.0 , 82580 , - 87660. , 434000 ]  - 14721.  ,  127   Applied Maple for Engineers and Scientists  Again note that some solutions to this twelfth-order problem show  strong ﬁlter artifact from the regression process. The X_Peak_Values value equal to - .11.70881911 and two Y_Max_Values values  - 14721 and - 87660  clearly do not represent anything associated with the ob- served data set. The ﬁrst Y_Max_Values value is quite high  .2961197602 × 1012 , which is a regression artifact when compared to the observed data. Consequently, the reader is again warned against accepting any regression result blindly without verifying the veracity of the output against the real data.  Now that we have the x-y values associated with the polynomial’s peaks, let’s abstract the polynomial’s result for the maximal intensity  Y_Max_Value  and its corresponding window step position  X_Max_Value . These x-y values graphically correspond to the data set peak fairly well as shown when we generate a composite curve ﬁt and data plot  Figure 3.10 :  w Data_Set := zip  a,b -[a,b],Xvalues,Yvalues :  Data_Plot := pointplot Data_Set,style=point,symbol= circle,  color=black :  Estimated_Plot := plot Y_Estimated,x=0..nops Yvalues -1,  style=line,color=black :  display {Estimated_Plot,Data_Plot},axes=boxed,labels=  [Window_Step_Position,Intensity] ;  Note the severe rippling of the curve ﬁt in Figure 3.10 due to the high- order polynomial. Remembering this curve has 12–1 or 11 extrema, 10 are clearly seen in Figure 3.9. Obviously, the eleventh extremum is outside the 16-step window, but we do not know on which side it exists.  Again, plotting the residual error between the actual and estimated  data, we can see where the interpolation errors are greatest  Figure 3.11 . Also, when the user uses very high order polynomials, the residual er-  ror plot will exhibit a large amount of zigzag behavior.  128   1e+06  800,000  600,000  400,000  200,000  - 200,000  - 400,000  - 600,000  - 800,000  Intensity  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.10 Estimated  solid line  and actual  open circles  intensity versus window step position for general polynomial fit  twelfth-order fit .  w Estimator := y=Y_Estimated:  Transform_Equation := unapply rhs Estimator ,x : Estimated_Data :=  transform[apply[Transform_Equation]] Xvalues :  Residual_Error := transform[multiapply[ x,y -x-y]] [Yvalues,  Estimated_Data] :  Error_Set := zip  a,b -[a,b],Xvalues,Residual_Error : Error_1 := pointplot Error_Set,style=line,color=black : Error_2 :=  pointplot Error_Set,style=point,symbol=circle,color=black :  Curve ﬁtting  129   Applied Maple for Engineers and Scientists  40,000  20,000  0  Intensity  - 20,000  - 40,000  130  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.11 Residual error between estimated  solid line  and actual  open circles  intensity versus window step position  twelfth-order fit .  display {Error_1,Error_2},labels=[Window_Step_Position, Intensity], axes=boxed ;  Again, plotting the residual error versus window step position as a rela-  tive percentage error at each step  Figure 3.12 :  w Percent_Residual_Error := transform[multiapply[ x,y -    x-y  x *100]] [Yvalues,Estimated_Data] :  Percent_Error_Set :=  zip  a,b -[a,b],Xvalues,Percent_Residual_Error :  Percent_Error_1 := pointplot Percent_Error_Set,style=line : Percent_Error_2 :=  pointplot Percent_Error_Set,style=point,symbol=circle,  color=black :   Curve ﬁtting  Percent_Error  200  150  100  50  0  - 50  0  2  4  6  8  10  12  14  Window_Step_Position  Figure 3.12 Percent relative residual error versus window step position  twelfth-order fit .  display  {Percent_Error_1,Percent_Error_2},labels= [Window_Step_Position,Percent_Error],axes=boxed ;  Again, note in Figure 3.12 the large jagged percent error toward the  end of the window. This indicates that for any window step position an er- ror between estimated and observed data will create a large “reaction” to the high-order polynomial. Again, because this high-order polynomial “ﬁlter” has the bandwidth to track the data, it can jump quickly from meas- ure to measure trying to compensate rather than smooth the result.  Quick moral about curve fitting Finally, the moral of the curve-ﬁtting story is that the reader should never arbitrarily use a higher order estimator than is necessary to smooth the data. Further, before using any regression, linear or otherwise, try to ﬁgure what the data are doing in a subjective way before you get into all the me- chanics of producing a large Maple session. Sometimes, and it is an art, a  131   Applied Maple for Engineers and Scientists  little human insight in the beginning is worth hundreds of hours and per- haps tens of thousands of dollars of eﬀort, after the fact.  Conclusion Maple has allowed us to see the eﬀects of using several diﬀerent regressors or estimators with a given set of data. What becomes clear is that whatever the user has for data determines which type of curve ﬁtting to use  i.e., sim- ple polynomial, nonlinear, or high-order polynomial . No software pack- age can take the place of human intuition and past experience with data structures when it comes time to use the correct curve-ﬁtting algorithm. However, when one has determined which type or even types have eﬃ- cacy, Maple can easily get the user up and running both numerically and graphically to produce the required insights and or algorithm implementa- tion. Contrast what we have done in this chapter with Maple as opposed to more conventional numerical packages on the market. Most C, C++, and nonsymbolic statistical packages can give you curve ﬁtting, but only a sym- bolic package can give a universal handle on the algorithmic engine in sym- bolic form that is understandable to the user. This fact is critical to the human comprehension of any underlying process, because, as humans, we are quicker to see a trend via symbolics rather than abstracting information associated with an analysis via a bunch of numbers. Maple allows the user to deal in concepts much more than any standard numerical only analysis package.  [1] Wadsworth, Harrison M.  ed. , Handbook of Statistical Methods for  Engineers and Scientists, New York: McGraw-Hill, 1990.  [2] Fletcher, R., Practical Methods of Optimization, 2nd Ed., New York:  John Wiley & Sons, 1987.  John Wiley & Sons, 1981.  [3] Draper, N. R., and H. Smith, Applied Regression Analysis, New York:  References  132   Applied Maple for Engineers and Scientists Mathematical models: working with differential equations  Chapter 4  Mathematical models: working with diﬀerential equations  An important part of the design process is the modeling and simula-  tion stage using a mathematical prototype. Once the basic frame- work of a prototype is in place, it is important to be able to  interrogate its state at any time during the simulation process, modify the model, and rerun it as necessary. The Maple system enables us to develop complex mathematical models, run them, analyze their output, modify them, and then rerun them easily.  In this chapter we take a brief look at some of the functions that Maple  provides for investigating diﬀerential equations. We analyze the time re- sponse of a tachometer needle using the series methods and develop and in- vestigate a shock absorber model. Maple’s ability to deal with both linear and nonlinear systems is addressed. The techniques used in this section are applicable to any dynamic system modeled using diﬀerential equations, not just to the control systems that are discussed in the examples.  133   Applied Maple for Engineers and Scientists  ODE tools: a tour  The most commonly used tool is the dsolve function. In addition, the DEtools, Difforms, and Liesymm packages contain functions that can be used to manipulate both ordinary diﬀerential equations  ODEs  and par- tial diﬀerential equations  PDEs . The Liesymm package is not considered further because it is beyond the scope of this book.  The dsolve function Maple’s standard tool for solving ODEs either symbolically or numerically, is the dsolve function. In the ﬁrst example, we ﬁnd the time solution to a second-order ODE with a triangular wave-forcing function. In this particu- lar example, the triangle wave is approximated with a six-term Fourier series:  w SYS1:=diff x t , t, t +2*diff x t , t +50*x t  =  sum 100*cos t* 2*n+1    2*n+1 ^2, n=0..5 ;  SYS1 :=  + 2  x t   + 50 x t  = 100 cos t   ¶ 2 ¶ t2 x t   ¶ t  + 100 9  cos 3t  + 4 cos 5t  + 100 49  cos 7t  + 100 81  cos 9t   When the system is initially at rest, the initial conditions are as follows:  w ICS1:=D x  0 =0, x 0 =0;  ICS1 := D x  0  = 0, x 0  = 0  The D or diﬀerential operator can be used to compute the derivative of  a function. The call D f  x  is equivalent the call diff f x , x :  w D x  t =diff x t , t ;  D x  t  =  x t   ¶ t  134   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł ¶  Mathematical models: working with differential equations  The preceding relationship becomes obvious if we let x equal the tan-  gent and evaluate it:  w eval subs x=tan, “  ;  1 + tan t 2 = 1 + tan t 2  Returning to the deﬁnition of the initial conditions, we can see that the  expression D x  0  is equivalent to the value of d  dtx t t = 0  .  The time response x t  is obtained and plotted using dsolve, rhs,  and plot as shown. As the function dsolve returns an equation of the form x t =…, the right-hand side is isolated using rhs so that it can be graphed  see Figure 4.1 :  w plot rhs dsolve {SYS1, ICS1}, x t   , t=0..10,  labels=[‘t’, ‘x t ’] ;  x t   3  2  1  0  - 1  - 2  0  2  4  6  8  10  Figure 4.1  t  Numeric When a closed-form analytic solution cannot be found, then a numerical so- lution can be attempted, as the next example shows:  135   Applied Maple for Engineers and Scientists  w SYS2:=diff x t , t + 2+cos t^2  *x t =2*sin 0.1*t^2 ,  x 0 =0;  SYS2 :=  x t   +  2 + cos t2   x t  = 2 sin .1t2 , x 0  = 0  ¶ t  w dsolve {SYS2}, x t  ;  x t  = 2.  cid:242   t  sin .1000000000 u2  du  cid:242   t   2.u  e  du  t  0 0  1.253314137 FresnelC .7978845605 u   e  du  1.253314137 FresnelC .7978845605 t    0  - 2.t - e  By specifying the method as numeric, we turn Maple’s ODE solver  from a symbolic one into a numerical one:  w SOLS:=dsolve {SYS2}, x t , type=numeric ;  SOLS := proc rkf45_x  ... end  Maple returns a called procedure such that the value of the function can be computed for any speciﬁed t. The formal parameter name, in this case rkf45_x, indicates which algorithm has been used.  w SOLS 10 ;  [t = 10, x t  = .1582530550576577]  Using this procedure we are able to plot the time response x t    see Figure 4.2 :  w pts:=[seq subs SOLS T 10 , [T 10, x t ] , T=0..100 ]:  w plot pts, labels=[‘t’,’x t ’] ;  136   cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:242   Mathematical models: working with differential equations  x t   1  0.8  0.6  0.4  0.2  0  - 0.2  - 0.4  - 0.6  - 0.8  0  2  4  6  8  10  Figure 4.2  t  The default numerical solver is the Fehlberg fourth-ﬁfth order Runga- Kutta method  see ?dsolve[numeric] . This algorithm requires four evaluations of the function in order to return an estimate of the dependent variable, which is equivalent to using a Taylor expansion as far as the term in  x - method is applicable in most cases this is not always the case. For this rea- son, Maple supports a set of alternative numerical solvers, as shown in Table 4.1. See ?dsolve[algorithm name] for more information.  x0 4. Although the Fehlberg fourth-ﬁfth order Runga-Kutta  The DEtools package The DEtools package continues a suite of tools for investigating PDEs and ODEs graphically.  As before we model a second-order dynamic system with a second-or- der ODE, which we try to solve analytically using dsolve. The initial con- ditions are y´ 0  = 0 and y 0  = 1.  137   Applied Maple for Engineers and Scientists  Algorithm name  Method  Comments  dverk78  Seventh-eight order continous Runga-Kutta.  classical  Forward Euler method.  Heun formula also known as the trapezoidal or improved Euler method.  Improved polygon method or modified Euler method.  Adams-Bashford and Adams-Bashford-Moulton methods.  gear  Gear method.  mgear  Multistep Gear method.  Improved accuracy over fourth-fifth method but with an increased time of computation.  A collection of classical methods using a fixed step size between mesh points. None of the methods employs error correction or estimation to improve accuracy. The default method is Forward Euler.  The Adams-Bashford method is a predictor method, whereas the Adams-Bashford-Moulton method is a predictor-corrector.  Uses a variable-size single-step extrapolation method. The two methods are a Burlirsch-Stoer rational extrapolation method  default  and a polynomial extrapolation method.  Uses a variable-size multistep algorithm that is applicable to both stiff and nonstiff systems. The step size is determined by evaluating the Jacobian matrix of the system at every step. The Jacobian can be computed either symbolically or by using numerical differencing of the derivatives  default . The Adams predictor-corrector method can also be used to determine the step size.  Uses a variable size multistep algorithm to solve stiff systems of ODEs.  Used for high-accuracy solutions. Because this method is computationally intensive, computation times can be high.  lsode  The Livermore Stiff ODE solver.  taylorseries  Taylor series method.  Table 4.1 Alternative numerical solvers  138   Mathematical models: working with differential equations  w SYS3 := diff y t , t$2  + cos t *sin t *diff y t ,t  +  exp t 10 *y t  = cos t ^2;  SYS3 :=  ¶ 2 ¶ t2 y t   + cos t  sin t   y t    1⁄10 t   + e  y t  = cos t 2  ¶ t  w dsolve {SYS3, D y  0 =0, y 0 =1}, y t  ;  Maple returns null indicating that a solution could not be found. In- stead of obtaining the numerical solution to the system and plotting it as we did earlier, we use the general ODE plotter DEplot found in the DEtools package.  A package in Maple is a collection of functions with a common theme. The functions in a particular package can be accessed in one of two ways: Use their long names  package_name[function_name] arg1, arg2, .., argn   or deﬁne their short names in Maple’s name space using with and the short function name. Using with we load the functions in the DEtools package:  w with DEtools ;  [Denormal, DEPlot, DEPlot3d, Dchangevar, PDEchangecoords, PDEplot, autonomous, convertAlg, convertsys, dﬁeldplot, indicialeq, phaseportrait, reduceOrder, regularsp, translate, untranslate, varparam]  The list that is returned lists the functions that have been loaded from  the speciﬁed package. These functions can now be called in exactly the same way  using the short name syntax  as the standard Maple functions.  Using DEplot we can solve our ODE and plot the result directly. The  function’s syntax is as follows: an ODE or system of ODEs to be solved, the axes  in this case the abscissa is the independent variable t and the ordi- nate is the response y t  , the range of the independent variable, and the in- itial conditions followed by any optional arguments. In this example, we have set the step for the independent variable to be 0.1  see Figure 4.3 :  w DEplot SYS3, [t, y], 0..20, {[0, 1, 0]}, stepsize=0.1 ;  139   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  1.5  1  0.5  y  - 0.5  - 1  0  0  5  10  15  20  Figure 4.3  t  We need to exercise some care when using DEplot because initial conditions can be speciﬁed in one of two ways, either [t, y t , y´ t , ...] or [y t  = ic, y´ t  = ic1, ...]. So, for example, the following are both identical and valid: [2, -1, 1], [y 2  = -1, D y  2  = 1].  Phase-Plane Techniques Systems containing nonlinearities can prove diﬃcult to analyze using con- ventional methods, and in some cases phase-plane techniques can provide much needed insight into the nonlinear system’s behavior. The phase plane provides a bird’s-eye view of the possible solutions to the ODE for a given set of initial conditions by showing us the possible trajectories of the system.  In conjunction with the following nonlinear second-order ODE, we  use the Maple functions dfieldplot and phaseportrait to plot a di- rection ﬁeld and a trajectory:  w SYS4:=diff y t ,t,t +diff y t ,t   1-y t  +y t =0;  SYS4 :=  ¶ 2 ¶ t2 y t   +  ¶ t 1 -  y t  y t   + y t  = 0  140   cid:230   cid:231  Ł  cid:246   cid:247  ł ¶  Mathematical models: working with differential equations  The ﬁrst task is to convert our second-order ODE into two  coupled ﬁrst order ODEs so that we can use both dfieldplot and phaseportrait. We do this by deﬁning two state variables, x1 t  and x2 t :  w STATE1:=y t =x[1] t ;  STATE 1 := y t  = x1   t   w STATE2:=diff y t ,t =x[2] t ;  STATE 2 :=  y t  = x2   t   ¶ t  By using these variables we can transform the original ODE into two  coupled ODEs as shown:  w ‘2ND_DE’ := subs STATE2, STATE1, SYS4 ;  2ND_DE :=   t   x2  +  ¶ t  x2   t  x1   t   1 -  + x1   t  = 0  We are now ready to plot the direction ﬁeld x1 t  versus x2 t .  w dfieldplot {‘2ND_DE’, ‘1ST_DE’}, [x[1] t , x[2] t ], t=10..30, x[1]=-10..10, x[2]=-10..10, color=BLACK ;  Two things are immediately deducible from the direction ﬁeld of  Figure 4.4: The circular nature of the arrows indicates that limit cycles are possible and that a singularity at x1 t  equals one.  The next step is to compute the phase portrait of the system with in-  itial conditions of x1 0  = 4 and x2 0  = 1 using phaseportrait  see Figure 4.5 :  w phaseportrait [‘2ND_DE’, ‘1ST_DE’], [x[1] t , x[2] t ],  t=0..30, {[0,4,1]}, stepsize=0.2, thickness=2, color=BLACK ;  141  ¶  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  - 10  - 5  0  0  5  x1  10  x2  10  5  - 5  - 10  x[1] 1 , n[2] t   0.8  0.7  0.6  0.5  0.4  0.3  Figure 4.4  Figure 4.5  142  0  0.1  0.2  0.3  0.4  0.5  t   Mathematical models: working with differential equations  Using display, found in the plots package, we can place a trajectory  on this direction ﬁeld  see Figure 4.6 .  w plots[display] {“,”"}, view=[-6..6, -8..6] ;  x[2] t  - 4  - 2  - 6  x[1] t   0  2  4  6  6  4  2  0  - 2  - 4  - 6  - 8  Figure 4.6  We can see with reference to Figure 4.6 that the system, although it  does not enter a limit cycle, is stable if very oscillatory. It is also possible to see the eﬀect of the singularity on the system’s response.  The difforms package The difforms package contains a set of functions that enables us to deﬁne the variables in a computation, operate on them, and interrogate the resulting functions. This package has its origins more in the mathemati- cian’s world than the engineer’s in terms of the terminology used. The three functions of most interest to us in this package are d, defform, and &^, which computes the exterior derivative of an expression, deﬁnes the ba- sic variables used in a computation, and represents the wedge product, re- spectively. Using the difforms package a formal framework can be quickly formed that enables us to describe complex dynamic systems using diﬀerential equations and the elements that make up diﬀerential equations and to then manipulate them. The following code loads three functions from the difforms package:  143   Applied Maple for Engineers and Scientists  w with difforms, [ defform, d, &^] ;  [&^, d, defform]  First we declare our system of variables:  w EXPR := defform A=function, B=scalar, C=scalar, f=scalar :  This takes the external derivative  w d f*A+&^ B,C  ;   d f  &^A  + fd A  + Cd B  + Bd C   Here we take the derivative of a simpler function:  w d A B,C  ;  A B, C   d B  +  A B, C   d C   ¶ C  ¶ B  Here we deﬁne known external derivatives:  w defform d B  = X, d C =0 ;  Here we view the simpliﬁed expression:  w EXPR;  A B, C   X  ¶ B  Series methods  Although power series methods for solving ODEs are well understood and in many cases are perfectly adequate for ﬁnding accurate approximations, they do exhibit some drawbacks: The resultant series must converge and they can be computationally problematic in that they can require the evalu-  144   cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  Mathematical models: working with differential equations  ation of high-order derivatives. Maple uses the Frobenius series method, which assumes that a solution of the following form is possible: y = xc a0 + a1x + a2x2 + a3x3 + … + arxr + … ; see ?dsolve [series] for more information. In this example, however, we will use the Taylor series, for the sake of clarity, to demonstrate how Maple can be used to manipulate series in order to calculate the time response of a dy- namic system described by a diﬀerential equation.  This method requires that a Taylor’s series can be formed for a func-  tion y = f t  at t =0 by manipulating the higher order derivatives, f´ t , f´´ t , f´´´ t  , … . The general form of the Taylor series can be seen by simply computing the Taylor series for an arbitrary function of t.  w taylor f t ,t ;  f 0  + D f   0 t + 1 2  + 1 24   4  f   0 t4 + 1 D 120   2  f   0 t2 + 1 D 6   3  f   0 t3  5  f  0 t5 + O t6  D  D  The dynamics of a tachometer needle can be described with the follow-  ing ODE: dq  dt = 1 + cos t 10   - 0.05q where t is time and q lar displacement of the needle. We solve this ODE using the series methods as follows: Obtain the higher derivatives  the more derivatives, the better the accuracy , reduce them to functions of the ﬁrst-order deriva- tive, evaluate the derivatives at the point t = 0, generate the Taylor’s series and substitute the derivatives into the series, and, ﬁnally, substitute the in- itial condition and convert to a polynomial.  is the angu-  With reference to the Taylor series generated earlier we can see that it is ﬁfth order—because the default number of terms calculated by Maple is six, no order number was speciﬁed. In the following treatment we only need to calculate the ﬁrst ﬁve derivatives. Using the D and @@ operators we can map the preceding equation into Maple, but before we do we take a quick look at the @@ operator. The @@ operator is the inﬁx form of the re- peated composition operator, which is used to apply functions and opera- tors repeatedly. So applying the function f four times to the argument arg we get the following:  w  f@@4  arg ;  f  4  arg   145   Applied Maple for Engineers and Scientists  By expanding the previous result we can see that the function f is ﬁrst applied to the argument and then the function f is applied to the ﬁrst result followed by a further application of f to that result and so on.  Now we can deﬁne the ODE describing the systems dynamics in  Maple as follows:  0.05*theta t  ;  w SYS5 :=  D@@ n   theta  t  =  D@@ n-1   1+cos t 10 -  SYS5 := D   n  q   t  = D   n -  1  cid:230   1 + cos  1 10  t  .05 q  t  cid:246   At ﬁrst glance this does not resemble the original ODE given earlier.  However, a closer look reveals that with n set to one and thinking of D q   t  as shorthand for dq  dt, SYS5 and the above ODE are the same.  w subs  n = 1, SYS5  ;   1  q   t  = D  D  1 + cos   0  cid:230   1 10  t  .05 q  t  cid:246   Using this general expression we can generate the higher order deriva- tives with seq. However, we do need a trick to be able to do this. We can- not apply the D operator, using the repeated composition operator @@, to the expression 1+ cos  t 10   - 0.05q  t . The trick is to represent this as a function of t.  w TEMP:= t -1 + cos  t 10   - 0.05*theta t ;  TEMP := t ﬁ  1 + cos  .05 q  t   1 10  t  Now we are able to generate the higher order derivatives:  w TERMS := [seq  D@@ n   theta  t  =  D@@ n-1   TEMP  t ,  n=1..5 ];  146   cid:231  Ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:247  ł  cid:231  Ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  Mathematical models: working with differential equations  ative is a function of the  n - 1 th derivative. So the next stage is to step through the list of diﬀerential equations, reducing them to functions of the ﬁrst-order derivative only. We use a do loop for this operation:  TERMS := Ø  D q   t  = 1 + cos  1 10  t  .05 q  t ,   2  q   t  = -  D  1 10  sin  1 10  t  .05 D q   t ,   3  q   t  = - D   4  q   t  = D  1 100  cos  1  1000  sin  1 10  1 10  t  t   5  q   t  = D  1  10000  cos  1 10  t  .05 D   2  q   t ,  .05 D   3  q   t ,   4  q   t ø  .05 D  It is easy to see from this result that the nth derivative is a function of  the  n - 1 th derivative. So the next stage is to step through the list of diﬀer- ential equations, reducing them to functions of the ﬁrst-order derivative only. We use a do loop for this operation:  w ANS1 := [TERMS[1]]:  for n from 5 to 2 by -1 do ANS1:=[op ANS1 ,  TERMS[n] ]; od: ANS1;  subs op [seq op n-N,[TERMS[1..n-1]] , N=1..n-1 ] ,  D q   t  = 1 + cos  1 10  t  .05 q  t , D   5  q   t  =  .00008125000000 cos  .00003750000000 sin  1 10  t  + .625 10  - 5 -  .3125 10   4  q   t  =  t  1 10 - 6 q  t , D  .0007500000000 sin  1 10  t  + .0003750000000 cos  1 10  t  147  Œ º  cid:230   cid:231  Ł  cid:246   cid:247  ł - ø œ ß  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł - Ø Œ º  cid:230   cid:231  Ł  cid:246   cid:247  ł - œ ß Ø Œ º  cid:230   cid:231  Ł  cid:246   cid:247  ł - ø œ ß  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  .000125 + .625 10  - 5 q  t , D   3  q   t  =  - .00750000000 cos  + .005000000000 sin  1 10  t  1 10  t  + .0025  .000125 q  t , D   2  q   t  = -  1 10  sin  1 10  t  .05  .05 cos  1 10  t  + .0025 q  t ø  D q   t  = 1 + cos  1 10  t  .05 q  t , D5 q   t  = ø  .00008125000000 cos  .00003750000000 sin  1 10  t  1 10  t  + .625 10  - 5 -  .3125 10  - 6 q  t , D   4  q   t  =  .0007500000000 sin  1 10 - 5 q  t , D .000125 + .625 10  t   3  q   t  =  + .0003750000000 cos  1 10  t  - .00750000000 cos  + .005000000000 sin  1 10  t  1 10  t  + .0025  .000125 q  t , D2 q  t = - 1 10 + .0025 q  t ø  .05 cos  t  1 10  sin  1 10  t  .05  Note the way that subs is used for sequential substitution. The order of the substitution equations has been reversed. The next step is to evalu- ate the derivatives at the point t = 0:  w AT_ZERO := subs t=0,ANS1 ;  148  -  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł - Ø Œ º -  cid:230   cid:231  Ł  cid:246   cid:247  ł œ ß Ø Œ º  cid:230   cid:231  Ł  cid:246   cid:247  ł - œ ß  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł - Ø Œ º -  cid:230   cid:231  Ł  cid:246   cid:247  ł œ ß  Mathematical models: working with differential equations  AT_ZERO  :=  D q   0  = 1 + cos 0  -  .05 q  0 , D   5  q   0  =  x3 x3  .00008125000000 cos 0  -  .00003750000000 sin 0  + .625 10  - 5  .3125 10  - 6 q  0 , D   4  q   0  = .0007500000000 sin 0   + .00037540000000 cos 0  -  .000125 + .625  10 sup {-5} q  0 ,  3  q   0  = - .00750000000 cos 0  + .005000000000 sin 0  D + .0025 -  2  q   0  = - D  .000125 q  0 , sin 0  -  .05 cos 0  + .0025 q  0 ø  .05 -  1 10  Once we have generated a Taylor’s series in q  t  we substitute for the  derivatives:  w THE_SERIES:=taylor theta t , t ;  THE_SERIES := q  0  + D q   0 t + 1 2   2  q   0 t2 + 1 D 6   3  q   0 t3 D  5  q   0 t5 + O t6  D  + 1 24  D   4  q   0 t4 + 1 120  w WITHOUT_DIFFS:= subs AT_ZERO, THE_SERIES ;  .05 q  0   t .05000000000 + .001250000000 q  0   t2 .0008333333335 -  WITHOUT_DIFFS := q  0  +  2 - +  - +  - +  .00001041666667 + .2604166667 10 +  .7291666666 10 .2604166667 10  .00002083333334 q  0   t3 - 6 q  0   t4 - 8 q  0   t5 +O t6   - 6 -  Here we substitute the initial condition and convert the resulting ex-  pression to a polynomial by removing the order term:  149  Ø Œ º ø œ ß - Ø Œ º œ ß  Applied Maple for Engineers and Scientists  w WITH_IC := subs theta 0  = 1, WITHOUT_DIFFS ; WITH_IC := 1 + 1.95 t -  .04875000000 t2 -  + .00001067708334 t4 + .7265624999 10  .0008541666668 t3 - 6 t5 + O t6   w SERIES_APPROX := convert WITH_IC, polynom ;  SERIES_APPROX := 1 + 1.95t -  .04875000000t2  .0008541666668t3 + .00001067708334t4 + .7265624999 10  - 6t5  We now plot the response in Figure 4.7.  w plot SERIES_APPROX, t=0..40, labels=[‘t’,’Theta’] ;  Theta  40  30  20  10  0  10  30  40  20 t  Figure 4.7  As previously mentioned series techniques only provide approximate solutions to ODEs; the accuracy of the solution is determined by the type of series used and the number of terms in the series. Bearing this in mind, the accuracy of the time response of the tachometer needle appears to alter over its range. Within the range t = 0..20 the response is as we would ex- pect with the needle’s angular position increasing, overshooting, and then,  150  -  Mathematical models: working with differential equations  following some oscillations, ﬁnally settling at its ﬁnal position. It is in the range t = 20..40 that the needle’s response is not as we would expect as the angular position grows in an unbounded fashion. This accuracy problem is common with series methods because the series in question is only guaran- teed to be accurate for a limited range about the point of expansion, in out case t = 0. It is possible to improve the accuracy of a series method solution by using an alternative series, as Maple does. We increase the number of terms used and change the point about which the function is expanded. This last method means that a piecewise linear approximation to the solu- tion can be constructed in an iterative fashion. In this particular example, however, an analytic solution exists so we can compare that with the ap- proximate solution obtained using the series approach. First we save the plot of the series solution, changing the line style to dashed, so that we can compare it with the analytic solution.  w PLOT1 := plots[display] {“}, linestyle=2 :  Using dsolve we calculate the exact solution before displaying the  two responses on the same graph  see Figure 4.8 :  w EXACT := dsolve  {SYS5, theta 0 =1}, theta t  ;  EXACT := q  t  = 20. + 4. cos .1000000000t   + 8. sin .1000000000t  - 23. e   -  .05000000000t   Theta  40  30  20  10  Figure 4.8  0  10  30  40  20 t  151   Applied Maple for Engineers and Scientists  This plots the approximate and the exact solutions:  w plots[display] {plot rhs EXACT , t=0..40 , PLOT1},  labels=[‘t’,’Theta’] ;  Modeling dynamic systems  Using Maple’s ability to represent and manipulate symbolic quantities, we can quickly describe a dynamic system, using diﬀerential equations, and analyze it. In many instances, we will be able to obtain the exact closed- form solutions describing its behavior.  A simple shock absorber In our ﬁrst example, we consider a mass  m1 , a spring  constant k1  of length s1, and a damper  frictional constant b1  arrangement set up as a sim- ple shock absorber  Figure 4.9 . In this particular example, we are inter- ested in determining the behavior over time of the center of the mass  x1  following a disturbance in the reference x0.  Mass m1  x1 = 0  Spring  k1  x0 = 0  Figure 4.9  Damper  Spring length  b1  s1  By equating the forces acting on the mass m1 we can determine the  equations of motion that describe the system’s behavior, in this case, over time.  w mass[1]:= 0 = m[1]*diff x[1] t ,t,t  + b[1]*diff x[1] t ,t   - k[1]* s[1]-x[1] t +x[0] t  ;  152   Mathematical models: working with differential equations  mass1 := 0 + m1  + b1   t   x1  ¶ 2  t  ¶ t2 x1 x1 Ł s1  k1  ¶ t  t  cid:246    t  + x0  This is the general equation describing the system’s motion so we need to deﬁne the parameter values and the initial conditions before we proceed. The system parameters are as shown, the system is assumed to be initially at rest, and the forcing function is sin2 2.7t  2. This particular forcing func- tion has been chosen to simulate a series of impulses.  w params:=[m[1]=1, k[1]=1, b[1]=1, s[1]=1,  x[0] t =0.5*sin t*2.7 ^2]; params := Ø  = 1, k1  = 1, b1  º m1  = 1, s1  = 1, x0   t  = .5 sin 2.7 t 2ø  w ics:=D x[1]  0 =0, x[1] 0 =1;  ics := D x1    0  = 0, x1   0  = 1  These are substituted into the second-order ODE describing the  shock absorber, which is then solved analytically using dsolve:  w {subs params, mass[1] , ics}, {x[1] t }  D x1  0 =    0  = 0, x1 ¶ 2  t  ¶ t2 x1  +   0  = 1,   t   x1  ¶ t  11 212 1 + x1   t  -  .5 sin 2.7 t 2  ,  cid:236    cid:238  x1   t  cid:252   The convert  ..., rational  is necessary because dsolve  is unable to deal with ﬂoating-point numbers in the ODE’s coeﬃcients.  153   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:230  - ł ß  cid:236   cid:237   cid:238   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:252   cid:253   cid:254   cid:236   cid:237   cid:238   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:252   cid:253   cid:254   cid:237   cid:253   cid:254   Applied Maple for Engineers and Scientists  w simplify dsolve op convert [“], rational    ;   t  =  x1  2200  5137841  sin  1 2  ‘ 3 t  sin  1 2  ‘ 3 t + 27 5  t  +  3375  4110728  cos  ‘ 3 t  sin  ‘ 3 t + 27 5  t  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  1 2  +  +  +  +  3375  4110728  cos  2200  5137841  cos  ‘ 3 t  sin  ‘ 3 t -  ‘ 3 t  cos  ‘ 3 t -  27 5  t  27 5  t  2200  5137841  cos  ‘ 3 t  cos  ‘ 3 t + 27 5  t  2200  5137841  sin  1 2  ‘ 3 t  sin  ‘ 3 t -  27 5  t  + 5 4  9425  6166092  cos  ‘ 3 t  sin  ‘ 3 t -  + 64485 4110728  cos  ‘ 3 t  cos  ‘ 3 t -  1 2  27 5  t  ‘ 3  27 5  t  ‘ 3  +  9425  6166092  cos  ‘ 3 t  sin  1 2  ‘ 3 t + 27 5  t  ‘ 3  64485 4110728  cos  ‘ 3 t  cos  1 2  ‘ 3 t + 27 5  t  ‘ 3  9425  6166092  sin  ‘ 3 t  cos  1 2  ‘ 3 t + 27 5  t  ‘ 3  + 64485 4110728  sin  ‘ 3 t  sin  ‘ 3 t -  9425  6166092  sin  ‘ 3 t  cos  ‘ 3 t -  1 2  1 2  27 5  t  ‘ 3  27 5  t  ‘ 3  154   cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘ -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘ -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘ -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  Mathematical models: working with differential equations  64485 4110728  sin  ‘ 3 t  sin  1 2  ‘ 3 t + 27 5  t  ‘ 3  3375  4110728  cos  ‘ 3 t  sin  ‘ 3 t + 27 5  t  +  3375  4110728  cos  ‘ 3 t  sin  ‘ 3 t -  27 5  t  1 2  1 2  1 2  1 2  1 2  + 531441 2055364   - 1⁄2t  e  cos  ‘ 3  1 2  164997 2055364  ‘ 3 e   - 1⁄2t   sin  ‘ 3 t  1 2  As we can see, the solution of even simple-looking ODEs can be com- plex. Here we display both the time response of the system and the forcing function together:  w Plots[display] array 1..2,1..1,[[plot rhs “ , t=0..10, labels=[‘t’,’o p’] ],[ plot 0.5*sin 2.7*t ^2, t=0..10, labels=[‘t’,’i p’] ]]  ;  We can see in Figure 4.10 that this system would not make a particu-  larly good shock absorber because its response time is too slow. With refer- ence to the time response, we can deduce that the shock absorber is  1.3  1.25  1.2  1.1  1.05  o p  1.15  Figure 4.10  i p  0.5  0.4  0.3  0.2  0.1  0  0  1  0  2  4  6  8  10  t  2  4  6  8  10  t  155  -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘ -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  bouncing from high-spot to high-stop as the steady-state output is centered on the dc value of the input signal and tracks the oscillations at the input’s fundamental frequency.  Using the Heaviside function In many practical systems the forcing function to a system will be discon- tinuous in nature. For example, by using the Heaviside function we can model step, pulse, delayed, and windowed forcing functions.  In the previous example, we approximated a pulse train forcing func- tion with a sin2t function. Here, instead we can use Heaviside functions as shown:  w f t :=sum Heaviside  t-n * -1 ^ n+1 , n=1..10 ;  := Heaviside t -  1  - Heaviside t -  f t  - Heaviside t - + Heaviside t - - Heaviside t -  4  + Heaviside t - 7  - Heaviside t - 10   2  + Heaviside t - 6  9   5  - Heaviside t - 8  + Heaviside t -  3   Here we plot the forcing function f t . We save this plot for future use  by assigning it to the variable p1  see Figure 4.11 :  w plot f t , t=0..20, labels=[‘t’,’f t ’] ;  w p1:=":  f t :  s[1]=1]:  The parameter deﬁnition is modiﬁed to include the forcing function  w params:=[m[1]=1, g=10, k[1]=1, b[1]=1, x[0] t =f t ,  We can now substitute the new parameter list into the ODE describing  the mass’s motion developed above and then solve it.  w {subs params, mass[1] , ics}, {x[1] t };  dsolve “ ; p2:=plot rhs ” , t=0..20 :  156   Mathematical models: working with differential equations  1  0.8  0.6  0.4  0.2  f t   1.6  1.4  1.2  1  0.8  0.6  0.4  0.2  o p  0  0  5  10 t  15  20  Figure 4.11  The forcing function and system’s time response are displayed to- gether in Figure 4.12 using the display function found in the plots package.  w plots[display] {p2,p1}, labels=[‘t’,’o p’] ;  0  0  5  10 t  15  20  Figure 4.12  157   Applied Maple for Engineers and Scientists  A twin mass shock absorber In the next example, we model a car tire-spring-damper assembly with two masses  m1 and m2 , two springs  constants k1 and k2  of length s1 and s2, respectively, and two dampers  frictional constants b1 and b2  arranged as shown in Figure 4.13. The bottom mass-spring-damper arrangement mod- els the tire whereas the top mass-spring-damper conﬁguration models the car’s shock absorber assembly. In this particular example, we are interested in determining the behavior over time of both of the center of the masses  x1 and x2  following a disturbance in the reference x0.  x1 = 0  Mass m1  x2 = 0  Mass m2  Spring  k1  Damper  Spring length  b1  b2  s1  s2  Damper  Spring length  Spring  k2  x0 = 0  Figure 4.13  By equating the forces acting on both of the masses, we can determine the equations of motion that describe the system’s behavior over time. In this example, we are faced with two coupled ODEs that must be solved simultaneously.  w mass[1]:=m[1]*diff x[1] t ,t,t -k[1]* s[1]- x[1] t   x[2] t   +b[1]*diff x[1] t -x[2] t ,t =0;  158   Mathematical models: working with differential equations  x[2] t -x[0] t ,t =0;  mass1 := m1  ¶ 2 ¶ t2 x1   t   k1  Ł s1   t  + x2 x1   t  cid:246   + b1   t   x1  ¶ t   t   x2  = 0  ¶ t  w mass[2]:=m[2]*diff x[2] t ,t,t -k[1]* -s[1]+x[1] t  x[2] t  -b[1]*diff x[1] t -x[2] t ,t  -k[2]* s[2] x[2] t +x[0] t  +b[2]*diff x[2] t -x[0] t ,t =0;  mass2 := m2  ¶ 2  t  ¶ t2 x2  b1  + b2   t   x1   t   x2  ¶ t  ¶ t  ¶ t  ¶ t  k1  - s2  + x2   t  -   t  cid:246   x2   t   x2  k2  Ł s2   t  + x0   t  cid:246   x2   t   x0  = 0  As in the previous example, these are the general equations so we will  need to assign values to the system parameters for mass mi, damping bi, and the spring constants ki. The forcing function x0 t  is also deﬁned.  w params:=[m[1]=200, m[2]=10, k[1]=25000, k[2]=15000, b[1]=50,b[2]=1000,x[0] t =0.2, s[1]=0.2, s[2]=0.3];  params := Ø  º m1 b2  = 200, m2 = 1000, x0  = 10, k1  t  = .2, s2  = .3ø  = 25000, k2  = 15000, b1  = 50,  The ﬁnal set of parameters that needs to be deﬁned are the initial  conditions:  w ics:=x[1] 0 =0.5, x[2] 0 =0.3, D x[1]  0 =0, D x[2]  0 =0;  ics := x1   0  = .5, x2   0  = .3, D x1    0  = 0, D x2    0  = 0  159   cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230  - ł  cid:230   cid:231  Ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230  Ł ł -  cid:230   cid:231  Ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:246   cid:247  ł -  cid:230  - ł  cid:230   cid:231  Ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:246   cid:247  ł ø ß Ø º ß  Applied Maple for Engineers and Scientists  The ODEs and the parameter values are brought together using the  substitution function subs to form the equations that we will be manipulat- ing further:  w eqns:=subs params,{mass[1], mass[2]} ;  eqns :=  200  ¶ 2 ¶ t2 x1   t   5000.0 + 25000 x1   t  -  25000 x2   t   + 50   t   x2  ¶ t  50  ¶ t   t   x2  = 0, 10  25000 x1   t  + 40000 x2   t  -  50  x1  ¶ t   t   ¶ 2 ¶ t2 x1  t   + 1050  2500.0   t   x2  ¶ t  1000  ¶ t  .2  = 0  In this particular case we will use Laplace transform methods to solve the variables xi t . The Laplace transform functions are found in the inte- gral transforms package inttrans, which we load using with. If you are concerned with system resources  i.e., unnecessarily loading functions into Maple work space that will not be used  you can load only the Laplace transform functions by using with  inttrans, [laplace, invlaplace] :  We can now take the Laplace transforms of the system’s diﬀerential  w with inttrans :  equations:  w laplace eqns, t, s ;   t , t, s  s - 1. x1   0  cid:246   s - 200. D x1    0  - 5000.  1 s  200.  cid:230   laplace  x1 + 25000. laplace  cid:230  + 50. laplace  cid:230  + 50. x2  Ł x1  Ł x1  t , t, s cid:246    t , t, s cid:246   - 25000. laplace  cid:230    t , t, s cid:246   Ł x2  ł s - 50. x1   0  - 50. laplace  cid:230   0  cid:246   s - 1. x2   t , t, s cid:246   Ł x2 s   t , t, s cid:246   ł s   0  = 0, 10.  cid:230   Ł laplace cid:230   Ł x2  160   cid:236   cid:237   cid:238   cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:252   cid:253   cid:254   cid:230   cid:231  Ł ¶  cid:246   cid:247  ł -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł - -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:236   cid:237   cid:238  -  cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  cid:252   cid:253   cid:254   cid:236   cid:237   cid:238  Ł ł  cid:252   cid:253   cid:254  ł ł ł ł  Mathematical models: working with differential equations  - 10. D x2  0  - 2500. + 40000. laplace  cid:230   1 s  t , t, s cid:246   Ł x2  + 50. x1   0  + 1050. laplace  cid:230    t , t, s cid:246   - 25000. laplace  cid:230  ł s - 50. laplace  cid:230  Ł x2   t , t, s cid:246    t , t, s cid:246  ł s - 1050. x2  Ł x1 Ł x1  ł s  0  = 0  1 s  We can make these expressions clearer by means of Maple’s alias facil-  ity. The two unknowns that we are interested in are the Laplace trans- formed quantities laplace x1 t   and laplace x2 t  , which we will alias to X1 and X2, respectively:  w alias X1=laplace x[1] t , t, s , X2=laplace x[2] t , t, s  ;  I, diff1,  cid:242  1, X1, X2  Maple returns a sequence of the aliases currently known to the system.  Now we substitute for the initial conditions:  w subs ics, “” ;  - 25000. X1 + 25000. X2 + 50. X1 s  1 s  .5  s - 5000.  200.  X1 s - - 10.0- 50. X2 s = 0, 10.  X2 s -  1 s + 40000. X2 - 50. X1 s - 290.0 + 1050. X2 s = 0  .3  s - 2500.  - 25000. X1  1 s  We now can solve for the two unknowns X1 and X2  w solve “, {X1, X2} ;  X1 = .5000000000  X2 = .3000000000  16600. s2 + .1050000 107 + 52100. s + 421. s3 + 4. s4 s cid:230  Ł 750000. + 51500. s + 16600. s2 + 4. s4 + 421. s3 cid:246  4. s4 + 421. s3 + 20600. s2 + 52500. s + .1250000 107 s cid:230  Ł 750000. + 51500. s2 + 16600. s2 + 4. s4 + 421. s3 cid:246   ,  161  ł  cid:236   cid:237   cid:238   cid:252   cid:253   cid:254   cid:236   cid:237   cid:238   cid:252   cid:253   cid:254   cid:236   cid:237   cid:238   cid:252   cid:253   cid:254   cid:236   cid:237   cid:238  ł  cid:252   cid:253   cid:254   cid:236   cid:237   cid:238  ł  cid:252   cid:253   cid:254   Applied Maple for Engineers and Scientists  Using map in conjunction with invlaplace, we take the inverse  transform of both solutions in a single step and obtain the time responses xi t :  w map invlaplace, “, s, t ;  {x1 t  = .7000000000  .003867611722 e - 51.60982474 t  cos 35.05255107 t  + .001213402066 e - 51.60982474 t  sin 35.05255107 t  .1961323883 e - 1.015175265 t  cos 6.866003481 t  .06426567528 e - 1.015175265 t  sin 6.866003481 t , x2 t  = .5000000000 - .1143131946 e -51.60982474 t  sin  35.05255107 t  .1164923127 e -1.015175265 t  cos  6.866003481 t  .06133234948 e - 1.015175265 t  sin 6.866003481 t }  .08350768725 e -51.60982474 t  cos 35.05255107 t   Maple returns a set of solutions which we map onto a list of solutions a  shown.  w sols  :=subs  “, [x[1] t , x[2]  t ] ; sols := [ .7000000000 -  .003867611722 e - 51.60982474 t  cos 35.05255107 t   + .001213402066 e - 51.60982474 t  sin 35.05255107 t  .1961323883 e - 1.015175265 t  cos 6.866003481 t  .06426567528 e - 1.015175265 t  sin 6.866003481 t , .5000000000 - .1143131946 e -51.60982474 t  sin  35.05255107 t  .1164923127 e -1.015175265 t  cos  6.866003481 t  .06133234948 e - 1.015175265 t  sin 6.866003481 t ]  .08350768725 e -51.60982474 t  cos 35.05255107 t   Now we can plot the response of the system for an input step of 0.2  units in amplitude  Figure 4.14 :  w plot {sols[1], sols[2]},t=0..5,numpoints=100,  labels=[‘t’,’x[1] t , n[2] t ’] ;  162  - - - - - - - - - - -  Mathematical models: working with differential equations  x[1] t , x[2] t   x[1] t , n[2] t   0.8  0.7  0.6  0.5  0.4  0.3  0  0.8  0.7  0.6  0.5  0.4  0.3  0  Figure 4.14  1  2  3  4  5  t  At ﬁrst glance the step response of this system does not seem unusual with a settling time of approximately 3 sec, an overshoot of approximately 70%, and a natural damped natural frequency of about 1.2 Hz. The re- sponses are closely coupled with only a slight delay between the two masses. However, on closer inspection, the initial rises of each curve are not the same. Using Maple we can zoom in on this portion of the response  see Figure 4.15 :  w plot {sols[1], sols[2]},t=0..0.5, numpoints=100,  labels=[‘t’,’x[1] t , n[2] t ’] ;  Figure 4.15  0.1  0.2  0.3  0.4  0.5  t  163   Applied Maple for Engineers and Scientists  Using piecewise The strange “kink” in the response of mass m2 is indicative of the presence of high-frequency components. The high-frequency components in the output could lead to unsuitable operation for a shock absorber assembly when it is subjected to a sequence of impulses such as those that could be encountered when a car passes over a railroad crossing. It is this type of in- put and how to model it that we consider in this section.  As before we deﬁne the parameters for the system but this time we set  the forcing function to f t  as deﬁned below:  w params:=[m[1]=200, m[2]=10, k[1]=25000, k[2]=15000,  b[1]=50, b[2]=1000, x[0] t =f t , s[1]=0.2, s[2]=0.3];  params := Ø  º m1 b2  = 200, m2 = 1000, x0  = 10, k1  t  = f t , s1  = 25,000, k2  = .2, s2  = .3ø  = 15,000, b1  = 50,ø  Using the piecewise function we model a sequence of impulses that  will become the system’s forcing function:  w f t :=piecewise t 1 and t 1.5 and  t 1.75 and t 2.4 and t<=2.7, -0.2, t>2.7, 0 :  Here we substitute for the system parameters and the forcing function  prior to solving for xi t  numerically:  w sols:=dsolve subs params,{mass[1], mass[2], ics} ,  {x[1] t , x[2] t }, numeric ;  w sols := proc rkf45_x  ... end  This time we use odeplot to plot the time responses xi t  over the range t = 0..5 s. The system response along with the forcing function are displayed in Figure 4.16.  w plots[odeplot] sols, [[t,x[1] t ],[t,x[2] t ]],0..5,  numpoints=100 ;  164  ß Ø º ß  Mathematical models: working with differential equations  i p, o p  0.6  0.4  0.2  - 0.2  0  0  1  2  3  4  5  Figure 4.16  t  As predicted the response of the top mass is smooth despite the impul- sive nature of the forcing function, whereas the response of the lower mass exhibits a number of discontinuities corresponding to the rising and falling edges of the forcing function. In a real system, where the lower mass- spring-damper assembly would be tire, such behavior could lead to a loss of traction and hence control of the vehicle.  A nonlinear system Thus far we have used Maple to investigate linear ODEs but that tools and techniques used are equally applicable to nonlinear ODEs. In some cases it may be possible to obtain an analytical solution to a nonlinear ODE, in which case dsolve can still be used. For example,  w dsolve diff y t ,t,t =y t ^2, y t  ;  t =  cid:242   y t   0  t =  cid:242   - 3  y t   0  1  6y13 + 9_C1  dy1 -  _C2,  1  3  6y23 + 9_C1  dy2 -  _C2  165   cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  The number of nonlinear ODEs that can be solved analytically is  small, which means that more often than not we are forced to solve non- linear ODEs numerically. As we have already seen, Maple has a powerful array of numerical solvers that we can apply to nonlinear ODEs. Returning to the linear coupled system of ODEs considered earlier, we can consider a nonlinear system by introducing a nonlinear spring into the top mass- damper-spring assembly of the preceding example. We redeﬁne the force balance equation for the top mass as follows:  w mass[1]:=m[1]*diff x[1] t ,t,t -k[1]* s[1]- x[1] t -  x[2] t  ^2 +b[1]*diff x[1] t -x[2] t ,t =0;  mass1 := m1  k1  Ł s1   t  -  Ł x1  2  cid:246    t  cid:246   x2  ¶ 2  t  ¶ t2 x1 ¶ 1 ¶ t1 x1   t   + b1  ¶ 1  t  ¶ t1 x2  = 0  We use the following system parameters and the original initial condi-  tions to compute the system step response:  w ics:=x[1] 0 =0.5, x[2] 0 =0.3, D x[1]  0 =0, D x[2]  0 =0:  params:=[m[1]=200, m[2]=10, k[1]=25000, k[2]=15000,  b[1]=50,b[2]=1000, x[0] t =0.2, s[1]=0.2, s[2]=0.3]:  sols:=dsolve simplify subs params,{mass[1], mass[2],  ics}  , {x[1] t , x[2] t }, numeric ;  sols := proc rkf45_x  ... end  Note the use of simplify to tidy up the diﬀerential equations prior  to them being passed to dsolve.  w plots[odeplot] sols, [[t,x[1] t ],[t,x[2] t ]],0..5,  numpoints=100, labels=[‘t’,’x1 t , x2 t ’] ;  The response obtained  Figure 4.17  for the nonlinear system is obvi- ously diﬀerent from that obtained for the linear system in that the displace-  166   cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230  -  cid:230  ł ł  cid:230   cid:231  Ł  cid:230   cid:231  Ł  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:246   cid:247  ł  Mathematical models: working with differential equations  ment of both masses is much larger and the settling time in increased. The kink in the lower traces is not, however, as pronounced in the nonlinear system as in the linear one.  1.8  1.6  1.4  1.2  1  0.8  0.6  0.4  x1 t , x2 t   Figure 4.17  0  1  2  3  4  5  t  The ability to deal with nonlinear components in our models enables us to investigate how systems will react to marked changes in the system’s parameters. For example, what happens to the system if a spring or damper fails? In this our ﬁnal example in this section, we investigate how the sys- tem’s response changes with regard to changes in the damping coeﬃcient of the bottom mass-spring-damper assembly. Such a change in the coeﬃ- cient could be associated with changes in temperature or a punctured tire.  First we deﬁne how the damper’s coeﬃcient of friction will change  over time:  Figure 4.18.  w B:=T->piecewise T>12, 4000, T>8, 1000, T>4, 500,T>0, 0 :  The proﬁle of the damping coeﬃcient can be plotted as shown in  w plot B t ,t=0..20, labels=[‘t’,’B t ’] ;  167   Applied Maple for Engineers and Scientists  4,000  3,000  1,000  B t   2,000  0  0  5  10 t  15  20  Figure 4.18  Next we deﬁne the square-wave forcing function of 4-Hz frequency  and peak-to-peak amplitude of 0.4 units:  w f:=T->piecewise T>16, 0.2, T>12, -0.2, T>8, 0.2, T>4, -0.2,  T>0, 0.2 :  Here we plot the forcing function, which is shown in Figure 4.19:  w plot f t ,t=0..20, labels=[‘t’,’f t ’] ;  The parameter list is altered so that the coeﬃcients b2 and x0 t  are the  functions of time B t  and f t , respectively:  w params:=[m[1]=200, m[2]=10, k[1]=25000, k[2]=15000,  b[1]=50, b[2]=B t ,x[0] t =f t , s[1]=0.2, s[2]=0.3];  params := Ø  = 10, k1  = 200, m2  = 25000, k2  = = 50, b2 º m1 piecewise 0, 12 < t, 4000, 8 < t, 1000, 4 < t, 500, 0 < t, 0, undeﬁned , x0 t  = piecewise 0, 16 < t, .2, 12 < t, - 4 < t, - .2, 0 < t, .2, undeﬁned , s1 = .2, s2 = .3 ]  = 15000, b1  .2, 8 < t, .2  168  ø ß  Mathematical models: working with differential equations  0.2  0.1  - 0.1  - 0.2  f t   0  0  5  10  15  20  Figure 4.19  t  We can now solve this numerically  w sols:=dsolve subs params,{mass[1], mass[2], ics} ,  {x[1] t , x[2] t }, numeric ;  w sols := proc rkf45_x  ... end  and plot the result  Figure 4.20  as before using odeplot:  w plots[odeplot] sols,[[t,x[1] t ],[t,x[2] t ]],0..20,  numpoints=100, labels=[‘t’,’x1 t , x2 t ’] ;  This previous plot demonstrates that this particular system is closely coupled. As the tire becomes more and more stiﬀ, the oscillations of both the masses reduces until, in the range of t = 16..20, the majority of the damping is supplied by the top damper. The data displayed in Figure 4.20 is a little cluttered. By altering the representation to a three-dimensional surface, the oscillations and their eﬀect on the system’s step response as the damping coeﬃcient varies can be clearly seen.  169   Applied Maple for Engineers and Scientists  x1 t , x2 t   0.4  0.8  0.6  0.2  0  0  Figure 4.20  5  15  20  10 t  First we redeﬁne the function B t  so that it has four bands and the pa-  rameter list so that the forcing function is a step of amplitude 0.2 units:  w B:=T->piecewise T>3, 4000, T>2, 1000, T> 1, 500, T>0, 0 :  params:=[m[1]=200, m[2]=10, k[1]=25000, k[2]=15000,  b[1]=50,b[2]=B,x[0] t =0.2, s[1]=0.2, s[2]=0.3]:  Next we deﬁne a function that returns a Maple procedure. The proce-  dure is the numeric solution, for a given damping coeﬃcient, to the non- linear ODE:  w sols:= y -dsolve subs params, B=B y ,{mass[1], mass[2],  ics} , {x[1] t ,x[2] t }, numeric ;  sols := y ﬁ  Ł subs  cid:230  dsolve  cid:230   t  cid:252   t , x2  cid:254  , numeric cid:246    cid:238  x1  Ł params, B = B y ,  cid:236    cid:238  ics, mass1, mass 2  ,  This is called in the following manner:  170   cid:237   cid:252   cid:253   cid:254   cid:246  ł  cid:246  ł  cid:230  Ł  cid:236   cid:237   cid:253  ł  Mathematical models: working with differential equations  w sols 3 ;  proc rkf45_x  ... end  By using two nested for loops we construct the surface. The outer loop computes the step response for each band in the damping function, and the inner loop copies the response to thicken the band. Finally, the computed data are displayed using the surfdata function found in the plots package  Figure 4.21 .  w ANS:=NULL:  for n in [0,1,2,3] do  TEMP:=plots[odeplot] sols n , [t, x[1] t ], 0..5, numpoints=100 ; TEMP:=op 1,op 1,[op TEMP ]  ; ANS:=ANS,map  x,y -[y, op x ],TEMP,2*n ; for nn to 2 do  ANS:=ANS,map  x,y -[y, op x ],TEMP,2*n+nn ;  od;  od: plots[surfdata] [ANS], color=BLACK, orientation=[25, 60], axes=FRAME,labels=[‘b1’,’t’,’x1 t ’] ;  x1 t   0.9  0.8  0.7  0.6  0.5  0  1  2  t  3  4  8  5  10  0  2  4  6  b1  Figure 4.21  171   Applied Maple for Engineers and Scientists Continuous control application theory  Chapter 5  Continuous control application theory  Linear control system analysis  The most common use for Maple’s linear algebra capabilities are  those applications where matrix algebra is advantageous when dealing with systems that have many constituent equations de-  scribing the underlying dynamics. These systems arise in particular when dealing with circuits  mesh and nodal equations  and general control sys- tem analysis  stability and sensitivity analysis with many variables .  Many extremely valuable references are available that discuss classical control techniques [1–4]. Most of these texts introduce the use of matrices and linear algebra since most control system applications, whether done in the frequency or the time domain, are described and solved using these mathematical methods.  173   Applied Maple for Engineers and Scientists  We deal here with two separate approaches for solving a standard lin- ear controller, namely, the frequency-domain method and the time-domain method. The best way to perform this comparison is to analyze a control problem and compare the desired results, both graphically and analyti- cally. This comparison will demonstrate that linear algebra is a very powerful method for obtaining needed solutions. However, and more im- portantly, some basic matrix methods coupled with Maple give the user an ability to play with internal system dynamics symbolically, hence greatly helping the user understand the underlying general dynamics associated with any variable of any given controller.  We start our discussion with the general feedback model as shown in Figure 5.1. No matter how complicated the controller becomes, most de- tailed analyses break the bigger system into smaller subsystems as shown in Figure 5.1. Consequently, the importance of knowing how to use Maple to set up, solve, and manipulate variables within the system under investiga- tion is what this chapter is about.  +  Input  Error signal  Forward dynamics  Output  G  H  Reverse dynamics  Figure 5.1 Standard feedback controller model.  Figure 5.1 shows the basic feedback controller with designated input, output, feed-forward  forward dynamics , and feedback  reverse dynamics  paths. These are described as follows:  1.  2.  3.  Forward dynamics. Sometimes called the plant. This block repre- sents the dynamics associated with the power or overall system actuator. It is also called the eﬀector or motivator branch. Reverse dynamics. Sometimes called the compensator. This block represents the dynamics associated with the sensor of the overall system actuator. It is also called the aﬀector or sensor branch. Summation   cid:229  forward and reverse system components. This diﬀerence signal is known as the control system error signal.   . This block creates the diﬀerence between the  174  S -  Continuous control application theory  We start our analysis of the frequency-domain approach with a simple example and compare the results with the time-domain analysis given later.  Frequency-domain approach  Generally, the block components shown in Figure 5.1 are transformed via Laplace transforms for analysis [1–4]. This transform technique allows the user to describe the system dynamics in algebraic terms rather than inte- grodiﬀerential time-invariant equations. Thus, the Laplace transform of a time function, f t , becomes F s  as deﬁned by Laplace[ f t ] = F s   Mathematically, this is achieved by the following transform:  Laplace[ f t ] =  cid:242   f t e  - st dt ”  F s   0  where s = jw  and j represents the imaginary value of  cid:214   - 1 .  As a consequence, the system blocks are considered linear, although  this graphic representation can certainly be utilized with nonlinear dynam- ics. However, Laplace transform techniques cannot be used in these cases [1–3].  Let’s borrow some system dynamics from an air stabilizer design used  in aerodynamics [2]  see Table 5.1 . The overall closed-loop or system transfer function, assuming no loading between blocks, is deﬁned as  Control branch  Laplace transform  Forward dynamics  G s  =  2 s + 2 2  2s2 + 3s + 2  Reverse dynamics  H s  = 1 2s  Table 5.1 Stabilizer controller transfer functions  The no loading between system blocks means that no individual block’s output is aﬀected by the input of the following system block.  175  ¥ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  Overall transfer function =  G s   1 + G s H s   Incorporating this expression via Maple yields,  w G := 2* s+2 ^2  2*s^2+3*s+2 :  H := 1  2*s : System_Xfer_Function := simplify G  1+G*H  ; s s + 2 2  System_Xfer_Function :=  s3 + 2 s2 + 3 s + 2  Now, let’s give the system an input step function:  Input = 1 s  The output response is determined by multiplying the system with the  input function, or  Output =  System transfer function  ·   Input   Hence,  w Input := 1 s:  System_Response := simplify System_Xfer_Function*Input ;  System_Response :=   s + 2 2  s3 + 2 s2 + 3 s + 2  Now we invoke the Laplace transform within the inttrans library, because we will be converting between the frequency and time domains:  w with inttrans :  we obtain  Computing the inverse Laplace transform of the System_Response,  176   Continuous control application theory  w System_Response_Time_Domain := evalf invlaplace System_  Response,s,t  ;  System_Response_Time_Domain := .5000000000 e sin 1.322875656 t  cos 1.322875656 t    - + 2.078804601 e  - + .5000000000 e  .5000000000 t  .5000000000 t    - 1. t   Plotting the output response  Figure 5.2 , we see the time-domain sys-  tem’s response to a unit step function as  w with plots :  plot  System_Response_Time_Domain,t=0..10,axes= normal,color=black, labels=[time,response] ;  Response  1.6 1.4  1.2 1  0.8 0.6 0.4 0.2 0 - 0.2 - 0.4  Figure 5.2 Time-domain step response for controller example.  0  2  4  8  10  6  Time  At this point, engineers are interested in the roots of the closed-loop Laplace transfer function expression. The roots of the Laplacian polyno- mial function, System_Response, give the stability and response charac- teristics of the individual components that comprise the overall closed-loop transfer function. The following Maple structure will factor the polynomial for the characteristic roots:  w Factored_Denominator := factor denom System_Response  ;  Factored_Denominator  :=  s + 1   s2 + s + 2   177   Applied Maple for Engineers and Scientists  Maple was able to factor the third-order polynomial, but could not fac-  tor the composite quadratic term because that term contains complex roots. However, we can have Maple directly solve the denominator expres- sion for the three roots with the solve command:  w System_Roots := [evalf solve Factored_Denominator=0,s  ];  System_Roots  := [- 1., - .5000000000 -  .5000000000 + 1.322875656 I,  1.322875656 I]  Extracting and separating the roots from the System_Roots  expression:  w Root_1 := op 1, System_Roots ; Root_2 := op 2, System_Roots ; Root_3 := op 3, System_Roots ;  Root_1 := - 1. Root_2 := - Root_3 := -  .5000000000 + 1.322875656 I .5000000000 - 1.322875656 I  Now that we have the roots of the characteristic equation of the system,  we can see that none of the roots is in the right half plane  i.e., none of the real aspects of the complex roots exhibits a positive number , hence the system is stable. Stability is deﬁned when a bounded input produces a bounded output. If a system exhibits positive real roots, then the output grows exponentially with time for any input [1–3]. Further,  [1–3] indicate the following about the three roots:  Root_1 ﬁ Root_2, Root_3 ﬁ  Pure exponential decay term  Exponentially decaying sinusoidal term  In fact, we could have written the general time-domain response directly from these root expressions. Hence, the general form would have been  178  -  Continuous control application theory  Output  t  = K1e   [Root_1] t + e   Re[Root_2, 3]   cid:230  + K3 cos  cid:239  Im[Root_2, 3] cid:239  t  cid:246   Ł K2 sin  cid:239  Im[Root_2, 3] cid:239  t   where  Re[Root_2,3] ﬁ Real part of either Root_2 or Root_3 Im[Root_2,3] ﬁ K1, K2, K3  ﬁ Coeﬃcients dependent on intial conditions  Imaginary part of either Root_2 or Root_3  and characteristic roots  Partial fraction expansion A very useful way to derive the Laplace transforms of complex rational polynomials is to use a method known as partial fraction expansion [1–4]. This method allows the user to deal with smaller rational polynomials that transform easier via the Laplace transform deﬁnition. The basic idea here is that an Nth-order rational polynomial is equivalent to N ﬁrst-order rational polynomials.  Certain polynomials can have their partial fraction expression obtained  via Maple; however, for the simple approach, the roots must not be com- plex  i.e., they must be real numbers . If the roots are complex or purely imaginary, then you should use the complex option within the convert command argument when using the parfrac option. We demonstrate this and another approach for handling complex roots in the next subsection.  Real and distinct roots Consider the following Laplacian transfer function:  w Transfer_Function :=  s+5   s^3+6*s^2+11*s+6 ;  Transfer_Function :=  s + 5  s3 + 6 s2 + 11 s + 6  using the convert command with the parfrac option:  179   cid:246  ł  cid:230  Ł ł  Applied Maple for Engineers and Scientists  w Partial_Fraction_Form := convert Transfer_Function,  parfrac,s ;  Partial_Fraction_Form :=  1  s + 3  3  1  s + 2  + 2  1  s + 1  Now, we can take the Laplace transform of each transfer function con- tributor, multiply each term by the input driving function, and add them to obtain the complete output time-domain response  linearity property . To illustrate this, let’s assign new Maple variables to each contributor:  w First_Term := op 1,Partial_Fraction_Form ; Second_Term := op 2,Partial_Fraction_Form ; Third_Term := op 3,Partial_Fraction_Form ;  First_Term  :=  Second_Term := - 3  Third_Term := 2  1  s + 3  1  s + 2 1  s + 1  Now assume the input is a unit step:  w Unit_Step_Input := 1 s:  Then multiply each contributor with the input transform:  w First_Term_Laplace := First_Term*Unit_Step_Input;  Second_Term_Laplace := Second_Term*Unit_Step_Input; Third_Term_Laplace := Third_Term*Unit_Step_Input;  First_Term_Laplace  :=  Second_Term_Laplace := - 3  Third_Term_Laplace  := 2  1   s + 3  s 1   s + 2  s  1   s + 1  s  180  -  Continuous control application theory  take the inverse transform of each contributor:  w with inttrans :  First_Term_Time := invlaplace First_Term_Laplace,s,t ; Second_Term_Time := invlaplace Second_Term_Laplace,s,t ; Third_Term_Time := invlaplace Third_Term_Laplace,s,t ;  First_Term_Time  := - 1 3 3 2   - 3 t  + 1 e 3   - 2 t  e  3 2  - t  + 2  Second_Term_Time :=  Third_Term_Time  := - 2 e  and add all the output time-domain responses:  w System_Response_Time := First_Term_Time+Second_Term_Time  +Third_Term_Time;  System_Response_Time := - 1 3   - 3 t  + 5 e 6  + 3 2   - 2 t  e   - t   2 e  Compare this to the direct approach for obtaining the output response  to a unit step input function:  w System_Response_Time_Direct := invlaplace Transfer_  Function*Unit_Step_Input,s,t ;  System_Response_Time_Direct := - 1 3   - 3 t  + 5 e 6  + 3 2   - 2 t   e   - t   2 e  This last expression is identical to the previously obtained one except  that the ability to see the individual eﬀects of the roots is not directly ob- served. Obviously this method is especially useful when the reader needs to perform individual root analyses as they apply to the output’s response.  Real and nondistinct roots What about Maple’s ability to abstract the roots of a polynomial if the roots are real, but nondistinct  repetitive ? Let’s create a Laplacian output func-  181  - - -  Applied Maple for Engineers and Scientists  tion that exhibits two repetitive roots at s = - 2, a distinct root at s = - 3, and a zero at s = - 1, namely,  System_Response =  s + 1   s + 2 2  s + 3   Enter the function into Maple,  w System_Response :=  s+1    s+2 ^2* s+3  ; s + 1  System_Response =   s + 2 2  s + 3   perform the partial fraction expansion,  w Partial_Fraction_Form := convert System_Response,parfrac,s ;  Partial_Fraction_Form := -  1   s + 2 2  + 2  1  s + 2  2  1  s + 3  which is correct if you were to do a hand calculation, and then compare it to the coeﬃcient solutions  A, B, C   of the following expression, which is generated by the residue theorem [1–3]:  System_Response =  s + 1   s + 2 2 s + 3   =  A  s + 2  +  B   s + 2 2  +  C  s + 3  When compared to the Partial_Fraction_Form, this would indi-  cate the following values for the coeﬃcients:  A = 2 B = - 1 C = - 2  To prove this fact, let’s perform the analysis in Maple. We start by deﬁning the left- and right-hand sides of the last System_Response equation:  182  -  Continuous control application theory  f1 ﬁ Left-hand side f2 ﬁ Right-hand side  Hence,  w f1 :=  s+1    s+2 ^2* s+3  ;  f2 := A  s+2 +B  s+2 ^2+C  s+3 ;  f1 :=  f 2 :=  s + 1   s + 2 2  s + 3   A  s + 2  +  B   s + 2 2  +  C  s + 3  Then use Maple’s do loop capability to generate the diﬀerent simulta- neous equations  i.e., three diﬀerent solutions for three diﬀerent  values  re- quired to solve for the three unknown coeﬃcients:  w for i from 0 to 2 do  F1 i  := subs s=i,f1 : F2 i  := subs s=i,f2 : Equation i  := F1 i -F2 i : od:  Now with the three simultaneous equations, Equation i , gener- ated and stored in Maple’s memory, we regenerate the subscripted equa- tions, Equations, into a list with the seq command. Then we abstract each operand within the Equations list with the op command, and use Maple’s solve command to generate another list comprised of the coeﬃ- cient solutions, Solutions:  w Equations := [seq Equation i ,i=0..2 ]:  Eq_1 := op 1,Equations : Eq_2 := op 2,Equations : Eq_3 := op 3,Equations : Solutions := solve {Eq_1=0,Eq_2=0,Eq_3=0},{A,B,C} :  Finally, abstracting the results and reassociating those values back with  the original unknown variables, we obtain the numerical results of the un- known partial fraction coeﬃcients  A, B, C :  183   Applied Maple for Engineers and Scientists  w Results := subs Solutions,[A,B,C] :  A := op 1,Results ; B := op 2,Results ; C := op 3,Results ;  A := 2 B := - 1 C := - 2  These values agree with the values obtained using Maple’s  convert[parfrac] command. Hence, the reader can see that Maple performs a signiﬁcant amount of internal computation to obtain the partial fraction values of a given function with the convert[parfrac] command.  Continuing, let’s isolate the individual Laplacian terms by assigning  them variable names:  w First_Term_Laplace := A  s+2 ;  Second_Term_Laplace := B  s+2 ^2; Third_Term_Laplace := C  s+3 ;  First_Term_Laplace  := 2  Second_Term_Laplace := -  Third_Term_Laplace  := - 2  1  s + 2 1   s + 2 2  1  s + 3  Now, take the inverse Laplace transform of each partial fraction term:  w First_Term_Time := invlaplace First_Term_Laplace,s,t ;  Second_Term_Time := invlaplace Second_Term_Laplace,s,t ; Third_Term_Time := invlaplace Third_Term_Laplace,s,t ;  First_Term_Time Second_Term_Time := - Third_Term_Time  := 2 e t e := - 2 e   - 2 t   - 2 t   - 3 t   184   Continuous control application theory  The ﬁnal output time-domain expression is the sum of all partial frac- tion terms, hence the reader can see that the sum of these time-domain ex- pressions is identical to the direct inverse transform of the Partial_Fraction_Form obtained with Maple:  w System_Response_Time :=  invlaplace Partial_Fraction_Form,s,t ;  - 2 t  + 2 e  System_Response_Time := - t e   - 2 t    - 3 t   2 e  or the inverse of the System_Response:  w System_Response_Time_Direct :=  invlaplace System_Response,s,t ;  System_Response_Time_Direct  := - t e   - 2 t  + 2 e   - 2 t    - 3 t   2 e  or reiterating our hand-calculated version  now that Maple remembers the computed partial fraction coeﬃcients  :  w System_Response_Time_HC := invlaplace f2,s,t ;  System_Response_Time_HC := - t e   - 2 t  + 2 e   - 2 t    - 3 t   2 e   - 2t   The double root at s = - 2 caused the te  which is identical to the two previous time-domain inverse transforms. form in the out-  - 3t  put, whereas the real and distinct root at s = - 3 directly created the e term. The reason we know this is because each of the time-domain terms, First_Term_Time, etc., corresponds to each of the frequency-domain described roots, First_Term, etc., which is directly observed from the Maple commands previously shown, i.e.,  and e   - 2t   w First_Term_Laplace := A  s+2 ;  Second_Term_Laplace := B  s+2 ^2; Third_Term_Laplace := C  s+3 ;  185  - - -  Applied Maple for Engineers and Scientists  First_Term_Laplace  := 2  Second_Term_Laplace := -  Third_Term_Laplace  := - 2  1  s + 2 1   s + 2 2  1  s + 3  w First_Term_Time := invlaplace First_Term_Laplace,s,t ;  Second_Term_Time := invlaplace Second_Term_Laplace,s,t ; Third_Term_Time := invlaplace Third_Term_Laplace,s,t ;   - 2 t   := 2 e  First_Term_Time Second_Term_Time := - Third_Term_Time  t e := - 2 e   - 2 t   - 3 t   yielded  Hence,  Frequency domain  Time domain  First_Term_Laplace := 2  1  s + 2  Second_Term_Laplace := -  First_Term_Time := 2 e   - 2 t   Second_Term_Time := - t e   - 2 t   Third_Term_Laplace := - 2  Third_Term_Time := - 2 e   - 3 t   1   s + 2 2  1  s + 3  Remember, when Maple solves an equation or provides a transform of some function, the order of the result may not  and usually does not  corre- spond to the order in which the operands were entered into a Maple ses- sion for computation. Therefore, be careful of your Maple associations.  186   Continuous control application theory  Complex roots Maple can create a partial fraction expression directly from expressions containing complex roots. However, the user must specify the complex op- tion within the convert[parfrac] command.  Consider the transfer function from the system that was stated earlier:  System_Xfer_Function =  s s + 2 2  s3 + 2s2 + 3s + 2  Since we already know that Maple can directly solve for the roots, let’s obtain the system’s output response to a unit step function via partial frac- tion expansion. Hence, if  System_Response =  s s + 2 2   s + 2 2  s3 + 2s2 + 3s + 2  s3 + 2s2 + 3s + 2  =  1 s  Let’s attempt to perform the partial fraction expansion directly without  the complex option:  w System_Response :=   s+2 ^2   s^3+2*s^2+3*s+2 :  System_Response_Partial_Fraction := convert System_  Response,parfrac,s ;  System_Response_Partial_Fraction := 1 2  1  s + 1  + 1 2  6 + s  s2 + s + 2  and now with the complex option:  w System_Response_Partial_Fraction_C := convert System_  Response,parfrac,s,complex ;  System_Response_Partial_Fraction_C := .49998  1  +  .25001 + 1.0394 I  s + .50000 + 1.3229 I  +  s + 1 .25001 + 1.0394 I  - 1. s -  .50000 + 1.3229 I  187   cid:230   cid:231  Ł  cid:246   cid:247  ł -  Applied Maple for Engineers and Scientists  Depending on what the user desires, Maple has yielded either the  quadratic or fully factored complex partial fraction form. Maple can easily convert either expression into the correct time-domain expression, hence, the quadratic form:  w System_Response_Time := invlaplace System_Response_  Partial_Fraction,s,t ;  System_Response_Time := 1 2   - t  + 1 e 2   - e  1⁄2 t   cos  ‘ 7 t  1 2  + 11 14   - e  1⁄2 t   ‘ 7 sin  ‘ 7 t  1 2  or the complex form:  w System_Response_Time_C := invlaplace System_Response_  Partial_Fraction,s,t ;  System_Response_Time_C := .49998 e   - +  .25001 + 1.0394 I  e   - +  .25001 - 1.0394 I  e   - 1. t  .50000 - 1.3229 I  t  .50000 + 1.3229 I  t   We need to eliminate the explicit imaginary terms from the  System_Response_Time_C expression. To do so, we use the evalc command:  w System_Response_Time_C1 := evalc invlaplace System_  Response_Partial_Fraction,s,t  ;  System_Response_Time_C1 := .49998 e cos 1.3229 t  sin 1.3229 t   + .50002 e  - + 2.0788 e  .50000 t  .50000 t    -   - 1. t   or we could have converted the inverse to a trig with the simplify and convert[trig] command[option]:  188   cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  Continuous control application theory  w System_Response_Time_C2 := simplify convert invlaplace   System_Response_Partial_Fraction,s,t ,trig  ;  System_Response_Time_C2 := .49998 cosh t   .49998 sinh t  + .50002 cosh .50000 t  cos 1.3229 t  .50002 sinh .50000 t  cos 1.3229 t  + 2.0788 cosh .50000 t  sin 1.3229 t  2.0788 sinh .50000 t  sin 1.3229 t   Clearly, the System_Response_Time_C2 expression is not as  familiar to work with as either the System_Response_Time_C1 or System_Response_Time expressions. However, these expressions are approximately the same. The reason for the word approximate is due to the ﬂoating-point operations that Maple performs to obtain the complex computation.  An alternate and manual method for obtaining the time-domain re-  sponse of System_Response is to abstract the root denominators of the partial fraction expansion, System_Response_Partial_Fraction, by initially factoring the denominator of the System_Response and ob- taining the necessary terms to perform a general coeﬃcient partial fraction expansion form:  w System_Response :=   s+2 ^2   s^3+2*s^2+3*s+2 :  System_Response_Partial_Fraction := convert System_Response,  parfrac,s ;  System_Response_Partial_Fraction := 1 2  1  s + 1  + 1 2  6 + s  s2 + s + 2  As expected, the quadratic is left in the expansion. Now let’s separate  the denominator terms to deal with them more easily  we also divide by the common scalar so as to isolate the polynomials in s :  w First_Root := denom op 1,System_Response_Partial_  Quadratic_Root := denom op 2,System_Response_Partial_  Fraction   2;  Fraction   2;  First_Root := s + 1 Quadratic_Root := s2 + s + 2  189  - - -  Applied Maple for Engineers and Scientists  As stated previously, we can obtain a valid partial fraction expansion of  the System_Response when stated as follows:  System_Response =   s + 2 2  A  s3 + 2s2 + 3s + 2  s + Root_1  +  B  +  s + Root_2  s + Root_3  =  C  where A, B, C, Root_1, Root_2, Root_3 can be real or complex quanti- ties. The general Laplacian form obtained from this approach is  X  s + Root_Z  Inverse Laplace  XeRoot_Z  Continuing with our problem, we now solve for the roots of both ﬁrst-  order  FRoot_Output  and quadratic  QRoots_Output  terms:  w FRoot_Output := [solve First_Root=0,s ];  QRoots_Output := [solve Quadratic_Root=0,s ];  FRoot_Output := [- 1] QRoots_Output := Ø - 1 2  + 1 2  I  cid:214   ‘ 7 , - 1 2  I  cid:214   ‘ 7  1 2  We abstract and assign the roots to some interim Maple variables,  w FRoot := op 1,FRoot_Output ;  QRoot_1 := op 1,QRoots_Output ; QRoot_2 := op 2,QRoots_Output ; FRoot1 := - 1 Qroots_1 := - 1 2 Qroot_2 := - 1 2  + 1 2 1 2  I  cid:214   ‘ 7  I  cid:214   ‘ 7  generate the quadratic root’s partial fraction expansion along with the ﬁrst- order root operands,  190  Œ º ‘ - ‘ ø œ ß ‘ - ‘  Continuous control application theory  w PFraction_1 := A  s-FRoot ;  PFraction_2 := B  s-QRoot_1 ; PFraction_3 := C  s-QRoot_2 ;  Pfraction_1 :=  Pfraction_2 :=  Pfraction_3 :=  A  s + 1  s + 1 2  s + 1 2  B  C + 1 2  I  cid:214   ‘ 7  1 2  I  cid:214   ‘ 7  and add the individual partial fraction terms to obtain the total Laplace out- put response for the input unit step function:  w Partial_Fraction_Output := PFraction_1+PFraction_2+  PFraction_3;  Partial_Fraction_Output :=  A  s + 1  +  B  +  s + 1 2  I  cid:214   ‘ 7  1 2  s + 1 2  C + 1 2  I  cid:214   ‘ 7  Solving for the A,B,C coeﬃcients a little diﬀerently than before, we gen-  erate a set of equations with arbitrarily assigned values of the Laplace vari- able, s:  w PF_Output_1 := subs s=1,System_Response -subs s=1,Partial_  PF_Output_2 := subs s=2,System_Response -subs s=2,Partial_  PF_Output_3 := subs s=3,System_Response -subs s=3,Partial_  Fraction_Output ;  Fraction_Output ;  Fraction_Output ;  191  - ‘ ‘ - ‘ ‘  Applied Maple for Engineers and Scientists  PF_Output_1 := 9 8  PF_Output_2 := 2 3  A -  A -  1 2  1 3  PF_Output_3 := 25 56  A -  1 4  B 1 2 B 1 2 B 1 2  I  cid:214   ‘ 7  I  cid:214   ‘ 7  I  cid:214   ‘ 7  3 2  5 2  7 2  C + 1 2 C + 1 2 C + 1 2  3 2  5 2  7 2  I  cid:214   ‘ 7  I  cid:214   ‘ 7  I  cid:214   ‘ 7  and solve the simultaneous equations:  w Solutions  :=solve {PF_Output_1=0,PF_Output_2=0,  PF_Output_3=0},{A,B,C}  ;  Solutions :=  cid:236    cid:238  A = 1 2  , C = 1 4  + 11 28  I  cid:214   ‘ 7 , B = 1 4  11 28  I  cid:214   ‘ 7  cid:252   We abstract the results and assign the values to the appropriate  coeﬃcient:  w Results := subs Solutions,[A,B,C] :  A := op 1,Results ; B := op 2,Results ; C := op 3,Results ;  A := 1 2 B := 1 4 C := 1 4  11 28 + 11 28  I  cid:214   ‘ 7  I  cid:214   ‘ 7  and restate the original output partial fraction function to obtain Maple’s response:  192  - - ‘ - ‘ - - ‘ - ‘ - - ‘ - ‘  cid:237  ‘ - ‘  cid:253   cid:254  - ‘ ‘  Continuous control application theory  w Partial_Fraction_Output;  1 2  1  s + 1  +  1 4 s + 1 2  11 28  ‘ 7  I  cid:214   ‘ 7  I  cid:214  1 2  +  1 4 s + 1 2  + 11 I  cid:214  28 + 1 2  ‘ 7  I  cid:214   ‘ 7  Since we have complex terms in the coeﬃcients, let’s simply use  Maple’s evalc command when taking the inverse Laplace transform to in- terpret these automatically into contributing output response phase terms:  w System_Response_Time :=  evalc invlaplace Partial_Fraction_ Output,s,t  ;  System_Response_Time := 1 2   - t  + 1 e 2   - 1⁄2 t  e  cos  t  cid:214   ‘ 7  1 2  + 11 14  ‘ 7 e   - 1⁄2 t   sin  t  cid:214   ‘ 7  1 2  Finally, plotting the unit step response,  w with plots :  plot System_Response_Time,t=0..10,color=black,axes=normal,  labels=[Time,Response] ;  As Figure 5.3 shows, the result is identical to the previously plotted  Figure 5.2.  Let’s compare this ﬁnal result with Maple’s direct inverse Laplace  transform of the System_Response:  w Direct_Result := invlaplace System_Response,s,t ;  Direct_Result := 1 2   - t  + 1 e 2   - 1⁄2 t  e  cos  t  cid:214   ‘ 7  1 2  + 11 14  ‘ 7 e   - 1⁄2 t   sin  t  cid:214   ‘ 7  1 2  193  - ‘ - ‘ ‘ ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  Response  1.6  1.4  1.2  1  0.8  0.6  0.4  0.2  0 - 0.2 - 0.4  Figure 5.3 Partial fraction expansion solution to unit step response.  0  2  4  6  8  10  Time  The reader will see that the Direct_Result is identical to the partial  fraction result, System_Response_Time.  In summary, the use of partial fraction expansion is useful when analyz- ing the eﬀect of individual terms or roots associated with any linear system function. Originally, partial fractions were used when symbolic mathemat- ics packages were not available to students and professionals and obtaining time-domain solutions from large Laplace transforms was either impossible or cumbersome. Partial fraction expansion breaks the problem down into smaller transforms. In this way, the student or professional can obtain the inverse by hand and or look-up tables.  Time-domain approach  The state space approach to analyzing control systems has become ex- tremely popular due to the advent of computers. In fact, this method has almost become the de facto standard given the prevalence of the personal computer.  State space techniques use matrix representation of system parameters to ascertain transient, steady-state, and general dynamic responses of very high order linear and some nonlinear systems [1,3,5,6].  194   Continuous control application theory  Time-invariant versus time-variant systems For the remainder of this chapter, we examine constant coeﬃcient matrices  i.e., linear time-invariant systems . Time-dependent coeﬃcient or linear time-variant systems can require the users to perform a similarity or other type of transform [3–6] of the state space vector equation, which the authors do not want to involve the reader with at this time.  The authors do not want to confuse the reader by delving into some  odd systems that require this or other transformation techniques while studying the main chapter. We only want to expose the reader to the basic approach of state space using Maple from which all other techniques are usually derived or based. If the reader is more interested in this and other matrix transformations, they are referred to the cited references. A basic similarity transformation is depicted in Appendix A at the end of the book.  Analysis of a time-invariant system: fundamentals Our ﬁrst approach is to characterize the system by the use of state vari- ables, which are generated by choosing speciﬁc states or nodes  xi  of inter- est in the system under consideration. One starts by creating a set of state equations and putting them into a normal equation form, which simply means the set of simultaneous equations representing a linear transforma- tion of coupled dependent variables, hence,  . x  . x  1  2  . x N  = a11x1  + a12x2  + a13x3  + …  + a1NxN  + b11u1  + … + b1MuM  = a21x1  + a22x2  + a23x3 …  + a2NxN  + b21u1  + … +b2MuM  = aN1x1  + aN2x2  + aN3x3  + …  + aNNxN  + bN1u1  + … + bNMuM  which can be implemented into matrix formulation as  195   cid:215   cid:215   cid:215   Applied Maple for Engineers and Scientists  x1 x2 x3  a11 a21 a31  a12 a22 a32  a13 a23 a33  d dt  =  a1N a2N a3N  x1 x2 x3  b11 b21 b31  b12 b22 b32  +  xN  aN1  aN2  aN3  aNN  xN  bN1  b1M b2M b3M  u1 u2 u3  bNM  uM  which can then be restated in a matrix shorthand vector matrix form as  . = Ax + Bu x  or, in general,  . t  = A t x t  + B t u t  x  Similarly, the output vector y of any system can be stated as follows:  c11 c21 c31  c12 c22 c32  c13 c23 c33  y1 y2 y3  =  c1N c2N c3N  x1 x2 x3  d11 d21 d31  +  d1M d2M d3M  u1 u2 u3  dPM  uM  yP  cP1  cP2  cP3  cPN  xN  dP1  which, again, can be restated in shorthand vector matrix form as  y = Cx + Du  For our particular example, we will only have one input and one output  so the vector matrix equations reduce to  196  Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ Œ Œ  cid:215   cid:215   cid:215  ø œ ß œ œ œ œ œ œ œ œ  Continuous control application theory  . = Ax + Bu x y =   + du  where u, y,  , and d are scalars    represents the inner or scalar product .  Let’s start by converting the previous frequency-domain transfer func-  tion into a time diﬀerential form, i.e.,  Output Input  =  s s + 2 2  s3 + 2s2 + 3s + 2  First, cross-multiplying the Laplace transfer function, we obtain º s s + 2 2ø  º s3 + 2s2 + 3s + 2ø  ß = Input Ø  Output Ø  y t , Input ﬁ  u t  and realizing that s ﬁ  letting Output ﬁ vious expression becomes  assuming initial conditions are zero : d3y t  dt3  + 2y t  = d3u t  dt3  d2u t  dt2  d2y t  dt2  dy t  dt  + 3  + 2  + 4  + 4  du t  dt  d⁄dt, then the pre-  or in the shorthand dot notation, .. + 3y  … y + 2y  . + 2y = u + 4u  …  .. .. + 4u  Restating this problem into the normal state space equation form,  we get  . x . x . x  1  2  3  = x2 = x3 .. - … y = - 2y  . 3y  …  2y + u + 4u  . .. + 4u  The problem with directly implementing this form of the simulation is  .. the rather diﬃcult aspect of handling input derivatives  i.e., u, u rivatives, whether done in a numerical or symbolic simulation, create prob-   . De-  . , u  …  197  ß ” -  Applied Maple for Engineers and Scientists  lems due to the noisy nature associated with these operators. Noisy opera- tion means that, computationally, derivatives are very sensitive to slight variations in value. Therefore, any extraneous artifact not associated with the solution is ampliﬁed and will directly contribute to a lower quality re- sult. Consequently, utilizing the following state ﬂow diagram more easily fa- cilitates the vector matrix setup for either a time- or frequency-domain analysis, regardless of the input derivative variable number or order.  Figure 5.4 shows the general simulation diagram formulation for a sys- tem that can be expressed as a rational polynomial in s or time-domain vari- able derivative of the form  y s  u s   = ansn + an - 1sn - 1 + … + a2s2 + a1s + a0 bmsm + bm - 1sm - 1 + … + b2s2 + b1s + b0  u t   an 1-  a2  a1  y t   1 bm  a0  an  - bn 1-  - b2  - b1  - b0  Simulation diagram form for an arbitrary rational polynomial function. Hence, in the time-domain diﬀerential form,  y t  u t   =  an  dn dtn dm dtm  bm  + an - 1  + bm - 1  dn - 1 dtn - 1 dm - 1 dtm - 1  + … + a2  + … + b2  d2 dt2 d2 dt 2  + a1  d dt  + a0  + b1  d dt  + b0  Figure 5.4 General simulation diagram.  198  S S  cid:242   cid:242   cid:242   cid:242   Continuous control application theory  for  m ‡ n  . 2, x  . 3, …, x  This canonical simulation form is one of the easiest to implement provided one realizes that the state variables  i.e., . . . 1  are not directly representative of the diﬀer- 2, x 1, x x m - .. . ent output  i.e.,y, y , y , etc.  variable orders. However, one can easily obtain the solutions any of these y variables by directly taking the derivative of the output vector matrix equation. Therefore, plugging in our speciﬁc example into Figure 5.4 yields the simulation diagram of Figure 5.5.  m -  From Figure 5.5, we can generate the previous example’s state space  matrices by inspection, thus the form  . = Ax + Bu x y =   + du  1  u t   4  y t   4  x3  - 2  x = x  3  2  - 3  x = x  2  1  - 2  Figure 5.5 Simulation diagram for previously given example.  199  S S  cid:242   cid:242   cid:242   Applied Maple for Engineers and Scientists  . x . x . x  1  2  3  =  0 0 - 2  1 0 - 3  0 1 - 2  +  x1 x2 x3  u t   0 0 0  y t  = [- 2  1  2]  + [1] u t   x1 x2 x3  = - 2x1  + x2  + 2x3  + u t   becomes  where  A =  0 0 - 2  1 0 - 3  0 1 - 2  B  =  0 0 0  C = [- 2  1  2]  d = [1]  As the reader can see from the scalar output equation, the complete  output time-domain solution for this system y t  is obtained by solving the column state vector for any given input function, u t :  x1 x2 x3  ” x or x t   The state transition matrix The time-domain solution for the state space approach uses the following formulation [2,3]:  x t  = F   t -  F   t -  l  Bu l   dl   x t0 t0    +  cid:242   t  t0  200  Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ ” Ø Œ º Œ Œ ø œ ß œ œ  Continuous control application theory  where F   t -  t0  is the state transition matrix initiated at t0 and is deﬁned as  F   t -    ” t0  eA t -     t0  Therefore, evaluating our speciﬁc transition matrix, and assuming  t0 = 0, we have the following transition matrix expression:  F   t  ”  eAt = e  0 0 - 2t  t 0 - 3t  0 t - 2t  Cayley-Hamilton theorem The Cayley-Hamilton theorem [2–4] says that a matrix solves its own char- acteristic equation  via the eigenvalues ; hence, the transition or exponen- tial matrix can be solved by implementing this theorem. Therefore, because we have a third-order system, the transition matrix becomes  eAt = a   At 2 + a 2   At  + a 1  0I  where a 2, a 1, a 0 are scalars and  represents a 3 × 3 identity matrix. Obvi- ously, this matrix equation creates a 3 × 3 square matrix on both sides of the equation. Now we implement a scalar representation of the matrix equa- tion since the Cayley-Hamilton theorem says a scalar form of eigenvalues  l   will solve for the three unknown coeﬃcients, a 2, a 1, a 0…  it = a  e   l 2  it 2 + a   l 1  it  + a  0  where there are three scalar equations to solve in a simultaneous fashion due to the order of the system. Hence, 1t 2 + a  1t  + a  1t = a   l 2   l  e  0  1  2t = a  3t = a  e  e   l 2   l 2  2t 2 + a  3t 2 + a   l  1   l  1  2t  + a  3t  + a  0  0  201  Ø Œ º Œ Œ ø œ ß œ œ l l l l  Applied Maple for Engineers and Scientists  State space analysis with Maple Now, let’s determine the three  l 1, l 2, l 3  eigenvalues via the following matrix formulation:  detA -  I = 0  Hence,  w with  linalg :  A_Matrix := array  [[0,1,0],[0,0,1],[-2,-3,-2]] : Identity := array  [[1,0,0],[0,1,0],[0,0,1]] : Interim_1 := evalm  A_Matrix- lambda *Identity : Interim_2 := det  Interim_1 : Interim_3 := solve  Interim_2=0,lambda : Eigenvalue_1 := Interim_3[1]; Eigenvalue_2 := Interim_3[2]; Eigenvalue_3 := Interim_3[3];  Eigenvalue_1 := - 1 Eigenvalue_2 := - 1 2 Eigenvalue_3 := - 1 2  + 1 2 1 2  I  cid:214   ‘ 7  I  cid:214   ‘ 7  or using Maple’s eigenvals operand and abstracting the eigenvalues, we obtain the same result:  w Eigenvalues := [eigenvals A_Matrix ];  Eigenvalue_1 := op 1,Eigenvalues ; Eigenvalue_2 := op 2,Eigenvalues ; Eigenvalue_3 := op 3,Eigenvalues ;  + 1 2  I  cid:214   ‘ 7 , - 1 2  I  cid:214   ‘ 7  1 2  Eigenvalues := Ø Eigenvalue_1  Eigenvalue_2  Eigenvalue_3  - 1, - 1 2 := - 1 := - 1 2 := - 1 2  + 1 2 1 2  I  cid:214  I  cid:214   ‘ 7 ‘ 7  202  l ‘ - ‘ Œ º ‘ - ‘ ø œ ß ‘ - ‘  Continuous control application theory  Notice the I or imaginary component to our complex eigenvalues.  Also, note that complex eigenvalues must appear as conjugate pairs  Eigenvalue_2 and Eigenvalue_3 , whereas eigenvalue 1 is real, as we have seen before in the frequency-domain approach.  Continuing with our state transition matrix computation, remember  that  eAt = a   At 2 + a 2   At  + a 1  0I  therefore via the Cayley-Hamilton theorem we generate the simultaneous equation set as follows:  1t = a 2t = a 3t = a  e e e   l 2  l 2  l 2  1t 2 + a 2t 2 + a 3t 2 + a   l  l  l  1  1  1  1t  + a 2t  + a 3t  + a  0  0  0  or put into another form for Maple to solve  Equation_1 = a Equation_2 = a Equation_3 = a   l 2  l 2  l 2  1t 2 + a 2t 2 + a 3t 2 + a   l  l  l  1  1  1  1t  + a 2t  + a 3t  + a  0  0  0  1t  2t  3t  e e e  This is clearly messy, thus,  w Equation_1 := alfa2* Eigenvalue_1*t ^2+alfa1*  Eigenvalue_1*t +alfa0-exp Eigenvalue_1 *t ; Equation_2 := alfa2* Eigenvalue_2*t ^2+alfa1*   Eigenvalue_2*t +alfa0-exp Eigenvalue_2*t ;  Equation_3 := alfa2* Eigenvalue_3*t ^2+alfa1*   Eigenvalue_3*t +alfa0-exp Eigenvalue_3*t ;  203  l l l - l - l - l  Applied Maple for Engineers and Scientists  Equation_1 := alfa2 t2 -  alfa1 t + alfa0 -  t  e  Equation_2 := alfa2  - 1 2  + 1 2  I  cid:214   ‘ 7  2  t2  + alfa1  - 1 2  + 1 2  I  cid:214   ‘ 7  t + alfa0 -  e    - 1⁄2 + 1⁄2 I  cid:214   ‘ 7   t    Equation_3 := alfa2  I  cid:214   ‘ 7  2  t2  - 1 2  - 1 2  1 2  1 2  + alfa1  I  cid:214   ‘ 7  t  + alfa0 -    - 1⁄2 - e  1⁄2 I  cid:214   ‘ 7   t    and then  w Solutions := solve {Equation_1=0,Equation_2=0,  Equation_3=0},{alfa2,alfa1,alfa0} ;  Solutions :=  cid:236   alfa1 = -  1 28  I  e I  cid:214   ‘ 7 t   cid:214   ‘ 7 e   - t   cid:214   ‘ et -  I  cid:214    I  cid:214  ‘ 7 e  ‘ 7 t  - 5 -  ‘ 7 cid:246   I  cid:214   ‘ 7    ‘ 7 t  + 2 I  cid:214  ‘ et cid:246   ‘ 7 t   cid:214   e I  cid:214    I  cid:214  Ł 5 e Ł t  cid:214  + 35 e + 7 I  cid:214   - 6 I  cid:214    I  cid:214  ‘ 7 e  ‘ 7 t   , alfa2 = -  1 448 ‘ et - 14 e  I  cid:214    - t   cid:214   e I  cid:214   ‘ 7 t   cid:214   e I  cid:214   ‘ 7 t   cid:214   ‘ 7 e  - I  cid:214   ‘ 7 e   I cid:214   ‘ 7 t  -   - t   cid:214   I  cid:214  ‘ 7     cid:230  ł  - 5 + I  cid:214   - t   cid:214  ‘ 7 t   cid:214  e I  cid:214  ‘ et  ‘ 7 t   cid:214   ‘ et cid:246  ‘ 7 t  + 7 e e I  cid:214   ‘ 7 - 21 Ł t2  cid:214  ‘ et + I  cid:214   ‘ 7  alfa0 = 1 7  e I  cid:214   ‘ 7 t   cid:214   ‘ et cid:246   ,  Now abstract the roots and assign them to the appropriate variable:  204  -  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł ‘  cid:230   cid:231  Ł - ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł - ‘  cid:246   cid:247  ł ‘  cid:237   cid:238   cid:252   cid:253   cid:254   cid:230  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ł  cid:214  ‘  cid:230  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ł  cid:230  Ł ‘ ‘  cid:246  ł ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:230  Ł ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ł  cid:236   cid:237   cid:238   cid:239   cid:239   cid:239   cid:239  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘  cid:252   cid:253   cid:254   cid:239   cid:239   cid:239   cid:239   Continuous control application theory  w XX := subs Solutions,[alfa2,alfa1,alfa0] :  alfa2 := simplify XX[1] ; alfa1 := simplify XX[2] ; alfa0 := simplify XX[3] ;  alfa2 :=  cid:230   Ł 1⁄2t  - 1 + I cid:214   ‘ 7  cid:246   ł + 3 e   - 1⁄2t  I  cid:214   ‘ 7 + 1   -   - 1⁄2t  I  cid:214   ‘ 7 + 1    Ł 4 e + I e   - t   cid:214   ‘ 7 - 7 e   - t  cid:246   I  cid:214   ‘ 7 -  alfa1 :=  cid:230   Ł 16 e   - 1⁄2 t I  cid:214   ‘ 7 + 1   + 5 I  cid:214    1⁄2 t - 1 + I cid:214    1⁄2 t - 1 + I cid:214   ‘ 7     1 112 ‘ 7 e  I  cid:214   ‘ 7 e   t2  1 16 ‘ 7    - 9 e   t  ‘ 7  I  cid:214    - t   cid:214   ‘ 7 - 7 e  5 Ie   - t  cid:246   1 64  + 5 448  alfa0 := - 1 7  I  cid:214   ‘ 7 e   1⁄2 t - 1 + I  cid:214   ‘ 7   + e   - t  + 1 7  I  cid:214   ‘ 7 e   - 1⁄2 t I  cid:214   ‘ 7 + 1    Note the presence of the imaginary term, I . Unfortunately, Maple can-  not automatically “see” certain trigonometric identities which would ab- sorb the imaginary and real terms into trigonometric functions and, hence, would greatly ease our computations and simplify our results. The particu- lar trigonometric identities of interest here are  - Iq  cos q  = eIq + e sin q  = eIq - Iq e  2  2I  However, Maple can see these identities when asked to do so in a certain way. Let’s reformulate the alfa coeﬃcients by asking Maple to combine the exponentials and other terms in the coeﬃcients into any appli- cable trigonometric forms with the combine expression,trig  command. We will further ask Maple to simplify those trigonometric re- sults before displaying them. The evalc command requires the combina- tion process to use and be cognizant of complex forms in the trigonometric conversions.  205   cid:230  ‘ ‘ ‘ ‘  cid:246  ł  cid:230  Ł ‘ ł  cid:230   cid:231  Ł - ‘  cid:246   cid:247  ł ‘ ‘ ‘ ‘  cid:246  ł  cid:230  Ł - ‘ ł  cid:230   cid:231  Ł - ‘  cid:246   cid:247  ł ‘ ‘ ‘ ‘ -  Applied Maple for Engineers and Scientists  w alfa_0 := simplify evalc combine alfa0,trig   ; alfa_1 := simplify evalc combine alfa1,trig   ; alfa_2 := simplify evalc combine alfa2,trig   ;  alfa_0 := 2 7   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t   - t   + e  1 2  alfa_1 := 1 14  alfa_2 := 1 14   - 1⁄2 t   - 7 e  cos  ‘ 7 t  + 5  cid:214   ‘ 7 e   - 1⁄2 t   sin  ‘ 7 t  + 7 e   - t   1 2   - 1⁄2 t   - 7 e  sin  - 7 e   - 1⁄2 t   cos  7 t  1 2  7 t  + 7 e   - t   1 2  1 2  t  t2  Now we have the coeﬃcients in terms that are necessary for substitu- tion into the transition matrix. Therefore, solving for the transition matrix  assuming t0 = 0 :  F   t  ”  eAt = e  0 0 - 2t  t 0 - 3t  0 t - 2t  œ = a   At 2 + a  2   At  + a 1  0I  by directly substituting the alpha coeﬃcients  alfa_0,alfa_1, alfa_2  and performing the following substitution into the time variable t as  t = t -  we can set up the Transition_Matrix  F  expression into the follow- ing  zero initial conditions and t0 = 0  for integration. Also, substituting the input step function, u z  = 1, and the B matrix will also ﬁnalize the inte- grand product setup, hence, symbolically we perform the following:  t -  z   x t  = F   t -  F   t -  z  Bu z   dz   x t0 t0    +  cid:242   t  t0  for t0  = 0 and x t0    = 0 then becomes  206   cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘ ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘ ‘  cid:246   cid:247  ł Ø Œ º Œ Œ ø œ ß œ z  Continuous control application theory  x t  =  cid:242   F   t -  z  Bu z   dz  for u z  = 1 which becomes x t  =  cid:242   z  B dz  t -  F   t  t  0  0  Implementing this with the Maple commands,  w Transition_Matrix := evalm subs t=t-zeta,alfa_2*   A_Matrix*t ^2+alfa_1*A_Matrix*t+alfa_0*Identity  :  B_Matrix := array [[0],[0],[1]] :  Now with the integrand component computed, we perform matrix multiplication of the B_Matrix and Transition_Matrix matrices, which completes the integrand expression  w Integrand := evalm Transition_Matrix&*B_Matrix ;  Integrand :=  1 14  - 1 2  3 14  + 1 2  + 1 2   - 1⁄2 t + 1⁄2 z   ‘ 7 e  sin  ‘ 7  t -  z   1 2  1 2  1 2  1 2  1 2   - 1⁄2 t + 1⁄2 z  e  cos  ‘ 7  t -  z    - t + z  ø  + 1 2  e   - 1⁄2 t + 1⁄2 z   ‘ 7 e  sin  ‘ 7  t -  z    - 1⁄2 t + 1⁄2 z  e  cos  ‘ 7  t -  z    - t + z  ø e  1 2  5 14  ‘ 7 e   - 1⁄2 t + 1⁄2 z   sin  ‘ 7  t -  z   1 2   - 1⁄2 t + 1⁄2 z  e  cos  ‘ 7  t -  z    - t + z  ø e  + 1 2  Obtain the individual state variables  x t   results:  207  Ø Œ º  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł ø œ ß Ø Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß Ø Œ º  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł ø œ ß Ø Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł - œ ß Ø Œ º -  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł ø œ ß Ø Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß  Applied Maple for Engineers and Scientists  w State_X1 := [int Integrand[1,1],zeta=0..t ]; State_X2 := [int Integrand[2,1],zeta=0..t ]; State_X3 := [int Integrand[3,1],zeta=0..t ];  State_X1 := Ø  1 2  - 1 7   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2   - t ø e  - 1 2  State_X2 := Ø  State_X3 := Ø  - 1 2  1 2   - 1⁄2 t  e  cos  ‘ 7 t  1 2  + 1 14   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2   - 1⁄2 t  e  cos  ‘ 7 t  1 2  + 3 14   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2  - 1 2   - t ø e  + 1 2  - t ø e  Create the state variable vector  State_Variable_Vector  and  convert the matrix or array into a vector for an inner product computation done later:  w State_Variable_Vector := con-  vert stack State_X1,State_X2,State_X3 ,vector ;  State_Variable_Vector := Ø  1 2  - 1 7   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2  - 1 2   - t   e  - 1 2  e   - 1⁄2t   cos  1 2  ‘ 7 t  + 1 14   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2  + 1 2   - t  e   - 1⁄2 t   cos  1 2  e  ‘ 7 t  1 2  + 3 14   - 1⁄2 t   ‘ 7 e  sin  ‘ 7 t  1 2   - t ø e  - 1 2  Enter the C vector in the output equation:  w C_Vector := vector [-2,1,2] ;  C_Vector := [- 2  1  2]  and substitute into the output function by implementing the inner product operation of the C_Vector with the State_Variable_Vector plus addition of the input step function:  208  Œ º  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß Œ º  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł ø œ ß  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł Ø Œ º  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł œ ß  Continuous control application theory  w Output := innerprod C_Vector,State_Variable_Vector +1;  Output := 11 14  ‘ 7 e   - 1⁄2 t   sin  ‘ 7 t  1 2  + 1 2   - t  e  + 1 2   - 1⁄2 t  e  cos  ‘ 7 t  1 2  As stated earlier, even though the state variables chosen,  x1 t , x2, t , x3 t , do not directly represent time derivative states of the out- put  as is true in some simulation diagram forms , the output equation, y t  =   + du t , related these computed states and any inputs, to the ﬁnal output result, Output.  Now we plot this result to compare with the previous section using the  frequency-domain approach to get the solution:  w with plots :  plot Output,t=0..10,color=black,axes=normal,  labels=[Time, Response] ;  Response  1.6 1.4  1.2 1  0.8 0.6 0.4 0.2 0 - 0.2 - 0.4  Figure 5.6 Output response for the third-order system example.  0  2  4  8  10  6  Time  Figure 5.6 is identical to the frequency-domain output plot depicted in Figures 5.2 and 5.3. The diﬀerence with this approach is the more general mathematics involved with the system’s dynamics. The state space ap- proach is also useful when the coeﬃcients are functions of time. This linear time-variant system cannot be handled by Laplace transform methods,  209   cid:214  ‘  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  Applied Maple for Engineers and Scientists  Conclusion  hence, with the use of personal computers and Maple, one can perform some rather indepth dynamic analyses utilizing the state space technique just discussed  see MATRZANT.MWS ﬁle on enclosed diskette .  In this chapter, we have examined a simple template application of a third- order linear system for both frequency- and time-domain approaches. The fundamental diﬀerence was that the Laplace transform method was simpler to understand and mathematically set up, since all computations are alge- braic in nature. However, if the system dynamics have nonconstant coeﬃ- cients, then the state space or time-domain approach would have been the only method available to us for analysis. In either case, we had the ability to see the individual characteristic root eﬀects. Though expressly discussed in the Laplace transform via partial fraction expansion, we did not get into the equivalent analysis via eigenvalue observation with the state space method. However, one obtains this individual root eﬀect information on computation of the characteristic equation root solution in the state space approach. Since the characteristic equation has to be computed as a natural course of solving the control problem in the time domain  i.e., the eigenval- ues , there was no need to examine speciﬁcally the individual root eﬀect on the output response.  Maple has given the user a quick and exhaustive method of setting up and solving linear control problems of any order. In our template applica- tion, we used a documented third-order system, but it could have easily been a much higher order system without any change in either the mathe- matical or Maple syntax procedures.  As for nonlinear control problems, the standard procedure for setting  up the solutions using describing or linearizing functions and numerical methods for obtaining speciﬁc solutions under a set of initial conditions is well documented [5,6] and easily implemented with Maple. The funda- mental diﬀerence between linear and nonlinear solutions in Maple would be the increased number of procedures for numerical iteration to obtain bounded error solutions. However, the study of nonlinear systems with Maple was not the intention of the authors for this text at this time. Such systems require a much more rigorous mathematical base than we have pre- sented for this section and is better left for another chapter.  210   Continuous control application theory  References  [1] DeRusso, Roy, and Close, State Variables for Engineers, New York:  John Wiley & Sons, 1965.  [2] Dorf, R., Modern Control Systems, Reading, MA: Addison-Wesley  Publishing Co., 1967.  [3] Hirsch, M., and S. Smale, Diﬀerential Equations, Dynamical Systems,  and Linear Algebra, New York: Academic Press, 1974.  [4] Saucedo, R., and E. Schiring, Introduction to Continuous and Digital  Control Systems, New York: Macmillan Publishing Co., 1968.  [5] Ku, Y. H., Analysis and Control of Nonlinear Systems, The Ronald  Press Co., 1958.  [6] Cunningham, W. J., Introduction to Nonlinear Analysis, New York:  McGraw-Hill Book Company, 1958.  211   Applied Maple for Engineers and Scientists  Chapter 6  Discrete control applications  Digital control is dependent on our being able to perform two  fundamental operations, sampling and storage, both of which can be simulated in a Maple session. Through the process of sampling  the signals present within a continuous system, we physically and mathe- matically transform the continuous system into a discrete or digital one. The eﬀect of sampling a continuous control system can be rather dramatic as the following example illustrates. Using the Laplace operator s, deﬁne the transfer function of a dynamic system as follows:  1  1 + s2  which has the corresponding impulse response shown in Figure 6.1.  213   Applied Maple for Engineers and Scientists  By simply sampling this conditionally stable system we transform it  into an unconditionally stable one as the impulse response of the sampled system shows  Figure 6.2 .  1  0.5  - 0.5  - 1  0.5  0.4  0.3  f t   0.2  0.1  0  0  - 0.1  Figure 6.1 Continuous system.  Figure 6.2 Sampled system.  214  f t   0  0  2  4  6  8  10  t  t  2  4  6  8  10   Discrete control applications  The impulse response of the sampled system, in terms of the delay op-  erator  1 z , is  1 - 1 + z  - 2  2 + 2z  The process of transforming a continuous system into a discrete one,  computing the discrete system’s time response using Maple, is discussed in this chapter.  First we see how, by using Maple, we can obtain the pulse transform  function of a continuous system  converting from a continuous to a discrete system  and then apply a forcing function and compute the resulting time series. Then we see how Maple can help us form the state space matrices from a system’s transfer function and then convert the matrices from one ca- nonical form to another.  The pulse transfer function is the digital version of the continuous system’s transfer function and describes the digital system’s behavior in terms of in- put and output pulses. Commonly, the input and output pulse trains are produced by sampling both the input and output signals repeatedly at a ﬁxed rate, the sampling rate for the system. The idea of the pulse transfer function is conveyed in Figure 6.3 where x t  is the system input and G s  is the system’s dynamics. You will notice that both starred variables, which are functions of time, and functions of z are used to label the same signals on the diagram. The starred variables represent sampled continuous sig- nals, whereas the variables that are a function of z represent the continuous signals transformed into the discrete realm, via a transformation technique, and is the notation that we will be using in this chapter. Both sets of starred and z signals are equivalent and can be thought of as time series of weighted impulses. The connection between a continuous signal and its starred and z representation is shown in Figure 6.4.  The pulse transfer function  x t   *  x  t  X z   T  G s   *  y  t  Y z   T  Figure 6.3  215   Applied Maple for Engineers and Scientists  Continuous signal  Sampled  2 1.5 1 0.5 0 - 0.5  20  4  8  10  6 t  Transformed  2 1.5 1 0.5 0 - 0.5  2 1.5 1 0.5 0 - 0.5  Starred signal  20  4  6  8  10  t  z signal  z0  z- 2  z- 8  z- 10  z- 6 z- 4 1 z  Transforming continuous signals A number of techniques are available to us by which we can compute the Z-transform of a continuous signal. The most direct technique involves summing an inﬁnite series of samples or weighted impulses; other tech- niques involve approximation by substitution and transforming from the s domain to the z domain. This ﬁnal method is also known as the impulse or step invariant transform. We consider the direct approach ﬁrst. A step of amplitude a  can be described as the following series for positive n.  w Step := n->alpha*z^ -n ;  Step := n ﬁ   - n   z  A unit step function, i.e., a =1, is shown in Figure 6.5. The ﬁrst ten terms of the step function are easily calculated:  w TERMS:=convert [seq Step n , n=0..10 ], ‘+’ ;  TERMS := + a +  z  +  +  +  +  +  +  +  +  z2  z3  z4  z5  z6  z7  z8  z9  z10  Figure 6.4  216  a a a a a a a a a a a  Discrete control applications  h t   1  0.8  0.6  0.4  0.2  0  0 t  - 10  - 5  5  10  Figure 6.5 A unit step.  If we now sum our series from zero to inﬁnity and a closed form exists,  it will by deﬁnition be the Z-transform of the continuous step function a h t .1 The variable n needs to be reset because it currently has a value from the previous seq operation. Now we can perform the summation2  w n:=’n’:  n=0..infinity ;  Sum Step n , n=0..infinity =sum alpha*z^ -n ,   - n  =  z  z - 1 + z  n = 0  The right-hand side of this expression represents the closed-form solu-  tion, which we denote as STEP.  1. The unit step is commonly denoted by h t .  2. The function Sum is the inert form of the function sum. Maple returns inert function calls unevaluated.  217   cid:229  ¥ a a  Applied Maple for Engineers and Scientists  w STEP:=rhs “ ;  STEP :=  z  - 1 + z  The convention when using the Z-transform is that the current sample is denoted by z0; the next sample, the one taken after a delay of one sample period, is z- 1; the sample taken after two sample delays is z- 2; and so on. This means that a series of samples can be easily time shifted either by mul- tiplying or dividing by the z operator  multiplying will shift the series for- ward in time whereas dividing will delay it . It is for this reason that the z operator is also known as the delay operator.  Next we ﬁnd the Z-transform of the exponential sequence Aet t where t  is the time constant:  w Exp:=A*exp tau*t ;  As before we sum this expression for t = 0..inﬁnity:  w sum Exp*z^ -t , t=0..infinity ;   t Exp := A e  t    a  t   A e   - t   z  t = 0  Unfortunately, this is not what we expect as Maple has returned an un-  evaluated form. We are still able to compute the Z-transform of the expo- nential sequence by performing a simple substitution, rt = et t, and then performing the summation on this new expression:  w TEMP:=subs exp tau*t =r^t, Exp ;  TEMP := A rt  218  a  cid:229  ¥  Discrete control applications  w Z_Exp:=sum TEMP*z^ -t , t=0..infinity ;  Z_Exp := -  A z r -  z  Now we can perform the substitution, r = et T where T is the sampling  period, to obtain the general Z-transform of the exponential sequence:  w Z_Exp:=normal subs r=exp tau*T , Z_Exp  ;  Z_Exp :=  A z  t T  + z - e  Using the Z-transform for the exponential sequence we can easily ﬁnd the Z-transforms of a whole new class of functions, for example, trigono- metric functions. Here we ﬁnd the Z-transform of the function sin w  t :  w ToExp := convert sin omega*t , exp ;  ToExp := - 1 2   I w e  t   I  1  I w e  t   Before we continue we need to change the expression ToExp slightly:  w ToExp:=subs 1 exp I*omega*t =exp -I*omega*t , ToExp ;  ToExp := - 1 2  I  cid:230    I w Ł e  t    - I w  e  t  cid:246   With reference to this expression, we see that t  in the general expres- sion for the Z-transform of the exponential Ae t t  = …, calculated earlier, is equal to Iw   and A is equal to unity, so sub- stituting we get the following:   the sign of t equals the sign Iw  219   cid:230   cid:231  Ł -  cid:246   cid:247  ł - ł  Applied Maple for Engineers and Scientists  w ZTF:=subs exp I*omega*t =Z_Exp, tau=I*omega,  exp -I*omega*t =Z_Exp, tau=-I*omega, A=1, ToExp ;  ZTF := - 1 2  I  z  z   I w T  + z  - e   - I w T  + z - e  By representing the exponential terms as trigonometric functions we display the above expression ZTF in its usual form. Again, because we are using a CAS, the sequence of the operations and type of operation per- formed do not always match the sequence of operations that we would ex- pect if we were solving the same problem by hand.  w convert ZTF, trig ;  - 1 2  I  - cos w T   -  z I sin w T   + z  z  - cos w T   + I sin w T   + z  w normal “, expanded ;  z sin w T    cos w T  2 -  2 cos w T   z + sin w T  2 + z2  So, ﬁnally we have the Z-transform of sin w  t :  w simplify “ ;  z sin w T    - 2 cos w T   z + 1 + z2  Of course, whenever using a computer algebra tool we should always  exercise some caution as the ﬁnal example of computing the Z-transform di- rectly shows. Here we are trying to return the Z-transform of the unit ramp shown in Figure 6.6.  220   cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247  ł  Discrete control applications  w RAMP = sum n*z^ -n , n=0..infinity ;  1 2  1 -  1 z4 z  - 1 + z 3 z2  1 2  z  RAMP = 2  w simplify “ ;  RAMP = - 1 + 2 z z - 1 + z 2  r t   10  8  6  4  2  0  Figure 6.6 A unit ramp.  0  2  4  6  8  10  t  Unfortunately, Maple returns an incorrect answer when compared with the result returned by the built-in Z-transform function ztrans:  w ztrans t, t, z ;  z   z -  1 2  221   cid:230   cid:231  Ł  cid:246   cid:247  ł -  Applied Maple for Engineers and Scientists  We conﬁrm our suspicions by taking the inverse transform of the Z-  transform of the ramp obtained using the direct method.  w invztrans “”", z, t ;  D  t  RAMP = -  D  t -  1  + t  The moral of the story is that care should always be exercised when us-  ing computers to manipulate complex expressions and answers should be checked wherever possible!  Impulse-invariant transformation The method of substituting for the exponential terms, as in the sin w t  ex- ample given earlier, is more formally known as the impulse-invariant trans- formation and is commonly used when a continuous system needs to be quantized. Using this technique we compute the Z-transform of a test sys- tem by ﬁrst obtaining the system’s impulse response and expanding it us- ing partial fractions and substituting for the exponential terms. This technique is easily demonstrated with a simple example. Consider the fol- lowing continuous Laplace expression:  w SYS:=4  s^3+6.5*s^2+5.5*s ;  SYS := 4  1  s3 + 6.5 s2 + 5.5 s  The ﬁrst step is to transform the transfer function into partial fractions using convert ..., parfrac,... . . Before we do this we must convert the ﬂoating-point numbers in the denominator of SYS into rationals:  w SYSR:=convert SYS, rational ;  SYSR := 4  s3 + 13 2  1 s2 + 11 2  s  222   Discrete control applications  w PF:=convert SYSR, parfrac,s ;  PF := 8 11  1 s  + 32 99  1  2 s + 11  8 9  1  s + 1  The partial fraction form of the transfer function is used because it en- sures that when we take the inverse Laplace transform of it we get a result that consists of atomic elements; in this case, steps, impulses, and exponen- tial terms. The Laplace transform pair is loaded from the inttrans pack- age using with as follows:  w with inttrans, [laplace, invlaplace] :  IRESPONSE:=invlaplace PF, s, t ;  IRESPONSE := 8 11  + 16 99   - 11⁄2 t  e   - t  e  8 9  Now we can substitute for the step and the exponential terms using the  transforms calculated earlier. We will do the substitutions one at a time starting with the step.  w H[z]:=subs alpha=select type, IRESPONSE, numeric , STEP ;  Hz := 8 11  z  - 1 + z  w Exps := select has, IRESPONSE, exp ;  Exps := 16 99   - 11⁄2 t  e   - t  e  8 9  Here we deﬁne a custom conversion routine  “teach” Maple’s convert  routine a new conversion type  to transform the exponential terms. The routine takes an expression containing an exponential and makes a copy  a1  of the numeric multiplier, if present, it makes a copy  a2  of the expo- nential and then ﬁnds the free variable  a3 . The transformation is then made using subs and the contents of a1, a2, and a3.  223  - - -  Applied Maple for Engineers and Scientists  w ‘convert toexp’:=proc a  local a1, a2, a3;  options ‘Copyright Coded by Dr. Steve Adams 1995’; a1:=select type, a, numeric ; a2:=op select type, a, function  ; a3:=op indets a2  ; subs A=a1, alpha=a2, a3=T, A*z  z-exp alpha   : end:  We apply the conversion routine to the remaining elements of the im-  pulse response and compute the complete pulse transfer function Hz.  w H[z]:=H[z] + map convert, Exps, toexp ;  Hz  := 8 11  z  - 1 + z  + 16 99  z  - 11⁄2 T   - e  8 9  z -  z  - T   e  z -  The Z-transform Hz still is general in that the sample period T is still  present as a variable, which gives us a chance to see how the simple choice of sample period aﬀects the impulse response of the system. The following sequence of Maple commands computes the time response of Hz, trans- forms the time response into function notation, and then generates a three- dimensional surface as the sample period T is varied:  w h t :=invztrans H[z], z, t ;  h t  :=  1 99  13⁄2  t  cid:246   + 16 cid:230   72  Ł eT cid:246   11⁄2  t  cid:246   88  Ł eT cid:246   t  13⁄2  Ł eT cid:246  t  cid:246   Ł eT cid:246   w h t :=unapply h t , T, t ;  h t  :=  T, t  ﬁ  1 99  13⁄2  t  cid:246   + 16 cid:230   72  Ł eT cid:246   11⁄2  t  cid:246   88  Ł eT cid:246   t  13⁄2  Ł eT cid:246  t  cid:246   Ł eT cid:246   224   cid:230  Ł  cid:230  ł ł ł -  cid:230  Ł  cid:230  ł ł  cid:230  Ł  cid:230  ł ł  cid:230  Ł  cid:230  ł ł ł -  cid:230  Ł  cid:230  ł ł  cid:230  Ł  cid:230  ł ł  Discrete control applications  w plot3d h ‘t’  T, t , t=0..3, T=0.01..1, labels=[‘’T’’,  ‘’t’’, ‘h t ’], title=’Effect Of T Size On System Impulse Response’, axes=BOXED, style=HIDDEN, color=BLACK, orienta- tion=[-25, 70] ;  Figure 6.7 shows how the eﬀective time constant of the system  increases as the sample period is reduced.  h t   0.6  0.5  0.4  0.3  0.2  0.1  0  0  Figure 6.7 Effect of T size on system impulse response.  0.5  1  T  1.5  2  2.5  3  0  0.2  0.4  t  0.6  0.8  1  Substitution methods Next we take a look at two of the substitution methods available for calculat- ing the Z-transform of a continuous signal or system. The two techniques that we will look at are  1  using a numerical solution to the diﬀerential equation and  2  the bilinear transform. Both techniques provide a relation- ship between the Laplace operator s, which is equivalent to the diﬀerential operator d⁄dt, and the delay operator z, which means that we can transform between continuous and discrete functions.  The ﬁrst approach relies on us being able to make the following  approximation:  x t  »  ¶ t  x n  -  1   x n - T  225  ¶  Applied Maple for Engineers and Scientists  This expression approximates the derivative of x t  with a ﬁnite diﬀer-  ence, which is true for a suﬃciently small sample period T. If we use the respective operator notation, d⁄dt = s, and the delay as 1⁄z, in the above approximation, we get  w Approx[1] := s= 1-z^ -1   T;  Approx1 := s =  - 1 z  + 1 T  The bilinear transform on the other hand is derived by solving a simple  ﬁrst-order ordinary diﬀerential equation  ODE  of the form  w ODE:=diff y t , t  + a*y t  = b*u t ;  ODE :=  y t   + a y t  = b u t   ¶ t  using a popular numerical integration technique. The bilinear transform is in fact a conformal mapping, which translates the jw onto the unit circle of the z-plane. If we integrate each side over the limits  n - 1 T to nT we get:  axis of the s-plane  w IntODE:=map int,lhs ODE , t= n-1 *T..n*T =int rhs ODE ,  t= n-1 *T..n*T ;  IntODE := y n T   -  +  n T  +  cid:242    n - 1 T  y n T - T   a y t  dt =  cid:242   n T   n - 1 T  b u t  dt  The unevaluated integrals can be approximated by applying the trape-  zoid rule  see ?student[trapezoid] . First we isolate the integrals, using select, and then apply the trapezoid rule. The command select type, lhs IntODE , specfunc anything, int   is used to isolate the functions of the form int anything, anything  from the expression lhs IntODE .  226   cid:230   cid:231  Ł ¶  cid:246   cid:247  ł  Discrete control applications  w TheInts:=[select type, lhs IntODE , specfunc anything,  int  ,rhs IntODE ];  TheInts :=  n T   n - 1 T  a y t  dt,  cid:242   n T  b u t  dt   n - 1 T  w Y:=student[trapezoid] op op 1, TheInts  , 1 ;  Y := 1 2   n T -   n - 1 T    0  i = 0  a y  n - 1  T  + 2  a y  n - 1  T + i n T -   n - 1 T    + a y n T    Expanding and simplifying the above result we get  w Y:=expand simplify Y  ;  Y := 1 2  T a y  n -  1  T   + T a  y n T - T + i T    0  i = 1  + 1 2  T a y n T    If we do the same with the second element of TheInts and combine  the results we get the following:  w U:=expand simplify student[trapezoid] op op 2,  TheInts  ,1   :  w RR:=convert [op 1..2, lhs IntODE  , op 1,Y , op 3,Y ],  ‘+’ =  convert [op 1, U , op 3, U ], ‘+’ ;  RR := y n T   -  y n T - T   + 1 2  T a y  n -  1 T    + 1 2  T a y n T   = 1 2  T b u  n -  1 T   + 1 2  T b u n T    227  Ø Œ º  cid:242  ø œ ß  cid:230   cid:231  Ł  cid:231   cid:231   cid:230   cid:231  Ł  cid:231   cid:231   cid:229   cid:246   cid:247  ł  cid:247   cid:247   cid:246   cid:247  ł  cid:247   cid:247   cid:230   cid:231  Ł  cid:231   cid:231   cid:229   cid:246   cid:247  ł  cid:247   cid:247   Applied Maple for Engineers and Scientists  Taking the Z-transform of this diﬀerence equation by substituting for  x nT  = x and x  n - 1 T  = xz- 1, where x can be either y or b, we get  w ZT:=subs   n-1 *T =  n*T-T ,  n*T-T =1 z, n*T=1,RR ;  ZT := y 1  -  y  T a y  1 z  + 1 2  T a y 1   1 z  1 z  + 1 2  + 1 2  = 1 2  T b u  T b u 1   By convention transformed variables are represented as uppercase  characters, for example, Z y t   ﬁ Y z  where Z y t   is the Z-transform of y t . We can achieve this cosmetic change in the above transformed expres- sion by ﬁrst clearing the variables Y and U, which we used earlier, and then deﬁning two functions as follows. When the expression ZT is used next Maple will automatically perform the simpliﬁcation.  w Y:=’Y’:U:=’U’:  y:=x->Y[z]*x:u:=x->U[z]*x:  Solving for Y[z] U[z], the system’s transfer function, we get the  following:  w Discrete:=simplify solve ZT,Y[z]   U[z]; T b  1 + z  2 + T a + T a z  Discrete :=  2 z -  If, by deﬁnition, the discrete and the continuous transfer functions are  similar, we need to compare them in order to determine under what cir- cumstances this is true. First, therefore, let us compute the s-domain repre- sentation of the ode  d dt y t  + ay t  = bu t   The use of the Maple alias facility enables us to view the result in a con-  cise form:  228   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  Discrete control applications  w y:=’y’:u:=’u’:  alias y[s]=laplace y t ,t,s , b[s]=laplace u t , t,s  : laplace ODE, t, s ;  ys s -  y 0  + a ys  = b bs  Now solving the above for y[s] b[s], setting y 0 =0, and assuming that  the system is initially at rest, we get the following continuous transfer function:  w Continuous:=subs y 0 =0,solve “, y[s]   b[s];  Continuous :=  b  s + a  By comparing the Discrete and Continuous expressions we can  see that for them to be equal the following must be true:  w Approx[2]:=simplify readlib isolate  Continuous=  Discrete, s  ;  Approx2 := s = 2  - 1 + z T 1 + z   This mapping is the bilinear transform. If we now apply this and the previous mapping to our test system with a sample period of 1⁄5 we get:  w tf[1]:=convert simplify subs Approx[1], T=1 5, SYS  ,  rational ;  tf1 := 8 5  - 50 + 215 z -  z3 291 z2 + 126 z3  w tf[2]:=convert simplify subs Approx[2], T=1 5, SYS  ,  rational ;  229   Applied Maple for Engineers and Scientists  tf2  = 4 5   1 + z 3   - 1 + z   cid:230   Ł 81 -  378 z + 341 z2 cid:246   Finally, we show the ﬁrst transformation again so that the results of all  three techniques can be easily compared:  w tf[3]:=convert simplify subs T=1 5,H[z]  , rational ;  z  cid:230   tf3 := 8 99 Ł + 2 e   - 1⁄5   - 11 z e   - 1⁄5  + 2 e   - 11⁄10   z + 9 e   - 13⁄10  + 9 z  11 e   - 11⁄10  cid:246   ł    cid:230   Ł  - 1 + z   cid:230   Ł z -   - 11⁄10  cid:246  e  Ł z -   - 1⁄5  cid:246  e  It is obvious that each approach results in a subtly diﬀerent answer.  The diﬀerences can be seen if we plot the impulse response obtained from each of the transfer functions. The following procedure generates a list of points that, when plotted, gives a staircase plot from a Z-transform and a time range. One thing to note in the procedure is the use of eval and the delay quotes. The delay quotes are used so that the sequence operator functions correctly and eval is used to force evaluation of the point pairs generated:  w calc_response:=proc X, Z, R   options ‘Copyright Coded by Dr. Steve Adams 1996’; local ans, pts, n, var; var:= op 1, R ; ans:= invztrans X,Z,var ; ans:=eval [‘seq’ [var, ans], R ] ; pts:=NULL; for n to nops ans -1 do  pts:=pts, ans[n], [op 1, ans[n+1] , op 2, ans[n] ];  od; [pts]: end:  With reference to the transfer function tf3,we can see that the degree of the numerator is the same as the denominator. This will result in D s be- ing present in the corresponding time response and in Iris  Maple’s graphi- cal engine  being unable to plot expressions containing D s. The following function will remove any D s that appear:  230  ł Ł  cid:246  ł  cid:230  - ł  cid:230  ł  cid:246  ł  Discrete control applications  w Delta:=x->if x=0 then 1 else 0 fi:  Now we can plot and compare the three transfer functions  see  Figure 6.8 :  w plot {plots[textplot] [0.1, 2.5, ‘tf[1]’] ,  calc_response tf[1], z, ‘t’=0..15  :  plot {plots[textplot] [0.2, 4, ‘tf[2]’] ,  calc_response tf[2], z, ‘t’=1..15  :  plot {plots[textplot] [16, 0.6, ‘tf[3]’] ,  calc_response tf[3], z, ‘t’=0..15 } :  w plots[display] {“”", “”, “}, title=’Impulse Responses’,  labels=[‘’t’’,’f t ’] ;  tf[3]  f t   0.6  0.5  0.4  0.3  0.2  0.1  tf[1]  tf[2]  0  0  2  4  6  10  12  14  8  t  Figure 6.8 Impulse responses.  The three basic responses are similar except for the relative amounts of  gain in each system.  231   Applied Maple for Engineers and Scientists  Conclusion As previously mentioned the pulse transfer functions obtained by diﬀerent methods for the same continuous system are similar but not identical. What then are the advantages for choosing one method over another?  Impulse-invariant transform When the impulse-invariant transform is used, we are ensuring that the impulse response of the discrete system is identical to that of the continuous system, at least at the sample instances. The consequence of using this approach is the introduction of distortion due to aliasing. This is easily understood if the relationship between the fre- quency responses of the continuous and the discrete systems is examined. Unlike the frequency response of the continuous system, the frequency spectrum of the discrete system is repeated many times due to the fact that when the continuous spectrum is sampled with a period of T seconds the spectrum of the sampled signal is simply a scaled version of the continuous one repeated every R Hz. The repetition frequency R is equal to 1 T Hz and the scale factor is 1 T. The sampling period must be set suﬃciently high so that the repeated spectra do not overlap, thus eliminating any chance of aliasing and mismatch in the discrete system’s impulse response  see Figure 6.9 . This is not possible in practical systems although it is pos- sible to approximate such conditions.  Amp  Amp  - R  0  f  R  - R  0  R  f  Sampling without aliasing  Sampling with aliasing  Another point of interest is the actual mapping of the s-plane onto the z-plane. This mapping is as follows: The left-hand side of the s-plane maps onto the interior of the unit circle centered on the origin of the z-plane, whereas the right-hand side of the s-plane maps to the exterior as shown in Figure 6.10.  Figure 6.9  232   Discrete control applications  s-plane  z-plane  LHS  RHS  Unit circle  Figure 6.10  Mapping from s-plane to z-plane  Despite the nonlinear relationship of the overall mapping, the relation- ship between the continuous frequency and the corresponding discrete fre- quency is linear, which means that the shape of the frequency response is preserved and hence the identical  at the sample instances  impulse re- sponses of the continuous and discrete systems.  Numerical approximation This transformation method, although easy, gives less than ideal results. In order to achieve accurate transformation from the continuous to the discrete worlds, very high sample rates are nec- essary. This tends to result in ineﬃcient designs in every area except for low-pass digital ﬁlters. The mapping provided by this method is like the previous one, nonlinear. Unlike the previous one, however, the relation- ship linking the continuous frequency spectrum to the discrete one is also nonlinear. Whereas the invariant impulse response transform mapped the s-plane to either the inside or outside of the unit circle, this transform maps the left-hand side of the s-plane onto the interior of a circle of radius 1⁄2 with a center of  - 1⁄2, 0  as shown in Figure 6.11.  s-plane  LHS  RHS  Figure 6.11  Mapping from s-plane to z-plane  z-plane  Circle of radius 1 2, center   1 2, 0   233  -  Applied Maple for Engineers and Scientists  As before, the right-hand side maps to the outside of this circle. Al-  though diﬀerent than the earlier one, this mapping does preserve stability but without mapping the jw  -axis into the unit circle in the z-plane.  z = 1  and is valid for any order of system  Bilinear transform This transform method has these advantages over the previous two: Aliasing is avoided, it is eﬃcient, and the dc gain of the system is preserved  s = 0 ﬁ since any nth-order system can be represented as n ﬁrst-order systems. Al- though the mapping provided by this technique is, as we would expect, nonlinear, the frequency mapping between the s- and the z-planes is one to one and aliasing has been avoided at the cost of distorting the frequency axis. Like the ﬁrst mapping, the bilinear transform maps the stable poles and zeros to the interior of the unit circle centered at the origin of the z-plane and the unstable ones to its exterior.  Calculating the time response The computation of a system’s time response  at the sample instants  is, in eﬀect, the inverse transformation from the discrete realm to the continuous. This process can be performed in one of three basic ways: Solve the recur- rence relationship formed by the Z-transform, polynomial or synthetic long division, or the direct method.  a +  1 -  The recurrence relationship A recurrence relationship is one that describes the current value of a se- quence in terms of its history and in some cases its future. For example, the exponential ﬁlter describes the following recurrence relationship: a  y n - 1  where the current output y n  is a weighted y n  = r n e e combination of the current ﬁlter input r n  and the previous ﬁlter output y n-1 . Recurrence relationships are easily generated from a system’s discrete transfer function and solved, after which the corresponding time sequence can be computed. The following sequence of Maple commands demon- strates how this is done using the transfer function  1 - 1 -  3z  1 -  - 2,  0.2z  which is equal to  Y z  U z , the ratio of the input signal to output signal.  234   Discrete control applications  w SYS:=1  1-3 z-0.2 z^2 ;  SYS :=  1 -  3  1 1 z  .2  1 z2  Using numer and denom we ﬁrst isolate the numerator and the  denominator:  w BOT:=denom SYS ;  w TOP:=numer SYS ;  BOT := z2 -  3 z -  .2  TOP := z2  z2 3z -  z2 -  0.2  We can see from the two expressions that Maple rationalizes and sim-  pliﬁes SYS to  prior to computing the numerator and the denominator. The next stage is to manipulate these expressions by dividing them both by z raised to the degree of the numerator, in this case z2, which is equal to TOP, to transform all of the forward time shifts into time delays. We will assume that the sys- tem’s forcing function U z  is a unit step. Note, however, that the forcing function can be any sequence, as discussed in the next section.  w LHS:=expand BOT TOP ;  LHS := 1 -  3  1 z  .2  1 z2  w RHS:=TOP TOP;  RHS := 1  235  - -  Applied Maple for Engineers and Scientists  We are now at the stage where we can convert the Z-transform into a re-   n -    where Y  is the signal of interest, b  currence relationship that can be solved by replacing terms in z with terms of the form Y an integer denot- ing the number of delays associated with the term, and n the current time count. The custom conversion routine deﬁned below enables us to convert the polynomial in 1⁄z into its equivalent recurrence relationship. The rou- tine takes the expression to be converted, the name of the signal, the from variable and the to variable as parameters.  w ‘convert toRR’:=proc x, y, z, t  local a1,a2;  option ‘Copyright Coded by Dr. Steve Adams 1995’; a1:=select type, x, numeric ; a2:=degree x, z ; a1*y t+a2 ; end:  We now translate LHS with the signal name Y, the variable z, and the variable n as follows. The map function enables us to convert each term of the expression LHS in a single operation and is equivalent to con- vert op i, LHS , toRR, Y, z, n  for i=1..nops LHS .  w RR := map convert, LHS, toRR, Y, z, n ;  RR := Y n  -  3 Y n -  1  -  .2 Y n -  2   Now using rsolve, the Maple recurrence relationship solver, we can  solve RR for Y n  with the initial conditions Y 0 =3 and Y 1 =0:  w SEQ:=rsolve {RR=RHS, Y 0 =3, Y 1 =0}, Y n  ;  SEQ := 3 7   - 47 + 21  cid:214   - 2  ‘ 5 ‘ 5   cid:214  ‘ 5 + 15 - 7  cid:214   - 7  cid:214   n  1 ‘ 5 + 15   47 + 21  cid:214   - 2  ‘ 5  ‘ 5   cid:214  15 + 7  cid:214   ‘ 5  + 3 7  n  1 15 + 7 cid:214   ‘ 5  5 11  236  b ‘ ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł ‘ ‘ ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł ‘ -  Discrete control applications  n  1 ‘ 5 + 15   - 16 + 7  cid:214   - 2  ‘ 5   cid:214  ‘ 5 ‘ 5 + 15 - 7  cid:214   - 7  cid:214    16 + 7  cid:214   ‘ 5   cid:214   ‘ 5  n  - 2  1 15 + 7 cid:214   ‘ 5  15 + 7  cid:214   ‘ 5  + 10 77  + 10 77  We plot this function, which is valid at the sample instances, by trans-  forming it to function notation, generating the sequence of samples, con- verting the samples to a staircase plot, and then displaying the result  Figure 6.12 :  w TIME:=unapply SEQ, n :  THE_SEQ:=[seq [T, TIME T ], T=[0,1,2,3,4,5] ]: STAIR:=NULL: for n to nops THE_SEQ -1 do STAIR:=STAIR, THE_SEQ[n], [op 1, THE_SEQ[n+1] ,  op 2, THE_SEQ[n] ];  od: plot [STAIR], labels=[‘t’,’f t ’], title=  ‘Impulse Response’ ;  We can deduce from the plot of Figure 6.12 that this particular system is unstable. This is further conﬁrmed by looking at the poles of the system.  w solve BOT, {z} ;   cid:238  z = 3.065247585 cid:252    cid:254  ,  cid:236    cid:238  z = - .065247585 cid:252   One of the poles lies outside the unit circle, indicating the system is  unstable.  237  ‘ ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł ‘ ‘ ‘  cid:230   cid:231  Ł ‘  cid:246   cid:247  ł ‘  cid:236   cid:237   cid:253   cid:237   cid:253   cid:254   Applied Maple for Engineers and Scientists  f t   18  16  14  12  10  8  6  4  2  0  Figure 6.12 Impulse response.  0  1  2  3  4  5  t  The direct method The direct method is more general than the recurrence relationship method because it does not rely on a closed-form solution being available. It is also well suited to computer implementation as well as being able to in- corporate random input sequences. As before we use SYS as our example pulse transfer function. The basic principle for computing the output se- quence is as follows, the discrete transfer function G z  is equal to the quo- tient Y z  U z , which can be manipulated to yield Yn + aYn-1 + bYn-2 + … = Un + Un-1 + … Further manipulation yields the desired equation for the current output as a function of the current input and the previous inputs and outputs: Yn = - aYn 1 - bYn-2 + … +Un - Un-1 + …  w SYS;  1 -  3  1 1 z  .2  1 z2  As before we need to operate on the numerator and denominator of  this expression separately to isolate the sample weights.  238  -  Discrete control applications  w BOT:=denom SYS ;  BOT := z2 -  3 z -  .2  Next we determine the degree of the polynomial BOT by determining  the free variable and then using degree.  w VAR:=indets SYS ;  w TO:=degree BOT, VAR ;  VAR :=  cid:236    cid:238  z cid:252   TO := 2  Using this as the upper bound, we form a list of ordered coeﬃcients in an explicit fashion instead of using coeffs because this command will not return zero for any missing terms.  w YWEIGHTS:=[seq coeff BOT, op VAR , n , n=0..TO ];  YWEIGHTS := [- .2, - 3, 1]  Reading this list from right to left we have the weights to be applied to the current output Y n , the previous output Y n - 1 , and the output prior to that Y n - 2 , respectively.  Although trivial in this example, repeating the same sequence of opera- tions would return a list of weights associated with current and past values of the input sequence. In this example the list is, by inspection, [1]:  w UWEIGHTS:=[1];  UWEIGHTS := [1]  Now that we have the weightings and the respective delays, we can  compute the output sequence from a given input sequence and a set of in- itial conditions. Here we assume that the system is initially at rest:  239   cid:237   cid:253   cid:254   Applied Maple for Engineers and Scientists  w ICS:=[0, 0];  ICS := [0, 0]  The ﬁrst output is calculated, assuming that the ﬁrst input sample is  one, as follows:  w OUTPUT:=zip  x, y -> -x*y, ICS, op 1..2, YWEIGHTS   +  zip  x,y -> x*y, UWEIGHTS, [1] ;  OUTPUT := [0, 0] + [1]  The elements of the lists are summed to return Yn :  w OUTPUT:=map convert,OUTPUT, ‘+’ ;  OUTPUT := 1  Before we can repeat the process and compute the next value in the  output sequence we need to update the list containing the previous output values, in our case the variable ICS:  w ICS:=[ICS[1], OUTPUT];  ICS := [0, 1]  Before we plot the system output for a forcing function of a bipolar  square wave with a peak-to-peak amplitude of two  Figure 6.13 , we must remind ourselves that our test system is unstable in its current conﬁgura- tion  see the previous section .  By placing a 10:1 attenuator in the forward path we stabilize the sys- tem  Figure 6.14 . This particular modiﬁcation is easily accomplished by simply dividing the Y n  weighting in the calling sequence as shown here:  w plot output_sequence [-2, -3, 1 10], [1], [0, 0],  [1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1] , title=’System Output’, labels=[‘t’,’o p’] ;  240   f t   0  - 0.5  1  0.5  - 1  0.4  0.2  o p  0  - 0.2  - 0.4  Figure 6.13 Forcing function.  Figure 6.14 System output.  Discrete control applications  0  2  4  6  8  10  t  t  2  4  6  8  10  12  This entire process has been automated in the function  output_sequence found on the program disk.  241   Applied Maple for Engineers and Scientists  w output_sequence := proc YWEIGHTS, UWEIGHTS, ics, IP   local OUTPUT, ICS, n, temp; ICS:=ics; OUTPUT:=NULL: for n to nops IP  do temp:=op 3, YWEIGHTS *map convert, zip  x, y -> -x*y, ICS, [op 1..2, YWEIGHTS ]  +  zip  x,y -> x*y, UWEIGHTS, [IP[n]] , ‘+’ ;  OUTPUT:=OUTPUT, [n,temp]; ICS:=[ICS[1], IP[n]]; od; temp:=[OUTPUT]; OUTPUT:=NULL: for n to nops temp -1 do OUTPUT:=OUTPUT, temp[n], [op 1, temp[n+1] , op 2,  temp[n] ];  od; [OUTPUT]; end:  State space equations and their canonical forms One of Maple’s primary uses to the control engineer is as a fast, eﬃcient, and accurate manipulator of equations, expressions, and matrices using the host of functions found in the linalg package. In this section, we use Ma- ple to convert discrete transfer functions into their state space forms and generate the many useful canonical forms.3  Transfer function to state space  the controllable canonical form  Historically, dynamic systems have been described using diﬀerential equa- tions. Now, however, state space descriptions using matrices are common. Using state matrices a dynamic system can now be described in the follow- ing manner:  3.  Although discrete systems are being used in this example, the techniques are equally applicable to continuous systems.  242   Discrete control applications  . = Ax + Bu x y = Cx + Du  . where x , x, A, B, u, y, C, and D are all matrices. The system states are held in the x matrix, the A matrix contains the system coeﬃcients, the B matrix contains the input gains, u is the input matrix, y is the system output, the C matrix contains the output gains, and D is known as the disturbance matrix.  Using the pulse transfer function of a discrete system it is a relatively  simple process to generate the corresponding state space matrices. Al- though this looks like a complex process, do not forget that we are using Maple, which does all of the housekeeping for us, ensuring that no terms are missed and no signs are dropped. Omitting terms and dropping signs is all too easy when we are dealing with high-order complex systems contain- ing both numbers and symbols.  In the following example, we derive the state space representation of a  third-order discrete system with symbolic coeﬃcients:  w SYS:=z^3  a*z^3 + b*z^2+c*z+d ;  SYS :=  z3  a z3 + b z2 + c z + d  We have deliberately selected a system where the degrees of the nu-  merator and the denominator are equal, which means that we must ﬁrst di- vide out the transfer function by converting it to a continued fraction using convert …, confrac, … :  w D_SYS:=convert SYS, confrac, z ;  D_SYS := 1 a  b ⁄  z -  - b2 + c a  a b  a2 x x x x  x x x x  b2  z + c 2 b d - b b d -  b d - c2  c2  +  c2   b d -  d3 b z -  c2 2 cid:230   d c b d -  c2  243  -  cid:230   cid:231  Ł  cid:231   cid:231   cid:246   cid:247  ł  cid:247   cid:247   cid:230   cid:231  Ł  cid:231   cid:231   cid:246   cid:247  ł  cid:247   cid:247   cid:230   cid:231  Ł  cid:231   cid:231   cid:231   cid:231   cid:230   cid:231  Ł  cid:231   cid:231   cid:231   cid:231  -  cid:230   cid:231  Ł  cid:231   cid:231   cid:231  Ł  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:247   cid:247   cid:246   cid:247  ł  cid:247   cid:247   cid:247   cid:247   cid:246   cid:247  ł  cid:247   cid:247   cid:247   cid:247   Applied Maple for Engineers and Scientists  The ﬁrst term is the disturbance matrix D [we use Dist because D is a  Maple system name  the diﬀerential operator  and is protected]:  w Dist:=linalg[matrix] 1,1, [[op 1, D_SYS ]] ;  Dist := Ø  1 a  The ﬁrst row of the A matrix is made up of the coeﬃcients of the nu-  merator of the remaining polynomial D_SYS:  w POLY:=normal op 2, D_SYS , expanded ; d -  - b z2 -  c z  POLY :=  a2 z3 + a b z2 + a c z + d a  For convenience we really want the coeﬃcient of the leading term of the denominator to be unity and we must allow for this when we form the matrices:  w DIV:=lcoeff denom POLY , z ;  DIV := a2  By picking oﬀ each coeﬃcient of the denominator in turn, starting with the highest-but-one term in z, negating it, and dividing by the leading coeﬃ- cient  DIV , we can construct the A matrix:  w TO:=degree denom POLY , z -1;  TO := 2  w FIRST:=[seq -coeff expand denom POLY  , z, TO-n  DIV,  n=0..TO ];  FIRST := Ø  - b a, -  c  a, - d  a  244  Œ º ø œ ß Œ º ø œ ß  Discrete control applications  The other two rows of the A matrix are [1, 0, 0] and [0, 1, 0], so the  ﬁnal A matrix becomes:  w A:=linalg[matrix] 3,3, [ FIRST, [1,0,0],[0,1,0]] ;  A :=  - b a  1  0  c a  0  1  - d a  0  0  The C matrix is just the negated numerator coeﬃcients of the transfer  function divided by DIV starting with the highest-term-but-one in z and continuing through the lowest term in z:  w C:= linalg[matrix] 1,3, [[seq -coeff expand numer POLY  , z,  TO-n  DIV, n=0..TO ] ] ;  C := Ø  b a2  c a2  d a2  Finally, because the system is a single-input single-output system, the  B matrix is  w B:=linalg[matrix] 3,1, [[1], [0], [0]] ;  B :=  1 0 0  These state matrices are said to be in the controllable canonical form  and are well suited to the design of state variable feedback controllers.  Jordan canonical form In many designs it is advantageous to decouple the system through the diagonalization of the A matrix and the application of a transformation matrix. If the system has distinct eigenvalues, then the matrix transfor- mation x = Pz, where P is a Vandermonde matrix  see  245  Ø Œ º Œ Œ Œ Œ - ø œ ß œ œ œ œ Œ º ø œ ß  Applied Maple for Engineers and Scientists  ?linalg[vandermonde]  formed from the eigenvalues, is possible. Ma- ple has the built-in function jordan with which to perform the transfor- mation. For the sake of brevity we set values for the a, b, c, and d to one, two, three, and four, respectively, and then diagonalize the A matrix.  w NEWA:=linalg[jordan] subs a=1, b=2, c=3, d=4, eval A  ,  TRANS ;  NEWA :=  1 2  35 27  + 5 9  ‘ 6  I  cid:214   ‘ 3  1 2  35 27  + 5 9  ‘ 6  1⁄3  0,  1 2  35 27  + 5 9  ‘ 6  1⁄3  1⁄3  5 18  1⁄3  º 0, 0, -  35 27  + 5 9  ‘ 6  + 5 9  1⁄3  Simplifying this we get  5 18  5 9  35 27  + 5 9  ‘ 6  1  1  1⁄3  1⁄3  35 27  + 5 9  ‘ 6  2 3  , 0, 0  1  1⁄3  2 3  35 27  + 5 9  ‘ 6  1⁄3  2 3  35 27  + 5 9  6  1 + 5 9  35 27  1⁄3  ‘ 6  + 1 2  I  cid:214   ‘ 3  35 27  + 5 9  ‘ 6  5 9  1  , 0  246  Ø Œ º Œ Œ  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł - ø œ ß œ œ Ø Œ º Œ Œ Œ Œ - ‘  cid:230   cid:231  Ł  cid:231   cid:231  -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:247   cid:247  ø œ ß œ œ œ œ Ø Œ º Œ Œ  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł - ø œ ß œ œ Ø Œ º Œ Œ Œ Œ ‘  cid:230   cid:231  Ł  cid:231   cid:231  -  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł -  cid:230   cid:231  Ł  cid:214  ‘ ‘  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:247   cid:247  ø œ ß œ œ œ œ Ø Œ  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:214  ‘  cid:246   cid:247  ł - ø œ ß  Discrete control applications  w map evalf, NEWA ;  - .1746854042 + 1.546868888 I, 0, 0 0, - .1746854042 - 1.546868888 I, 0 - 1.650629192 0,  0,  The jordan function returns a transition matrix, speciﬁed by the last  argument passed to the function, which in our case is tagged TRANS.  w evalf eval TRANS , 4 ;  1. 1. 1.  1.825 + 1.547 I 1.825 - 1.547 I .3487  .2891 + 2.554 I .2891 - 2.554 I 2.423  The inverse of this transition matrix can then be used to transform the  B, C, and Dist matrices.  w ‘B’:=evalf evalm linalg[inverse] eval TRANS   &* B  ;  B :=  .2019853944 + .3056525967 I .1805460653 - .1509657080 I .1093801481 - .1043649861 I  w ‘C’:=evalf evalm subs a=1, b=2, c=3, d=4, eval C   &* linalg  [inverse] TRANS   ;  C := [.5080883927 -  .250518744 I, .5080883927 +  .2590518744 I, .9838232148]  Observable canonical form The dual form of the controllable canonical form is known as the observ- able canonical form. Like the controllable form the coeﬃcients of the trans- fer function appear directly in the state matrices. The controllable form matrices can be transformed into the observable form simply as follows: Aﬁ AT, Bﬁ CT, and Cﬁ BT; hence, we get:  247  Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ ø œ ß œ œ Ø Œ º Œ Œ - ø œ ß œ œ  Applied Maple for Engineers and Scientists  w A:=linalg[transpose] A ;  A :=  - b a c a - d a  1  0  0  0  1  0  w temp:=eval C :  w C:=linalg[transpose] B ;  C := [1  0  0]  and  w B:=linalg[transpose] temp ;  B :=  b a2 c a2 d a2  248  Ø Œ º Œ Œ Œ Œ - ø œ ß œ œ œ œ Ø Œ º Œ Œ Œ Œ Œ Œ ø œ ß œ œ œ œ œ œ  Applied Maple for Engineers and Scientists  Chapter 7  Discrete data processing  Most common discrete data processing applications fall into one  of two general categories: digital signal processing and image processing. In many instances the operations required are simi- lar if not identical. Although in this discussion we will concentrate mainly on image processing tools, many of the tools developed are equally applica- ble to signal processing. Because we will be using plots to generate our test data and to display the processed results, we will start with a brief overview of the Maple plotting routines and structures.  Maple plots  The most commonly used plotting functions are plot and plot3d and they are immediately accessible. In addition to these, two additional plot- ting packages are available in Maple: plots and plottools. The plots package contains additional data visualization tools, and the  249   Applied Maple for Engineers and Scientists  plottools packages contains a set of graphics primitives and graphics manipulation routines such as rotation and translation functions.  The plot structure  All maple plotting functions produce either a PLOT or a PLOT3D data structure describing the image to be displayed. Both types of plot structure have the same basic form: PLOT  plot_object1, plot_object2, .., plot_objectn, plot_options   or PLOT3D  plot_object1, plot_object2, .., plot_objectn, plot_options  . For example, here are plot structures for the plots in Figures 7.1 and 7.2:  w PLOT CURVES [[0,0],[2,2],[1,-1],[1,3],[3,4]] , TEXT [1.1,3],  ‘Strange Curve’,ALIGNABOVE, ALIGNRIGHT, FONT TIMES, BOLDITALIC,15   ;  w PLOT3D MESH [[[0,0,0], [1,0,0]], [[0,1,2], [1,1,2]],  [[0,2,0], [1,2,0]]] ,POLYGONS [[0, 0,.5], [1, 0, .5],  [1,2,.5], [0, 2, .5]] , ORIENTATION 150, 70 ,  TITLE ‘A-FRAME’ , COLOUR RGB,0,0,0  ;  Strange Curve  0  0.5  1  1.5  2  2.5  3  4  3  2  1  0  - 1  Figure 7.1  250   Discrete data processing  Figure 7.2 A_FRAME.  The objects plot_objecti can take a number of diﬀerent forms  but they conform to the same basic syntax throughout, namely, object_ type  data  . The object_type describes how the data are to be drawn and can be one of the following: CURVES, POINTS, POLYGONS, TEXT, GRID, or MESH. The objects POINTS, POLYGONS, and TEXT can be either two- or three-dimensional depending on whether the data supplied to each are in the form of pairs or triplets. The plot_options are used to set the style of the resulting plot and allow us to set such things as color, axes styles, view ranges, font styles, point sym- bols, and so on. The table in Appendix B shows the correspondence be- tween the various plot data structures and the user-deﬁned plot options. Unless otherwise stated, the data structures and their corresponding plot options are equally applicable to two- and three-dimensional plot structures.  LIGHTMODEL USER  LIGHT_1  LIGHT_2  LIGHT_3  LIGHT_4   lightmodel= USER  LIGHT_1  LIGHT_2  LIGHT_3  LIGHT_4  Before we move on, it is worth mentioning that the plot data structures  are in reality unevaluated function calls that are evaluated when they are passed to IRIS, Maple’s graphics interface. An unevaluated function can  Allows a lighting scheme, from those available, to be selected. If USER is specified the light definitions given in the LIGHT and AMBIENTLIGHT options are used.  251   Applied Maple for Engineers and Scientists  Image conversion  have many uses in Maple; in this case, it is just a wrapper placed around some plot data as a convenient way of storing the data and context in a way that it can be passed to and processed by IRIS. For more information see ?plot[structure] and plots[options].  In this ﬁrst section, we develop a set of conversion tools: togreyscale, tofalsecolor, normalize, and histogram. These tools enable us to convert images’ color formats from RGB color to monochrome and from monochrome to RGB color, normalize monochrome color data to the range 0 .. 1, where 0 is black and 1 is white, and return a histogram of a data set, respectively. In this particular case we develop our own procedure in deference to Maple’s own histogram function  stats[statplots, histogram]  because there is no exact match between the functionality required and that provided. The mismatch is because Maple’s histogram procedure has been designed and implemented as a statistical tool, not as a DSP tool.  To develop and apply these tools, we need to be able to both retrieve and manipulate a plot’s color information and then reattach it. In a Maple plot the color information can be speciﬁed in three ways: an RGB color spe- ciﬁcation, an HSV color speciﬁcation, or a HUE color speciﬁcation. The RGB speciﬁcation uses three ﬂoating-point values, each between 0 and 1, for each of the primary colors. HUE, on the other hand, uses a single ﬂoat- ing-point value, also between 0 and 1, to select the color, whereas the HSV speciﬁcation requires three ﬂoating-point values between 1 and 0: one for color, one for saturation, and one for brightness. The HUE deﬁnition cycles through the spectrum with the 0–1 transition being the join. Hence, COLOUR HUE, 0  equals COLOUR HUE, 1  equals black  Figure 7.3 .  NOTE that because of Maple’s Canadian origins, many spellings are UK-English, not American-English.  w PLOT POLYGONS [[0,0],[2,0],[2,2],[0,2]] , COLOUR RGB, 0, 0,  0 , TITLE ‘A Black Square’  ;  252   Discrete data processing  2  1.5  1  0.5  Figure 7.3 A black square.  0  0  0.5  1  1.5  2  The following plot structure created by explicitly assigning color val- ues using a color function shows how the color information is attached to a plot object. We use the RGB format so our color function has to provide values for each color. Although we have taken care to scale the color func- tion’s output to lie within the range 0 .. 1 this is not strictly necessary be- cause Maple normalizes the color data prior to rendering it.  w COLORFUNC:=[x 3,  3-y  3, x*y 9];  COLORFUNC := Ø  x, 1 -  1 3  1 3  y,  x y  1 9  Using this color function we compute plot structure. By assigning it to  a variable, we force Maple to display the data and not the plot.  w TESTPLOT:=plot3d sin x*y , x=0..3, y=0..3, color=COLORFUNC,  numpoints=9 ;  TESTPLOT := PLOT3D GRID 0 .. 3., 0 .. 3., [[0, 0, 0, 0],  [0, .8414709848078965, .9092974268256817, .1411200080598672], [0, .9092974268256817, - [0, .1411200080598672, - COLOR RGB, 0, 1., 0, 0, .6666666666666667, 0, 0,  .7568024953079282, - .2794154981989259], .2794154981989259, .4121184852417566]],  253  Œ º ø œ ß  Applied Maple for Engineers and Scientists  .3333333333333334, 0, 0, 0, 0, .3333333333333333, 1., 0, .3333333333333333, .6666666666666667, .1111111111111111, .3333333333333333, .3333333333333334, .2222222222222222, .3333333333333333, 0, .3333333333333333, .6666666666666666, 1., 0, .6666666666666666, .6666666666666667, .2222222222222222, .6666666666666666, .3333333333333334, .4444444444444444, .6666666666666666, 0, .666666666666666, 1., 1., 0, 1., .6666666666666667, .3333333333333333, 1., .3333333333333334, .6666666666666666, 1., 0, 1.  , AXESLABELS x, y,  , TITLE  , STYLE PATCH    With reference to the preceding Maple output, we can see that Maple  inserted the plot’s color information after the three-dimensional surface deﬁnition. We can, therefore, isolate the color information by selecting the correct portion of the plot structure. In this particular example, the infor- mation we are interested in is surrounded by the wrapper GRID and can be picked out by op. The op function allows us to select operands from within data structures, in the current release,1 op’s functionality has been extended to operate on nested data structures implicitly. The call op [4, 1], …  returns the ﬁrst operand of the fourth operand of the plot structure, namely, the color information.  w DATA:=op [4, 1], TESTPLOT ;  DATA := COLOR RGB, 0, 1., 0, 0, .6666666666666667, 0, 0, .3333333333333334, 0, 0, 0, 0, .333333333333333, 1., 0, .3333333333333333, .6666666666666667, .1111111111111111, .3333333333333333, .3333333333333334, .2222222222222222, .3333333333333333, 0, .3333333333333333, .6666666666666666, 1., 0, .6666666666666666, .6666666666666667, .2222222222222222, .6666666666666666, .3333333333333334, .4444444444444444, .6666666666666666, 0,.6666666666666666, 1., 1., 0, 1., .6666666666666667, .3333333333333333, 1., .3333333333333334, .666666666666666, 1., 0, 1.   1. This syntax is valid for releases greater than Maple Vr3. For earlier releases, nested ops must be used;  i.e., op  4, op 1, ...  .  254   Discrete data processing  We can see that the color information is presented as a sequence of  data points, which must be taken three at a time to provide the actual color. If we take a closer look at the data, we can see that there are more data points than there appear to be grid points, i.e., numpoints equals 9 while there are 16 data points. This is because Maple generates a grid that is num- bered from zero to  cid:214  ‘ numpoints , hence the extra points. Here we read in a previously created test image and then plot the three original planes. Now that we can isolate the color information, the next step is to isolate the indi- vidual color planes—red, green, and blue. By way of an example, we re- move the red color plane from the image data using a for loop as shown:  w RDATA:=NULL:  for n from 2 to nops DATA  by 3 do  RDATA:=RDATA, op n, DATA ;  od: [RDATA];  [0, 0, 0, 0, .3333333333333333, .3333333333333333, .3333333333333333, .3333333333333333, .6666666666666666, .6666666666666666, .6666666666666666, .6666666666666666, 1., 1., 1., 1.]  The list of red color values has no spatial information  i.e., where in the plot grid it applies  associated with it so we must recreate this manu- ally. This is a simple task of converting the list into a square matrix whose ijth element corresponds with the  i - 1  j - 1 th red intensity in the image grid. The oﬀset is necessary because Maple matrix indices must start at one.  w REDMAT:= linalg[matrix] sqrt nops [RDATA]  ,  sqrt nops [RDATA]  ,[RDATA] ;  REDMAT := [0, 0, 0, 0] .3333333333333333 , .3333333333333333 , .3333333333333333 , .3333333333333333] [.6666666666666666 , .6666666666666666 , .66666666666666666 , .6666666666666666] [1., 1., 1., 1.]  255  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  The intensity of the image’s red component can be viewed with matrixplot, which is found in the plots package  Figure 7.4 :  w plots[matrixplot] REDMAT, axes= FRAME,  labels=[‘x’,’y’,’Int’], title=’Image’s red plane’, style=HIDDEN, color=BLACK ;  Int  1  0.8  0.6  0.4  0.2  0  1  1.5  2 y  2.5  3  3.5  3.5  4  4  2.5 x  3  1  1.5  2  Figure 7.4  The Maple code just developed has been encapsulated in the following  two procedures. The ﬁrst procedure takes two arguments, the color data and the color plane required, and returns the selected color information as a list. Within the body of the procedure, the selected color plane is con- verted into an index oﬀset into the data structure by using a table. The color information is then stepped through and the appropriate data are removed using a for loop. The second procedure takes the color informa- tion list and returns a graphical representation of it using matrixplot:  w GET_COLOR:=proc data, colour   options ‘Copyright Coded by Dr. Steve Adams 1995’; local colordat, temp, n; colordat:=table [RED=1, GREEN=2, BLUE=3] ; temp:=NULL; for n from 1+colordat[colour] to nops data  by 3 do  temp:=temp, op n, data ;  od; [temp];  end:  256   Discrete data processing  w COLOR_PLOT:=proc data, Title   options ‘Copyright Coded by Dr. Steve Adams 1996’; local count; count:=sqrt nops data  ; plots[matrixplot] linalg[matrix] count, count, data , style=WIREFRAME, color=BLACK, axes=FRAME, title=Title, labels=[‘x’,’y’,’Int’] :  end:  Applying these functions to a previously obtained color  stored in the  ﬁle colour.dat  plot to return the three color planes—red, blue, and green—and plotting the results as a graphics array we get the following:  w read ‘colour.dat’ :  w P1:=COLOR_PLOT GET_COLOR DATA, RED , ‘Red Plane’ :  w P2:=COLOR_PLOT GET_COLOR DATA, GREEN , ‘Green Plane’ :  w P3:=COLOR_PLOT GET_COLOR DATA, BLUE , ‘Blue Plane’ ;  w plots[display] array 1..1, 1..3, [P1, P2, P3]  :  Figures 7.5, 7.6, and 7.7 show the intensities of the three primary col-  ors  red, blue, and green, respectively  at each point on a three-dimen- sional surface. The actual surface is irrelevant at this point because we are only interested in its color map.  Togreyscale A common digital image processing transformation is to change an image’s color map into a greyscale one by forcing the red, green, and blue components of the RGB data structure to be equal. This approach can drastically reduce the size required to store an image. In this example we use, as a starting point, the color information stored earlier in the variable DATA.  Maple supports an extensive set of conversion routines that can  be easily extended by the user. The procedure convert uses helper routines to manipulate data passed to it. These “helper” routines all have the same form of procedure name: convert helper_name and are all invoked in the same way: convert data, helper_name . Hence, in this particular case we create the helper routine convert  togreyscale, shown next, to convert an image’s color information  257   Applied Maple for Engineers and Scientists  Int  1  0.8  0.6  0.4  0.2  0  Int  1  0.8  0.6  0.4  0.2  0  5  10  y  15  5  10  x  15  20  20  25  25  Figure 7.5 Red plane.  5  10  y  15  5  10 x  15  20  20  25  25  into greyscale information that is invoked with convert data, togreyscale . The core of this routine is a for loop that allows us to step through the data backwards in steps of three. Each triplet is averaged to compute the greyscale value.  Figure 7.6 Green plane.  258   Discrete data processing  Int  1  0.8  0.6  0.4  0.2  0  5  10 y  15  5  10  15  x  20  20  25  25  Figure 7.7 Blue plane.  w ‘convert togreyscale’:=proc data   options ‘Copyright coded by Dr. Steve Adams 1995’; local n, START, new_data, level; new_data:=NULL; START:=nops data -1; for n from START-1 to 1 by -3 do  level:= convert [op n..n+2, data ], ‘+’  3; new_data:=level$3, new_data;  od; COLOUR RGB, new_data ;  end:  Converting the color data to greyscale data and plotting the three indi-  vidual color planes enables us to compare the new color data with the original data shown earlier.  w NEW_DATA:=convert DATA, togreyscale :  As above we plot each color plane of the new greyscale image for  comparison:  259   Applied Maple for Engineers and Scientists  w P11:=COLOR_PLOT GET_COLOR NEW_DATA, RED , ‘New Red Plane’ :  w P21:=COLOR_PLOT GET_COLOR NEW_DATA, GREEN ,  ‘New Green Plane’ :  w P31:=COLOR_PLOT GET_COLOR NEW_DATA, BLUE , ‘  New Blue Plane’ :  w plots[display] array 1..1, 1..3, [P11, P21, P31]  ;  0.7 0.6 0.5 Int 0.4 0.3 0.2 0.1 0  0.7 0.6 0.5 Int 0.4 0.3 0.2 0.1 0  5  5  5  5  10 y  15  10  x  15  20  20  25  25  Figure 7.8 New red plane.  10 y  15  10  x  15  20  20  25  25  Figure 7.9 New green plane.  260   Discrete data processing  0.7 0.6 0.5 Int 0.4 0.3 0.2 0.1 0  5  10 y  15  5  10  x  15  20  20  25  25  Figure 7.10 New blue plane.  With reference to Figures 7.8, 7.9, and 7.10, we can see that all of the  color intensities have the same value for any given point on the image, which means that the color map is now a greyscale one. The ﬁnal stage in this process is to substitute the greyscale information into the original plot structure:  w NEW_PLOT:=subs DATA=NEW_DATA, TESTPLOT :  The new greyscale image can now be viewed, which is left as an exer-  cise for the reader.  Before we move to our next topic, normalization, we conclude this sec- tion by outlining how Maple generates greyscale images. Unless otherwise speciﬁed by explicitly deﬁning a color map, Maple produces an image ob- ject with the default color map applied automatically by IRIS. The default color map, usually a hue value dependent on the x-y-z coordinate of the point in question, can be overridden by setting the user option shading to be equal to a valid map, currently, XYZ, XY, Z, ZGREYSCALE, ZHUE, and NONE. Depending on which color map is selected, IRIS computes the color at each point on the surface as it renders it. If we want to display a greyscale image, we simply set shading as shown: shading= ZGREYSCALE. This has the same eﬀect as setting the color map explicitly with the red, green, and blue components equal.  261   Applied Maple for Engineers and Scientists  Normalize If we refer to the greyscale information displayed in the last section, we see that the intensity values do not cover all of the intensity values available, namely, 0 .. 1. It can be seen that the intensity values only range between 0.2 to 0.7 resulting in the contrast of the image being compressed. A sim- ple, but eﬀective, image processing technique is contrast adjustment is one in which the original intensity values are mapped onto the entire support- able range of intensity values as shown in Figure 7.11.  Original data  0.23 0.31 0.5  ..  0.56 0.79  Mapped data  0.0  ..  1.0  Figure 7.11  The actual mapping process that we will perform is linear, in which we will ﬁrst shift the data and then stretch it to cover the range 0 .. 1. But ﬁrst we need to isolate the original data and, because all of the color planes con- tain the same information in the greyscale image, we will simply isolate the red plane data:  w DATA_ONLY:=GET_COLOR NEW_DATA, RED :  Before we adjust the contrast we will take a look at a histogram of the original data. Before we can do this, however, we need to manipulate the raw data to take into account that we are dealing with a discrete system. In a discrete system the number of valid levels is determined by the bit length or depth of the imaging system. In our example, we will use a bit depth of eight giving 256  0 .. 255  valid levels:  w BIT_DEPTH:=8;  BIT_DEPTH := 8  Here we look at the ﬁrst ﬁve elements of the data:  262   Discrete data processing  w DATA_ONLY[1..5];  [0, .001306928340, .005207319179, .01164030823, .02050551083]  Now we quantize the original data to the bit depth of the system using map and round as shown next. The function round rounds down a nu- meric value to the nearest integer:  w QUANTIZED:=map round,map  x,y -x*y, DATA_ONLY,  2^BIT_DEPTH-1  :  Here we look at the ﬁrst ﬁve elements of the quantized data:  w QUANTIZED[1..15];  [0, 0, 1, 3, 5, 8, 11, 15, 20, 24, 29, 34, 40, 45, 50]  Now we are ready to sort the quantized data into bins, one unit wide, and plot them to produce the required histogram. Filling the bins is done very simply by using a table and a for loop. First we create 256 empty bins as shown:  w BINS:=table [seq n=0, n=0..2^BIT_DEPTH-1 ] :  Now we step through the sorted data incrementing the bin counts as  appropriate:  w for n in QUANTIZED do  BINS[n]:=BINS[n]+1; od:  Before we can plot the data we have to convert the table entries, which  is in essence unsorted, into a sorted list of data pairs: [bin number, entries].  w pts := [seq [n, BINS[n]], n=0..2^BIT_DEPTH-1 ]:  In Figure 7.12, we plot the histogram of the original data quantized to  eight bits:  263   Applied Maple for Engineers and Scientists  Count  16  14  12  10  8  6  4  2  0  Figure 7.12  0  50  100  150  200  250  Bin  w plot pts, labels=[‘Bin’,’Count’] ;  The histogram plot, although valid, needs some cosmetic adjustment because Maple by default plots a list by connecting all of the points in se- quence. What we want is a sequence of vertical lines the length of which is proportional to the number of the entries in the bin. We can achieve this very easily by scanning the point pairs searching for nonzero abscissa val- ues. Once a nonzero value is discovered, two additional points are in- serted, one on either side, which forces Maple to plot a line starting and ending at the point [ bin number, 0]. For example, given the point se- quence [0, 0], [1, 10], [2, 4] we would generate the new point sequence [0, 0], [1, 0], [1, 10], [1, 0], [2, 0], [2, 4], [2, 0], where the additional point pairs are emboldened for clarity. This process is demonstrated in Figure 7.13. The following Maple function performs this task:  w FUNC:=x->if x[2] 0 then [x[1], 0], x, [x[1], 0] else x fi;  w FUNC :=proc x   options operator,arrow; if x[2]  0 then [x[1],0],x,[x[1],0] else x fi end  264   Discrete data processing  10  8  6  4  2  0  Figure 7.13  a  Original, and  b  with extra points.   a    b   10  8  6  4  2  0  0  0.5  1  1.5  2  0  0.5  1  1.5  2  Here we test our new function to check that it operates as we expect:  w FUNC [1,1] ;  w FUNC [1,0] ;  [1, 0], [1, 1], [1, 0]  [1, 0]  Now we are ready to replot the histogram  Figure 7.14 :  w plot map FUNC, pts , title=’Histogram Plot’,  labels=[‘Bins’,’Count’] ;  The process just explained to generate a histogram plot of a set of data  has been automated in the function histogramplot found in the pro- gram disk.  The histogram conﬁrms our original observation that the contrast of the original image is compressed because there are no intensity values in the range 200 .. 250 present in the original plot. The original data are there- fore adjusted for contrast by ﬁrst resetting the origin and then stretched the translated data so that it covers the supported range 0 .. 1. This resets the origin:  265   Applied Maple for Engineers and Scientists  Count  16  14  12  10  8  6  4  2  0  Figure 7.14 Histogram plot.  0  50  100  150  200  250  Bins  w LOW:=min op DATA_ONLY  ;  LOW := 0  w SHIFTED := map  x,y ->x-y, DATA_ONLY, LOW :  Now we stretch the shifted data:  w HIGH:=max op SHIFTED  ;  HIGH := .7819887006  w STRETCHED := map  x, y ->x y, SHIFTED, HIGH :  Here we look at the ﬁrst and last ﬁve elements of the adjusted data set:  266   Discrete data processing  w [op op 1..5,sort STRETCHED   , ‘..’, op op nops STRETCHED   -5..nops STRETCHED , sort STRETCHED   ];  [0, .001671288011, .006659072152, .01488551973, .02622225975, .., .9865825261, .9871622880, .9948650055, .9959871150, .9994963150, 1.000000000]  As before we ﬁrst quantize the data to eight bits and then using  histogramplot we plot a histogram of the adjusted data  Figure 7.15 :  w QUANTIZED:=map round,map  x,y ->x*y, STRETCHED,  2^BIT_DEPTH-1  :  w histogramplot QUANTIZED, 8, title=’Normalized Histogram  Plot’ ;  Count  18  16  14  12  10  8  6  4  2  0  Figure 7.15 Normalized histogram.  0  50  100  150  200  250  Bins  With reference to the histogram of Figure 7.15 we can see that the im- age’s contrast has been successfully stretched, but the overall shape of its intensity proﬁle has remained unchanged. The number of instances of vari- ous intensity values occurring in the contrast adjusted image will be diﬀer- ent than the unadjusted image as a result of the mapping and quantization process.  267   Applied Maple for Engineers and Scientists  The normalize function can be found on the program disk.  Tofalsecolor In many applications the analysis of an image is simpliﬁed by adding false color, as the next example demonstrates. We wish to investigate the three- dimensional image shown in Figure 7.16 by applying contours of equal color intensity.  w plot3d  exp -sin x^2 -cos y^2  , x=-2..2, y=-2..2,  labels=[‘x’,’y’,’z’], style=CONTOUR, color=BLACK  ;  With the image in its original form we are unable to deduce much re-  garding the dominant plateau region of the surface. One possible approach is to apply a mapping function to the data, analogous to applying false color, and plotting the result  Figure 7.17 :  w MAP:=log;  MAP := log  w plot3d MAP exp -sin x^2 -cos y^2   , x=-2..2, y=-2..2,  labels=[‘x’,’y’,’z’], style=CONTOUR, color=BLACK  ;  Figure 7.16  268   Discrete data processing  By manipulating the data in this way we can ‘see’ information buried in  the data.  Using Maple we can add false color to the adjusted greyscale data gen- erated earlier  stored in the variable NEW_DATA  using mapping functions. These mapping functions are normally functions of intensity and can re- turn any value in the range 0 .. 1. The example functions that we will be using as defaults, one for each plane, are as follows:  Figure 7.17  w a:=t->  1-cos t*2*Pi  ^2  4;  b:=t-> 1-cos t*Pi   2; c:=t-> cos t*Pi +1  2;  a := t ﬁ  b := t ﬁ c := t ﬁ  cos 2 t p    2   1 - 1 2  1 4 1 2 1 2  cos t p   cos t p  +  1 2  Here we plot the mapping functions as a function of intensity over the  range 0 .. 1  Figure 7.18 :  w plots[display] [plots[textplot] [[0.1, 0.9, ‘a’],[0.5, 0.9,  ‘b’],[ 0.9, 0.9, ‘c’]] ,plot {a t , b t , c t }, t=0..1, title=’False Color Functions’, color=BLACK, labels=[‘Old’,’New’] ] ;  269  -  Applied Maple for Engineers and Scientists  a  b  c  New  1  0.8  0.6  0.4  0.2  0  0  Figure 7.18  0.2  0.4  0.6  0.8  1  Old  The process of applying false color is outlined in the next example. First we get the color data for the other two planes  we have already nor- malized the red color plane data and stored it in the variable STRETCHED  in our test image and normalize it:  w DATA2:=normalize GET_COLOR NEW_DATA, GREEN  : DATA3:=normalize GET_COLOR NEW_DATA, BLUE   :  Using this and the previously obtained data  STRETCHED  we apply  the false color mapping functions in order to generate three new color planes:  w NEW_COLOR1:=map a, STRETCHED :  NEW_COLOR2:=map b, DATA2 : NEW_COLOR3:=map c, DATA3 :  The three sets of false color information need to be knitted together in the correct order so the complete COLOUR data structure can be built. We do this in two stages:  270   Discrete data processing  w TEMP:=zip  x,y ->[x,y], NEW_COLOR1, NEW_COLOR2 :  COLOUR RGB, op map op,zip  x,y ->[op x , y], TEMP, NEW_COLOR3    :  Again this is left to the reader to do as an exercise. Before moving on, we will look at the ﬁrst false color plane data as a three-dimensional surface  Figure 7.19 :  w plots[matrixplot] linalg[matrix] 25,25,NEW_COLOR1 ,  title=’False Color Plane 1’, labels=[‘x’,’y’,’Int’], color=BLACK, style=HIDDEN, axes=FRAME ;  Int  1  0.8  0.6  0.4  0.2  0  5  10 y  15  5  10  15  x  20  20  25  25  Figure 7.19 False color plane 1.  The process of applying false color to greyscale images has been extended and encapsulated in the procedure ‘convert  tofalsecolor’ which is available on the data disk.  Conclusion In the previous section we demonstrated how Maple can be used eﬀec- tively as a tool to manipulate and investigate discrete images. We have also shown how Maple can help us to develop prototype algorithms for digital image processing techniques by ﬁrst developing the algorithm interactively and then implementing the algorithm as a procedure. The three tools devel- oped in this manner were the conversion routines togreyscale and  271   Applied Maple for Engineers and Scientists  tofalsecolor, the utility functions normalize and GET_COLOR, and the plotting routines COLOR_PLOT and histogramplot.  Linear filters  Another common discrete data processing application is that of time series data ﬁltering. With Maple’s list and array structures, we can manipulate time series data very eﬀectively. In this section we use Maple to develop routines to implement ﬁve of the more common ﬁltering techniques, namely, ﬁrst-order diﬀerencing, moving average, moving median, and exponential ﬁltering.  Differencing Diﬀerencing is a technique commonly applied to time series data in disci- plines as diverse as ﬁnance to image processing. For example, recently, the stock market appears to be relentlessly increasing and therefore it may ap- pear to be a good long-term investment. However, if the average increases in the average price are less than the prevailing rate of inﬂation, then it would not be such an attractive proposition. We can use diﬀerencing tech- niques to determine the underlying trend, if any, concealed within the data. In this particular implementation we operate on a list data structure using the for-next construct. First we read the series data into the current Maple session. The data ﬁle is in a Maple-friendly form  i.e., the ﬁle con- tains text that conforms to the Maple syntax  so the data are automatically assigned to the variable SERIES_DATA. The time series data consists of a list with 256 entries, a portion of which, along with a plot of the data  Figure 7.20 , is given here:  w read ‘series.dat’ :  w [op op 1..10,SERIES_DATA  , ‘..’, op op 246..255,  SERIES_DATA  ];  [2, 0, 1, 0, 1, 0, 0, 1, 0, 0, .., 4, 1, 0, 3, 1, 2, 2, 2, 0, 2]  w plots[listplot] SERIES_DATA, title=’Original Data’,  labels=[‘t’,’amp’] ;  272   Discrete data processing  amp  10  20  15  5  0  0  Figure 7.20 Original data.  50  100  150  200  250  t  Using a sample of the entire data set we will develop the diﬀerence  algorithm:  w SAMPLE:=SERIES_DATA[1..10];  SAMPLE := [2, 0, 1, 0, 1, 0, 0, 1, 0, 0]  The algorithm used is as follows: The ith ﬁltered output is the diﬀer- ence between the ith and the  i+1 th inputs. We compute the ﬁlter’s output sequence using the for-next construct shown:  w temp:=NULL:  for n to nops SAMPLE -1 do  the_diff:=SAMPLE[n+1] - SAMPLE[n]: temp := temp, the_diff: print temp ;  od: [temp];  273   Applied Maple for Engineers and Scientists  - 2 - 2, 1  - 2, 1, - 1 - 2, 1, - 1, 1  - 2, 1, - 1, 1, - 1 - 2, 1, - 1, 1, - 1, 0 - 2, 1, - 1, 1, - 1, 0, 1  - 2, 1, - 1, 1, - 1, 0, 1, - 1 - 2, 1, - 1, 1, - 1, 0, 1, - 1, 0  [ - 2, 1, - 1, 1, - 1, 0, 1, - 1, 0 ]  We can see that the manipulated data do not contain the ﬁrst and last data points of the original list and, hence, each time the diﬀerence ﬁlter is used the length of the available data set is reduced by two as we lose the ﬁrst and the last data points from the list. The function difference, found on the program disk, takes a list of samples and returns a list of their diﬀerences. Here we use this function to return a list of diﬀerences from the original data and plot it  Figure 7.21  using listplot:  w DIFFERENCED:=difference SERIES_DATA :  plots[listplot] [DIFFERENCED], title=’Difference Filter  Output’,labels=[‘t’,’delta’] ;  The output from the diﬀerence ﬁlter shows the underlying trends pre-  sent. With reference to both the original and the ﬁltered data, we can see that the test data exhibit periods of uniform growth and decline on top of which periods of volatile activity are impressed. By using the diﬀerence ﬁlter it is easy to highlight the periods of high volatility that are directly applicable to, for example, the ﬁnance industry.  274   Discrete data processing  delta  10  8  6  4  2  0  - 2  - 4  - 6  Figure 7.21 Difference filter output.  0  50  100  150  200  250  t  Moving average Another common ﬁltering technique that is eﬀective at reducing the noise component of a data set is that of returning the moving average of a data set. Unfortunately this type of ﬁltering has the tendency to blur edges be- cause it mimics a low-pass ﬁltering operation. The moving average algo- rithm, like the diﬀerencing algorithm, is relatively simple to implement in Maple through the manipulation of matrices. Put simply, a moving average ﬁlter takes a list of samples and produces a new one, the elements of which are the average of a windowed version of the original. This process is de- picted in Figure 7.22, where we take a three-element window and pass it the data to generate the new ﬁltered data. The ﬁrst element of the ﬁltered data is the same as the original because only a single element is covered by the ﬁlter window. The second element is the average of the ﬁrst two of the original data as the window has now moved to cover them. The third entry in the ﬁltered data set is the average of the ﬁrst three elements of the origi- nal data set and so on. As before we use SAMPLE as our test data set with which to develop our ﬁlter.  w WINDOW:=3;  WINDOW := 3  275   Applied Maple for Engineers and Scientists  Direction of travel  of window  Window  Data  x1 x2 x3 x4  .. xn  x1 x2 x3 x4  .. xn  x1 x2 x3 x4  .. xn  x1 x2 x3 x4  .. xn  Figure 7.22  Create a matrix of the data that is larger by 2 WINDOW-1  and pad it  with zeros at both the beginning and the end. This makes it easier to sweep the window over the data at its extremities.  w ZEROS:=0$WINDOW-1;  ZEROS := 0, 0  w MAT:=linalg[matrix] 1, nops SAMPLE + WINDOW-1 *2, [ZEROS,  op SAMPLE , ZEROS] ;  MAT := [0 0 2 0 1 0 1 0 0 1 0 0 0 0]  Using the for loop shown next, we sweep the window over the pre- ceding matrix and compute the next element in the ﬁltered data set by ﬁrst removing the windowed elements, converting the submatrix to a list of lists, isolating the sublist, and then ﬁnding the average of its entries. The result is appended to the previously calculated results.  w FILTERED:=NULL:  for n to nops SAMPLE  do  temp:=linalg[submatrix] MAT, 1..1, n..n+2 : temp:=convert temp, listlist : temp:=convert op temp , ‘+’  WINDOW: FILTERED:=FILTERED, temp: print FILTERED ;  od: [FILTERED];  276   Discrete data processing  2 3  2 3  ,  2 3  2 3  ,  2 3  , 1  2 3  ,  2 3  , 1,  1 3  2 3  ,  2 3  , 1,  1 3  ,  2 3  2 3  ,  2 3  , 1,  1 3  ,  2 3  ,  1 3  2 3  ,  2 3  , 1,  1 3  ,  2 3  ,  1 3  ,  1 3  2 3  ,  2 3  , 1,  1 3  ,  2 3  ,  1 3  ,  1 3  ,  1 3  2 3  ,  2 3  , 1,  1 3  ,  2 3  ,  1 3  ,  1 3  ,  1 3  ,  1 3  2 3  2 3  ,  ,  2 3  2 3  , 1,  , 1,  1 3  1 3  ,  ,  2 3  2 3  ,  ,  1 3  1 3  ,  ,  1 3  1 3  ,  ,  1 3  1 3  ,  ,  1 3  1 3  ,  ,  1 3  1 3  The function moving_ave, which is an extension of the for loop  shown previously, is found on the program disk and can be used to ﬁlter a list of sample points. In addition to the data list, the window length must also be speciﬁed. Here we apply moving_ave to the data list used in the previous example  Figure 7.23 :  w FILTERED:=moving_ave SERIES_DATA,3 :  plots[listplot] [FILTERED], title=’Moving Average Filter  Output’, lables=[‘t’,’amp’] ;  277  Ø Œ º ø œ ß  Applied Maple for Engineers and Scientists  amp  10  8  6  4  2  0  Figure 7.23 Moving average filter output.  0  50  100  150  200  250  t  Now we can investigate the eﬀect on the ﬁltered data of altering the  window size:  w MANY_TIMES:=SERIES_DATA:  3*n   od:  for n to 3 do MANY_TIMES:=MANY_TIMES, moving_ave op n, [MANY_TIMES] ,  Using listplot we can plot the output from each iteration   Figures 7.24 through 7.27 . By placing the resulting plots into an array structure we can compare the output for each iteration easily. By using a ta- ble we can easily place a relevant title on each plot.  w TITLES:=table [1=’Original Data’, 2=’Window = 3’, 3=’Window  = 6’, 4=’Window = 9’] :  temp:=[seq plots[listplot] [MANY_TIMES[n]], title=TITLES[n]  view=[0..255, 0..20] , n=1..4 ]:  plots[display] array 1..2,1..2, [temp[1..2], temp[3..4]]  :  278   Discrete data processing  Figure 7.24 Original data.  50  100  150  200  250  amp  10  amp  10  20  15  5  0  0  20  15  5  0  0  t  t  Figure 7.25 Window = 3.  50  100  150  200  250  279   Applied Maple for Engineers and Scientists  Figure 7.26 Window = 6.  50  100  150  200  250  t  20  15  amp  10  5  0  0  20  15  5  0  0  amp  10  Figure 7.27 Window = 9.  50  100  150  200  250  t  The moving average ﬁlter is an easy ﬁlter to implement that possesses  good noise reduction qualities. With reference to Figures 7.24 through  280   Discrete data processing  7.27, we can see that there is a trade-oﬀ between the amount of smoothing achieved, determined by the window size and the retention of information in areas of high volatility or rapid change. As the window size is increased, more elements are averaged, which results in increased noise rejection but individual peaks in the data tend to be blurred. The reduction in signal am- plitude is an artifact of the averaging process that can be avoided through normalization techniques.  Moving median The moving median ﬁlter is similar to the moving average ﬁlter in terms of operation  computing the new data from the old data by sweeping a win- dow over the old data . but instead of using the average value, we use the median value of the windowed data. So, for example, the median of the data list SAMPLE is:  w stats[describe, median] SAMPLE ;  0  0  We can see more clearly how this answer was arrived at by ﬁrst sorting  SAMPLE and then taking the middle entry:  w sort SAMPLE ;  [0, 0, 0, 0, 0, 0, 1, 1, 1, 2]  w op floor nops SAMPLE  2 , “ ;  Next we repeat the ﬁltering process while sweeping the window across  the data:  w WINDOW:=3:  MAT:=linalg[matrix] 1, nops SAMPLE , SAMPLE : FILTERED:=op 1..WINDOW-1, SAMPLE :  w for n from WINDOW to nops SAMPLE -WINDOW+1 do  temp:=linalg[submatrix] MAT, 1..1, n..n+WINDOW-1 :  281   Applied Maple for Engineers and Scientists  temp:=convert temp, listlist : temp:=stats[describe, median] op temp  : FILTERED:=FILTERED, temp: print FILTERED ;  od:  2, 0, 1  2, 0, 1, 0  2, 0, 1, 0, 0  2, 0, 1, 0, 0, 0  2, 0, 1, 0, 0, 0, 0  2, 0, 1, 0, 0, 0, 0, 0  Now we can compare the original with the ﬁltered data:  w FILTERED:=FILTERED, op nops SAMPLE -WINDOW+2..nops   SAMPLE , SAMPLE ;  FILTERED := 2, 0, 1, 0, 0, 0, 0, 0, 0, 0  w SAMPLE;  [2, 0, 1, 0, 1, 0, 0, 1, 0, 0]  When applying a median ﬁlter, we have the option of applying it until the ﬁltered data are identical to the unﬁltered data. At this point no more ﬁltering is possible so we stop. In Maple we would implement this as fol- lows. First we save the original data for the current iteration:  w OLD:=[FILTERED]:  FILTERED:=moving_median [FILTERED],3 ;  FILTERED := [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  Are the ﬁltered data equal to the original?  282   Discrete data processing  w linalg[iszero] linalg[matrix] 1, nops OLD , zip  x,y ->x-y,  OLD,FILTERED   ;  false  This time around they are not, so we must continue:  w OLD:=FILTERED:  FILTERED:=moving_median FILTERED,3 ;  FILTERED := [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  We continue to repeat the operations in the loop until the output data from an iteration are equal to the prior iteration. Although it is not neces- sary to continue in this particular way, the following code can be used to ﬁlter the data repeatedly and compare the ﬁlter’s output with its input. If the ﬁlter’s input and output are diﬀerent, then the ﬁltering operation ceases; if not, it continues:  w while not linalg[iszero] linalg[matrix] 1, nops OLD ,  zip  x,y ->x-y, OLD, FILTERED    do  OLD:=FILTERED: FILTERED:=moving_median FILTERED,3 ; od;  Here we use the function moving_median ﬁrst in a single-shot mode  and then with repeated application. The mode of operation is set with a third, optional, argument. If this argument is omitted, the single-shot mode of operation is used by default. The diﬀerence in the ﬁlter’s output is obvious.  w moving_median SAMPLE, 3, repeated=false ;  [2, 0, 1, 0, 0, 0, 0, 0, 0, 0]  w moving_median SAMPLE, 3, repeated=true ;  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  283   Applied Maple for Engineers and Scientists  Here we test the moving median ﬁlter on our test data and show the re-  sults in Figure 7.28:  w FILTERED:=moving_median SERIES_DATA,3 :  plots[listplot] [FILTERED], title=’Moving Median Filter  Output’ ;  amp  10  8  6  4  2  0  284  Figure 7.28 Moving median filter output.  0  50  100  150  200  250  t  Now we can look at the eﬀect on the ﬁltered data as we pass it through  the ﬁlter more than once:  w MANY_TIMES:=SERIES_DATA:  for n to 3 do MANY_TIMES:=MANY_TIMES, moving_median op n, [MANY_TIMES] , 3  od:   Discrete data processing  Using listplot we can plot the output from each iteration   Figures 7.29 through 7.32 . By placing the resulting plots into an array structure, we can compare the output for each iteration easily. By using a table we can easily place a relevant title on each plot.  w TITLES:=table [1=’Original Data’, 2=’First Iteration’,  3=’Second Iteration’, 4=’Third Iteration’] :  temp:=[seq, plots[listplot] [MANY_TIMES[n]],  title=TITLES[n] , view=[0..255, 0..20] , n=1..4 ]:  plots[display] array 1..2, 1..2, [temp[1..2], temp[3..4]]  :  amp  10  20  15  5  0  0  Figure 7.29 Original data.  50  100  150  200  250  t  The moving median ﬁlter is another easy ﬁlter to implement that  possesses good noise reduction qualities. Like the moving average ﬁlter discussed earlier, there is a trade-oﬀ between the amount of smoothing achieved, determined by the window size, and the retention of information in areas of high volatility or rapid change. The major advantage of the mov- ing median ﬁlter over the moving average is its ability to reject noise  while retaining individual peaks in the data. The reduction in signal amplitude, which is a consequence of the ﬁltering process, is not as dramatic as in the moving average ﬁlter’s case and can be avoided through normalization techniques.  285   Applied Maple for Engineers and Scientists  20  15  amp  10  5  0  0  20  15  5  0  0  amp  10  t  t  Figure 7.30 First iteration.  50  100  150  200  250  50  100  150  200  250  Figure 7.31 Second iteration.  286   Discrete data processing  20  15  amp  10  5  0  0  Figure 7.32 Third iteration.  50  100  150  200  250  t  Exponential filtering The ﬁlters that we have looked at so far have all operated on the data, giv- ing each element in the data set an equal weight. The ﬁlters have also all been without memory, that is to say, once a ﬁltered sample has been com- puted it plays no further role in the ﬁltering function. The exponential ﬁlter is diﬀerent on both counts: Previously calculated ﬁlter outputs are used in the calculation of the current output, and previous outputs have a weight associated with them that decreases exponentially the further back in time we go. The ﬁrst task is to build the type of ﬁlter that we want, in this case a simple exponential ﬁlter:  w filter := y t  r t =exp a*t ;  filter := y t  r t    a t   = e  Using the Z-transform function found in the integral transforms pack-  age inttrans we transform the continuous ﬁlter into its discrete form. We are using the normal conventions in terms of t and z.  287   Applied Maple for Engineers and Scientists  w with inttrans :  Before we actually perform this ﬁltering operation we develop a simple  function that performs cross multiplication:  w cross_multiply:= x->numer lhs x  *denom rhs x   =  numer rhs x  *denom lhs x  ;  cross_multiply  := x ﬁ  numer lhs x   denom rhs x   = numer rhs x   denom lhs x    Applying this to the ﬁlter transfer function we get  w Filter:=cross_multiply Y z  R z = ztrans rhs filter ,  t, z  ;  Filter := Y z   cid:230   Ł z -  ea cid:246  ł = z R z   The ﬁlter response in terms of z can now be manipulated. Here we multiply each side by z to ensure that the input R z  is always the current sample.  w Filter:=expand Filter z ;  Filter := Y z  - Y z  ea  = R z   z  Using Maple’s alias function we simplify the printed form of the trans-  fer function:  w alias Y=Y z , R=R z  ;  I, Y, R  Next we get the coeﬃcients of Y z  and R z , respectively. These will  be the weightings that are applied to the ﬁlter samples:  288   Discrete data processing  w map coeffs, Filter, {Y, R} ;  1 -  ea z  = 1  w coefflist:=map convert,",list ;  coefflist :=  1, -  = [1]  ea z  The next stage is to recreate the ﬁlter transfer function in terms of the  current output, the previous outputs, and the current input. We deﬁne these as y0, y1, and r0, respectively.  w left:=zip  x,y ->x*y,lhs coefflist , [‘y.n’$ n=0..1 ] ;  w right:=zip  x,y ->x*y,rhs coefflist , [‘r.n’$n=0..0] ;  left :=  y0, -  eay1 z  right := [r0]  w new_filter:=subs z=1, readlib isolate  convert left, ‘+’  =  convert right, ‘+’ , y0  ;  new_filter := y0 = r0 + eay1  The ﬁrst thing that we notice is that the ﬁlter has gain. We can elimi-  nate this by adjusting the weighting of the ﬁlter input r0. It is common when designing digital ﬁlters of this nature to ensure that the ﬁlter coeﬃ- cients add to unity. In this case we need to multiply r0 by A and y1 by 1 - A, where A is ea and is known as the ﬁlter weight.  289  Ø Œ º ø œ ß Ø Œ º ø œ ß  Applied Maple for Engineers and Scientists  w new_filter:=subs r0=r0*A, exp a = 1-A , A=exp a ,  new_filter ;  new_filter := y0 + r0 ea +  cid:230   Ł 1 -  ea cid:246   y1  Now we can use unapply to convert the transfer function into function notation:  w NEW_FILTER := unapply rhs new_filter , r0, y1, a ; ea cid:246   NEW_FILTER :=  r0, y1, a  ﬁ  r0 ea +  cid:230   y1  Ł 1 -  Finally, we test the ﬁltering function.  w NEW_FILTER 1,0,-0.5 ;  w NEW_FILTER 0, “, -0.5 ;  .6065306597  .2386512185  the ﬁlter’s impulse response:  w LAST:=0:ANS:=NULL:R:=1:  for n from 0 to 10 do  LAST:=NEW_FILTER R, LAST, -0.5 : ANS:=ANS, [n, LAST]: if n>=0 then R:=0 fi:  So far so good. Now using a loop we compute and plot  Figure 7.33   od: plot [ANS], title=’Impulse Response’, labels=[‘t’,’amp’] ;  290  ł ł  Discrete data processing  0.6  0.5  0.4  0.2  0.1  amp  0.3  Figure 7.33 Impulse response.  0  0  2  4  6  8  10  t  Here we apply the new ﬁlter to our test data. We are using the function  exp_filter found on the program disk.  w exp_filter SAMPLE, -0.7 ;  [.9931706076, .4999766797, .7482809121, .3766956080, .6862194089, .3454529353, .1739060845, .5841321825, .2940607252, .1480344906]  By applying the exp_filter to our test data, we can exponentially  smooth it. In the ﬁrst case we use a ﬁlter weight of - 0.7 and plot  Figure 7.34  the ﬁlter output using listplot as shown:  w exp_filter SERIES_DATA, -0.7 :  plots[listplot] [“], title=’Output from Exponential  Filter’, labels=[‘t’,’amp’] ;  291   Applied Maple for Engineers and Scientists  amp  6  10  8  4  2  0  Figure 7.34 Output from exponential filter.  0  50  100  150  200  250  t  As with the previous types, it is beneﬁcial to compare the exponential  ﬁlters response to changing ﬁlter weights. The next few lines of Maple code produce plots of the original and ﬁltered data, with ﬁlter weights - 0.7, - 0.3, and - 0.1, and displays them all in a single graphics array  Figures 7.35 through 7.38 :  w MANY_TIMES:=READINGS:WEIGHTS:=[-0.7, -0.3, -0.1]:  for n to 3 do MANY_TIMES:=MANY_TIMES,exp_filter READINGS, WEIGHTS[n] : od:  w TITLES:=table [1=’Original Data’, 2=’Filter Weight = -0.7’,  3=’Filter Weight = -0.3’, 4=’Filter Weight = -0.1’] :  temp:=[seq plots[listplot] [MANY_TIMES[n]],  title=TITLES[n], view=[0..255, 0..20] , n=1..4 ]:  plots[display] array 1..2,1..2, [temp[1..2], temp[3..4]]  :  292   Discrete data processing  Figure 7.35 Original data.  50  100  150  200  250  amp  10  20  15  5  0  0  20  15  amp  10  5  0  0  t  t  Figure 7.36 Filter weight = - 0.7.  50  100  150  200  250  293   Applied Maple for Engineers and Scientists  20  15  amp  10  5  0  0  20  15  5  0  0  amp  10  t  t  Figure 7.37 Filter weight = - 0.3.  50  100  150  200  250  50  100  150  200  250  Figure 7.38 Filter weight = - 0.1.  294   Discrete data processing  The exponential ﬁlter is unique among the ﬁlter conﬁgurations dis- cussed in this section in that it contains hystersis  i.e., there is a memory component in its implementation which means that the next ﬁlter output is aﬀected by previous ﬁlter outputs . With reference to Figures 7.35 through 7.38, we can see that the exponential ﬁlter has good noise reduction quali- ties while being able to retain data that are changing rapidly. The level of noise reduction and the corresponding ability to track fast changing data are determined by the ﬁlter weight—the higher the weight the greater the noise reduction. The reduction in signal amplitude is due to the ﬁlter process and can be avoided through the application of normalization techniques.  Conclusion  The ﬁnal graphics show the original series data along with the outputs from the diﬀerence, moving average, moving median, and the exponential ﬁlters  Figure 7.39 through 7.47 .  amp  10  20  15  5  0  0  Figure 7.39 Original data.  50  100  150  200  250  t  295   Applied Maple for Engineers and Scientists  delta  amp  10  8  6  4  2  0  - 2  - 4  - 6  10  8  6  4  2  0  t  t  Figure 7.40 Difference filter output.  0  50  100  150  200  250  0  50  100  150  200  250  Figure 7.41 Moving average filter output.  296   Discrete data processing  Figure 7.42 Moving median filter output.  0  50  100  150  200  250  amp  10  8  6  4  2  0  10  8  4  2  0  amp  6  t  t  Figure 7.43 Output from exponential filter.  0  50  100  150  200  250  297   Applied Maple for Engineers and Scientists  amp  10  amp  10  20  15  5  0  0  20  15  5  0  0  t  t  Figure 7.44 Filter weight = - 0.3.  50  100  150  200  250  50  100  150  200  250  Figure 7.45 Filter weight = - 0.1.  298   Discrete data processing  20  15  amp  10  5  0  0  20  15  5  0  0  amp  10  Figure 7.46 Window = 6.  50  100  150  200  250  t  Figure 7.47 Window = 9.  50  100  150  200  250  t  299   Applied Maple for Engineers and Scientists  The four ﬁlter conﬁgurations that have been discussed in this chapter are the diﬀerencing ﬁlter, the moving average ﬁlter, the moving mean ﬁlter, and the exponential ﬁlter. The diﬀerencing ﬁlter is good at helping to iden- tify underlying trends and areas of rapid changes within data sets. The mov- ing average and moving mean ﬁlters both exhibit good noise cancellation properties with the moving median ﬁlter possessing the best ability to track fast moving data. Finally, the exponential ﬁlter is a special implementation of a digital ﬁlter that has good noise reduction qualities and can track fast moving data adequately. All of the ﬁlters reduce the signal amplitude but this attenuation can be avoided through the application of normalization techniques.  300   Applied Maple for Engineers and Scientists  Chapter 8  Switching topologies  Generally, switching topologies are used for optimal power han-  dling eﬃciency  conventional switching power supplies  and or certain types of signal processing  e.g., precision analog multipli- ers dividers, phase detectors . Two immediate and common applications involving switching circuit topologies are  1  pulse width modulator  PWM  signal acquisition and or PWM drivers, and  2  switching power supplies. Both of these circuit topologies utilize switching to minimize the amount of varying conduction time, which results in excessive heating, ex- perienced by the controlling device s . Also, if it is a signal processing ap- plication, then varying conduction times cause mathematical errors via excessive noise  amplitude variance versus phase information variations .  In this chapter we explore two methods for analyzing switching output waveforms. The ﬁrst method assumes the system is at steady state and each period exhibits the same response. The second method uses Fourier analy- sis to show the transient startup behavior of the switching topology.  301   Applied Maple for Engineers and Scientists  For further reading on the solution for these and other switching net-  works, [1–4] are strongly recommended.  Steady-state method  Pulse width modulator driver Figure 8.1 shows a typical PWM input waveform with a period, T. The second part of this design requires a ﬁlter that simply produces the average of the PWM waveform. Figure 8.2 shows a simple RC ﬁlter that achieves this result. Further, we know what the output voltage will approximate, so we can redraw Figure 8.1 with the ﬁltered output superimposed as shown in Figure 8.3.  Input voltage  A  Nonconduction phase  Conduction phase  0  0  Figure 8.1 PWM input waveform.  T 4  T 2  3T 4  T  Time  Input voltage  Vin   Output voltage  Vout   R  C  Figure 8.2 RC filter.  302   Switching topologies  Input voltage  Nonconduction phase  V2  V2  Conduction phase  Output voltage  V1  0  T 4  T 2  3T 4  T  Time  A  V1  0  Figure 8.3  Note that we have assumed a steady-state solution for the network for a given set of conditions. In short, the output voltage waveform will exhibit a periodic form once transients have gone to zero. Therefore, we may derive the voltages V1 and V2 and from these values determine the entire steady- state response of the PWM circuit.  Perhaps the most important aspect of this driver is what kind of output  can we tolerate in terms of ripple or switching noise associated with the switching operation? By deriving the V1 and V2 values in Figure 8.3, we not only solve the steady-state dynamics, but can also reverse engineer the process to determine the maximum allowable ripple  i.e., V1- V2  for any given set of circuit parameters.  To determine this and other important design aspects, let’s start a  Maple session that enters the waveforms and RC ﬁlter topology. Starting with the required Maple libraries,  we enter the topology and switching input waveform values:  w with inttrans ::  with plots :  w Freq := 10^4:  R := 1000: C := 10^ -6 : alfa := .5: Vin := 10 s: T := 1 Freq:  303   Applied Maple for Engineers and Scientists  where  Freq ﬁ R C alfa Vin ﬁ T  switching frequency  hertz  resistor value  ohms  capacitor value  farads  duty cycle  dimensionless  input voltage  volts  switching period  seconds   Next, we take the inverse Laplace transforms associated with two con-  tinuous regimes, i.e.,  Regime 1 0 £ Regime 2 a T £  t < a T t < T  Let’s deﬁne the output under the two regimes as  Regime 1 VOUT Regime 2 VOUT  1 VOUT 2 VOUT  Vout_1_Time Vout_2_Time  Therefore, in Maple syntax,  w Vout_1_Time := invlaplace  Vin+s*R*C*V1 s   s*R*C+1 ,s,t ;  Vout_2_Time := invlaplace  s*R*C*V2 s   s*R*C+1 ,s,t ;  Vout_1_Time := 10 - Vout_2_Time := V2 e  10 e  - 1000 t    - 1000 t  + V1 e   - 1000 t   Figure 8.3 indicates that at steady state the boundary conditions under  the two regimes are  1  VOUT VOUT  2   t = a T   = V2  t = T -  a T   = V1  304  ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ  Switching topologies  We cannot simply state the second boundary condition as  2  VOUT   t = T   = V1  because as far as the output voltage under the second regime is concerned, the dynamics are functionally dependent on a time duration as opposed to any speciﬁc time on an arbitrary time axis. Consequently, we have two equations and two unknowns and can get the unique solution in Maple as follows: First, we solve the following boundary conditions just stated as:  w Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  ;  Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T, Vout_2_Time  ;  Vout_1_Time_AlfaT := .487705755 + .9512294245 V1 Vout_2_Time_TminusAlfaT := .9512294245 V2  Then using Maple’s solve command,  w Solutions : =  solve {Vout_1_Time_AlfaT=V2,Vout_2_Time_TminusAlfaT=V1}, {V1,V2} ;  Solutions :=  cid:236    cid:238  V2 = 5.124973963 , V1 = 4.875026033  cid:252   Converting the result into an order list for resubstitution, we perform  w XX := subs Solutions,[V1,V2] :  the following:  V1 := XX[1]; V2 := XX[2];  V1 = 4.875026033 V2 = 5.124973963  Now, we need to convert the output voltage under the second regime t < T  to reﬂect the time duration by sliding the time scale relative to   t  expression as mentioned earlier. Hence,   a T £ the VOUT  2  305   cid:237   cid:253   cid:254   Applied Maple for Engineers and Scientists  w Vout_2_Time_Duration : = subs t = t-alfa*T,Vout_2_Time :  In this way, we can substitute the graphic values of time into the sec-  ond regime’s output expression directly as we see them in the graph. Plotting the periodic voltage output along with the average value  requires that we ﬁrst compute the average value of the periodic output as  VAVG  = 1 T  a T  0  1  VOUT  T   t dt +  cid:242  a T  2  VOUT   t dt  In Maple,  w Output_Average := 1 T* int Vout_1_Time,t=0..alfa*T +int   Vout_2_Time_Duration,t=alfa*T..T  ;  Output_Average := 5.000000000  This result is not surprising considering that we are using a 50% duty  cycle with a 10-volt PWM square wave.  Now plotting the average value along with the entire two-regime time  response over a per period of T,  w Plot_1 := plot Vout_1_Time,t=0..alfa*T,color = black,  style=point,symbol=cross : Plot_2 := plot Vout_2_Time_Duration,t=alfa*T..T, color=black,style=point,symbol=circle : Plot_3 := plot  Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed,color=black, labels=[Time_seconds,Voltage] ;  In Figure 8.4, we point plotted the regimes diﬀerently, so that the t < T is plotted with  reader can see the individual solutions on one plot. Regime 1 or 0 £ is plotted with crosses, whereas regime 2 or a T £ circles.  t < a T  306   cid:230   cid:231  Ł  cid:231   cid:231   cid:242   cid:246   cid:247  ł  cid:247   cid:247   Switching topologies  5.1  5.05  4.95  4.9  Voltage  5  0  2e-05  4e-05  6e-05  8e-05  0.001  Time_seconds  Figure 8.4 Output voltage plot of filtered PWM signal  R = 1000ohms, C = 1 µF, frequency = 10 kHz, duty cycle = 50%, Vin = 10V .  Now we can play around with the variables to see the eﬀects of parame- ter variation. For instance, what if we were to increase the RC ﬁlter’s band- width by two orders of magnitude? We would expect to see more of the traditional RC roll-oﬀ characteristics on a per-period basis. Therefore, change the ﬁlter capacitor to 0.1 m F and resistance to 100 W  .  w with plots :  with inttrans : Freq := 10^4: R := 100: C := 10^ -7 : alfa := .5: Vin := 10 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*R*C*V1 s   s*R*C+1 ,s,t : Vout_2_Time := invlaplace  s*R*C*V2 s   s*R*C+1 ,s,t :  307   Applied Maple for Engineers and Scientists  Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T, Vout_2_Time  : Solutions := solve {Vout_1_Time_AlfaT=V2,  Vout_2_Time_TminusAlfaT=V1},{V1,V2} :  XX := subs Solutions,[V1,V2] : V1 := XX[1]: V2 := XX[2]: Vout_2_Time_Duration := subs t=t-alfa*T,Vout_2_Time : Output_Average := 1 T* int Vout_1_Time,t=0..alfa*T +  int Vout_2_Time_Duration,t=alfa*T..T  :  Plot_1 := plot Vout_1_Time,t=0..alfa*T,color=black, style=point,symbol=cross : Plot_2 := plot Vout_2_Time_Duration,t=alfa*T..T, color=black,style=point,symbol=circle : Plot_3 := plot  Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed, color=black, labels=[Time_seconds,Voltage] ;  Figure 8.5 shows that the low-pass RC ﬁlter has allowed the ripple to  nearly be the full square-wave swing or 10V peak to peak.  Now let’s set the duty cycle to 25% under the two previously per-  formed ﬁlter values: R = 1000 W and C = 1 m F  w with plots :  with inttrans : Freq := 10^4: R := 1000: C := 10^ -6 : alfa := .25: Vin := 10 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*R*C*V1 s   s*R*C+1 ,s,t : Vout_2_Time := invlaplace  s*R*C*V2 s   s*R*C+1 ,s,t : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T, Vout_2_Time  : Solutions := solve {Vout_1_Time_AlfaT=V2, Vout_2_Time_ TminusAlfaT=V1},{V1,V2} :  308   Switching topologies  XX := subs Solutions,[V1,V2] : V1 := XX[1]: V2 := XX[2]: Vout_2_Time_Duration := subs t=t-alfa*T,Vout_2_Time : Output_Average := 1 T* int Vout_1_Time,t=0..alfa*T +  int Vout_2_Time_Duration,t=alfa*T..T  :  Plot_1 := plot Vout_1_Time,t=0..alfa*T,color=black, style=point,symbol=cross : Plot _2 := plot Vout_2_Time_Duration,t=alfa*T..T, color=black,style=point,symbol=circle : Plot_3  := plot  Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed,color=black, labels=[Time_seconds,Voltage] ;  Voltage  10  8  6  4  2  0  2e-05  4e-05  8e-05  0.001  6e-05 Time_seconds  Figure 8.5 Output voltage plot of filtered PWM signal  R = 100 ohms, C = 0.1 µF, frequency = 10 kHz, duty cycle = 50%, Vin = 10V .  309   Applied Maple for Engineers and Scientists  R = 100 W and C = 0.1 m F  w with plots :  with inttrans : Freq := 10^4: R := 100: C := 10^ -7 : alfa := .25: Vin := 10 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*R*C*V1 s   s*R*C+1 ,s,t : Vout_2_Time := invlaplace  s*R*C*V2 s   s*R*C+1 ,s,t : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  Vout_2_Time  :  Solutions := solve {Vout_1_Time_AlfaT=V2,  Vout_2_Time_TminusAlfaT=V1},{V1,V2} :  XX := subs Solutions,[V1,V2] : V1 :=XX[1]: V2 := XX[2]: Vout_2_Time_Duration := subs t=t-alfa*T,Vout_2_Time : Output_Average := 1 T* int Vout_1_Time,t=0..alfa*T +  int Vout_2_Time_Duration,t=alfa*T..T  :  Plot_1 := plot Vout_1_Time,t=0..alfa*T,color=black,  style =point,symbol=cross :  Plot_2 := plot Vout_2_Time_Duration,t=alfa*T..T,  color=black,style=point,symbol=circle :  Plot_3 := plot  Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed,color=black,  labels=[Time_seconds,Voltage] ;  From Figures 8.6 and 8.7 we immediately see that having a low-pass  ﬁlter whose cutoﬀ frequency  fCUTOFF  =  1  2p RC  is well below the switching frequency provides a reasonably good averag- ing of the input waveform. The cutoﬀ frequencies associated with the ﬁrst and second cases were  310   Switching topologies  Voltage  2.5  2.58  2.56  2.54  2.52  2.48  2.46  2.44  2.42  2e-05  4e-05  6e-05  8e-05  0.0001  TIme_seconds  Figure 8.6 Output voltage plot of filtered PWM signal  R = 1000 ohms, C = 1 µF, frequency = 10 kHz, duty cycle = 25%, Vin = 10V .  Case 1 fCUTOFF  Case 2 fCUTOFF  =  =  1  1  2p RC  2p RC  =  =  1  1  2p  1000  1m F    2p  100  .1m F    = 159.15 Hz  = 15.915 kHz  With a switching frequency of 10 kHz, most of the switching fre-  quency was removed in the ﬁrst case, and almost all of the switching infor- mation was passed in the second case as is evident from the plots. Now, let’s reverse the process by specifying a certain ripple V1 - V2 £ for a given load under ﬁxed conditions of duty cycle and input switching volt- age. In this way, whether the circuit is being used for signal processing or power transduction, we will know the switching ripple’s worst case  311  z  Applied Maple for Engineers and Scientists  Voltage  8  6  4  2  0  312  2e-05  4e-05  8e-05  0.0001  6e-05 Time_seconds  Figure 8.7 Output voltage plot of filtered PWM signal  R = 100 ohms, C = 0.1 µF, frequency = 10 kHz, duty cycle = 25%, Vin = 10V .  scenario. In signal processing applications, the ripple can detract from the averaging ﬁlter’s dynamic range, whereas for a power application  say, heat- ing coils , the ripple connotes the excessive voltages  especially V1  beyond the desired average value stressing the elements.  If we constrain the ripple to a maximum of 1V peak to peak  V1 - V2 £ 1 under a duty cycle of 50% with an applied input switching volt- age of 50V at 5 kHz, then we can determine the minimal RC product needed to ensure this speciﬁcation. First we enter the knowns of the prob- lem along with the appropriate Maple libraries:   Switching topologies  w with inttrans : Freq := 5*10^3: alfa := .50: Vin := 50 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*RC*V1 s   s*RC+1 ,s,t : Vout_2_Time := invlaplace  s*RC*V2 s   s*RC+1 ,s,t : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  Vout_2_Time  :  Solutions := solve {Vout_1_Time_AlfaT=V2,  Vout_2_Time_TminusAlfaT=V1},{V1,V2} :  XX := subs Solutions,[V1,V2] : V1 := XX[1]: V2 := XX[2]: Peak_To_Peak_Ripple :=abs V2-V1 ;  Peak_To_Peak_Ripple :=  1  .0001000000000  50.  e  1 RC  ł +1.  50.  e  1 RC  .0001000000000  e .0001000000000  1 RC  ł + 1  Now that we have the expression relating the RC product to the peak- to-peak ripple, we solve the expression using Maple’s solve command:  w Ripple_Result : = solve Peak_To_Peak_Ripple = 1,RC ;  Ripple_Result := -  .002499666603 , .002499666629  Since the RC product must be positive and nonzero, the correct value  for the problem is  RCMINIMUM  = .002499666629  From this, we can simply play a balancing act between available resis- tor and capacitance values to obtain the minimal RC product to ensure the previous design requirements.  313   cid:239   cid:239   cid:239   cid:239   cid:239   cid:230   cid:231  Ł -  cid:246   cid:247  -  cid:230   cid:231  Ł -  cid:246   cid:247  ł  cid:230   cid:231  Ł -  cid:246   cid:247   cid:239   cid:239   cid:239   cid:239   cid:239   Applied Maple for Engineers and Scientists  From an analysis point of view, the question now becomes what is the allowable range of duty cycle variance to ensure that the peak-to-peak rip- ple does not exceed 1V? This question is best answered by looking at the dependence of output ripple voltage as a function of duty cycle, hence, a plot of these variables in Maple becomes  w with plots :  with inttrans : Freq : =5*10^3: RC : =.002499666629: Vin : =50 s: T :=1 Freq: Vout_1_Time := invlaplace  Vin+s*RC*V1 s   s*RC+1 ,s,t : Vout_2_Time : =invlaplace  s*RC*V2 s   s*RC+1 ,s,t : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  Vout_2_Time  :  Solutions := solve {Vout_1_Time_AlfaT=V2,  Vout_2_Time_TminusAlfaT=V1},{V1,V2} :  XX := subs Solutions,[V1,V2] : V1 :=XX[1]: V2 := XX[2]: Peak_To_Peak_Ripple := abs V2-V1 : plot Peak_To_Peak_Ripple,alfa=.3..+.7,axes=boxed,  color=black,labels=[D uty_Cycle,Ripple] ;  From Figure 8.8, it appears that the original computation of the mini- mal RC product was given at the maximal ripple duty cycle value  50% . Therefore, to ensure a range of acceptable duty cycle variations, we need only specify the minimum RC product suﬃcient to ensure that we do not exceed the 1V peak-to-peak ripple speciﬁcation at 50%.  However, if we are in the signal processing business and we are con-  cerned over the relative signal-to-noise ratio  SNR , then the picture is diﬀerent. For instance, if we operate the PWM system at a low duty cycle, incurring a low average value, then the recovered information  average value  might not be suﬃciently larger than that passed through switching frequency ripple.  314   Switching topologies  Ripple  0.92  1  0.98  0.96  0.94  0.9  0.88  0.86  0.84  0.3  0.4  0.6  0.7  0.5  Duty_Cycle  Figure 8.8 Peak-to-peak ripple versus duty cycle  RC = .002499666629, frequency = 5 kHz, duty cycle range = 30% to 70%, Vin = 50V .  The relative SNR merit function, SNRREL, might be  SNRREL  =  Average output to- peak ripple output  Peak-  Since we have computed these functions previously, we can plot this  merit function as a function of duty cycle. Thus,  w with plots :  with inttrans : Freq := 5*10^3: RC := .002499666629: Vin := 50 s: T :=  Freq:  315   Applied Maple for Engineers and Scientists  Vout_1_Time := invlaplace  Vin+s*RC*V1 s   s*RC+1 ,s,t : Vout_2_Time := invlaplace  s*RC*V2 s   s*RC+1 ,s,t : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  Vout_2_Time  :  Solutions := solve {Vout_1_Time_AlfaT=V2,Vout_2_Time_  TminusAlfaT=V1},{V1,V2} :  XX := subs Solutions,[V1,V2] : V1 := XX[1]: V2 := XX[2]: Vout_2_Time_Duration := subs t=t-alfa*T,Vout_2_Time : Output_Average := 1 T* int Vout_1_Time,t=0..alfa*T +  int Vout_2_Time_Duration,t=alfa*T..T  :  Peak_To_Peak_Ripple := abs V2-V1 : SNR_Rel := Output_Average  Peak_To_Peak_Ripple: plot SNR_Rel,alfa=+.1..+.9,axes=boxed,color=black,  labels=  [Duty_Cycle,SNR] ;  As evident in Figure 8.9, the lower duty cycles have a much lower SNR, even though Figure 8.8 indicated that a 50% duty cycle gave the maximal ripple. Consequently, depending on the application of this type of signal handling, one needs to determine which aspect of the PWM recov- ered information is of importance, in other words, which quiescent operat- ing point should be employed.  Switching power supply In those applications where the regulated output dc voltage is less than the input unregulated dc voltage, a certain switching regulator is utilized. Since the output is less than the input voltage, it is called a buck-type converter. If the output voltage is greater than the input, then the switching regulator is called a boost-type converter. We will be dealing with the design and analysis of a buck-type dc-to-dc converter.  Figure 8.10 depicts the general topology associated with a buck-type converter, which can be functionally reduced to Figure 8.11 for analysis purposes. From Figure 8.11, one notices the second-order low-pass ﬁlter  LPF  with the inductor, capacitor, and resistive load circuitry. The topol- ogy is simply a series resonant circuit with resistive dissipation. Further simpliﬁcation is obtained when the switching transistor model  Q1  and PWM controller blocks are modeled and removed by incorporation of their function into the input signal as shown in Figure 8.12.  316   Switching topologies  SNR  120  100  80  60  40  20  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  Duty_Cycle  Figure 8.9 Relative SNR versus duty cycle  RC = .002499666629, frequency = 5kHz, Vin = 50V .  Vdc  Q1  L  Vout  C  D1  R  Figure 8.10 Simple buck-type switching power supply.  PWM controller  Feedback  317   Applied Maple for Engineers and Scientists  Vdc  Q1  L  Vout  C  R  Figure 8.11 Base buck-type converter topology.  PWM controller  Feedback  Vout  R  L  C   a   Vin  Vin t   Vdc  0  0  a T  Figure 8.12 Basic model for the buck-type converter.  Time  T   b   The average dc output voltage  Vout, Figure 8.12 a   dependence on  duty cycle  a alfa, Figure 8.12 b   transfer function is more complex and exhibits diﬀerent dynamics than the previously described PWM de- sign case. The same is also true for the output voltage ripple computations. Again, the recovered output, relative to the input waveform, will appear as shown in Figure 8.13.  318  ﬁ  Switching topologies  Input voltage  Vin   Nonconduction phase  V2  V2  Conduction phase  Output voltage  Vout   V1  0  T 4  T 2  3T 4  T  Time  A  V1  0  Figure 8.13 Output and input waveforms on a per-period basis.  However, there is another initial condition associated with this second- order circuit, namely, the inductor’s  L  core current along with the output capacitor’s initial voltage at each time interface. These initial boundary con- ditions are shown in Figure 8.14 and apply identically to each period once the steady-state dynamics have been reached.  I 1,2   L  Vout  R  Vin  C  +  V 1,2   Figure 8.14 Boundary initial conditions elements.  The initial current source in parallel with the inductor has two dc  states as does the initial voltage source in series with the output capacitor. The nomenclature is as follows:  319  -  Applied Maple for Engineers and Scientists  t < a T   Regime 1  0 £ Inductor current = I1 Capacitor voltage = V1  Regime 2  a T £ Inductor current = I2 Capacitor voltage = V2  t < T   Therefore, there are two circuits that are being solved and matched at  the time boundaries indicated earlier. Figures 8.15 a  and 8.15 b  show the two topologies within the two time regimes. From these circuits, one derives the appropriate equations for each regime.  I 1,2   L  Vin  C  +  V 1,2   Vout_1_time  R  Regime 1  Vout_2_time  I 2   L  R  Regime 2  C  V 2    a    b   Let’s begin by initiating the appropriate Maple libraries and compo-  nent values into a session:  Figure 8.15 Two models associated with the two switching regimes.  320  -  Switching topologies  w with inttrans : Freq := 40*10^3: R := 50: L := 10^ -2 : C := 10^ -3 : Vin := 24 s: alfa := .50: T := 1 Freq:  before,  Computing the time-domain forms over the two regimes per period as  w Vout_1_Time :=invlaplace  Vin+s*L*C*V1+L*I1     L*C*s^2+s*L R+1 ,s,t ; Vout_2_Time :=invlaplace  s*L*C*V2+L*I2    L*C*s^2+s*L R+1 ,s,t ;  Vout_1_Time := 24 -  - 10 t   I1 e  - 10 t   + 100 333 24 e 1 333 + V1 e  + V2 e + 100 333  V1 e  - 10 t  Vout_2_Time := -  - 10 t   cos 30  cid:214   - 10 t    - 10 t  e  8 111 sin 30  cid:214  ‘ 3  cid:214  sin 30  cid:214  ‘ 3  cid:214   - 10 t   ‘ 3  cid:214  ‘37 t  ‘ 3  cid:214  ‘37 t   ‘ 3  cid:214  sin 30  cid:214   ‘37 t  ‘ 3  cid:214   cos 30 1 V2 e 333 cos 30  cid:214   sin 30  cid:214   ‘ 3  cid:214   ‘37 t   cid:214   ‘ 3  cid:214   ‘37  ‘37 t   cid:214   ‘ 3  cid:214   ‘37  ‘37 t   cid:214   ‘ 3  cid:214   ‘37  sin 30  cid:214   ‘ 3  cid:214   ‘37 t   cid:214   ‘ 3  cid:214   ‘37   - 10 t   I2 e  ‘37 t   cid:214   ‘ 3  cid:214   ‘37  From these results, we compute a few boundary conditions:  VOUT _1_Time t = 0  = VOUT _1_Time_Zero = V1  Second-to-ﬁrst regime boundary check   VOUT_2_Time t  =  0  = VOUT_2_Time_Zero  = V2   First-to-second regime boundary check   321  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ - ‘ ‘ ‘ - ‘ ‘ ‘ ‘ ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  VOUT_1_Time t = a T   = VOUT_1_Time_AlfaT VOUT_2_Time t = T -  a T   = VOUT_2_Time_AlfaT  Continuing,  w Vout_1_Time_Zero := evalf subs t=0,Vout_1_Time  ; Vout_2_Time_Zero := evalf subs t=0,Vout_2_Time  ;  VOUT_1_Time_Zero := 1. V1 VOUT_2_Time_Zero := 1. V2  They check out; now continuing to generate the two basis equations,  w Vout_1_Time_AlfaT := evalf subs t = alfa*T,Vout_1_Time  ;  Vout_2_Time_TminusAlfaT := evalf subs t = T-alfa*T, Vout_2_Time  ;  VOUT_1_Time_AlfaT  := .00018748 + .01249840508 I1  VOUT_2_Time_TminusAlfaT  := .9997422200 V2 +  + .9997422200 V1  .01249840508 I2  Maple nearly has all the basis equations, but we still need two more  conditions to solve uniquely. Note in Figures 8.15 a  and 8.15 b  that for any boundary  again, assuming steady state  that the following statements must hold:  I1 = V1 R I2 = V2 R  this is true because the boundary exhibits zero time duration, hence all in- ductors and capacitors have inﬁnite and zero impedance, respectively.  Now Maple has a suﬃcient number of equations to solve for unique so-  lutions at the boundaries.  w Solutions := solve {Vout_2_Time_TminusAlfaT=V1,  Vout_1_Time_AlfaT=V2,I1=V1 R,I2=V2 R},{V1,V2,I1,I2} ;  322   Switching topologies  Solutions := {V2 = 11.99971838 , V1 = 11.99962464 ,  I2 = .2399943676 , I1 = .2399924928 }  Reassigning the variables explicitly since Maple’s output is in a set  form,  w XX :=subs Solutions,[V1,V2,I1,I2] ;  XX := [11.99962464 , 11.99971838 , .2399924928 , .2399943676 ]  then associating and abstracting the numerical solutions to the variables of interest,  w V1 := XX[1]; V2 := XX[2]; I1 := XX[3]; I2 := X[4];  V1 := 11.99962464 V2 := 11.99971838 I1 := .2399924928 I2 := .2399943676  Note that the values are pretty close to each other since we are ﬁltering at  fCUTOFF  =  1 ‘ LC  2p  =  1  2p   10 mH  1000 uF   = 50Hz  which is 2.90 orders below the switching frequency  40 kHz  with a sec- ond-order LPF. This will account for approximately a 640,000:1 attenu- ation of the 24V dc square-wave input. A quick reality check indicates that the V1,V2 diﬀerential of peak-to-peak ripple is about 94 m V. Dividing the 24V dc drive  or 24V peak to peak  by 640,000 yields an expected peak to peak value of 37.5 m V. The ratiometric diﬀerence between the Maple computation and the theoretical estimate is due to the eﬀective Q gain associated with the series resonant circuit. This would indicate a Q of around 2.5.  323   cid:214  ‘ ‘  cid:214  ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘ ‘  Applied Maple for Engineers and Scientists  Now we can state the ﬁnal time-domain expression for the two time re-  gimes on a per-period basis:  w Vout_1_Time_Final := evalf subs V1=V1,Vout_1_Time  ;  Vout_2_Time_Duration := evalf subs V2=V2,Vout_2_Time  : Vout_2_Time_Final := evalf subs t=t-alfa*T,Vout_2_Time_  Duration  ;  Vout_1_Time_Final  := 24.   - 10. t    - 10. t  .3796750740 e cos 316.0696125 t   12.00037536 e  sin 316.0696125 t   Vout_2_Time_Final := .3796542881  - 10. t +.0001250000000   e + 11.99971838  - 10. t +.0001250000000   e  sin 316.0696125 t -  .003950870156    cos 316.0696125 t -  .003950870156    Now to create plots of both regimes  i.e., output for 0 £  t < T  with the corresponding average dc value, we enter the following to display pertinent output voltage information of the converter under the given constraints:  w Output_Average := 1 T* int Vout_1_Time_Final,t=0..alfa*T +  int Vout_2_Time_Final,t=alfa*T..T  ;  Output_Peak_to_Peak_Ripple := abs V1-V2 ;  Output_Average :=  11.99967152 Output_Peak_to_Peak_Ripple  :=  .00009374  and to generate the compound plot  Figure 8.16 :  w with plots :  Plot_1 := plot Vout_1_Time_Final,t=0..alfa*T,color = black,  style=point,symbol=cross :  Plot_2 := plot Vout_2_Time_Final,t=alfa*T..T,color = black,  style=point,symbol=circle :  Plot_3 := plot Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed,labels=  [Time_seconds,Voltage] ;  324  - -  Switching topologies  11.99986  Voltage  11.99984  11.99982  11.9998  11.99978  5e-06  1e-05  1.5e-05  2e-05  2.5e-05  Time_seconds  Figure 8.16 Buck converter output waveform  R = 50 ohms, L = 10 mH, C = 1000 µF, Vin = 24V, duty cycle = 50% .  Now let’s try some diﬀerent component values and another duty cycle:  w with plots :  with inttrans : Freq := 40*10^3: R := 50: L := 10^ -3 : C := 10^ -5 : Vin := 24 s: alfa := .25: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*L*C*V1+L*I1     L*C*s^2+s*L R+1 ,s,t :  Vout_2_Time := invlaplace  s*L*C*V2+L*I2     L*C*s^2+s*L R+1 ,s,t :  Vout_1_Time_Zero := evalf subs t=0,Vout_1_Time  : Vout_2_Time_Zero := evalf subs t=0,Vout_2_Time  :  325   Applied Maple for Engineers and Scientists  Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT :=evalf subs t=T-alfa*T,  Vout_2_Time  :  Solutions := solve {Vout_2_Time_TminusAlfaT=V1,  Vout_1_Time_AlfaT=V2,I1=V1 R,I2=V2 R},{V1,V2,I1,I2} :  XX := subs Solutions,[V1,V2,I1,I2] : V1 := XX[1]: V2 := XX[2]: I1 := XX[3]: I2 := XX[4]: Vout_1_Time_Final := evalf subs V1=V1,Vout_1_Time  : Vout_2_Time_Duration := evalf subs V2=V2,Vout_2_Time  : Vout_2_Time_Final := evalf subs t=t-alfa*T,Vout_2_Time_  Duration  :  Output_Average := 1 T* int Vout_1_Time_Final,t=0..alfa*T +  int Vout_2_Time_Final,t=alfa*T..T  ;  Output_Peak_to_Peak_Ripple :=abs V1-V2 ; Plot_1 := plot Vout_1_Time_Final,t=0..alfa*T,color=black,  style=point,symbol=cross :  Plot_2 := plot Vout_2_Time_Final,t=alfa*T..T,color=black,  style=point,symbol=cir cle :  Plot_3 := plot Output_Average,t=0..T,color=black : display {Plot_1,Plot_2,Plot_3},axes=boxed,labels =  [Time_seconds,Voltage] ;  Output_Average :=  2.410331814 Output_Peak_to_Peak_Ripple := .042026107  Figure 8.17 exhibits a much larger peak-to-peak ripple than pre-  viously. This is the result of a much smaller amount of ﬁltering  note the reduction in capacitance and inductance . Also note that the dc or average recovered voltage is not linearly related to the duty cycle as was the PWM case. If this system were linear, we would have expected to see an average dc value of 6.0V  25% of 24V  instead of the computed 2.41V.  To see the dependence of the average output dc voltage on duty cycle, we need to set up the equation relating these two items and then plot them; thus:  326   Switching topologies  Voltage  2.42  2.41  2.4  2.39  0  5e-06  1e-05  1.5e-05  2e-05  2.5e-05  Time_seconds  Figure 8.17 Buck converter output waveform  R = 50 ohms, L = 1 mH, C = 10 µF, Vin = 24V, duty cycle = 25%, frequency = 40 kHz .  w with plots :  with inttrans : Freq := 40*10^3: R := 50: L := 10^ -3 : C := 10^ -5 : Vin := 24 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*L*C*V1+L*I1     L*C*s^2+s*L R+1 ,s,t :  Vout_2_Time := invlaplace  s*L*C*V2+L*I2     L*C*s^2+s*L R+1 ,s,t :  Vout_1_Time_Zero := evalf subs t=0,Vout_1_Time  : Vout_2_Time_Zero := evalf subs t=0,Vout_2_Time  : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  327   Applied Maple for Engineers and Scientists  Vout_2_Time  :  Solutions := solve {Vout_2_Time_TminusAlfaT=V1,  Vout_1_Time_AlfaT=V2,I1=V1 R,I2=V2 R},{V1,V2,I1,I2} :  XX := subs Solutions,[V1,V2,I1,I2] : V1 := XX[1]: V2 := XX[2]: I1 := XX[3]: I2 := XX[4]: Vout_1_Time_Final := evalf subs V1=V1,Vout_1_Time  : Vout_2_Time_Duration := evalf subs V2=V2,Vout_2_Time  : Vout_2_Time_Final := evalf subs t=t-alfa*T,Vout_2_Time_  Duration  :  Output_Average := 1 T* int Vout_1_Time_Final,t=0..alfa*T +  int Vout_2_Time_Final,t=alfa*T..T  :  plot Output_Average,alfa=0..1,color=black,axes=boxed,  labels=[Duty_Cycle,Voltage] ;  Clearly, Figure 8.18 does not represent a linear relationship between  duty cycle and dc output voltage. Consequently, this type of ﬁltering would not be an advisable approach to signal processing  i.e., decoding phase information , especially if linearity were important. However, for power supply regulation it is desirable, because the eﬃciency of these switching converters can be as high as 95%  depending on the power levels involved . Further, considering the compressing of the encoded informa- tion  the dc value , one would want to operate the buck converter some- where around the middle of the duty cycle curve. Otherwise, larger loop gains will be necessary to hold output voltage levels at values far removed from the 12V center  duty cycle = 50% at Vin = 24V  under varying pa- rameter and environmental conditions. This could lead to instability and probable loss of the controlled output voltage variance speciﬁcation.  To show Figure 8.18’s S-shaped dependence on the value of induc-  tance, let’s produce a 3-D plot of average output voltage versus duty cycle and inductance value:  328   Switching topologies  Voltage  20  15  10  5  0  0  0.2  0.4  0.6  0.8  1  Duty_cycle  Figure 8.18 Output voltage versus duty cycle of buck converter  R = 50 ohms, L = 1 mH, C = 10 µF, Vin = 24V, frequency = 40 kHz .  w with plots :  with inttrans : Freq := 40*10^3: R := 50: C := 10^ -5 : Vin := 24 s: T := 1 Freq: Vout_1_Time := invlaplace  Vin+s*L*C*V1+L*I1     L*C*s^2+s*L R+1 ,s,t :  Vout_2_Time := invlaplace  s*L*C*V2+L*I2     L*C*s^2+s*L R+1 ,s,t :  Vout_1_Time_Zero := evalf subs t=0,Vout_1_Time  : Vout_2_Time_Zero := evalf subs t=0,Vout_2_Time  : Vout_1_Time_AlfaT := evalf subs t=alfa*T,Vout_1_Time  : Vout_2_Time_TminusAlfaT := evalf subs t=T-alfa*T,  329   Applied Maple for Engineers and Scientists  Vout_2_Time  :  Solutions := solve {Vout_2_Time_TminusAlfaT=V1,  Vout_1_Time_AlfaT=V2,I1=V1 R,I2=V2  R},{V1,V2,I1,I2} :  XX := subs Solutions,[V1,V2,I1,I2] : V1 := XX[1]: V2 := XX[2]: I1 := XX[3]: I2 := XX[4]: Vout_1_Time_Final := evalf subs V1=V1,Vout_1_Time  : Vout_2_Time_Duration := evalf subs V2=V2,Vout_2_Time  : Vout_2_Time_Final := evalf subs t=t-alfa*T,Vout_2_Time_  Duration  :  Output_Average := 1 T* int Vout_1_Time_Final,t=0..alfa*T +  int Vout_2_Time_Final,t=alfa*T..T  :  Now plotting the three variable relationship,  w plot 3d Output_Average,alfa=0..1,L=10^ -9 ..10^ -5 ,  grid=[50,50], color=black,axes=boxed, style=hidden,orientation= [-45,60],labels=[Duty_Cycle, Inductance,Volts] ;  Figure 8.19 shows that as the inductance value  scale on the right-hand  side baseline  decreases, the output voltage transfer becomes linear with the duty cycle  dc . The peaking taking place during the lower inductance values reﬂects the fact that some resonant behavior is getting through to the output along with a dramatic increase in switching ripple  look closely at the jagged nature of the straight line at low inductance on the left-hand wall of the 3-D plot . Clearly, the inductor aﬀords us a great deal of ﬁltering, but does so at the cost of linearity to the output voltage’s dependence upon duty cycle.  Fourier method  Now that we have seen the exact solution at steady state on a per-period ba- sis, let’s look at another method for determining the output voltage charac- teristics. However, this method approximates the input PWM signal with its approximate Fourier series. Also, this method does not use any time sliding to implement two separate time-domain solutions to reconstruct the complete periodic solution; instead, this approach works on the premise of a running time average.  330   Switching topologies  60  40  20  0  - 20  Volts  0  0.2  0.4  Duty_cycle  0.6  1e-05  8e-06  4e-06  6e-06  Inductance  0.8  2e-06  1  0  Figure 8.19 Dependence of converter linearity on Inductance  C = 10 µF, Vin = 24V, R = 50 ohms, frequency = 40 kHz .  Before we start generating Maple code, let’s review the Fourier series that will approximate the PWM equivalent input as shown in Figure 8.1. Simply stated, the Fourier series can approximate any periodic function with a ﬁnite number of discontinuities that converge from both the left- and right-hand side of any given discontinuity. Further, the Fourier series ap- proximation quality depends on how many expansion terms one wants to handle during the analysis. Consequently, creating a PWM waveform  a general square wave  is generally considered reasonably approximated with the ﬁrst 10 harmonics. More harmonics are better, but this can be- come computationally prohibitive, as we shall see during our forthcoming revisit of the buck-type switching power supply.  The Fourier series is deﬁned by the following set of constituent  relations:  331   Applied Maple for Engineers and Scientists  f t  = a0  Ł an cos nw  0t  + bn sin nw  0t  cid:246   +  cid:229  n = 1  where the Fourier coeﬃcients are  Revisiting Figure 8.1 again, by inspection, we can state the limits of  integration:  a0  = 1 T  a0  = 2 T  bn  = 2 T  a0  = 1 T  a0  = 2 T  bn  = 2 T  T⁄2  - T⁄2 T⁄2  - T⁄2 T⁄2  - T⁄2  a T  0 a T  0 a T  0  f t dt  f t  cos nw  0t dt  f t  sin nw  0t dt  f t dt  f t  cos nw  0t dt  f t  sin nw  0t dt  where  f t  =  cid:236   A 0  for for  0 £ ± < a T a T £ ± < T  332  ¥  cid:230  ł  cid:242   cid:242   cid:242   cid:242   cid:242   cid:242   cid:237   cid:238   Switching topologies  and where  A ﬁ T ﬁ  Peak amplitude of input square wave Switching period Duty cycle  0 = 2p f0  Switching frequency  Substituting this dc voltage value, f  t , into the Fourier relations yields  the following Fourier coeﬃcients:  a0  an  bn  = Aa = 2A T  = 2A T  sin nw nw  Ł 1 -  a T   0  0 cos nw nw  0  a T   cid:246  0  Resubstituting this into the overall Fourier series form gives us  f t  = Aa +  2A 0T  n = 1  sin n0  a T   cos nw  0t  +  1 - cos nw  a T    sin nw  0  0t   Since we know that w 0 = 2p f = 2p  ⁄T, then the series can be restated as 2p nt T  +  1 - cos 2p na    sin  2p nt T  sin 2p na   cos  f t  = Aa + A  n = 1  This is the input voltage function form we will use in our Maple ses- sion to compute the output voltage waveform after passing through a sec- ond-order low-pass passive RLC circuit. Put graphically, Figure 8.20 shows the process we will now analyze.  n  n  333  a ﬁ w ﬁ  cid:230  ł w  cid:229  ¥  cid:230   cid:231  Ł  cid:246   cid:247  ł p  cid:229  ¥  cid:230   cid:231  Ł  cid:231   cid:231   cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:230   cid:231  Ł  cid:246   cid:247  ł  cid:246   cid:247  ł  cid:247   cid:247   Applied Maple for Engineers and Scientists  Vdc  Duty cycle  A  Fourier series approximation  T  Switching frequency  Figure 8.20 Overall Fourier analysis process.  Approximated PWM input voltage function  Second-order LPF  Output voltage waveform  Starting the Maple session with the appropriate libraries,  w with inttrans :  with  plots :  we continue by entering the circuit components and input switching wave- form shown in Figures 8.12 a  and 8.12 b , respectively:  w Switching_Freq := 40*10^3:  Vin := 24: L := 10^ -2 : C := 10^ -3 : R := 50: alfa := .50: T := 1 Switching_Freq:  Computing the Fourier coeﬃcients,  w Ao := 1 T*int Vin,t=0..alfa*T ;  An := 2 T*int Vin*cos 2*n*Pi*t T ,t=0..alfa*T ; Bn := 2 T*int Vin*sin 2*n*Pi*t T ,t=0..alfa*T ;  Ao := 12.00000000 An := 7.639437266  Bn := - 7.639437266  sin 3.141592654 n   cos 3.141592654 n   n  n  + 24  1 n p  334  a  Switching topologies  The Ao term represents the dc component of the Fourier series and  simply evaluates from the integral to the following:  Ao = Vin  ×  alfa  = 24V  × 50%  = 12V  Now substituting the coeﬃcients into the approximating series,  w Vin_Fourier : =  Ao+sum An*cos 2*n*Pi*t T +Bn*sin 2*n*Pi*t T , n = 1..10 ;  Vin_Fourier := 12.00000000 -  - 8 cos 251327.4123 t   .3133748821 10 + 15.27887453 sin 251327.4123 t  + .3133748821 10  - 8 cos 502654.8246 t  - 8 cos 753982.2370 t   .3133748822 10  + 5.092958178 sin 753982.2370 t  + .1077318609 10  .3133748821 10 + 3.055774906 sin cid:230   .1959209356 10  .5316445184 10 + 2.182696362 sin cid:230  + .1223889504 10  .6529054273 10 + 1.697652726 sin cid:230  + .3133748821 10  Ł .1507964474 107 t cid:246  Ł .1759291886 107 t cid:246   Ł .1005309649 107 t cid:246  Ł .1256637062 107 t cid:246   - 7 cos cid:230  - 8cos cid:230  Ł .1256637062 107 t cid:246  - 8 cos cid:230  - 8 cos cid:230  Ł .1759291886 107 t cid:246  - 8 cos cid:230  - 8 cos cid:230  Ł .2261946711 107 t cid:246  - 8 cos cid:230   Ł .2010619299 107 t cid:246  Ł .2261946711 107 t cid:246   Ł .2513274123 107 t cid:246   If we plot this Fourier approximation, we can compare the series ap-  proximation  at least subjectively  against the exact input waveform shown  335  - ł - ł ł - ł - ł ł ł - ł ł ł  Applied Maple for Engineers and Scientists  in Figure 8.12 b . The following Maple structure will generate two com- plete switching waveform periods:  w Fourier_Plot :=plot Vin_Fourier,t=0..2*T,color=black :  piece_1 :=piecewise t=0,Vin,0 : piece_2 :=piecewise t=alfa*T,-Vin,0 : piece_3 :=piecewise t=T,Vin,0 : piece_4 :=piecewise t=T* 1+alfa ,-Vin,0 : Exact_Plot :=plot piece_1+piece_2+piece_3+piece_4,  display {Fourier_Plot,Exact_Plot},axes=boxed,labels=  t=0..2*T,color=black :  [Time_seconds,Voltage] ;  Figure 8.21 indicates that the ﬁrst 10 harmonics  plus dc term  seem to give a fairly reasonable approximation to the 50% duty cycle modulated in- put waveform.  If we were to sacriﬁce some computer resources and wait a bit  this computation can get really long and cause dangerously low system re- sources, so save your work before you execute the Maple command , we can increase the approximation to the ﬁrst 30 harmonics:  w Vin_Fourier_30 :=Ao+sum An*cos 2*n*Pi*t T +Bn*  sin 2*n*Pi*t T ,n=1..30 :  Fo urier_Plot_30 :=plot Vin_Fourier_30,t=0..2*T,color=black : display {Fourier_Plot_30,Exact_Plot},axes=boxed,  labels=[Time_seconds,Voltage] ;  Clearly, the more harmonics we incorporate into the input PWM  synthesis, the better the approximation  Figure 8.22 . The limit here, of course, is that of time and system resources for the extra harmonic terms as- sociated with the Fourier series expansion. It is for this reason that we will use the approximation depicted in Figure 8.21, which only uses the ﬁrst 10 harmonics.  Later, we take the Laplace transform of each of these harmonics. One can readily see that this computational approach can get extremely inten- sive, especially if the use of a large number of harmonics is required for a more accurate result.  336   Switching topologies  Voltage  25  20  15  10  5  0  0  1e-05  2e-05  3e-05  4e-05  5e-05  Time_seconds  Figure 8.21 Comparison of Fourier approximation to exact input waveform  10 harmonics plus dc with a 50% duty cycle .  Now continuing by taking the Laplace transform of the Fourier ap- proximated input voltage  Figure 8.20, Vin_Fourier  and stating the second-order LCR ﬁlter’s  Figure 8.12 a   transform,  w Vin_Laplace :=laplace Vin_Fourier,t,s :  LPF_Transfer :=1  L*C*s^2+L R*s+1 : Output_Voltage_Laplace :=LPF_Transfer*Vin_Laplace: Output_Voltage_Time :=invlaplace Output_Voltage_Laplace,  s,t :  and then plotting the output as a function of time over the ﬁrst 10,000 switching periods. The result we obtain is as follows  the superimposed diamond plot of Figure 8.23 represents the ﬁnal average dc output value :  337   Applied Maple for Engineers and Scientists  Voltage  25  20  15  10  5  0  338  1e-05  2e-05  3e-05  4e-05  5e-05  Time_seconds  Figure 8.22 Comparison of the Fourier approximation with the exact input waveform  30 harmonics plus dc .  w Output_Plot := plot Output_Voltage_Time,t=0..10000*T,  color=black :  Output_DC_Plot := plot Ao,t=0..10000*T,color=black,  style=point,symbol=diamond :  display {Output_Plot, Output_DC_Plot},axes=boxed,  labels=[Time_seconds,Voltage] ;  Figure 8.23 shows a typical underdamped second-order eﬀect to a  12V step input. As stated earlier, the 12V average is the dc term associated with the Fourier series approximation.   Switching topologies  Voltage  20  15  10  5  0  0  0.5  0.1  0.15  0.2  0.25  Time_seconds  Figure 8.23 Output voltage derived from Fourier series analysis  Vin = 24V, L = 10 mH, C = 1000 µF, R = 50 ohms, duty cycle = 50%, frequency = 40 kHz .  In the exact method, we derived the boundary voltages to solve the out-  put waveform for any period. This method also gave us the peak-to- peak ripple by simply subtracting the two boundary voltages. The output ripple value can be determined from the Fourier method, but only after we per- form an RMS  Root-Mean-Square  derivation of the approximated out- put function  Output_Voltage_Time .  We start by going well out in time, where the output has settled down, and integrating over one period. In this case, the choice of translating out to 100,000 switching periods was used, which, at 40 kHz, equates to about 2.5 sec after startup. Further increases in this period measure decreased the ripple computation but did not change the ripple value appreciably.  339   Applied Maple for Engineers and Scientists  w Output_RMS_Ripple := evalf sqrt 1 T* int  Output_  Voltage_Time-Ao ^2,t=100000*T..100001*T    ;  Output_PP_Ripple := evalf 2*Output_RMS_Ripple*sqrt 2  ;  Output_RMS_Ripple := .00001711662531 Output_PP_Ripple := .00004841312730  Consequently, the peak-to-peak ripple with the Fourier method was about half the value computed using the exact method  peak-to-peak ripple = 94 m V . The reason for the lower ripple value in the Fourier method is due to the fact that we only used the ﬁrst 10 harmonics, whereas in the ex- act method, all harmonics were present, hence leading to a higher residual ripple value.  At this point, we can play around with some component values and  watch the eﬀects at the output. For instance, let’s change the duty cycle, in- ductor, and capacitance values to the following:  alfa ﬁ C ﬁ L ﬁ  .25 10 m F l mH  Starting the Maple session:  w with inttrans :  with  plots :  The component values are entered:  w Switching_Freq := 40*10^3:  Vin := 24: L := 10^ -3 : C := 10^ -5 : R := 50: alfa := .25: T := 1 Switching_Freq:  The Fourier coeﬃcients are computed:  340   Switching topologies  w Ao := 1 T*int Vin,t=0..alfa*T :  An := 2 T*int Vin*cos 2*n*Pi*t T ,t=0..alfa*T : Bn := 2 T*int Vin*sin 2*n*Pi*t T ,t=0..alfa*T :  The Fourier approximation using the ﬁrst 10 harmonics is computed:  w Vin_Fourier := Ao+sum An*cos 2*n*Pi*t T +Bn*  sin 2*n*Pi*t T ,n=1..10 :  Compare the Fourier approximation with the exact PWM input wave-  form  Figure 8.24 :  w Fourier_Plot := plot Vin_Fourier,t=0..2*T,color=black :  piece_1 := piecewise t=0,Vin,0 : piece_2 := piecewise t=alfa*T,-Vin,0 : piece_3 := piecewise t=T,Vin,0 : piece_4 := piecewise t=T* 1+alfa ,-Vin,0 : Exact_Plot :=plot piece_1+piece_2+piece_3+piece_4,  display {Fourier_Plot,Exact_Plot},axes=boxed,labels=  t=0..2*T,color=black :  [Time_seconds,Voltage] ;  The the appropriate Laplace transforms are taken and the time-domain  output is computed:  w Vin_Laplace := laplace Vin_Fourier,t,s :  LPF_Transfer := 1  L*C*s^2+L R*s+1 : Output_Voltage_Laplace := LPF_Transfer*Vin_Laplace: Output_Voltage_Time : = invlaplace  Output_Voltage_Laplace,  s,t :  We then plot  Figure 8.25  the output’s time-domain response  line   along with the average value  diamond :  w Output_Plot :=plot Output_Voltage_Time,t=0..100*T,  color=black :  Output_DC_Plot :=plot Ao,t=0..100*T,color=black,  style=point,symbol=diamond :  display {Output_Plot, Output_DC_Plot},axes=boxed,  labels=[Time_seconds,Voltage] ;  341   Applied Maple for Engineers and Scientists  Voltage  25  20  15  10  5  0  342  1e-05  2e-05  3e-05  4e-05  5e-05  Time_seconds  Figure 8.24 Comparison of Fourier approximation to exact input waveform  10 harmonics plus dc with a 25% duty cycle .  We now compute the output ripple’s RMS and peak-to-peak value:  w Output_RMS_Ripple := evalf sqrt 1 T* int    Output_Voltage_Time-Ao ^2,t=10000*T..10001*T    ;  Output_PP_Ripple := evalf 2*Output_RMS_Ripple*sqrt 2  ;  Output_RMS_Ripple := .01230936550 Output_PP_Ripple := .03481614326  The peak-to-peak ripple is comparable to the exact method computa- tion  peak to peak = 42 mV , though, as before, it is lower with the Fourier method due to the presence of only the ﬁrst 10 harmonics. However, what is interesting here is that the average value appears to be about   Switching topologies  Voltage  10  8  6  4  2  0  0  0.0005  0.001  0.0015  0.002  0.0025  Time_seconds  Figure 8.25 Output voltage derived from Fourier series analysis  Vin = 24V, L = 1 mH, C = 10 µF, R = 50 ohms, duty cycle = 25%, frequency = 40 kHz .  6.0V  25% of 24V , whereas the exact method gave us around 2.41V. Why is this? From Figure 8.18 we saw that some sort of output voltage compres- sion was taking place, and Figure 8.19 indicated the compression was de- pendent on the existence of the inductor. Consequently, the phenomenon is not strictly a function of the duty cycle, but the interactive presence be- tween the inductor and output capacitor  a second-order eﬀect . There- fore, is the Fourier method somewhat incorrect? No, but understand that the approximation eliminates an inﬁnite number of harmonics that are re- ally present in the input to the second-order ﬁlter. Remember, the lower signiﬁcant harmonic contents of a PWM waveform are maximal at a 50% duty cycle and, by symmetrical reasoning, minimal at duty cycles above and below the 50% point. Consequently, this approximation will contrib- ute further to the output’s compressed transfer and, in this case, to the non- linear output voltage versus duty cycle transfer function.  343   Applied Maple for Engineers and Scientists  References  [1] Pressman, A. I., Switching and Linear Power Supply, Power Converter  Design, Hayden Book Co., 1977.  [2] Chryssis, George, High-Frequency Switching Power Supplies, New  York: McGraw-Hill, 1984.  [3] Close, Charles M.,The Analysis of Linear Circuits, New York:  Harcourt, Brace & World, 1966.  [4] Chua, Leon O., Introduction to Nonlinear Network Theory, New York:  McGraw-Hill, 1969.  344   Applied Maple for Engineers and Scientists  Appendix A  where A t  contains one or more time-dependent elements. Then looking at a reduced scalar formulation  i.e., dealing with only one state variable ,  Deﬁne the state equation  . = A t x x  . = a t x x  A solution to this scalar form is  x t  = eb t   x t   345   Applied Maple for Engineers and Scientists  is deﬁned as the initial time condition. Letting t = 0 will not invali-  where t date this analysis, therefore we rewrite the scalar solution form as  and  where  x t  = eb t   x 0   b t  =  cid:242   t  a l  dl  t = 0  x t  =  A l  dl  º e cid:242   t  0  ß x 0   eB t  = dB t  dt  d dt  eB t   B t  =  cid:242   A l  dl  t  0  Substituting this result into the vector matrix form, we obtain:  However, if we substitute this expression into x  this expression holds true if and only if  . = A t x, we see that  Unfortunately, these last two mathematical statements are rarely true except when the A matrix is either a constant or diagonal matrix. In fact, it can be shown that the A matrix must have the following commutative prop- erty [1] if we are to use the conventional scalar approach for the state vari- able solutions:  A t1   A t2    = A t2   A t1     Needless to say, when dealing with matrices, this equation can only be  true for a constant coeﬃcient or for diagonal matrices.  346  Ø Œ ø œ  Appendix A  Hence, if we desire to solve this type of state variable system, then let’s perform a diagonalization of the A matrix using what is known as a similar- ity transformation. The similarity transformation requires the user to ob- tain the eigenvectors and redeﬁne the states as follows:  x = Pq  . . = Pq x  Then assuming a constant coeﬃcient transformation matrix, P,  substituting this expression into the state space formulation, . = A Pq  + Bu Pq  . = Ax + Bu x  Transforms  and premultiplying both sides by P-1 yields - 1APq + P  . = P q  - 1Bu  The matrix expression P-1AP is exactly of the form  Hence,  - 1AM ﬁ D M  P = M  where M is deﬁned as the modal matrix and is composed of the A’s eigen- vectors. The D matrix product is special and is denoted as the spectral or canonic matrix associated with the A matrix. By way of deﬁnition, the ma- trix A is said to be similar to a matrix D if there exists a nonsingular matrix M such that M  - 1AM ﬁ D holds true.  347   Applied Maple for Engineers and Scientists  The D matrix has the property  D =  0 0  3  1 0 0  0  0  2 0  0  0  0 0  0  N  where it only has diagonal elements, which are the A matrix’s distinct eigen- values  nonrepeated characteristics roots . Consequently, substituting this expression into our transformed state space formulation yields  Then let’s redeﬁne this state equation in more familiar terms of A and B:  - 1AM and BN = M  - 1B. At this point, the user has to re- where AN = M member what the new state variables, q, represent in terms of the original state variables, x, i.e.,  Hence, on obtaining the solution set in q, one resubstitutes and pre-  multiplies by the modal matrix results in the solutions for the original states.  Also, the output matrix formulation was given as  . = Dq + M q  - 1Bu  . = ANq + BNu  q  x = Pq = Mq  y = Cx + Du  Hence,  where CN = CM.  y = C Mq  + Du ﬁ  CNq + Du  348  Ø Œ º Œ Œ Œ Œ Œ Œ l  cid:215  l  cid:215  l  cid:215   cid:215   cid:215   cid:215   cid:215   cid:215   cid:215  l ø œ ß œ œ œ œ œ œ  Appendix A  The process of obtaining the transition matrix and continuing onto the ﬁnal complete solution to the states is identical to the process described in Chapter 5.  Reference  [1] Hirsch, M., and S. Smale, Diﬀerential Equations, Dynamical Systems,  and Linear Algebra, New York: Academic Press, 1974.  349   Applied Maple for Engineers and Scientists  Appendix B  351   Applied Maple for Engineers and Scientists  Data Structure Keyword*  User Plot Option  Description  STYLE POINT  LINE  PATCH  PATCHNOGRID  HIDDEN  CONTOUR  PATCHCONTOUR .  style= POINT  LINE  PATCH  PATCHNOGRID HIDDEN  CONTOUR  PATCHCONTOUR.  THICKNESS 0  n , where n is a positive integer.  thickness=0  n.  Sets the plot style of the nontext objects in the image. The options given in italics are for 3-D plots.  Controls the thickness of any line segments, other than the axes, resulting from a graphics primitives in the image. The higher the value of n the thicker the line. The special value 0 corresponds to the default thickness for the selected output device.  Sets the dash pattern to be used when drawing line segments in the image. The special value 0 selects the device default whereas the value 1 selects a solid line.  Specifies the color of the graphics object. The options in italics are applicable to the rendering of three-dimensional surfaces and apply color information according to a particular attribute of the plot in question.  LINESTYLE 0  n , where n is a positive integer.  linestyle=0  n.  COLOUR† RGB,r, g, b   COLOUR HUE, c   COLOUR HSV,c, s, h   COLOUR type , where the variables r, g, b, c, s and h are floating-point numbers in the range 0..1 and type can be XYZSHADING  XYSHADING  ZSHADING  ZHUE  ZGREYSCALE.  color=expr, where expr is either a color name‡  red, blue, green, etc. , a value  0 .. 1 , a procedure returning a valid color desciptor, or a valid color expression.  AXESSTYLE BOX  FRAME  NORMAL  NONE  DEFAULT .  axesstyle= BOX  FRAME  NORMAL  NONE.  Selects the axes style for the image.  * All of the valid arguments to each structure and option are listed with the default being emboldened. Where a single  argument must be selected from a list the elements of the list are seperated using , for example, op1  op2  op3 is shorthand for select op1 or op2 or op3.  † Due to Maple’s Canadian origins, many spellings are UK-English instead of American-English.  ‡ The color name must be known to Maple. For more help see ?color.  352   Data Structure Keyword*  User Plot Option  Description  xtickmarks=xvals and ytickmarks=yvals, or axisticks=[xvals, yvals, zvals] in the three-dimensional case.  AXESTICKS xvals, yvals, zvals , where xvals, yvals and zvals, in the three-dimensional case can be N,  [n1, n2, .., ni]  [eqn1, eqn2, .., eqni]  DEFAULT, where N is an integer, i are numbers and eqn i have n the form ni=labeli. The value label  i is a string.  SCALING DEFAULT  CONSTRAINED  UNCONSTRAINED .  scaling=CONSTRAINED  UNCONSTRAINED.  Appendix B  Allows the number, location and labeling of the tick marks on an axis to be specified. An integer value causes the axis ticks to be chosen such that there is at least the number requested, a list of numbers causes the ticks and labels to be those specified in the list and no more while a list of equations produces tick marks at the position specified by the left-hand side of the equation with the label specified by the right-hand side.  Scaling is used to determine whether the x and y axes scaling is the same: CONSTRAINED, independent: UNCONSTRAINED. Selecting DEFAULT normally is the same as selecting UNCONSTRAINED.  SYMBOL BOX  CROSS  CIRCLE  POINT  DIAMOND  DEFAULT .  symbol=BOXCROSSCIRCLE POINTDIAMOND.  Allows the point plot symbol accordingly.  TITLE Null string  title string .  title=title string.  Enables a title to be set for the plot.  AXESLABELS Null string  x-label string, Null string  y-label string .  axeslabels=Null string  x-label string, Null string  y-label string.  Enables axes labels to be set for the plot. specifications must be present.  If used both label  * All of the valid arguments to each structure and option are listed with the default being emboldened. Where a single  argument must be selected from a list the elements of the list are seperated using , for example, op1  op2  op3 is shorthand for select op1 or op2 or op3.  353   Applied Maple for Engineers and Scientists  Data Structure Keyword*  User Plot Option  Description  FONT family, typeface, size  where family can be TIMES  COURIER  HELVETICA, typeface can be ROMAN  DEFAULT  BOLD  ITALIC  BOLDITALIC  OBLIQUE  BOLDOBLIQUE and size is the point size.§  font=[ family, typeface, size], axesfont=[ family, typeface, size], labelfont=[ family, typeface, size], titlefont=[ family, typeface, size].  Allows the font, used in rendering TEXT objects, to be specified. The font specification of a text object is set either directly using FONT or via the plot options shown.II  VIEW x1..x2  DEFAULT, ..y y 2 1 and yi are numbers.   DEFAULT , where xi  view=[ x1..x2, y1..y2 ].  ..x 1  Allows regions of a plot to be viewed. The ranges x 2 and y1..y2 specify the subrange of the x-y plane that is to be displayed. The special value DEFAULT forces a view to be selected such that all of the elements in the plot object are displayed.  Allows either a rectangular or triangular grid to be used when a three-dimensional surface is rendered.  GRIDSTYLE TRIANGULAR  RECTANGULAR .  gridstyle=TRIANGULAR  RECTANGULAR.  ORIENTATION 45  q , 45  f  , where . q and q are angles of rotation and inclination respectively in degrees.  AMBIENTLIGHT r, g, b , where the entries r, g and b have numeric values between 0 and 1.  orientation=[theta,phi].  Set the view angle of a three-dimensional plot.  ambientlight=[r, g, b].  Sets the ambient light of a three-dimensional plot in terms of the intensity of the red, green, and blue components of the light.  * All of the valid arguments to each structure and option are listed with the default being emboldened. Where a single  argument must be selected from a list the elements of the list are seperated using , for example, op1  op2  op3 is shorthand for select op1 or op2 or op3.  § For more information see ?plot[options].  II It should be noted that not all combinations are possible.  354   Appendix B  Data Structure Keyword*  User Plot Option  Description  and f  LIGHT 45  q , 45  f , r, g, b , where q specify the direction to the light in polar coordinates  angles specified in degrees  and r, g and b have numeric values as in AMBIENTLIGHT defined above.  light=[q , f , r, g, b].  Allows the direction and intensity of a directed light shining on a three-dimensional surface to be specified.  LIGHTMODEL USER  LIGHT_1  LIGHT_2  LIGHT_3  LIGHT_4 .  lightmodel= USER  LIGHT_1  LIGHT_2  LIGHT_3  LIGHT_4.  Allows a lighting scheme, from those available, to be selected. If USER is specified the light definitions given in the LIGHT and AMBIENTLIGHT options are used.  * All of the valid arguments to each structure and option are listed with the default being emboldened. Where a single  argument must be selected from a list the elements of the list are seperated using , for example, op1  op2  op3 is shorthand for select op1 or op2 or op3.  355   Applied Maple for Engineers and Scientists  Glossary  Term  Description  The factorial of a expression.  Shorthand for the previously evaluated expression. The evaluation stack is three deep  i.e., “, ““, and “““ can be used .  a:=2: “ 2  The infix form of seq.  Syntax  expr! 5! = 120  expr$range a$4 a^n$n=1..4  !  “  $  357   Applied Maple for Engineers and Scientists  Description  Syntax  Part of the liesymm package, this infix operator computes the wedge product of its arguments.  expr1&^expr2  The arrow operator used in defining functions.  f:= args -body f:=x-x^2 f:= a,b -a*b  Infix operator used to assign a type definition to a procedure argument.  proc argn::typen  proc x::numeric   Return the help page for the specified topic or function.  Return the calling sequence for the specified function.  Return the examples section for the specified function.  ?topic ?topic[sub-topic] ?help ?plots[animate]  ??function ??package[function] ??sin ??plots[animate]  ???function ???package[function] ???sin ???plots[animate]  The repeated composition operator that applies the expression f to the expression g n times.   f@@n  g   sin@@2  x  a@@y  Used in state-space analysis, the elements of the A matrix are determined by the system’s dynamics.  Calculate the absolute value of an expression.  abs expr  abs -2  abs n   Create an alias to an expression.  alias aliasi=expri  alias sin=s  alias a_matrix=linalg[matrix]   Term  &^  -  ::  ?  ??  ???  @  A matrix  abs  alias  358   Term  aliasing  allvalues  analytic solution  animate  animate3d  args  array  Glossary  Description  Syntax  Aliasing is caused when a signal is sampled at a rate less than the Nyquist rate. This causes the higher frequency components of the signal to be folded down or aliased to lower frequences. This effect accounts for the wagon wheels “running” backwards in old films.  Evaluate all of the possible values of an expression containing RootOfs.  allvalues expr  allvalues expr, dependent   A solution that has been obtained by resorting to numerical methods.  Create a two-dimensional animation of the functions over the range r with the frame parameter t. This function is found in the plots package.  animate funci, r, t, opts  animate sin x+p , x=0..10, p=0..5   Create a three-dimensional animation of the functions over the ranges r1, r2 with the frame parameter t. This function is found in the plots package.  animate3d funci, r1, r2, t, opts  animate sin x*y+p , x=0..10, y=0..3, p=0..5   arbitrary precision arithmetic  The ability to perform floating point calculations with a selected number of digits.  A global variable containing the list of arguments passed to the current procedure.  A Maple array is defined by setting the row and column dimensions and the elements.  assigned  A Boolean test to determine whether a name has a value other than its name.  assigned name  assigned f   array dim  array dim, elems  array dim1, dim2  array dim1, dim2,, elems  array 0..2  array 0..1, 1..2  array 1..2, [1,2]  array 1..2, 1..2, [[a, b], [1, 2]]   359   Applied Maple for Engineers and Scientists  Term  attenuator  axis jw  B matrix  Bilinear transform  Description  Syntax  A device that reduces a signals amplitude by a preset ratio.  Also called the frequency axis, it is the vertical axis on the s-plane.  Used in state-space analysis, the elements of the B matrix represent the input gains of the system.  The bilinear transform is conformal mapping which translates the j axis of the s-plane onto the unit circle of the z-plane.  1 - 1 z T  s =  s = 2  1 - z T 1 + z   bit depth  The number of bits available to represent all of the intensity levels in an image.  Boolean valued expression  An expression that can only take true or false.  Used in state-space analysis the elements of the C matrix represent the output gains of the system.  State matrices in a form that are well suited to the design of state variable feedback controllers.  The system is decoupled, as A matrix is diagonal.  In the observable canonical form, the system coefficients appear in the first column of the A matrix.  canonical form  An expression is said to be in a canonical form when it is the most concise form.  CAS  Computer algerba system.  C matrix  controllable  Jordan  observable  360   Description  Syntax  The concatonation function.  cat expri  cat ‘a’, ‘ b’, ‘ 1’   characteristic equation  The characteristic equation in l of a matrix is  A-Il  =0.  Return the coefficient of the term in xn in the polynomial p.  coeff p,x  coeff p,x,n  coeff p,x^n  coeff x+x^2, x, 2  coeff x+x^2, x^2  coeff x+x^2, x   coeffs p, x   The wrapper for an image’s color information.  COLOUR format, data  COLOUR RGB,0,1,0   Return all of the coefficients of the polynomial in x.  A function that determines the coloring of an image.  Maple’s default color map for coloring a surface. Color is applied at a point on the surface as a function of that point’s x-y-z coordinates.  The application of unnatural colors to an image for the purpose of image enhancement.  The Maple keyword determing that the color information is in the hue-intensity-saturation format.  See color function.  A single layer of color information used in a composite color image.  Term  cat  coeff  coeffs  color function  color, COLOUR  color, default map  color, false  color, HVS  color, mapping functions  color, plane, 15  Glossary  361   Applied Maple for Engineers and Scientists  Description  Syntax  A set of pure colors from which all other colors can be made.  RGB CYM  The Maple keyword determing that the color information is in the red-green-blue format.  conditional statement  See if.  conformal mapping  A function that defines the mathematical relationship between two systems.  conjugate  Return the conjugat of a complex number.  A global variable containing the constants known to Maple.  Add the elements of a list or set.  Transform an expression into its continued fraction form.  Convert a trigonometric expression into one comprising exponentials.  conjugate expr  conjugate a+I*b  conjugate 3 4+I*0.56   convert expr, ‘+’  convert [a, b, c], ‘+’  convert {1, 2, 3}, ‘+’   convert expr, confrac, var  convert 1  s^2* s+1  , confrac, s  convert exp y , confrac, y   convert expr, exp  convert sin y +cos y , exp convert sin y +cos y , exp  convert tan t , exp   ‘convert\convert_tag’:= …  convert, helper functions  Conversion helper functions are implemented by the user to extend the convert function. Helper functions are either functions or procedures but all conform to the same naming convention: “convert\convert_tag.”  Term  color, primary  color, RGB  constants  convert, +  convert, confrac  convert, exp  362   Term  convert, parfrac  convert, polynom  convert, rational  convert, trig  convert  CURVES  D matrix  D  dc gain  DC  defform  degree  Description  Syntax  Decompose a rational function f in the variable var into partial fractions.  Convert a series data structure into a polynomial by removing the order term.  Convert a floating-point number to an approximate rational number.  Glossary  convert expr, parfrac, var  convert 1  s^2* s+1  , parfrac, s  convert exp y   y+1 , parfrac, y   convert expr, polynom  convert series exp x , x , polynom   convert num, rational, opts  convert 3.142, rational  convert 3.142, rational, 5   Convert all exponentials in expr to trigonometric and hyperbolic trigonometric functions.  convert expr, trig  convert exp I*t +I*exp t   The mechanism by which Maple objects and data structures can be converted to different formats.  A wrapper inside a plot structure containing data points that are to be plotted as a curve.  CURVE data  CURVE [[0, 0], [10, 100]]   Used in state-space analysis, the D matrix is the disturbance matrix.  The Maple differential operator.  The gain of a system at zero hertz.  A signal with a frequency of zero hertz.  Define the basic variables used in a computation or define the exterior derivative of an expression using the equations eqni.  Return the degree  highest power of the free variable  of a polynomial.  degree  poly, var  degree x^7-y^5*x-1=0, x   defform eqni  defform a=const,b=scalar   363   Applied Maple for Engineers and Scientists  Description  Syntax  Return the denominator of a quotient.  denom expr  denom  1+s   1-s   See ODE, odeplot.  Approximate the derivative of a function at a point  x, y  using the horizontal and vertical differences between it and a previous point; dy dx  inc in y inc in x  A representation of a solution of a differential equation.  The Maple package containing the differeintial equation manipulation utilities.  Found in the Detools package, this plots the direction field of one- or two- dimensional systems of differential equations over the range t. This function uses numerical techniques.  dfieldplot eqni, vari, t, opts dfieldplot y^2*sin x ,[x,y],-5..5  ;   Return the derivative, with respect to the variable var, of an expression.  diff expr, var  diff sin x , x   difference equation  See recurrence relation.  differential operator  See D.  difforms  digital control  The Maple package containing differential equation manipulation utilities.  The method of manipulating the behavior of dynamical systems using digital techniques.  digital signal processing  The method of manipulating continuous and discrete signals using digital techniques.  Term  denom  DEplot  derivative, finite difference  DESol  DEtools  dfieldplot  diff  364  »  discrete transfer function  The expression linking the input and output of a discrete system.  Term  discont  display  ditto  dverk78  dsolve, gear  dsolve, lsode  dsolve, mgear  dsolve, numeric  dsolve, Runga-Kutta  dsolve, taylorseries  Glossary  Description  Syntax  The optional argument to plot allowing any discontinuities encountered to be displayed.  plot func, range, discont=true, opts  plot tan x , x=-10..10, discont=true   Found in the plots package display is used to rerender plot structures.  display plot, opts  display {ploti}, opts  display pp  display {plot sin , plot cos }   See “.  A setting for dsolve’s optional argument method which sets the method to be used to be the gear method.  dsolve {diff y t ,t =y t , y 0 =3}, y t , method=dverk78   A setting for dsolve’s optional argument method, which sets the method to be used to be the gear method.  dsolve {diff y t ,t =y t , y 0 =3}, y t , method=gear   A setting for dsolve’s optional argument method, which sets the solution method to lsode.  dsolve {diff y t ,t =y t , y 0 =3}, y t , method=lsode   A setting for dsolve’s optional argument method, which sets the solution method to mgear.  dsolve {diff y t ,t =y t , y 0 =3}, y t , method=mgear   A setting for dsolve’s optional argument method, which sets the solution method to numerical.  dsolve {diff y t ,t =y t , y 0 =3}, y t , numeric   The default numeric method used by dsolve.  dsolve {diff y t ,t =y t , y 0 =3}, y t , numeric   A setting for dsolve’s optional argument method, which sets the solution method to Taylor series.  dsolve {diff y t ,t =y t , y 0 =3}, y t , method=taylorseries   365   Applied Maple for Engineers and Scientists  Description  Syntax  Maple’s ordinary differential equation solver.  dsolve {eqns}, {vars}, opts  dsolve diff y t ,t =y t , y t   dsolve {diff y t ,t =y t , y 0 =3}, y t    DSP  Digital signal processing.  dynamical system  A system that contains both energy storage and enegry disipation elements.  Values indicating the behavior of a dynamical system.  Return the error function of expr.  Force an error condition resulting in control being returned to the top-most level.  Force the evaluation of an expression.  Evaluate expr as a floating point quantity.  Evaluate expr as a matrix.  See ???.  Return the exponential of expr.  erf expr  erf Pi 2   ERROR   ERROR expr  ERROR ‘this is wrong’  ERROR 0   eval expr  eval sin   evalf expr  evalf expr, digits  evalf Pi 2  evalf Pi 2, 500   evalm expr  evalm A &* B   exp expr  expr 1   expand expr  expand  x+1 * a+b    expand  Expand the subterms in expr.  exterior derivative  Creates an explicit differential form of a multivariate expression.  Term  dsolve  eigenvalues  erf  ERROR  eval  evalf  evalm  example  exp  366   Description  Syntax  Factorize an expression.  factor expr  factor  x^2+1    Fehlberg four-five order Runga-Kutta  The default method used by Maple to solve ODEs numerically.  Term  factor  filter, difference  filter, digital  filter, exponential  filter, forcing function  filter, hystersis  filter, linear  filter, low-pass  filter, memory  filter, moving average  filter, moving median  A filter whose output is the difference between the previous two input data values.  A filter, predominantly microprocessor based, which operates on numeric representations of continuous signals.  A digital filter whose next output is dependent upon the next data and previous output values.  The input signal to the filter.  See filter memory.  A filter whose output is a linear weighted combination of its input and output values.  A filter that attenuates all frequency components above a certian cut-off frequency.  The filter’s ability to store previous output values.  The filter output is the average value of the windowed data.  The filter output is the median value of the windowed data.  Glossary  367   Applied Maple for Engineers and Scientists  Description  Syntax  Used with the exponential filter, it determines the level of emphasis applied to previous filter output values.  This number of data points manipulated at once to compute the filter’s next output.  A method by which a fixed number of data points are isolated, prior to the filter’s output being computed, from a stream of data.  Return the nearest integer that is less than or equal to expr.  floor expr  floor 3.4   A wrapper containing font information in a plot structure.  FONT family, face, size   One of Maple’s looping constructs.  for var to val do expr od for var to val by inc do expr od for var from init to val by inc do expr od for var in expr1 do expr2 od for x to 10 do x+1 od for y to 4 by 0.1 do y^2 od for z from -2 to 2 by .5 do z od for a in [1,2,3] do a^2 od  force balance equation  For a body in equilibium, the sum of the forces acting upon it must equal zero.  A forcing function containing discontinuities, such as a step or a pulse.  A forcing function comprising a sequence of pulses.  A forcing function comprising a single pulse.  Term  filter, weight  filter, window size  filter, window  floor  FONT  for  forcing function, discontinuous  forcing function, pulse train  forcing function, pulse  368   Glossary  Term  Description  Syntax  forcing function, step  forcing function  friendly files  A forcing function comprising step change.  The function that is used to excite a dynamical system via its input terminal.  Text files that only contain valid Maple expressions.  fsolve  Maple’s numeric equation solver.  fsolve eqn,  fsolve eqn, var  fsolve x+1=0  fsolve sin y =cos y , y   The expressions comprising the function.  A function without a name.  A Maple expression capable of manipulating expressions.  f:=x-x^2 f:= a,b -a*b  fundamential frequency  The lowest frequency component present in a complex waveform.  Return either the complete or the incomplete G function.  GAMMA expr  GAMMA expr, expr  GAMMA 2.3  GAMMA 2.3+I, 3 4   function, body  function, pure  function  GAMMA  greyscale, default  greyscale  GRID  The default map used by Maple to represent a color image in monochrome, invoked by setting shading=GREYSCALE.  A map often used to represent a color image in monochrome.  Plot structure representing a surface defined by a uniform sampling over an aligned rectangular region.  GRID a..b,c..d,[[z11,...z1n],[z21 ,...z2n],...[zm1...zmn]]  GRID 1..2, 1..2, [[1, 2], [2, 2], [1, 4], [4, 8]]   369   Applied Maple for Engineers and Scientists  Description  Syntax  Determine whether an expression contains any exponential components.  has  expr, exp  has  sin f +5, exp  has  exp sin y  *y, exp   A step function with a value of unity for t < 0 and zero for t.  help  The procedural form of ?.  help topic  help topic, sub-topic   A graphical representation of quantized data showing the data values and their frequencies.  Live links embeded in a document that allow easy navigation through it.  The unit of frequency, hertz.  The Maple constant corresponding to the imaginary constant Ã-1.  The conditional construct, where test is a Boolean valued expression.  if test then expr fi if test then expr1 else expr2 fi if test1 then expr1 elif test2 then expr2 else expr3 fi  ifactor expr  ifactor  2^64+4  5   ifactor  Return the integer factors of expr.  image processing  An operation whereby an image is altered to produce a new one.  The data being processed.  The time response of a dynamical system that has been excited using an impulse.  An impulse with a finite amplitude.  Term  has, exp  Heaviside  histogram  hyperlinks  Hz  I  if … fi  image  impulse, response  impulse, weighted  370   Term  impulse  indets  infinity  infix form  insequence  Description  Syntax  A pulse of infinite height and infinitely narrow width with an area equal to unity.  Return the unassigned variables in an expression.  indets expr  indets sin x +a b+7   The Maple constant corresponding to ¥  .  The form that a procedure or function takes when it is invoked by placing it between its arguments.  arg1 func arg2 arg1 proc arg2  An optional argument to display that when set equal to true causes a sequence ploti to be displayed as an animation.  display {ploti}, insequence=true, opts   int  Return the intergral of an expression.  int expr, var  int expr, range  int sin y , y  int sin y , y=-1..alpha   integer  The Maple type integer.  type 3, integer   integration trapezoid rule  A method of approximating the area under a function.  intensity  intersect  inttrans  inverse Z transform, direct method  The value of brightness of an image at the point  x,y .  Return the intersetion of two sets.  intersect set1, set2  intersect {1,2,3,a}, {a}   The Maple package containing the integral transformations.  Obtaining the time response of a discrete system by obtaining the weighted sum of the system’s previous outputs and the system’s previous  and current  inputs.  Glossary  371   Applied Maple for Engineers and Scientists  Term  Description  Syntax  inverse Z transform, long division method  inverse Z transform  Obtaining the time response of a discrete system described by a polynomial in 1 z through the process of long polynomial division.  The process of transforming an expression from the discrete domain to the continuous domain.  invlaplace  Compute the inverse Laplace transform of expr.  invlaplace expr, var1, var2   invlaplace 1  1-s , s, t  invztrans  Compute the inverse Z transform of expr.  invztrans expr, var1, var2  invztrans 1  1-z , z, t   The Maple display engine.  Isolate an expression from an equation. This function is readlib defined.  isolate  eqn, expr  isolate  x*y-4=0, y   ithprime  Return the ith prime number.  ithprime i  ithprime 501   The complex constant  cid:214  engineers.  - 1 , used by  Compute the Jordan form of a matrix. The transition matrix is stored in the optional name. This function is found in the linalg package.  jordan mat  jordan mat, name  jordan matrix 2,2,[1,2,3,4]   jordan matrix 2,2,[1,2,3,4] , ‘trans’   The part of the Maple system that is compiled for reasons of efficiency.  IRIS  isolate  j  jordan  kernel  372  ‘ ‘ ‘  Term  labels  Description  Syntax  The optional argument to plot and plot3d allowing axes labels to be set.  Laplace transform  laplace  last name evaluation  lcoeff  lhs  library  Liesymm  The process of transforming a function of time into a function of the Laplace operators.  Return the Laplace transform in var2 of the function func in var1. The Laplace transform pair is found in the inttrans package.  The process whereby the last name only is evaluated. This applies particularly to matrices, tables, and arays. It is done to save screen real estate.  Return the leading coefficient of a polynomial.  Obtain the left-hand side of an equation.  The part of the Maple system that contains approximately 95% of Maple’s functionality.  The Maple package containing functions for determining equations leading to the similarity solutions of a system of partial differential equations.  Limit  The inert form of limit.  Limit expr, lim, opts   Glossary  plot func, range, labels=[namex, namey], opts  plot3d func, range1, range2, labels=[namex, namey, namez], opts  plot sin, labels=[‘x’, ‘amp’]  plot sin, labels=[‘x’, ‘amp’]  plot3d sin x y , x=0..1, y=1..2. labels=[‘x’, ‘y’ ,’ z’]   laplace func, var1, var2  laplace sin x ^2, x, g   lcoeff poly  lcoeff poly, var  lcoeff 2*x^2+x-1  lcoeff a*x^2+x-1, a   lhs eqn  lhs a  lhs x^2+1=a+b   373   Applied Maple for Engineers and Scientists  Term  limit  linalg  Description  Syntax  Return the limit of an expression in the limit lim.  limit expr, lim, opts  limit sin x  x, x=0  limit cos x  x, x=0, left   The Maple package containing the linear and matrix algebra functions.  linalg[band]  Define a band matrix.  linalg[crossprod]  Return the vector product of two lists or vectors.  linalg[det]  Return the determinant of a matrix.  linalg[inverse]  Return the inverse of a matrix.  linalg[iszero]  Determine whether a matrix is zero.  linalg[jordan]  See jordan.  linalg[matrix]  linalg[submatrix]  Define an n-by-m matrix in the Maple system.  linalg[matrix] n, m, [elemi,j]  linalg[matrix] 2,2, [1,2,3,4]   Select a submatrix from an already existing one.  linalg[transpose]  Return the transpose of a matrix.  linalg[vector]  See vector.  linalg[band] [elem], size ; linalg[band] [A], 3 ;  linalg[crossprod] list1, list2  linalg[crossprod] [1,2,3], [a,b,c]   linalg[det] mat  linalg[det] matrix 2,2, [1,2,3,4]   linalg[inverse] mat  linalg[inverse] matrix 2,2, [1,2,3,4]   linalg[iszero] mat  linalg[iszero] matrix 2,2, [0,0,0,0,]   linalg[submatrix] mat, rows, cols  linalg[submatrix] A, 1..2, 3..5   linalg[transpose] mat  linalg[transpose] matrix 2,2, [1,2,3,4]   374   Term  list  listlist  listplot  log  map  map2  long name  matrixplot  mellin  member  Description  Syntax  A Maple type and data structure.  type [1,2,3], list  [1,2,3,4]  A Maple type, a list of lists.  type [[a],[b,c]], listlist   Found in the plots package this will plot a curve defined using a list of points, [[x1, y1],[ x2, y2], … [xn, yn]].  listplot list, opts   Return the general logarithm of expr.  log expr  log a  log 123.456   linalg[matrix] liesymm[&^] plots[listplot]  A Maple function or procedure name that includes the package name. These can be used without the respective function or package being loaded using with.  Apply an operation or function to the elements comprising a compound expression.  map f, expr, ops  map x-x^2, [1,2,a]  map  x, y -x+y, [1, r], 7   Apply a function, with the first parameter specified, to the operands of a compound expression.  map2 func, op1, expr  map2  x,y -x^y, 10, [a, b]   Found in the plots package, matrixplot enables numerical matrices to be displayed as a three-dimensional surface.  matrixplot mat, opts  matrixplot matrix 2,2, [1,2,3,4]   Found in the inttrans package, mellin returns the Mellin transform in var2 of an expression in var1.  mellin expr, var1, var2  mellin sin t , t, p   Test for membership of a set or list. If the optional argument is used and member returns true, the position of the first occurance of elm is stored in it.  member expr, elem  member expr, elem, opts  member [1,2,3], 3  member {1,2,3,4,5,6}, 4, ‘where’   Glossary  375   Applied Maple for Engineers and Scientists  Description  Syntax  A wrapper inside a plot structure containing data points  [x, y, z]  that define a surface.  Return the difference of two sets.  MESH data  MESH [[[0, 0, 0], [10, 100, 1000]], [[0, 0, 0], [10, 100, 1000]]]   set1 minus set2 {1,2,3} minus {3,4}  Return the expression evaluated over the integers modulo m.  expr mod m 12 mod 4  A name is a Maple string that can have data assigned to it. A name can be less than or equal to 500k characters in length.  a ‘A_string’  Return the number of operands in a compound expression.  nops expr  nops a  nops [1,2,3,4,5]   Return a normalize or simplified rational expression. If the optional expanded is present, then the numerator and denominator will be a product of expanded polynomials.  normal expr  normal expr, expanded  normal 1 a+1 b  normal 1  a* a+1  +1 b, expanded   The process whereby a set of data values are mapped onto the range 0..1.  The Boolean negation operation.  not a  The Maple Null operator.  Return the numertor of a quotient.  numer expr  numer  1+s   1-s   type 34, numeric  type 2 3, numeric  type -67.9, numeric   numeric  A Maple type.  Term  MESH  minus  mod  name  nops  normal  normalize  not  NULL  numer  376   Term  numpoints  Description  Syntax  The optional argument to plot and plot3d allowing the number of plot points to be set.  Glossary  plot func, range, numpoints=value opts  plot3d func, range1, range2, numpoints=value, opts  plot sin, numpoints=100  plot3d sin x y , x=0..1, y=1..2. numpoints=40^2   ODE, analytical solution  Normally an exact solution obtained without resulting to numerical methods.  ODE, coupled  ODE, initial conditions  ODE, numerical solution  An nth-order ODE described with a set of simultaneous lower order ODEs.  Values from which the constants of integration can be obtained.  An approximate solution to the ODE obtained by using one of the numerical methods known to Maple.  ODE, odeplot  ODE  op  operator, delay  operator, differential  A plotter capable of plotting an ODE using the procedures supplied by dsolve …, numeric .  odeplot proc, vars, r1, r2, opts ;  Ordinary differential equation.  Return a single or list of operands from a compound expression.  op expr  op num, expr  op range, expr  op [num1, num2], expr  op 2^a  op 2, [1, 2, 3]  op 2..3, [1, 2, 3]  op [2, 2], [1, [2^a], 3]   See z.  d dt  377   Applied Maple for Engineers and Scientists  Term  operator Laplace  operator, z  Description  Syntax  See s.  A delay of one sample period is introduced when an expression is divided by the delay operator z. Using this technique, continuous signals can be discretized and the temperal information maintined.  orientation  The optional argument to plot3d allowing the viewing orientation  q, j  to be set.  plot3d func, range1, range2, orientation=[q, j], opts  plot3d sin x y , x=0..1, y=1..2. orientation=[10, -150]   overshoot  The amount by which the output of a dynamical system initially overshoots the steady-state value following the application of a step input.  partial differential equations  A differential equation in more than a single variable.  partial fraction expansion  A process whereby a rational function f in the variable x is decomposed into partial fractions.  A graphical method of approximating solutions to first- and second-order differential equations.  Plot the phase portrait or approximate solutions to one- or two-dimensional systems of differential equations. This uses numerical methods.  The Maple representation of 1.  Construct a function using segments.  phaseportrait eqni, vars, range, ics, opts   piecewise eqni  piecewise x, sin x , x3, cos x , 3   phase-plane  phaseportrait  Pi  piecewise  378   Term  PLOT  plot  PLOT3D  plot3d  Description  Syntax  An unevaluated function that forms the data structure of a two-dimensional plot  Generate a two-dimensional plot of the functions over the range r.  An unevaluated function that forms the data structure of a three-dimensional plot.  Generate a two-dimensional plot of the functions over the range r.  Glossary  PLOT data  PLOT CURVES [[1,1],[2,3]] , TITLE ‘A plot’    plot func  plot func, r, opts  plot {func}, r, opts  plot [pts], opts  plot sin  plot sin t , t=0..Pi  plot {sun y , cos y }, y=-5..5  plot [[1, 1],[2, 4]]   PLOT3D data  PLOT MESH [[[1,1,1],[2,3,4]],[ [1,2,3],[4,3,6]]] , TITLE ‘A 3d plot’    plot func  plot func, r, opts  plot {func}, r, opts  plot [pts], opts  plot sin  plot sin t , t=0..Pi  plot {sun y , cos y }, y=-5..5  plot [[1, 1],[2, 4]]   plots, 10Z  plots[display]  plots[listplot]  The Maple package containing the graphing functions and utilities.  See display.  See listplot.  plots[matrixplot]  See matrixplot.  plots[odeplot]  See ODE, odeplot.  plots[surfdata]  plots[textplot]  See surfdata.  See textplot.  379   Applied Maple for Engineers and Scientists  Description  Syntax  The Maple package containing the plotting, utilities, and graphical objects.  plottools[disk]  Plots a disk.  plottools[disk]  [x, y], rad, opts  plottools[disk]  [0, 1], 5   A setting for STYLE determining that all nontext objects will be rendered as points.  The roots of the denominator of the system transfer function when expressed in either the s- or z-plane.  A wrapper inside a plot structure containing data that are to be plotted as polygons.  POLYGONS data  POLYGONS [[1,1], [2,2], [3,3]]   See degree.  A Maple type.  type 3, posint   Print an expression to the current output device.  The Maple keyword used in a procedure definition.  print expr  print ‘This is printed’  print sin   f:=proc args  body end f:=proc x  x^2 end f:=proc a,b  a*b end  The expressions comprising the procedure.  A procedure without a name.  A Maple expression for manipulating expressions.  f:=proc args  body end f:=proc x  x^2 end f:=proc a,b  a*b end  Term  plottools  POINTS  pole  POLYGONS  polynomial degree of  posint  print  proc  procedure, body  procedure, pure  procedure  380   Glossary  pulse transfer function  The transfer function of a discretized system.  Term  product  quantization  read  readlib  Description  Syntax  Compute the product of expr.  product expr  product expr, r  product 1 n  product n^s, s=0..3   The process whereby a signal with an infinite number of levels is represented by a fixed number, for example, 256.  Read the contents of file into the current Maple session.  Read a readlib-defined function or procedure into the current Maple session. Readlib-defined functions and procedures are not stored using the Maple package structure.  read file  read ‘data.ms’  read data1   readlib func  readlib isolate   recurrence relationship  A relationship equating the current output to a weighted sum of previous outputs.  y n =y n-1 +y n-2   related  Return the “see also” section of specified help page.  related topic  related sin   repetition frequency  The frequency at which an object or operation is repeated.  RETURN  Return control to the previous level.  rhs  Obtain the right-hand side of an equation.  RootOf  The placeholder for the roots of a polynomial.  RETURN   RETURN expr  RETURN ‘data invalid’  RETURN 0   rhs eqn  rhs a  rhs x^2+1=a+b   RootOf x^2-1   381   Applied Maple for Engineers and Scientists  Description  Return the nearest integer to expr.  Syntax  round expr  round 3.4   The Maple recurrence relationship solver, which solves the equations eqni for the functions funci.  rsolve eqns, fcns  rsolve y n-1 =y n , y n    The Laplace operator where s = d dt =  cid:242  dt. 1 s  and  The plane on which the trajectories of a continuous system’s poles are plotted.  sample instance  The point at which a sample is valid.  sample period  The period between successive samples of a continuous system.  See sample period.  See sample period.  The process by which a continuous system is converted into a discrete one.  Return the secant of expr.  sec expr  sec 5.46   Select all elements of a specified type from an object.  select oper, expr  select oper, expr, opts  select isprime, [$1..20]  select type, [$10..20], even   The Maple sequence operator. A sequence is formed using expr over the range r=x..y such that r=x, x+1, x+2, ... for r£ y.  seq expr, r  seq a^n, n=1..3  seq a*n, n=[1,2,3,s]   Term  round  rsolve  s  s-plane  sampling period  sampling rate  sampling  sec  select  seq  382   Glossary  Term  series, Fourier  series, Frobenius  series, Taylor  settling time  short name  Description  Syntax  The Fourier series has the following form:  y = a0  +  cid:229  n=1  bn sin nw  t  +  cid:229   cncos nw  t   n=1  The Frobenius series has the following form: y = xc   a0 + a1x + a2x2 + a3x3 + ... + arxr + ...   where a0 is the first nonzero coefficient.  The Taylor series has the following form; y = f 0  + f ¢  0 t + f ¢ ¢  0 t2 2 f ¢ ¢  0 t2 + … + fn 0 tn n!  +  6  38  The time taken for a dynamical system to reach its steady-state ± 5%  sometimes ±2% is used .  A Maple function or procedure name without the package name included. These can only be used once the respective function or package has been loaded using with.  matrix &^ listplot  set  A Maple type and data structure.  type {1,2,3}, set  {a,b,c}  simplify  Return a simplified form of expr.  sin  Return a sine form of expr.  single-input-single-output  A dynamical system with a single input terminal and a single output terminal.  simplify expr  simplify expr, {siderels}  simplify 1+a+2*a  simplify x+y+z, {y+z=A}   sin expr  sin a  sin 3.67   383  ¥ ¥ ¢  Applied Maple for Engineers and Scientists  Term  Description  Syntax  sort obj  sort q,w,e,r,t,y  sort 1,3,4,7,3,9,3,2,8,5,4   An event that only happens once after it has been triggered.  Maple’s symbolic equation solver.  Return a sorted set of objects.  The frequency spectrum of a continuous system.  The frequency spectrum of a discrete system.  A graphical representation of a signal’s frequency components.  A dynamical system whose output does not grow in an unbounded fashion with time in the absence of any stimuli.  A two-dimensional plot that resembles a staircase. Often used to plot signals within a digital system that only change at the sampling instant.  sqrt  Return the square root of expr.  sqrt expr  sqrt 2.34   stared variables  Variables representing samples versions of a corresponding continuous signal.  state variable feedback controller  state variables  state-space matrices  A controller using all of the system states.  The variables that define the state of a dynamical system at any time.  The matrices that define a system in . _ = Ax__ + Bu__ state-space: x y_ = Cx__ + D__  single-shot  solve  sort  spectrum, continuous  spectrum, discrete  spectrum  stable system  staircase plot  384   Glossary  Term  Description  Syntax  state-space  The n-dimensional space that contains the trajectories of the system’s states.  stats[describe, median]  Return the median of a sorted list of numbers.  stats[describe, median] [data]  stats[describe, median] [1,4,3,7,6,2,1]   The final state of a dynamical system reached when there is no further change in its input.  A function that abruptly changes from one amplitude to another.  string  A Maple type.  ‘This is a string’  A numerical method of approximating an intergral of func over the range r. The optional argument specifies the number of rectangles to use in the computation.  trapezoid func, r  trapezoid func, r, n  trapezoid sin t , t=0..5  trapezoid sin t , t=0..5, 10   The optional argument to plot allowing the interpolation style to be set.  plot func, range, style=value, opts  plot tan x , x=-10..10, style=line   A matrix produced by removing elements from another matrix.  Substitute the equations into the expression.  Substitute for the specified operands in the expression.  subs eqni, expr  subs [eqni], expr  subs a=3, b=t, a*sin a*t   subs [a=y, y=x], a*y   subsop  opi, expr  subsop 0=g, f t   subsop 2=3, [a, b, c]   The inert form of sum.  Sum expr, eqn,   385  steady state  step function  student[trapezoid]  style  sub-matrix  subs  subsop  Sum   Applied Maple for Engineers and Scientists  system, continuous  A dynamical system whose output is valid for all time t.  Description  Syntax  Return the definite or indefinite,  determined by eqn , sum of the expression.  sum expr, eqn  sum 1 n^2, n  sum 1 n^2, n=1..5   Produce a three-dimensional surface from a list of amplitude points. This is found in the plots package.  surfdata data, opts  surfdata [[1,2,3],[4,5,6], [1,2,3]]   A dynamical system whose output is valid at the sample instance.  See system, digital.  The part of a system that determines how that system will react when it is excited.  The condition of a dynamical system at a given moment in time.  See unstable system.  Define a Maple table using the equations eqn. The left-hand side of eqn is the index into the table, while the right-hand side is the table entry.  table[eqni]  table [a=1, b=2]   Return the hypobolic tangent of an expression.  tanh expr  tanh a  tanh 5 6   Return the Taylor series approximation of an expression about the point given by eqn. By default six terms are returned.  taylor expr, eqn, opts  taylor sin x , x  taylor sin x , x, 19  taylor sin x , x=h, 7   Term  sum  surfdata  system, digital  system, discrete  system, dynamics  system, state  system, unstable  table  tanh  taylor  386   Term  TEXT  time constant  time response  time series data  transfer function  type, anything  type, function  type, numeric  type, specfunc  type  u matrix  unapply  Glossary  Description  Syntax  The wrapper for an image’s text information.  TEXT [x,y],’string’,horiz,vert  TEXT [1,1],’This is text’, ALIGNLEFT, ALIGNBELOW   textplot data, opts  textplot [1, 2, ‘This is text’]   textplot  Render text on a graphic.  A measure of how quickly a dynamical system will respond to external stimuli.  The output of a dynamical system as a function of time.  Data that has been gathered periodically over time.  A description relating a dynamical system’s input and output.  Test for any valid Maple expression.  type x, anything   Test for a Maple function.  type x-x^2, function   Test for a numeric quantity.  type 56, numeric   Test for a specific function with a given type of argument.  type sin t , specfunc name, sin    Maple’s type checker, which can be used in procedural programming because it is a Boolean valued function.  type expr, type  type sin, function  type a, posint   Used in state-space analysis, the u matrix contains the system’s inputs.  Convert an expression to functional notation in var.  unapply expr, var  unapply x^2+x+1, x   387   Applied Maple for Engineers and Scientists  Term  Description  Syntax  unassigned  Determine whether a Maple expression is unassigned.  unassign name   unconditionally stable  See stable system.  union  Return the union of two sets.  union set1, set2  union {1,2,3,a}, {a}   unit circle  The region of unconditional stability on the z-plane.  unit step  A step change in a signal of unit amplitude.  unstable system  Vandermonde matrix  A dynamical system whose output grows in an unbounded fashion with time in the absence of any stimuli.  A square matrix with its  i,j th entry equal to L j-1  where L is the matrices’ second column.  vector  Define a vector in Maple.  view  The optional argument to plot and plot3d allowing a specific view to be set.  1 1 1  a b c  a2 b2 c2  vector len  vector [elmi]  vector 3  vector [1,2,3,4]   plot func, range, view=[rangex, rangey], opts  plot3d func, range1, range2, view=[rangex, rangey, rangez], opts  plot sin, view=[1..4, DEFAULT plot3d sin x y , x=0..1, y=1..2. view=[0.5..1, 1..3 2, -1..1]   volatility  A measure of how rapidly time series data is changing.  wedge product  see &^.  388  Ø Œ º Œ Œ ø œ ß œ œ  Term  Description  Syntax  whattype  Maple’s interactive type checker.  whattype expr  whattype sin  whattype 6 8   A form of the repetition construct supported by Maple. The body of the loop is evaluated while the loop test is true.  while test do … od while true do x:=x+1 od  Load the package function’s short names into the session’s name space.  with pack  with pack, [funci]  with linalg  witn linalg, [matrix, vector]   while  with  Worksheet  x matrix  y matrix  Z transform, direct  Z transform, impulse-invariant  Z transform, step invatiant  Maple’s graphical user interface.  Used in state-space analysis, this matrix contains the states of the system under observation.  Used in state-space analysis, this matrix contains the output signals of the system.  A method of discretizing a system by finding a closed form solution to an infinite sum.  A method of discretizing a system in such a way that the discrete and continuous impulse responses are identical, at least at the sample instances.  A method of discretizing a system in such a way that the discrete and continuous step responses are identical, at least at the sample instances.  Z transform, substitution method  A method of discretizing a system by substituting for s in the continuous transfer function.  z-plane  The plane on which the trajectories of a continuous system’s poles are plotted.  Glossary  389   Applied Maple for Engineers and Scientists  Term  Description  Syntax  Z-transform  The process of discretizing a function of time.  zero  zip  ztrans  The roots of the numerator of the system transfer function when expressed in either the s- or z-plane.  Combine the elemets of two lists or vectors according to some operation.  zip f, expr1, expr2, opts  zip  x,y -x+y, [1,2,3], [a,b,c]  zip  x,y -x^y, [a,b,c], [1], r   Return the Z transform in var2 of the function func in var1.  ztrans func, var1, var2  ztrans sin x ^2, x, z   390   Applied Maple for Engineers and Scientists  About the authors  Christopher S. Tocci is currently a senior projects engineer at Allen- Bradley Automation Company, Inc., in Chelmsford, Massachusetts. Dr. Tocci was also one of the cofounders of Applied Research Consor- tium, Inc., in Charlton, Massachusetts. His past technical experience has been in atomic spectroscopy, medical engineering, optical communica- tions, optical device technology, and biophysics. He has been involved with industrial and military hardware designs and analysis of optics and optoelectronics as it applied to infrared sensors, two-dimensional signal processing, communication, and interconnection for massively parallel computing architectures. He has had senior positions at Baird Electronic, Raytheon, MIT Lincoln Labs, Augat Fiberoptics, and he has consulted for Ciba-Geigy Diagnostics on optical metrology for blood analysis. Dr. Tocci has had several patents in electro-optical device technology and over 35 publications in both trade and professional journals. He received his Ph.D. from Clarkson University in engineering science in 1985. Dr. Tocci is a  391   Applied Maple for Engineers and Scientists  member of OSA, Who’s Who in the East in Science & Technology, AMS, AAAS, and the NRA.  Steven Adams is currently technical marketing director for TCI Soft- ware Research, Inc., in Las Cruces, New Mexico. Previously, Dr. Adams was the director of Technical Marketing for Harmonix Corporation, Woburn, Massachusetts. Dr. Adams has had a strong working relationship with Waterloo Maple Software in Waterloo, Canada, since 1993, when he was manager of their U.S. Technical Services group. Previous to his in- volvement with Maple Software, he was technical member of Wolfram Re- search’s Applications Group, the developers of Mathematica. Dr. Adams has had several consulting and lecturing positions within industry and aca- demia—most notably, senior lecturer at South Bank Polytechnic, London, U.K., in the Department of Electrical and Electronic Engineering. At South Bank Polytechnic, Steve lectured on robotics, modern control sys- tems, and sensor design and analysis. Dr. Adams has also lectured in Bom- bay and Puna, India, as a sponsored representative of the British Council, and IPM in Moscow CIS, Russia, as sponsored by the British Royal Soci- ety. Steve received his Ph.D. in Electrical Engineering from King’s College, University of London, School of Electronic Engineering, London, U.K., in 1984.  392   Applied Maple for Engineers and Scientists  Index  $ function, 32–33, 357 &^, 358 3-D plotting grid, 78 ???, 8, 358 ??, 358 ?, 358 “, 9, 357 !, 357 -, 358 @@ operator, 145, 358  Abs function, 358 Active ﬁlter design and analysis, 39–91  analog LPF, 40–70 comb, 71–91  Alias facility, 161, 228 Alias function, 288, 358 Aliasing, 359 Allvalues function, 359 A matrix, 358 Analog LPF design and analysis, 40–69  1-kHz Butterworth LPF, 47–49 bode magnitude and phase plots, 49–53  Butterworth LPF component  sensitivity analysis, 55–57  Butterworth unequal resistance values, 57–60 conclusion, 69–70 constituent relationships derived, 41–47 Laplace transform, 41 for newer ﬁlter requirements, 64–67 unit step response, 67–69  Analytic solution, 359 Animate 3d function, 19, 359 Animate function, 19, 359 Applied Maple for Engineers and Scientists  application areas, xvi organization of, xiv–xvi philosophy of, xiv purpose of, xiv who needs to use, xiv  Arbitrary precision arithmetic, 359 Args variable, 359 Array function, 359 Arrays, 23, 359 Assigned function, 359 Attenuation, 64  393   Applied Maple for Engineers and Scientists  Attenuation  continued   increasing, of very close signals, 86 suﬃcient, 64  Attenuators 10:1, 240 deﬁned, 360  Axis jw, 360 Bandpass ﬁlter  BPF , 40 Bessel ﬁlters, 69 Bilinear transform, 225  advantages, 234 conformal mapping, 226 deﬁned, 360 deriving, 226 mapping, 229 See also Substitution methods  Bit depth, 360 Blue plane, 259, 261 B matrix, 360 Bode magnitude, 49–50 Boolean valued expression, 360 Buck-type converter, 329  base topology, 318 basic model for, 318 output voltage vs. duty cycle, 329 output waveform, 325, 327 See also Switching power supply Butterworth amplitude response, 41 Butterworth LPF, 40  1-kHz, 47–49 1-kHz improvement, 53–55 bode plot for, 50 component sensitivity analysis, 55–57 cutoﬀ frequency, 54 damping factor, 54 designing, 47–49 ﬁlter design, 66, 67 ﬁltered unﬁltered output comparison, 63 ﬂat transient response and, 69 interference signal attenuation, 62 phase plot for, 52 second-order, 40 sensitivity cases for, 56 spectral response, 49 test setup, 60–63  394  unequal resistance values, 57–60 See also Low-pass ﬁlters  LPFs   Calculator, 9–26  calculus, 17–18 data structures, 20–26 equation solver, 15–17 graphics, 18–20 numeric, 9–12 symbolic, 12–15  Canonical forms  controllable, 242–45, 360 deﬁned, 360 jordan, 245–47, 360 observable, 247–48, 360 See also State space equations  Canonic matrix, 347 Capacitors, sensitivity functions, 59 Cascading comb ﬁlters, 86–90  improvements, 91 response for various alfa, 89 switching technology, 87 See also Comb ﬁlters  Cat function, 361 Cayley-Hamilton theorem, 201, 203 Characteristic equation, 361 Charge-coupled devices  CCDs , 71  circuit model, 71 clocking speed, 83 delay cells, 82 shift registers, 71 switching ﬁlter equations, 86 switch states for, 72 total delay with, 82  Classical algorithm, 138 C matrix, 360 Coeﬃcient extraction values, 46 Coeﬀs function, 239, 361 Color functions, 361–62 Color information, 252  greyscale conversion of, 257–61 speciﬁcation methods, 252  COLOUR wrapper, 361 Comb ﬁlters  3D-plot response, 78, 79, 80 analysis and design, 71–91   behavior, 76 cascading, 86–90 control diagram, 73 delay element, 73 derivation and analysis, 72–80 ﬁltering from interfering  background signal, 81–86  magnitude response, 83 peak responses, 82 rejection ratio, 84, 85 response for various values, 77  Combine function, 205 Complex arithmetic, 11 Complex roots, 187–94 Composite curve ﬁtting, 122–23 Computer algebra system  CAS , xiii, 1  deﬁned, 2, 360 numbers, 2–3 performance of, 2 symbols, 3–5  Computer sensitivities, 57 Conformal mapping, 226, 362 Conjugate function, 362 Constants, 13–14  deﬁned, 362 list, 14  Continuous control application theory, 173–210  frequency-domain approach, 175–94 linear control system analysis, 173–75 time-domain approach, 194–210  Continuous signals, transforming, 216–34  impulse-invariant, 222–25 substitution methods, 225–34 See also Pulse transfer function  Continuous system illustrated, 214 pulse transfer function of, 215 transformation process, 215  Continuous transfer function, 229 Contrast adjustment, 262 Controllable canonical form, 242–45 Controllable form matrices, 247–48 Control structures, 29–30 Control system analysis, 173–75  frequency-domain approach, 175–94 time-domain approach, 194–210  Conversion helper functions, 362 Conversion routine, custom, 223–24 Convert function, 179, 184, 362–63 Cost functions, 94, 117, 118 Cross multiplication function, 288 Curve ﬁtting, 93–132 composite, 122–23 conclusion, 132 LMA, 114–20 moral about, 131–32 regressive, 95–143 rippling, 123 types of, 93  CURVES wrapper, 363 Cutoﬀ frequency  Butterworth, 54 lowering, 63 resistor values and, 65 trimming, 53  Damping coeﬃcient, 167–68, 169, 170 Damping factor, 47 Butterworth, 54 component sensitivity for, 57  Data structures, 20–26  arrays, 23 keywords, 352–55 lists, 21–22 matrices, 23–24 sets, 21–22 tables, 25–26 vectors, 24–25  Dc gain, 363 Deﬀorm function, 363 Degree function, 363 Delay cells, 82 Delay function, 73 Delay operator, 225 Delay quotes, 230 Denom function, 364 DEplot, 139–40, 364 DESol, 364 DEtools package, 137–44  contents of, 137 deﬁned, 364 DEplot, 139–40, 364  Index  395   Applied Maple for Engineers and Scientists  DEtools package  continued   function access, 139 phase-plane techniques, 140–43 See also ODE tools  Dﬁeldplot function, 140–41, 364 Diﬀerence function, 274, 364 Diﬀerencing, 272–75  advantages, 300 algorithm, 273 deﬁned, 272 ﬁlter, 367 output, 274–75, 296 time series data, 272 See also Linear ﬁlters  Diﬀerential equations, 133–71  deﬁned, 364 describing dynamic systems with, 152 Laplace transforms of, 160–61 numerical solution to, 225 partial  PDEs , 134 reducing, 147 See also Ordinary diﬀerential equations  ODEs   Diﬀerential operator, 225, 244 Diﬀorms package, 143–44  contents of, 143 deﬁned, 364 in formal framework, 143 loading functions from, 144 See also ODE tools  Digital control, 364 Digital signal processing  DSP , 364, 366 Direct method, 238–42  deﬁned, 238, 389 See also Time response calculation; Z-transform  Discrete control applications, 213–48  pulse transfer function, 215–42 state space equations, 242–48  Discrete data processing, 249–300  categories, 249 image conversion, 252–72 linear ﬁlters, 272–95 Maple plots, 249–50 plot structure, 250–52  Discrete transfer function, 365 Display function, 365 Disturbance matrix, 244  396  Ditto  “  pointer, 9, 357 D matrix, 363 Do loops, 105, 106, 107, 147, 183 D operator, 363, 364 Dsolve function, 134–37, 153, 365–66  ﬂoating-point numbers in ODE  Duty cycle  coeﬃcients and, 153  nonlinear ODEs and, 165 numeric, 135–37 returned equation, 135  acceptable variations, 314 of buck converter, 329 low, 314 output dc voltage and, 326 peak-to-peak ripple vs., 315 relative SNR vs., 317 ripple value, 314 SNR and, 316  Dverk78 algorithm, 138, 365 Dynamic system modeling, 152–71  deﬁned, 366 with diﬀerential equations, 152 with Heaviside function, 156–57 nonlinear system, 165 simple shock absorber, 152–56 twin mass shock absorber, 158–65 See also Mathematical models  Eigenvals operand, 202 Eigenvalues  abstracting, 202 deﬁned, 366 distinctive, 245  Equation solver, 15–17  numerical solutions, 15–16 symbolic solutions, 16–17  Erf function, 366 ERROR, 36–37, 366 Euler’s identity, 74 Evalc function, 188, 193, 205 Evalf function, 366 Eval function, 366 Evalm function, 366 Example function, 8, 366 Expand function, 366   Exp_ﬁlter function, 291 Exp function, 366 Exponential ﬁltering, 287–95  advantages, 300 comparisons, 292 deﬁned, 287 ﬁlter, 367 ﬁlter weight, 289–90 impulse response, 290–91 noise reduction, 295 output, 297 signal amplitude reduction, 295 testing, 290 tracking, 295 See also Linear ﬁlters Exterior derivative, 366  Factor function, 367 False color, 268–71  application process, 270 to greyscale images, 271 illustrated, 271 mapping functions, 270 plane data, 271 See also Image conversion  Feedback controller  model, 174 state variable, 360  Fehlberg fourth-ﬁfth order Runga-Kutta method,  15, 137, 367  Filters, 367–68 Filter transfer function, 288, 289 Filter weight, 289–90  changing, 292 deﬁned, 289, 368 illustrated, 293–94, 298 See also Exponential ﬁltering  Floating-point approximations, 2, 9–10 FONT wrapper, 368 Force balance equation, 368 Forcing functions, 156–57, 369 of bipolar square wave, 240 deﬁning, 159 discontinuous, 368 displaying, 157 ﬁlter, 367  modeling, 164 plotting, 156, 168 pulse, 368 pulse train, 368 square-wave, 168 step, 369 substituting for, 164 system output illustration, 241 For loops, 30–31, 256, 263, 277  deﬁned, 368 nested, 171  Forward dynamics, 174 Fourier approximation, 335  comparison with exact  input waveform, 338, 342  comparison with exact PWM  input waveform, 341  comparison with exact waveform, 337 dc term, 338 with ﬁrst 10 harmonics, 341 Laplace transform of, 337 quality, 331  Fourier method, 330–43 analysis process, 334 output ripple value, 339 peak-to-peak ripple with, 340 running time average, 330 time sliding and, 330 See also Steady-state method  Fourier series, 330, 331  analysis, output voltage from, 339, 343 approximating, 335 coeﬃcients, 332, 333, 334 dc component, 335 deﬁned, 383 deﬁning, 331–32  Frequency-domain approach, 175–94  output plot, 209 partial fraction expression, 179–94 roots, 185 See also Time-domain approach  Frequency response, 233 Friendly ﬁles, 369 Frobenius series deﬁned, 383 method, 145  Index  397   Applied Maple for Engineers and Scientists  Fsolve function, 54, 59–60, 369 Function list  $, 32–33, 357 abs, 358 alias, 288, 358 allvalues, 359 animate3d, 19, 359 animate, 19, 359 array, 359 assigned, 359 cat, 361 coeﬀ, 361 conjugate, 362 deﬀorm, 363 degree, 363 denom, 364 dﬁeldplot, 140–41, 364 diﬀ, 364 diﬀerence, 274 display, 365 dsolve, 134–37, 153, 365–66 erf, 366 eval, 366 evalf, 366 evalm, 366 exp, 366 expand, 366 exp_ﬁlter, 291 factor, 367 has, 370 Heaviside, 156–57, 370 histogramplot, 265–67 ifactor, 370 indets, 371 int, 371 integrate, 18 intersect, 371 invlaplace, 372 isolate, 372 ithprime, 372 jordan, 246–47, 372 laplace, 374 lcoeﬀ, 374 lhs, 373 limit, 373–74 listplot, 375  398  log, 375 LPF_Transfer, 61 map2, 28, 375 map, 28, 236, 375 matrixplot, 256, 375 mellin, 375 member, 375 moving_ave, 277 moving_median, 283–84 nops, 376 normal, 376 numer, 376 op, 254, 377 phaseportrait, 140–41, 378 piecewise, 164–65, 378 plot3d, 249, 379 plot, 249, 379 print, 380 product, 381 read, 381 readlib, 381 related, 8, 381 rhs, 381 RootOf, 381 round, 263, 382 rsolve, 382 sec, 382 select, 226, 382 seq, 32–33, 382 simplify, 383 sin, 8, 383 sort, 384 sqrt, 384 stats, 385 subs, 385 subsop, 385 sum, 386 surfdata, 171, 386 table, 386 tanh, 386 taylor, 386 textplot, 387 unapply, 28–29, 387 unassigned, 388 union, 388 vector, 388   Fundamental frequency, 369  GAMMA, 369 Gaussian proﬁle function, 95–96 Gear algorithm, 138 General polynomial regression, 120–26  estimated and actual intensity, 123 problems, 125 See also Polynomial regression; Regression  whattype, 389 with, 389 zip, 390 ztrans, 221, 390  Functions, 27–29  body, 369 deﬁned, 27, 369 deﬁnition form, 27 example, 8 forcing, 156–57, 159 hyperlinks to, 8–9 inﬁx form, 30, 371 parameters, 27 pure, 27–28, 369  Graphical computations  calculator, 18–20 Maple, 5  Green plane, 258, 260 Greyscale  conversion, 257–61 default, 369 deﬁned, 369 false color and, 271 image generation, 261  Grids, 255, 369  Has function, 370 Heaviside function, 156–57  deﬁned, 370 using, 156  Help, 370  database, 6 menu, 6  High-order polynomial regression, 126–31  ﬁlter bandwidth, 131 peaks, 128 rippling, 128 See also Polynomial regression; Regression  Index  Histogramplot function, 265–67 Histogram plots, 263–65  deﬁned, 370 illustrated, 266, 267 procedure for, 252  H_Mag expression, 84, 87 HSV color speciﬁcation, 252 HUE color speciﬁcation, 252 Hyperlinks, 370  Ifactor function, 370 If...ﬁ construct, 370 Image conversion, 252–72  blue plane, 259, 261 deﬁned, 370 false color, 268–72 green plane, 258, 260 to greyscale, 257–61 normalization, 262–68 red component, viewing, 256 red plane, 258, 260 tools, 252 See also Discrete data processing  Impulse, 371  responses, 231, 238, 290–91, 370 transform, 216 weighted, 370  Impulse-invariant transformation, 222–25  advantages of, 232–33 deﬁned, 222, 389 time constant and, 225 See also Z-transform  Indets function, 371 Inductance, 330, 331 Inﬁx form, 30, 371 Inner product operation, 208 Input pulses, 215 Input step function, 176, 181, 206 Integrate function, 18 Integration trapezoid rule, 226, 371 Intensity  average computation, 109 deﬁned, 371 estimated and actual vs. window  step position, 100, 113 LMA estimated and actual, 121  399   Applied Maple for Engineers and Scientists  Intensity  continued  peak RSD, 103–8 proﬁle, 95  Intersect function, 371 Int function, 371 Inttrans package, 223, 287, 371 Inverse Z transform, 371–72 Invlaplace function, 372 IRIS, 252  color computation, 261 deﬁned, 372  Isode algorithm, 138 Isolate function, 372 Ithprime function, 372  Jordan canonical form, 245–47, 360 Jordan function, 246–47, 372  Kernel, 5, 372  Laplace function, 373 Laplace transform, 41, 61  deﬁned, 373 of delay function, 73 of Fourier approximation, 337 of harmonics, 336 inverse, 62  computing, 176–77 of partial fraction terms, 184  methods, 160 output, 68–69 of step function, 68 of time function, 175 use of, 42  Laplacian output function, 181–82 Laplacian polynomial function, 177 Laplacian transfer function, 179 Last name evaluation, 373 Lcoeﬀ function, 373 Least median squares error  LMSE , 94 Least squares error  LSE , 94 Least squares regression, 98 Levenberg-Marquardt algorithm  LMA ,  96, 114–20  curve ﬁtting, 114–20 deﬁned, 115 estimated and actual intensities, 121  400  optimization, 118 output iteration, 119 regressed estimation model, 119–20 See also Nonlinear regression  Lhs function, 373 Libraries, 5  deﬁned, 373 PLOTS, 96 STATS, 96  Liesymm package, 134, 373 Limit function, 373–74 Linalg package, 242, 374 Linear control system analysis, 173–75 Linear ﬁlters, 272–95  diﬀerencing, 272–75 exponential ﬁltering, 287–95 moving average, 275–81 moving median, 281–87 See also Discrete data processing  Linear regression, 96–114  problem data for, 111–13 sensitivity, 114 using logarithmic representation of  Gaussian model, 96–114  See also Regression  Linear time invariant  LTI  topologies, 41 Line print commands, 105 Line printing, 105–6 Listplot function, 375 Lists, 21–22  converting to square matrix, 255 deﬁned, 375 deﬁning, 21 joining, 22 sets vs., 21 summed elements, 240 testing for, 22 Log function, 375 Looping, 30–33  $, 32–33 for, 30–31 seq, 32–33 terminating, 36 while, 31–32 See also Do loops; For loops Low-pass ﬁlters  LPFs , 39–40   analog design and analysis, 40–70 Butterworth, 40, 47–49, 53–55, 60–63 design iteration for newer  ﬁltering requirements, 64–67  intent of, 60 measurement test setup, 60 order of, 39 second-order, 316 voltage transfer function, 45  LPF_Transfer function, 61  Macsyma, 1 Magnitude response  analog LPF, 49–50 comb ﬁlter, 83  Map2 function, 28, 375 Map function, 28, 236, 375 Maple  as calculator, 9–26 deﬁned, xiii functions, 5 graphical computations, 5 Help database, 6 history of, 5 kernel, 5 library, 5 numerical computations, 5, 9–12 parts of, 6 plots, 249–50 as programmable calculator, 27–36 symbolic computations, 5, 12–15 syntax, 1 tutorial, 5–37 Vr4, 5 worksheet, 5  Mapping functions, 269, 270 Mathematical models, 133–71 dynamic systems, 152–71 ODE tools, 134–44 series methods, 144–52  Matrices, 23–24, 45 Matrixplot function, 256, 375 Mellin function, 4, 375 Member function, 375 Memory, component values in, 55 MESH wrapper, 376  Mgear algorithm, 138 Modal matrix, 347 Moving average, 275–81  advantages, 300 data elements, 275 deﬁned, 275 ﬁlter, 280–81, 367 implementation, 275 output, 296 window size and, 281 See also Linear ﬁlters  Moving_ave function, 277 Moving median, 281–87 advantages, 285, 300 applying, 282 deﬁned, 281 ﬁlter, 285, 367 implementation, 281–85 iterations, 286–87 output, 284, 297 smoothing and, 285 See also Linear ﬁlters  approaches, 120 danger, 120 See also Regression  Nops function, 376 Normal function, 376 Normalization, 262–68  deﬁned, 376 histogram, 267 See also Image conversion  NULL operator, 376 Numer function, 376 Numerical computations  calculator, 9–12 CAS and, 2–3 dsolve function, 135–37 equation solver, 15–16 Maple, 5  Moving_median function, 283–84  Nonlinear ODEs, 165–71  dsolve function and, 166 lower traces kink, 167 See also Ordinary diﬀerential equations  ODEs   Nonlinear regression, 114–20  Index  401   Applied Maple for Engineers and Scientists  Observable canonical form, 247–48, 360 ODE tools, 134–44  alternative numerical solvers, 138 DEtools package, 137–43 diﬀorms package, 143–44 dsolve function, 134–37 liesymm package, 134 See also Mathematical models  Operators, 377–78 Op function, 183, 254, 377 Ordinary diﬀerential equations  ODEs , 134, 377  analytical solution, 377 coupled, 158, 377 ﬁrst-order, 226 initial conditions, 377 nonlinear, 165–71 numerical solution, 377 odeplot, 377 plotter, 139 power series methods, 144 series method solutions, 150 solving, 134–37 time solution, 134 See also ODE tools  Output pulses, 215 Output vectors, 196 Overshoot, 378  Packages  DEtools, 137–44, 364 diﬀorms, 143–44 inttrans, 223, 287, 371 liesymm, 134, 373 linalg, 242, 374 plots, 171, 249, 256, 379 plottools, 249–50, 380  Parameters, 27 Partial diﬀerential equations  PDEs , 134, 378 Partial fraction expansion, 179–94  complex roots, 187–94 deﬁned, 378 inverse Laplace transform of terms, 184 real and distinct roots, 179–81 real and nondistinct roots, 181–86 solution to unit step response, 194 term sums, 185  402  transform breakdown, 194 See also Frequency-domain approach  Peak centers, 83 Peak data point, 126 Peak estimator ﬁlter example, 95–132 Peak picking method, 108 Peak-to-peak ripples, 313  diﬀerential, 323 duty cycle vs., 315 with Fourier method, 340 obtaining, 339 output value computation, 342  Phase-lock loop  PLL , 51 Phase-plane, 378 Phaseportrait function, 140–41, 378 Phase response, 50–53 Piecewise function, 164–65  deﬁned, 378 using, 164  Plot3d function, 249, 379 Plot function, 249, 379 Plots package, 171, 249, 256, 379 Plot structures, 250–52 PLOT3D, 250, 379 PLOT, 250, 379 three-dimensional, 251 two-dimensional, 251  Plotting, 78–80 3-D grid, 78 curve ﬁt, 99–102 damping coeﬃcient change, 167–68 forcing function, 156, 168 periodic voltage output, 306–7 residual error, 99–102, 123  between actual and estimated data, 128 as relative percentage error, 125, 130  Taylor series response, 150 three variable relationship, 330 time-domain output response, 177 twin mass shock absorber, 162–63  Plottools package, 249–50, 380 Pole, 380 POLYGONS wrapper, 380 Polynomial regression, 120–31  curve ﬁt rippling, 123 general, 120–26   high-order, 126–31 maximal intensity, 122 window step positions associated with, 121  Print function, 380 Procedures, 33–34  deﬁned, 380 form of, 33 parameters, 33 pure, 34 terminating, 36 Proc keyword, 380 Product function, 381 Programmable calculator, 27–36  control statements, 29–30 functions, 27–29 looping, 30–33 procedural programming, 33–34 RETURN ERROR and, 36–37 types, 35–36  Pulse transfer function, 215–42  computing, 224 continuous signal transformation, 216–34 deﬁned, 215, 381 of discrete system, 243 time response calculation, 234–42  Pulse width modulator  PWM   controller blocks, 316 drivers, 301, 302–16 input synthesis, 336 input waveform, 302 output voltage plot, 309, 311, 312 signal acquisition, 301 steady-state response, 303 See also Steady-state method  Pure functions, 27–28 Pure procedures, 34  Quadratic polynomial function, 97, 98 Quantization, 381 RC ﬁlters, 40, 302, 303  bandwidth increase, 307 cutoﬀ frequency, 310 low-pass, 308 RC product, 313 Read function, 381 Readlib function, 381  Index  Recurrence relationship, 234–38  deﬁned, 234, 381 generation of, 234 See also Time response calculation  Red plane, 258, 260 Regression  coeﬃcients, 98, 121, 127 errors, 112 estimators, 94 ﬁlter artifacts and, 128 general polynomial, 120–26 improvement by cheating or data stuﬃng, 113–14  least squares, 98 linear, 96–114 for robustness against outlier data, 108–10 starting session, 96  Regressive curve ﬁtting, 95–132 Rejection ratio, 84, 85 Related function, 8, 381 Relative standard deviation  RSD , 103  of curve estimator, 108 estimator capability, 103 measurement, 108 peak intensity, 103–8 uniform behavior, 110 Repetition frequency, 381 Residual error  between estimated and  actual intensity, 124, 128  percent relative, 102, 126 plotting, 99–102, 123 plotting as relative percentage error, 125, 130 window step position vs., 101, 102 Resistor-capacitor ﬁlters. See RC ﬁlters Resulting time series, 215 RETURN, 36–37, 381 Reverse dynamics, 174 RGB color speciﬁcation, 252, 253 Rhs function, 381 Rice clicks, 51 Riche algorithm, 17 Rippling  curve ﬁtting, 123 high-order polynomial, 128 See also Peak-to-peak ripples  403   Applied Maple for Engineers and Scientists  RootOf function, 381 Roots  abstracting and assigning, 190 of characteristic equation, 178 complex, 187–94 frequency-domain, 185 real and distinct, 179–81 real and nondistinct, 181–86  Round function, 263, 382 Rsolve function, 382  Sampled system  illustrated, 214 impulse response, 215  Sample instance, 382 Sampling  with aliasing, 232 in continuous control system, 213 deﬁned, 382 period, 219, 232, 382 rate, 382 without aliasing, 232  Sec function, 382 Select function, 226, 382 Sensitivities  of Butterworth LPF, 56 Butterworth LPF component analysis, 55–57 capacitor functions, 59 for damping factor, 57 Maple computer, 57 Sensitivity function, 56 Seq function, 32–33, 382 Series expansions, 12–13 Series methods, 144–52  accuracy problems, 151 ODE solutions, 150 See also Fourier series; Frobenius series;  Taylor series  Sets, 21–22  deﬁning, 21 joining, 22 lists vs., 21 testing for, 22 Settling time, 383 Shock absorbers  simple model, 152–56  404  twin mass model, 158–65  Short name, 383 Signal separation application, 81 Signal-to-noise ratio  SNR , 63, 314  duty cycles and, 316 relative merit function, 315 relative vs. duty cycle, 317 Similarity transformation, 347 Simple shock absorber, 152–56  forcing function, 153, 156–57 illustrated, 152 motion equation, 153 time response, 155–56 See also Dynamic system modeling; Twin mass  shock absorber  Simplify function, 383 Sin function, 8, 383 Single-shot, 384 Solve function, 59–60, 183, 305, 313, 384 Sort function, 384 Spectrum, 384 S-plane, 382 Sqrt function, 384 Stability, deﬁning, 178 Stable system, 384 Staircase plots, 230, 384 Stared variables, 215, 384 State equation, 345 State matrices, 242–43 State-space  analysis with Maple, 202–10 approach, 200–201 deﬁned, 385 matrices, 384 uses, 209–10  State space equations, 242–48  controllable canonical form, 242–45 jordan canonical form, 245–47 observable canonical form, 247–48 transfer function, 242–48  State transition matrix, 200–210  Cayley-Hamilton theorem, 201 state space analysis, 202–10 See also Time-domain approach  State variables, 195  deﬁned, 384   vector, 208  Stats function, 385 Steady-state method, 302–30  boundary conditions, 304, 305 deﬁned, 385 pulse width modulator driver, 301–16 switching power supply, 316–30 See also Fourier method  Step function, 68 deﬁned, 385 input, 176 unit, 177, 216  Step response, 67–69 Strings, 21 Stuﬃng, 113–14 Sub-matrix, 385 Subs function, 385 Subsop function, 385 Substitution methods, 225–31  bilinear transform, 226–31, 234 numerical solution, 225–26 types of, 225 See also Z-transform  Sum function, 386 Summation, 174 Surfdata function, 171, 386 Switching power supply, 316–30  eﬃciency, 328 initial boundary conditions, 319 models, 320 single buck-type, 316, 317 time-domain forms, 321 See also Steady-state method  Switching topologies, 301–43  Fourier method, 330–43 steady-state method, 302–30 uses, 301  Symbolic computations  calculator, 12–15 CAS and, 3–5 equation solver, 16–17 Maple, 5 Systems, 386 System transfer function, 175  Table function, 386  Index  Tables, 25–26 creating, 25 deﬁned, 25 name evaluation, 26 viewing contents of, 26  Tanh function, 386 Taylor function, 386 Taylor series, 145  accuracy problem, 151 computing, 145 deﬁned, 383 ﬁfth order, 145 generating, 146–49 plotting response, 150 See also Series methods Taylorseries algorithm, 138 Textplot function, 387 TEXT wrapper, 387 Thompson ﬁlters, 69 Time constant, 387 Time-domain  diﬀerential form, 198–99 output responses, 181 responses, 387  Time-domain approach, 194–210 general simulation diagram, 198 response from root expressions, 178–79 state transition matrix, 200–210 system response to unit step function, 177 time-invariant vs. time-variant systems, 195 See also Frequency-domain approach  Time function, 175 Time-invariant systems, 195–200  analysis of, 195–200 time-variant systems vs., 195 See also Time-domain approach Time response calculation, 234–42  direct method, 238–42 recurrence relationship, 234–38 See also Pulse transfer function  Time series data, 387 Transfer function, 73, 187  behavior, 76 continuous, 229 deﬁned, 387 dividing out, 243  405   Applied Maple for Engineers and Scientists  Transfer function  continued   ﬁlter, 288, 289 frequency-domain conversion, 197 Laplace, 197 magnitude, 87 magnitude response, 74 single-to-cascaded ratio, 90 to state space, 242–48 transforming into partial fractions, 222  Transformations  continuous signal, 216–34 impulse-invariant, 222–25 similarity, 347 transfer function into partial fractions, 222  Transition matrix, 201, 206, 247 Trapezoid rule, 226, 371 Triangle waves, approximating, 134 Trigonometric functions, 11–12 Tutorial, 5–37  calculator, 9–26 goal of, 5 Help, 6–9 programmable calculator, 27–36 Twin mass shock absorber, 158–65  coupled ODEs, 158–59 forcing function, 159 illustrated, 158 input step response plot, 162 mass-spring-damper arrangement, 158 See also Dynamic system modeling; Simple  shock absorber  Types, 35–36  checking routines, 35–36 deﬁned, 387 list of, 35  U matrix, 387 Unapply function, 28–29, 387 Unassigned function, 388 Unequal resistance values, 57–60 Union function, 388 Unit circle, 388 Unit step function, 177, 216  calculating, 216 deﬁned, 388 illustrated, 217  406  Unstable system, 388  Vandermonde matrix, 388 Variables, 14–15  abstracting solutions, 45 convention transformed, 228 dummy, 74–75 setting, 14 stared, 215, 384 state, 195, 384 unassigned, 15  Vector function, 388 Vectors, 24–25  matrix array conversion to, 208 output, 196 state variable, 208  Volatility, 388 Voltage-controlled oscillator  VCO , 90  Whattype function, 389 While construct, 31–32, 389 With function, 389 Worksheet, 5, 389 Wrappers, 252  X matrix, 389  Y matrix, 389  Zero, 390 Zip function, 390 Z-plane, 389 Z-transform, 218  built-in function, 221 deﬁned, 390 of diﬀerential equation, 228 direct, 389 for exponential sequence, 219 impulse-invariant, 389 inverse  direct method, 371 long division method, 372  of sin, 220 step invariant, 389 substitution method, 389 of test system, 222 of unit ramp, 220–21 Ztrans function, 221, 390

@highlight

MAPLE is easy-to-use software that performs numerical and symbolic analysis to solve complex mathematical problems. A reference for engineers, scientists, and application developers, it shows you how to tap the full power of MAPLE in solving real-world engineering problems in circuit theory, control theory, curve fitting, mechanics and digital signal processing. The book includes more than 65 figure, 100 equatiions, and accompanying software that includes exercises, MAPLE features and MAPLE subroutines.