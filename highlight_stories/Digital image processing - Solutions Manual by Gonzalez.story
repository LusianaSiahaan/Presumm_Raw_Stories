Digital Image Processing  Second Edition  Instructorzs Manual  Rafael C. Gonzalez Richard E. Woods  Prentice Hall  Upper Saddle River, NJ 07458  www.prenhall.com gonzalezwoods  or  www.imageprocessingbook.com   ii  Revision history  10 9 8 7 6 5 4 3 2 1  Copyright c 1992 2002 by Rafael C. Gonzalez and Richard E. Woods   Preface  This manual contains detailed solutions to all problems in Digital Image Processing, 2nd Edition. We also include a suggested set of guidelines for using the book, and discuss the use of computer projects designed to promote a deeper understanding of the subject matter. The notation used throughout this manual corresponds to the notation used in the text.  The decision of what material to cover in a course rests with the instructor, and it de  pends on the purpose of the course and the background of the students. We have found that the course outlines suggested here can be covered comfortably in the time frames indicated when the course is being taught in an electrical engineering or computer sci  ence curriculum. In each case, no prior exposure to image processing is assumed. We give suggested guidelines for one semester courses at the senior and ﬁrst year graduate levels. It is possible to cover most of the book in a two semester graduate sequence.  The book was completely revised in this edition, with the purpose not only of updating the material, but just as important, making the book a better teaching aid. To this end, the instructor will ﬁnd the new organization to be much more ›exible and better illustrated. Although the book is self contained, we recommend use of the companion web site, where the student will ﬁnd detailed solutions to the problems marked with a star in the text, review material, suggested projects, and images from the book. One of the principal reasons for creating the web site was to free the instructor from having to prepare materials and handouts beyond what is required to teach from the book.  Computer projects such as those described in the web site are an important part of a course on image processing. These projects give the student hands on experience with algorithm implementation and reinforce the material covered in the classroom. The projects suggested at the web site can be implemented on almost any reasonably  equipped multi user or personal computer having a hard copy output device.   1 Introduction  Teaching Features of the Book  The purpose of this chapter is to present suggested guidelines for teaching material from this book at the senior and ﬁrst year graduate level. We also discuss use of the book web site. Although the book is totally self contained, the web site offers, among other things, complementary review material and computer projects that can be assigned in conjunction with classroom work. Detailed solutions to all problems in the book also are included in the remaining chapters of this manual.  Undergraduate programs that offer digital image processing typically limit coverage to one semester. Graduate programs vary, and can include one or two semesters of the ma  terial. In the following discussion we give general guidelines for a one semester senior course, a one semester graduate course, and a full year course of study covering two semesters. We assume a 15 week program per semester with three lectures per week. In order to provide ›exibility for exams and review sessions, the guidelines discussed in the following sections are based on forty, 50 minute lectures per semester. The back  ground assumed on the part of the student is senior level preparation in mathematical analysis, matrix theory, probability, and computer programming.  The suggested teaching guidelines are presented in terms of general objectives, and not as time schedules. There is so much variety in the way image processing material is taught that it makes little sense to attempt a breakdown of the material by class period. In particular, the organization of the present edition of the book is such that it makes it much easier than before to adopt signiﬁcantly different teaching strategies, depending on course objectives and student background. For example, it is possible with the new organization to offer a course that emphasizes spatial techniques and covers little or no transform material. This is not something we recommend, but it is an option that often is attractive in programs that place little emphasis on the signal processing aspects of the ﬁeld and prefer to focus more on the implementation of spatial techniques.   2  Chapter 1 Introduction  The companion web site  One Semester Senior Course  www:prenhall:com=gonzalezwoods  or  www:imageprocessingbook:com  is a valuable teaching aid, in the sense that it includes material that previously was cov  ered in class. In particular, the review material on probability, matrices, vectors, and linear systems, was prepared using the same notation as in the book, and is focused on areas that are directly relevant to discussions in the text. This allows the instructor to assign the material as independent reading, and spend no more than one total lecture pe  riod reviewing those subjects. Another major feature is the set of solutions to problems marked with a star in the book. These solutions are quite detailed, and were prepared with the idea of using them as teaching support. The on line availability of projects and digital images frees the instructor from having to prepare experiments, data, and handouts for students. The fact that most of the images in the book are available for downloading further enhances the value of the web site as a teaching resource.  A basic strategy in teaching a senior course is to focus on aspects of image processing in which both the inputs and outputs of those processes are images. In the scope of a senior course, this usually means the material contained in Chapters 1 through 6. Depending on instructor preferences, wavelets  Chapter 7  usually are beyond the scope of coverage in a typical senior curriculum . However, we recommend covering at least some material on image compression  Chapter 8  as outlined below.  We have found in more than two decades of teaching this material to seniors in electrical engineering, computer science, and other technical disciplines, that one of the keys to success is to spend at least one lecture on motivation and the equivalent of one lecture on review of background material, as the need arises. The motivational material is provided in the numerous application areas discussed in Chapter 1. This chapter was totally rewritten with this objective in mind. Some of this material can be covered in class and the rest assigned as independent reading. Background review should cover probability theory  of one random variable  before histogram processing  Section 3.3 . A brief review of vectors and matrices may be required later, depending on the material covered. The review material included in the book web site was designed for just this purpose.   One Semester Senior Course 3  Chapter 2 should be covered in its entirety. Some of the material  such as parts of Sections 2.1 and 2.3  can be assigned as independent reading, but a detailed explanation of Sections 2.4 through 2.6 is time well spent.  Chapter 3 serves two principal purposes. It covers image enhancement  a topic of signif  icant appeal to the beginning student  and it introduces a host of basic spatial processing tools used throughout the book. For a senior course, we recommend coverage of Sec  tions 3.2.1 through 3.2.2u Section 3.3.1u Section 3.4u Section 3.5u Section 3.6u Section 3.7.1, 3.7.2  through Example 3.11 , and 3.7.3. Section 3.8 can be assigned as indepen  dent reading, depending on time.  Chapter 4 also discusses enhancement, but from a frequency domain point of view. The instructor has signiﬁcant ›exibility here. As mentioned earlier, it is possible to skip the chapter altogether, but this will typically preclude meaningful coverage of other areas based on the Fourier transform  such as ﬁltering and restoration . The key in covering the frequency domain is to get to the convolution theorem and thus develop a tie between the frequency and spatial domains. All this material is presented in very readable form in Section 4.2. Light} coverage of frequency domain concepts can be based on discussing all the material through this section and then selecting a few simple ﬁltering examples  say, low  and highpass ﬁltering using Butterworth ﬁlters, as discussed in Sections 4.3.2 and 4.4.2 . At the discretion of the instructor, additional material can include full coverage of Sections 4.3 and 4.4. It is seldom possible to go beyond this point in a senior course.  Chapter 5 can be covered as a continuation of Chapter 4. Section 5.1 makes this an easy approach. Then, it is possible give the student a ›avor} of what restoration is  and still keep the discussion brief  by covering only Gaussian and impulse noise in Section 5.2.1, and a couple of spatial ﬁlters in Section 5.3. This latter section is a frequent source of confusion to the student who, based on discussions earlier in the chapter, is expecting to see a more objective approach. It is worthwhile to emphasize at this point that spatial enhancement and restoration are the same thing when it comes to noise reduction by spatial ﬁltering. A good way to keep it brief and conclude coverage of restoration is to jump at this point to inverse ﬁltering  which follows directly from the model in Section 5.1  and show the problems with this approach. Then, with a brief explanation regarding the fact that much of restoration centers around the instabilities inherent in inverse ﬁltering, it is possible to introduce the interactive} form of the Wiener ﬁlter in Eq.  5.8 3  and conclude the chapter with Examples 5.12 and 5.13.  Chapter 6 on color image processing is a new feature of the book. Coverage of this   4  Chapter 1 Introduction  One Semester Graduate Course  No Background in DIP   chapter also can be brief at the senior level by focusing on enough material to give the student a foundation on the physics of color  Section 6.1 , two basic color models  RGB and CMY CMYK , and then concluding with a brief coverage of pseudocolor processing  Section 6.3 .  We typically conclude a senior course by covering some of the basic aspects of image compression  Chapter 8 . Interest on this topic has increased signiﬁcantly as a result of the heavy use of images and graphics over the Internet, and students usually are easily motivated by the topic. Minimum coverage of this material includes Sections 8.1.1 and 8.1.2, Section 8.2, and Section 8.4.1. In this limited scope, it is worthwhile spending one half of a lecture period ﬁlling in any gaps that may arise by skipping earlier parts of the chapter.  The main difference between a senior and a ﬁrst year graduate course in which neither group has formal background in image processing is mostly in the scope of material covered, in the sense that we simply go faster in a graduate course, and feel much freer in assigning independent reading. In addition to the material discussed in the previous section, we add the following material in a graduate course.  Coverage of histogram matching  Section 3.3.2  is added. Sections 4.3, 4.4, and 4.5 are covered in full. Section 4.6 is touched upon brie›y regarding the fact that imple  mentation of discrete Fourier transform techniques requires non intuitive concepts such as function padding. The separability of the Fourier transform should be covered, and mention of the advantages of the FFT should be made. In Chapter 5 we add Sections 5.5 through 5.8. In Chapter 6 we add the HSI model  Section 6.3.2  , Section 6.4, and Sec  tion 6.6. A nice introduction to wavelets  Chapter 7  can be achieved by a combination of classroom discussions and independent reading. The minimum number of sections in that chapter are 7.1, 7.2, 7.3, and 7.5, with appropriate  but brief  mention of the exis  tence of fast wavelet transforms. Finally, in Chapter 8 we add coverage of Sections 8.3, 8.4.2, 8.5.1  through Example 8.16 , Section 8.5.2  through Example 8.20  and Section 8.5.3.  If additional time is available, a natural topic to cover next is morphological image processing  Chapter 9 . The material in this chapter begins a transition from methods whose inputs and outputs are images to methods in which the inputs are images, but the outputs are attributes about those images, in the sense deﬁned in Section 1.1. We   One Semester Graduate Course  with Background in DIP   5  recommend coverage of Sections 9.1 through 9.4, and some of the algorithms in Section 9.5.  One Semester Graduate Course  with Background in DIP   Some programs have an undergraduate course in image processing as a prerequisite to a graduate course on the subject. In this case, it is possible to cover material from the ﬁrst eleven chapters of the book. Using the undergraduate guidelines described above, we add the following material to form a teaching outline for a one semester graduate course that has that undergraduate material as prerequisite. Given that students have the appropriate background on the subject, independent reading assignments can be used to control the schedule.  Coverage of histogram matching  Section 3.3.2  is added. Sections 4,3, 4.4, 4.5, and 4.6 are added. This strengthens the studentzs background in frequency domain concepts. A more extensive coverage of Chapter 5 is possible by adding sections 5.2.3, 5.3.3, 5.4.3, 5.5, 5.6, and 5.8. In Chapter 6 we add full color image processing  Sections 6.4 through 6.7 . Chapters 7 and 8 are covered as in the previous section. As noted in the previous section, Chapter 9 begins a transition from methods whose inputs and outputs are images to methods in which the inputs are images, but the outputs are attributes about those images. As a minimum, we recommend coverage of binary morphology: Sections 9.1 through 9.4, and some of the algorithms in Section 9.5. Mention should be made about possible extensions to gray scale images, but coverage of this material may not be possible, depending on the schedule. In Chapter 10, we recommend Sections 10.1, 10.2.1 and 10.2.2, 10.3.1 through 10.3.4, 10.4, and 10.5. In Chapter 11we typically cover Sections 11.1 through 11.4.  Two Semester Graduate Course  No Background in DIP   A full year graduate course consists of the material covered in the one semester under  graduate course, the material outlined in the previous section, and Sections 12.1, 12.2, 12.3.1, and 12.3.2.  Projects  One of the most interesting aspects of a course in digital image processing is the pictorial   6  Chapter 1 Introduction  nature of the subject. It has been our experience that students truly enjoy and beneﬁt from judicious use of computer projects to complement the material covered in class. Since computer projects are in addition to course work and homework assignments, we try to keep the formal project reporting as brief as possible. In order to facilitate grading, we try to achieve uniformity in the way project reports are prepared. A useful report format is as follows:  Page 1: Cover page.  ¢ Project title ¢ Project number ¢ Course number ¢ Studentzs name ¢ Date due ¢ Date handed in ¢ Abstract  not to exceed 1 2 page   Page 2: One to two pages  max  of technical discussion.  Page 3  or 4 : Discussion of results. One to two pages  max .  Results: Image results  printed typically on a laser or inkjet printer . All images must contain a number and title referred to in the discussion of results.  Appendix: Program listings, focused on any original code prepared by the student. For brevity, functions and routines provided to the student are referred to by name, but the code is not included.  Layout: The entire report must be on a standard sheet size  e.g., 8:5 £ 11 inches , stapled with three or more staples on the left margin to form a booklet, or bound using clear plastic standard binding products.  Project resources available in the book web site include a sample project, a list of sug  gested projects from which the instructor can select, book and other images, and MAT  LAB functions. Instructors who do not wish to use MATLAB will ﬁnd additional soft  ware suggestions in the Support Software section of the web site.   2 Problem Solutions  Problem 2.1  =  The diameter, x, of the retinal image corresponding to the dot is obtained from similar triangles, as shown in Fig. P2.1. That is,  d=2  0:2   x=2  0:014  which gives x = 0:07d. From the discussion in Section 2.1.1, and taking some liberties of interpretation, we can think of the fovea as a square sensor array having on the order of 337,000 elements, which translates into an array of size 580 £ 580 elements. Assuming equal spacing between elements, this gives 580 elements and 579 spaces on a line 1.5 mm long. The size of each element and each space is then s = [ 1:5mm =1; 159] = 1:3£ 10¡6 m. If the size  on the fovea  of the imaged dot is less than the size of a single resolution element, we assume that the dot will be invisible to the eye. In other words, the eye will not detect a dot if its diameter, d, is such that 0:07 d  < 1:3 £ 10¡6 m, or d < 18:6 £ 10¡6 m.  Figure P2.1   8  Chapter 2 Problem Solutions  Problem 2.2  Brightness adaptation.  Problem 2.3  Problem 2.4  Problem 2.5  Problem 2.6  ¸ = c=v = 2:998 £ 108 m s =60 1 s  = 4:99 £ 106m = 5000 Km.   a  From the discussion on the electromagnetic spectrum in Section 2.2, the source of the illumination required to see an object must have wavelength the same size or smaller than the object. Because interest lies only on the boundary shape and not on other spec  tral characteristics of the specimens, a single illumination source in the far ultraviolet  wavelength of .001 microns or less  will be able to detect all objects. A far ultraviolet camera sensor would be needed to image the specimens.  b  No answer required since the answer to  a  is afﬁrmative.  From the geometry of Fig. 2.3, 7mm=35mm= z=500mm, or z = 100 mm. So the target size is 100 mm on the side. We have a total of 1024 elements per line, so the resolution of 1 line is 1024=100 = 10 elements mm. For line pairs we divide by 2, giving an answer of 5 lp mm.  One possible solution is to equip a monochrome camera with a mechanical device that sequentially places a red, a green, and a blue pass ﬁlter in front of the lens. The strongest camera response determines the color. If all three responses are approximately equal, the object is white. A faster system would utilize three different cameras, each equipped with an individual ﬁlter. The analysis would be then based on polling the response of each camera. This system would be a little more expensive, but it would be faster and more reliable. Note that both solutions assume that the ﬁeld of view of the camera s  is such that it is completely ﬁlled by a uniform color [i.e., the camera s  is are  focused on   Problem 2.7  a part of the vehicle where only its color is seen. Otherwise further analysis would be required to isolate the region of uniform color, which is all that is of interest in solving this problem].  Problem 2.7 9  The image in question is given by  f  x; y  = i x; y r x; y   = 255e¡[ x¡x0 2+ y¡y0 2] 1:0  = 255e¡[ x¡x0 2+ y¡y0 2]  A cross section of the image is shown in Fig. P2.7 a . If the intensity is quantized using m bits, then we have the situation shown in Fig. P2.7 b , where 4G =  255 + 1 =2m. Since an abrupt change of 8 gray levels is assumed to be detectable by the eye, it follows that 4G = 8 = 256=2m, or m = 5. In other words, 32, or fewer, gray levels will produce visible false contouring.  Figure P2.7   10  Chapter 2 Problem Solutions  Problem 2.8  The use of two bits  m = 2  of intensity resolution produces four gray levels in the range 0 to 255. One way to subdivide this range is to let all levels between 0 and 63 be coded as 63, all levels between 64 and 127 be coded as 127, and so on. The image resulting from this type of subdivision is shown in Fig. P2.8. Of course, there are other ways to subdivide the range [0; 255] into four bands.  Figure P2.8  Problem 2.9  Problem 2.10   a  The total amount of data  including the start and stop bit  in an 8 bit, 1024 £ 1024 image, is  1024 2 £ [8 + 2] bits. The total time required to transmit this image over a At 56K baud link is  1024 2 £ [8 + 2]=56000 = 187:25 sec or about 3.1 min.  b  At 750K this time goes down to about 14 sec.  The width to height ratio is 16 9 and the resolution in the vertical direction is 1125 lines It is given that the  or, what is the same thing, 1125 pixels in the vertical direction .   Problem 2.11 11  resolution in the horizontal direction is in the 16 9 proportion, so the resolution in the vertical direction is  1125 £  16=9  = 2000 pixels per line. The system paints} a full 1125£ 2000, 8 bit image every 1 30 sec for each of the red, green, and blue component images. There are 7200 sec in two hours, so the total digital data generated in this time interval is  1125  2000  8  30  3  7200  = 1:166 £ 1013 bits, or 1:458 £ 1012 bytes  i.e., about 1.5 terrabytes . These ﬁgures show why image data compression  Chapter 8  is so important.  Let p and q be as shown in Fig. P2.11. Then,  a  S1 and S2 are not 4 connected because q is not in the set N4 p u  b  S1 and S2 are 8 connected because q is in the set N8 p u  c  S1 and S2 are m connected because  i  q is in ND p , and  ii  the set N4 p  \ N4 q  is empty.  Figure P2.11  The solution to this problem consists of deﬁning all possible neighborhood shapes to go from a diagonal segment to a corresponding 4 connected segment, as shown in Fig. P2.12. The algorithm then simply looks for the appropriate match every time a diagonal segment is encountered in the boundary.  The solution to this problem is the same as for Problem 2.12 because converting from an m connected path to a 4 connected path simply involves detecting diagonal segments and converting them to the appropriate 4 connected segment.  Problem 2.11  Problem 2.12  Problem 2.13   12  Chapter 2 Problem Solutions  Figure P2.12  Problem 2.14  Problem 2.15  A region R of an image is composed of a set of connected points in the image. The boundary of a region is the set of points that have one or more neighbors that are not in R. Because boundary points also are part of R, it follows that a point on the boundary has at least one neighbor in R and at least one neighbor not in R.  If the point in the boundary did not have a neighbor in R, the point would be disconnected from R, which violates the deﬁnition of points in a region.  Since all points in R are part of a connected component  see Section 2.5.2 , all points in the boundary are also connected and a path  entirely in R  exists between any two points on the boundary. Thus the boundary forms a closed path.   a  When V = f0; 1g, 4 path does not exist between p and q because it is impossible to get from p to q by traveling along points that are both 4 adjacent and also have values from V . Figure P2.15 a  shows this conditionu it is not possible to get to q. The shortest 8 path is shown in Fig. P2.15 b u its length is 4. The length of the shortest m  path  b  One  shown dashed  is 5. Both of these shortest paths are unique in this case.   Problem 2.16 13  possibility for the shortest 4 path when V = f1; 2g is shown in Fig. P2.15 c u its length is 6. It is easily veriﬁed that another 4 path of the same length exists between p and q. One possibility for the shortest 8 path  it is not unique  is shown in Fig. P2.15 d u its length is 4. The length of a shortest m path  shown dashed  is 6. This path is not unique.  Figure P2.15  Problem 2.16   a  A shortest 4 path between a point p with coordinates  x; y  and a point q with coor  dinates  s; t  is shown in Fig. P2.16, where the assumption is that all points along the path are from V . The length of the segments of the path are jx ¡ sj and jy ¡ tj, respec  tively. The total path length is jx ¡ sj + jy ¡ tj, which we recognize as the deﬁnition of the D4 distance, as given in Eq.  2.5 16 .  Recall that this distance is independent of any paths that may exist between the points.  The D4 distance obviously is equal to the length of the shortest 4 path when the length of the path is jx ¡ sj + jy ¡ tj. This oc  curs whenever we can get from p to q by following a path whose elements  1  are from V; and  2  are arranged in such a way that we can traverse the path from p to q by mak  ing turns in at most two directions  e.g., right and up .  b  The path may of may not be unique, depending on V and the values of the points along the way.   14  Chapter 2 Problem Solutions  Figure P2.16  Problem 2.17  Problem 2.18   a  The D8 distance between p and q  see Fig. P2.16  is deﬁned as max  jx ¡ sj ; jy ¡ tj . Recall that the D8 distance  unlike the Euclidean distance  counts diagonal segments the same as horizontal and vertical segments, and, as in the case of the D4 distance, is inde  pendent of whether or not a path exists between p and q. As in the previous problem, the shortest 8 path is equal to the D8 distance when the path length is max  jx ¡ sj ; jy ¡ tj . This occurs when we can get from p to q by following a path whose elements  1  are from V , and  2  are arranged in such a way that we can traverse the path from p to q by by traveling diagonally in only one direction and, whenever diagonal travel is not possi  ble, by making turns in the horizontal or vertical  but not both  direction.  b  The path may of may not be unique, depending on V and the values of the points along the way.  With reference to Eq.  2.6 1 , let H denote the neighborhood sum operator, let S1 and S2 denote two different small subimage areas of the same size, and let S1 +S2 denote the corresponding pixel by pixel sum of the elements in S1 and S2, as explained in Section 2.5.4. Note that the size of the neighborhood  i.e., number of pixels  is not changed by this pixel by pixel sum. The operator H computes the sum of pixel values is a given neighborhood. Then, H aS1 + bS2  means:  1  multiplying the pixels in each of the subimage areas by the constants shown,  2  adding the pixel by pixel values from S1 and S2  which produces a single subimage area , and  3  computing the sum of the values of all the pixels in that single subimage area. Let ap1 and bp2 denote two arbitrary  but   Problem 2.19  Problem 2.20  corresponding  pixels from aS1 + bS2. Then we can write  H aS1 + bS2  =  Problem 2.19 15  ap1 + bp2  Xp12S1 and p22S2 = Xp12S1 ap1 + Xp22S2 p1 + b Xp22S2 = a Xp12S1  = aH S1  + bH S2   bp2  p2  which, according to Eq.  2.6 1 , indicates that H is a linear operator.  The median, ³, of a set of numbers is such that half the values in the set are below ³ and the other half are above it. A simple example will sufﬁce to show that Eq.  2.6 1  is vi  olated by the median operator. Let S1 = f1;¡2; 3g, S2 = f4; 5; 6g, and a = b = 1. In this case H is the median operator. We then have H S1 + S2  =medianf5; 3; 9g = 5, where it is understood that S1 + S2 is the element by corresponding element sum of S1 and S2. Next, we compute H S1  = medianf1; ¡2; 3g = 1 and H S2  = medianf4; 5; 6g = 5. Then, since H aS1 + bS2  6= aH S1  + bH S2 , it follows that Eq.  2.6 1  is violated and the median is a nonlinear operator.  The geometry of the chips is shown in Fig. P2.20 a . From Fig. P2.20 b  and the geometry in Fig. 2.3, we know that  ¢x =  ¸ £ 80 ¸ ¡ z  where ¢x is the side dimension of the image  assumed square since the viewing screen is square  impinging on the image plane, and the 80 mm refers to the size of the viewing screen, as described in the problem statement. The most inexpensive solution will result from using a camera of resolution 512£ 512. Based on the information in Fig. P2.20 a , a CCD chip with this resolution will be of size  16¹  £  512  = 8 mm on each side. Substituting ¢x = 8 mm in the above equation gives z = 9¸ as the relationship between the distance z and the focal length of the lens, where a minus sign was ignored because it is just a coordinate inversion. If a 25 mm lens is used, the front of the lens will have to be located at approximately 225 mm from the viewing screen so that the size of the   16  Chapter 2 Problem Solutions  image of the screen projected onto the CCD image plane does not exceed the 8 mm size of the CCD chip for the 512 £ 512 camera. This value for z is reasonable, but it is obvious that any of the other given lens sizes would work alsou the camera would just have to be positioned further away.  Figure P2.20  Assuming a 25 mm lens, the next issue is to determine if the smallest defect will be imaged on, at least, a 2 £ 2 pixel area, as required by the speciﬁcation. It is given that the defects are circular, with the smallest defect having a diameter of 0.8 mm. So, all that needs to be done is to determine if the image of a circle of diameter 0.8 mm or greater will, at least, be of size 2£ 2 pixels on the CCD imaging plane. This can be determined by using the same model as in Fig. P2.20 b  with the 80 mm replaced by 0.8 mm. Using ¸ = 25 mm and z = 225 mm in the above equation yields ¢x = 100 ¹. In other words, a circular defect of diameter 0.8 mm will be imaged as a circle with a diameter of 100 ¹ on the CCD chip of a 512 £ 512 camera equipped with a 25 mm lens and which views the defect at a distance of 225 mm.  If, in order for a CCD receptor to be activated, its area has to be excited in its entirety, then, it can be seen from Fig. P2.20 a  that to guarantee that a 2 £ 2 array of such receptors will be activated, a circular area of diameter no less than  6  8  = 48 ¹ has to be imaged onto the CCD chip. The smallest defect is imaged as a circle with diameter of 100 ¹, which is well above the 48 ¹ minimum requirement.  Thus, it is concluded that a CCD camera of resolution 512 £ 512 pixels, using a 25 mm lens and imaging the viewing screen at a distance of 225 mm, is sufﬁcient to solve the problem posed by the plant manager.   3 Problem Solutions  Problem 3.1   a  General form: s = T  r  = Ae¡Kr2. For the condition shown in the problem ﬁgure, Ae¡KL2  0 = A=2. Solving for K yields ¡KL2  0 = ln 0:5  K = 0:693=L2 0:  Then,  s = T  r  = Ae¡ 0:693  L2 0  r2  :   b  General form: s = T  r  = B 1 ¡ e¡Kr2 ﬁgure, B 1 ¡ e¡KL2  0   = B=2. The solution for K is the same as in  a , so   . For the condition shown in the problem  s = T  r  = B 1 ¡ e¡ 0:693  L2 0  r2      c  General form: s = T  r  =  D ¡ C  1 ¡ e¡Kr2    + C.  Problem 3.2   a  s = T  r  =  1  1+ m=r E .   b  See Fig. P3.2.   c  We want the value of s to be 0 for r   m. When r = m, s = 1=2. But, because the values of r are integers, the behavior we want is  s = T  r  =8> :  0:0 0:5 1:0  when r · m ¡ 1 when r = m when r ¸ m + 1:  The question in the problem statement is to ﬁnd the smallest value of E that will make the threshold behave as in the equation above. When r = m, we see from  a  that s = 0:5, regardless of the value of E. If C is the smallest positive number representable   18  Chapter 3 Problem Solutions  in the computer, and keeping in mind that s is positive, then any value of s less than C=2 will be called 0 by the computer. To ﬁnd out the smallest value of E for which this happens, simply solve the following equation for E, using the given value m = 128:  1  1 + [m= m ¡ 1 ]E < C=2:  Because the function is symmetric about m, the resulting value of E will yield s = 1 for r ¸ m + 1.  Problem 3.3  Figure P3.2  The transformations required to produce the individual bit planes are nothing more than mappings of the truth table for eight binary variables. In this truth table, the values of the 7th bit are 0 for byte values 0 to 127, and 1 for byte values 128 to 255, thus giving the transformation mentioned in the problem statement. Note that the given transformed values of either 0 or 255 simply indicate a binary image for the 7th bit plane. Any other two values would have been equally valid, though less conventional.   Problem 3.4 19  Continuing with the truth table concept, the transformation required to produce an image of the 6th bit plane outputs a 0 for byte values in the range [0, 63], a 1 for byte values in the range [64, 127], a 0 for byte values in the range [128, 191], and a 1 for byte values in the range [192, 255]. Similarly, the transformation for the 5th bit plane alternates between eight ranges of byte values, the transformation for the 4th bit plane alternates between 16 ranges, and so on. Finally, the output of the transformation for the 0th bit plane alternates between 0 and 255 depending as the byte values are even or odd. Thus, this transformation alternates between 128 byte value ranges, which explains why an image of the 0th bit plane is usually the busiest looking of all the bit plane images.   a  The number of pixels having different gray level values would decrease, thus causing the number of components in the histogram to decrease. Since the number of pixels would not change, this would cause the height some of the remaining histogram peaks to increase in general. Typically, less variability in gray level values will reduce contrast.  b  The most visible effect would be signiﬁcant darkening of the image. For example, dropping the highest bit would limit to 127 the brightest level in an 8 bit image. Since the number of pixels would remain constant, the height of some of the histogram peaks would increase. The general shape of the histogram would now be taller and narrower, with no histogram components being located past 127.  All that histogram equalization does is remap histogram components on the intensity scale. To obtain a uniform  ›at  histogram would require in general that pixel intensities be actually redistributed so that there are L groups of n=L pixels with the same intensity, where L is the number of allowed discrete intensity levels and n is the total number of pixels in the input image. The histogram equalization method has no provisions for this type of  artiﬁcial  redistribution process.  Let n be the total number of pixels and let nrj be the number of pixels in the input image  Problem 3.4  Problem 3.5  Problem 3.6   20  Chapter 3 Problem Solutions  Problem 3.7  with intensity value rj. Then, the histogram equalization transformation is  sk = T  rk  =  nrj =n =  nrj :  kXj=0  1 n  kXj=0  Since every pixel  and no others  with value rk is mapped to value sk, it follows that nsk = nrk. A second pass of histogram equalization would produce values vk according to the transformation  But, nsj = nrj , so  vk = T  sk  =  nsj :  1 n  kXj=0 kXj=0  1 n  vk = T  sk  =  nrj = sk  which shows that a second pass of histogram equalization would yield the same result as the ﬁrst pass. We have assumed negligible round off errors.  The general histogram equalization transformation function is  s = T  r  =  pr w  dw:  rZ0  There are two important points to which the student must show awareness in answer  ing this problem. First, this equation assumes only positive values for r. However, the Gaussian density extends in general from ¡1 to 1. Recognition of this fact is impor  tant. Once recognized, the student can approach this difﬁculty in several ways. One good answer is to make some assumption, such as the standard deviation being small enough so that the area of the curve under pr r  for negative values of r is negligible. Another is to scale up the values until the area under the negative tail is negligible. The second major point is to recognize is that the transformation function itself,  s = T  r  =  e¡  w¡m 2  2¾2 dw  1  p2¼¾  rZ0  has no closed form solution. This is the cumulative distribution function of the Gaussian density, which is either integrated numerically, or its values are looked up in a table. A third, less important point, that the student should address is the high end values of r. Again, the Gaussian PDF extends to +1. One possibility here is to make the same   Problem 3.8 21  assumption as above regarding the standard deviation. Another is to divide by a large enough value so that the area under the positive tail past that point is negligible  this scaling reduces the standard deviation .  Another principal approach the student can take is to work with histograms, in which case the transformation function would be in the form of a summation. The issue of negative and high positive values must still be addressed, and the possible answers suggested above regarding these issues still apply. The student needs to indicate that the histogram is obtained by sampling the continuous function, so some mention should be made regarding the number of samples  bits  used. The most likely answer is 8 bits, in which case the student needs to address the scaling of the function so that the range is [0; 255].  We are interested in just one example in order to satisfy the statement of the problem. Consider the probability density function shown in Fig. P3.8 a . A plot of the trans  formation T  r  in Eq.  3.3 4  using this particular density function is shown in Fig. P3.8 b . Because pr r  is a probability density function we know from the discussion in Section 3.3.1 that the transformation T  r  satisﬁes conditions  a  and  b  stated in that section. However, we see from Fig. P3.8 b  that the inverse transformation from s back to r is not single valued, as there are an inﬁnite number of possible mappings from s = 1=2 back to r. It is important to note that the reason the inverse transformation function turned out not to be single valued is the gap in pr r  in the interval [1=4; 3=4].   a  We need to show that the transformation function in Eq.  3.3 8  is monotonic, single  valued, and that its values are in the range [0, 1]. From Eq.  3.3 8 ,  sk = T  rk  =  pr rj   kXj=0  =  nj n  kXj=0  k = 0; 1; : : : ; L ¡ 1:  Because all the pr rj  are positive, it follows that T  rk  is monotonic. Because all the pr rj  are ﬁnite, and the limit of summation is ﬁnite, it follows that T  rk  is of ﬁnite  Problem 3.8  Problem 3.9   22  Chapter 3 Problem Solutions  slope and thus us a single valued function. Finally, since the sum of all the pr rj  is 1, it follows that 0 · sk · 1:  Figure P3.8.   b  From the discussion in Problem 3.8, it follows that if an image has missing gray levels the histogram equalization transformation function given above will be constant in the interval of the missing gray levels. Thus, in theory, the inverse mapping will not be single valued in the discrete case either. In practice, assuming that we wanted to perform the inverse transformation, this is not important for the following reason: Assume that no gray level values exist in the open interval  a; b , so that ra is the last gray level before the empty gray level band begins and rb is the ﬁrst gray level right after the empty band ends. The corresponding mapped gray levels are sa and sb. The fact that no gray levels r exist in interval  a; b  means that no gray levels will exist between sa and sb either, and, therefore, there will be no levels s to map back to r in the bands where the multi valued inverse function would present problems. Thus, in practice, the issue of the inverse not being single valued is not an issue since it would not be needed. Note that mapping back from sa and sb presents no problems, since T  ra  and T  rb   and thus their inverses  are different. A similar discussion applies if there are more than one band empty of gray levels.   Problem 3.10  Problem 3.11   c  If none of the gray levels rk; k = 1; 2; : : : ; L ¡ 1; are 0, then T  rk  will be strictly monotonic. This implies that the inverse transformation will be of ﬁnite slope and this will be single valued.  Problem 3.10 23  First, we obtain the histogram equalization transformation:  s = T  r  =  pr w  dw =   ¡2w + 2  dw = ¡r2 + 2r:  rZ0  rZ0  v = G z  =  2w dw = z2:  Next we ﬁnd  Finally,  pz w  dw =  zZ0 zZ0 z = G¡1 v  = §pv:  z =p¡r2 + 2r:  But only positive gray levels are allowed, so z = pv. Then, we replace v with s, which in turn is ¡r2 + 2r, and we have  The value of the histogram component corresponding to the kth intensity level in a neigh  borhood is  pr rk  =  nk n  for k = 1; 2; : : : ; K ¡ 1;where nk is the number of pixels having gray level value rk, n is the total number of pixels in the neighborhood, and K is the total number of possible gray levels. Suppose that the neighborhood is moved one pixel to the right. This deletes the leftmost column and introduces a new column on the right. The updated histogram then becomes  p0r rk  =  1 n  [nk ¡ nLk + nRk]  for k = 0; 1; : : : ; K ¡ 1, where nLk is the number of occurrences of level rk on the left column and nRk is the similar quantity on the right column. The preceding equation can   24  Chapter 3 Problem Solutions  be written also as  Problem 3.12  for k = 0; 1; : : : ; K ¡ 1: The same concept applies to other modes of neighborhood motion:  p0r rk  = pr rk  +  1 n  [nRk ¡ nLk ]  p0r rk  = pr rk  +  1 n  [bk ¡ ak]  for k = 0; 1; : : : ; K ¡ 1, where ak is the number of pixels with value rk in the neighbor  hood area deleted by the move, and bk is the corresponding number introduced by the move.  The purpose of this simple problem is to make the student think of the meaning of his  tograms and arrive at the conclusion that histograms carry no information about spatial properties of images. Thus, the only time that the histogram of the images formed by the operations shown in the problem statement can be determined in terms of the orig  inal histograms is when one or both of the images is  are  constant. In  d  we have the additional requirement that none of the pixels of g x; y  can be 0. Assume for convenience that the histograms are not normalized, so that, for example, hf  rk  is the number of pixels in f  x; y  having gray level rk, assume that all the pixels in g x; y  have constant value c. The pixels of both images are assumed to be positive. Finally, let uk denote the gray levels of the pixels of the images formed by any of the arithmetic operations given in the problem statement. Under the preceding set of conditions, the histograms are determined as follows:   a  The histogram hsum uk  of the sum is obtained by letting uk = rk+c; and hsum uk  = hf  rk  for all k. In other words, the values  height  of the components of hsum are the same as the components of hf , but their locations on the gray axis are shifted right by an amount c.   b  Similarly, the histogram hdiff uk  of the difference has the same components as hf but their locations are moved left by an amount c as a result of the subtraction operation.   c  Following the same reasoning, the values  heights  of the components of histogram hprod uk  of the product are the same as hf , but their locations are at uk = c£ rk. Note that while the spacing between components of the resulting histograms in  a  and  b  was not affected, the spacing between components of hprod uk  will be spread out by an amount c.   Problem 3.13  Problem 3.13 25   d  Finally, assuming that c 6= 0, the components of hdiv uk  are the same as those of hf , but their locations will be at uk = rk=c. Thus, the spacing between components of hdiv uk  will be compressed by an amount equal to 1=c.  The preceding solutions are applicable if image f x; y  also is constant. In this case the four histograms just discussed would each have only one component. Their location would be affected as described  a  through  c .  Using 10 bits  with one bit being the sign bit  allows numbers in the range ¡511 to 511. The process of repeated subtractions can be expressed as  dK x; y  = a x; y  ¡  b x; y   = a x; y  ¡ K £ b x; y   KXk=1  where K is the largest value such that dK x; y  does not exceed ¡511 at any coordinates  x; y , at which time the subtraction process stops. We know nothing about the images, only that both have values ranging from 0 to 255. Therefore, all we can determine are the maximum and minimum number of times that the subtraction can be carried out and the possible range of gray level values in each of these two situations.  Because it is given that g x; y  has at least one pixel valued 255, the maximum value that K can have before the subtraction exceeds ¡511 is 3. This condition occurs when, at some pair of coordinates  s; t , a s; t  = b s; t  = 255. In this case, the possible range of values in the difference image is  510 to 255. The latter condition can occur if, at some pair of coordinates  i; j , a i; j  = 255 and b i; j  = 0.  The minimum value that K will have is 2, which occurs when, at some pair of coordi  nates, a s; t  = 0 and b s; t  = 255. In this case, the possible range of values in the difference image again is ¡510 to 255. The latter condition can occur if, at some pair of coordinates  i; j , a i; j  = 255 and b i; j  = 0.  Problem 3.14  Let g x; y  denote the golden image, and let f  x; y  denote any input image acquired during routine operation of the system. Change detection via subtraction is based on computing the simple difference d x; y  = g x; y  ¡ f  x; y . The resulting image   26  Chapter 3 Problem Solutions  d x; y  can be used in two fundamental ways for change detection. One way is use a pixel by pixel analysis. In this case we say that f  x; y  is }close enough} to the golden image if all the pixels in d x; y  fall within a speciﬁed threshold band [Tmin; Tmax] where Tmin is negative and Tmax is positive. Usually, the same value of threshold is used for both negative and positive differences, in which case we have a band [¡T; T ] in which all pixels of d x; y  must fall in order for f  x; y  to be declared acceptable. The second major approach is simply to sum all the pixels in jd x; y j and compare the sum against a threshold S. Note that the absolute value needs to be used to avoid errors cancelling out. This is a much cruder test, so we will concentrate on the ﬁrst approach.  There are three fundamental factors that need tight control for difference based inspec  tion to work:  1  proper registration,  2  controlled illumination, and  3  noise levels that are low enough so that difference values are not affected appreciably by variations due to noise. The ﬁrst condition basically addresses the requirement that comparisons be made between corresponding pixels. Two images can be identical, but if they are displaced with respect to each other, comparing the differences between them makes no sense. Often, special markings are manufactured into the product for mechanical or image based alignment  Controlled illumination  note that illumination} is not limited to visible light  obviously is important because changes in illumination can affect dramatically the values in a difference image. One approach often used in conjunction with illumination control is intensity scaling based on actual conditions. For example, the products could have one or more small patches of a tightly controlled color, and the intensity  and perhaps even color  of each pixels in the entire image would be modiﬁed based on the actual versus expected intensity and or color of the patches in the image being processed.  Finally, the noise content of a difference image needs to be low enough so that it does not materially affect comparisons between the golden and input images. Good signal strength goes a long way toward reducing the effects of noise. Another  sometimes complementary  approach is to implement image processing techniques  e.g., image averaging  to reduce noise.  Obviously there are a number if variations of the basic theme just described. For exam  ple, additional intelligence in the form of tests that are more sophisticated than pixel by  pixel threshold comparisons can be implemented. A technique often used in this regard is to subdivide the golden image into different regions and perform different  usually more than one  tests in each of the regions, based on expected region content.   Problem 3.15   a  From Eq.  3.4 3 , at any point  x; y ,  Problem 3.15 27  g =  1 K  gi =  fi +  1 K  KXi=1  1 K  KXi=1  ´i:  Efgg =  Effig +  Ef´ig:  1 K  KXi=1  KXi=1  1 K  KXi=1  But all the fi are the same image, so Effig = f. Also, it is given that the noise has zero mean, so Ef´ig = 0: Thus, it follows that Efgg = f, which proves the validity of  Then  Eq.  3.4 4 .   b  From  a ,  g =  gi =  fi +  1 K  KXi=1  1 K  KXi=1  1 K  KXi=1  ´i:  It is known from random variable theory that the variance of the sum of uncorrelated random variables is the sum of the variances of those variables  Papoulis [1991] . Since the elements of f are constant and the ´i are uncorrelated, then + ¢¢ ¢ + ¾2  1 K2 [¾2  g = ¾2 ¾2  + ¾2 ´2  f +  ´1  ]:  K  ´  The ﬁrst term on the right side is 0 because the elements of f are constants. The various ´ and we ¾2 ´i have  are simply samples of the noise, which is has variance ¾2  ´. Thus, ¾2 ´i  = ¾2  ¾2  g =  K K 2 ¾2  ´ =  1 K  ¾2 ´  which proves the validity of Eq.  3.4 5 .  Problem 3.16  With reference to Section 3.4.2, when i = 1  no averaging , we have  When i = K,  g 1  = g1 and ¾2  g 1  = ¾2 ´:  g K  =  gi and ¾2  g K  =  1 K  ¾2 ´:  1 K  KXi=1   28  Chapter 3 Problem Solutions  We want the ratio of ¾2  g K  to ¾2  g 1  to be 1 10, so ¾2 g K  ¾2  1 10  =  =  g 1   1  ´  K ¾2 ¾2 ´  from which we get K = 10. Since the images are generated at 30 frames s, the station  ary time required is 1 3 s.  Problem 3.17   a  Consider a 3 £ 3 mask ﬁrst. Since all the coefﬁcients are 1  we are ignoring the 1 9 scale factor , the net effect of the lowpass ﬁlter operation is to add all the gray levels of pixels under the mask. Initially, it takes 8 additions to produce the response of the mask. However, when the mask moves one pixel location to the right, it picks up only one new column. The new response can be computed as  Rnew = Rold ¡ C1 + C3  where C1 is the sum of pixels under the ﬁrst column of the mask before it was moved, and C3 is the similar sum in the column it picked up after it moved. This is the basic box ﬁlter or moving average equation. For a 3 £ 3 mask it takes 2 additions to get C3  C1 was already computed . To this we add one subtraction and one addition to get Rnew. Thus, a total of 4 arithmetic operations are needed to update the response after one move. This is a recursive procedure for moving from left to right along one row of the image. When we get to the end of a row, we move down one pixel  the nature of the computation is the same  and continue the scan in the opposite direction.  For a mask of size n £ n,  n ¡ 1  additions are needed to obtain C3, plus the single subtraction and addition needed to obtain Rnew, which gives a total of  n + 1  arith  metic operations after each move. A brute force implementation would require n2 ¡ 1 additions after each move.   b  The computational advantage is n2 ¡ 1 n + 1  A =  =   n + 1  n ¡ 1    n + 1   = n ¡ 1:  The plot of A as a function of n is a simple linear function starting at A = 1 for n = 2.  Problem 3.18  One of the easiest ways to look at repeated applications of a spatial ﬁlter is to use super    Problem 3.17 29  position. Let f  x; y  and h x; y  denote the image and the ﬁlter function, respectively. Assuming square images of size N £ N for convenience, we can express f  x; y  as the sum of at most N 2 images, each of which has only one nonzero pixel  initially, we as  sume that N can be inﬁnite . Then, the process of running h x; y  over f  x; y  can be expressed as the following convolution:  h x; y  ¤ f  x; y  = h x; y  ¤ [f1 x; y  + f2 x; y  + ¢¢¢ fN 2 x; y ] :  Suppose for illustrative purposes that fi x; y  has value 1 at its center, while the other pixels are valued 0, as discussed above  see Fig. P3.18a . If h x; y  is a 3 £ 3 mask of 1 9zs  Fig. P3.18b , then convolving h x; y  with fi x; y  will produce an image with a 3 £ 3 array of 1 9zs at its center and 0zs elsewhere, as shown in Fig. P3.18 c . If h x; y  is now applied to this image, the resulting image will be as shown in Fig. P3.18 d . Note that the sum of the nonzero pixels in both Figs. P3.18 c  and  d  is the same, and equal to the value of the original pixel. Thus, it is intuitively evident that successive applications of h x; y  will }diffuse} the nonzero value of fi x; y   not an unexpected result, because h x; y  is a blurring ﬁlter . Since the sum remains constant, the values of the nonzero elements will become smaller and smaller, as the number of applications of the ﬁlter increases. The overall result is given by adding all the convolved fk x; y , for k = 1; 2; :::; N 2. The net effect of successive applications of the lowpass spatial ﬁlter h x; y  is thus seen to be more and more blurring, with the value of each pixel }redistributed} among the others. The average value of the blurred image will be thus be the same as the average value of f  x; y .  It is noted that every iteration of blurring further diffuses the values outwardly from the starting point. In the limit, the values would get inﬁnitely small, but, because the average value remains constant, this would require an image of inﬁnite spatial proportions. It is at this junction that border conditions become important. Although it is not required in the problem statement, it is instructive to discuss in class the effect of successive applications of h x; y  to an image of ﬁnite proportions. The net effect is that, since the values cannot diffuse outward past the boundary of the image, the denominator in the successive applications of averaging eventually overpowers the pixel values, driving the image to zero in the limit. A simple example of this is given in Fig. P3.18 e , which shows an array of size 1£ 7 that is blurred by successive applications of the 1£ 3 mask h y  = 1 3 [1; 1; 1]. We see that, as long as the values of the blurred 1 can diffuse out, the sum, S, of the resulting pixels is 1. However, when the boundary is met, an assumption must be made regarding how mask operations on the border are treated. Here, we used the commonly made assumption that pixel value immediately past the boundary are 0. The mask operation does not go beyond the boundary, however. In this example, we   30  Chapter 3 Problem Solutions  see that the sum of the pixel values begins to decrease with successive applications of the mask. In the limit, the term 1= 3 n would overpower the sum of the pixel values, yielding an array of 0zs.  Problem 3.19  Figure P3.18   a  There are n2 points in an n £ n median ﬁlter mask. Since n is odd, the median value, ³, is such that there are  n2 ¡ 1 =2 points with values less than or equal to ³ and the same number with values greater than or equal to ³. However, since the area A  number of points  in the cluster is less than one half n2, and A and n are integers, it follows that A is always less than or equal to  n2 ¡ 1 =2. Thus, even in the extreme case when all cluster points are encompassed by the ﬁlter mask, there are not enough   Problem 3.20 31  points in the cluster for any of them to be equal to the value of the median  remember, we are assuming that all cluster points are lighter or darker than the background points . Therefore, if the center point in the mask is a cluster point, it will be set to the median value, which is a background shade, and thus it will be eliminated} from the cluster. This conclusion obviously applies to the less extreme case when the number of cluster points encompassed by the mask is less than the maximum size of the cluster.   b  For the conclusion reached in  a  to hold, the number of points that we consider cluster  object  points can never exceed  n2 ¡ 1 =2. Thus, two or more different clusters cannot be in close enough proximity for the ﬁlter mask to encompass points from more than one cluster at any mask position. It then follows that no two points from different clusters can be closer than the diagonal dimension of the mask minus one cell  which can be occupied by a point from one of the clusters . Assuming a grid spacing of 1 unit, the minimum distance between any two points of different clusters then must greater  than p2 n ¡ 1 . In other words, these points must be separated by at least the distance spanned by n ¡ 1 cells along the mask diagonal.   a  Numerically sort the n2 values. The median is  ³ = [ n2 + 1 =2] th largest value.   b  Once the values have been sorted one time, we simply delete the values in the trailing edge of the neighborhood and insert the values in the leading edge in the appropriate locations in the sorted array.   a  The most extreme case is when the mask is positioned on the center pixel of a 3 pixel gap, along a thin segment, in which case a 3 £ 3 mask would encompass a completely blank ﬁeld. Since this is known to be the largest gap, the next  odd  mask size up is guaranteed to encompass some of the pixels in the segment. Thus, the smallest mask that will do the job is a 5 £ 5 averaging mask.  b  The smallest average value produced by the mask is when it encompasses only two pixels of the segment. This average value is a gray scale value, not binary, like the rest of the segment pixels. Denote the smallest average value by Amin, and the binary values  Problem 3.20  Problem 3.21   32  Chapter 3 Problem Solutions  of pixels in the thin segment by B. Clearly, Amin is less than B. Then, setting the binarizing threshold slightly smaller than Amin will create one binary pixel of value B in the center of the mask.  Problem 3.22  From Fig. 3.35, the vertical bars are 5 pixels wide, 100 pixels high, and their separation is 20 pixels. The phenomenon in question is related to the horizontal separation between bars, so we can simplify the problem by considering a single scan line through the bars in the image. The key to answering this question lies in the fact that the distance  in pixels  between the onset of one bar and the onset of the next one  say, to its right  is 25 pixels. Consider the scan line shown in Fig. P3.22. Also shown is a cross section of a 25£25 mask. The response of the mask is the average of the pixels that it encompasses. We note that when the mask moves one pixel to the right, it loses on value of the vertical bar on the left, but it picks up an identical one on the right, so the response doesnzt change. In fact, the number of pixels belonging to the vertical bars and contained within the mask does not change, regardless of where the mask is located  as long as it is contained within the bars, and not near the edges of the set of bars . The fact that the number of bar pixels under the mask does not change is due to the peculiar separation between bars and the width of the lines in relation to the 25 pixel width of the mask This constant response is the reason no white gaps is seen in the image shown in the problem statement. Note that this constant response does not happen with the 23 £ 23 or the 45£ 45 masks because they are not }synchronized} with the width of the bars and their separation.  Figure P3.22   Problem 3.23  Problem 3.22 33  There are at most q2 points in the area for which we want to reduce the gray level of each pixel to one tenth its original value. Consider an averaging mask of size n £ n encompassing the q £ q neighborhood. The averaging mask has n2 points of which we are assuming that q2 points are from the object and the rest from the background. Note that this assumption implies separation between objects at least the area of the mask all around each object. The problem becomes intractable unless this assumption is made. This condition was not given in the problem statement on purpose in order to force the student to arrive at that conclusion. If the instructor wishes to simplify the problem, this should then be mentioned when the problem is assigned. A further simpliﬁcation is to tell the students that the gray level of the background is 0.  Let B represent the gray level of background pixels, let ai denote the gray levels of points inside the mask and oi the levels of the objects. In addition, let Sa denote the set of points in the averaging mask, So the set of points in the object, and Sb the set of points in the mask that are not object points. Then, the response of the averaging mask at any point on the image can be written as  R =  =  =  =  1  1  ai  n2 Xai2Sa n224 Xoj2So oj + Xak2Sb n224 q2 oj35 + q2 Xoj2So n2£ n2 ¡ q2 B¤  q2 n2 Q +  1  1  ak35 n2" Xak2Sb  1  ak  where Q denotes the average value of object points. Let the maximum expected average value of object points be denoted by Qmax. Then we want the response of the mask at any point on the object under this maximum condition to be less than one tenth Qmax, or  q2 n2 Qmax + from which we get the requirement  Qmax  1 10  1  n2£ n2 ¡ q2 B¤ <  Qmax ¡ 10B ¸1=2 n > q·10 Qmax ¡ B   for the minimum size of the averaging mask. Note that if the background gray level is 0, we the minimum mask size is n < p10q. If this was a fact speciﬁed by the instructor,   34  Chapter 3 Problem Solutions  or student made this assumption from the beginning, then this answer follows almost by inspection.  Problem 3.24  Problem 3.25  The student should realize that both the Laplacian and the averaging process are linear operations, so it makes no difference which one is applied ﬁrst.  The Laplacian operator is deﬁned as  r2f =  @2f @x2 +  @2f @y2  for the unrotated coordinates and as  r2f = for rotated coordinates. It is given that  @2f @x02 +  @2f @y02 :  x = x0 cos µ ¡ y0 sin µ and y = x0 sin µ + y0 cos µ  where µ is the angle of rotation. We want to show that the right sides of the ﬁrst two equations are equal. We start with  Taking the partial derivative of this expression again with respect to x0 yields @2f @y2 sin2 µ:  @2f @x2 cos2 µ +  @x¶ cos µ sin µ +  @y¶ sin µ cos µ +  @xµ @f  @yµ@f  @  @  @2f @x02 = Next, we compute  @f @x0  @x @x0  +  =  =  @f @x @f @x  @y @x0  @f @y @f @y  cos µ +  sin µ:  @f @y0  =  @f @x  @x @y0  +  @f @y  = ¡  @f @x  sin µ +  cos µ:  @y @y0 @f @y  Taking the derivative of this expression again with respect to y0 gives  @2f @y02 = Adding the two expressions for the second derivatives yields  @2f @x2 sin2 µ ¡  @y¶ cos µ sin µ ¡  @xµ@f  @yµ @f  @x¶ sin µ cos µ +  @  @  @2f @y2 cos2 µ:  @2f @x02 +  @2f @y02 =  @2f @x2 +  @2f @y2   which proves that the Laplacian operator is independent of rotation.  Problem 3.26 35  Problem 3.26  Unsharp masking is high boost ﬁltering [Eq.  3.7 11 ] with A = 1. Figure P3.26 shows the two possible solutions based on that equation. The left and right masks correspond to the ﬁrst and second line in the equation, respectively.  Problem 3.26.  Problem 3.27  Consider the following equation:  f x; y  ¡ r2f  x; y  = f  x; y  ¡ [f  x + 1; y  + f  x ¡ 1; y  + f  x; y + 1   +f  x; y ¡ 1  ¡ 4f  x; y ]  = 6f  x; y  ¡ [f  x + 1; y  + f x ¡ 1; y  + f  x; y + 1   +f  x; y ¡ 1  + f  x; y ]  = 5f1:2f x; y ¡  1 [f  x + 1; y  + f x ¡ 1; y  + f  x; y + 1  5 +f  x; y ¡ 1  + f x; y ]g  = 5£1:2f  x; y  ¡ f  x; y ¤  where f  x; y  denotes the average of f  x; y  in a predeﬁned neighborhood that is cen  tered at  x; y  and includes the center pixel and its four immediate neighbors. Treating the constants in the last line of the above equation as proportionality factors, we may write  f  x; y  ¡ r2f  x; y  s f x; y  ¡ f  x; y :  The right side of this equation is recognized as the deﬁnition of unsharp masking given in Eq.  3.7 7 . Thus, it has been demonstrated that subtracting the Laplacian from an   36  Chapter 3 Problem Solutions  image is proportional to unsharp masking.  Problem 3.28   a  From Problem 3.25,  and  or  and  @f @x0  @f @x  =  cos µ +  sin µ  @f @y  @f @y  @f @y0  @f @x  = ¡  sin µ +  cos µ  from which it follows that  µ @f @x0¶2 +µ @f @y0¶2 "µ @f @y0¶21=2 +µ @f @x0¶2  =µ @f @x¶2 ="µ @f @x¶2  +µ@f @y¶2 @y¶21=2 +µ@f  :  Thus, we see that the magnitude of the gradient is an isotropic operator.   b  From Eq.  3.7 12 ,  3.7 14  and the preceding results,  @f  @f  @x¯¯¯¯ jGxj =¯¯¯¯ @x0¯¯¯¯ =¯¯¯¯ jGx0j =¯¯¯¯ @y0¯¯¯¯ =¯¯¯¯¡ jGy0j =¯¯¯¯  @f  @f @x  @f @x  jGyj =¯¯¯¯  cos µ +  sin µ +  @f @y  @f  @y¯¯¯¯ ; sin µ¯¯¯¯ ; cos µ¯¯¯¯ :  @f @y  Clearly, jGx0j + jGy0j 6= jGxj + jGyj.  Problem 3.29  It is given that the range of illumination stays in the linear portion of the camera response range, but no values for the range are given. The fact that images stay in the linear range simply says that images will not be saturated at the high end or be driven in the low end to such an extent that the camera will not be able to respond, thus losing image information irretrievably. The only way to establish a benchmark value for illumination   Problem 3.28 37  is when the variable  daylight  illumination is not present. Let f0 x; y  denote an image taken under artiﬁcial illumination only, with no moving objects  e.g., people or vehicles  in the scene. This becomes the standard by which all other images will be normalized. There are numerous ways to solve this problem, but the student must show awareness that areas in the image likely to change due to moving objects should be excluded from the illumination correction approach.  One simple way is to select various representative subareas of f0 x; y  not likely to be obscured by moving objects and compute their average intensities. We then select the minimum and maximum of all the individual average values, denoted by, f min and f max. The objective then is to process any input image, f  x; y , so that its minimum and maximum will be equal to f min and f max, respectively. The easiest way to do this is with a linear transformation function of the form  fout x; y  = af  x; y  + b:  It is easily veriﬁed that the output image will have the  where fout is the output image. required minimum and maximum values if we choose f max ¡ f min fmax ¡ fmin  a =  and  where fmax and fmin are the maximum and minimum values of the input image.  f minfmax ¡ f maxfmin  b =  fmax ¡ fmin  Note that the key assumption behind this method is that all images stay within the linear operating range of the camera, thus saturation and other nonlinearities are not an issue. Another implicit assumption is that moving objects comprise a relatively small area in the ﬁeld of view of the camera, otherwise these objects would overpower the scene and the values obtained from f0 x; y  would not make a lot of sense. If the student selects another automated approach  e.g., histogram equalization , he she must discuss the same or similar types of assumptions.    4 Problem Solutions  Problem 4.1  Problem 4.2  By direct substitution of f  x  [Eq.  4.2 6 ] into F  u  [Eq.  4.2 5 ]:  M¡1Xx=0"M¡1Xr=0 F  r ej2¼rx=M e¡j2¼ux=M M¡1Xx=0 M¡1Xr=0  ej2¼rx=M e¡j2¼ux=M  F  r   F  u  =  1 M  1 M  1 M  =  =  F  u  [M]  = F  u   where the third step follows from the orthogonality condition given in the problem state  ment. Substitution of F  u  into f  x  is handled in a similar manner.  This is a simple problem to familiarize the student with just the manipulation of the 2 D Fourier transform and its inverse. The Fourier transform is linear iff:  = [a1f1 x; y  + a2f2 x; y ] = a1= [f1 x; y ] + a2= [f2 x; y ]  where a1 and a2 are arbitrary constants. From the deﬁnition of the 2 D transform,  = [a1f1 x; y  + a2f2 x; y ] =  M N  [a1f1 x; y  + a2f2 x; y ]  e¡j2¼ ux=M + vy=N    1  1  N¡1Xy=0 M¡1Xx=0 N¡1Xy=0 M¡1Xx=0 N¡1Xy=0 M¡1Xx=0  =  M N  1  +  M N  = a1= [f1 x; y ] + a2= [f2 x; y ]  a1f1 x; y e¡j2¼ ux=M + vy=N   a2f2 x; y e¡j2¼ ux=M + vy=N    40  Chapter 4 Problem Solutions  which proves linearity. The inverse is done in the same way.  Problem 4.3  Problem 4.4  The inverse DFT of a constant A in the frequency domain is an impulse of strength A in the spatial domain. Convolving the impulse with the image copies  multiplies  the value of the impulse at each pixel location in the image.  An important aspect of this problem is to recognize that the quantity  u2 + v2  can be replaced by the distance squared, D2 u; v . This reduces the problem to one vari  able, which is notationally easier to manage. Rather than carry an award capital letter throughout the development, we deﬁne w2 , D2 u; v  =  u2 + v2 . Then we proceed as follows:  The inverse Fourier transform is  H w  = e¡w2=2¾2  :  ¡1  h z  = Z 1 = Z 1 = Z 1  ¡1  ¡1  H w ej2¼wzdw  e¡w2=2¾2  ej2¼wzdw  e¡ 1  2¾2 [w2¡j4¼¾2wz]dw:  e¡  2¼ 2z2¾2  2  e   2¼ 2z2 ¾2  2  = 1:  We now make use of the identity  Inserting this identity in the preceding integral yields  h z  = e¡  2¼ 2z2¾2  2  e¡ 1  2¾2 [w2¡j4¼¾2wz¡ 2¼ 2¾4z2]dw  = e¡  2¼ 2z2¾2  2  e¡ 1  2¾2 [w ¡ j2¼¾2z]2  dw:  ¡1  Z 1 Z 1  ¡1  Next we make the change of variable r = w ¡ j2¼¾2z. Then, dr = dw and the above integral becomes  h z  == e¡  2¼ 2z2¾2  2  2¾2 dr:  Finally, we multiply and divide the right side of this equation by p2¼¾: 2¾2 dr¸ :  h z  = p2¼¾e¡  2¼ 2z2 ¾2  e¡ r2  ·  1  2  e¡ r2  ¡1  Z 1 p2¼¾Z 1  ¡1   Problem 4.5  Problem 4.6  Problem 4.5 41  The expression inside the brackets is recognized as a Gaussian probability density func  tion, whose integral from ¡1 to 1 is 1. Then, Going back to two spatial variables gives the ﬁnal result:h x; y  = p2¼¾ e¡2¼2¾2 x2+y2 :  h z  = p2¼¾e¡  2¼ 2z2¾2  :  2  The spatial ﬁlter is obtained by taking the inverse Fourier transform of the frequency  domain ﬁlter:  hhp x; y  = =¡1 [1 ¡ Hlp u; v ]  = =¡1 [1] ¡ =¡1 [Hlp u; v ] = ± 0  ¡ p2¼¾ e¡2¼2¾2 x2+y2    a  We note ﬁrst that  ¡1 x+y = ej¼ x+y . Then,  =hf x; y ej¼ x+y i =  M N  M N  1  1  1  M N  M¡1Xx=0 M¡1Xx=0 M¡1Xx=0  N¡1Xy=0hf  x; y ej¼ x+y i e¡j2¼ ux=M + vy=N   N¡1Xy=0hf  x; y e¡j2¼ ¡ xM N¡1Xy=0  f x; y e¡j2¼ x[u¡ M  2N  i  2 ]=M +y[v¡ N  2M ¡ yN  2 ]=N   e¡j2¼ ux=M + vy=N    =  =  = F  u ¡ M=2; v ¡ N=2 :   b  Following the same format as in  a ,  =hf  x; y ej2¼ u0x=M + v0y=M i =  e¡j2¼ ux=M + vy=N   M N  1  1  M¡1Xx=0 M¡1Xx=0  N¡1Xy=0hf x; y ej2¼ u0x=M + v0y=M  i N¡1Xy=0  f  x; y   e¡j2¼ x[u¡u0]=M + y[v¡v0]=N   =  M N  = F  u ¡ u0; v ¡ v0    42  Chapter 4 Problem Solutions  Similarly,  =¡1hF  u; v e¡j2¼ ux0=M + vy0=M i = f  x ¡ x0; y ¡ y0 :  The equally spaced, vertical bars on the left, lower third of the image.  Problem 4.7  Problem 4.8  Problem 4.9  Problem 4.10  With reference to Eq.  4.4 1 , all the highpass ﬁlters in discussed in Section 4.4 can be expressed a 1 minus the transfer function of lowpass ﬁlter  which we know do not have an impulse at the origin . The inverse Fourier transform of 1 gives an impulse at the origin in the highpass spatial ﬁlters.  The complex conjugate simply changes j to ¡j in the inverse transform, so the image on the right is given by  =¡1 [F¤ u; v ] =  F  u:v e¡j2¼ ux=M + vy=N   =  F  u:v ej2¼ u ¡x =M + v ¡y =N   M¡1Xx=0 M¡1Xx=0  N¡1Xy=0 N¡1Xy=0  = f  ¡x; ¡y   which simply mirrors f  x; y  about the origin, thus producing the image on the right.  If H u; v  is real and symmetric, then  H u; v  = H¤ u; v  = H¤ ¡u;¡v  = H ¡u; ¡v :  The ﬁlter in the spatial domain is  h x; y  = =¡1 [H u; v ] =  H u:v ej2¼ ux=M + vy=N :  M¡1Xx=0  N¡1Xy=0   Then,  h¤ x; y  =  H¤ u:v e¡j2¼ ux=M + vy=N   Problem 4.11 43  M¡1Xx=0 M¡1Xx=0 M¡1Xx=0  N¡1Xy=0 N¡1Xy=0 N¡1Xy=0  =  =  M¡1Xx=0 M¡1Xx=0 M¡1Xx=0  N¡1Xy=0 N¡1Xy=0 N¡1Xy=0  =  =  H¤ ¡u;¡v ej2¼ ux=M + vy=N   H u; v ej2¼ ux=M + vy=N   Similarly,  = h x; y     real  .  h ¡x;¡y  =  H u; v e¡j2¼ ux=M + vy=N    H ¡u;¡v ej2¼ ux=M + vy=N   H u; v ej2¼ ux=M + vy=N    = h x; y    symmetric .  Starting from Eq.  4.2 30 , we easily ﬁnd the expression for the deﬁnition of continuous convolution in one dimension:  The Fourier transform of this expression is  f  ® g x ¡ ® d®:  ¡1  f  x  ¤ g x  =Z 1 ¡1·Z 1 f ® ·Z 1  = [f  x  ¤ g x ] = Z 1 = Z 1 = [g x ¡ ® ] = G u e¡j2¼u®  ¡1  ¡1  ¡1  f ® g x ¡ ® d®¸ e¡j2¼uxdx g x ¡ ® e¡j2¼uxdx¸ d®:  The term inside the inner brackets is the Fourier transform of g x ¡ ® . But,  so  = [f x  ¤ g x ] = Z 1  ¡1  f  ® £G u e¡j2¼u®¤ d®  f  ® e¡j2¼u®d®  = G u Z 1  ¡1 = G u F  u :  Problem 4.11   44  Chapter 4 Problem Solutions  This proves that multiplication in the frequency domain is equal to convolution in the spatial domain. The proof that multiplication in the spatial domain is equal to convolu  tion in the spatial domain is done in similar way.  Problem 4.12   a  The ring in fact has a dark center area as a result of the highpass operation only  the following image shows the result of highpass ﬁltering only . However, the dark center area is averaged out by the lowpass ﬁlter. The reason the ﬁnal result looks so bright is that the discontinuity  edge  on boundaries of the ring are much higher than anywhere else in the image, thus giving an averaged area whose gray level dominates.   b  Filtering with the Fourier transform is a linear process. The order does not matter.  Figure P4.12  Problem 4.13   a  One application of the ﬁlter gives:  G u; v  = H u; v F  u; v  = e¡D2 u;v =2D2  0 F  u; v :   Problem 4.12 45  Similarly, K applications of the ﬁlter would give  GK u; v  = e¡KD2 u;v =2D2  0 F  u; v :  The inverse DFT of GK u; v  would give the image resulting from K passes of the Gaussian ﬁlter. If K is large enough,} the Gaussian LPF will become a notch pass ﬁlter, passing only F  0; 0 . We know that this term is equal to the average value of the image. So, there is a value of K after which the result of repeated lowpass ﬁltering will simply produce a constant image. The value of all pixels on this image will be equal to the average value of the original image. Note that the answer applies even as K approaches inﬁnity. In this case the ﬁlter will approach an impulse at the origin, and this would still give us F  0; 0  as the result of ﬁltering.   b  To guarantee the result in  a , K has to be chosen large enough so that the ﬁlter becomes a notch pass ﬁlter  at the origin  for all values of D u; v . Keeping in mind that increments of frequencies are in unit values, this means  HK u; v  = e¡KD2 u;v =2D2  0 =  1  0  if  u; v  =  0; 0  Otherwise.  Because u and v are integers, the conditions on the second line in this equation are satisﬁed for all u > 1 and or v > 1. When u = v = 0, D u; v  = 0, and HK u; v  = 1, as desired.  We want all values of the ﬁlter to be zero for all values of the distance from the origin that are greater than 0  i.e., for values of u and or v greater than 0 . However, the ﬁlter is a Gaussian function, so its value is always greater than 0 for all ﬁnite values of D u; v . But, we are dealing with digital numbers, which will be designated as zero whenever the value of the ﬁlter is less than 1 2 the smallest positive number representable in the computer being used. Assume this number to be kmin  donzt confuse the meaning of this k with K, which is the number of applications of the ﬁlter . So, values of K for which for which the ﬁlter function is greater than 0:5 £ kmin will sufﬁce. That is, we want the minimum value of K for which  or  e¡KD2 u;v =2D2  0 < 0:5kmin  K > ¡  > ¡  ln 0:5kmin  D2 u; v =2D2 0 2D2  0 ln 0:5kmin  D2 u; v   :  As noted above, we want this equation for hold for all values of D2 u; v  > 0. Since the exponential decreases as a function of increasing distance from the origin, we choose   46  Chapter 4 Problem Solutions  the smallest possible value of D2 u; v , which is 1. Tis gives the result  K > ¡2D2  0 ln 0:5kmin   which gives a positive number because kmin << 1. This result guarantees that the lowpass ﬁlter will act as a notch pass ﬁlter, leaving only the value of the transform at the origin. The image will not change past this value of K.  Problem 4.14   a  The spatial average is  g x; y  = From Eq.  4.6 2 ,  1 4  [f  x; y + 1  + f  x + 1; y  + f  x ¡ 1; y  + f  x; y ¡ 1 ] :  G u; v  =  1  4hej2¼v=N + ej2¼u=M + e¡j2¼u=M + e¡j2¼v=Ni F  u; v   = H u; v F  u; v ;  where  is the ﬁlter transfer function in the frequency domain.  H u; v  =  [cos 2¼u=M  + cos 2¼v=N ]  1 2   b  To see that this is a lowpass ﬁlter, it helps to express the preceding equation in the form of our familiar centered functions:  1 2  H u; v  =  [cos 2¼[u ¡ M=2 =M  + cos 2¼[v ¡ N=2]=N ] :  Consider one variable for convenience. As u ranges from 0 to M, the value of cos 2¼[u¡ M=2 =M  starts at ¡1, peaks at 1 when u = M=2  the center of the ﬁlter  and then de  creases to ¡1 again when u = M. Thus, we see that the amplitude of the ﬁlter decreases as a function of distance from the origin of the centered ﬁlter, which is the characteris  tic of a lowpass ﬁlter. A similar argument is easily carried out when considering both variables simultaneously.  Problem 4.15  The problem statement gives the form of the difference in the x direction. A similar expression gives the difference in the y direction. The ﬁltered function in the spatial domain then is:  g x; y  = f  x; y  ¡ f  x + 1; y  + f  x; y  ¡ f  x; y + 1 :   Problem 4.16 47  From Eq.  4.6 2 ,  G u; v  = F  u; v  ¡ F  u; v ej2¼u=M + F  u; v  ¡ F  u; v ej2¼v=N  = [1 ¡ ej2¼u=M ]F  u; v  + [1 ¡ ej2¼v=N ]F  u; v  = H u; v F  u; v ;  where H u; v  is the ﬁlter function:  H u; v  = ¡2jhsin ¼u=M ej¼u=M + sin ¼v=N ej¼v=Ni :   b  To see that this is a highpass ﬁlter, it helps to express the ﬁlter function in the form of our familiar centered functions:  H u; v  = ¡2jhsin ¼[u ¡ M=2]=M ej¼u=M + sin ¼[v ¡ N=2]=N ej¼v=Ni :  Consider one variable for convenience. As u ranges from 0 to M, H u; v  starts at its maximum  complex  value of 2j for u = 0 and decreases from there. When u = M=2  the center of the shifted function , A similar argument is easily carried out when considering both variables simultaneously.. The value of H u; v  starts increasing again and achieves the maximum value of 2j again when u = M. Thus, this ﬁlter has a value of 0 a the origin and increases with increasing distance from the origin. This is the characteristic of a highpass ﬁlter. A similar argument is easily carried out when considering both variables simultaneously.   a  The key for the student to be able to solve the problem is to treat the number of applications  denoted by K  of the highpass ﬁlter as 1 minus K applications of the corresponding lowpass ﬁlter, so that  HK u; v  = HK u; v F  u; v   = h1 ¡ e¡KD2 u;v =2D2  0i H u; v   where the Gaussian lowpass ﬁlter is from Problem 4.13. Students who start directly  with the expression of the Gaussian highpass ﬁlterh1 ¡ e¡KD2 u;v =2D2  to raise it to the Kth power will run into a dead end.  0i and attempt  The solution to this problem parallels the solution to Problem 4.13. Here, however, the ﬁlter will approach a notch ﬁlter that will take out F  0; 0  and thus will produce an image with zero average values  this implies negative pixels . So, there is a value of K after which the result of repeated highpass ﬁltering will simply produce a constant image.  Problem 4.16   48  Chapter 4 Problem Solutions  Problem 4.17   b  The problem is to determine the value of K for which  HK u; v  = 1 ¡ e¡KD2 u;v =2D2  0 =  0  1  if  u; v  =  0; 0  Otherwise.  Because u and v are integers, the conditions on the second line in this equation are satisﬁed for all u > 1 and or v > 1. When u = v = 0, D u; v  = 0, and HK u; v  = 0, as desired.  We want all values of the ﬁlter to be 1 for all values of the distance from the origin that are greater than 0  i.e., for values of u and or v greater than 0 . For HK u; v  to become 1, the exponential term has to become 0 for values of u and or v greater than 0. This is the same requirement as in Problem 4.13, so the solution of that problem applies here as well.   a  Express ﬁltering as convolution to reduce all processes to the spatial domain. Then, the ﬁltered image is given by  g x; y  = h x; y  ¤ f x; y   where h is the spatial ﬁlter  inverse Fourier transform of the frequency domain ﬁlter  and f is the input image. Histogram processing this result yields  g0 x; y  = T [g x; y ]  = T [h x; y  ¤ f  x; y ] ;  where T denotes the histogram equalization transformation. If we histogram equalize ﬁrst, then  and  g x; y  = T [f  x; y ]  g0 x; y  = h x; y  ¤ T [f  x; y ] :  In general, T is a nonlinear function determined by the nature of the pixels in the im  age from which it is computed. Thus, in general, T [h x; y  ¤ f  x; y ] 6= h x; y  ¤ T [f  x; y ] and the order does matter.   b  As indicated in Section 4.4, highpass ﬁltering severely diminishes the contrast of an image. Although high frequency emphasis helps some, the improvement is usually not dramatic  see Fig. 4.30 . Thus, if an image is histogram equalized ﬁrst, the gain in contrast improvement will essentially be lost in the ﬁltering process. Therefore, the procedure in general is to ﬁlter ﬁrst and histogram equalize the image after that.   Problem 4.18 49  The answer is no. The Fourier transform is a linear process, while the square and square roots involved in computing the gradient are nonlinear operations. The Fourier trans  form could be used to compute the derivatives  as differencesxsee Prob.4.15 , but the squares, square root, or absolute values must be computed directly in the spatial domain.  The equation corresponding to the mask in Fig. 4.27 f  is Eq.  3.7 4 :  g x; y  = [f  x + 1; y  + f  x ¡ 1; y  + f  x; y + 1  + f  x; y ¡ 1 ] ¡ 4f  x; y :  As in Problem 4.15,  G u; v  = H u; v F  u; v   where  H u; v  = hej2¼u=M + e¡j2¼u=M + ej2¼v=N + e¡j2¼v=N ¡ 4i  = 2 [cos 2¼u=M  + cos 2¼v=N  ¡ 2] : Shifting the ﬁlter to the center of the frequency rectangle gives  H u; v  = 2 [cos 2¼ [u ¡ M=2] =M  + cos 2¼ [v ¡ N=2] =N  ¡ 2] :  When  u; v  =  M=2; N=2   the center of the shifted ﬁlter . For values away from the center values of H u; v  decrease, but this is as expected [see Fig. 4.27 a ] for this particular formulation of the Laplacian.  Problem 4.18  Problem 4.19  Problem 4.20  From Eq.  4.4 3 , the transfer function of a Butterworth highpass ﬁlter is  We want the ﬁlter to have a value of  L when D u; v  = 0, and approach  H for high values of D u; v . The preceding equation is easily modiﬁed to accomplish this:  H u; v  =  1  1 +h D0  D u;v i2n :  H u; v  =  L +    H ¡  L   1 +h D0  D u;v i2n :  The value of n controls the sharpness of the transition between  L and  H .   50  Chapter 4 Problem Solutions  Problem 4.21  Recall that the reason for padding is to establish a }buffer} between the periods that are implicit in the DFT. Imagine the image on the left being duplicated inﬁnitely many times to cover the xy plane. The result would be a checkerboard, with each square being in the checkerboard being the image  and the black extensions . Now imagine doing the same thing to the image on the right. The results would be indistinguishable. Thus, either form of padding accomplishes the same separation between images, as desired.   a  Padding an image with zeros increases its size, but not its gray level content. Thus, the average gray level of the padded image is lower than that of the original image. This implies that F  0; 0  in the spectrum of the padded image is less than F  0; 0  in the original image  recall that F  0; 0  is the average value of the corresponding image . Thus, we can visualize F  0; 0  being lower in the spectrum on the right, with all values away from the origin being lower too, and covering a narrower range of values. Thatzs the reason the overall contrast is lower in the picture on the right.   b  Padding an image with 0zs introduces signiﬁcant discontinuities at the borders of the original images. This process introduces strong horizontal and vertical edges, where the image ends abruptly and then continues with 0 values. These sharp transitions correspond to the strength of the spectrum along the horizontal and vertical axes of the spectrum.  As in problem 4.9, taking the complex conjugate of an image mirrors it in the spatial domain. Thus, we would expect the result to be a mirror image  about both axes  of Fig. 4.41 e .   a  and  b  See Figs. P4.24 a  and  b .  c  and  d  See Figs. P4.24 c  and  d .  Problem 4.22  Problem 4.23  Problem 4.24   Problem 4.25 51  Figures P4.24 a  and  b   Figures P4.24 c  and  d   Problem 4.25  Because M = 2n, we can write Eqs.  4.6 47  and  4.6 48  respectively as  and  m n  =  M n  1 2  a n  = Mn:  Proof by induction begins by showing that both equations hold for n = 1:  m 1  =   2  1  = 1  and  a 1  =  2  1  = 2:  1 2  We know these results to be correct from the discussion in Section 4.6.6. Next, we assume that the equations hold for n. Then, we are required to prove that they also are true for n + 1. From Eq.  4.6 45 ,  m n + 1  = 2m n  + 2n:   52  Chapter 4 Problem Solutions  Substituting m n  from above,  m n + 1  = 2µ1 = 2µ1  2  2  M n¶ + 2n 2nn¶ + 2n 2¡2n+1¢  n + 1 :  1  = 2n n + 1   = Therefore, Eq.  4.6 47  is valid for all n.  From Eq.  4.6 46 ,  Substituting the above expression for a n  yields  a n + 1  = 2a n  + 2n+1:  a n + 1  = 2M n + 2n+1  = 2 2nn  + 2n+1 = 2n+1 n + 1   which completes the proof.  Problem 4.26  Consider a single star modeled as an impulse ± x ¡ x0; y ¡ y0 . Then,  f  x; y  = K± x ¡ x0; y ¡ y0   from which  Taking the Fourier transform of both sides yields  z x; y  = ln f  x; y  = ln K + ln ± x ¡ x0; y ¡ y0   = K0 + ±0 x ¡ x0; y ¡ y0 :  = [z x; y ] = = [K0] + =£±0 x ¡ x0; y ¡ y0 ¤  = ± 0; 0  + e¡2¼ ux0+vy0 :  From this result, it is evident that the contribution of illumination is an impulse at the origin of the frequency plane. A notch ﬁlter that attenuates only this component will take care of the problem. Extension of this development to multiple impulses  stars  is straightforward. The ﬁlter will be the same.  Problem 4.27  The problem can be solved by carrying out the following steps:   Problem 4.26 53  1. Perform a median ﬁltering operation.  2. Follow  1  by high frequency emphasis.  3. Histogram equalize this result.  4. Compute the average gray level, K0. Add the quantity  K ¡ K0  to all pixels. 5. Perform the transformations shown in Fig. P4.27, where r is the input gray level,  and R, G, and B are fed into an RGB color monitor.  Figure P4.27    5 Problem Solutions  Problem 5.1  The solutions to  a ,  b , and  c  are shown in Fig. P5.1, from left to right:  Problem 5.2  The solutions to  a ,  b , and  c  are shown in Fig. P5.2, from left to right:  Figure P5.1  Figure P5.2   56  Chapter 5 Problem Solutions  Problem 5.3  The solutions to  a ,  b , and  c  are shown in Fig. P5.3, from left to right:  Problem 5.4  The solutions to  a ,  b , and  c  are shown in Fig. P5.4, from left to right:  Figure P5.3  Figure P5.4  Problem 5.5  The solutions to  a ,  b , and  c  are shown in Fig. P5.5, from left to right:   Problem 5.6 57  Problem 5.6  The solutions to  a ,  b , and  c  are shown in Fig. P5.6, from left to right:  Problem 5.7  The solutions to  a ,  b , and  c  are shown in Fig. P5.7, from left to right:  Figure P5.5  Figure P5.6  Figure P5.7   58  Chapter 5 Problem Solutions  Problem 5.8  The solutions to  a ,  b , and  c  are shown in Fig. P5.8, from left to right:  Problem 5.9  The solutions to  a ,  b , and  c  are shown in Fig. P5.9, from left to right:  Figure P5.8  Figure P5.9  Problem 5.10   a  The key to this problem is that the geometric mean is zero whenever any pixel is zero. Draw a proﬁle of an ideal edge with a few points valued 0 and a few points valued 1. The geometric mean will give only values of 0 and 1, whereas the arithmetic mean will give intermediate values  blur .   b  Black is 0, so the geometric mean will return values of 0 as long as at least one pixel   in the window is black. Since the center of the mask can be outside the original black area when this happens, the ﬁgure will be thickened.  Problem 5.11 59  Problem 5.11  The key to understanding the behavior of the contra harmonic ﬁlter is to think of the pix  els in the neighborhood surrounding a noise impulse as being constant, with the impulse noise point being in the center of the neighborhood. For the noise spike to be visible, its value must be considerably larger than the value of its neighbors. Also keep in mind that the power in the numerator is 1 plus the power in the denominator.   a  By deﬁnition, pepper noise is a low value  really 0 . It is most visible when sur  rounded by light values. Then center pixel  the pepper noise , will have little in›uence in the sums. If the area spanned by the ﬁlter is approximately constant, the ratio will approach the value of the pixels in the neighborhoodxthus reducing the effect of the low value pixel. For example, here are some values of the ﬁlter for a dark point of value 1 in a 3 £ 3 region with pixels of value 100: For Q = 0:5, ﬁlter = 98:78u for Q = 1, ﬁlter = 99:88, for Q = 2, ﬁlter = 99:99u and for Q = 5, ﬁlter = 100:00.   b  The reverse happens when the center point is large and its neighbors are small. The center pixel will now be the largest. However, the exponent is now negative, so the small numbers will dominate the result. The numerator can then be thought of a constant raised to the power Q + 1 and the denominator as a the same constant raised to the power Q. That constant is the value of the pixels in the neighborhood. So the ratio is just that value.   c  When the wrong polarity is used the large numbers in the case of the salt noise will be raised to a positive power, thus the noise will overpower the result. For salt noise the image will become very light. The opposite is true for pepper noisexthe image will become dark.   d  When Q = ¡1, the value of the numerator becomes equal to the number of pixels in the neighborhood  m £ n . The value of the denominator become sum values, each of which is 1 over the value of a pixel in the neighborhood. This is the same as the average of 1=A, where A is the image average.   e  In a constant area, the ﬁlter returns the value of the pixels in the area, independently of the value of Q.   60  Chapter 5 Problem Solutions  Problem 5.12  A bandpass ﬁlter is obtained by subtracting the corresponding bandreject ﬁlter from 1:  Hbp u; v  = 1 ¡ Hbr u; v :  Then:   a  Ideal bandpass ﬁlter:  HIbp u; v  =8> :  0 if D u; v  < D0 ¡ W 1 if D0 ¡ W 0 D u; v  > D0 + W 2  2  2 · D u; v  · D0 + W 2 :   b  Butterworth bandpass ﬁlter:  HBbp u; v  = 1 ¡  1  D2 u;v ¡D2  1 +h D u;v W 0i2n h D u;v W 0i2n 0i2n : 1 +h D u;v W  D2 u;v ¡D2  D2 u;v ¡D2  =  HGbp u; v  = 1 ¡"1 ¡ e¡ 1 2· D2  u;v ¡D2 D u;v W ¸ 2  = e¡ 1  0  :  D u;v W ¸ 2 2· D2 u;v ¡D2  0   c  Gaussian bandpass ﬁlter:  Problem 5.13  A notch pass ﬁlter is obtained by subtracting the corresponding notch reject ﬁlter from 1:  Hnp u; v  = 1 ¡ Hnr u; v :  Then:   a  Ideal notch pass ﬁlter:  HInp u; v  =  1 if D1 u; v  · D0 or D2 u; v  · D0  0 otherwise  :   Problem 5.14  Problem 5.14 61   b  Butterworth notch pass ﬁlter:  HBnp u; v  = 1 ¡  =  1 D2 0  D2 0  D1  u;v D2  u;v in 1 +h D1  u;v D2  u;v in h D1  u;v D2  u;v in : 1 +h 2· D1 u;v D2 u;v   D2 0  D2 0  ¸  HGnp u; v  = 1 ¡"1 ¡ e¡ 1 2· D1 u;v D2 u;v   = e¡ 1  D2 0  ¸ :   c  Gaussian notch pass ﬁlter:  We proceed as follows:  F  u; v  = ZZ 1 = ZZ 1  ¡1  ¡1  Using the exponential deﬁnition of the sine function:  f  x; y e¡j2¼ ux + vy dx dy  A sin u0x + v0y e¡j2¼ ux + vy dx dy:  sin µ =  1  2j¡ejµ ¡ e¡jµ¢  gives us  F  u; v  = ¡jA  = ¡jA  2 ZZ 1 2 ·ZZ 1 2 ·ZZ 1  ¡1  ¡1  ¡1hej u0x + v0y  ¡ e¡j u0x + v0y i e¡j2¼ ux + vy dx dy ej2¼ u0x=2¼ + v0y=2¼ e¡j2¼ ux + vy dx dy¸ ¡ e¡j2¼ u0x=2¼ + v0y=2¼ e¡j2¼ ux + vy dx dy¸ : 1 £ ej2¼ u0x=2¼ + v0y=2¼   jA  These are the Fourier transforms of the functions  and  1 £ e¡j2¼ u0x=2¼ + v0y=2¼   respectively. The Fourier transform of the 1 gives an impulse at the origin, and the exponentials shift the origin of the impulse, as discussed in Section 4.6.1. Thus,  F  u; v  = ¡jA 2  h±³u ¡  u0 2¼  ; v ¡  v0  2¼´ ¡ ±³u +  u0 2¼  ; v +  v0  2¼´i :   62  Chapter 5 Problem Solutions  Problem 5.15  From Eq.  5.4 19   ¾2 =  1   2a + 1   2b + 1 XXf[g    ¡ w´   ] ¡ [g ¡ w´]g2  where  } indicates terms affected by the summations. Letting K = 1= 2a+1  2b+1 , taking the partial derivative of ¾2 with respect to w and setting the result equal to zero gives  @¾2 @w  = KXX 2 [g    ¡ w´    ¡ g + w´] [¡´    + ´] = 0 = KXX¡g   ´    + g   ´ + w´2    ¡ w´   ´ + g´    ¡ g´ ¡ w´´    + w´2  = 0 = ¡g´ + g´ + w´2 ¡ w´2 + g´ ¡ g´ ¡ w´2 + w´2 = 0 = ¡g´ + g´ + w³´2 ¡ ´2´ = 0  1   2a + 1   2b + 1 XX g   ´    = g´:  where, for example, we used the fact that  Solving for w gives us  Finally, inserting the variables x and y,  w =  g´ ¡ g´ ´2 ¡ ´2  :  w x; y  =  g x; y ´ x; y  ¡ g x; y ´ x; y   ´2 x; y  ¡ ´2 x; y   which agrees with Eq.  5.4 21 .  Problem 5.16  From Eq.  5.5 13 ,  It is given that f  x; y  = ± x ¡ a ; so f  ®; ¯  = ± ® ¡ a : Then, using the impulse response given in the problem statement,  f  ®; ¯ h x ¡ ®; y ¡ ¯  d® d¯:  ± ® ¡ a e¡[ x¡® 2+ y¡¯ 2] d® d¯  ¡1  g x; y  =ZZ 1 g x; y  =ZZ 1  ¡1   Problem 5.17  Problem 5.17 63  ± ® ¡ a e¡[ x¡® 2] e¡[ y¡¯ 2] d® d¯ ± ® ¡ a e¡[ x¡® 2] d®Z 1  ¡1  e¡[ y¡¯ 2] d¯  e¡[ y¡¯ 2] d¯  ¡1  ¡1  = ZZ 1 = Z 1 = e¡[ x¡a 2]Z 1 Z 1  ¡1  where we used the fact that the integral of the impulse is nonzero only when ® = a: Next, we note that  e¡[ y¡¯ 2] d¯ =Z 1 which is in the form of a constant times a Gaussian density with variance ¾2 = 1=2 or standard deviation ¾ = 1=p2. In other words,  e¡[ ¯¡y 2] d¯  ¡1  ¡1  e¡[ ¯¡y 2] =p2¼ 1=2 "  1  p2¼ 1=2    1=2  ¸ : e¡ 1=2 ·  ¯¡y 2  The integral from minus to plus inﬁnity of the quantity inside the brackets is 1, so  which is a blurred version of the original image.  g x; y  = p¼e¡[ x¡a 2]  Because the motion in the x  and y directions are independent  motion is in the vertical  x  direction only at ﬁrst, and then switching to motion only in the horizontal  y  direc  tion  this problem can be solved in two steps. The ﬁrst step is identical to the analysis that resulted in Eq.  5.6 10 , which gives the blurring function due to vertical motion only:  H1 u; v  =  sin ¼ua e¡j¼ua;  T1 ¼ua  where we are representing linear motion by the equation x0 t  = at=T1:The function H1 u; v  would give us a blurred image in the vertical direction. That blurred image is the image that would then start moving in the horizontal direction and to which horizon  tal blurring would be applied. This is nothing more than applying a second ﬁlter with transfer function  H2 u; v  =  sin ¼ub e¡j¼ub  T2 ¼ub  where we assumed the form y0 t  = bt=T2 for motion in the y direction. Therefore, the overall blurring transfer function is given by the product of these two functions:  H u; v  =  T1T2   ¼ua  ¼ub   sin ¼ua  sin ¼ub e¡j¼ ua¡ub ;   64  Chapter 5 Problem Solutions  and the overall blurred image is  g x; y  = =¡1 [H u; v F  u; v ] where F  u; v  is the Fourier transform of the input image.  Problem 5.18  Following the procedure in Section 5.6.3,  0  0  0  dt  e¡j¼uat2  e¡j2¼ux0 t dt  e¡j2¼u[ 1=2 at2]dt  H u; v  = Z T = Z T = Z T = Z T £cos ¼uat2  ¡ j sin ¼uat2 ¤ dt = r T 2 2¼uaT 2£C p¼uaT   ¡ jS p¼uaT  ¤ C x  =r2¼ T Z x S x  =r 2 ¼Z x  sin t2dt:  cos t2dt  0  0  0  where  and  These are Fresnel cosine and sine integrals. They can be found, for example, the Hand  book of Mathematical Functions, by Abramowitz, or other similar reference.  A basic approach for restoring a rotationally blurred image is to convert the image from rectangular to polar coordinates. The blur will then appear as one dimensional uniform motion blur along the µ axis. Any of the techniques discussed in this chapter for han  dling uniform blur along one dimension can then be applied to the problem. The image is then converted back to rectangular coordinates after restoration. The mathematical solution is simple. For any pixel with rectangular coordinates  x; y  we generate a cor  responding pixel with polar coordinates  r; µ , where  r =px2 + y2  Problem 5.19   Problem 5.20 65  and  µ = tan¡1³ y x´ :  A display of the resulting image would shown an image that is blurred along the µ axis and would, in addition, appear distorted due to the coordinate conversion. Since the extent of the rotational blur is known  it is given as ¼=8 radians , we can use the same solution we used for uniform linear motion  Section 5.6.3 , with x = µ and y = r to obtain the transfer function. Any of the methods in Sections 5.7 through 5.9 then become applicable.  Measure the average value of the background. Set all pixels in the image, except the cross hairs, to that gray level. Denote the Fourier transform of this image by G u; v . Since the characteristics of the cross hairs are given with a high degree of accuracy, we can construct an image of the background  of the same size  using the background gray levels determined previously. We then construct a model of the cross hairs in the correct location  determined from he given image  using the provided dimensions and gray level of the crosshairs. Denote by F  u; v  the Fourier transform of this new image . The ratio G u; v =F  u; v  is an estimate of the blurring function H u; v . In the likely event of vanishing values in F  u; v , we can construct a radially limited ﬁlter using the method discussed in connection with Fig. 5.27. Because we know F  u; v  and G u; v , and an estimate of H u; v , we can also reﬁne our estimate of the blurring function by substituting G and H in Eq.  5.8 3  and adjusting K to get as close as possible to a good result for F  u; v  [the result can be evaluated visually by taking the inverse Fourier transform]. The resulting ﬁlter in either case can then be used to deblur the image of the heart, if desired.  The key to solving this problem is to recognize that the given function  h r  =  r2 ¡ ¾2  ¾4  e¡r2=2¾2  h0 r  = e¡r2=2¾2  :  where r2 = x2 +y2, is the Laplacian  second derivative with respect to r  of the function  That is, r2[h0 r ] is equal to the given function. Then we know from Eq.  4.4 7  that,  Problem 5.20  Problem 5.21   66  Chapter 5 Problem Solutions  for a function f  x; y ,  =£r2f  x; y ¤ = ¡ u2 + v2 F  u; v :  Thus, we have reduced the problem to ﬁnding the Fourier transform of e¡r2=2¾2, which is in the form of a Gaussian function. From Table 4.1, we note from the Gaussian transform pair that the Fourier transform of a function of the form e¡ x2+y2 =2¾2 is  Therefore, the Fourier transform of the given degradation function is  H u; v  = =· r2 ¡ ¾2  =he¡ x2+y2 =2¾2i = p2¼¾e¡2¼2¾2 x2+y2 : e¡r2=2¾2¸ = =£r2h0 r ¤ = ¡ u2 + v2 F  u; v  = ¡p2¼¾ u2 + v2 e¡2¼2¾2 x2+y2 :  ¾4  This is a simple plugin problem. Its purpose is to gain familiarity with the various terms of the Wiener ﬁlter. From Eq.  5.8 3 ,  where  Then,  1  HW  u; v  =" jH u; v j2 = H¤ u; v H u; v   H u; v   jH u; v j2  jH u; v j2 + K  = 2¼¾2 u2 + v2 2e¡4¼2¾2 x2+y2 :  HW  u; v  = ¡" p2¼¾ u2 + v2 e¡2¼2¾2 x2+y2   £2¼¾2 u2 + v2 2e¡4¼2¾2 x2+y2 ¤ + K :  This also is a simple plugin problem, whose purpose is the same as the previous problem. From Eq.  5.9 4   HC u; v  =  H¤ u; v   jH u; v j2 +   jP  u; v j2  p2¼¾ u2 + v2 e¡2¼2¾2 x2+y2   = ¡  where P  u; v  is the Fourier transform of the Laplacian operator [Eq.  5.9 5 ]. This is as far as we can reasonably carry this problem. It is worthwhile pointing out to students  2¼¾2 u2 + v2 2e¡4¼2¾2 x2+y2  +   jP  u; v j2  Problem 5.22  Problem 5.23   that a closed expression for the transform of the Laplacian operator was obtained in Problem 4.19. However, substituting that solution for P  u; v  here would only increase the number of terms in the ﬁlter and would not aid at all in simplifying the expression.  Problem 5.24 67  Because the system is assumed linear and position invariant, it follows that Eq.  5.5 17  holds. Furthermore, we can use superposition and obtain the response of the system ﬁrst to F  u; v  and then to N u; v . The sum of the two individual responses gives the complete response. First, using only F  u; v ,  G1 u; v  = H u; v F  u; v   and  and  so that  Then, using only N u; v ,  jG1 u; v j2 = jH u; v j2 jF  u; v j2 :  G2 u; v  = N u; v   jG2 u; v j2 = jN u; v j2  jG u; v j2 = jG1 u; v j2 + jG2 u; v j2  = jH u; v j2 jF  u; v j2 + jN u; v j2 :  Problem 5.24  Problem 5.25   a  It is given that  2  2  From Problem 5.24,  = jR u; v j2 jG u; v j2 :  ¯¯¯ ^F  u; v ¯¯¯ ¯¯¯ ^F  u; v ¯¯¯ = jR u; v j2hjH u; v j2 jF  u; v j2 + jN u; v j2i : Forcing¯¯¯ ^F  u; v ¯¯¯ to equal jF  u; v j2 gives R u; v  ="  jH u; v j2 jF  u; v j2 + jN u; v j21=2  jF  u; v j2  :  2   68  Chapter 5 Problem Solutions  Problem 5.26  Problem 5.27   b   ^F  u; v  = R u; v G u; v   = " = 24 ^F  u; v  =24  jH u; v j2 jF  u; v j2 + jN u; v j21=2  jF  u; v j2  G u; v   1  jH u; v j2 + jN  u;v j2 jF  u;v j2  G u; v   1  jH u; v j2 + S´ u;v   Sf  u;v   G u; v :  1=2  35  1=2  35  and, because jF  u; v j2 = Sf  u; v  and jN u; v j2 = S´ u; v ;  One possible solution:  1  Average images to reduce noise.  2  obtain blurred image of a bright, single star to simulate an impulse  the star should be as small as possible in the ﬁeld of view of the telescope to simulate an impulse as closely as possible.  3  The Fourier transform of this image will give H u; v .  4  Use a Wiener ﬁlter and vary K until the sharpest image possible is obtained.  The basic idea behind this problem is to use the camera and representative coins to model the degradation process and then utilize the results in an inverse ﬁlter operation. The principal steps are as follows:  1. Select coins as close as possible in size and content as the lost coins. Select a back  ground that approximates the texture and brightness of the photos of the lost coins.  2. Set up the museum photographic camera in a geometry as close as possible to give images that resemble the images of the lost coins  this includes paying attention to illumination . Obtain a few test photos. To simplify experimentation, obtain a TV camera capable of giving images that resemble the test photos. This can be done by connecting the camera to an image processing system and generating digital images, which will be used in the experiment.  3. Obtain sets of images of each coin with different lens settings. The resulting images should approximate the aspect angle, size  in relation to the area occupied by the background , and blur of the photos of the lost coins.   Problem 5.28 69  4. The lens setting for each image in  3  is a model of the blurring process for the corresponding image of a lost coin. For each such setting, remove the coin and background and replace them with a small, bright dot on a uniform background, or other mechanism to approximate an impulse of light. Digitize the impulse. Its Fourier transform is the transfer function of the blurring process.  5. Digitize each  blurred  photo of a lost coin, and obtain its Fourier transform. At this  point, we have H u; v  and G u; v  for each coin.  6. Obtain an approximation to F  u; v  by using a Wiener ﬁlter. Equation  5.8 3  is particularly attractive because it gives an additional degree of freedom  K  for ex  perimenting.  7. The inverse Fourier transform of each approximate F  u; v  gives the restored image. In general, several experimental passes of these basic steps with various different settings and parameters are required to obtain acceptable results in a problem such as this.  Using triangular regions means three tiepoints, so we can solve the following set of linear equations for six coefﬁcients:  x0 = c1x + c2y + c3 y0 = c4x + c5y + c6  to implement spatial transformations. We also solve the following equation for three coefﬁcients  to implement gray level interpolation.  v x0; y0  = ax0 + by0 + c  Problem 5.28    6 Problem Solutions  Problem 6.1  Problem 6.2  From the ﬁgure, x = 0:43 and y = 0:4. Since x + y + z = 1, it follows that z = 0:17. These are the trichromatic coefﬁcients. We are interested in tristimulus values X, Y , and Z, which are related to the trichromatic coefﬁcients by Eqs.  6.1 1  through  6.1 3 . We note however, that all the tristimulus coefﬁcients are divided by the same constant, so their percentages relative to the trichromatic coefﬁcients are the same as those of the coefﬁcients. Thus, the answer is X = 0:43, Y = 0:40; and Z = 0:17.  Denote by c the given color, and let its coordinates be denoted by  x0; y0 . The distance between c and c1 is  Similarly the distance between c1 and c2  d c; c1  =h x0 ¡ x1 2 +  y0 ¡ y1 2i1=2 d c1; c2  =h x1 ¡ x2 2 +  y1 ¡ y2 2i1=2  :  :  The percentage p1 of c1 in c is  d c1; c2  ¡ d c; c1   p1 =  d c1; c2   £ 100: In the preceding equation we see, The percentage p2 of c2 is simply p2 = 100 ¡ p1. for example, that when c = c1, then d c; c1  = 0 and it follows that p1 = 100% and p2 = 0%. Similarly, when d c; c1  = d c1; c2 ; it follows that p1 = 0% and p2 = 100%. Values in between are easily seen to follow from these simple relations.   72  Chapter 6 Problem Solutions  Problem 6.3  Consider Fig. P6.3, in which c1, c2, and c3 are the given vertices of the color triangle and c is an arbitrary color point contained within the triangle or on its boundary. The key to solving this problem is to realize that any color on the border of the triangle is made up of proportions from the two vertices deﬁning the line segment that contains the point. The contribution to a point on the line by the color vertex opposite this line is 0% .  The line segment connecting points c3 and c is shown extended  dashed segment  until it intersects the line segment connecting c1 and c2. The point of intersection is denoted c0. Because we have the values of c1 and c2, if we knew c0, we could compute the percentages of c1 and c2 contained in c0 by using the method described in Problem 6.2. Denote the ratio of the content of c1 and c2 in c0 be denoted by R12. If we now add color c3 to c0, we know from Problem 6.2 that the point will start to move toward c3 along the line shown. For any position of a point along this line we could determine the percentage of c3 and c0, again, by using the method described in Problem 6.2. What is important to keep in mind that the ratio R12 will remain the same for any point along the segment connecting c3 and c0. The color of the points along this line is different for each position, but the ratio of c1 to c2 will remain constant.  So, if we can obtain c0, we can then determine the ratio R12, and the percentage of c3, in color c. The point c0 is not difﬁcult to obtain. Let y = a12x + b12 be the straight line containing points c1 and c2, and y = a3cx + b3c the line containing c3 and c. The intersection of these two lines gives the coordinates of c0. The lines can be determined uniquely because we know the coordinates of the two point pairs needed to determine the line coefﬁcients. Solving for the intersection in terms of these coordinates is straightforward, but tedious. Our interest here is in the fundamental method, not the mechanics of manipulating simple equations so we don not give the details.  At this juncture we have the percentage of c3 and the ratio between c1 and c2. Let the percentages of these three colors composing c be denoted by p1, p2, and p3 respectively. Since we know that p1 + p2 = 100¡ p3, and that p1=p2 = R12, we can solve for p1 and p2. Finally, note that this problem could have been solved the same way by intersecting one of the other two sides of the triangle. Going to another side would be necessary, for example, if the line we used in the preceding discussion had an inﬁnite slope. A simple test to determine if the color of c is equal to any of the vertices should be the ﬁrst step in the procedureu in this case no additional calculations would be required.   Problem 6.4 73  Figure P6.3  Problem 6.4  Problem 6.5  Problem 6.6  Use color ﬁlters sharply tuned to the wavelengths of the colors of the three objects. Thus, with a speciﬁc ﬁlter in place, only the objects whose color corresponds to that wavelength will produce a predominant response on the monochrome camera. A mo  torized ﬁlter wheel can be used to control ﬁlter position from a computer. If one of the colors is white, then the response of the three ﬁlters will be approximately equal and high. If one of the colors is black, the response of the three ﬁlters will be approximately equal and low.  At the center point we have  1 2  1 2  1 2  R +  B + G =   R + G + B  +  G = midgray +  G  1 2  1 2  which looks to a viewer like pure green with a boot in intensity due to the additive gray component.  For the image given, the maximum intensity and saturation requirement means that the RGB component values are 0 or 1. We can create the following table with 0 and 255   74  Chapter 6 Problem Solutions  representing black and white, respectively:  Color Black Red  Yellow Green Cyan Blue  Magenta White  R 0 1 1 0 0 0 1 1  G 0 0 1 1 1 0 0 1  Table P6.6 B Mono R Mono G Mono B 0 0 0 0 1 1 1 1  0 0 255 255 255 0 0 255  0 255 255 0 0 0 255 255  0 0 0 0 255 255 255 255  Gray  0.5  0.5  0.5  128  128  128  Thus, we get the monochrome displays shown in Fig. P6.6.  Figure P6.6  Problem 6.7  Problem 6.8  There are 28 = 256 possible values in each 8 bit image. For a color to be gray, all RGB components have to be equal, so there are 256 shades of gray.  In the Green image, the ﬁrst column is  a  All pixel values in the Red image are 255. all 0zsu the second column all 1zsu and so on until the last column, which is composed of all 255zs. In the Blue image, the ﬁrst row is all 255zsu the second row all 254zs, and so on until the last row which is composed of all 0zs.   Problem 6.9  Problem 6.9 75   b  Let the axis numbering be the same as in Fig. 6.7. Then:  0; 0; 0  = white,  1; 1; 1;   = black,  1; 0; 0  = cyan,  1; 1; 0  = blue,  1; 0; 1  = green,  0; 1; 1  = red,  0; 0; 1  = yellow,  0; 1; 0  = magenta.   c  The ones that do not contain the black or white point are fully saturated. The others decrease in saturation from the corners toward the black or white point.   a  For the image given, the maximum intensity and saturation requirement means that the RGB component values are 0 or 1. We can create Table P6.9 using Eq.  6.2 1 :  Table P6.9  Color Black Red  Yellow Green Cyan Blue  Magenta White  R 0 1 1 0 0 0 1 1  G 0 0 1 1 1 0 0 1  B 0 0 0 0 1 1 1 1  C M Y Mono C Mono M Mono Y 1 0 0 1 1 1 0 0  255 255 0 0 0 255 255 0  255 0 0 255 255 255 0 0  255 255 255 255 0 0 0 0  1 1 0 0 0 1 1 0  1 1 1 1 0 0 0 0  Gray  0.5  0.5  0.5  0.5  0.5  0.5  128  128  128  Thus, we get the monochrome displays shown in Fig. P6.9 a .   b  The resulting display is the complement of the starting RGB image. From left to right, the color bars are  in accordance with Fig. 6.32  white, cyan, blue, magenta, red, yellow, green, and black. The middle gray background is unchanged.  Figure P6.9   76  Chapter 6 Problem Solutions  Problem 6.10  Equation  6.2 1  reveals that each component of the CMY image is a function of a single component of the corresponding RGB imagexC is a function of R, M of G, and Y of B. For clarity, we will use a prime to denote the CMY components. From Eq.  6.5 6 , we know that  for i = 1; 2; 3  for the R, G, and B components . And from Eq.  6.2 1 , we know that the CMY components corresponding to the ri and si  which we are denoting with primes  are  si = kri  ri¶= 1 ¡ ri  si¶= 1 ¡ si:  ri = 1 ¡ ri¶  si¶= 1 ¡ si = 1 ¡ kri = 1 ¡ k  1 ¡ ri¶   si¶= kri¶+  1 ¡ k  :  and  Thus,  and  so that  Problem 6.11  Problem 6.12   a  The purest green is 00FF00, which corresponds to cell  7, 18 .   b  The purest blue is 0000FF, which corresponds to cell  12, 13 .  Using Eqs.  6.2 2  through  6.2 4 , we get the results shown in Table P6.12. Note that, in  0¢. accordance with Eq.  6.2 2 , hue is undeﬁned when R = G = B since µ = cos¡1¡ 0  In addition, saturation is undeﬁned when R = G = B = 0 since Eq.  6.2 3  yields   S = 1 ¡ 3 min 0   3¢0 = 1 ¡ 0  0. Thus, we get the monochrome display shown in Fig. P6.12.  Problem 6.13 77  Mono H Mono S Mono I  Color Black Red  Yellow Green Cyan Blue  Magenta White  R 0 1 1 0 0 0 1 1  G 0 0 1 1 1 0 0 1  B 0 0 0 0 1 1 1 1  Table P6.12  I 0  0.33 0.67 0.33 0.67 0.33 0.67  1  H w 0  0.17 0.33 0.5 0.67 0.83  w  w  S 0 1 1 1 1 1 1 0  0  w 0 43 85 128 170 213 w  w 255 255 255 255 255 255 0  0  0 85 170 85 170 85 170 255  128  Gray  0.5  0.5  0.5  0.5  w  Figure P6.12  Problem 6.13  With reference to the HSI color circle in Fig. 6.14 b , deep purple is found at approxi  mately 270±: To generate a color rectangle with the properties required in the problem statement, we choose a ﬁxed intensity I, and maximum saturation  these are spectrum colors, which are supposed to be fully saturated , S. The ﬁrst column in the rectangle uses these two values and a hue of 270±. The next column  and all subsequent columns  would use the same values of I and S, but the hue would be decreased to 269±, and so on all the way down to a hue of 0±, which corresponds to red. If the image is limited to 8 bits, then we can only have 256 variations in hue in the range from 270± down to 0±, which will require a different uniform spacing than one degree increments or, alterna  tively, starting at a 255± and proceed in increments of 1, but this would leave out most of the purple. If we have more than eight bits, then the increments can be smaller. Longer strips also can be made by duplicating column values.   78  Chapter 6 Problem Solutions  Problem 6.14  There are two important aspects to this problem. One is to approach it in HSI space and the other is to use polar coordinates to create a hue image whose values grow as a function of angle. The center of the image is the middle of whatever image area is used. Then, for example, the values of the hue image along a radius when the angle is 0± would be all 0zs. The angle then is incremented by, say, one degree, and all the values along that radius would be 1zs, and so on. Values of the saturation image decrease linearly in all radial directions from the origin. The intensity image is just a speciﬁed constant. With these basics in mind it is not difﬁcult to write a program that generates the desired result.  Problem 6.15  The hue, saturation, and intensity images are shown in Fig. P6.15, from left to right.  Figure P6.15  Problem 6.16   a  It is given that the colors in Fig. 6.16 a  are primary spectrum colors. It also is given that the gray level images in the problem statement are 8 bit images. The latter condition means that hue  angle  can only be divided into a maximum number of 256 values. Since hue values are represented in the interval from 0± to 360± this means that for an 8 bit image the increments between contiguous hue values are now 360=255. Another way of looking at this is that the entire [0, 360] hue scale is compressed to the range [0, 255]. Thus, for example, yellow  the ﬁrst primary color we encounter , which   Problem 6.17 79  is 60± now becomes 43  the closest integer  in the integer scale of the 8 bit image shown in the problem statement. Similarly, green, which is 120± becomes 85 in this image. From this we easily compute the values of the other two regions as being 170 and 213. The region in the middle is pure white [equal proportions of red green and blue in Fig. 6.61 a ] so its hue by deﬁnition is 0. This also is true of the black background.   b  The colors are spectrum colors, so they are fully saturated. Therefore, the values shown of 255 applies to all circle regions. The region in the center of the color image is white, so its saturation is 0.   c  The key to getting the values in this ﬁgure is to realize that the center portion of the color image is white, which means equal intensities of fully saturated red, green, and blue. Therefore, the value of both darker gray regions in the intensity image have value 85  i.e., the same value as the other corresponding region . Similarly, equal proportions of the secondaries yellow, cyan, and magenta produce white, so the two lighter gray regions have the same value  170  as the region shown in the ﬁgure. The center of the image is white, so its value is 255.   a  Because the infrared image which was used in place of the red component image has very high gray level values.   b  The water appears as solid black  0  in the near infrared image [Fig. 6.27 d ]. Threshold the image with a threshold value slightly larger than 0. The result is shown in Fig. P6.17. It is clear that coloring all the black points in the desired shade of blue presents no difﬁculties.   c  Note that the predominant color of natural terrain is in various shades of red. We al  ready know how to take out the water from  b . Thus a method that actually removes the }background} of red and black would leave predominantly the other man made struc  tures, which appear mostly in a bluish light color. Removal of the red [and the black if you do not want to use the method as in  b ] can be done by using the technique discussed in Section 6.7.2.  Problem 6.17   80  Chapter 6 Problem Solutions  Figure P6.17  Problem 6.18  Using Eq.  6.2 3 , we see that the basic problem is that many different colors have the same saturation value. This was demonstrated in Problem 6.12, where pure red, yellow, green, cyan, blue, and magenta all had a saturation of 1. That is, as long as any one of the RGB components is 0, Eq.  6.2 3  yields a saturation of 1.  Consider RGB colors  1, 0, 0  and  0, 0.59, 0 , which represent a red and a green. The HSI triplets for these colors [per Eq.  6.4 2  through  6.4 4 ] are  0, 1, 0.33  and  0.33, 1, 0.2 , respectively. Now, the complements of the beginning RGB values  see Section 6.5.2  are  0, 1, 1  and  1, 0.41, 1 , respectivelyu the corresponding colors are cyan and magenta. Their HSI values [per Eqs.  6.4 2  through  6.4 4 ] are  0.5, 1, 0.66  and  0.83, 0.48, 0.8 , respectively. Thus, for the red, a starting saturation of 1 yielded the cyan complemented} saturation of 1, while for the green, a starting saturation of 1 yielded the magenta complemented} saturation of 0.48. That is, the same starting saturation resulted in two different complemented} saturations. Saturation alone is not enough information to compute the saturation of the complemented color.  Problem 6.19  The complement of a color is the color opposite it on the color circle of Fig. 6.32. The hue component is the angle from red in a counterclockwise direction normalized by 360 degrees. For a color on the top half of the circle  i.e., 0 · H · 0:5 , the hue of the complementary color is H + 0:5. For a color on the bottom half of the circle  i.e., for   0:5 · H · 1 , the hue of the complement is H ¡ 0:5.  Problem 6.20  Problem 6.20 81  The RGB transformations for a complement [from Fig. 6.33 b ] are:  where i = 1; 2; 3  for the R, G, and B components . But from the deﬁnition of the CMY space in Eq.  6.2 1 , we know that the CMY components corresponding to ri and si, which we will denote using primes, are  Thus,  and  so that  Problem 6.21  si¶= 1 ¡ si = 1 ¡  1 ¡ ri  = 1 ¡  1 ¡  1 ¡ ri¶    The RGB transformation should darken the highlights and lighten the shadow areas, effectively compressing all values toward the midtones. The red, green, and blue com  ponents should be transformed with the same mapping function so that the colors do not change. The general shape of the curve would be as shown in Fig. P6.21.  si = 1 ¡ ri  ri¶= 1 ¡ ri si¶= 1 ¡ si:  ri = 1 ¡ ri¶  s¶= 1 ¡ ri¶:  Figure P6.21   82  Chapter 6 Problem Solutions  Problem 6.22  Problem 6.23  Based on the discussion is Section 6.5.4 and with reference to the color wheel in Fig. 6.32, we can decrease the proportion of yellow by  1  decreasing yellow,  2  increasing blue,  3  increasing cyan and magenta, or  4  decreasing red and green.  The L¤a¤b¤ components are computed using Eqs.  6.5 9  through  6.5 12 . Reference white is R = G = B = 1. The computations are best done in a spreadsheet, as shown in Table P6.23.  Problem 6.24  Problem 6.25  The conceptually simplest approach is to transform every input image to the HSI color space, perform histogram speciﬁcation per the discussion in Section 3.3.2 on the inten  sity  I  component only  leaving H and S alone , and convert the resulting intensity component with the original hue and saturation components back to the starting color space.   a  The boundary between red and green becomes thickened and yellow as a result of blurring between the red and green primaries  recall that yellow is the color between green and red in, for example, Fig. 6.14 . The boundary between green and blue is similarly blurred into a cyan color. The result is shown in Fig. P6.25.    b  Blurring has no effect in this case. The intensity image is constant  at its maximum value  because the pure colors are fully saturated.  Problem 6.26 83  Problem 6.26  This is a simple problem to encourage the student to think about the meaning of the elements in Eq.  6.7 2 . When C = I, it follows that C¡1 = I and Eq.  6.7 2  becomes  D z; a  =£ z ¡ a T  z ¡ a ¤1=2  :  But the term inside the brackets is recognized as the inner product of the vector  z ¡ a  with itself, which, by deﬁnition, is equal to the right side of Eq.  6.7 1 .  Figure P6.25  Problem 6.27   a  The cube is composed of 6 intersecting planes in RGB space. The general equation for such planes is  a zR + b zG + c zB + d = 0  where a, b, c, and d are parameters and the zzs are the components of any point  vector  z in RGB space lying on the plane. If an RGB point z does not lie on the plane, and its coordinates are substituted in the preceding equation, then equation will give either a positive or a negative valueu it will not yield zero. We say that z lies on the positive or negative side of the plane, depending on whether the result is positive or negative. We can change the positive side of a plane by multiplying its coefﬁcients  except d  by ¡1. Suppose that we test the point a given in the problem statement to see whether it is on the positive or negative side each of the six planes composing the box, and change the   84  Chapter 6 Problem Solutions  coefﬁcients of any plane for which the result is negative. Then, a will lie on the positive side of all planes composing the bounding box. In fact all points inside the bounding box will yield positive values when their coordinates are substituted in the equations of the planes. Points outside the box will give at least one negative or zero value. Thus, the method consists of substituting an unknown color point in the equations of all six planes. If all the results are positive, the point is inside the boxu otherwise it is outside the box. A ›ow diagram is asked for in the problem statement to make it simpler to evaluate the studentzs line of reasoning.   b  If the box is lined up with the RGB coordinate axes, then the planes intersect the RGB coordinate planes perpendicularly. The intersections of pairs of parallel planes establish a range of values along each of the RGB axis that must be checked to see if the if an unknown point lies inside the box or not. This can be done on an image per image basis  i.e., the three component images of an RGB image , designating by 1 a coordinate that is within its corresponding range and 0 otherwise. These will produce three binary images which, when ANDed, will give all the points inside the box.  The sketch is an elongated ellipsoidal ﬁgure in which the length lined up with the R axis is 8 times longer that the other two dimensions. In other words, the ﬁgure looks like a blimp aligned with the R axis.  Set one of the three primary images to a constant value  say, 0 , then consider the two images shown in Fig. P6.29. If we formed an RGB composite image by letting the im  age on the left be the red component and the image on the right the green component, then the result would be an image with a green region on the left separated by a vertical edge from a red region on the right. To compute the gradient of each component image we take second order partial derivatives. In this case, only the component of the deriv  ative in the horizontal direction is nonzero. If we model the edge as a ramp edge [Fig. 3.38 b ] then a proﬁle of the derivative image would appear as shown in Fig. P6.29. The magniﬁed view shows clearly that the derivatives of the two images are mirrors of each other. Thus, if we computed the gradient vector of each image and added the results as suggested in the problem statement, the components of the gradient would cancel out, giving a zero gradient for a color image that has a clearly deﬁned edge between two dif   Problem 6.28  Problem 6.29   ferent color regions. This simple example illustrates that the gradient vector of a color image is not equivalent to the result of forming a color gradient vector from the sum of the gradient vectors of the individual component images.  Problem 6.28 85  Figure P6.29    Problem 7.1  Problem 7.2  7 Problem Solutions  Following the explanation in Example 7.1, the decoder is as shown in Fig. P7.1  Figure P7.1  " 3:5 11:5 13:5   5:5  A mean approximation pyramid is formed by forming 2 £ 2 block averages. Since the starting image is of size 4 £ 4, J = 2, and f x; y  is placed in level 2 of the mean approximation pyramid. The level 1 approximation is  by taking 2 £ 2 block averages over f  x; y  and subsampling :  and the level 0 approximation is similarly [8.5]. The completed mean approximation pyramid is  266664  3 7  1 4 2 5 6 8 9 10 11 12 13 14 15 16  11:5 13:5 h 8:5 i : " 3:5  5:5  377775   88  Chapter 7 Problem Solutions  Since no interpolation ﬁltering is speciﬁed, pixel replication is used in the generation of the mean prediction residual pyramid levels. Level 0 of the prediction residual pyramid is the lowest resolution approximation, [8.5]. The level 2 prediction residual is obtained by upsampling the level 1 approximation and subtracting it from the level 2  original image . Thus, we get  266664  3 7  4 2 1 6 8 5 10 11 12 9 13 14 15 16  3:5 3:5  5:5 5:5  5:5 3:5 3:5 5:5 11:5 11:5 13:5 13:5 11:5 11:5 13:5 13:5  377775  ¡  266664  377775  =266664  2:5  ¡2:5 ¡1:5 ¡2:5 ¡1:5 1:5 2:5 ¡2:5 ¡1:5 ¡2:5 ¡1:5 2:5 1:5  2:5  1:5  1:5  :377775  Similarly, the level 1 prediction residual is obtained by upsampling the level 0 approxi  mation and subtracting it from the level 1 approximation to yield  " 3:5 11:5 13:5  ¡" 8:5 8:5  8:5 8:5  =" ¡5 ¡3 5  :  5:5  3  The mean prediction residual pyramid is therefore  266664  2:5  ¡2:5 ¡1:5 ¡2:5 ¡1:5 1:5 2:5 ¡2:5 ¡1:5 ¡2:5 ¡1:5 2:5 1:5  1:5  1:5  2:5  " ¡5 ¡3  5  [8:5] :  3  377775  Problem 7.3  The number of elements in a J + 1 level pyramid is bounded by 4 3  see Section 7.1.1 :  22J"1 +  1  4 1 +  1  4 2 + ¢¢ ¢ +  1   4 J ·  4 3  22J   for J > 0. We can generate Table P7.3:  Problem 7.4 89  Table P7.3  Pyramid Elements Compression Ratio  1 5 21 85  1  5=4 = 1:25  21=16 = 1:3125 85=86 = 1:328  4=3 = 1:33  J 0 1 2 3 ... 1  All but the trivial case  J = 0  are expansions. The expansion factor is a function of and bounded by 4 3 or 1.33.  Problem 7.4   a  The QMF ﬁlters must satisfy Eqs.  7.1 9  and  7.1 10 . From Table 7.1, G0 z  = H0 z  and H1 z  = H0 ¡z , so H1 ¡z  = H0 z . Thus, beginning with Eq.  7.1 9 ,  Similarly, beginning with Eq.  7.1 10  and substituting for H1 z , G0 z , and G1 z  from rows 2, 3, and 4 of Table 7.1, we get  H0 ¡z G0 z  + H1 ¡z G1 z  = 0 H0 ¡z H0 z  ¡ H0 z H0 ¡z  = 0 0 = 0:  H0 z G0 z  + H1 z G1 z  = 2 H0 z H0 z  + H0 ¡z [¡H0 ¡z ] = 2 0  ¡z  = 2  H2 0  z  ¡ H 2  which is the design equation for the H0 z  prototype ﬁlter in row 1 of the table.   b  The orthonormal ﬁlter proof follows the QMF proof in  a . For Eq.  7.1 9 , we get  H0 ¡z G0 z  + H1 z G1 z  = 0 G0[ ¡z ¡1]G0 z  + G1[ ¡z ¡1][¡z¡2K+1G0 ¡z¡1 ] = 0 G0 ¡z¡1 G0 z  ¡ z¡2K+1G1 ¡z¡1 G0 ¡z¡1  = 0 G0 ¡z¡1 G0 z  ¡ z¡2K+1[¡ ¡z¡1 ¡2K+1G0 ¡[¡z¡1]¡1 ]G0 ¡z¡1  = 0 G0 ¡z¡1 G0 z  ¡ z¡2K+1[z2K¡1G0 z ]G0 ¡z¡1  = 0 G0 ¡z¡1 G0 z  ¡ G0 z G0 ¡z¡1  = 0:  Similarly, beginning with Eq.  7.1 10 ,   90  Chapter 7 Problem Solutions  H0 z G0 z  + H1 z G1 z  = 2 G0 z¡1 G0 z  + G1 z¡1 G1 z  = 2 G0 z¡1 G0 z  + [¡ ¡z¡1 ¡2K+1G0 ¡[¡z¡1]¡1 ][¡z¡2K+1G0 ¡z¡1 ] = 2 G0 z¡1 G0 z  +  ¡z¡2K+1  ¡z¡[¡2K+1] G0 ¡z G0 ¡z¡1  = 2 G0 z¡1 G0 z  + G0 ¡z G0 ¡z¡1  = 2  which is the design equation for the G0 z  prototype ﬁlter in row 3 of the table.  Problem 7.5  Problem 7.6  To be biorthogonal, QMF ﬁlters must satisfy matrix Eq.  7.1 13 . Letting  in that expression we can write  2  ® =  det[Hm z ]  G0 z  = ®H1 ¡z  G1 z  = ¡®H0 ¡z   and see that the QMF ﬁlters in column 1 of Table 7.1 do satisfy it with ® = 1. Thus, QMF ﬁlters are biorthogonal. They are not orthonormal, however, since they do not satisfy the requirements of column 3 in Table 7.1. For QMF ﬁlters, for instance,  but orthonormality  see column 3  requires that H1 z  = G1 z¡1 .  H1 z  = H0 ¡z  = ¡G1 z   Example 7.2 deﬁnes h0 n  for n = 0; 1; 2; : : : ; 7 to be about ¡0:01, 0:03, 0:03, ¡0:19, ¡0:03, 0:63, 0:72, 0:23. Using Eq.  7.1 23  with 2K = 8, we can write  g0 7 ¡ n  = h0 n   g1 n  =  ¡1 ng0 7 ¡ n :  Thus g0 n  is time reversed h0 n , or 0:23, 0:72, 0:63, ¡0:03,¡0:19, 0:03, 0:03, ¡0:01. In addtion, g1 n  is a time reversed and modulated copy of g0 n u that is, ¡0:01, ¡0:03,0:03, 0:19, ¡0:03, ¡0:63, 0:72, ¡0:23. To numerically prove the orthonormality of the ﬁlters, let m = 0 in Eq.  7.1 22 :  hgi n gj n i = ± i ¡ j  with i; j = f0; 1g:  Iterating over i and j we get   Problem 7.7 91  Xn  g2  0 n  = Xn  = 1  g2 1  n   g0 n g1 n  = 0:  Xn  Substitution of the ﬁlter coefﬁcient values into these two equations yields:  g0 n g1 n  =  0:23  ¡0:01  +  0:72  ¡0:03  +  0:63  0:03  +  Xn   ¡0:03  0:19  +  ¡0:19  ¡0:03  +  0:03  ¡0:63  +  0:03  0:72  +  ¡0:01  ¡0:23   = 0  Xn  g2  0 n  = Xn  g2 1 n   =  §0:23 2 +  0:72 2 +  §:63 2 +  ¡0:03 2 +  §0:19 2 +   0:03 2 +  §0:03 2 +  ¡0:01 2  = 1:  Problem 7.7  Reconstruction is performed by reversing the decomposition processu that is, by replac  ing the downsamplers with upsamplers and the analysis ﬁlters by their synthesis ﬁlter counterparts, as shown in Fig. P7.7.  Figure P7.7   92  Chapter 7 Problem Solutions  Problem 7.8  Problem 7.9  The Haar transform matrix for N = 8 is  H8 =  1 p8  2666666666666664  1 1  1 1  1 1  1 1  p2 p2 ¡p2 ¡p2 0 0 2 ¡2 0 0 0 0 0 0  0 0 ¡2 0 0  0 0 2 0 0  1  1 1 1 ¡1 ¡1 ¡1 ¡1 0 0 0 p2 p2 ¡p2 ¡p2  0  0 0 0 0 2 ¡2 0 0  0 0 0 2  0 0 0 ¡2  3777777777777775   a  Equation  7.1 28  deﬁnes the 2 £ 2 Haar transformation matrix as  1  1  H2 =  p2" 1 1 ¡1  : 1 ¡1 " 3 ¡1 p2¶2" 1  1  6  2 " 1  1  1 ¡1   Then, using Eq.  7.1 24 , we get  T = HFH =µ 1 ¡3 0  : = " 5  4   b  First, compute  c  1  H¡1  2 =" a b d  1 ¡1  =" 1 0 p2" 1 0 1  : 1 ¡1  p2" 1  =  1  1  = H2:  " a b c d  1  H¡1 2  Solving this matrix equation yields  so that  Thus,   Problem 7.10 93  F = H¡1TH¡1  1  p2¶2" 1 1 ¡1 " 5 = µ 1 2  : = " 3 ¡1  6  4  ¡3 0 " 1  1 ¡1   1  Problem 7.10   a  The basis is orthonormal and the coefﬁcients are computed by the vector equivalent of Eq.  7.2 5 :  1p2 i" 3 2  ®0 = h 1p2 5p2 2 ®1 = h 1p2 ¡ 1p2 i" 3 2   =  p2 2  =  ®0 = h 1 ¡1 i" 3 2  ®1 = h 0 1 i" 3 2   = 1  = 2  so,  so,  5p2 2  p2 2  '0 +  '1 =  1p2  +  2 " p2  1p2  ¡ 1p2   2 " 1p2 5p2 = " 3 2  :   b  The basis is biorthonormal and the coefﬁcients are computed by the vector equivalent of Eq.  7.2 3 :   94  Chapter 7 Problem Solutions   c  The basis is overcomplete and the coefﬁcients are computed by the vector equivalent of Eq.  7.2 3 :  0  + 2" 1 '0 + 2'1 = " 1 1  = " 3 2  :  3  ®0 = h 2 ®1 = h ¡ 1  = 2  3  = ¡1 +  ®2 = h ¡ 1  = ¡1 ¡  p3  0 i" 3 2  3 i" 3 2  3 i" 3 2   2p3 3  p3  3 ¡ 2p3 3  so,  2'0 +"¡1 +  3  '1 +"¡1 ¡ 2p3  3  '2 = 2" 1 0  + 2p3 2  + 3 " ¡ 1 "¡1 + 2p3 "¡1 ¡ 3 " ¡ 1 2  2p3 = " 3 2  :  2p3  2 p3  ¡  Problem 7.11  As can be seen in Fig. P7.11, scaling function '0;0 x  cannot be written as a sum of double resolution copies of itself. Note the gap between '1;0 x  and '1;1 x .   Problem 7.12 95  Figure P7.11  Problem 7.12  Substituting j = 3 into Eq.  7.2 13  we get  Using the Haar scaling function in Eq.  7.2 14  we get the results shown in Fig. P7.12.  V3 = Span  k f'3;k x g k f23=2' 23x ¡ k g k f2p2' 8x ¡ k g:  = Span  = Span  Figure P7.12   96  Chapter 7 Problem Solutions  Problem 7.13  From Eq.  7.2 19  we ﬁnd that  Ã3;3 x  = 23=2Ã 23x ¡ 3  = 2p2Ã 8x ¡ 3   and using the Haar wavelet function deﬁnition from Eq.  7.2 30 , obtain the plot shown in Fig. P7.13.  To express Ã3;3 x  as a function of scaling functions, we employ Eq.  7.2 28  and the Haar wavelet vector deﬁned in Example 7.6xthat is, hÃ 0  = 1=p2 and hÃ 1  = ¡1=p2. Thus we get  Ã x  =Xn  hÃ n p2' 2x ¡ n  hÃ n p2' 2[8x ¡ 3] ¡ n  p2' 16x ¡ 6  +µ¡1  = ' 16x ¡ 6  ¡ ' 16x ¡ 7 :  so that  Ã 8x ¡ 3  = Xn 1 p2 Then, since Ã3;3 = 2p2Ã 8x ¡ 3 ,  =  p2¶p2' 16x ¡ 7   Ã3;3 = 2p2Ã 8x ¡ 3   = 2p2' 16x ¡ 6  ¡ 2p2' 16x ¡ 7 :  Figure P7.13  Problem 7.14  Using Eq.  7.2 22 ,   Problem 7.15 97  V3 = V2   W2  = V1   W1   W2 = V0   W0   W1   W2: The scaling and wavelet functions are plotted in Fig. P7.14.  Figure P7.14  Problem 7.15  With j0 = 1 the approximation coefﬁcients are c1 0  and c1 1 :  c1 0  =  c1 1  =  1=2Z0 x2p2dx = 1Z1=2 x2p2dx =  p2 24 7p2 24  :  Therefore, the V1 approximation is p2 24  '1;0 x  +  '1;1  x  ;  7p2 24  which, when plotted, is identical to the V1 approximation in Fig. 7.13 d . The last two coefﬁcients are d1 0  and d1 1 , which are computed as in the example. Thus, the   98  Chapter 7 Problem Solutions  expansion is  p2 24  y =  '1;0 x  +  7p2 24  '1;1 x  +"¡p2  32  Ã1;0 x  ¡  3p2 32  Ã1;1 x  + ¢ ¢¢  Problem 7.16   a  Since M = 4, J = 2, and j0 = 1, the summations in Eqs.  7.3 5  through  7.3 7  are performed over x = 0; 1; 2; 3, j = 1, and k = 0; 1. Using Haar functions and assuming that they are distributed over the range of the input sequence, we get  W' 1; 0  =  W' 1; 1  =  WÃ 1; 0  =  WÃ 1; 1  =  =  =  =  =  1  1  1  1  5p2 2  2£f  0 '1;0 0  + f  1 '1;0 1  + f  2 '1;0 2  + f  3 '1;0 3 ¤ 2h 1  p2  +  4  p2  +  ¡3  0  +  0  0 i = 2£f  0 '1;1 0  + f  1 '1;1 1  + f  2 '1;1 2  + f  3 '1;1 3 ¤ 2h 1  0  +  4  0  +  ¡3  p2  +  0  p2 i = ¡3p2 2£f  0 Ã1;0 0  + f 1 Ã1;0 1  + f 2 Ã1;0 2  + f  3 Ã1;0 3 ¤ p2  +  ¡3  0  +  0  0 i = ¡3p2 2h 1  p2  +  4  ¡ 2£f  0 Ã1;1 0  + f 1 Ã1;1 1  + f 2 Ã1;1 2  + f  3 Ã1;1 3 ¤ 2h 1  0  +  4  0  +  ¡3  p2  +  0  ¡p2 i = ¡3p2  2  2  2  1  1  1  1  so that the DWT is f5p2=2;¡3p2=2; ¡3p2=2; ¡3p2=2g:   b  Using Eq.  7.3 7 ,  f x  =  [W' 1; 0 '1;0 x  + W' 1; 1 '1;1 x  +  1 2 WÃ 1; 0 Ã1;0 x  + WÃ 1; 1 Ã1;1 x ]  which, with x = 1, becomes p2 4 h 5  p2  +  ¡3  0  +  ¡3  p2  +  ¡3  0 i 2 p2 2  f  1  =  =  = 1:  4  Problem 7.17  Intuitively, the continuous wavelet transform  CWT  calculates a resemblance index}   Problem 7.18 99  between the signal and the wavelet at various scales and translations. When the index is large, the resemblance is strongu else it is weak. Thus, if a function is similar to itself at different scales, the resemblance index will be similar at different scales. The CWT coefﬁcient values  the index  will have a characteristic pattern. As a result, we can say that the function whose CWT is shown is self similarxlike a fractal signal.   a  The scale and translation parameters are continuous, which leads to the overcom  pleteness of the transform.   b  The DWT is a better choice when we need a space saving representation that is sufﬁcient for reconstruction of the original function or image. The CWT is often easier to interpret because the built in redundancy tends to reinforce traits of the function or image. For example, see the self similarity of Problem 7.18.  The ﬁlter bank is the ﬁrst bank in Fig.  7.17 , as shown in Fig. P7.19:  Problem 7.18  Problem 7.19  Figure P7.19  Problem 7.20  The complexity is determined by the number of coefﬁcients in the scaling and wavelet vectorsxthat is, by n in Eqs.  7.2 18  and  72 28 . This deﬁnes the number of taps in ﬁlters hÃ  ¡n , h'  ¡n , hÃ  n , and h'  n .   100  Chapter 7 Problem Solutions  Problem 7.21   a  Input ' n  = f1; 1; 1; 1; 1; 1; 1; 1g = '0;0 n  for a three scale wavelet transform with Haar scaling and wavelet functions. Since wavelet transform coefﬁcients measure the similarity of the input to the basis functions, the resulting transform is  fW' 0; 0 ; WÃ 0; 0 ; WÃ 1; 0 ; WÃ 1; 1 ; WÃ 2; 0 ; WÃ 2; 1 ; WÃ 2; 2   WÃ 2; 3 g = f2p2; 0; 0; 0; 0; 0; 0; 0g  The W' 0; 0  term can be computed using Eq.  7.3 5  with j0 = k = 0.   b  Using the same reasoning as in part  a , the transform is f0; 2p2; 0; 0; 0; 0; 0; 0g.   c  For the given transform, WÃ 2; 2  = B and all other transform coefﬁcients are 0. Thus, the input must be proportional to Ã2;2 x . The input sequence must be of the form f0; 0; 0; 0; C;¡C; 0; 0g for some C. To determine C, use Eq.  7.3 6  to write WÃ 2; 2  =  1 p8ff  0 Ã2;2 0  + f 1 Ã2;2 1  + f 2 Ã2;2 2  + f  3 Ã2;2 3  + f  4 Ã2;2 4  + f  5 Ã2;2 5  + f 6 Ã2;2 6  + f  7 Ã2;2 7 g 1 p8f 0  0  +  0  0  +  0  0  +  0  0  +  C  2  +  ¡C  ¡2  +  0  0  +  0  0 g 1 p8f2C + 2Cg =  = p2C:  4C p8  =  =  Because this coefﬁcient is known to have the value B, we have that p2C = B or  p2 2  C =  B:  Thus, the input sequence is f0; 0; 0; 0;p2B=2;¡p2B=2; 0; 0g. To check the result  substitute these values into Eq.  7.3 6 :  WÃ 2; 2  =  1 p8f 0  0  +  0  0  +  0  0  +  0  0  +    p2 2  B  2  +  p2 B  ¡2  +  0  0  +  0  0 g  ¡ 2 p2B + p2Bg 1 p8f  =  = B:  Problem 7.22  They are both multi resolution representations that employ a single reduced resolution   Problem 7.23 101  approximation image and a series of difference} images. For the FWT, these differ  ence} images are the transform detail coefﬁcientsu for the pyramid, they are the predic  tion residuals.  To construct the approximation pyramid that corresponds to the transform in Fig. 7.8 a , we will use the F W T ¡1 2 d synthesis bank of Fig. 7.22 c . First, place the 64 £ 64 ap  proximation coefﬁcients} from Fig. 7.8 a  at the top of the pyramid being constructed. Then use it, along with 64 £ 64 horizontal, vertical, and diagonal detail coefﬁcients from the upper left of Fig. 7.8 a , to drive the ﬁlter bank inputs in Fig. 7.22 c . The output will be a 128 £ 128 approximation of the original image and should be used as the next level of the approximation pyramid. The 128£ 128 approximation is then used with the three 128 £ 128 detail coefﬁcient images in the upper 1 4 of the transform in Fig. 7.8 a  to drive the synthesis ﬁlter bank in Fig. 7.22 c  a second timexproducing a 256 £ 256 approximation that is placed as the next level of the approximation pyra  mid. This process is then repeated a third time to recover the 512 £ 512 original image, which is placed at the bottom of the approximation pyramid. Thus, the approximation pyramid would have 4 levels.  Problem 7.23  One pass through the FWT 2 d ﬁlter bank of Fig. 7.22 a  is all that is required  see Fig. P7.23 :  Figure P7.23   102  Chapter 7 Problem Solutions  Problem 7.24  As can be seen in the sequence of images that are shown, the DWT is not shift in  variant. If the input is shifted, the transform changes. Since all original images in the problem are 128 £ 128, they become the W' 7; m; n  inputs for the FWT computa  tion process. The ﬁlter bank of Fig. 7.22 a  can be used with j + 1 = 7. For a single scale transform, transform coefﬁcients W' 6; m; n  and W i Ã 6; m; n  for i = H; V; D are generated. With Haar wavelets, the transformation process subdivides the image into non overlapping 2 £ 2 blocks and computes 2 point averages and differences  per the scaling and wavelet vectors . Thus, there are no horizontal, vertical, or diagonal detail coefﬁcients in the ﬁrst two transforms shownu the input images are constant in all 2 £ 2 blocks  so all differences are 0 . If the original image is shifted by 1 pixel, detail coef  ﬁcients are generated since there are then 2 £ 2 areas that are not constant. This is the case in the third transform shown.  Problem 7.25  The table is completed as shown in Fig. P7.25.  Figure P7.25  The functions are determined using Eqs.  7.2 18  and  7.2 28  with the Haar scaling and   Problem 7.26 103  wavelet vectors from Examples 7.5 and 7.6:  ' x  = ' 2x  + ' 2x ¡ 1  Ã x  = ' 2x  ¡ ' 2x ¡ 1 :  Problem 7.26   a  The analysis tree is shown in Fig. P7.26 a :   b  The corresponding frequency spectrum is shown in Fig. P7.26 b :  Figure P7.26  Problem 7.27  First use the entropy measure to ﬁnd the starting value for the input sequence, which is  Eff  n g =  7Xn=0  f 2 n  ln£f 2 n ¤ = 2:7726:   104  Chapter 7 Problem Solutions  Then perform an iteration of the FWT and compute the entropy of the generated approx  imation and detail coefﬁcients. They are 2.0794 and 0, respectively. Since their sum is less than the starting entropy of 2.7726, we will use the decomposition.  Because the detail entropy is 0, no further decomposition of the detail is warranted. Thus, we perform another FWT iteration on the approximation to see if it should be decomposed again. This process is then repeated until no further decompositions are called for. The resulting optimal tree is shown in Fig. P7.27:  Figure P7.27   8 Problem Solutions  Problem 8.1  Problem 8.2   a  A histogram equalized image  in theory  has a gray level distribution which is uni  form. That is, all gray levels are equally probable. Eq.  8.1 4  thus becomes  where 1=2n is the probability of occurrence of any gray level. Since all levels are equally probable, there is no advantage to assigning any particular gray level fewer bits than any other. Thus, we assign each the fewest possible bits required to cover the 2n levels. This, of course is n bits and Lavg becomes n bits also:  Lavg =   rk   1 2n  2n¡1Xk=0  Lavg =   n   1 2n  2n¡1Xk=0  1 2n  2n  n  =  = n:   b  Since interpixel redundancy is associated with the spatial arrangement of the gray levels in the image, it is possible for a histogram equalized image to contain a high level of interpixel redundancy   or none at all.   a  A single line of raw data contains n1 = 2n bits. The maximum run length would be 2n and thus require n bits for representation. The starting coordinate of each run also requires n bits since it may be arbitrarily located within the 2n pixel line. Since a run length of 0 can not occur and the run length pair  0; 0  is used to signal the start of each new line   an additional 2n bits are required per line. Thus, the total number of bits   106  Chapter 8 Problem Solutions  required to code any scan line is  where Navg is the average number of run length pairs on a line. To achieve some level of compression, CR must be greater than 1. So,  n2 = 2n + Navg  n + n   = 2n  1 + Navg   CR =  n1 n2  2n  =  2n  1 + Navg   > 1  Navg <  2n¡1 n ¡ 1:  and  Problem 8.3   b  For n = 10, Navg must be less than 50.2 run length pairs per line.  Table P8.3 shows the data, its 6 bit code, the IGS sum for each step, the actual IGS 3 bit code and its equivalent decoded value, the error between the decoded IGS value and the input values, and the squared error.  Data  6 bit Code  Sum IGS Code Decoded IGS Error  Sq. Error  Table P8.3  000000 001100 010000 001101 010010 001100 010001 111001 110111  001100 001100 001101 001101 001010 001101 111001 110110  12 12 13 13 10 13 57 54  001 010 001 010 001 010 111 110  8 16 8 16 8 16 56 48  4  4 5  3 2  3 1 6  16 16 25 9 4 9 1 36  Problem 8.4  The average square error is the sum of the last column of the table in Problem 8.3 divided by 8, the number of data points. This computation yields 116 8 or 14.5. The rms error is then 3.81, the square root of 14.5. The squared signal value  i.e., 6400  is obtained by   summing the squares of column 5 of the table. The rms signal to noise ratio is then  SN Rrms = 2r6400  116  = 7:43  Problem 8.5 107  Problem 8.5   a  For the ﬁrst value of the table  i.e., 0110 , substitution into Eq.  8.2 1  gives:  h1 = b3   b2   b0 = 0   1   0 = 1 h2 = b3   b1   b0 = 0   1   0 = 1 h3 = b3 = 0 h4 = b2   b1   b0 = 1   1   0 = 0 h5 = b2 = 1 h6 = b1 = 1 h7 = b0 = 0:  Thus, the encoded value is 1100110. The remaining values of Table 8.2 are treated similarly. The resulting code words are 0011001, 1110000, and 1111111, respectively.   b  For 1100111, construct the following three bit odd parity word: c1 = h1   h3   h5   h7 = 1   0   1   1 = 1 c2 = h2   h3   h6   h7 = 1   0   1   1 = 1 c4 = h4   h5   h6   h7 = 0   1   1   1 = 1:  A parity word of 1112 indicates that bit 7 is in error. The correctly decoded binary value is 01102. In a similar manner, the parity words for 1100110 and 1100010 are 000 and 101, respectively. The decoded values are identical and are 0110.  Problem 8.6  Problem 8.7  The conversion factors are computed using the logarithmic relationship  Thus, 1 Hartley = 3.3219 bits and 1 nat = 1.4427 bits.  loga x =  logb x:  1  logb a  Let the set of source symbols be fa1; a2; :::; aqg with probabilities  z = [P  a1  ; P  a2  ; :::; P  aq ]T :   108  Chapter 8 Problem Solutions  Then, using Eq.  8.3 3  and the fact that the sum of all P  ai  is 1, we get  log q ¡ H  z  =  P  ai  log q +  P  ai  log P  ai   qXi=1  =  P  ai  log qP  ai  :  Using the log relationship from Problem 8.6, this becomes  = log e  P  ai  ln qP  ai  :  qXi=1 qXi=1 qXi=1  Then, multiplying the inequality ln x · x ¡ 1 by  1 to get ln 1=x ¸ 1 ¡ x and applying it to this last result,  log q ¡ H  z  ¸ log e  P  ai ·1 ¡  P  ai  ¡  1 q  1  qP  ai ¸ P  ai  qXi=1  P  ai   qXi=1 ¸ log e" qXi=1  ¸ log e [1 ¡ 1] ¸ 0  so that  log q ¸ H  z  :  Therefore, H  z  is always less than, or equal to, log q. Furthermore, in view of the equality condition  x = 1  for ln 1=x ¸ 1 ¡ x, which was introduced at only one point in the above derivation, we will have strict equality if and only if P  ai  = 1=q for all i.  The source symbol probabilities are taken directly from z and are P  a = 0  = 0:75 and P  a = 1  = 0:25. Likewise, the elements of Q are the forward transition probabilities P  b = 0ja = 0  = 2=3, P  b = 0ja = 1  = 1=10, P  b = 1ja = 0  = 1=3, and P  b = 1ja = 1  = 9=10. The matrix multiplication of Eq.  8.3 6  yields the output probabilities  v = Qz =" 2  3 1 3  10 " 3  1 10 9  4  =" 21 40  :  40 19  4 1  Thus, P  b = 0  = 21=40 and P  b = 1  = 19=40. The conditional input probabilities are computed using Bayesz formula  P  ajjbk  =  P  bkjaj P  aj   :  P  bk   Thus, P  a = 0jb = 0  = 20=21, P  a = 0jb = 1  = 10=19, P  a = 1jb = 0  = 1=21,  Problem 8.8   Problem 8.9  Problem 8.10  Problem 8.9 109  and P  a = 1jb = 1  = 9=19. Finally, the joint probabilities are computed using  P  aj; bk  = P  aj  P  bkjaj   which yields P  a = 0; b = 0  = 1=2, P  a = 0; b = 1  = 1=4, P  a = 1; b = 0  = 1=40, and P  a = 1; b = 1  = 9=40.   a  Substituting the given values of pbs and pe into the binary entropy function derived in the example, the average information or entropy of the source is 0.811 bits symbol.   b  The equivocation or average entropy of the source given that the output has been observed  using Eq. 8.3 9  is 0.75 bits symbol. Thus, the decrease in uncertainty is 0.061 bits symbol.   c  It is the mutual information I z; v  of the system and is less than the capacity of the channel, which is, in accordance with the equation derived in the example, 0.0817 bits symbol.   a  The proof proceeds by substituting the elements of Q into Eq.  8.3 13  and simpli  fying. The source probabilities are left as variables during the simpliﬁcation.  C = maxz [I [z; v]]  qkj  qk2  qk1  i=1 P  aj qki  i=1 P  aj qki  k=1 P  aj  qkj log  k=1 P  a1  qk1 log k=1 P  a2  qk2 log  j=1PK = maxzPJ = maxzhP3 +P3 = maxzhP  a1 ³ 1 ¡ ¯  log + P  a2 ³0 + ¯ log = maxzhP  a1 ³ 1 ¡ ¯  log + P  a2 ³¯ log  P J P 2 i=1 P  aj  qkii P 2 P  a1  1¡¯  + ¯ log P  a2  1¡¯  +  1 ¡ ¯  log P  a1  + ¯ log 2P  a2  +  1 ¡ ¯  log  2P  a1 ´ P  a2 ´i  = maxz [¡P  a1    1 ¡ ¯  log P  a1  + ¯ log 2P  a1   ¡ P  a2   ¯ log 2P  a2  +  1 ¡ ¯  log P  a2  ]  1¡¯ ¯  1  1  1  1  ¯  P  a1  1¡¯  + 0´ P  a2  1¡¯ ´i  1¡¯   110  Chapter 8 Problem Solutions  = maxz [¡P  a1    1 ¡ ¯  log P  a1  + ¯ log 2 + ¯ log P  a1   ¡ P  a2   ¯ log 2 + ¯ log P  a2  +  1 ¡ ¯  log P  a2  ]  = maxz [¡P  a1   log P  a1  + ¯ log 2  ¡ P  a2   ¯ log 2 + log P  a2  ] = maxz [¡P  a1  log P  a1  ¡ P  a2  log P  a2  ¡ P  a1  ¯ log 2   ¡ P  a2  ¯ log 2] :  Noting that the ﬁrst two terms of this sum are the entropy of the source and factoring out the common factor in the last two terms, we get  C = max  z  [H  z  ¡  P  a1  + P  a2   ¯ log 2] :  Since the sum of the source probabilities is 1 and the maximum entropy of a binary source is also 1 with both symbols equally probable, this reduces to  C = 1 ¡ ¯:   b  Substituting 0.5 into the above equation, the capacity of the erasure channel is 0.5. Substituting 0.125 into the equation for the capacity of a BSC given in Section 8.3.2, we ﬁnd that its capacity is 0.456. Thus, the binary erasure channel with a higher probability of error has a larger capacity to transfer information.  Problem 8.11   a  The plot is shown in Fig. P8.11.   b  Dmax is ¾2.   c  If we wish to code the source in this example so that the maximum average encoding  decoding distortion D is 0:75¾2, we ﬁrst evaluate R D  for D = 0:75 ¾2. Since R 0:75¾2  = 0:21, we know that at least 0.21 code bits per source symbol must be used to achieve the ﬁdelity objective. Thus, this is the maximum possible information compression under this criterion.  Problem 8.12   a  There are two unique codes.   b  The codes are:  1  0, 11, 10 and  2  1, 00, 01. The codes are complements of one another. They are constructed by following the Huffman procedure for three symbols of arbitrary probability.   Problem 8.13 111  Figure P8.11  Problem 8.13   a  The entropy is computed using Eq.  8.3 3  and is 2.6508 bits symbol.   b  The speciﬁc binary codes assigned to each gray level may vary depending upon the arbitrary selection of 1s and 0s assigned at each step of the coding algorithm. The number of bits used for each gray level, however, should be the same for all versions constructed. The construction of Code 2 in Table 8.1 proceeds as follows:  Step 1: Arrange according to symbol probabilities from left to right, as shown in Fig. P8.13 a .  Step 2: Assign code words based on the ordered probabilities from right to left, as shown in Fig. P8.13 b .  Step 3: The codes associated with each gray level are read at the left of the diagram.   c     f  The remaining codes and their average lengths, which are computed using  8.1  4 , are shown in Table P8.13. Note that two Huffman shift codes are listed, one of which is the best. In generating these codes, the sum of probabilities 4   7 were used as the probability of the shift up symbol. The sum is 0.19, which is equivalent to the probability of symbol r0. Thus, the two codes shown differ by the ordering of r0 and the shift symbol during the Huffman coding process.   112  Chapter 8 Problem Solutions  rk r0 = 0 r1 = 1=7 r2 = 2=7 r3 = 3=7 r4 = 4=7 r5 = 5=7 r6 = 6=7 r7 = 1 Length  pr  rk  B1 code C0C0 0:19 C0 0:25 C1 0:21 C0C1 0:16 C1C0 0:08 0:06 C1C1 0:03 C0C0C0 0:02 C0C0C1  3:18  Table P8.13 2 bit Shift H. Shift 1 H. Shift 2 Huffman 11 01 10 001 0001 00001 000001 000000  11 01 10 001 00001 00010 00011 000001 2:75  10 00 01 1100 1101 1110 111100 111101 2:8  000 01 10 001 1101 1110 11000 11001 2:78  2:7  The entropy of the source is H = 2:65 from Eq.  8.3 3  and the probabilities from column 2.  Problem 8.14  The arithmetic decoding process is the reverse of the encoding procedure. Start by dividing the [0, 1  interval according to the symbol probabilities. This is shown in Table P8.14. The decoder immediately knows the message 0.23355 begins with an e}, since the coded message lies in the interval [0.2, 0.5 . This makes it clear that the second symbol is an a}, which narrows the interval to [0.2, 0.26 . To further see this, divide the interval [0.2, 0.5  according to the symbol probabilities. Proceeding like this, which is the same procedure used to code the message, we get eaii!}.  Table P8.14 Probability  Symbol  Range [0.0, 0.2  [0.2, 0.5  [0.5, 0.6  [0.6, 0.8  [0.8, 0.9  [0.9, 1.0   0.2 0.3 0.1 0.2 0.1 0.1  a e i o u !   Problem 8.14 113  Figure P8.13   114  Chapter 8 Problem Solutions  Problem 8.15  Assume that the ﬁrst 256 codes in the starting dictionary are the ASCII codes. If you assume 7 bit ASCII, the ﬁrst 128 locations are all that are needed. In either case, the ASCII }a} corresponds to location 97. The coding proceeds as shown in Table P8.15.  Recognized Character Output Dict. Address Dict. Entry  Table P8.15  a a aa a aa aaa a aa aaa aaaa  a  a a a a a a a a a a a  97  256  258 97  256  257  aa  aaa  257  258  aaaa  259  aaaaa  The input to the LZW decoding algorithm for the example in Example 8.12 is  39 39 126 126 256 258 260 259 257 126  The starting dictionary, to be consistent with the coding itself, contains 512 locationsw with the ﬁrst 256 corresponding to gray level values 0 through 255. The decoding algo  rithm begins by getting the ﬁrst encoded value, outputting the corresponding value from the dictionary, and setting the }recognized sequence} to the ﬁrst value. For each addi  tional encoded value, we  1  output the dictionary entry for the pixel value s ,  2  add a new dictionary entry whose content is the }recognized sequence} plus the ﬁrst element of the encoded value being processed, and  3  set the }recognized sequence} to the en  coded value being processed. For the encoded output in Example 8.12, the sequence of operations is as shown in Table P8.16.  Note, for example, in row 5 of the table that the new dictionary entry for location 259 is 126 39, the concatenation of the currently recognized sequence, 126, and the ﬁrst  Problem 8.16   element of the encoded value being processedwthe 39 from the 39 39 entry in dictionary location 256. The output is then read from the third column of the table to yield  Problem 8.17 115  39 39 126 126 39 39 126 126 39 39 126 126 39 39 126 126  where it is assumed that the decoder knows or is given the size of the image that was recieved. Note that the dictionary is generated as the decoding is carried out.  Recognized Encoded Value  Pixels  Dict. Address  Dict. Entry  Table P8.16  39 39 126 126 39 39 126 126 39 39 126  126 39 39 126  126  39 39 126 126 256 258 260 259 257 126  256 257 258 259 260 261 262 263 264  39 39 39 126 126 126 126 39  39 39 126 126 126 39  39 39 126 126  126 39 39 39 126 126  39 39 126 126 256 258 260 259 257  Problem 8.17   a  Using Eq.  8.4 3 , form Table P8.17.  Table P8.17  Binary Gray Code 0000 0001 0010 0011 0100 0101 0110 0111  0000 0001 0011 0010 0110 0111 0101 0100  Binary Gray Code 1000 1001 1010 1011 1100 1101 1110 1111  1100 1101 1111 1110 1010 1011 1001 1000   116  Chapter 8 Problem Solutions   b  The procedure is to work from the most signiﬁcant bit to the least signiﬁcant bit using the equations:  The decoded binary value is thus 0101100111010.  am¡1 = gm¡1 ai = gi   ai+1  0 · i · m ¡ 2:  Problem 8.18   a  Using the procedure described in Section 8.4.3, the decoded line is  [W 1001 W W W W W W 0000 0010 W W W W W W ]  where W denotes four white pixels   i.e., 1111.   b     c  Establish the convention that sub blocks are included in the code string from left to right. Then, using brackets to clarify the decomposition steps, we get  1 [ [W 1001 W W W W W W ] [0000 0010 W W W W W W ] ]  1 [ 1 [W 1001 W W ] [W W W W ] ] [ 1 [0000 0010 W W ] [W W W W ] ] ]  1 [ 1 [ 1 [ [W 1001] [W W ] ] [ 0 ] ] [ 1 [ 1 [ [0000 0010] [W W ] ] [ 0 ] ] ]  1 [ 1 [ 1 [ 1 [W ] [1001] ] [ 0 ] ] [ 0 ] ] [ 1 [ 1 [ 1 [0000] [0010] ] [ 0 ] ] [ 0 ] ] ]  1 [ 1 [ 1 [ 1 [ 0 ] [11001] ] [ 0 ] ] [ 0 ] ] [ 1 [ 1 [ 1 [10000] [10010] ] [ 0 ] ] [ 0 ] ] ]  Thus, the encoded string is 111101100100111100001001000, which requires 27 bits. The ﬁrst encoding required 28 bits.  Problem 8.19  Problem 8.20   a  The motivation is clear from Fig. 8.17. The transition at c must somehow be tied to a particular transition on the previous line. Note that there is a closer white to black transition on the previous line to the right of c, but how would the decoder know to use it instead of the one to the left. Both are less than ec. The ﬁrst similar transition past e establishes the convention to make this decision.   b  An alternate solution would be to include a special code which skips transitions on the previous line until you get to the closest one.   a  Substituting ½h = 0 into Eq.  8.5 12  and evaluating it to form the elements of R   Problem 8.21  Problem 8.21 117  and r, we get   b  First form the inverse of R,  R = ¾2" 1 ½  ½ 1  and r = ¾2" ½ ½2  : ¾2  1 ¡ ½2 " 1  :  =" ½ 0  : ¾2  1 ¡ ½2 " ½¡1 ¡ ½2¢  1 ¡½ ¡½  ¾2  1  0  R¡1 =  Then, perform the matrix multiplication of Eq.  8.5 8 :  ® = R¡1r =  Thus, ®1 = ½ and ®2 = 0.   c  The variance is computed using Eq.  8.5 11 :  ¾2  e = ¾2 ¡ ®T r =h ½ 0 i" ½  ½2  = ¾2¡1 ¡ ½2¢ :  The derivation proceeds by substituting the uniform probability function into Eqs.  8.5  20     8.5 22  and solving the resulting simultaneous equations with L = 4. Eq.  8.5 21  yields  s0 = 0 s1 = 1 s2 = 1:  2  t1 + t2   Substituting these values into the integrals deﬁned by Eq.  8.5 20 , we get two equations. The ﬁrst is  assuming s1 · A   2  t1+t2   1  2AZ 1  0  Z s1  s0   s ¡ t1  p  s  ds = 0  s2  2 ¡ t1s¯¯¯¯¯  1 2  t1 + t2   s ¡ t1  ds = 0  t1 + t2 2 ¡ 4t1  t1 + t2  = 0  t1 + t2   t2 ¡ 3t1  = 0 t1 = ¡t2 and t2 = 3t1:  = 0  The ﬁrst of these relations does not make sense since both t1 and t2 must be positive. The second relationship is a valid one. The second integral yields  noting that s1 is less than A so the integral from A to 1 is 0 by the deﬁnition of p s    1  2AZ A  1 2  t1+t2    s ¡ t2  ds =  A 1 2  t1 + t2   = 0  s2  2 ¡ t2s¯¯¯¯¯   118  Chapter 8 Problem Solutions  Substituting t2 = 3t1 from the ﬁrst integral simpliﬁcation into this result, we get  4A2 ¡ 8At2 ¡  t1 + t2 2 ¡ 4t2  t1 + t2  = 0:  Back substituting these values of t1, we ﬁnd the corresponding t2 and s1 values:  Since s1 = A is not a real solution  the second integral equation would then be evaluated from A to A, yielding 0 or no equation , the solution is given by the second. That is,  1 ¡ 6At1 + A2 = 0 8t2  £t1 ¡ A  t1 = A  2¤  8t1 ¡ 2A  = 0  2 and t1 = A 4 :  t2 = 3A t2 = 3A  2 and s1 = A for t1 = A 2 4 and s1 = A 2 for t1 = A 4 :  s0 = 0 t1 = A 4  s1 = A 2 t2 = 3A 4  s2 = 1  Problem 8.22  Problem 8.23  Problem 8.24  Following the procedure in the ›ow chart of Fig. 8.37, the proper code is  0001 010 1 0011000011 0001  where the spaces have been inserted for readability alone. The coding mode sequence is pass, vertical  1 left , vertical  directly below , horizontal  distances 3 and 4 , and pass.   a     b  Following the procedure outlined in Section 8.6.2, we obtain the results shown in Table P8.23.  Since the T1 transfer rate is 1.544 Mbit sec, a 6 second transfer will provide   1:544 £ 106  6 sec  = 9:264 £ 106 bits  of data. The initial approximation of the X ray must contain no more than this number of bits. The required compression ratio is thus  CR =  4096 £ 4096 £ 12  9:264 £ 106  = 21:73  The JPEG transform coding approach of Section 6.6 can achieve this level of compres  sion and provide reasonably good reconstructions. At the X ray encoder, the X ray can be JPEG compressed using a normalization array that yields about a 25:1 compression.   Problem 8.22 119  While it is being transmitted over the T1 line to the remote viewing station, the encoder can decode the compressed JPEG data and identify the differences} between the result  ing X ray approximation and the original X ray image. Since we wish to transmit these differences} over a span of 1 minute with reﬁnements every 5   6 seconds, there can be no more than  60 sec  60 sec  to  6  5  = 10 to 12 reﬁnements.  If we assume that 12 reﬁnements are made and that each reﬁnement corresponds to the differences} between one of the 12 bits in the original X ray and the JPEG recon  structed approximation, then the compression that must be obtained per bit  to allow a 6 second average transfer time for each bit  is  CR =  4096 £ 4096 £ 1 9:264 £ 106 = 1:81  where, as before, the bottom of the fraction is the number of bits that can be transmitted over a T1 line in 6 seconds. Thus, the difference} data for each bit must be compressed by a factor just less than 2. One simple way to generate the difference information} is to XOR the actual X ray with the reconstructed JPEG approximation. The resulting binary image will contain a 1 in every bit position at which the approximation differs from the original. If the XOR result is transmitted one bit at a time beginning with the MSB and ending with the LSB, and each bit is compressed by an average factor of 1.81:1, we will achieve the performance that is required in the problem statement. To achieve an average error free bit plane compression of 1.81:1  see Section 6.4 , the XOR data can be Gray coded, run length coded, and ﬁnally variable length coded. A conceptual block diagram for both the encoder and decoder are given below. Note that the decoder computes the bit reﬁnements by XORing the decoded XOR data with the reconstructed JPEG approximation.  DC Coefﬁcient Difference Twozs Complement Value  Table P8.23   7  6  5  4 4 5 6 7  1...1001 1...1010 1...1011 1...1100 0...0100 0...0101 0...0110 0...0111  Code 00000 00001 00010 00011 00100 00101 00110 00111   120  Chapter 8 Problem Solutions  Figure P8.24  Problem 8.25  To demonstrate the equivalence of the lifting based approach and the traditional FWT ﬁlter bank method, we simply derive general expressions for one of the odd and even outputs of the lifting algorithm of Eq.  8.6 2 . For example, the Y  0  output of step 4 of the algorithm can be written as  Y4  0  = Y2  0  + ± [Y3  ¡1  + Y3  1 ]  = X  0  + ¯ [Y1  ¡1  + Y1  1 ] + ± [Y3  ¡1  + Y3  1 ]  where the subscripts on the Y zs have been added to identify the step of the lifting al  gorithm from which the value is generated. Continuing this substitution pattern from earlier steps of the algorithm until Y4  0  is a function of Xzs only, we get   Y  0  = [1 + 2®¯ + 2®± + 6®¯ ± + 2 ±] X  0   Problem 8.25 121  + [¯ + 3¯ ± + ±] X  1   + [®¯ + 4®¯ ± + ®± +  ±] X  2   + [¯ ±] X  3   + [®¯ ±] X  4  + [¯ + 3¯ ± + ±] X  ¡1  + [®¯ + 4®¯ ± + ®± +  ±] X  ¡2  + [¯ ±] X  ¡3  + [®¯ ±] X  ¡4  :  Thus, we can form the lowpass analysis ﬁlter coefﬁcients shown in Table P8.25 1.  Table P8.25 1 Expression ®¯ ±=K ¯ ±=K  Coefﬁcient Index  Value  §4 §3 §2 §1 0  0.026748757  0.016864118  0.07822326 0.26686411  1 + 2®¯ + 2®± + 6®¯ ± + 2 ±  =K 0.60294901   ®¯ + 4®¯ ± + ®± +  ±  =K   ¯ + 3¯ ± + ±  =K  Here, the coefﬁcient expressions are taken directly from our expansion of Y  0  and the division by K is in accordance with step 6 of Eq.  8.6 2 . The coefﬁcient values in column 3 are determined by substituting the values of ®, ¯,  , ±, and K from the text into the expressions of column 2. A similar derivation beginning with  yields  Y3  1  = Y1  1  +   [Y2  0  + Y2  2 ]  Y  1  = [® + 3®¯  + ±] X  0   + [1 + 2¯ ] X  1   + [® + 3®¯  + ±] X  2   + [¯ ] X  3   + [®¯ ] X  4  + [¯ ] X  ¡1  + [®¯ ] X  ¡2   from which we can obtain the highpass analysis ﬁlter coefﬁcients shown in Table P8.25  2   122  Chapter 8 Problem Solutions  Coefﬁcient Index  Table P8.25 2 Expression ¡K  ®¯   ¡K  ¯    ¡K  ® + 3®¯  + ±   ¡K  1 + 2¯    ¡K  ® + 3®¯  + ±   ¡K  ¯   ¡K  ®¯    Value   0.091271762 0.057543525 0.591271766  1.115087053 0.591271766 0.057543525  0.091271762   2  1 0 1 2 3 4  Problem 8.26  From Eq.  8.6 5  and the problem statement, we get that  Substituting these values into Eq.  8.6 4 , we ﬁnd that for the 2LL subband  Here, we have assumed an 8 bit image so that Rb = 8. Likewise, using Eqs.  8.6 5 ,  8.6 4 , and Fig. 8.46  to ﬁnd the analysis gain bits for each subband , we get  ¹2LL = ¹0 = 8 ²2LL = ²0 + 2 ¡ 2 = ²0 = 8:  8  ¢2LL = 2 8+0 ¡8·1 + ¢2HH = 2 8+2 ¡8£1 + 8 ¢2HL = ¢2LH = 2 8+1 ¡8£1 + 8 ¢1HH = 2 8+2 ¡8£1 + 8 ¢1HL = ¢1LH = 2 8+1 ¡8£1 + 8  211¸ = 1:00390625: 211¤ = 4:015625 211¤ = 4:015625  211¤ = 2:0078125 211¤ = 2:0078125:  Problem 8.27  The appropriate MPEG decoder is shown in Fig. P8.27.  Figure P8.27   9 Problem Solutions  Problem 9.1   a  Converting a rectangular to a hexagonal grid basically requires that even and odd lines be displaced horizontally with respect to each other by one half the horizontal distance between adjacent pixels  see the ﬁgure in the problem statement . Since in a rectangular grid there are no pixel values deﬁned at the new locations, a rule must be speciﬁed for their creation. A simple approach is to double the image resolution in both dimensions by interpolation  see Section 2.4.5 . Then, the appropriate 6 connected points are picked out of the expanded array. The resolution of the new image will be the same as the original  but the former will be slightly blurred due to interpolation . Figure P9.1 a  illustrates this approach. The black points are the original pixels and the white points are the new points created by interpolation. The squares are the image points picked for the hexagonal grid arrangement.   b  Rotations in a 6 neighbor arrangement are invariant to rotations in 60± increments.   c  Yes. Ambiguities arise when there is more than one path that can be followed from one 6 connected pixel to another. Figure P9.1 c  shows an example, in which the 6  connected points of interest are in black.  Figure P9.1   124  Chapter 9 Problem Solutions  Problem 9.2   a  The answer is shown shaded in Fig. P9.2.   b  With reference to the sets shown in the problem statement, the answers are, from left to right,   A \ B \ C  ¡  B \ C u   A \ B \ C  [  A \ C  [  A \ B u and  fB \  A [ C cg [ f A \ C  ¡ [ A \ C  \  B \ C ]g :  Figure P9.2  Problem 9.3  With reference to the discussion in Section 2.5.2, m connectivity is used to avoid multi  ple paths that are inherent in 8 connectivity. In one pixel thick, fully connected bound  aries, these multiple paths manifest themselves in the four basic patterns shown in Fig. P9.3.  The solution to the problem is to use the hit or miss transform to detect the patterns and then to change the center pixel to 0, thus eliminating the multiple paths. A basic sequence of morphological steps to accomplish this is as follows:  X1 = A ~ B1 Y1 = A \ X c  1   Problem 9.4 125  X2 = Y1 ~ B2 Y2 = Y1 \ X c X3 = Y2 ~ B3 Y3 = Y2 \ X c X4 = Y3 ~ B4 Y4 = Y3 \ X c 4 where A is the input image containing the boundary.  2  3   b  Only one pass is required. Application of the hit or miss transform using a given Bi ﬁnds all instances of occurrence of the pattern described by that structuring element.   c  The order does matter. For example, consider the sequence of points shown in Fig. If B1 is applied ﬁrst, P9.3 c . and assume that we are traveling from left to right. point a will be deleted and point b will remain after application of all other structuring elements.. If, on the other hand, B3 is applied ﬁrst, point b will be deleted and point a will remain. Thus, we would end up with different  but of course, acceptable  m paths.  Figure P9.3  Problem 9.4  See Fig. P9.4. Keep in mind that erosion is the set described by the origin of the structuring element, such that the structuring element is contained within the set being eroded.   126  Chapter 9 Problem Solutions  Problem 9.5  Problem 9.6   a  Erosion is set intersection. The intersection of two convex sets is convex also. See Fig. P9.5 for solutions to parts  b  through  d . Keep in mind that the digital sets in question are the larger black dots. The lines are shown for convenience in visualizing what the continuous sets would be. In  b  the result of dilation is not convex because the center point is not in the set. In  c  we see that the lower right point is not connected to the others. In  d , it is clear that the two inner points are not in the set.  Figure P9.4  Figure P9.5  Refer to Fig. P9.6. The center of each structuring element is shown as a black dot. Solution  a  was obtained by eroding the original set  shown dashed  with the structuring element shown  note that the origin is at the bottom, right . Solution  b  was obtained by eroding the original set with the tall rectangular structuring element shown. Solution   Problem 9.7 127   c  was obtained by ﬁrst eroding the image shown down to two vertical lines using the rectangular structuring elementu this result was then dilated with the circular structuring element. Solution  d  was obtained by ﬁrst dilating the original set with the large disk shown. Then dilated image was then eroded with a disk of half the diameter of the disk used for dilation.  Figure P9.6  Problem 9.7  Problem 9.8  Problem 9.9  The solutions to  a  through  d  are shown from top to bottom in Fig. P9.7.   a  The dilated image will grow without bound.  b  A one element set  i.e., a one pixel image .   a  The image will erode to one element.  b  The smallest set that contains the structuring element.   128  Chapter 9 Problem Solutions  Figure P9.7  Problem 9.10  Problem 9.11  The approach is to prove that  nx 2 Z2¯¯¯  ^B x \ A 6= ;o ´ x 2 Z2 j x = a + b for a 2 A and b 2 Bª :  The elements of   ^B x are of the form x ¡ b for b 2 B. The condition   ^B x \ A 6= ; implies that for some b 2 B, x ¡ b 2 A, or x ¡ b = a for some a 2 A  note in the preceding equation that x = a + b . Conversely, if x = a + b for some a 2 A and b 2 B, then x ¡ b = a or x ¡ b 2 A, which implies that   ^B x \ A 6= ;.   a  Suppose that x 2 A   B. Then, for some a 2 A and b 2 B, x = a + b. Thus,   Problem 9.12  Problem 9.13  Problem 9.12 129  x 2  A b and, therefore, x 2 Sb2B   A b : Then, for some b 2 B, x 2  A b. However, x 2  A b implies that there exists an a 2 A such that x = a + b. But, from the deﬁnition of dilation given in the problem statement, a 2 A, b 2 B, and x = a + b imply that x 2 A   B.   A b : On the other hand, suppose that x 2 Sb2B   A b : Then, for some b 2 B, x 2  A b. However, x 2  A b implies that there exists an a 2 A such that x = a + b. But, if x = a + b for some a 2 A   b  Suppose that x 2 Sb2B and b 2 B, then x¡ b = a or x¡ b 2 A, which implies that x 2h  ^B x \ A 6= ;i. Now, suppose that x 2h  ^B x \ A 6= ;i. The condition   ^B x \ A 6= ; implies that for some some a 2 A and b 2 B, then x 2  A b and, therefore, x 2 Sb2B  b 2 B, x ¡ b 2 A or x ¡ b = a  i.e., x = a + b   for some a 2 A. But, if x = a + b for   A b.  The proof, which consists of proving that   x 2 Z2 j x + b 2 A , for every b 2 Bª ´ x 2 Z2 j  B x µ Aª ,  follows directly from the deﬁnition of translation because the set  B x has elements of the form x + b for b 2 B. That is, x + b 2 A for every b 2 B implies that  B x µ A. Conversely,  B x µ A implies that all elements of  B x are contained in A, or x+b 2 A for every b 2 B.   A ¡b. Suppose now that x 2 Tb2B   a  Let x 2 A Ä B. Then, from the deﬁnition of erosion given in the problem statement, ¡b : Thus, for every for every b 2 B, x + b 2 A. But, x + b 2 A implies that x 2  A  ¡b, which implies that x 2 Tb2B b 2 B, x 2  A   A ¡b. Then, for every b 2 B, x 2  A ¡b. Thus, for every b 2 B, x + b 2 A which, from the deﬁnition of erosion, means that x 2 A Ä B.  b  Suppose that x 2 A Ä B = Tb2B ¡b, or x + b 2 A. But, as shown in Problem 9.12, x + b 2 A for every b 2 B implies that  B x µ A, so that x 2 A Ä B = x 2 Z2 j  B x µ Aª : Similarly,  B x µ A implies that all elements of  B x are contained in A, or x + b 2 A for every b 2 B or, as in  a , x + b 2 A implies that x 2  A  ¡b, then x 2 Tb2B   A ¡b. Then, for every b 2 B, x 2  A   ¡b. Thus, if for every b 2 B, x 2  A    A ¡b.   130  Chapter 9 Problem Solutions  Problem 9.14  Starting with the deﬁnition of closing,   A ² B c = [ A   B  Ä B]c =  A   B c   ^B =  Ac Ä ^B    ^B = Ac ± ^B:  Problem 9.15   a  Erosion of a set A by B is deﬁned as the set of all values of translates, z, of B such that  B z is contained in A. If the origin of B is contained in B, then the set of points describing the erosion is simply all the possible locations of the origin of B such that  B z is contained in A. Then it follows from this interpretation  and the deﬁnition of erosion  that erosion of A by B is a subset of A. Similarly, dilation of a set C by B is the set of all locations of the origin of ^B such that the intersection of C and   ^B z is not empty. If the origin of B is contained in B, this implies that C is a subset of the dilation of C by B. Now, from Eq.  9.3 1 , we know that A± B =  A Ä B   B. Let C denote the erosion of A by B. It was already established that C is a subset of A. From the preceding discussion, we know also that C is a subset of the dilation of C by B. But C is a subset of A, so the opening of A by B  the erosion of A by B followed by a dilation of the result  is a subset of A.   b  From Eq.  9.3 3 ,  and  C ± B =[f B z j B z µ C g  D ± B =[f B z j B z µ Dg :  Therefore, if C µ D, it follows that C ± B µ D ± B.   Problem 9.16   c  From  a ,  A ± B  ± B µ  A ± B . From the deﬁnition of opening,   A ± B  ± B = f A ± B  Ä Bg   B  Problem 9.16 131  = f[ A Ä B    B] Ä Bg   B = f A Ä B  ² Bg   B ¶  A Ä B    B ¶ A ± B:  But, the only way that  A ± B  ± B µ  A ± B  and  A ± B  ± B ¶  A ± B  can hold is if  A ± B  ± B =  A ± B . The next to last step in the preceding sequence follows from the fact that the closing of a set by another contains the original set [this is from Problem 9.16 a ].   a  From Problem 9.14,  A ² B c = Ac ± ^B, and, from Problem 9.15 a , it follows that   A ² B c = Ac ± ^B µ Ac:  Taking the complement of both sides of this equation reverses the inclusion sign and we have that A µ  A ² B , as desired.  b  From Problem 9.16 b , if Dc µ Cc, then Dc ± ^B µ C c ± ^B where we used Dc, Cc, and ^B instead of C, D, and B. From Problem 9.15,  C ² B c = C c± ^B and  D ² B c = Dc ± ^B. Therefore, if Dc µ Cc then  D ² B c µ  C ² B c. Taking complements reverses the inclusion, so we have that if C µ D, then  C ² B  µ  D ² B , as desired.  c  Starting with the result of Problem 9.15,   A ² B  ² B = n A ² B c ± ^Boc = n Ac ± ^B  ± ^Boc = n Ac ± ^B oc = f A ² B cgc =  A ² B  :  where the third step follows from Problem 9.15 c  and the fourth step follows from Problem 9.14.   132  Chapter 9 Problem Solutions  Problem 9.17  The solution is shown in Fig. P9.17. Although the images shown could be sketched by hand, they were done in MATLAB The size of the original is 647 £ 624 pixels. A disk structuring element of radius 11 was used. This structuring element was just large enough to encompass all noise elements, as given in the problem statement. The images shown in Fig. P9.17 are:  a  erosion of the original,  b  dilation of the result,  c  another dilation, and ﬁnally  d  an erosion. The main points we are looking for from the studentzs answer are: The ﬁrst erosion  leftmost image  should take out all noise elements that do not touch the rectangle, should increase the size of the noise elements completely contained within the rectangle, and should decrease the size of the rectangle. If worked by hand, the student may or may not realize that some }imperfections} are left along the boundary of the object. We do not consider this an important issue because it is scale dependent, and nothing is said in the problem statement about this. The ﬁrst dilation  next image  should shrink the noise components that were increased in erosion, should increase the size of the rectangle, and should round the corners. The next dilation should eliminate the internal noise components completely and further increase the size of the rectangle. The ﬁnal erosion  last image on the right  should then decrease the size of the rectangle. The rounded corners in the ﬁnal answer are an important point that should be recognized by the student.  Figure P9.17   Problem 9.18  Problem 9.19  Problem 9.20  Problem 9.18 133  It was possible to reconstruct the three large squares to their original size because they were not completely eroded and the geometry of the objects and structuring element was the same  i.e., they were squares . This also would have been true if the objects and structuring elements were rectangular. However, a complete reconstruction, for instance, by dilating a rectangle that was partially eroded by a circle, would not be possible.   a  Select a one pixel border around the image of the T, assuming that the resulting subimage is odd, let the origin be located at the horizontal vertical midpoint of this subimage  if the dimensions were even, we could just as easily select any other point . The resulting of applying the hit or miss transform would be a single point where the two Tzs were in perfect registration. The location of the point would be the same as the origin of the structuring element.   b  The hit or miss transform and  normalized  correlation are similar in the sense that they produce their maximum value at the location of a perfect match, and also in the mechanics of sliding the template  structuring element  past all locations in the image. Major differences are the lack of a complex conjugate in the hit or miss transform, and the fact that this transform produced a single nonzero binary value in this case, as op  posed to the multiple nonzero values produced by correlation of the two images.  The key difference between the Lake and the other two features is that the former forms a closed contour. Assuming that the shapes are processed one at a time, basic two step approach for differentiating between the three shapes is as follows:  Step 1. Apply an end point detector to the object until convergence is achieved. If the result is not the empty set, the object is a Lake. Otherwise it is a Bay or a Line.  Step 2. There are numerous ways to differentiate between a lake and a line. One of the simplest is to determine a line joining the two end points of the object. If the AND of the object and this line contains only two points, the ﬁgure is a Bay. Otherwise it is   134  Chapter 9 Problem Solutions  a line segment. There are pathological cases in which this test will fail, and additional }intelligence} needs to be built into the process, but these pathological cases become less probable with increasing resolution of the thinned ﬁgures.   a  The entire image would be ﬁlled with 1zs.  b  The background would be ﬁlled with 1zs.  c  See Fig. P9.21.  Problem 9.21  Problem 9.22   a  With reference to the example shown in Fig. P9.22 a , the boundary that results from using the structuring element in Fig. 9.15 c  generally forms an 8 connected path  leftmost ﬁgure , whereas the boundary resulting from the structuring element in Fig. 9.13 b  forms a 4 connected path  rightmost ﬁgure .   b  Using a 3 £ 3 structuring element of all 1zs would introduce corner pixels into seg  ments characterized by diagonally connected pixels. For example, square  2,2  in Fig. 9.15 e  would be a 1 instead of a 0. That value of 1 would carry all the way to the ﬁnal result in Fig. 9.15 i . There would be other 1zs introduced that would turn Fig. 9.15 i  into a much more distorted object.  Figure P9.21  Figure P9.22 a    Problem 9.23  Problem 9.21 135  If spheres are allowed to touch, we can make the simplifying assumption that no spheres touch it in such a way that they create pockets} of black points surrounded by all white or surrounded by all white and part of the boundary of the image. This situation requires additional preprocessing, as discussed below. With these simpliﬁcation in mind, the problem reduces ﬁrst to determining which points are background  black  points. To do this, we pick a black point on the boundary of the image and ﬁnd all black points connected to it using a connected component algorithm  Section 9.5.3 . These connected components are labels with a value different from 1 or 0. The remaining black points are interior to spheres. We can ﬁll all spheres with white by applying the region ﬁlling algorithm until all interior black points have been turned into white points. The alert student will realize that if the interior points are already known, they can all be turned simply into white points thus ﬁlling the spheres without having to do region ﬁlling as a separate procedure.  If the spheres are allowed to touch in arbitrary ways, a way must be found to separate them because they could create }pockets} of black points surrounded by all white or surrounded by all white and part of the boundary of the image. The simplest approach is to separate the spheres by preprocessing. One way to do this is to erode the white components of the image by one pass of a 3 £ 3 mask, effectively creating a black border around the spheres, thus }separating} them. This approach works in this case because the objects are spherical, thus having small areas of contact. To handle the case of spheres touching the border of the image, we simply set all border point to black. We then proceed to ﬁnd all background points To do this, we pick a point on the boundary of the image  which we know is black due to preprocessing  and ﬁnd all black points connected to it using a connected component algorithm  Section 9.5.3 . These connected components are labels with a value different from 1 or 0. The remaining black points are interior to spheres. We can ﬁll all spheres with white by applying the region ﬁlling algorithm until all such interior black points have been turned into white points. The alert student will realize that if the interior points are already known, they can all be turned simply into white points thus ﬁlling the spheres without having to do region ﬁlling as a separate procedure.  Note that the erosion of white areas makes the black areas interior to the spheres grow, so the possibility exists that such an area near the border of a sphere could grow into the background. This issue introduces further complications that the student may not have the tools to solve yet. We recommend making the assumption that the interior black   136  Chapter 9 Problem Solutions  areas are small and near the center. Recognition of the potential problem by the student should be sufﬁcient.  Problem 9.24  Problem 9.25  Denote the original image by A. Create an image of the same size as the original, but consisting of all 0zs, call it B. Choose an arbitrary point labeled 1 in A, call it p1, and apply the algorithm. When the algorithm converges, a connected component has been detected. Label and copy into B the set of all points in A belonging to the connected components just found, set those points to 0 in A and call the modiﬁed image A1. Choose an arbitrary point labeled 1 in A1, call it p2, and repeat the procedure just given. If there are K connected components in the original image, this procedure will result in an image consisting of all 0zs after K applications of the procedure just given. Image B will contain K labeled connected components.   a  Equation  9.6 1  requires that the  x; y  used in the computation of dilation must satisfy the condition  x; y  2 Db. In terms of the intervals given in the problem state  ment, this means that x and y must be in the closed interval x 2 [Bx1; Bx2] and y 2 [By1; By2]. It is required also that  s ¡ x ;  t ¡ y  2 Df , which means that  s ¡ x  2 [Fx1; Fx2] and  t ¡ y  2 [Fy1; Fy2]. Since the valid range of x is the interval [Bx1; Bx2], the valid range of  s¡x  is [s¡Bx1; s¡Bx2]. But, since x must also satisfy the condition  s ¡ x  2 [Fx1; Fx2], it follows that Fx1 · s ¡ Bx1 and Fx2 ¸ s ¡ Bx2, which ﬁnally yields Fx1 + Bx1 · s · Fx2 + Bx2. Following the same analysis for t yields Fy1 + By1 · t · Fy2 + By2. Since dilation is a function of  s; t , these two inequalities establish the domain of  f   b  s; t  in the st plane.  b  Following a similar procedure yields the following intervals for s and t: Fx1¡Bx1 · s · Fx2 ¡ Bx2 and Fy1 ¡ By1 · t · Fy2 ¡ By2. Since erosion is a function of  s; t , these two inequalities establish the domain of  f ª b  s; t  in the st plane.  Problem 9.26   a  The noise spikes are of the general form shown in Fig. P9.26 a , with other possi  bilities in between. The amplitude is irrelevant in this caseu only the shape of the noise   Problem 9.27 137  spikes is of interest. To remove these spikes we perform an opening with a cylindri  cal structuring element of radius greater than Rmax, as shown in Fig. P9.26 b   see Fig. 9.30 for an explanation of the process . Note that the shape of the structuring element is matched to the known shape of the noise spikes.   b  The basic solution is the same as in  a , but now we have to take into account the various possible overlapping geometries shown in Fig. P9.26 c . A structuring element like the one used in  a  but with radius slightly larger than 4Rmax will do the job. Note in  a  and  b  that other parts of the image would be affected by this approach. The bigger Rmax, the bigger the structuring element that would be needed and, consequently, the greater the effect on the image as a whole.  Figure P9.26  Problem 9.27   a  Color the image border pixels the same color as the particles  white . Call the result  ing set of border pixels B. Apply the connected component algorithm. All connected components that contain elements from B are particles that have merged with the border of the image.   138  Chapter 9 Problem Solutions   b  It is given that all particles are of the same size  this is done to simplify the problemu more general analysis requires tools from Chapter 11 . Determine the area  number of pixels  of a single particleu denote the area by R. Eliminate from the image the particles that were merged with the border of the image. Apply the connected component algo  rithm. Count the number of pixels in each component. A component is then designated as a single particle if the number of pixels is less than or equal to R + ", where " is a small quantity added to account for variations in size due to noise.   c  Subtract from the image single particles and the particles that have merged with the border, and the remaining particles are overlapping particles.  Problem 9.28  As given in the problem statement, interest lies on deviations from the round in the inner and outer boundaries of the washers. It also is stated that we can ignore errors due to digitizing and positioning. This means that the imaging system has enough resolution so that artifacts will not be introduced as a result of digitization. The mechanical accuracy similarly tells us that no appreciable errors will be introduced as a result of positioning. This is important if we want to do matching without having to register the images.  The ﬁrst step in the solution is the speciﬁcation of an illumination approach. Because we are interested in boundary defects, the method of choice is a backlighting system that will produce a binary image. We are assured from the problem statement that the illu  mination system has enough resolution so that we can ignore defects due to digitizing.  The next step is to specify a comparison scheme. The simplest way to match binary images is to AND one image with the complement of the other. Here, we match the input binary image with the complement of the golden image  this is more efﬁcient than computing the complement of each input image and comparing it to the golden image . If the images are identical  and perfectly registered  the result of the AND operation will be all 0zs. Otherwise, there will be 1zs in the areas where the two images do not match. Note that this requires that the images be of the same size and be registered, thus the assumption of the mechanical accuracy given in the problem statement.  As noted, differences in the images will appear as regions of 1zs in the AND image. These we group into regions  connected components  by using the algorithm given in Section 9.5.3. Once all connected components have been extracted, we can compare them against speciﬁed criteria for acceptance or rejection of a given washer. The sim    Problem 9.28 139  plest criterion is to set a limit on the number and size  number of pixels  of connected components. The most stringent criterion is 0 connected components. This means a perfect match. The next level for }relaxing} acceptance is one connected component with of size 1, and so on. More sophisticated criteria might involve measures like the shape of connected components and the relative locations with respect to each other. These types of descriptors are studied in Chapter 11.    10 Problem Solutions  Problem 10.1  The masks would have the coefﬁcients shown in Fig. P10.1. Each mask would yield a value of 0 when centered on a pixel of an unbroken 3 pixel segment oriented in the direction favored by that mask. Conversely, the response would be a +2 when a mask is centered on a one pixel gap in a 3 pixel segment oriented in the direction favored by that mask.  Figure P10.1  Problem 10.2  The key to solving this problem is to ﬁnd all end points of line segments in the image. End points are those points on a line which have only one 8 neighbor valued 1. Once all end points have been found, the D8 distance between all pairs of such end points gives the lengths of the various gaps. We choose the smallest distance between end points of every pair of segments and any such distance less than or equal to L satisﬁes the statement of the problem. This is a rudimentary solution, and numerous embellishments can be added to build intelligence into the process. For example, it is possible for end points of different, but closely adjacent, lines to be less than L pixels apart, and heuristic tests that attempt to sort out things like this are quite useful. Although the problem statement does not call for any such tests, they are normally needed in practice and it is   142  Chapter 10 Problem Solutions  worthwhile to bring this up in class if this particular problem is assigned as a homework assignment.  Problem 10.3  Problem 10.4   a  The lines were thicker than the width of the line detector masks. Thus, when, for example, a mask was centered on the line it }saw} a constant area and gave a response of 0.   b  Via connectivity analysis.  It is given that the location of the edge relative to the size of the mask is such that image border effects can be ignored. Assume that n is odd and keep in mind that an ideal step edge transition takes place between adjacent pixels. Then, the average is 0 until the center of the mask is  n ¡ 1 =2 pixels or more to the left of the edge. The average is 1 when the center of the mask is further away than  n ¡ 1 =2 pixels to the right of the edge. When transitioning into the edge,  say from left to right  the average picks up one column of the mask for every pixel that it moves to the right, so the value of the average grows as n=n2; 2n=n2; : : : ;  n ¡ 1  n=n2; n2=n2, or 1=n; 2=n; : : : ;  n ¡ 1 =n; 1. This is a simple linear growth with slope equal to 1=n. Figure P10.4 shows a plot of the original proﬁle and what the proﬁle would look like after smoothing. Thus, we get a ramp edge, as expected.  Figure P10.4   Problem 10.5  Problem 10.3 143  The gradient and Laplacian  ﬁrst and second derivatives  are shown in Fig. P10.5.  Figure P10.5  Problem 10.6  Problem 10.7   a  Inspection of the Sobel masks shows that Gx = 0 for edges oriented vertically and Gy = 0 for edges oriented horizontally. Therefore, it follows in this case that , for  vertical edges, rf =qG2   b  The same argument applies to the Prewitt masks.  y = jGyj ; and similarly for horizontal edges.  Consider ﬁrst the Sobel masks of Figs. 10.8 and 10.9. The easiest way to prove that   144  Chapter 10 Problem Solutions  these masks give isotropic results for edge segments oriented at multiples of 45± is to obtain the mask responses for the four general edge segments shown in Fig. P10.7, which are oriented at increments of 45±. The objective is to show that the responses of the Sobel masks are indistinguishable for these four edges. That this is the case is evident from Table P10.1, which shows the response of each Sobel mask to the four general edge segments. We see that in each case the response of the mask that matches the edge direction is  4a ¡ 4b , and the response of the corresponding orthogonal mask is 0. The response of the remaining two masks is either  3a ¡ 3b  or  3b ¡ 3a . The sign difference is not signiﬁcant because the gradient is computed by either squaring or taking the absolute value of the mask responses. The same line of reasoning applies to the Prewitt masks.  Edge  direction Horizontal  Vertical +45± ¡45±  Horizontal Sobel  Gx  4a ¡ 4b  0  3a ¡ 3b 3b ¡ 3a  Table P10.7 Vertical  Sobel  Gy   0  4a ¡ 4b 3a ¡ 3b 3a ¡ 3b  +45±  Sobel  G45  3a ¡ 3b 3a ¡ 3b 4a ¡ 4b  0  ¡45±  Sobel  G¡45   3b ¡ 3a 3a ¡ 3b  0  4a ¡ 4b  Figure P10.7  Problem 10.8  With reference to Fig. P10.8, consider ﬁrst the 3 £ 3 smoothing mask mentioned in the problem statement, as well as the general subimage area shown in the ﬁgure. Recall that value e is replaced by the response of the 3 £ 3 mask when its center is at that location. Ignoring the 1 9 scale factor, the response of the mask when centered at that location is  a + b + c + d + e + f + g + h + i .  The idea with the one dimensional mask is the same: We replace the value of a pixel by the response of the mask when it is centered on that pixel. With this in mind, the mask   [1 1 1] would yield the following responses when centered at the pixels with values b, e, and h, respectively:  a + b + c ,  d + e + f , and  g + h + i . Next, we pass the mask  Problem 10.8 145  264  1 1 1  375  264  ¡1 0 1  375  through these results. When this mask is centered at the pixel with value e, its response will be [ a + b + c  +  d+ e + f   +  g + h + i ], which is the same as the result produced by the 3 £ 3 smoothing mask. Returning now to problem at hand, when the Gx Sobel mask is centered at the pixel with value e, its response is Gx =  g + 2h + i  ¡  a + 2b + c . If we pass the one dimensional differencing mask  through the image, its response when its center is at the pixels with values d, e, and f, respectively, would be: g¡ a  ,  h¡ b , and  i¡ c . Next we apply the smoothing mask [1 2 1] to these results. When the mask is centered at the pixel with value e, its response would be [ g¡ a  + 2 h¡ b  +  i¡ c ] which is [ g + 2h + i  ¡  a+ 2b + c ]. This is the same as the response of the 3 £ 3 Sobel mask for Gx. The process to show equivalence for Gy is basically the same. Note, however, that the directions of the one dimensional masks would be reversed in the sense that the differencing mask would be a column mask and the smoothing mask would be a row mask.  Figure P10.8   146  Chapter 10 Problem Solutions  Problem 10.9  The solution is shown in Fig. P10.9  negative numbers are shown underlined .  NE  N  Edge direction NW  W  SW  Gradient direction  NW  W  SW  S  SE  E  N  S  E  SE  NE  1 1 1 0 0 0 1 1 1  1 1 0 1 0 1 0 1 1  Compass gradient operators 1 10 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1  0 1 1 1 0 1 1 1 0  1 1 1 0 0 0 1 1 1  1 0 1 1 0 1 1 0 1  0 1 1 1 0 1 1 1 0  Figure P10.9  Problem 10.10  Problem 10.11   a  The solution is shown in Fig. P10.10 a . The numbers in brackets are values of [Gx; Gy].  b  The solution is shown in Fig. P10.10 b . The angle was not computed for the trivial cases in which Gx = Gy = 0.. The histogram follows directly from this table.  c  The solution is shown in Fig. P10.10 c .   a  With reference to Eq.  10.1 17 , we need to prove that  Expanding this equation results in the expression  ¸ e¡ r2  2¾2 dr = 0:  ¾4  1Z¡1 · r2 ¡ ¾2 ¸ e¡ r2  1Z¡1 ·r2 ¡ ¾2  ¾4  2¾2 dr =  r2e¡ r2  2¾2 dr  1 ¾4  ¡  1Z¡1 1Z¡1  1 ¾2  e¡ r2  2¾2 dr:  Recall from the deﬁnition of the Gaussian density that  1  p2¼¾2  1Z¡1  e¡ r2  2¾2 dr = 1   Problem 10.9 147  and, from the deﬁnition of the variance of a Gaussian random variable that  Var r  = ¾2 =  r2e¡ r2  2¾2 dr:  1Z¡1  Thus, it follows from the preceding equations that p2¼¾2 ¾4 ¾2 ¡  2¾2 dr =  1Z¡1 · r2 ¡ ¾2  ¾4  ¸ e¡ r2  p2¼¾2  ¾2 = 0:  Figure P10.10   b  Suppose that we convolve an image f with r2h. Using the convolution theorem, this   148  Chapter 10 Problem Solutions  is the same as multiplying the Fourier transform of f by the Fourier transform of r2h. The average value of the convolution can be obtained by evaluating the Fourier transform of this product at the origin of the frequency plane [see Eq.  4.2 22 ]. But, it was shown in  a  that the average value of r2h is zero, which means that its Fourier transform is zero at the origin. From this it follows that the value of the product of the two Fourier transforms is also zero, thus proving that the average value of the convolution of f with r2h is zero.  c  Yes. Consider Eq.  10.1 14 , expressed as r2f x; y  = 4f  x; y  ¡ [f  x + 1; y  + f  x ¡ 1; y  + f  x; y + 1  + f  x; y ¡ 1 ]: As in  b , we evaluate the average value of a spatial expression by looking at the value of its Fourier transform at the origin. Here, it follows from Eq.  4.6 2  that, if F  u; v  denotes the Fourier transform of f  x; y , then the transforms of all the terms inside the brackets in the above equation are F  u; v  multiplied by appropriate exponential terms. However, the exponential terms have value 1 at the origin, so the net result is 4F  0; 0  ¡ 4F  0; 0  = 0, thus proving that the Laplacian obtained by convolving an image with the operator shown in Fig. 10.13  which implements Eq.  10.1 14 ] has an average value of zero. The same zero result is obtained for Eq.  10.1 15 .   a  Figure 10.15 g  was obtained from Fig. 10.15 h  which is a binary image, and thus consists of sets of connected components of 1zs  see Section 2.5.2 regarding connected components . The boundary of each connected component forms a closed path  Prob  lem 2.14 . The contours in Fig. 10.15 g  were obtained by noting transitions of the boundaries of the connected components with the background, and thus form closed paths.   b  The answer is yes for functions that meet certain mild conditions, and if the zero crossing method is based on rotational operators like the LoG function. Geometrical properties of zero crossings in general are explained in some detail in the paper }On Edge Detection,} by V. Torre and T. Poggio, IEEE Trans. Pattern Analysis and Machine Intell., vol. 8, no. 2, pp. 147 163. Looking up this paper and becoming familiar with the mathematical underpinnings of edge detection is an excellent reading assignment for graduate students.  Problem 10.12   Problem 10.13  Problem 10.14  Problem 10.15  Problem 10.12 149   a  Point 1 has coordinates x = 0 and y = 0. Substituting into Eq.  10.2 3  yields ½ = 0, which, in a plot of ½ vs. µ,is a straight line.   b  Only the origin  0; 0  would yield this result.   c  At µ = +90±, it follows from Eq.  10.2 3  that x ¢  0  + y ¢  1  = ½, or y = ½. At µ = ¡ 90±, x ¢  0  + y ¢  ¡1  = ½, or ¡y = ½. Thus the re›ective adjacency.   a  Express xcosµ + ysinµ = ½ in the form x = ¡ cot µ x + ½= sin µ. Equating terms with the slope intercept form, y = ax + b, gives a = and ¡ cot µ  and b = ½= sin µ. This gives µ = cot¡1 a  and ½ = b sin µ. Once obtained from a and b of a given line, the parameters µ and ½ completely specify the normal representation of that line.   b  µ = cot¡1 2  = 26:6± and ½ =  1  sin µ = 0:45:  This problem is a natural for the Hough transform, which is set up as follows: The µ axis is divided into six subdivisions, corresponding to the six speciﬁed directions and their error bands. For example  since the angle directions speciﬁed in the problem statement are with respect to the horizontal  the ﬁrst band for angle µ extends from ¡30± to ¡20±, corresponding to the ¡25± direction and its §5± band. The ½ axis extends from ½ = ¡pD to ½ = +pD, where D is the largest distance between opposite corners of the  image, properly calibrated to ﬁt the particular imaging set up used. The subdivisions in the ½ axis are chosen ﬁnely enough to resolve the minimum expected distance between tracks that may be parallel, but have different origins, thus satisfying the last condition of the problem statement.  Set up in this way, the Hough transform can be used as a }ﬁlter} to categorize all points in a given image into groups of points in the six speciﬁed directions. Each group is then processed further to determine if its points satisfy the criteria for a valid track:  1  each group must have at least 100 pointsu and  2  it cannot have more than three gaps, each of which cannot be more than 10 pixels long  see Problem 10.2 on the estimation of gaps of a given length .   150  Chapter 10 Problem Solutions  Problem 10.16   a  The paths are shown in Fig. P10.16. These paths are as follows:  1 :  1; 1  1; 2  !  2; 1  2; 2  !  3; 1  3; 2  2 :  1; 1  1; 2  !  2; 1  2; 2  !  3; 2  2; 2  !  3; 2  3; 3  3 :  1; 1  1; 2  !  2; 2  1; 2  !  2; 2  2; 3  !  3; 2  3; 3  4 :  1; 1  1; 2  !  2; 2  1; 2  !  2; 2  2; 3  !  2; 2  3; 2  !  3; 1  3; 2  5 :  1; 2  1; 3  !  2; 2  2; 3  !  3; 2  3; 3  6 :  1; 2  1; 3  !  2; 2  2; 3  !  2; 2  3; 2  !  3; 1  3; 2  7 :  1; 2  1; 3  !  1; 2  2; 2  !  2; 1  2; 2  !  3; 1  3; 2  8 :  1; 2  1; 3  !  1; 2  2; 2  !  2; 1  2; 2  !  3; 2  2; 2  !  3; 2  3; 3    b  From Fig. 10.24 and  a , we see that the optimum path is path 6. Its cost is c = 2 + 0 + 1 + 1 = 4.  Figure P10.16  Problem 10.17  From Eq.  10.2 6 , c p; q  = H ¡ [f  p ¡f  q ]. In this case H = 8. Assume that p is to the right as the image is traversed from left to right. The possible paths are shown in Fig. P10.17 a . The costs are detailed in Fig. P10.17 b . The graph  with the minimum cost path shown dashed  is shown in Fig. P10.17 c . Finally, the edge corresponding to the minimum cost path is shown in Fig. P10.17 d .   Problem 10.18 151  Figure P10.17  Problem 10.18   a  The number of boundary points between black and white regions is much larger in the image on the right. When the images are blurred, the boundary points will give rise to a larger number of different values for the image on the right, so the histograms of the two blurred images will be different.   b  To handle border effects, we surround the image with a border of 0zs. We assume that the image is of size N £ N  the fact that the image is square is evident from the right image in the problem statement . Blurring is implemented by a 3 £ 3 mask whose coefﬁcients are 1=9. Figure P10.18 shows the different types of values that the blurred left image  see problem statement  will have. These values are summarized in Table It is easily veriﬁed that the sum of the numbers on the left column of the P10.18 1. table is N 2.   152  Chapter 10 Problem Solutions  A histogram is easily constructed from the entries in this table. A similar  tedious, but not difﬁcult  procedure yields the results shown in Table P10.18 2 for the checkerboard image.  Table P10.18 1  No. of Points  2 ¡ 1¢ N¡ N  2  N ¡ 2  4  3N ¡ 8   N ¡ 2 ¡ N  2 ¡ 2¢  Value  0 2=9 3=9 4=9 6=9 1  Table P10.18 2  No. of Points N 2 2 ¡ 14N + 98  14N ¡ 224  28  128 98  N 2  16N ¡ 256 2 ¡ 16N + 128  Value  0 2=9 3=9 4=9 5=9 6=9 1  Figure P10.18  Problem 10.19  The gray level proﬁle of one row of the image is shown in Fig. P10.19 a , and the   Problem 10.20 153  histogram of the image is shown in Fig. P10.19 b . The gray level proﬁle of one row in the wedge image is shown in Fig. P10.19 c , and its histogram is shown in Fig. P10.19 d . The gray level proﬁle of a row in the product image is shown in Fig. P10.19 e . The histogram of the product is shown in Fig. P10.19 f .  Problem 10.20  Figure P10.19   a  A1 = A2 and ¾1 = ¾2 = ¾, which makes the two modes identical. If the number of samples is not large, convergence to a value at or near the mid point between the two means also requires that a clear valley exist between the two modes. We can guarantee this by assuming that ¾ <<  m1 + m2 =2:   b  That this condition cannot happen if A2 6= 0. This is easily established by starting the algorithm with an initial value less than m1. Even if the right mode associated with m2 is much smaller in size  e.g., A1 >> A2 and ¾1 >> ¾2  the average value of the   154  Chapter 10 Problem Solutions  region to the left of the starting threshold will be smaller than the average of the region to the right because the modes are symmetrical about their mean, and the mode associated with m2 will bias the data to the right. Thus, the next iterative step will bring the value of the threshold closer to m1, and eventually to the right of it. This analysis assumes that enough points are available in order to avoid pathological cases in which the algorithm can get }stuck} due to insufﬁcient data that truly represents the shapes assumed in the problem statement.   c  ¾2 >> ¾1. This will }draw} the threshold toward m2 during iteration.  Problem 10.21  The illumination function is a bell shaped surface with its center at  500; 500 . The value of illumination at this point is 1, and it decreases radially from there. Draw a series of concentric circles about point  500; 500  so that the value of i x; y  at each circle is 0.1 less than the circle before. Any two points within these two circles do no differ by more than 10% in illumination. Segment  threshold  the region between adjacent circles. If the distance between circles is greater than 10 pixels, then we are told that the segmentation will be correct. That is, proper segmentation of areas greater than 10 £ 10 pixels is guaranteed in the problem statement, as long as illumination between any two points does not differ by more than 10%. Regions of 10 £ 10 pixels will ﬁt If the distance between between concentric circles that are more than 10 pixels apart. circles is less than 10 pixels, then the segmentation is not guaranteed to be perfect. But, there is nothing that can be done about that because changes in illumination are determined by the illumination function, which is given.  Problem 10.22  From the ﬁgure in the problem statement,  and  p1 z  =8> : p2 z  =8> :  0 2 z ¡ 1 1 0  2  0 ¡ 1 2 z + 1 0  z < 1 1 · z · 3 z > 3  z < 0 0 · z · 2 z > 2  :   Problem 10.23 155  The optimum threshold is the value z = T for which P1p1 T   = P2p2 T  . In this case P1 = P2, so  from which we get T = 1:5.  1 2  T ¡  1 2  = ¡  1 2  T + 1  Keeping the same sense of directions as in Problem 10.22, let p2 z  be the probability density function given in the problem statement. The key in solving the problem is to recognize that the direction of the }tail} of the Rayleigh function can be reversed as follows:  p1 z  =  2  d  ¡z + c e¡ ¡z+c 2=d 0  z · c z > c  :  Then, the optimum threshold, T , is found by solving the following equation for T :  P1p1 T   = P2p2 T  :  Substituting the density functions into these equations yields  P1  2 d   ¡T + c e¡ ¡T +c 2=d = P2   T ¡ a e¡ T¡a 2=d  2 b  which must be solved for T to ﬁnd the optimum threshold. With the exception of some possible additional reformatting  like taking the natural log , this is as far as we normally expect students to carry this problem. However, it is important for the student to state that the solution is valid only in the range a · T · c:  Problem 10.23  Problem 10.24  From Eq.  10.3 10 ,  Taking the ln of both sides yields  P1p1 T   = P2p2 T  :  ln P1 + ln p1 T   = ln P2 + ln p2 T  :  But  and  1  1  e¡  T¡¹1 2  2¾2 1  e¡  T¡¹2 2  2¾2 2  p1 T   =  p2¼¾1  p2 T   =  p2¼¾2  so it follows that  ln P1 + ln  1  p2¼¾1 ¡   T ¡ ¹1 2  2¾2 1  = ln P2 + ln  1  p2¼¾2 ¡   T ¡ ¹2 2  2¾2 2   156  Chapter 10 Problem Solutions  ¾1 ¾2 ¡  ln P1 ¡ ln ¾1 ¡ 1 P1 + ln 2¾2 P2 1 ¾2P1 2 ¡ ¾1P2  + T 2µ 1  ln  ln  2¾2 From this expression we get   T ¡ ¹1 2  2¾2 1  ¡ ln P 2 + ln ¾2 +   T ¡ ¹2 2  2¾2 2  = 0  1  +   T 2 ¡ 2¹1T + ¹2 1¶ + Tµ ¹1 1 ¡ ¾2  1 2¾2  1 2¾2 2 ¹2 ¾2  2  = 0   T 2 ¡ 2¹2T + ¹2 2¶ +µ ¹2 ¹2 1 2 ¡ 2¾2  2 2¾2  1¶ = 0:  AT 2 + BT + C = 0  A =  ¾2 B = 2 ¾2  1 ¡ ¾2 2  2¹1 ¡ ¾2  1¹2   C = ¾2  1¹2  2 ¡ ¾2  2¹2  1 + 2¾2  1¾2  2 ln  ¾2P1 ¾1P2  :  with  and  with  and  or  Problem 10.25  Problem 10.26  If ¾1 = ¾2 = ¾, then A = 0 in Eq.  10.3 12  and we have to solve the equation  BT + C = 0  B = 2¾2 ¹1 ¡ ¹2   C = ¾2 ¹2 Substituting and cancelling terms gives  2 ¡ ¹2  1  + 2¾4 ln  P1 P2  :  2 ¹1 ¡ ¹2 T ¡  ¹1 + ¹2  ¹1 ¡ ¹2  + 2¾2 ln  P1 P2  = 0  T =  ¹1 + ¹2  +  2  ¾2  ¹1 ¡ ¹2  ln  P1 P2  :  The simplest solution is to use the given means and standard deviations to form two Gaussian probability density functions, and then to use the optimum thresholding ap  proach discussed in Section 10.3.5  in particular, see Eqs.  10.3 11  through  10.3 13 . The probabilities P1 and P2 can be estimated by visual analysis of the images  i.e., by determining the relative areas of the image occupied by objects and background . It is clear by looking at the image that the probability of occurrence of object points is less than that of background points. Alternatively, an automatic estimate can be obtained by   Problem 10.27  Problem 10.28  Problem 10.29  Problem 10.27 157  thresholding the image into points with values greater than 200 and less than 110  see problem statement . Using the given parameters, the results would be good estimates of the relative probability of occurrence of object and background points due to the separa  tion between means, and the relatively tight standard deviations. A more sophisticated approach is to use the Chow Kaneko procedure discussed in Section 10.3.5.  Let m1 and m2 denote the mean gray level of objects and background, respectively, and let ¾1 and ¾2 denote the corresponding standard deviations  see the problem statement for speciﬁc values . We note that §2¾2 about the mean background level gives a range of gray level values from 80 to 140, and that §2¾1 about the mean intensity of the objects gives a range of 120 to 280, so a reasonable separation exists between the two gray level populations. Choosing m1 = 200 as the seed value is quite adequate. Regions are then grown by appending to a seed any point that is 8 connected to any point previously appended to that seed, and whose gray level is m1 § 2¾1.  The region splitting is shown in Fig. P10.28 a . The corresponding quadtree is shown in Fig. P10.28 b .   a  The elements of T [n] are the coordinates of points in the image below the plane g x; y  = n, where n is an integer that represents a given step in the execution of the algorithm. Since n never decreases, the set of elements in T [n ¡ 1] is a subset of the el  ements in T [n]. In addition, we note that all the points below the plane g x; y  = n ¡ 1 are also below the plane g x; y  = n, so the elements of T [n] are never replaced. Sim  ilarly, Cn Mi  is formed by the intersection of C Mi  and T [n], where C Mi   whose elements never change  is the set of coordinates of all points in the catchment basin as  sociated with regional minimum Mi. Since the elements of C Mi  never change, and the elements of T [n] are never replaced, it follows that the elements in Cn Mi  are never replaced either. In addition, we see that Cn¡1 Mi  µ Cn Mi :  b  This part of the problem is answered by the same argument as in  a . Since  1  n   158  Chapter 10 Problem Solutions  always increasesu  2  the elements of neither Cn Mi  nor T [n] are ever replacedu and  3  T [n ¡ 1] µ T [n] and Cn¡1 Mi  µ Cn Mi , it follows that the number of elements of both Cn Mi  and T [n] either increases or remains the same.  Figure P10.28  Problem 10.30  Using the terminology of the watershed algorithm, a break in a boundary between two catchment basins would cause water between the two basins to merge. However, the   Problem 10.31  Problem 10.31 159  heart of the algorithm is to build a dam higher than the highest gray level in the image any time a break in such boundaries occurs. Since the entire topography is enclosed by such a dam, dams are built any time there is a break that causes water to merge between two regions, and segmentation boundaries are precisely the tops of the dams, it follows that the watershed algorithm always produces closed boundaries between regions.  The ﬁrst step in the application of the watershed segmentation algorithm is to build a dam of height max + 1 to prevent the rising water from running off the ends of the function, as shown in Fig. P10.31 b . For an image function we would build a box of height max + 1 around its border. The algorithm is initialized by setting C[1] = T [1]. In this case, T [1] = fg 2 g, as shown in Fig. P10.31 c   note the water level . There is only one connected component in this case: Q[1] = fq1g = fg 2 g: Next, we let n = 2 and, as shown in Fig. P10.31 d , T [2] = fg 2 ; g 14 g and Q[2] = fq1; q2g, where, for clarity, different connected components are separated by semicolons. We start construction of C[2] by considering each connected component in Q[2]. When q = q1, the term q \ C[1] is equal to fg 2 g, so condition 2 is satisﬁed and, therefore, C[2] = fg 2 g. When q = q2, q \ C[1] = ;  the empty set  so condition 1 is satisﬁed and we incorporate q in C[2], which then becomes C[2] = fg 2 ; g 14 g where, as above, different connected components are separated by semicolons.  When n = 3 [Fig. P10.31 e ], T [3] = f2; 3; 10; 11; 13; 14g and Q[3] = fq1; q2; q3g = f2; 3; 10; 11; 13; 14g where, in order to simplify the notation we let k denote g k . Pro  ceeding as above, q1 \ C[2] = f2g satisﬁes condition 2, so q1 is incorporated into the new set to yield C[3] = f2; 3; 14g. Similarly, q2 \ C[2] = ; satisﬁes condition 1 and C[3] = f2; 3; 10; 11; 14g. Finally, q3 \ C[2] = f14g satisﬁes condition 2 and C[3] = f2; 3; 10; 11; 13; 14g. It is easily veriﬁed that C[4] = C[3] = f2; 3; 10; 11; 13; 14g. When n = 5 [Fig. P10.31 f ], we have, T [5] = f2; 3; 5; 6; 10; 11; 12; 13; 14g and Q[5] = fq1; q2; q3g = f2; 3; 5; 6; 10; 11; 12; 13; 14g  note the merging of two previously distinct connected components . Is is easily veriﬁed that q1 \ C[4] satisﬁes condition 2 and that q2 \ C[4] satisﬁed condition 1. Proceeding with these two connected compo  nents exactly as above yields C[5] = f2; 3; 5; 6; 10; 11; 13; 14g up to this point. Things get more interesting when we consider q3. Now, q3 \ C[4] = f10; 11; 13; 14g which, since it contains two connected components of C[4] satisﬁes condition 3. As mentioned previously, this is an indication that water from two different basins has merged and a   160  Chapter 10 Problem Solutions  dam must be built to prevent this. Dam building is nothing more than separating q3 into the two original connected components. In this particular case, this is accomplished by the dam shown in Fig. P10.31 g , so that now q3 = fq31; q32g = f10; 11; 13; 14g. Then, q31 \ C[4] and q32 \ C[4] each satisfy condition 2 and we have the ﬁnal result for n = 5, C[5] = f2; 3; 5; 6; 10; 11; 13; 14g. Continuing in the manner just explained yields the ﬁnal segmentation result shown in Fig. P10.31 h , where the }edges} are visible  from the top  just above the water line. A ﬁnal post processing step would remove the outer dam walls to yield the inner edges of interest.  Problem 10.32  With reference to Eqs.  10.6 4  and  10.6 3 , we see that comparing the negative ADI against a positive, rather than a negative, threshold would yield the image negative of the positive ADI. The result is shown in the left of Fig. P10.32. The image on the right is the positive ADI from Fig. 10.49 b . We have included it here for convenience in making the comparison.  Figure P10.32   Problem 10.32 161  Figure P10.31   162  Chapter 10 Problem Solutions  Problem 10.33   a  True, assuming that the threshold is not set larger than all the differences encountered as the object moves. The easiest way to see this is to draw a simple reference image, such as the white rectangle on a black background. Let that rectangle be the object that moves. Since the absolute ADI image value at any location is the absolute difference between the reference and the new image, it is easy to see that as the object enters areas that are background in the reference image, the absolute difference will change from zero to nonzero at the new area occupied by the moving object. Thus, as long as the object moves the dimension of the absolute ADI will grow.   b  True. The positive ADI is stationary and equal to the dimensions of the moving object because the differences between the reference and the moving object never exceed the threshold in areas that are background in the reference image  assuming as Eq.  10.6  3  that the background has lower values than the object .   c  True. From Eq.  10.6 4 , we see that difference between the background and the object will always be negative  assuming as in Eq.  10.6 4  that the gray levels in the ob  ject exceed the value of the background . Assuming also that the differences are more negative than the threshold, we see for the same reason as in  a  that all new background areas occupied by the moving object will have nonzero counts, thus increasing the di  mension of the nonzero entries in the negative ADI  keep in mind that the values in this image are counts .  Consider ﬁrst the fact that motion in the x direction is zero. When all components of an image are stationary, gx t; a1  is a constant, and its Fourier transform yields an impulse at the origin. Therefore, Fig. 10.53 would now consists of a single impulse at the origin. The other two peaks shown in the ﬁgure would no longer be present. To handle the motion in the positive y direction and its change opposite direction, recall that the Fourier transform is a linear process, so we can use superposition to obtain a solution. The ﬁrst part of motion is in the positive y direction at 1 pixel frame. This is the same as in Example 10.2, so the peaks corresponding to this part of the motion are the same as the ones shown in Fig. 10.54. The reversal of motion is instantaneous, so the 33rd frame would show the object traveling in exactly the opposite direction. To handle this, we simply change a2 to ¡a2 in Eq.  10.6 7 . Based on the discussion in  Problem 10.34   Problem 10.35  Problem 10.35 163  connection with Eq.  10.6 5 , all this change would do is produce peaks at frequencies u = ¡a2v2 and K + a2v2. From Example 10.21 we know that the value of a2 is 4. From the problem statement, we know that v2 = 1 and K = 32. Thus, we have two new peaks added to Fig. 10.54: one at u = ¡4 and the other at u = 36. As noted above, the original peaks correspond to the motion in the positive y direction given in the problem statement, which is the same as in Example 10.21. Note that the frame count was restarted from 0 to 31 with the change in direction.   a  It is given that 10% of the image area in the horizontal direction is occupied by a bullet that is 2.5 cm long. Since the imaging device is square  256 £ 256 elements  the camera looks at an area that is 25 cm £ 25 cm, assuming no optical distortions. Thus, the distance between pixels is 25 256=0.098 cm pixel. The maximum speed of the bullet is 1000 m sec = 100,000 cm sec. At this speed, the bullet will travel 100; 000=0:98 = 1:02 £ 106 pixels sec. It is required that the bullet not travel more than one pixel during exposure. That is,  1:02 £ 106 pixels sec  £ K sec · 1 pixel. So, K · 9:8 £ 10¡7 sec. b  The frame rate must be fast enough to capture at least two images of the bullet in successive frames so that the speed can be computed. If the frame rate is set so that the bullet cannot travel a distance longer  between successive frames  than one half the width of the image, then we have the cases shown in Fig. P10.35. In cases A and E we get two shots of the entire bullet in frames t2 and t3 and t1 and t2, respectively. In the other cases we get partial bullets. Although these cases could be handled with some processing  e.g., by determining size, leading and trailing edges, and so forth  it is possible to guarantee that at least two complete shots of every bullet will be available by setting the frame rate so that a bullet cannot travel more than one half the width of the frame, minus the length of the bullet. The length of the bullet in pixels is  2.5 cm   0.098 cm pixel  ¼ 26 pixels. One half of the image frame is 128 pixels, so the maximum travel distance allowed is 102 pixels. Since the bullet travels at a maximum speed of 1:02£106 pixels sec, the minimum frame rate is 1:02 £ 106=102 = 104 frames  sec.  c  In a ›ashing situation with a re›ective object, the images will tend to be dark, with the object shining brightly. The techniques discussed in Section 10.6.1 would then be quite adequate.   d  First we have to determine if a partial or whole image of the bullet has been obtained. After the pixels corresponding to the object have been identiﬁed using motion segmen    164  Chapter 10 Problem Solutions  tation, we determine if the object runs into the left boundary  see the solution to Problem 9.27  regarding a method for determining if a binary object runs into the boundary of an image . If it does, we look at the next two frames, with the assurance that a complete image of the bullet has been obtained in each because of the frame rate in  b . If the object does not run into the left boundary, we are similarly assured of two full shots in two of the three frames. We then compute the centroid of the object in each image and count the number of pixels between the centroids. Since the distance between pixels and the time between frames are known, computation of the speed is a trivial problem. The principal uncertainty in this approach is how well the object is segmented. However, since the images are of the same object in basically the same geometry, consistency of segmentation between frames can be expected.  Figure P10.35   11 Problem Solutions  Problem 11.1  Problem 11.2  Problem 11.3   a  The key to this problem is to recognize that the value of every element in a chain code is relative to the value of its predecessor. The code for a boundary that is traced in a consistent manner  e.g., clockwise  is a unique circular set of numbers. Starting at different locations in this set does not change the structure of the circular sequence. Selecting the smallest integer as the starting point simply identiﬁes the same point in the sequence. Even if the starting point is not unique, this method would still give a unique sequence. For example, the sequence 101010 has three possible starting points, but they all yield the same smallest integer 010101.   b  Code: 11076765543322. The starting point is 0, yielding the sequence  07676554332211:   a  The ﬁrst difference only counts the number of directions that separate adjacent el  ements of the code. Since the counting process is independent of direction, the ﬁrst difference is independent of boundary rotation.  It is worthwhile to point out to students that the assumption here is that rotation does not change the code itself .   b  Code: 0101030303323232212111. Difference: 3131331313031313031300.  Note that the code was treated as a circular sequence, so the ﬁrst element of the difference is the transition between the last and ﬁrst element of the code, as explained in the text .   a  The rubber band approach forces the polygon to have vertices at every in›ection of the cell wall. That is, the locations of the vertices are ﬁxed by the structure of the   166  Chapter 11 Problem Solutions  inner and outer walls. Since the vertices are joined by straight lines, this produces the minimum perimeter polygon for any given wall conﬁguration.   b  If a corner of a cell is centered at a pixel on the boundary, and the cell is such that the rubber band is tightened on the opposite corner, we would have a situation as shown in Fig. P11.3. Assuming that the cell is of size d£ d, the maximum difference between the pixel and the boundary in that cell is p2d. If cells are centered on pixels, the maximum difference is  p2d =2.  Figure P11.3  Problem 11.4  Problem 11.5   a  The resulting polygon would contain all the boundary pixels.   b  Actually, in both cases the resulting polygon would contain all the boundary pixels.   a  The solution is shown in Fig. P11.5 b .  b  The solution is shown in Fig. P11.5 c .   Problem 11.6 167  Figure P11.5  Problem 11.6   a  From Fig. P11.6 a , we see that the distance from the origin to the triangle is given by  r µ  =  D0 cos µ  0± · µ < 60±  =  =  =  =  =  D0  D0  D0  cos 120± ¡ µ  cos 180± ¡ µ  cos 240± ¡ µ  cos 300± ¡ µ  cos 360± ¡ µ   D0  D0  60± · µ < 120± 120± · µ < 180± 180± · µ < 240± 240± · µ < 300± 300± · µ < 360±  where D0 is the perpendicular distance from the origin to one of the sides of the triangle, and D = D0= cos 60±  = 2D0. Once the coordinates of the vertices of the triangle are given, determining the equation of each straight line is a simple problem, and D0  which is the same for the three straight lines  follows from elementary geometry.   168  Chapter 11 Problem Solutions   b  From Fig. P11.6 b ,  r µ  =  B  2 cos µ  A  A  B  B  2 cos 90± ¡ µ  2 cos µ ¡ 90±  2 cos 180± ¡ µ  2 cos µ ¡ 180±  2 cos 270± ¡ µ  2 cos µ ¡ 270  2 cos 360± ¡ µ   B  A  A  =  =  =  =  =  =  =  0± · µ < ' ' · µ < 90± 90± · µ <  180± ¡ '   180± ¡ '  · µ < 180± 180± · µ < 180± + ' 180± + ' · µ < 270± 270± · µ < 270± + ' 270± + ' · µ < 360±:  We are interested in the distance from the origin to an arbitrary point  x; y  on the ellipse. In polar coordinates,  where ' = tan¡1 A=B :   c  The equation of the ellipse in Fig. P11.6 c  is  x2 a2 +  y2 b2 = 1:  x = r cos µ  y = r sin µ  r =px2 + y2:  and  where is the distance from the origin to  x; y :  Substituting into the equation of the ellipse we obtain  from which we obtain the desired result:  r2 cos2 µ  r2 sin2 µ  +  a2  = 1  b2  1  r µ  =  "µ cos µ a ¶2  +µsin µ  b ¶21=2 :  When b = a, we have the familiar equation of a circle, r µ  = a, or x2 + y2 = a2.  Plots of the three signatures just derived are shown in Fig. P11.6 d   f .   Problem 11.7 169  Figure P11.6  Problem 11.7  The solutions are shown in Fig. P11.7.   170  Chapter 11 Problem Solutions  Figure P11.7  Problem 11.8   a  In the ﬁrst case, N p  = 5, S p  = 1, p2 ¢ p4 ¢ p6 = 0, and p4 ¢ p6 ¢ p8 = 0, so Eq.  11.1 1  is satisﬁed and p is ›agged for deletion. In the second case, N p  = 1, so Eq.  11.1 1  is violated and p is left unchanged. In the third case p2 ¢ p4 ¢ p6 = 1 and p4 ¢ p6 ¢ p8 = 1, so conditions  c  and  d  of Eq.  11.1 1  are violated and p is left unchanged. In the forth case S p  = 2, so condition  b  is violated and p is left unchanged.   b  In the ﬁrst case p2 ¢ p6 ¢ p8 = 1 so condition  dz  in Eq.  11.1 3  is violated and p is left unchanged. In the second case N p  = 1 so p is left unchanged. In the third case  cz  and  dz  are violated and p is left unchanged. In the fourth case S p  = 2 and p is left unchanged.  Problem 11.9   a  The result is shown in Fig. 11.9 b .  b  The result is shown in Fig. 11.9 c .  Figure P11.9  Problem 11.10   a  The number of symbols in the ﬁrst difference is equal to the number of segment   Problem 11.11 171  primitives in the boundary, so the shape order is 12.   b  Starting at the top left corner,  Chain code: Difference: Shape no.:  000332123211 300303311330 003033113303  With reference to the discussion in Section 4.6.1, the DFT can be real only if the data sequence is conjugate symmetric. Only contours that are symmetric with respect to the origin have this property. The axis system of Fig. 11.13 would have to be set up so that this condition is satisﬁed for symmetric ﬁgures. This can be accomplished by placing the origin at the center of gravity of the contour.  Problem 11.11  Problem 11.12  Problem 11.13  The mean is sufﬁcient.  Problem 11.14  Two ellipses with different, say, major axes, have signatures with the same mean and third statistical moment descriptors  both due to symmetry  but different second moment  due to spread .  This problem can be solved by using two descriptors: holes and the convex deﬁciency  see Section 9.5.4 regarding the convex hull and convex deﬁciency of a set . The deci  sion making process can be summarized in the form of a simple decision, as follows: If the character has two holes, it is an 8. If it has one hole it is a 0 or a 9. Otherwise, it is a 1 or an X. To differentiate between 0 and 9 we compute the convex deﬁciently. The presence of a }signiﬁcant} deﬁciency  say, having an area greater than 20% of the area of a rectangle that encloses the character  signiﬁes a 9u otherwise we classify the char  acter as a 0. We follow a similar procedure to separate a 1 from an X. The presence of a convex deﬁciency with four components whose centroids are located approximately in   172  Chapter 11 Problem Solutions  the North, East, West, and East quadrants of the character indicates that the character is an X. Otherwise we say that the character is a 1. This is the basic approach. Imple  mentation of this technique in a real character recognition environment has to take into account other factors such as multiple }small} components in the convex deﬁciency due to noise, differences in orientation, open loops, and the like. However, the material in Chapters 3, 9 and 11 provide a solid base from which to formulate solutions.  Problem 11.15  Problem 11.16   a  The image is  We can use the position operator P : }2m pixels to the right and 2m pixels below.} Other possibilities are P : }2m pixels to the right,} and P : }2m pixels below.} The ﬁrst choice is better in terms of retaining the }›avor} of a checkerboard.  Let z1 = 0 and z2 = 1. Since there are only two gray levels the matrix A is of order 2£ 2. Element a11 is the number of pixels valued 0 located one pixel to the right of a 0. By inspection, a11 = 0. Similarly, a12 = 10, a21 = 10, and a22 = 0. The total number of pixels satisfying the predicate P is 20, so   b In this case, a11 is the number of 0zs two pixels to the right of a pixel valued 0. By inspection, a11 = 8. Similarly, a12 = 0, a21 = 0, and a22 = 7. The number of pixels satisfying P is 15, so  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0  :  C =" 0  1=2  1=2  0  :  C =" 8=15  0  0  7=15  :  Problem 11.17  When assigning this problem, the Instructor may wish to point the student to the review   Problem 11.15 173  of matrices and vectors in the book web site.  From Eq.  11.4 6 ,  Then,  y = A x ¡ mx :  my = Efyg = EfA x ¡ mx g  = A[Efxg ¡ Efmxg] = A[mx ¡ mx] = 0:  This establishes the validity of Eq.  11.4 7 .  To prove the validity of Eq.  11.4 8 , we start with the deﬁnition of the covariance matrix given in Eq.  11.4 3 :  Since my = 0, it follows that  Cy = Ef y ¡ my  y ¡ my Tg:  Cy = EfyyTg  = Ef[A x ¡ mx ][A x ¡ mx ]T g = A Ef x ¡ mx  x ¡ mx TgAT = ACxAT :  Showing the validity of Eq.  11.4 9  is a little more complicated. We start by noting that covariance matrices are real and symmetric. From basic matrix algebra, it is known that a real symmetric matrix of order n has n linearly independent eigenvectors  which are easily orthonormalized by, say, the Gram Schmidt procedure . The rows of matrix A are the orthonormal eigenvectors of Cx. Then,  where use was made of the deﬁnition of an eigenvector  i.e., Cxei = ¸iei  and D is a diagonal matrix composed of the eigenvalues of Cx:  CxAT = Cx[e1; e2; : : : en]  = [Cxe1; Cxe2; : : : Cxen]  = [¸1e1; ¸2e2; : : : ; ¸nen] = AT D  D =266664  ¸1 0 ... 0  0 ¸2 ... 0  ¢ ¢¢ 0 ¢ ¢¢ 0 ... ... ¢ ¢¢ ¸n  :  377775   174  Chapter 11 Problem Solutions  Premultiplying both sides of the preceding equation by matrix a gives  ACxAT = AAT D  = D  where we used the fact that AT A = AAT = I because the rows of A are orthonormal vectors. Thus, since, Cy = ACxAT , we have shown that Cy is a diagonal matrix which is produced by diagonalizing matrix Cx using a transformation matrix composed of its eigenvectors. The eigenvalues of Cy are seen to be the same as the eigenvalues of Cx.  Recall that the eigenvalues of a diagonal matrix are its diagonal terms . The fact that Cyei = Dei = ¸iei shows that the eigenvectors of Cy are equal to the eigenvectors of Cx.  The mean square error, given by Eq.  11.4 12 , is the sum of the eigenvalues whose corresponding eigenvectors are not used in the transformation. In this particular case, the four smallest eigenvalues are applicable  see Table 11.5 , so the mean square error is  ems =  ¸j = 280:  6Xj=3  The maximum error occurs when K = 0 in Eq.  11.4 12  which then is the sum of all the eigenvalues, or 4421 in this case. Thus, the error incurred by using the two eigenvectors corresponding to the largest eigenvalues is only 6.3 % of the total possible error.  This problem is similar to the previous one. The covariance matrix is of order 4096 £ 4096 because the images are of size 64£ 64. It is given that the covariance matrix is the identity matrix, so all its 4096 eigenvalues are equal to 1. From Eq.  11.4 12 , the mean square error is  ems =  4096Xj=1  ¸j ¡  ¸i  2048Xi=1  = 2048:  When the boundary is symmetric about the both the major and minor axes and both axes  Problem 11.18  Problem 11.19  Problem 11.20   Problem 11.21 175  intersect at the centroid of the boundary.  Problem 11.21  A solution using the relationship }connected to,} is shown in Fig. P11.21.  Figure P11.21  Problem 11.22  We can compute a measure of texture using the expression  R x; y  = 1 ¡  1 + ¾2 x; y   1  where ¾2 x; y  is the gray level variance computed in a neighborhood of  x; y . The size of the neighborhood must be sufﬁciently large so as to contain enough samples to have a stable estimate of the mean and variance. Neighborhoods of size 7 £ 7 or 9 £ 9 generally are appropriate for a low noise case such as this.  Since the variance of normal wafers is known to be 400, we can obtain a normal value for R x; y  by using ¾2 = 400 in the above equation. An abnormal region will have a variance of about  50 2 = 2; 500 or higher, yielding a larger value of R x; y . The procedure then is to compute R x; y  at every point  x; y  and label that point as 0 if it is normal and 1 if it is not. At the end of this procedure we look for clusters of 1zs using, for example, connected components  see Section 9.5.3 regarding computation of   176  Chapter 11 Problem Solutions  connected components  . If the area  number of pixels  of any connected component exceeds 400 pixels, then we classify the sample as defective.  Problem 11.23   1  Detecting individual bottles in an imageu  2  This problem has four major parts. ﬁnding the top each bottleu  3  ﬁnding the neck and shoulder of each bottleu and  4  determining the level of the liquid in the region between the neck and the shoulder.   1  Finding individual bottles. Note that the background in the sample image is much darker than the bottles. We assume that this is true in all images. Then, a simple way to ﬁnd individual bottles is to ﬁnd vertical black stripes in the image having a width de  termined by the average separation between bottles, a number that is easily computable from images representative of the actual setup during operation. We can ﬁnd these stripes in various ways. One way is to smooth the image to reduce the effects of noise  we assume that, say, a 3£ 3 or 5£ 5 averaging mask is sufﬁcient . Then, we run a hor  izontal scan line through the middle of the image. The low values in the scan line will correspond to the black or nearly black background. Each bottle will produce a sig  niﬁcant rise and fall of gray level in the scan line for the width of the bottle. Bottles that are fully in the ﬁeld of view of the camera will have a predetermined average width. Bottles that are only partially in the ﬁeld of view will have narrower proﬁles, and can be eliminated from further analysis  but we need to make sure that the trailing incom  plete bottles are analyzed in the next imageu presumably, the leading partial bottle was already processed. .   2  Finding the top of each bottle. Once the location of each  complete or nearly com  plete  bottle is determined, we again can use the contrast between the bottles and the background to ﬁnd the top of the bottle. One possible approach is to compute a gradi  ent image  sensitive only to horizontal edges  and look for a horizontal line near the top of the gradient image. An easier method is to run a vertical scan line through the cen  ter of the locations found in the previous step. The ﬁrst major transition in gray level  from the top of the image  in the scan line will give a good indication of the location of the top of a bottle.   3  Finding the neck and shoulder of a bottle. In the absence of other information, we assume that all bottles are of the same size, as shown in the sample image. Then, once we now where the top of a bottle is, the location of the neck and shoulder are known to be at a ﬁxed distance from the bottle top.   Problem 11.24 177   4  Determining the level of the liquid. The area deﬁned by the bottom of the neck and the top of the shoulder is the only area that needs to be examined to determine acceptable vs. unacceptable ﬁll level in a given bottle. In fact, As shown in the sample image, an area of a bottle that is void of liquid appears quite bright in an image, so we have various options. We could run a single vertical scan line again, but note that the bottles have areas of re›ection that could confuse this approach. This computation is at the core of what this system is designed to do, so a more reliable method should be used. One approach is to threshold the area spanning a rectangle deﬁned by the bottom of the neck, the shoulder, and sides of the bottle. Then, we count the number of white pixels above the midpoint of this rectangle. If this number is greater than a pre established value, we know that enough liquid is missing and declare the bottle improperly ﬁlled. A slightly more sophisticated technique would be to actually ﬁnd the level of the liquid. This would consist of looking for a horizontal edge in the region within the bottle deﬁned by the sides of the bottle, the bottom of the neck, and a line passing midway between the shoulder and the bottom of the neck. A gradient edge linking approach, as described in Sections 10.1 and 10.2 would be suitable. Note however, that if no edge is found, the region is either ﬁlled  dark values in the region  or completely void of liquid  white, or near white values in the region . A computation to resolve these two possible conditions has to follow if the system fails to ﬁnd an edge.  The key speciﬁcation of the desired system is that it be able to detect individual bubbles. No speciﬁc sizes are given. We assume that bubbles are nearly round, as shown in the test image. One solution consists of  1  segmenting the imageu  2  post processing the resultu  3  ﬁnding the bubbles and bubble clusters, and determining bubbles that merged with the boundary of the imageu  4  detecting groups of touching bubblesu  5  counting individual bubblesu and  6  determining the ratio of the area occupied by all bubbles to the total image area.   1  Segmenting the image. We assume that the sample image is truly representative of the class of images that the system will encounter. The image shown in the problem statement is typical of images that can be segmented by a global threshold. As shown by the histogram in Fig. P11.24, the gray level of the objects of interest is high on the gray scale. A simple adaptive threshold method for data that is that high on the scale is to choose a threshold equal to the mean plus a multiple of the standard deviation. We chose a threshold equal to m + 2¾, which, for the image in the problem statement, was  Problem 11.24   178  Chapter 11 Problem Solutions  195. The segmented result is shown on the right of Fig. P11.24. Obviously this is not the only approach we could take, but this is a simple method that adapts to overall changes in intensity.   2  Post processing. As shown in the segmented image of Fig. P11.24, many of the bubbles appear as broken disks, or disks with interior black components. These are mostly due either to re›ection  as in Fig. 9.16  or actual voids within a bubble. We could attempt to build a procedure to repair and or ﬁll the bubbles  as in Problem 9.23 . However, this can turn into a computationally expensive process that is not warranted unless stringent measurement standards are required, a fact not mentioned in the problem statement. An alternative is to calculate, on the average  as determined from a set of sample images , the percentage of bubble areas that are ﬁlled with black or have black }bays} which makes their black areas merge with the background. Then, once the dimensions of each bubble  or bubble cluster  have been established, a correction factor based on area would be applied.   3  Finding the bubbles. Refer to the solution to Problem 9.27. The solution is based on connected components, which also yields all bubbles and bubble clusters.   4  In order to detect bubble clusters we make use of shape analysis. For each con  nected component, we ﬁnd the eigen axes  see Section 11.4  and the standard deviation of the data along these axes  square root of the eigenvalues of the covariance matrix . One simple solution is to compute the ratio of the large to the small variance of each connected component along the eigen axes. A single, uniformly ﬁlled, perfectly round bubble will have a ratio of 1. Deviations from 1 indicate elongations about one of the axes. We look for elliptical shapes as being formed by clusters of bubbles. A threshold to classify bubbles as single vs. clusters has to be determined experimentally. Note that single pixels or pixel streaks one pixel wide have a standard deviation of zero, so they must be processed separately. We have the option of considering connected components that consist of only one pixel to be either noise, or the smallest detectable bubble. No information is given in the problem statement about this. In theory, it is possible for a cluster to be formed such that its shape would be symmetrical about both axes, in which case the system would classify the cluster as a single bubble. Resolution of con›icts such as this would require additional processing. However, there is no evidence in the sample image to suggest that this in fact is a problem. Bubble clusters tend to appear as elliptical shapes. In cases where the ratio of the standard deviations is close to the threshold value, we could add additional processing to reduce the chances of making a mistake.   Problem 11.24 179   5  Counting individual bubbles. A bubble that does not merge with the border of the image or is not a cluster, is by deﬁnition a single bubble. Thus, counting these bubbles is simply counting the connected components that have not been tagged as clusters or merged with the boundary of the image.   6  Ratio of the areas. This ratio is simply the number of pixels in all the connected components plus the correction factors mentioned in  2 , divided by the total number of pixels in the image.  If, as The problem also asks for the size of the smallest bubble the system can detect. mentioned in  4 , we elect to call a one pixel connected component a bubble, then the smallest bubble dimension detectable is the physical size of one pixel. From the problem statement, 700 pixels cover 7 cm, so the dimension of one pixel is 10 mm.  Figure P11.24    12 Problem Solutions  Problem 12.1   a  By inspection, the mean vectors of the three classes are, approximately, m1 =  1:5; 0:3 T , m2 =  4:3; 1:3 T , and m3 =  5:5; 2:1 T for the classes Iris setosa, ver  sicolor, and virginica, respectively. The decision functions are of the form given in Eq.  12.2 5 . Substituting the above values of mean vectors gives:  d1 x  = xT m1 ¡ d2 x  = xT m2 ¡ d3 x  = xT m3 ¡  mT  mT  mT  1 m1 = 1:5x1 + 0:3x2 ¡ 1:2 2 m2 = 4:3x1 + 1:3x2 ¡ 10:1 3 m3 = 5:5x1 + 2:1x2 ¡ 17:3  1 2 1 2 1 2   b  The decision boundaries are given by the equations  d12 x  = d1 x  ¡ d2 x  = ¡2:8x1 ¡ 1:0x2 + 8:9 = 0 d13 x  = d1 x  ¡ d3 x  = ¡4:0x1 ¡ 1:8x2 + 16:1 = 0 d23 x  = d2 x  ¡ d3 x  = ¡1:2x1 ¡ 0:8x2 + 7:2 = 0  A plot of these boundaries is shown in Fig. P12.1.  Figure P12.1   182  Chapter 12 Problem Solutions  Problem 12.2  Problem 12.3  From the deﬁnition of the Euclidean distance,  Since Dj x  is non negative, choosing the smallest Dj x  is the same as choosing the smallest D2  Dj x  = kx ¡ mjk =£ x ¡ mj T  x ¡ mj ¤1=2 j  x , where j  x  = kx ¡ mjk2 =  x ¡ mj T  x ¡ mj  D2 j mj¶  = xT x ¡ 2xT mj + mT j mj = xT x ¡ 2µxT mj ¡ 1 2  mT  We note that the term xT x is independent of j  that is, it is a constant with respect to j in j  x  is equivalent to choosing D2  j  x , j = 1; 2; ::: . Thus, choosing the minimum of D2  the maximum of¡xT mj ¡ 1  2 mT  j mj¢.  The equation of the decision boundary between a pair of mean vectors is  dij x  = xT  mi ¡ mj  ¡   mT  i mi ¡ mT  j mj   1 2  The midpoint between mi and mj is  mi +mj =2  see Fig. P12.3  . First, we show that this point is on the boundary by substituting it for x in the above equation and showing that the result is equal to 0:  1 2   mT  i mi ¡ mT  j mj  ¡   mT  i mi ¡ mT  j mj  =  1 2  1 2 ¡ = 0  j mj    mT  i mi ¡ mT  mT i mi ¡ mT  1 2  j mj   Next, we show that the vector  mi ¡ mj  is perpendicular to the hyperplane boundary. There are several ways to do this. Perhaps the easiest is to show that  mi ¡ mj  is in the same direction as the unit normal to the hyperplane. For a hyperplane with equation w1x1 + w2x2 + :::wnxn + wn+1 = 0, the unit normal is  where wo =  w1; w2; :::; wn T . Comparing the above equation for dij x  with the general equation of a hyperplane just given, we see that wo =  mi ¡ mj  and wn+1 = ¡ mT  j mj =2 . Thus, the unit normal of our decision boundary is  i mi ¡ mT  u =  wo kwok  u =   mi ¡ mj  kmi ¡ mjk   which is in the same direction as the vector  mi ¡ mj . This concludes the proof.  Problem 12.4 183  Problem 12.4  The solution is shown in Fig. P12.4, where the xzs are treated as voltages and the Y zs denote impedances. From basic circuit theory, the currents, Izs, are the products of the voltages times the impedances.  Figure P12.3  Figure P12.4   184  Chapter 12 Problem Solutions  Problem 12.5  Assume that the mask is of size J £ K. For any value of displacement  s; t , we can express the area of the image under the mask, as well as the mask w x; y , in vector form by letting the ﬁrst row of the subimage under the mask represent the ﬁrst K elements of a column vector a, the elements of next row the next K elements of a, and so on. At the end of the procedure we subtract the average value of the gray levels in the subimage from every element of a. The vector a is of size  J £ K  £ 1. A similar approach yields a vector, b, of the same size, for the mask w x; y  minus its average. This vector does not change as  s; t  varies because the coefﬁcients of the mask are ﬁxed. With this construction in mind, we see that the numerator of Eq.  xx.3 8  is simply the vector inner product aT b. Similarly, the ﬁrst term in the denominator is the norm squared of a, denoted aT a = kak2, while the second term has a similar interpretation for b. The correlation coefﬁcient then becomes    s; t  =  aT b  h aT a  bT b i1=2  When a = b  a perfect match ,   s; t  = kak2 =kakkak = 1, which is the maximum value obtainable by the above expression. Similarly, the minimum value occurs when a = ¡b, in which case   s; t  = ¡1. Thus, although the vector a varies in general for every value of  s; t , the values of   s; t  are all in the range [¡1; 1].  The solution to the ﬁrst part of this problem is based on being able to extract connected components  see Chapters 2 and 11  and then determining whether a connected com  ponent is convex or not  see Chapter 11 . Once all connected components have been extracted we perform a convexity check on each and reject the ones that are not convex. All that is left after this is to determine if the remaining blobs are complete or incom  plete. To do this, the region consisting of the extreme rows and columns of the image is declared a region of 1zs. Then if the pixel by pixel AND of this region with a particu  lar blob yields at least one result that is a 1, it follows that the actual boundary touches that blob, and the blob is called incomplete. When only a single pixel in a blob yields an AND of 1 we have a marginal result in which only one pixel in a blob touches the boundary. We can arbitrarily declare the blob incomplete or not. From the point of view of implementation, it is much simpler to have a procedure that calls a blob incomplete whenever the AND operation yields one or more results valued 1.  Problem 12.6   Problem 12.7 185  After the blobs have been screened using the method just discussed, they need to be classiﬁed into one of the three classes given in the problem statement. We perform the classiﬁcation problem based on vectors of the form x =  x1; x2 T , where x1 and x2 are, respectively, the lengths of the major and minor axis of an elliptical blob, the only type left after screening. Alternatively, we could use the eigen axes for the same purpose.  See Section 11.2.1 on obtaining the major axes or the end of Section 11.4 regarding the eigen axes.  The mean vector of each class needed to implement a minimum distance classiﬁer is really given in the problem statement as the average length of each of the two axes for each class of blob. Ify they were not given, they could be obtained by measuring the length of the axes for complete ellipses that have been classiﬁed a priori as belonging to each of the three classes. The given set of ellipses would thus constitute a training set, and learning would simply consist of computing the principal axes for all ellipses of one class and then obtaining the average. This would be repeated for each class. A block diagram outlining the solution to this problem is straightforward.  Problem 12.7   a  Since it is given that the pattern classes are governed by Gaussian densities, only knowledge of the mean vector and covariance matrix of each class are required to specify the Bayes classiﬁer. Substituting the given patterns into Eqs.  12.2 22  and  12.2 23  yields  m1 = " 1 1  5  m2 = " 5 C1 = " 1 0 0 1  = C¡1 0 1  = C¡1 C2 =" 1 0  1  2  and  and  Since C1 = C2 = I, the decision functions are the same as for a minimum distance classiﬁer:  d1 x  = xT m1 ¡  mT  1 m1 = 1:0x1 + 1:0x2 ¡ 1:0  d2 x  = xT m2 ¡  mT  2 m2 = 5:0x1 + 5:0x2 ¡ 25:0  1 2  1 2   186  Chapter 12 Problem Solutions  The Bayes decision boundary is given by the equation d x  = d1 x  ¡ d2 x  = 0, or  d x  = ¡4:0x1 ¡ 4:0x2 + 24:0 = 0   b  A plot of the boundary is shown in Fig. P12.7.  Figure P12.7  Problem 12.8   a  As in Problem 12.7,  m1 = " 0 0  m1 = " 0 0  1 = 2" 1 0 0 1  ; 2" 1 0 0 1  ; 2 xT" 2 0  ln 0:25  ¡  2 =  1  1  jC1j = 0:25  jC2j = 4:00  0 2  x   1  C1 =  2" 1 0 0 1  ; C¡1 0 1  ; C¡1 C2 = 2" 1 0  d1 x  = ¡  = ¡  ln 0:25  ¡  x2  1 + x2 2   d2 x  = ¡  ln 4:00  ¡  1  2 xT" 0:5  0  0  0:5  x   = ¡  ln 4:00  ¡  1 4   x2  1 + x2 2   1 2  1 2  1 2  1 2  and  and  Since the covariance matrices are not equal, it follows from Eq.  12.2 26  that   Problem 12.9 187  where the term ln P  !j  was not included because it is the same for both decision functions in this case. The equation of the Bayes decision boundary is  d x  = d1 x  ¡ d2 x  = 1:39 ¡  b  A plot of the boundary is shown in Fig. P12.8.  3 4   x2  1 + x2  2  = 0:  Problem 12.9  Problem 12.10  Figure P12.8  The basic mechanics are the same as in Problem 12.6, but we have the additional re  quirement of computing covariance matrices from the training patterns of each class.  From basic probability theory,  For any pattern belonging to class !j, p c=x  = p !j=x . Therefore,  Substituting into this equation the formula p !j=x  = p x=!j p !j =p x  gives  p c  =Xx p c  =Xx p c  =Xx  p c=x p x :  p !j =x p x :  p x=!j p !j :  Since the argument of the summation is positive, p c  is maximized by maximizing p x=!j p !j  for each j. That is, if for each x we compute p x=!j p !j  for j = 1; 2; :::; W , and use the largest value each time as the basis for selecting the class from which x came, then p c  will be maximized. Since p e  = 1 ¡ p c , the probability of error is minimized by this procedure.   188  Chapter 12 Problem Solutions  Problem 12.11   a  For class !1 we let y 1  =  0; 0; 0; 1 T , y 2  =  1; 0; 0; 1 T , y 3  =  1; 0; 1; 1 T , y 4  =  1; 1; 0; 1 T . Similarly, for class !2, y 5  =  0; 0; 1; 1 T , y 6  =  0; 1; 1; 1 T , y 7  =  0; 1; 0; 1 T , y 8  =  1; 1; 1; 1 T . Then, using c = 1 and  it follows from Eqs.  12.2 34  through  12.2 36  that:  w 1  =  ¡1; ¡2;¡2; 0 T  w 1 T y 1  = 0; w 2 T y 2  = 0; w 3 T y 3  = 0; w 4 T y 4  = 2; w 5 T y 5  = 2; w 6 T y 6  = ¡2; w 7 T y 7  = 0; w 8 T y 8  = ¡3;  w 2  = w 1  + y 1  =  ¡1; ¡2;¡2; 1 T ; w 3  = w 2  + y 2  =  0;¡2; ¡2; 2 T ; w 4  = w 3  + y 3  =  1;¡2; ¡1; 3 T ; w 5  = w 4  =  1; ¡2;¡1; 3 T ; w 6  = w 5  ¡ y 5  =  ¡1; ¡2;¡2; 2 T ; w 7  = w 6  =  ¡1;¡2; ¡2; 2 T ; w 8  = w 7  ¡ y 7  =  1;¡3; ¡2; 1 T ; w 9  = w 8  =  1; ¡3;¡2; 1 T :  Since a complete iteration through all patterns without an error was not achieved, the patterns are recycled by letting y 9  = y 1 , y 10  = y 2 , and so on, which gives  w 9 T y 9  = 1; w 10 T y 10  = 2; w 11 T y 11  = 0; w 12 T y 12  = 1; w 13 T y 13  = 1; w 14 T y 14  = ¡4; w 15 T y 15  = ¡2; w 16 T y 16  = ¡2;  w 10  = w 9  =  1;¡3; ¡2; 1 T ; w 11  = w 10  =  1;¡3;¡2; 1 T ; w 12  = w 11  + y 11  =  2;¡3; ¡1; 2 T ; w 13  = w 12  =  2;¡3;¡1; 2 T ; w 14  = w 13  ¡ y 13  =  2;¡3; ¡2; 1 T ; w 15  = w 14  =  2;¡3;¡2; 1 T ; w 16  = w 15  =  2;¡3;¡2; 1 T ; w 17  = w 16  =  2;¡3;¡2; 1 T :  Again, since a complete iteration over all patterns without an error was not achieved, the patterns are recycled by letting y 17  = y 1 , y 18  = y 2 , and so on, which gives:  w 17 T y 17  = 1; w 18  = w 17  =  2;¡3; ¡2; 1 T ; w 18 T y 18  = 3; w 19  = w 18  =  2;¡3; ¡2; 1 T ; w 19 T y 19  = 1; w 20  = w 19  =  2;¡3; ¡2; 1 T ; w 20 T y 20  = 0; w 21  = w 20  + y 20  =  3;¡2;¡2; 2 T ; w 21 T y 21  = 0; w 22  = w 21  ¡ y 21  =  3;¡2;¡3; 1 T :  It is easily veriﬁed that no more corrections take place after this step, so w 22  =  3;¡2;¡3; 1 T is a solution weight vector.  b  The decision surface is given by the equation  wT y = 3y1 ¡ 2y2 ¡ 3y3 + 1 = 0   A section of this surface is shown schematically in Fig. P12.11. The positive side of the surface faces the origin.  Problem 12.12 189  Figure P12.11  Problem 12.12  We start by taking the partial derivative of J with respect to w:  @J @w  =  1  2£ysgn wT y  ¡ y¤  where, by deﬁnition, sgn wT y  = 1 if wT y > 0, and sgn wT y  = ¡1 otherwise. Substituting the partial derivative into the general expression given in the problem state  ment gives  w k + 1  = w k  +  c  2ny k  ¡ y k sgnhw k T y k io  where y k  is the training pattern being considered at the kth iterative step. Substituting the deﬁnition of the sgn function into this result yields  w k + 1  = w k  + c  0  if w k T y k   y k  otherwise  where c > 0 and w 1  is arbitrary. This expression agrees with the formulation given in the problem statement.  Problem 12.13  Let the training set of patterns be denoted by y1; y2; : : : ; yN . It is assumed that the   190  Chapter 12 Problem Solutions  training patterns of class !2 have been multiplied by ¡1. If the classes are linearly separable, we want to prove that the perceptron training algorithm yields a solution weight vector, w¤, with the property  w¤T yi ¸ T0  where T0 is a nonnegative threshold. With this notation, the Perceptron algorithm  with c = 1  is expressed as w k + 1  = w k  if wT  k yi k  ¸ T0 or w k + 1  = w k  + yi k  otherwise.  Suppose that we retain only the values of k for which a correction takes place  these are really the only indices of interest . Then, re adapting the index notation, we may write  w k + 1  = w k  + yi k   wT  k yi k  · T0  and  or  or  With these simpliﬁcations in mind, the proof of convergence is as follows: From the above equation,  w k + 1  = w 1  + yi 1  + yi 2  + ¢ ¢¢ + yi k   Taking the inner product of the solution weight vector with both sides of this equation gives  wT  k + 1 w¤ = wT  1 w¤ + yT  i  1 w¤ + yT i  j w¤, j = 1; 2; :::; k, is less than T0, so  Each term yT  i  2 w¤ + ¢ ¢¢ + yT  i  k w¤  Using the Cauchy Schwartz inequality, kak2 kbk2 ¸  aT b 2, results in  wT  k + 1 w¤ ¸ wT  1 w¤ + kT0 £wT  k + 1 w¤¤2   wT  k + 1   2  ·  wT  k + 1   2 kw¤k2 ¸ £wT  k + 1 w¤¤2  kw¤k2  :  Another line of reasoning leads to a contradiction regarding   wT  k + 1   2 . From  above,  kw j + 1 k2 = kw j k2 + 2wT  j yi j  + kyi j k2  kw j + 1 k2 ¡ kw j k2 = 2wT  j yi j  + kyi j k2  Let Q = max  jjyi j jj2. Then, since wT  j yi j  · T0,  i  Adding these inequalities for j = 1; 2; : : : ; k yields  kw j + 1 k2 ¡ kw j k2 · 2T0 + Q  kw j + 1 k2 · kw 1 k2 + [2T0 + Q] k   Problem 12.14 191  This inequality establishes a bound on kw j + 1 k22 that con›icts for sufﬁciently large k with the bound established by our earlier inequality. In fact, k can be no larger than km, which is a solution to the equation  £wT  k + 1 w¤ + kmT0¤2  kw¤k2  = kw 1 k2 + [2T0 + Q] km  This equation says that km is ﬁnite, thus proving that the perceptron training algorithm converges in a ﬁnite number of steps to a solution weight vector w¤ if the patterns of the training set are linearly separable.  Note: The special case with T0 = 0 is proved in a slightly different manner. Under this condition we have  where  Since, by hypothesis, w¤ is a solution weight vector, we know that£yT  Also, since wT  j yi j  ·  T = 0 ,  i  j w¤¤ ¸ 0.  i  wT  k + 1 w¤ ¸ wT  1 w¤ + ka  a = min  £yT i  j w¤¤  kw j + 1 k2 ¡ kw j k2 · kyi j k2  · Q:  £wT  1 w¤ + kma¤2  kw¤k2  = kw 1 k2 + Qkm  The rest of the proof remains the same. The bound on the number of steps is the value of km that satisﬁes the following equation:  The single decision function that implements a minimum distance classiﬁer for two classes is of the form  dij x  = xT  mi ¡ mj  ¡   mT  i mi ¡ mT  j mj :  1 2  Thus, for a particular pattern vector x, when dij x  > 0, x is assigned to class !1 and, when dij x  < 0, x is assigned to class !2. Values of x for which dij x  = 0 are on the boundary  hyperplane  separating the two classes. By letting w =  mi ¡ mj  and wn+1 = ¡ 1 j mj , we can express the above decision function in the form  i mi ¡ mT  2  mT  d x  = wT x ¡ wn+1:  This is recognized as a linear decision function in n dimensions, which is implemented by a single layer neural network with coefﬁcients  wk =  mik ¡ mjk   k = 1; 2; : : : ; n  Problem 12.14   192  Chapter 12 Problem Solutions  Problem 12.15  µ = wn+1 = ¡   mT  i mi ¡ mT  j mj :  1 2  and  and  The approach to solving this problem is basically the same as in Problem 12.14. The idea is to combine the decision functions in the form of a hyperplane and then equate coefﬁcients. For equal covariance matrices, the decision function for two pattern classes is obtained Eq.  12.2 27 :  dij x  = di x  ¡ dj x  = ln P  !i  ¡ ln P  !j  + xT C¡1 mi ¡ mj   1 2  ¡   mi ¡ mj T C¡1 mi ¡ mj :  As in Problem 12.14, this is recognized as a linear decision function of the form  which is implemented by a single layer perceptron with coefﬁcients  d x  = wT x ¡ wn+1  wk = vk  k = 1; 2; : : : ; n  µ = wn+1 = ln P  !i  ¡ ln P  !j  + xT C¡1 mi ¡ mj   where the vk are elements of the vector  v = C¡1 mi ¡ mj :   a  When P  !i  = P  !j  and C = I.   b  No. The minimum distance classiﬁer implements a decision function that is the perpendicular bisector of the line joining the two means. If the probability densities are known, the Bayes classiﬁer is guaranteed to implement an optimum decision function in the minimum average loss sense. The generalized delta rule for training a neural network says nothing about these two criteria, so it cannot be expected to yield the decision functions in Problems 12.14 or 12.15.  The classes and boundary needed to separate them are shown in Fig. P12.17 a . The boundary of minimum complexity in this case is a triangle, but it would be so tight  Problem 12.16  Problem 12.17   Problem 12.18 193  in this arrangement that even small perturbations in the position of the patterns could result in classiﬁcation errors. Thus, we use a network with the capability to implement 4 surfaces  lines  in 2D. The network, shown in Fig. P12.17 b , is an extension of the concepts discussed in the text in connection with Fig. 12.22. In this case, the output node acts like an AND gate with 4 inputs. The output node outputs a 1  high  when the outputs of the preceding 4 nodes are all high simultaneously. This corresponds to a pattern being on the + side of all 4 lines and, therefore, belonging to class !1. Any other combination yields a 0  low  output, indicating class !21.  Figure P12.17  Problem 12.18  Problem 12.19  All that is needed is to generate for each class training vectors of the form x =  x1; x2 T , where x1 is the length of the major axis and x2 is the length of the minor axis of the blobs comprising the training set. These vectors would then be used to train a neural network using, for example, the generalized delta rule.  Since the patterns are in 2D, it is useful to point out to students that the neural network could be designed by inspection in the sense that the classes could be plotted, the decision boundary of minimum complexity obtained, and then its coefﬁcients used to specify the neural network. In this case the classes are far apart with respect to their spread, so most likely a single layer network implementing a linear decision function could do the job.   This problem, although it is a simple exercise in differentiation, is intended to help the student ﬁx in mind the notation used in the derivation of the generalize delta rule. From Eq.  12.2 50 , with µ0 = 1;  hj Ij  =  1  1 + e¡hP NK  k=1 wjkOk+µji :   194  Chapter 12 Problem Solutions  Since, from Eq.  12.2 48 ,  it follows that  Ij =  wjkOk  NKXk=1  hj Ij  =  1 + e¡[Ij + µj ] :  1  Taking the partial derivative of this expression with respect to Ij gives  h0j Ij  =  @hj Ij   @Ij  =  Oj = hj Ij  =  Oj 1 ¡ Oj  =  e¡[Ij + µj]  £1 + e¡[Ij + µj ]¤2 :  1  1 + e¡[Ij + µj ] : e¡[Ij + µj ]  £1 + e¡[Ij + µj]¤2  h0j Ij  = Oj 1 ¡ Oj   From Eq.  12.2 49   It is easily shown that  This completes the proof.  Problem 12.20  so  as  The ﬁrst part of Eq.  12.3 3  is proved by noting that the degree of similarity, k, is non  negative, so D A; B  = 1=k ¸ 0. Similarly, the second part follows from the fact that k is inﬁnite when  and only when  the shapes are identical.  To prove the third part we use the deﬁnition of D to write  D A; C  · max [D A; B ; D B; C ]  or, equivalently,  1  kac · max· 1  kab  ;  1  kbc¸  kac ¸ min [kab; kbc]  where kij is the degree of similarity between shape i and shape j. Recall from the de  ﬁnition that k is the largest order for which the shape numbers of shape i and shape j still coincide. As Fig. 12.24 b  illustrates, this is the point at which the ﬁgures }sepa  rate} as we move further down the tree  note that k increases as we move further down the tree . We prove that kac ¸ min[kab; kbc] by contradiction. For kac · min[kab; kbc] to hold, shape A has to separate from shape C before  1  shape A separates from shape B; and  2  before shape B separates from shape C, otherwise kab · kac or kbc · kac, which automatically violates the condition kac < min[kab; kbc]. But, if  1  has to hold,   Problem 12.21 195  then Fig. P12.20 shows the only way that A can separate from C before separating from B. This, however, violates  2 , which means that the condition kac < min[kab; kbc] is violated  we can also see this in the ﬁgure by noting that kac = kbc which, since kbc < kab, violates the condition . We use a similar argument to show that if  2  holds then  1  is violated. Thus, we conclude that it is impossible for the condition kac < min[kab; kbc] to hold, thus proving that kac ¸ min[kab; kbc] or, equivalently, that D A; C  · max[D A; B ; D B; C ].  Figure P12.20  Problem 12.21  Problem 12.22  Q = 0 implies that max jAj ;jBj  = M. Suppose that jAj > jBj. Then, it must follow that jAj = M and, therefore, that M > jBj. But M is obtained by matching A and B, so it must be bounded by M · min jAj ; jBj . Since we have stipulated that jAj > jBj, the condition M · min jAj ;jBj  implies M · jBj. But this contradicts the above result, so the only way for max jAj ; jBj  = M to hold is if jAj = jBj. This, in turn, implies that A and B must be identical strings  A ´ B  because jAj = jBj = M means that all symbols of A and B match. The converse result that if A ´ B then Q = 0 follows directly from the deﬁnition of Q.   a  An automaton capable of accepting only strings of the form abna ¸ 1, shown in Fig. P12.22, is given by  Af =  Q; §; ±; q0; F  ;   196  Chapter 12 Problem Solutions  with  mappings  and  Q = fq0; q1; q2; q3; q;g; § = fa; bg;  ± q0; a  = fq1g; ± q1; b  = fq1; q2g; ± q2; a  = fq3g  F = fq3g:  For completeness we write  ± q0; b  = ± q1; a  = ± q2; b  = ± q3; a  = ± q3; b  = ± q;; a  = ± q;; b  = fq;g;  corresponding to the null state.   b  To obtain the corresponding grammar we use the procedure discussed in Section 12.3.3 under the heading Automata as string recognizers: 1. If qj is in ± qi; c , there is a production Xi ¡! Xj in P u 2. If a state in F is in ± qi; c , there is a production Xi ¡! c in P. Normally, null state transitions are not included in the generation of productions. Using the results in  a  we obtain the grammar G =  N; §; P; X0 , with N = fX0; X1; X2g, § = fa; bg, and productions P = fX0 ¡! aX1; X1 ¡! bX1; X1 ¡! bX2; X2 ¡! ag.  Figure P12.22  Problem 12.23  The patterns are of the form shown in the solution to Problem 11.2.  This problem is   Problem 12.24 197  not starred, so a solution in not included in the book web site. If the problem was not assigned, it might be a good idea to give the solution in class . A possible expansive tree grammar is G =  N; §; P; r; S , with N = fS; X1; X2; :::; X6g, § = f0; 1g, r 0  = f0; 1; 2}, r 1  = f0; 1; 2g, and the productions shown in Fig. P12.23:  Figure P12.23  Problem 12.24  For the sample set R+ = faba; abba; abbbag it is easily shown that, for k = 1 and 2, h ¸; R+; k  = ;, the null set. Since q0 = h ¸; R+; k  is part of the inference procedure, we need to choose k large enough so that h ¸; R+; k  is not the null set. The shortest string in R+ has three symbols, so k = 3 is the smallest value that can accomplish this. For this value of k, a trial run will show that one more string needs to be added to R+ in order for the inference procedure to discover iterative regularity in symbol b. The sample string set then becomes R+ = faba; abba; abbba; abbbbag. Recalling that h z; R+; k  = fw jzw in R+; jwj · kg we proceed as follows:  z = ¸;  h ¸; R+; 3  = fw j¸w in R+;jwj · 3g  z = a;  h a; R+; 3  = fwjaw in R+;jwj · 3g  = fabag = q0;  = fba; bbag = q1;   198  Chapter 12 Problem Solutions  z = ab;  h ab; R+; 3  = fw jabw in R+;jwj · 3g  z = aba;  h aba; R+; 3  = fw jabaw in R+;jwj · 3g  z = abb;  h abb; R+; 3  = fw jabbw in R+;jwj · 3g  z = abba;  h abba; R+; 3  = fw jabbaw in R+;jwj · 3g  z = abbb;  h abbb; R+; 3  = fw jabbbw in R+;jwj · 3g  z = abbba;  h abbba; R+; 3  = fw jabbbaw in R+;jwj · 3g  z = abbbb;  h abbbb; R+; 3  = fw jabbbbw in R+; jwj · 3g  z = abbbba;  h abbbba; R+; 3  = fw jabbbbaw in R+; jwj · 3g  = fa; ba; bbag = q2;  = f¸g = q3;  = fa; ba; bbag = q2;  = f¸g = q3;  = fa; bag = q4;  = f¸g = q3;  = fag = q5;  = f¸g = q3;  Other strings z in §¤ =  a; b ¤ yield strings zw that do not belong to R+, giving rise to another state, denoted q;, which corresponds to the condition that h is the null set. Therefore, the states are q0 = fabag, q1 = fba; bbag, q2 = fa; ba; bbag, q3 = f¸g, q4 = fa; bag, and q5 = fag, which gives the set Q = fq0; q1; q2; q3; q4; q5; q;g. The next step is to obtain the mappings. We start by recalling that, in general, q0 = h ¸; R+; k . Also, in general,  ± q; c  = fq0 in Q¯¯q0 = h zc; R+; k ; with q = h z; R+; k g:  In our case, q0 = h ¸; R+; 3  and, therefore,  ± q0; a  = h ¸a; R+; 3  = h a; R+; 3  = fq1g = q1   Problem 12.24 199  and  ± q0; b  = h ¸b; R+; 3  = h b; R+; 3  = fq;g = q;;  where we have omitted the curly brackets for clarity in notation since the set contains only one element. Similarly, q1 = h a; R+; 3 , and  ± q1; a  = h aa; R+; 3  = h a; R+; 3  = q;; ± q1; b  = h ab; R+; 3  = q2:  Continuing in this manner gives q2 = h ab; R+; 3  = h abb; R+; 3 ,  ± q2; a  = h aba; R+; 3  = h abba; R+; 3  = q3; ± q2; b  = h abb; R+; 3  = q2;  and, also,  ± q2; b  = h abbb; R+; 3  = q4:  Next, q3 = h aba; R+; 3  = h abba; R+; 3  = h abbba; R+; 3  = h abbbba; R+; 3 , from which we obtain  ± q3; a  = h abaa; R+; 3  = h abbaa; R+; 3   = h abbbaa; R+; 3  = h abbbbaa; R+; 3  = q;  ± q3; b  = h abab; R+; 3  = h abbab; R+; 3   = h abbbab; R+; 3  = h abbbbab; R+; 3  = q;;  For the following state, q4 = h abbb; R+; 3 ;  Finally, for the last state, q5 = h abbbb; R+; 3 , and  ± q4; a  = h abbba; R+; 3  = q3; ± q4; b  = h abbbb; R+; 3  = q5:  ± q5; a  = h abbbba; R+; 3  = q3; ± q5; b  = h abbbbb; R+; 3  = q;:  We complete the elements of the automaton by recalling that F = fq jq in Q; ¸ in qg = q3. We also include two remaining mappings that yield the null set: ± q;; a  = ± q;; b  = q;. Summarizing, the state mappings are:  ± q0; a  = q1; ± q0; b  = q;; ± q1; a  = q;; ± q1; b  = q2;   200  Chapter 12 Problem Solutions  ± q2; a  = q3; ± q2; b  = fq2; q4g; ± q3; a  = q;; ± q3; b  = q;; ± q4; a  = q3; ± q4; b  = q5; ± q5; a  = q3; ± q5; b  = q;; ± q;; a  = q;; ± q;; b  = q;:  A diagram of the automaton is shown in Fig. P12.24. The iterative regularity on b is ev  ident in state q2. This automaton is not as elegant as its counterpart in Problem 12.22 a . This is not unexpected because nothing in the inference procedure deals with state min  imization. Note, however, that the automaton accepts only strings of the form abna, b ¸ 1, as desired. The minimization aspects of a design generally follow inference and are based on one of several standard methods  see, for example, Gonzalez and Thoma  son [1978] . In this particular example, even visual inspection reveals that states q4 and q5 are redundant.  Figure P12.24  Problem 12.25  Consider the automaton related to Fig. 12.30, and the tree shown in Fig. 12.31 b . The explanation is simpliﬁed by moving up the tree one level at a time, starting at the lowest level. In this case the lowest level is in the innermost branch labeled with azs. We start at its frontier node and assign state X1 to that node by virtue of fa. The next level contains   Problem 12.26  Problem 12.26 201  an a along that same branch, but its offspring now has been labeled X1. Assignment fa again indicates an assignment of X1. We move up the tree in this manner. The assignments along all the single branches of azs are X1zs, while those along the single branches of bzs are X2zs. This continues until the automaton gets to the bottom of the single branch of azs at the center of the tree. This particular a now has three offspring labeled X1 and three labeled X2, which causes fa to assign state S to that a. As the automaton moves up one more level, it encounters another a. Since its offspring is S, fa assigns state S to it and moves up another level. It is evident that the automaton will end in state S when the last  root  node is processed. Since S is in F , the automaton in fact has accepted the tree in Fig. 12.31 b .  There are various possible approaches to this problem, and our students have shown over the years a tendency to surprise us with new and novel approaches to problems of this type. We give here a set of guidelines that should be satisﬁed by most practical solu  tions, and also offer suggestions for speciﬁc solutions to various parts of the problem. Depending on the level of maturity of the class, some of these may be offered as }hints} when the problem is assigned.  Since speed and cost are essential system speciﬁcations, we conceptualize a binary ap  proach in which image acquisition, preprocessing, and segmentation are combined into one basic operation. This approach leads us to global thresholding as the method of choice. In this particular case this is possible because we can solve the inspection prob  lem by concentrating on the white parts of the ›ag  stars and white stripes . As discussed in Section 10.3.2, uniform illumination is essential, especially when global thresholding is used for segmentation. The student should mention something about uniform illumi  nation, or compensation for nonuniform illumination. A discussion by the student of color ﬁltering to improve contrast between white and  red blue background  parts of an image is a plus in the design.  The ﬁrst step is to specify the size of the viewing area, and the resolution required to detect the smallest components of interest, in this case the stars. Since the images are moving and the exact location of each ›ag is not known, it is necessary to specify a ﬁeld of view that will guarantee that every image will contain at least one complete ›ag. In addition, the frame rate must be fast enough so that no ›ags are missed. The ﬁrst part of the problem is easy to solve. The ﬁeld of view has to be wide enough to encompass an   202  Chapter 12 Problem Solutions  area slightly greater across than two ›ags plus the maximum separation between them. Thus, the width, W , of the viewing area must be at least W = 2 5  + 2:05 = 12:1in. If we use a standard CCD camera of resolution 640 £ 480 elements and view an area 12:8 in. wide, this will give us a sampling rate of approximately 50 pixels inch, or 250 pixels across a single ›ag. Visual inspection of a typical ›ag will show that the blue portion of a ›ag occupies about 0:4 times the length of the ›ag, which in this case gives us about 100 pixels per line in the blue area. There is a maximum of six stars per line, and the blue space between them is approximately 1.5 times the width of a star, so the number of pixels across a star is 100= [1 + 1:5] £ 6  ' 6 pixels star. The next two problems are to determine the shutter speed and the frame rate. Since the number of pixels across each object of interest is only 6, we ﬁx the blur at less than one pixel. Following the approach used in the solution of Problem 10.35, we ﬁrst determine the distance between pixels as  12:8 in =640 pixels = 0:02 in=pixel. The maximum speed of the ›ags is 21in sec. At this speed, the ›ags travel 21=0:02 = 1; 050 pixels sec. We are requiring that a ›ag not travel more than one pixel during exposureu that is  1; 050 pixels=sec  £ T sec · 1 pixel. So, T · 9:52 £ 10¡4 sec is the shutter speed needed.  The frame rate must be fast enough to capture an image of every ›ag that passes the inspection point. Since it takes a ›ag  21 in=sec = 12:8 in  ' 0:6 sec to cross the entire ﬁeld of view we take a frame every 0.3 sec in order to guarantee that every image will contain a whole ›ag, and that no ›ag will be missed. We assume that the camera is computer controlled to ﬁre from a clock signal. We also make the standard assumption that it takes 1=30 sec ' 330 £ 10¡4 sec to read a captured image into a frame buffer. Therefore, the total time needed to acquire an image is  330+9:5 £10¡4 ' 340£10¡4 sec. Subtracting this quantity from the 0.3 sec frame rate leaves us with about 0.27 sec to do all the processing required for inspection, and to output an appropriate signal to some other part of the manufacturing process.  Since a global thresholding function can be incorporated in most digitizers as part of the data acquisition process, no additional time is needed to generate a binary image. That is, we assume that the digitizer outputs the image in binary form. The next step is to isolate the data corresponding to a complete ›ag. Given the imaging geometry and frame rate discussed above, four basic binary image conﬁgurations are expected:  1  part of a ›ag on the left of the image, followed by a whole ›ag, followed by another partial ›agu  2  one entire ›ag touching the left border, followed by a second entire ›ag, and then a gap before the right borderu  3  the opposite of  2 u and  4  two entire ›ags, with   Problem 12.26 203  neither ›ag touching the boundary of the image. Cases  2 ,  3 , and  4  are not likely to occur with any signiﬁcant frequency, but we will check for each of these conditions. As will be seen below, Cases  2  and  3  can be handled the same as Case  1 , but, given the tight bounds on processing time, the output each time Case  4  occurs will be to reject both ›ags.  To handle Case  1  we have to identify a whole ›ag lying between two partial ›ags. One of the quickest ways to do this is to run a window as long as the image vertically, but nar  row in the horizontal direction, say, corresponding to 0.35 in.  based on the window size 1 2 of [12:8 ¡ 12:1] , which is approximately  0:35  640 =12:8 ' 17 pixels wide. This window is used look for a signiﬁcant gap between a high count of 1zs, and it is narrow enough to detect Case  4 . For Case  1 , this approach will produce high counts starting on the left of the image, then drop to very few counts  corresponding to the background  for about two inches, pick up again as the center  whole ›ag  is encountered, go like this for about ﬁve inches, drop again for about two inches as the next gap is encountered, then pick up again until the right border is encountered. The 1zs between the two inner gaps correspond to a complete ›ag and are processed further by the methods discussed belowu the other 1zs are ignored.  A more elegant and potentially more rugged way is to determine all connected components ﬁrst, and then look for vertical gaps, but time and cost are fundamental here . Cases  2  and  3  are handled in a similar manner with slightly different logic, being careful to isolate the data corresponding to an entire ›ag  i.e., the ›ag with a gap on each side . Case  4  corresponds to a gap data gap data gap sequence, but, as mentioned above, it is likely that time and cost constraints would dic  tate rejecting both ›ags as a more economical approach than increasing the complexity of the system to handle this special case. Note that this approach to extracting 1zs is based on the assumption that the background is not excessively noisy. In other words, the imaging set up must be such that the background is reliably segmented as black, with acceptable noise.  With reference to Fig. 1.23, the preceding discussion has carried us through the seg  mentation stage. The approach followed here for description, recognition, and the use of knowledge, is twofold. For the stars we use connected component analysis. For the stripes we use signature analysis. The system knows the coordinates of two vertical lines which contain the whole ›ag between them. First, we do a connected components analysis on the left half of the region  to save time  and ﬁlter out all components smaller and larger than the expected size of stars, say  to give some ›exibility , all components less than 9  3 £ 3  pixels and larger than 64  8 £ 8  pixels. The simplest test at this point is to count the number of remaining connected components  which we assume to   204  Chapter 12 Problem Solutions  be stars . If the number is 50 we continue with the next test on the stripes. If the number is less than 50 we reject the ›ag. Of course, the logic can be made much more compli  cated than this. For instance, it could include a regularity analysis in which the relative locations of the components are analyzed. There are likely to be as many answers here as there are students in the class, but the key objective should be to base the analysis on a rugged method such as connected component analysis.  To analyze the stripes, we assume that the ›ags are printed on white stock material. Thus, }dropping a stripe} means creating a white stripe twice as wide as normal. This is a simple defect detectable by running a vertical scan line in an area guaranteed to contain stripes, and then looking at the gray level signature for the number of pulses of the right height and duration. The fact that the data is binary helps in this regard, but the scan line should be preprocessed to bridge small gaps due to noise before it is analyzed. In spite of the §15± variation in direction, a region, say, 1in. to the right of the blue region is independent enough of the rotational variation in terms of showing only stripes along a scan line run vertically in that region.  It is important that any answer to this problem show awareness of the limits in available computation time. Since no mention is made in the problem statement about available processors, it is not possible to establish with absolute certainty if a solution will meet the requirements or not. However, the student should be expected to address this issue. The guidelines given in the preceding solution are among the fastest ways to solve the problem. A solution along these lines, and a mention that multiple systems may be required if a single system cannot meet the speciﬁcations, is an acceptable solution to the problem.

@highlight

This manual contains detailed solutionsto all problems in Digital Image Processing, 2nd Edition. We also include a suggested set of guidelines for using the book, and discuss the use of computer projects designed to promote a deeper understanding of the subject matter. The notation used throughout this manual corresponds to the notation used in the text. Computer projects such as those described in the web site are an important part of a course on image processing. These projects give the student hands-on experience with algorithm implementation and reinforce the material covered in the classroom. The projects suggested at the web site can be implemented on almost any reasonablyequipped multi-user or personal computer having a hard copy output device.
