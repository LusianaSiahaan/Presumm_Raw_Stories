Contents   cid:468  Starting your project   cid:468 . cid:468  P⁴thon versions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   cid:468 . cid:469  Project la⁴out . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   cid:468 . cid:470   Version numbering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   cid:468 . cid:471  Coding st⁴le & automated checks . . . . . . . . . . . . . . . . . . . . . .   cid:468   cid:468    cid:469    cid:472    cid:474    cid:469  Modules and libraries   cid:468  cid:468   cid:469 . cid:468  The import s⁴stem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468    cid:469 . cid:469  Standard libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:473    cid:469 . cid:470    cid:469 . cid:471    cid:469 . cid:472   External libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475   Frameworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:468   Interview with Doug Hellmann . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469    cid:469 . cid:473  Managing API changes . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:470  cid:468    cid:469 . cid:474   Interview with Christophe de Vienne . . . . . . . . . . . . . . . . . . . .  cid:470  cid:472    cid:470  Documentation   cid:471  cid:467   cid:470 . cid:468  Getting started with Sphinx and reST . . . . . . . . . . . . . . . . . . . .  cid:471  cid:469    CONTENTS  ii   cid:470 . cid:469  Sphinx modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:471  cid:470    cid:470 . cid:470   Extending Sphinx . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:471  cid:474    cid:471  Distribution   cid:472  cid:467   cid:471 . cid:468  A bit of histor⁴ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:467    cid:471 . cid:469  Packaging with pbr  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:470    cid:471 . cid:470  The Wheel format  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:472    cid:471 . cid:471  Package installation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:474    cid:471 . cid:472  Sharing ⁴our work with the world . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:476    cid:471 . cid:473    cid:471 . cid:474   Interview with Nick Coghlan . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:473  cid:471   Entr⁴ points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:473  cid:473    cid:471 . cid:474 . cid:468   Visualising entr⁴ points . . . . . . . . . . . . . . . . . . . . . . . .  cid:473  cid:474    cid:471 . cid:474 . cid:469  Using console scripts . . . . . . . . . . . . . . . . . . . . . . . . .  cid:473  cid:475    cid:471 . cid:474 . cid:470  Using plugins and drivers . . . . . . . . . . . . . . . . . . . . . . .  cid:474  cid:468    cid:472  Virtual environments   cid:474  cid:472    cid:473  Unit testing   cid:475  cid:469   cid:473 . cid:468  The basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:475  cid:469    cid:473 . cid:469   Fixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:468    cid:473 . cid:470  Mocking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:469    cid:473 . cid:471  Scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:475    cid:473 . cid:472  Test streaming and parallelism . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:469    cid:473 . cid:473  Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:474    cid:473 . cid:474  Using virtualenv with tox . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:468    CONTENTS  iii   cid:473 . cid:475  Testing polic⁴ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:473    cid:473 . cid:476   Interview with Robert Collins . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:474    cid:474  Methods and decorators   cid:468  cid:469  cid:468   cid:474 . cid:468  Creating decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:468    cid:474 . cid:469  How methods work in P⁴thon . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:475    cid:474 . cid:470  Static methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:468    cid:474 . cid:471  Class method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:469    cid:474 . cid:472  Abstract methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:470    cid:474 . cid:473  Mixing static, class, and abstract methods . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:472    cid:474 . cid:474  The truth about super . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:475    cid:475  Functional programming   cid:468  cid:471  cid:470   cid:475 . cid:468  Generators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:471  cid:471    cid:475 . cid:469    cid:475 . cid:470   List comprehensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:472  cid:467   Functional functions functioning . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:472  cid:468    cid:476  The AST   cid:468  cid:473  cid:468   cid:476 . cid:468  H⁴ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:473  cid:472    cid:476 . cid:469   Interview with Paul Tagliamonte . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:473  cid:474    cid:468  cid:467  Performances and optimizations   cid:468  cid:474  cid:470   cid:468  cid:467 . cid:468  Data structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:474  cid:470    cid:468  cid:467 . cid:469  Profiling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:474  cid:472    cid:468  cid:467 . cid:470  Ordered list and bisect . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:469    CONTENTS  iv   cid:468  cid:467 . cid:471  Namedtuple and slots . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:471    cid:468  cid:467 . cid:472  Memoi⁵ation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:476  cid:468    cid:468  cid:467 . cid:473  P⁴P⁴ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:476  cid:470    cid:468  cid:467 . cid:474  Achieving ⁵ero cop⁴ with the buﬀer protocol  . . . . . . . . . . . . . . .  cid:468  cid:476  cid:472    cid:468  cid:467 . cid:475  Interview with Victor Stinner  . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:469    cid:468  cid:468  Scaling and architecture   cid:469  cid:467  cid:472   cid:468  cid:468 . cid:468  A note on multi-threading . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:472    cid:468  cid:468 . cid:469  Multiprocessing vs multithreading . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:475    cid:468  cid:468 . cid:470  As⁴nchronous and event-driven architecture . . . . . . . . . . . . . . .  cid:469  cid:468  cid:467    cid:468  cid:468 . cid:471  Service-oriented architecture . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:468  cid:472    cid:468  cid:469  RDBMS and ORM   cid:469  cid:468  cid:476   cid:468  cid:469 . cid:468  Streaming data with Flask and PostgreSQL . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:470    cid:468  cid:469 . cid:469  Interview with Dimitri Fontaine . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:470  cid:467    cid:468  cid:470  Python  cid:470  support strategies   cid:469  cid:471  cid:468   cid:468  cid:470 . cid:468  Language and standard librar⁴ . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:471  cid:470    cid:468  cid:470 . cid:469  External libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:471  cid:473    cid:468  cid:470 . cid:470  Using six . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:471  cid:474    cid:468  cid:471  Write less, code more   cid:469  cid:472  cid:468   cid:468  cid:471 . cid:468  Single dispatcher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:472  cid:468    cid:468  cid:471 . cid:469  Context managers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:472  cid:474    List of Figures   cid:468 . cid:468  Standard package director⁴ . . . . . . . . . . . . . . . . . . . . . . . . . .   cid:470    cid:473 . cid:468  Coverage of ceilometer.publisher . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:467    cid:468  cid:467 . cid:468  KCacheGrind example . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:474  cid:474    cid:468  cid:467 . cid:469  Using slice on memoryview objects . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:476  cid:475    cid:468  cid:470 . cid:468  P⁴thon  cid:469  base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:471  cid:471    cid:468  cid:470 . cid:469  P⁴thon  cid:470  base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:471  cid:472    List of Examples   cid:475   cid:468 . cid:468  A pep cid:475  run . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468 . cid:469  Running pep cid:475  with --ignore . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476   cid:469 . cid:468  Hy module importer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470   cid:469 . cid:469  A documented API change . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:470  cid:469   cid:469 . cid:470  A documented API change with warning . . . . . . . . . . . . . . . . . .  cid:470  cid:470   cid:469 . cid:471  Running python -W error . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:470  cid:471   cid:470 . cid:468  Code from sphinxcontrib.pecanwsme.rest.setup . . . . . . . . . . .  cid:471  cid:475   cid:471 . cid:468  setup.py using distutils . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:467   cid:471 . cid:469  setup.py using setuptools . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:468   cid:471 . cid:470  Using setup.py sdist . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:472  cid:476   cid:471 . cid:471  Result of epi group list . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:473  cid:474   cid:471 . cid:472  Result of epi group show console_scripts . . . . . . . . . . . . . . . . . .  cid:473  cid:474   cid:471 . cid:473  Result of epi ep show console_scripts coverage . . . . . . . . . . . . . .  cid:473  cid:475   cid:471 . cid:474  A console script generated b⁴ setuptools . . . . . . . . . . . . . . . . . .  cid:474  cid:467   cid:471 . cid:475  Running p⁴timed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:474  cid:470   cid:472 . cid:468  Automatic virtual environment creation . . . . . . . . . . . . . . . . . .  cid:474  cid:474   cid:472 . cid:469  Boostraping a venv environment . . . . . . . . . . . . . . . . . . . . . . .  cid:474  cid:475   cid:473 . cid:468  A reall⁴ simple test in test_true.py . . . . . . . . . . . . . . . . . . . . .  cid:475  cid:470   cid:473 . cid:469  Failing a test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:475  cid:475   cid:473 . cid:470  Skipping tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:475  cid:475    LIST OF EXAMPLES  vii   cid:473 . cid:471  Using setUp with unittest . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:467   cid:473 . cid:472  Using fixtures.EnvironmentVariable . . . . . . . . . . . . . . . . . . .  cid:476  cid:469   cid:473 . cid:473  Basic mock usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:470   cid:473 . cid:474  Checking method calls . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:471   cid:473 . cid:475  Using mock.patch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:472   cid:473 . cid:476  Using mock.patch to test a set of behaviour . . . . . . . . . . . . . . . .  cid:476  cid:472   cid:473 . cid:468  cid:467  testscenarios basic usage . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:476  cid:476   cid:473 . cid:468  cid:468  Using testscenarios to test drivers . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:468   cid:473 . cid:468  cid:469  Using subunit2pyunit . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:469   cid:473 . cid:468  cid:470  A .testr.conf file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:472   cid:473 . cid:468  cid:471  Running testr run --parallel . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:473   cid:473 . cid:468  cid:472  Using nosetests --with-coverage . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:467  cid:475   cid:473 . cid:468  cid:473  Using coverage with testrepository . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:468   cid:473 . cid:468  cid:474  A .travis.yml example file . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:468  cid:474   cid:474 . cid:468  A registering decorator . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:469   cid:474 . cid:469  Source code of functools.update_wrapper in P⁴thon  cid:470 . cid:470  . . . . . . .  cid:468  cid:469  cid:472   cid:474 . cid:470  Using functools.wraps . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:473   cid:474 . cid:471  Retrieving function arguments using inspect . . . . . . . . . . . . . . .  cid:468  cid:469  cid:474   cid:474 . cid:472  A P⁴thon  cid:469  method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:475   cid:474 . cid:473  A P⁴thon  cid:470  method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:475   cid:474 . cid:474  Calling unbound get_si⁵e in P⁴thon  cid:469  . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:476   cid:474 . cid:475  Calling unbound get_si⁵e in P⁴thon  cid:470  . . . . . . . . . . . . . . . . . . . .  cid:468  cid:469  cid:476   cid:474 . cid:476  Calling bound get_size . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:467   cid:474 . cid:468  cid:467  @staticmethod usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:468   cid:474 . cid:468  cid:468  Implementing an abstract method . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:471   cid:474 . cid:468  cid:469  Implementing an abstract method using abc . . . . . . . . . . . . . . .  cid:468  cid:470  cid:471   cid:474 . cid:468  cid:470  Mixing @classmethod and @abstractmethod . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:473   cid:474 . cid:468  cid:471  Using super   with abstract methods . . . . . . . . . . . . . . . . . . . .  cid:468  cid:470  cid:474    LIST OF EXAMPLES  viii  yield returning a value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:471  cid:475   cid:475 . cid:468  filter usage in P⁴thon  cid:470  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:472  cid:469   cid:475 . cid:469   cid:475 . cid:470  Using first . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:472  cid:473   cid:475 . cid:471  Using the operator module with itertools.groupby . . . . . . . . . .  cid:468  cid:473  cid:467   cid:476 . cid:468  Parsing P⁴thon code to AST . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:473  cid:468   cid:476 . cid:469  Hello world using P⁴thon AST . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:473  cid:470   cid:476 . cid:470  Changing all binar⁴ operation to addition . . . . . . . . . . . . . . . . .  cid:468  cid:473  cid:471   cid:468  cid:467 . cid:468  Using the cProfile module . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:474  cid:472   cid:468  cid:467 . cid:469  Using KCacheGrind to visuali⁵e P⁴thon profiling data . . . . . . . . . .  cid:468  cid:474  cid:473   cid:468  cid:467 . cid:470  A function defined in a function, disassembled . . . . . . . . . . . . . .  cid:468  cid:475  cid:467   cid:468  cid:467 . cid:471  Disassembling a closure . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:468   cid:468  cid:467 . cid:472  Usage of bisect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:469   cid:468  cid:467 . cid:473  Usage of bisect.insort . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:470   cid:468  cid:467 . cid:474  A SortedList implementation . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:470   cid:468  cid:467 . cid:475  A class declaration using __slots__ . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:475   cid:468  cid:467 . cid:476  Memor⁴ usage of objects using __slots__ . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:475   cid:468  cid:467 . cid:468  cid:467 Declaring a class using namedtuple . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:475  cid:476   cid:468  cid:467 . cid:468  cid:468 Memor⁴ usage of a class built from collections.namedtuple . . . . .  cid:468  cid:476  cid:467   cid:468  cid:467 . cid:468  cid:469 A basic memoi⁵ation technique . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:476  cid:468   cid:468  cid:467 . cid:468  cid:470 Using functools.lru_cache . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:468  cid:476  cid:469   cid:468  cid:468 . cid:468  Result of time python worker.py . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:476   cid:468  cid:468 . cid:469  Worker using multiprocessing . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:476   cid:468  cid:468 . cid:470  Result of time python worker.py . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:467  cid:476   cid:468  cid:468 . cid:471  Basic example of using select . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:468  cid:468   cid:468  cid:468 . cid:472  Example with pyev . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:468  cid:471   cid:468  cid:469 . cid:468  Creating the message table . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:470   cid:468  cid:469 . cid:469  The notify_on_insert function . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:471   cid:468  cid:469 . cid:470  The trigger for notify_on_insert . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:472    LIST OF EXAMPLES  ix   cid:468  cid:469 . cid:471  Receiving notifications in P⁴thon . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:472   cid:468  cid:469 . cid:472  Flask streamer application . . . . . . . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:469  cid:474   cid:468  cid:471 . cid:468  Simple implementation of a context object . . . . . . . . . . . . . . . .  cid:469  cid:472  cid:474   cid:468  cid:471 . cid:469  Simplest usage of contextlib.contextmanager . . . . . . . . . . . . .  cid:469  cid:472  cid:475   cid:468  cid:471 . cid:470  Using a context manager on a pipeline object . . . . . . . . . . . . . . .  cid:469  cid:472  cid:476   cid:468  cid:471 . cid:471  Opening two files at the same time . . . . . . . . . . . . . . . . . . . . .  cid:469  cid:473  cid:467   cid:468  cid:471 . cid:472  Opening two files at the same time with one with statement . . . . .  cid:469  cid:473  cid:467    About this book  Version  cid:468 . cid:467  released in March  cid:469  cid:467  cid:468  cid:471 . If ⁴ou’re reading this, odds are good ⁴ou’ve been working with P⁴thon for some time alread⁴. Ma⁴be ⁴ou learned it using some tutorials, delved into some existing programs, or started from scratch, but whatever the case, ⁴ou’ve hacked ⁴our wa⁴ into learning it. That’s exactl⁴ how I got familiar with P⁴thon up until I joined the OpenStack team over two ⁴ears ago. Before then, I was building m⁴ own P⁴thon libraries and applications on a "garage project" scale, but things change once ⁴ou start working with hundreds of devel- opers on sotware and libraries that thousands of users rel⁴ on. The OpenStack platform represents over half a million lines of P⁴thon code, all of which needs to be concise, eﬀicient, and scalable to needs of whatever cloud computing applica- tion its users require. And when ⁴ou have a project this si⁵e, things like testing and documentation absolutel⁴ require automation, or else the⁴ won’t get done at all. I thought I knew a lot about P⁴thon when I first joined OpenStack, but I’ve learned a lot more these past two ⁴ears working on projects the scale of which I could barel⁴ even imagine when I got started. I’ve also had the opportunit⁴ to meet some of the best P⁴thon hackers in the industr⁴ and learn from them – ever⁴thing from general architecture and design principles to various helpful tips and tricks. Through this book, I hope to share the most important things I’ve learned so that ⁴ou can build better P⁴thon programs – and build them more eﬀicientl⁴, too!    cid:468  Starting your project  1.1 Python versions  One of the first questions ⁴ou’re likel⁴ to ask is "which versions of P⁴thon should m⁴ sotware support?". It’s well worth asking, since each new version of P⁴thon introduces new features and deprecates old ones. Furthermore, there’s a huge gap between P⁴thon  cid:469 .x and P⁴thon  cid:470 .x: there are enough changes between the two branches of the language that it can be hard to keep code compatible with both, as we’ll see in more detail later, and it can be hard to tell which version is more appropriate when ⁴ou’re starting a new project. Here are some short answers:    Versions  cid:469 . cid:472  and older are prett⁴ much obsolete b⁴ now, so ⁴ou don’t have to worr⁴ about supporting them at all. If ⁴ou’re intent on supporting these older ver- sions an⁴wa⁴, be warned that ⁴ou’ll have an even harder time ensuring that ⁴our program supports P⁴thon  cid:470 .x as well. Though ⁴ou might still run into P⁴thon  cid:469 . cid:472  on some older s⁴stems; if that’s the case for ⁴ou, sorr⁴!    Version  cid:469 . cid:473  is still viable; ⁴ou’ll find it in some older versions of operating s⁴stems such as Red Hat Enterprise Linux. It’s not hard to support P⁴thon  cid:469 . cid:473  as well as newer versions, but if ⁴ou don’t think ⁴our program will need to run on  cid:469 . cid:473 , don’t stress ⁴ourself tr⁴ing to accommodate it.    Version  cid:469 . cid:474  is and will remain the last version of P⁴thon  cid:469 .x. It’s a good idea to    cid:468 . cid:469 . PROJECT LAYOUT   cid:469   make it ⁴our main target, or one of ⁴our main targets, since a lot of sotware, li- braries, and developers still make use of it. P⁴thon  cid:469 . cid:474  should continue to be sup- ported until around  cid:469  cid:467  cid:468  cid:473 , so odds are it’s not going awa⁴ an⁴time soon.    Version  cid:470 . cid:467 ,  cid:470 . cid:468 , and  cid:470 . cid:469  were released in quick succession and as such haven’t seen much adoption. If ⁴our code alread⁴ supports  cid:469 . cid:474 , there’s not much point in supporting these versions as well.    Version  cid:470 . cid:470  and  cid:470 . cid:471  are the most recent distributed editions of P⁴thon  cid:470  and the ones ⁴ou should focus on supporting. P⁴thon  cid:470 . cid:470  and  cid:470 . cid:471  represent the future of the language, so unless ⁴ou’re focusing on compatibilit⁴ with older versions, ⁴ou should make sure ⁴our code runs on these versions as well.  In summar⁴: support  cid:469 . cid:473  onl⁴ if ⁴ou have to  or are looking for a challenge , def- initel⁴ support  cid:469 . cid:474 , and if ⁴ou want to guarantee that ⁴our sotware will continue to run for the foreseeable future, support  cid:470 . cid:470  and above as well. You can safel⁴ ig- nore other versions, though that’s not to sa⁴ it’s impossible to support them all: the Cherr⁴P⁴ project supports all versions of P⁴thon from  cid:469 . cid:470  onward.  Techniques for writing programs that support both P⁴thon  cid:469 . cid:474  and  cid:470 . cid:470  will be dis- cussed in Chapter  cid:468  cid:470 . You might spot some of these techniques in the sample code as ⁴ou read: all of the code that ⁴ou’ll see in this book has been written to support both major versions.  1.2 Project layout  Your project structure should be fairl⁴ simple. Use packages and hierarch⁴ wisel⁴: a deep hierarch⁴ can be a nightmare to navigate, while a flat hierarch⁴ tends to become bloated.  One common mistake is leaving unit tests outside the package director⁴. These tests should definitel⁴ be included in a sub-package of ⁴our sotware so that:    cid:468 . cid:469 . PROJECT LAYOUT   cid:470     the⁴ don’t get automaticall⁴ installed as a tests top-level module b⁴ setuptools   or some other packaging librar⁴ .    the⁴ can be installed and eventuall⁴ used b⁴ other packages to build their own  unit tests.  The following diagram illustrates what a standard file hierarch⁴ should look like:  Figure  cid:468 . cid:468 : Standard package director⁴  setup.py is the standard name for P⁴thon installation script. When run, it installs ⁴our package using the P⁴thon distribution utilities  distutils . You can also pro-    cid:468 . cid:469 . PROJECT LAYOUT   cid:471   vide important information to users in README.rst  or README.txt, or whatever file- name suits ⁴our fanc⁴ . requirements.txt should list ⁴our P⁴thon package’s de- pendencies – i.e., all of the packages that a tool such as pip should install to make ⁴our package work. You can also include test-requirements.txt, which lists onl⁴ the dependencies required to run the test suite. Finall⁴, the docs director⁴ should contain the package’s documentation in reStructuredText format, that will be con- sumed b⁴ Sphinx  see Section  cid:470 . cid:468  .  Packages oten have to provide extra data, such as images, shell scripts, and so forth. Unfortunatel⁴, there’s no universall⁴ accepted standard for where these files should be stored. Just put them wherever makes the most sense for ⁴our project.  The following top-level directories also frequentl⁴ appear:  Most of the time, the following extra top level directories are used:    etc is for sample configuration files.    tools is for shell scripts or related tools.    bin is for binar⁴ scripts ⁴ou’ve written that will be installed b⁴ setup.py.    data is for other kinds of data, such as media files.  A design issue I oten encountered is to create files or modules based on the t⁴pe of code the⁴ will store. Having a functions.py or exceptions.py file is a terrible approach. It doesn’t help an⁴thing at all with code organi⁵ation and forces a reader to jump between files for no good reason. Organi⁵e ⁴our code based on features, not t⁴pe.  Also, don’t create a director⁴ and just an __init__.py file in it, e.g. don’t create hooks __init__.py where hooks.py would have been enough. If ⁴ou create a di- rector⁴, it should contains several other P⁴thon files that belongs to the categor⁴ - module the director⁴ represents.    cid:468 . cid:470 . VERSION NUMBERING   cid:472   1.3 Version numbering  As ⁴ou might alread⁴ know, there’s an ongoing eﬀort to standardi⁵e package meta- data in the P⁴thon ecos⁴stem. One such piece of metadata is version number.  PEP  cid:471  cid:471  cid:467  introduces a version format that ever⁴ P⁴thon package, and ideall⁴ ever⁴ application, should follow. This wa⁴, other programs and packages will be able to easil⁴ and reliabl⁴ identif⁴ which versions of ⁴our package the⁴ require.  PEP  cid:471  cid:471  cid:467  defines the following regular expression format for version numbering: N[.N]+[{abcrc}N][.postN][.devN]  This allows for standard numbering like  cid:468 . cid:469  or  cid:468 . cid:469 . cid:470 . But note:     cid:468 . cid:469  is equivalent to  cid:468 . cid:469 . cid:467 ;  cid:468 . cid:470 . cid:471  is equivalent to  cid:468 . cid:470 . cid:471 . cid:467 , and so forth.    Versions matching N[.N]+ are considered final releases.    Date-based versions such as  cid:469  cid:467  cid:468  cid:470 . cid:467  cid:473 . cid:469  cid:469  are considered invalid. Automated tools designed to detect PEP  cid:471  cid:471  cid:467 -format version numbers will  or should  raise an error if the⁴ detect a version number greater than or equal to  cid:468  cid:476  cid:475  cid:467 .  Final components can also use the following format:    N[.N]+aN  e.g.  cid:468 . cid:469 a cid:468   denotes an alpha release, a version that might be unstable  and missing features.  complete but still bugg⁴.    N[.N]+bN  e.g.  cid:469 . cid:470 . cid:468 b cid:469   denotes a beta release, a version that might be feature-    N[.N]+cN or N[.N]+rcN  e.g.  cid:467 . cid:471 rc cid:468   denotes a  release  candidate, a version that might be released as the final product unless significant bugs emerge. While the rc and c suﬀixes have the same meaning, if both are used, rc releases are considered to be newer than c releases.    cid:468 . cid:470 . VERSION NUMBERING  These suﬀixes can also be used:   cid:473     .postN  e.g.  cid:468 . cid:471 .post cid:469   indicates a post release. These are t⁴picall⁴ used to ad- dress minor errors in the publication process  e.g. mistakes in release notes . You shouldn’t use .postN when releasing a bugfix version; instead, ⁴ou should incre- ment the minor version number.    .devN  e.g.  cid:469 . cid:470 . cid:471 .dev cid:470   indicates a developmental release. This suﬀix is discour- aged because it is harder for humans to parse. It indicates a prerelease of the version that it qualifies: e.g.  cid:469 . cid:470 . cid:471 .dev cid:470  indicates the third developmental version of the  cid:469 . cid:470 . cid:471  release, prior to an⁴ alpha, beta, candidate or final release.  This scheme should be suﬀicient for most common use cases.  Note You might have heard of Semantic Versioning, which provides its own guidelines for ver-  sion numbering. This specification partially overlaps with PEP 440, but unfortunately,  they’re not entirely compatible. For example, Semantic Versioning’s recommendation for  prerelease versioning uses a scheme such as 1.0.0-alpha+001 that is not compliant with  PEP 440.  If ⁴ou need to handle more advanced version numbers, ⁴ou should note that PEP  cid:471  cid:469  cid:473  defines source label, a field that ⁴ou can use to carr⁴ an⁴ version string, and then build a version number consistent with PEP requirements.  Man⁴ DVCS ¹ platforms, such as Git and Mercurial, are able to generate version num- bers using an identif⁴ing hash ². Unfortunatel⁴, this s⁴stem isn’t compatible with the scheme defined b⁴ PEP  cid:471  cid:471  cid:467 : for one thing, identif⁴ing hashes aren’t orderable. However, it’s possible to use a source label field to hold such a version number and use it to build a PEP  cid:471  cid:471  cid:467 -compliant version number.  ¹Distributed Version Control S⁴stem ²For Git, refer to git-describe  cid:468  .    cid:468 . cid:471 . CODING STYLE & AUTOMATED CHECKS   cid:474   Tip pbr ᵃ, which will be discussed in Section 4.2, is able to automatically build version numbers based on the Git revision of a project.  ᵃPython Build Reasonableness  1.4 Coding style & automated checks  Yes, coding st⁴le is a touch⁴ subject, but we still need to talk about it.  P⁴thon has an ama⁵ing qualit⁴ ³ that few other languages have: it uses indentation to define blocks. At first glance, it seems to oﬀer a solution to the age-old ques- tion of "where should I put m⁴ curl⁴ braces?"; unfortunatel⁴, it introduces a new question in the process: "how should I indent?"  And so the P⁴thon communit⁴, in their vast wisdom, came up with the PEP  cid:475  ⁛ stan- dard for writing P⁴thon code. The list of guidelines boils down to:    Use  cid:471  spaces per indentation level.    Limit all lines to a maximum of  cid:474  cid:476  characters.    Separate top-level function and class definitions with two blank lines.    Encode files using ASCII or UTF- cid:475 .    One module import per import statement and per line, at the top of the file, ater comments and docstrings, grouped first b⁴ standard, then third-part⁴, and finall⁴ local librar⁴ imports.    No extraneous whitespaces between parentheses, brackets, or braces, or before  commas. ³Your mileage ma⁴ var⁴. ⁛PEP  cid:475  Style Guide for Python Code,  cid:472 th Jul⁴  cid:469  cid:467  cid:467  cid:468 , Guido van Rossum, Barr⁴ Warsaw, Nick Coghlan    cid:468 . cid:471 . CODING STYLE & AUTOMATED CHECKS   cid:475     Name classes in CamelCase; suﬀix exceptions with Error  if applicable ; name func- tions in lowercase with words separated_by_underscores; and use a leading un- derscore for _private attributes or methods.  These guidelines reall⁴ aren’t hard to follow, and furthermore, the⁴ make a lot of sense. Most P⁴thon programmers have no trouble sticking to them as the⁴ write code.  However, errare humanum est, and it’s still a pain to look through ⁴our code to make sure it fits the PEP  cid:475  guidelines. That’s what the pep cid:475  tool is there for: it can auto- maticall⁴ check an⁴ P⁴thon file ⁴ou send its wa⁴. Example  cid:468 . cid:468  A pep cid:475  run  $ pep8 hello.py hello.py:4:1: E302 expected 2 blank lines, found 1 $ echo $? 1  pep cid:475  indicates which lines and columns do not conform to PEP  cid:475  and reports each issue with a code. Violations of MUST statements in the specification are reported as errors  starting with E , while minor problems are reported as warnings  starting with W . The three-digit code following the letter indicates the exact kind of error or warning; ⁴ou can tell the general categor⁴ at a glance b⁴ looking at the hundreds digit. For example, errors starting with E cid:469  indicate issues with whitespace; errors starting with E cid:470  indicate issues with blank lines; and warnings starting with W cid:473  in- dicate deprecated features being used.  The communit⁴ still debates whether validating against PEP  cid:475  code that is not part of the standard librar⁴ is a good practice. I advise ⁴ou to consider it and run a PEP  cid:475  validation tool against ⁴our source code on a regular basis. An eas⁴ wa⁴ to do this is to integrate it into ⁴our test suite. While it ma⁴ seem a bit extreme, it’s a good wa⁴ to ensure that ⁴ou continue to respect the PEP  cid:475  guidelines in the long term.    cid:468 . cid:471 . CODING STYLE & AUTOMATED CHECKS   cid:476   We’ll discuss in Section  cid:473 . cid:474  how ⁴ou can integrate pep cid:475  with tox to automate these checks.  The OpenStack project has enforced PEP  cid:475  conformance through automatic checks since the beginning. While it sometimes frustrates newcomers, it ensures that the codebase – which has grown to over  cid:468 . cid:473  cid:474  million lines of code – alwa⁴s looks the same in ever⁴ part of the project. This is ver⁴ important for a project of an⁴ si⁵e where there are multiple developers with diﬀering opinions on whitespace order- ing.  It’s also possible to ignore certain kinds of errors and warnings b⁴ using the --ignore option: Example  cid:468 . cid:469  Running pep cid:475  with --ignore $ pep8 --ignore=E3 hello.py $ echo $? 0  This allows ⁴ou to eﬀectivel⁴ ignore parts of the PEP  cid:475  standard that ⁴ou don’t want to follow. If ⁴ou’re running pep cid:475  on a existing code base, it also allows ⁴ou to ignore certain kinds of problems so ⁴ou can focus on fixing issues one categor⁴ at a time.  Note If you write C code for Python  e.g. modules , the PEP 7 standard describes the coding  style that you should follow.  Other tools also exist that check for actual coding errors rather than st⁴le errors. Some notable examples include:    p⁴flakes, which supports plugins  and supports plugins    p⁴lint, which also checks PEP  cid:475  conformance, performs more checks b⁴ default,    cid:468 . cid:471 . CODING STYLE & AUTOMATED CHECKS   cid:468  cid:467   These tools all make use of static anal⁴sis – that is, the⁴ parse the code and anal⁴⁵e it rather than running it outright.  If ⁴ou choose to use pyflakes, note that it doesn’t check PEP  cid:475  conformance on its own – ⁴ou’ll still need to run pep cid:475  as well. To simplif⁴ things, a project called flake cid:475  combines pyflakes and pep cid:475  into a single command. It also adds some new features such as skipping checks on lines containing noqa and extensibilit⁴ via entr⁴ points.  In its quest for beautiful and unified code, the OpenStack project chose flake cid:475  for all of its code checks. However, as time passed, the hackers took advantage of flake cid:475 's extensibilit⁴ to test for even more potential issues with submitted code. The end result of all this is a flake cid:475  extension called hacking. It checks for errors such as odd usage of except, P⁴thon  cid:469   cid:470  portabilit⁴ issues, import st⁴le, dangerous string formatting, and possible locali⁵ation issues.  If ⁴ou’re starting a new project, I strongl⁴ recommend ⁴ou use one of these tools and rel⁴ on it for automatic checking of ⁴our code qualit⁴ and st⁴le. If ⁴ou alread⁴ have a codebase, a good approach is to run them with most of the warnings disabled and fix issues one categor⁴ at a time.  While none of these tools ma⁴ be a perfect fit for ⁴our project or ⁴our preferences, using flake cid:475  and hacking together is a good wa⁴ to improve the qualit⁴ of ⁴our code and make it more durable. If nothing else, it’s a good start toward that goal.  Tip Many text editors, including the famous GNU Emacs and vim, have plugins available  such  as Flymake  that can run tools such as pep8 or flake8 directly in your code buffer, inter-  actively highlighting any part of your code that isn’t PEP 8-compliant. This is a handy way  to fix most style errors as you write your code.    cid:469  Modules and libraries  2.1 The import system  In order to use modules and libraries, ⁴ou have to import them. The Zen of Python >>> import this The Zen of Python, by Tim Peters  Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch.    cid:469 . cid:468 . THE IMPORT SYSTEM   cid:468  cid:469   Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those!  The import s⁴stem is quite complex, but ⁴ou probabl⁴ alread⁴ know the basics. Here, I’ll show ⁴ou some of the internals of this subs⁴stem.  The sys module contains a lot of information about P⁴thon’s import s⁴stem. First of all, the list of modules currentl⁴ imported is available through the sys.modules variable. It’s a dictionar⁴ where the ke⁴ is the module name and the value is the module object. >>> sys.modules['os']    Some modules are built-in; these are listed in sys.builtin_module_names. Built- in modules can var⁴ depending on the compilation options passed to the P⁴thon build s⁴stem.  When importing modules, P⁴thon relies on a list of paths. This list is stored in the sys.path variable and tells P⁴thon where to look for modules to load. You can change this list in code, adding or removing paths as necessar⁴, or ⁴ou can modif⁴ the PYTHONPATH environment variable to add paths without writing P⁴thon code at all. The following approaches are almost equivalent ¹: >>> import sys >>> sys.path.append ' foo bar'   $ PYTHONPATH= foo bar python >>> import sys  ¹Almost because the path will not be placed at the same level in the list, though it ma⁴ not matter  depending on ⁴our use case.    cid:469 . cid:468 . THE IMPORT SYSTEM  >>> ' foo bar' in sys.path True   cid:468  cid:470   The order in sys.path is important, since the list will be iterated over to find the requested module. It is also possible to extend the import mechanism using custom importers. This is the technique that Hy ² uses to teach P⁴thon how to import files other than standard .py or .pyc files. The import hook mechanism, as it is called, is defined b⁴ PEP  cid:470  cid:467  cid:469  ³. It allows ⁴ou to extend the standard import mechanism and appl⁴ preprocessing to it. You can also add a custom module finder b⁴ appending a factor⁴ class to sys.path_hooks. The module finder object must have a find_module fullname, path=None  method that returns a loader object. The load object also must have a load_module fulln ame  responsible for loading the module from a source file. To illustrate, here’s how Hy uses a custom importer to import source files ending with .hy instead of .py: Example  cid:469 . cid:468  Hy module importer class MetaImporter object :  def find_on_path self, fullname :  fls = ["%s __init__.hy", "%s.hy"] dirpath = " ".join fullname.split "."    for pth in sys.path:  pth = os.path.abspath pth  for fp in fls:  composed_path = fp %  "%s %s" %  pth, dirpath   if os.path.exists composed_path :  ²Hy is a Lisp implementation on top of P⁴thon, discussed in Section  cid:476 . cid:468  ³New Import Hooks, implemented since P⁴thon  cid:469 . cid:470     cid:469 . cid:468 . THE IMPORT SYSTEM   cid:468  cid:471   return composed_path  def find_module self, fullname, path=None :  path = self.find_on_path fullname  if path:  return MetaLoader path   sys.meta_path.append MetaImporter     Hy module loader class MetaLoader object :  def __init__ self, path :  self.path = path  Once the path is determined to both be valid and point to a module, a MetaLoader object is returned:  def is_package self, fullname :  dirpath = " ".join fullname.split "."   for pth in sys.path:  pth = os.path.abspath pth  composed_path = "%s %s __init__.hy" %  pth, dirpath  if os.path.exists composed_path :  return True  return False  def load_module self, fullname : if fullname in sys.modules:  return sys.modules[fullname]  if not self.path:    cid:469 . cid:468 . THE IMPORT SYSTEM  return   cid:468  cid:472   sys.modules[fullname] = None mod = import_file_to_module fullname,  self.path  ②1  ispkg = self.is_package fullname   mod.__file__ = self.path mod.__loader__ = self mod.__name__ = fullname  if ispkg:  else:  mod.__path__ = [] mod.__package__ = fullname  sys.modules[fullname] = mod return mod  mod.__package__ = fullname.rpartition '.' [0]  ②1  import_file_to_module reads a Hy source file, compiles it to P⁴thon code, and returns a P⁴thon module object.  The uprefix module is another good example of this feature in action. P⁴thon  cid:470 . cid:467  through  cid:470 . cid:469  didn’t have the u prefix for denoting Unicode strings featured in P⁴thon  cid:469  ⁛; this module ensures compatibilit⁴ between  cid:469 .x and  cid:470 .x b⁴ removing the u prefix from strings before compilation.  ⁛It was added back in P⁴thon  cid:470 . cid:470 .    cid:469 . cid:469 . STANDARD LIBRARIES   cid:468  cid:473   2.2 Standard libraries  P⁴thon comes with a huge standard librar⁴ packed with tools and features for an⁴ purpose ⁴ou can think of. Newcomers to P⁴thon who are used to having to write their own functions for basic tasks are oten shocked to find that the language itself ships with such functionalit⁴ built in and read⁴ for use.  Whenever ⁴ou’re about to write ⁴our own function to handle a simple task, please stop and look through the standard librar⁴ first. M⁴ advice is to skim through the whole thing at least once so that next time ⁴ou need a function, ⁴ou’ll alread⁴ know whether what ⁴ou need alread⁴ exists in the standard librar⁴.  We’ll talk about some of these modules in later sections, such as functools and itertools, but here’s a few of the standard modules that ⁴ou should definitel⁴ know about:    atexit allows ⁴ou to register functions to call when ⁴our program exits.    argparse provides functions for parsing command line arguments.    bisect provides bisection algorithms for sorting lists  see Section  cid:468  cid:467 . cid:470  .    calendar provides a number of date-related functions.    codecs provides functions for encoding and decoding data.    collections provides a variet⁴ of useful data structures.    copy provides functions for cop⁴ing data.    csv provides functions for reading and writing CSV files.    datetime provides classes for handling dates and times.    fnmatch provides functions for matching Unix-st⁴le filename patterns.    cid:469 . cid:469 . STANDARD LIBRARIES   cid:468  cid:474     glob provides functions for matching Unix-st⁴le path patterns.    io provides functions for handling I O streams. In P⁴thon  cid:470 , it also contains Strin- gIO  which is in the module of the same name in P⁴thon  cid:469  , which allows ⁴ou to treat strings as files.    json provides functions for reading and writing data in JSON format.    logging provides access to P⁴thon’s own built-in logging functionalit⁴.    multiprocessing allows ⁴ou to run multiple subprocesses from ⁴our application,  while providing an API that makes them look like threads.    operator provides functions implementing the basic P⁴thon operators which ⁴ou can use instead of having to write ⁴our own lambda expressions  see Section  cid:475 . cid:470  .    os provides access to basic OS functions.    random provides functions for generating pseudo-random numbers.    re provides regular expression functionalit⁴.    select provides access to the select   and poll   functions for creating event loops.    shutil provides access to high-level file functions.    signal provides functions for handling POSIX signals.    tempfile provides functions for creating temporar⁴ files and directories.    threading provides access to high-level threading functionalit⁴.    urllib  and urllib cid:469  and urlparse in P⁴thon  cid:469 .x  provides functions for handling  and parsing URLs.    uuid allows ⁴ou to generate UUIDs  Universall⁴ Unique Identifiers .    cid:469 . cid:470 . EXTERNAL LIBRARIES   cid:468  cid:475   Use this list as a quick reference to help ⁴ou keep track of which librar⁴ modules do what. If ⁴ou can memori⁵e even part of it, all the better. The less time ⁴ou have to spend looking up librar⁴ modules, the more time ⁴ou can spend writing the code ⁴ou actuall⁴ need.  Tip The entire standard library is written in Python, so there’s nothing stopping you from look-  ing at the source code of its modules and functions. When in doubt, crack open the code  and see what it does for yourself. Even if the documentation has everything you need to  know, there’s always a chance you could learn something useful.  2.3 External libraries  Have ⁴ou ever unwrapped an awesome birthda⁴ git or Christmas present onl⁴ to find out that whoever gave it to ⁴ou forgot to bu⁴ batteries for it? P⁴thon’s "bat- teries included" philosoph⁴ is all about keeping that from happening to ⁴ou as a programmer: the idea is that, once ⁴ou have P⁴thon installed, ⁴ou have ever⁴thing ⁴ou need to make an⁴thing ⁴ou want.  Unfortunatel⁴, there’s no wa⁴ the people behind P⁴thon can predict everything ⁴ou might want to make. And even if the⁴ could, most people won’t want to deal with a multi-gigab⁴te download when all the⁴ want to do is write a quick script for re- naming files. The bottom line is, even with all its extensive functionalit⁴, there are some things the P⁴thon Standard Librar⁴ just doesn’t cover. But that doesn’t mean that there are things ⁴ou simpl⁴ can’t do with P⁴thon – it just means that there are things ⁴ou’ll have to do using external libraries.  The P⁴thon Standard Librar⁴ is safe, well-charted territor⁴: its modules are heavil⁴ documented, and enough people use it on a regular basis that ⁴ou can be sure it won’t break messil⁴ when ⁴ou tr⁴ to use it – and in the unlikel⁴ event that it does,    cid:469 . cid:470 . EXTERNAL LIBRARIES   cid:468  cid:476   ⁴ou can be sure someone will fix it in short order. External libraries, on the other hand, are the parts of the map labeled "here there be dragons": documentation ma⁴ be sparse, functionalit⁴ ma⁴ be bugg⁴, and updates ma⁴ be sporadic or even nonexistent. An⁴ serious project will likel⁴ need functionalit⁴ that onl⁴ external li- braries can provide, but ⁴ou need to be mindful of the risks involved in using them.  Here’s a tale from the trenches. OpenStack uses SQLAlchem⁴, a database toolkit for P⁴thon; if ⁴ou’re familiar with SQL, ⁴ou know that database schemas can change over time, so we also made use of sqlalchem⁴-migrate to handle our schema migra- tion needs. And it worked…until it didn’t. Bugs started piling up, and nothing was getting done about them. Furthermore, OpenStack was getting interested in sup- porting P⁴thon  cid:470  at the time, but there was no sign that sqlalchem⁴-migrate was going to support it as well. It was clear b⁴ that point that sqlalchem⁴-migrate was eﬀectivel⁴ dead and we needed to switch to something else. At the time of this writ- ing, OpenStack projects are migrating towards using Alembic instead; not without some eﬀort, but fortunatel⁴ without much pain.  All of this builds up to one important question: "how can I be sure I won’t fall into this same trap?". Unfortunatel⁴, ⁴ou can’t: programmers are people, too, and there’s no wa⁴ ⁴ou can know for sure whether a librar⁴ that’s ⁵ealousl⁴ maintained toda⁴ will still be like that in a few months. However, here at OpenStack, we use the fol- lowing checklist to help tip the odds in our favor  and I encourage ⁴ou to do the same! :    P⁴thon  cid:470  compatibilit⁴. Even if ⁴ou’re not targeting P⁴thon  cid:470  right now, odds are good that ⁴ou will somewhere down the line, so it’s a good idea to check that ⁴our chosen librar⁴ is alread⁴ P⁴thon  cid:470 -compatible and committed to sta⁴ing that wa⁴.    Active development. GitHub and Ohloh usuall⁴ provide enough information to  determine whether a given librar⁴ is still being worked on b⁴ its maintainers.    Active maintenance. Even if a librar⁴ is "finished"  i.e.  feature-complete , the    cid:469 . cid:470 . EXTERNAL LIBRARIES   cid:469  cid:467   maintainers should still be working on ensuring it remains bug-free. Check the project’s tracking s⁴stem to see how quickl⁴ the maintainers respond to bugs.    Packaged with OS distributions. If a librar⁴ is packaged with major Linux distri- butions, that means other projects are depending on it – so if something goes wrong, ⁴ou won’t be the onl⁴ one complaining. It’s also a good idea to check this if ⁴ou plan to release ⁴our sotware to the public: it’ll be easier to distribute if its dependencies are alread⁴ installed on the end user’s machine.    API compatibilit⁴ commitment. Nothing’s worse than having ⁴our sotware sud- denl⁴ break because a librar⁴ it depends on changed its entire API. You might want to check whether ⁴our chosen librar⁴ has had an⁴thing like this happen in the past.  Appl⁴ing this checklist to dependencies is also a good idea, though it might be a huge undertaking. If ⁴ou know ⁴our application is going to depend heavil⁴ on a particular librar⁴, ⁴ou should at least appl⁴ this checklist to each of that librar⁴’s dependencies.  No matter what libraries ⁴ou end up using, ⁴ou need to treat them like ⁴ou would an⁴ other tools: as useful devices that could potentiall⁴ do some serious damage. It won’t alwa⁴s be the case, but ask ⁴ourself: if ⁴ou had a hammer, would ⁴ou carr⁴ it through ⁴our entire house, possibl⁴ breaking ⁴our stuﬀ b⁴ accident as ⁴ou went along? Or would ⁴ou keep it in ⁴our tool shed or garage, awa⁴ from ⁴our fragile valuables and right where ⁴ou actuall⁴ need it?  It’s the same thing with external libraries: no matter how useful the⁴ are, ⁴ou need to be war⁴ of letting them get their hooks into ⁴our actual source code. Otherwise, if something goes wrong and ⁴ou need to switch libraries, ⁴ou might have to rewrite huge swaths of ⁴our program. A better idea is to write ⁴our own API – a wrapper that encapsulates ⁴our external libraries and keeps them out of ⁴our source code. Your program never has to know what external libraries it’s using; onl⁴ what functionalit⁴    cid:469 . cid:471 . FRAMEWORKS   cid:469  cid:468   ⁴our API provides. Need to use a diﬀerent librar⁴? All ⁴ou have to change is ⁴our wrapper: as long as it still provides the same functionalit⁴, ⁴ou won’t have to touch ⁴our codebase at all. There might be exceptions, but there shouldn’t be man⁴: most libraries are designed to solve a tightl⁴ focused range of problems and can therefore be easil⁴ isolated.  Later, in Section  cid:471 . cid:474 . cid:470 , we’ll also look at how ⁴ou can use entr⁴ points to build driver s⁴stems that will allow ⁴ou to treat parts of ⁴our projects as modules that can be switched out at will.  2.4 Frameworks  There are various P⁴thon frameworks available for various kinds of P⁴thon appli- cations: if ⁴ou’re writing a Web application, ⁴ou could use Django, P⁴lons, Turbo- Gears, Tornado, Zope, or Plone; if ⁴ou’re looking for an event-driven framework, ⁴ou could use Twisted or Circuits; and so on.  The main diﬀerence between frameworks and external libraries is that applications make use of frameworks b⁴ building on top of them: ⁴our code will extend the framework rather than vice versa. Unlike a librar⁴, which is basicall⁴ an add-on ⁴ou can bring in to give ⁴our code some extra oomph, a framework forms the chassis of ⁴our code: ever⁴thing ⁴ou do is going to build on that chassis in some wa⁴, which can be a double-edged sword. There are plent⁴ of upsides to using frameworks, such as rapid protot⁴ping and development, but there are also some noteworth⁴ downsides, such as lock-in. You need to take these considerations into account when ⁴ou decide whether to use a framework.  The recommended method for choosing a framework for a P⁴thon application is largel⁴ the same as the one described earlier for external libraries - which onl⁴ makes sense, as frameworks are distributed as bundles of P⁴thon libraries. Sometimes the⁴ also include tools for creating, running, and deplo⁴ing applications, but that    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:469   doesn’t change the criteria ⁴ou should appl⁴. We’ve alread⁴ established that re- placing an external librar⁴ ater ⁴ou’ve alread⁴ written code that makes use of it is a pain, but replacing a framework is a thousand times worse, usuall⁴ requiring a complete rewrite of ⁴our program from the ground up.  Just to give an example, the Twisted framework mentioned earlier still doesn’t have full P⁴thon  cid:470  support: if ⁴ou wrote a program using Twisted a few ⁴ears back and want to update it to run on P⁴thon  cid:470 , ⁴ou’re out of luck unless either ⁴ou rewrite ⁴our entire program to use a diﬀerent framework or someone finall⁴ gets around to upgrading it with full P⁴thon  cid:470  support.  Some frameworks are lighter than others. For one comparison, Django has its own built-in ORM functionalit⁴; Flask, on the other hand, has nothing of the sort. The less a framework tries to do for ⁴ou, the fewer problems ⁴ou’ll have with it in the fu- ture; however, each feature a framework lacks is another problem for ⁴our to solve, either b⁴ writing ⁴our own code or going through the hassle of hand-picking an- other librar⁴ to handle it. It’s ⁴our choice which scenario ⁴ou’d rather deal with, but choose wisel⁴: migrating awa⁴ from a framework when things go sour can be a Herculean task, and even with all its other features, there’s nothing in P⁴thon that can help ⁴ou with that.  2.5 Interview with Doug Hellmann  I’ve had the chance to work with Doug Hellmann these past few months. He’s a se- nior developer at DreamHost and a fellow contributor to the OpenStack project. He launched the website P⁴thon Module of the Week a while back, and he’s also writ- ten an excellent book called The Python Standard Library By Example. He is also a P⁴thon core developer. I’ve asked Doug a few questions about the Standard Librar⁴ and designing libraries and applications around it.    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:470   When you start writing a Python application from scratch, what’s your first move? Is it diﬀerent from hacking an existing application? The steps are similar in the abstract, but the details change. There tend to be more diﬀerences between m⁴ approach to working on applications and libraries than there are for new versus existing projects.  When I want to change existing code, especiall⁴ when it has been created b⁴ someone else, I start b⁴ digging in to figure out how it works and where m⁴ change would need to go. I ma⁴ add logging or print statements, or use pdb, and run the app with test data to make sure I understand what it is doing. I usuall⁴ make the change and test it b⁴ hand, then add an⁴ automated tests before contributing a patch.  I take the same explorator⁴ approach when I create a new application. I create some code and run it b⁴ hand, then write tests to make sure I’ve covered all of the edge cases ater I have the basic aspect of a feature working. Creating the tests ma⁴ also lead to some refactoring to make the code easier to work with.  That was definitel⁴ the case with smiley. I started b⁴ experimenting with P⁴thon’s trace API using some throw-awa⁴ scripts, before building the real application. M⁴ original vision for smile⁴ included one piece to instrument and collect data from another running application, and a second piece to collect the data sent over the network and save it. In the course of adding a couple of diﬀerent reporting features, I reali⁵ed that the processing for repla⁴ing the data that had been collected was almost identical to the    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:471   processing for collecting it in the first place. I refactored a few classes, and was able to create a base class for the data collection, database ac- cess, and report generator. Making those classes conform to the same API allowed me to easil⁴ create a version of the data collection app that wrote directl⁴ to the database instead of sending information over the network.  While designing an app, I think about how the user interface works, but for libraries, I focus on how a developer will use the API. Thinking about how to write programs with the new librar⁴ can be made easier b⁴ writing the tests first, instead of ater the librar⁴ code. I usuall⁴ create a series of example programs in the form of tests, and then build the librar⁴ to work that wa⁴.  I have also found that writing the documentation for a librar⁴ before writ- ing an⁴ code at all gives me a wa⁴ to think through the features and work- flows for using it without committing to the implementation details. It also lets me record the choices I made in the design so the reader under- stands not just how to use the librar⁴ but the expectations I had while creating it. That was the approach I took with stevedore.  I knew I wanted stevedore to provide a set of classes for managing plu- gins for applications. During the design phase, I spent some time think- ing about common patterns I had seen for consuming plugins and wrote a few pages of rough documentation describing how the classes would be used. I reali⁵ed that if I put most of the complex arguments into the class constructors, the map   methods could be almost interchangeable. Those design notes fed directl⁴ into the introduction for stevedore’s of- ficial documentation, explaining the various patterns and guidelines for using plugins in an application. What’s the process for getting a module into the Python Standard Li- brary?    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:472   The full process and guidelines can be found in the P⁴thon Developer’s Guide. Before a module can be added to the P⁴thon Standard Librar⁴, it needs to be proven to be stable and widel⁴ useful. The module should provide something that is either hard to implement correctl⁴ or so useful that man⁴ developers have created their own variations. The API should be clear and the implementation should not have dependencies on modules outside the Standard Librar⁴. The first step to proposing a new module is bringing it up within the com- munit⁴ via the python-ideas list to informall⁴ gauge the level of interest. Assuming the response is positive, the next step is to create a P⁴thon En- hancement Proposal  PEP , which includes the motivation for adding the module and some implementation details of how the transition will hap- pen. Because package management and discover⁴ tools have become so reli- able, especiall⁴ pip and the P⁴thon Package Index  P⁴PI , it ma⁴ be more practical to maintain a new librar⁴ outside of the P⁴thon Standard Librar⁴. A separate release allows for more frequent updates with new features and bugfixes, which can be especiall⁴ important for libraries addressing new technologies or APIs. What are the top three modules from the Standard Library that you wish people knew more about and would start using? I’ve been doing a lot of work with d⁴namicall⁴ loaded extensions for ap- plications recentl⁴. I use the abc module to define the APIs for those ex- tensions as abstract base classes to help extension authors understand which methods of the API are required and which are optional. Abstract base classes are built into some other OOP languages, but I’ve found a lot of P⁴thon programmers don’t know we have them as well.    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:473   The binar⁴ search algorithm in the bisect module is a good example of a feature that is widel⁴ useful and oten implemented incorrectl⁴, which makes it a great fit for the Standard Librar⁴. I especiall⁴ like the fact that it can search sparse lists where the search value ma⁴ not be included in the data. There are some useful data structures in thecollections module that aren’t used as oten as the⁴ could be. I like to use namedtuple for creating small class-like data structures that just need to hold data but don’t have an⁴ associated logic. It’s ver⁴ eas⁴ to convert from a namedtuple to a regular class if logic does need to be added later, since namedtuple supports ac- cessing attributes b⁴ name. Another interesting data structure is Chain- Map, which makes a good stackable namespace. ChainMap can be used to create contexts for rendering templates or managing configuration set- tings from diﬀerent sources with clearl⁴ defined precedence. A lot of projects, including OpenStack, or external libraries, roll their own abstractions on top of the Standard Library. I’m particularly think- ing about things like date time handling, for example. What would be your advice on that? Should programmers stick to the Standard Library, roll their own functions, switch to some external library, or start sending patches to Python? All of the above! I prefer to avoid reinventing the wheel, so I advocate strongl⁴ for contributing fixes and enhancements upstream to projects that can be used as dependencies. On the other hand, sometimes it makes sense to create another abstraction and maintain that code separatel⁴, either within an application or as a new librar⁴. The example ⁴ou raise, the timeutils module in OpenStack, is a fairl⁴ thin wrapper around P⁴thon’s datetime module. Most of the functions are short and simple, but b⁴ creating a module with the most common oper-    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:474   ations, we can ensure the⁴ are handled consistentl⁴ throughout all Open- Stack projects. Because a lot of the functions are application-specific, in the sense that the⁴ enforce decisions about things like timestamp format strings or what "now" means, the⁴ are not good candidates for patches to P⁴thon’s librar⁴ or to be released as a general purpose librar⁴ and adopted b⁴ other projects. In contrast, I have been working to move the API services in OpenStack awa⁴ from the WSGI framework created in the earl⁴ da⁴s of the project and onto a third-part⁴ web development framework. There are a lot of op- tions for creating WSGI applications in P⁴thon, and while we ma⁴ need to enhance one to make it completel⁴ suitable for OpenStack’s API servers, contributing those reusable changes upstream is preferable to maintain- ing a "private" framework. Do you have any particular recommendations on what to do when im- porting and using a lot of modules, from the Standard Library or else- where? I don’t have a hard limit, but if I have more than a handful of imports, I reconsider the design of the module and think about splitting it up into a package. The split ma⁴ happen sooner for a lower level module than for a high-level or application module, since at a higher level I expect to be joining more pieces together. Regarding Python  cid:470 , what are the modules that are worth mentioning and might make developers more interested in looking into it? The number of third-part⁴ libraries supporting P⁴thon  cid:470  has reached crit- ical mass. It’s easier than ever to build new libraries and applications for P⁴thon  cid:470 , and maintaining support for P⁴thon  cid:469 . cid:474  is also easier thanks to the compatibilit⁴ features added to  cid:470 . cid:470 . The major Linux distributions are working on shipping releases with P⁴thon  cid:470  installed b⁴ default. An⁴one    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:475   starting a new project in P⁴thon should look seriousl⁴ at P⁴thon  cid:470  unless the⁴ have a dependenc⁴ that hasn’t been ported. At this point, though, li- braries that don’t run on P⁴thon  cid:470  could almost be classified as "unmain- tained." Many developers write all their code into an application, but there are cases where it would be worth the eﬀort to branch their code out into a Python library. In term of design, planning ahead, migration, etc., what are the best ways to do this? Applications are collections of "glue code" holding libraries together for a specific purpose. Designing based on implementing those features as a librar⁴ first and then building the application ensures that code is prop- erl⁴ organi⁵ed into logical units, which in turn makes testing simpler. It also means the features of an application are accessible through the li- brar⁴ and can be remixed to create other applications. Failing to take this approach means the features of the application are tightl⁴ bound to the user interface, which makes them harder to modif⁴ and reuse. What advice would you give to people planning to start their own Python libraries? I alwa⁴s recommend designing libraries and APIs from the top down, ap- pl⁴ing design criteria such as the Single Responsibilit⁴ Principle  SRP  at each la⁴er. Think about what the caller will want to do with the librar⁴, and create an API that supports those features. Think about what values can be stored in an instance and used b⁴ the methods versus what needs to be passed to each method ever⁴ time. Finall⁴, think about the imple- mentation and whether the underl⁴ing code should be organi⁵ed diﬀer- entl⁴ from the public API. SQLAlchemy is an excellent example of appl⁴ing those guidelines. The declarative ORM, data mapping, and expression generation la⁴ers are all    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:469  cid:476   separate. A developer can decide the right level of abstraction for entering the API and using the librar⁴ based on their needs rather than constraints imposed b⁴ the librar⁴’s design. What are the most common programming errors that you encounter while reading random Python developers' code? A big area where P⁴thon’s idioms are diﬀerent from other languages is looping and iteration. For example, one of the most common anti-patterns I see is using a for loop to filter one list b⁴ appending items to a new list and then processing the result in a second loop  possibl⁴ ater passing the list as an argument to a function . I almost alwa⁴s suggest converting fil- tering loops like that to generator expressions because the⁴ are more ef- ficient and easier to understand. It’s also common to see lists being com- bined so their contents can be processed together in some wa⁴, rather than using itertools.chain  . There are also some more subtle things I suggest in code reviews, like us- ing a dict   as a lookup table instead of a long if:then:else block; mak- ing sure functions alwa⁴s return the same t⁴pe of object  e.g., an empt⁴ list instead of None ; reducing the number of arguments to a function b⁴ combining related values into an object with either a tuple or a new class; and defining classes to use in public APIs instead of rel⁴ing on dictionar- ies. Do you have a concrete example, something you’ve either done or wit- nessed, of picking up a "wrong" dependency? Recentl⁴, I had a case in which a new release of pyparsing dropped P⁴thon  cid:469  support and caused me a little trouble with a librar⁴ I maintain. The up- date to p⁴parsing was a major revision, and was clearl⁴ labeled as such, but because I had not constrained the version of the dependenc⁴ in the settings for cliﬀ, the new release of p⁴parsing caused issues for some of    cid:469 . cid:472 . INTERVIEW WITH DOUG HELLMANN   cid:470  cid:467   cliﬀ's consumers. The solution was to provide diﬀerent version bounds for P⁴thon  cid:469  and P⁴thon  cid:470  in the dependenc⁴ list for cliﬀ. This situation highlighted the importance of both understanding dependenc⁴ manage- ment and ensuring proper test configurations for continuous integration testing. What’s your take on frameworks? Frameworks are like an⁴ other kind of tool. The⁴ can help, but ⁴ou need to take care when choosing one to make sure that it’s right for the job at hand.  B⁴ pulling out the common parts into a framework, ⁴ou can focus ⁴our development eﬀorts on the unique aspects of an application. The⁴ also help ⁴ou bring an application to a useful state more quickl⁴ than if ⁴ou started from scratch b⁴ providing a lot of bootstrapping code for doing things like running in development mode and writing a test suite. The⁴ also encourage ⁴ou to be consistent in the wa⁴ ⁴ou implement the appli- cation, which means ⁴ou end up with code that is easier to understand and more reusable.  There are some potential pitfalls to watch out for when working with frame- works, though. The decision to use a particular framework usuall⁴ im- plies something about the design of the application itself. Selecting the wrong framework can make an application harder to implement if those design constraints do not align naturall⁴ with the application’s require- ments. You ma⁴ end up fighting with the framework if ⁴ou tr⁴ to use dif- ferent patterns or idioms than it recommends.    cid:469 . cid:473 . MANAGING API CHANGES   cid:470  cid:468   2.6 Managing API changes  When building an API, it’s rare to get ever⁴thing right the first tr⁴. Your API will have to evolve, adding, removing, or changing the features it provides.  In the following paragraphs, we will discuss how to manage public API changes. Public APIs are the APIs that ⁴ou expose to users of ⁴our librar⁴ or application; in- ternal APIs are another concern, and since the⁴’re internal  i.e. ⁴our users will never have to deal with them , ⁴ou can do whatever ⁴ou want with them: break them, twist them, or generall⁴ abuse them as ⁴ou see fit.  The two t⁴pes of API can be easil⁴ distinguished from each other. The P⁴thon con- vention is to prefix private API s⁴mbols with an underscore: foo is public, but _bar is private.  When building an API, the worst thing ⁴ou can do is to break it abruptl⁴. Linus Tor- valds is  among other things  famous for having a ⁵ero tolerance polic⁴ on public API breakage for the Linux kernel. Considering how man⁴ people rel⁴ on Linux, it’s safe to sa⁴ he made a wise choice.  Unix platforms have a complex management s⁴stem for libraries, rel⁴ing on son- ame[http:  en.wikipedia.org wiki Soname] and fine-grained version identifiers. P⁴thon doesn’t provide such a s⁴stem, nor an equivalent convention. It’s up to maintain- ers to pick the right version numbers and policies. However, ⁴ou can still take the Unix s⁴stem as inspiration for how to version ⁴our own libraries or applications. Generall⁴, ⁴our version numbering should reflect changes in the API that will im- pact users; most developers use major version increments to denote such changes, but depending on how ⁴ou number ⁴our versions, ⁴ou can also use minor version increments as well.  Whatever else ⁴ou decide to do, the first thing and most important step when mod- if⁴ing an API is to heavil⁴ document the change. This includes:    cid:469 . cid:473 . MANAGING API CHANGES    documenting the new interface    documenting that the old interface is deprecated    documenting how to migrate to the new interface   cid:470  cid:469   You shouldn’t remove the old interface right awa⁴; in fact, ⁴ou should tr⁴ to keep the old interface for as long as possible. New users won’t use it since it’s explicitl⁴ marked as deprecated. You should onl⁴ remove the old interface when it’s too much trouble to keep. Example  cid:469 . cid:469  A documented API change  Use :func:`turn` instead with the direction argument set to left  class Car object :  def turn_left self :  """Turn the car left.  .. deprecated:: 1.1  """ self.turn direction='left'   def turn self, direction :  """Turn the car in some direction.  :param direction: The direction to turn to. :type direction: str """  Write actual code here instead pass  It’s a good idea to use Sphinx markup to highlight changes. When building the doc- umentation, it will be clear to users that the function should not be used, and direct    cid:469 . cid:473 . MANAGING API CHANGES   cid:470  cid:470   access to the new function will be provided along with an explanation of how to mi- grate old code. The downside of this approach is that ⁴ou can’t rel⁴ on developers to read ⁴our changelog or documentation when the⁴ upgrade to a newer version of ⁴our P⁴thon package.  P⁴thon provides an interesting module called warnings that can help in this regard. This module allows ⁴our code to issue various kinds of warnings, such as Pending DeprecationWarning and DeprecationWarning. These warnings can be used to in- form the developer that a function the⁴’re calling is either deprecated or going to be deprecated. This wa⁴, developers will be able to see that the⁴’re using an old interface and should do something about it. ⁜  To go back to the previous example, we can make use of this and warn the user: Example  cid:469 . cid:470  A documented API change with warning  import warnings  class Car object :  def turn_left self :  """Turn the car left.  .. deprecated:: 1.1  left".  Use :func:`turn` instead with the direction argument set to " ←֓  """ warnings.warn "turn_left is deprecated, use turn instead",  DeprecationWarning   self.turn direction='left'   def turn self, direction :  ⁜For those who work with C, this is a hand⁴ counterpart to the __attribute__   deprecated    GCC extension.    cid:469 . cid:473 . MANAGING API CHANGES   cid:470  cid:471   """Turn the car in some direction.  :param direction: The direction to turn to. :type direction: str """  Write actual code here instead pass  Should an⁴ code call the deprecated turn_left function, a warning will be raised: >>> Car  .turn_left   __main__:8: DeprecationWarning: turn_left is deprecated, use turn instead  Note Since Python 2.7, DeprecationWarning are not displayed by default. To disable this filter, you need to call python with the -W all option. See the python manual page for more information on the possible values for -W.  Having ⁴our code tell developers that their programs are using something that will stop working eventuall⁴ is a good idea because it can also be automated. When run- ning their test suites, developers can run python with the -W error option, which transforms warnings into exceptions. That means that ever⁴ time an obsolete func- tion is called, an error will be raised, and it will be eas⁴ for developers using ⁴our librar⁴ to know exactl⁴ where their code needs to be fixed. Example  cid:469 . cid:471  Running python -W error >>> import warnings >>> warnings.warn "This is deprecated", DeprecationWarning  Traceback  most recent call last :  File " ", line 1, in   DeprecationWarning: This is deprecated    cid:469 . cid:474 . INTERVIEW WITH CHRISTOPHE DE VIENNE   cid:470  cid:472   2.7 Interview with Christophe de Vienne  Christophe is a P⁴thon developer and the author of WSME, Web Services Made Easy. This framework allows developers to define web services in a P⁴thonic wa⁴ and sup- ports a wide variet⁴ of APIs, allowing it to be plugged into man⁴ other web frame- works.  What are the mistakes developers oten make when designing a Python API? There are a few mistakes I tr⁴ not to make when designing a P⁴thon API:    Making it too complicated. As the sa⁴ing goes, "Keep It Simple."  Some people would sa⁴ "Keep It Simple Stupid," but I don’t think "simple" and "stupid" are compatible.  Complicated APIs are hard to understand and hard to document. You don’t have to make the actual librar⁴ function- alit⁴ simple as well, but it’s a smart idea. A good example is the Re- quests librar⁴: compared to the various standard urllib libraries, the Re- quests API is ver⁴ simple and natural, but it does complex things behind the scenes. The urllib API, b⁴ contrast, is almost as complicated as the things it does.    Doing  visible  magic. When ⁴our API does things that ⁴our documen- tation doesn’t explain, ⁴our end users are going to want to crack open ⁴our code and see what’s going on under the hood. It’s oka⁴ if ⁴ou’ve got some magic happening behind the scenes, but ⁴our end users should never see an⁴thing unnatural happening up front.    cid:469 . cid:474 . INTERVIEW WITH CHRISTOPHE DE VIENNE   cid:470  cid:473     Forgetting ⁴our use cases. When writing code down in the depths of ⁴our librar⁴, it’s eas⁴ to forget how ⁴our librar⁴ will actuall⁴ be used. Coming up with good use cases makes it easier to design an API.    Not writing unit tests. TDD is a ver⁴ eﬀicient wa⁴ to write libraries, es- peciall⁴ in P⁴thon. It forces the developer to assume the role of the end user from the ver⁴ beginning and maintain compatibilit⁴ between ver- sions. It’s also the onl⁴ approach I know of that allows ⁴ou to completel⁴ rewrite a librar⁴. Even if it’s not alwa⁴s necessar⁴, it’s good to have that option.  Considering the variety of frameworks WSME can sit on top of, what kinds of API does it have to support? There actuall⁴ aren’t that man⁴, since the frameworks it sits on are similar in a lot of wa⁴s. The⁴ use decorators to expose functions and methods to the outside world; the⁴’re based on the WSGI standard  so their request objects look ver⁴ similar ; and the⁴’ve all more or less used each other as a source of inspiration. That said, we haven’t ⁴et attempted to plug it into an as⁴nchronous web framework such as Twisted.  The biggest diﬀerence I’ve had to deal with is the wa⁴ contextual informa- tion is accessed. In a web framework, the context is mainl⁴ the request and what can be deduced from or attached to it  identit⁴, session data, data connection, etc. , as well as a few global things like the global con- figuration, connection pool, and so forth. Most web frameworks assume the⁴’re running on a multi-threaded server and treat all this information as TSD  Thread-Specific Data . This allows them to access the current request b⁴ simpl⁴ importing a request prox⁴ object from a module and working with it. While it’s prett⁴ straightforward to use, it implies a little magic and makes global objects out of context-specific data.    cid:469 . cid:474 . INTERVIEW WITH CHRISTOPHE DE VIENNE   cid:470  cid:474   The P⁴ramid framework doesn’t work like this, for example. Instead, the context is explicitl⁴ injected into the code pieces that work with it. This is wh⁴ the views takes a "request" parameter, which wraps the WSGI envi- ronment and gives access to the global context of the application. What are their pros and cons? An API st⁴le like the one used in P⁴ramid has the big advantage that it allows a single program to run several completel⁴ distinct environments in a ver⁴ natural wa⁴. The downside is that its learning curve is a little steeper. How does Python make it easier or harder to design a library API? The lack of a built-in wa⁴ to define which parts are public and which parts aren’t is both a  slight  problem and an advantage. It’s a problem when it means developers don’t think as much as the⁴ should about which parts are their API and which parts aren’t. But with a little discipline, documentation, and  if needed  tools like zope.interface, it doesn’t sta⁴ a problem for long. It’s an advantage when it makes it quicker and easier to refactor APIs while keeping compatibilit⁴ with previous versions. What’s your rule of thumb about API evolution, deprecation, removal, etc.? There are several criteria I weigh when making a decision:    How diﬀicult will it be for users of the library to adapt their code? Considering that there are people rel⁴ing on ⁴our API, an⁴ change ⁴ou make has to be worth the eﬀort needed to adopt it. This rule is intended to prevent non-compatible changes to the parts of the API that are in common use. That said, one of the advantages of P⁴thon is that it’s rel- ativel⁴ eas⁴ to refactor code to adopt an API change.    cid:469 . cid:474 . INTERVIEW WITH CHRISTOPHE DE VIENNE   cid:470  cid:475     Will maintenance be easier with the change? Simplif⁴ing the imple- mentation, cleaning up the codebase, making the API easier to use, hav- ing more complete unit tests, making the API easier to understand at first glance… all of these things will make ⁴our life as a maintainer eas- ier.    How much more  or less  consistent will my API be ater the change? If all of the API’s functions follow a similar pattern  such as requiring the same parameter in the first position , it’s important to make sure that new functions follow that pattern as well. Also, doing too man⁴ things at once is a great wa⁴ to end up doing none of them right: keep ⁴our API focused on what it’s meant to do.    How will users benefit from this change? Last but not least, alwa⁴s  consider the users' point of view.  What advice do you have regarding API documentation in Python? Documentation makes it eas⁴ for newcomers to adopt ⁴our librar⁴. Ne- glecting it will drive awa⁴ a lot of potential users; not just beginners, ei- ther. The problem is, documenting is diﬀicult, so it gets neglected all the time!  Document earl⁴ and include ⁴our documentation build in continuous in- tegration. Now that we have Read the Docs, there’s no excuse for not having documentation built and published  at least for open-source sot- ware .  Use docstrings to document classes and functions in ⁴our API. Follow the PEP  cid:469  cid:472  cid:474 ⁝ guidelines so that developers won’t have to read ⁴our source to understand what ⁴our API does. Generate HTML documentation from ⁴our docstrings, and don’t limit it to the API reference.  ⁝Docstring Conventions, David Goodger, Guido van Rossum,  cid:469  cid:476  Ma⁴  cid:469  cid:467  cid:467  cid:468     cid:469 . cid:474 . INTERVIEW WITH CHRISTOPHE DE VIENNE   cid:470  cid:476   Give practical examples throughout. Have at least one "startup guide" that will show newcomers how to build a working example. The first page of the documentation should give a quick overview of ⁴our API’s basic and representative use case.  Document the evolution of ⁴our API in detail, version b⁴ version.  VCS logs are not enough!   Make ⁴our documentation accessible and, if possible, comfortable to read: ⁴our users need to be able to find it easil⁴ and get the information the⁴ need without feeling like the⁴’re being tortured. Publishing ⁴our docu- mentation through P⁴PI is one wa⁴ to achieve this; publishing on Read the Docs is also a good idea, since users will expect to find ⁴our documen- tation there.  Finall⁴, choose a theme that is both eﬀicient and attractive. I chose the "Cloud" Sphinx theme for WSME, but there are plent⁴ of other themes out there to choose from. You don’t have to be a web expert to produce nice- looking documentation.    cid:470  Documentation  As I’ve alread⁴ touched upon, documentation is one of the most important parts of writing sotware. Unfortunatel⁴, there are still a lot of projects out there that doesn’t provide proper documentation. Writing documentation is seen as a com- plicated and daunting task, but it doesn’t have to be: with the tools that are avail- able to P⁴thon programmers, documenting ⁴our code can be just as eas⁴ as writing it in the first place.  One of the biggest culprits behind wh⁴ documentation is either sparse or nonexis- tent is that man⁴ people assume that the onl⁴ wa⁴ to document code is b⁴ hand. Even if ⁴ou have multiple people working on the same project, this means that one or more of them is going to end up having to juggle contributing code with main- taining documentation – and if ⁴ou ask an⁴ developer which job the⁴’d prefer, ⁴ou can be sure the⁴’ll tell ⁴ou the⁴’d rather write sotware than write about sotware. Sometimes the documentation process is even completel⁴ separate from the devel- opment process, meaning that the documentation is written b⁴ people who have never written so much as a line of the actual code. Furthermore, an⁴ documenta- tion produced this wa⁴ is likel⁴ to be out-of-date: whether the documentation is handled b⁴ the programmers themselves or b⁴ dedicated writers, it’s almost im- possible for manual documentation to keep up with the pace of development.  The bottom line is, the more degrees of separation there are between ⁴our code and ⁴our documentation, the harder it will be to keep the latter properl⁴ maintained.   CHAPTER  cid:470 . DOCUMENTATION   cid:471  cid:468   So wh⁴ keep ⁴our code and documentation separate at all? It’s not onl⁴ possible to put ⁴our documentation directl⁴ in ⁴our code itself, but it’s also eas⁴ to convert that documentation into eas⁴-to-read HTML and PDF files.  The de facto standard documentation format for P⁴thon is reStructuredText, or reST for short. It’s a lightweight markup language  like the famous Markdown  that’s as eas⁴ to read and write for humans as it is for computers. Sphinx is the most com- monl⁴ used tool for working with this format: it can read reST-formatted content and output documentation in a variet⁴ of other formats.  Your project documentation should include:    The problem ⁴our project is intended to solve, in one or two sentences.    The license ⁴our project is distributed under. If ⁴our sotware is open source, ⁴ou should also include this information in a header in each code file: just because ⁴ou’ve uploaded ⁴our code to the Internet doesn’t mean that people will know what the⁴’re allowed to do with it.    A small example of how it works.    Installation instructions.    Links to communit⁴ support, mailing list, IRC, forums, etc.    A link to ⁴our bug tracker s⁴stem.    A link to ⁴our source code so that developers can download and start delving into  it right awa⁴.  You should also include a README.rst file that explains what ⁴our project does. This README will be displa⁴ed on ⁴our GitHub or P⁴PI project page; both sites know how to handle reST formatting.    cid:470 . cid:468 . GETTING STARTED WITH SPHINX AND REST   cid:471  cid:469   Tip If you’re using GitHub, you can also add a CONTRIBUTING.rst file that will be displayed It should provide a checklist for them to follow when someone creates a pull request.  before they submit the request, e.g. follow PEP 8 or don’t forget to run the unit tests.  Tip Read The Docs allows you to build and publish your documentation online automatically.  Signing up and configuring a project is a straightforward process:  it searches for your  Sphinx configuration file, builds your documentation, and makes it available for your users  to access. It’s a great companion to code hosting sites.  3.1 Getting started with Sphinx and reST  First of all, ⁴ou should run sphinx-quickstart in ⁴our project’s top-level director⁴. This will create the director⁴ structure Sphinx expects to find, along with two files in the doc source folder: conf.py, which contains Sphinx's configuration settings  and is absolutel⁴ required for Sphinx to work , and index.rst, which will serve as the front page of ⁴our documentation.  You can then build ⁴our documentation in HTML format b⁴ calling sphinx-build with ⁴our source director⁴ and output director⁴ as arguments: $ sphinx-build doc source doc build  import pkg_resources Running Sphinx v1.2b1 loading pickled environment... done No builder selected, using default: html building [html]: targets for 1 source files that are out of date updating environment: 0 added, 0 changed, 0 removed looking for now-outdated files... none found    cid:470 . cid:469 . SPHINX MODULES   cid:471  cid:470   preparing documents... done writing output... [100%] index writing additional files... genindex search copying static files... done dumping search index... done dumping object inventory... done build succeeded.  Now ⁴ou can open doc build index.html in ⁴our favorite browser and read ⁴our documentation.  Tip If you are using setuptools or pbr  see Section 4.2  for packaging, Sphinx extends them to support the command setup.py build_sphinx, which will run sphinx-build automatically. The pbr integration of Sphinx has some saner defaults, such as outputting the documentation in the doc subdirectory.  index.rst is where ⁴our documentation begins, but it doesn’t have to end there: reST supports includes, so there’s nothing stopping ⁴ou from dividing ⁴our docu- mentation up into multiple files. Don’t worr⁴ too much about s⁴ntax and semantics to start with: it’s true that reST oﬀers a lot of formatting possibilities, but ⁴ou’ll have plent⁴ of time to dive into the reference later. The complete reference explains how to create titles, bulleted lists, tables, and more.  3.2 Sphinx modules  Sphinx is highl⁴ extensible: its basic functionalit⁴ onl⁴ supports manual documen- tation, but it comes with a number of useful modules which enable automatic doc- umentation and other features. For example, sphinx.ext.autodoc extracts reST- formatted docstrings from ⁴our modules and generates .rst files for inclusion. sph    cid:470 . cid:469 . SPHINX MODULES   cid:471  cid:471   inx-quickstart will ask ⁴ou if ⁴ou want to activate this module when ⁴ou run it – alternatel⁴, ⁴ou can edit ⁴our conf.py file and add it as an extension: extensions = ['sphinx.ext.autodoc']  Note that autodoc will not automaticall⁴ recogni⁵e and include ⁴our modules. You need to explicitl⁴ indicate which modules ⁴ou want to be documented b⁴ adding something like this to one of ⁴our .rst files: .. automodule:: foobar  :members: ②1 :undoc-members: ②2 :show-inheritance: ②3  Request that all documented members be printed  optional   Request that all undocumented members be printed  optional   Show inheritance  optional   ②1  ②2  ②3  Also note:    If ⁴ou don’t include an⁴ directives, Sphinx won’t generate an⁴ output.    If ⁴ou onl⁴ specif⁴ :members:, undocumented nodes on ⁴our module class method tree will be skipped, even if all their members are documented. For example, if ⁴ou document the methods of a class but not the class itself, :members: will ex- clude both the class and its methods entirel⁴. To keep this from happening, ⁴ou’d either have to write a docstring for the class or specif⁴ :undoc-members: as well.    Your module needs to be where P⁴thon can import it. Adding ., .., and or .. ..  to sys.path can help with this.    cid:470 . cid:469 . SPHINX MODULES   cid:471  cid:472   autodoc gives ⁴ou the power to include most of ⁴our documentation in ⁴our actual source code. You can even pick and choose which modules and methods to doc- ument – it’s not an "all-or-nothing" solution. B⁴ maintaining ⁴our documentation directl⁴ alongside ⁴our source code, ⁴ou can easil⁴ ensure it sta⁴s up-to-date.  If ⁴ou’re writing a P⁴thon librar⁴, ⁴ou’ll usuall⁴ want to format ⁴our API documen- tation with a table of contents containing links to individual pages for each module. The sphinx.ext.autogen module was created specificall⁴ to handle this common use case. First, ⁴ou need to enable it in conf.py: extensions = ['sphinx.ext.autodoc', 'sphinx.ext.autosummary']  Now ⁴ou can add something like the following to an .rst file to automaticall⁴ gen- erate a TOC for the specified modules: .. autosummary::  mymodule mymodule.submodule  This will create files called generated mymodule.rst and generated mymodule.sub module.rst containing the autodoc directives described earlier. Using this same format, ⁴ou can specif⁴ which parts of ⁴our module API ⁴ou want included in ⁴our documentation.  Tip In large projects, it can be tedious to add modules to this list by hand. Just remember that conf.py is an ordinary Python source file: there’s nothing stopping you from writing your own code in it, including code that automatically builds .rst files indicating which modules to document.  Another useful feature of Sphinx is the abilit⁴ to run doctest on ⁴our examples auto- maticall⁴ when ⁴ou build ⁴our documentation. doctest is a standard P⁴thon mod-    cid:470 . cid:469 . SPHINX MODULES   cid:471  cid:473   ule which searches ⁴our documentation for code snippets and runs them to test whether the⁴ accuratel⁴ reflect what ⁴our code actuall⁴ does. Ever⁴ paragraph starting with >>>  i.e. the primar⁴ prompt  is treated as a code snippet to test: To print something to the standard output, use the :py:func:`print` ←֓  function.  >>> print "foobar"  foobar  It’s eas⁴ to end up leaving ⁴our examples unchanged as ⁴our API evolves; doctest helps ⁴ou make sure this doesn’t happen. If ⁴our documentation includes a step- b⁴-step tutorial, doctest will help ⁴ou keep it up-to-date throughout development. You can also use doctest for Documentation-Driven Development  DDD : write ⁴our documentation and examples first, and then write ⁴our code to match ⁴our docu- mentation.  Taking advantage of this feature is as simple as running sphinx-build with the spe- cial doctest builder:  $ sphinx-build -b doctest doc source doc build Running Sphinx v1.2b1 loading pickled environment... done building [doctest]: targets for 1 source files that are out of date updating environment: 0 added, 0 changed, 0 removed looking for now-outdated files... none found running tests...  Document: index --------------- 1 items passed all tests:  1 tests in default  1 tests in 1 items.    cid:470 . cid:470 . EXTENDING SPHINX   cid:471  cid:474   1 passed and 0 failed. Test passed.  Doctest summary ===============  1 test 0 failures in tests 0 failures in setup code 0 failures in cleanup code  build succeeded.    Link between projects using    HTML themes    Diagrams and formulas    Output to Texinfo and EPUB format    Linking to external documentation  Sphinx also provides a bev⁴ of other features, either out-of-the-box or through ex- tension modules, including:  You might not need all this functionalit⁴ right awa⁴, but if ⁴ou ever need it in the future, it’s good to know in advance that there are modules that can provide it.  3.3 Extending Sphinx  Sometimes the oﬀ-the-shelf solutions just aren’t enough. It’s one thing if ⁴ou’re writing an API that’s going to be used from within P⁴thon, but what if ⁴ou’re writ- ing, sa⁴, an HTTP REST API? Sphinx will onl⁴ document the P⁴thon side of ⁴our API,    cid:470 . cid:470 . EXTENDING SPHINX   cid:471  cid:475   forcing ⁴ou to write ⁴our REST API documentation b⁴ hand with all the problems that entails.  The creators of WSME had other ideas. The⁴ developed a Sphinx extension called sphinxcontrib-pecanwsme which anal⁴⁵es docstrings and actual P⁴thon code to gen- erate REST API documentation automaticall⁴. You can do the same thing for ⁴our own projects: if ⁴ou can extract information from ⁴our code that could be useful in ⁴our documentation, it onl⁴ makes sense to automate the process.  Tip You can use sphinxcontrib.httpdomain for other HTTP frameworks such as Flask, Bottle,  and Tornado.  M⁴ point here is that whenever ⁴ou know that ⁴ou could extract information from ⁴our code that could help to build documentation, ⁴ou should reall⁴ do that and automati⁵e it. It is better than tr⁴ing to maintain a manuall⁴ written documenta- tion, especiall⁴ when ⁴ou can leverage it with auto-publication tools like Read The Docs.  To write a Sphinx extension, first ⁴ou need to write a module, preferabl⁴ as a sub- module of sphinxcontrib  as long as ⁴our module is generic enough , and pick a name for it. Sphinx expects this module to have one predefined function called setup app . The app object will contain the methods ⁴ou’ll use to connect ⁴our code to Sphinx events and directives. The full list of methods is available in the Sphinx extension API.  For example, sphinxcontrib-pecanwsme adds a single directive called rest-contr oller using the setup app  function. This added directive needs a full⁴ qualified WSME controller class name to generate documentation for. Example  cid:470 . cid:468  Code from sphinxcontrib.pecanwsme.rest.setup    cid:470 . cid:470 . EXTENDING SPHINX   cid:471  cid:476   def setup app :  app.add_directive 'rest-controller', RESTControllerDirective   RESTControllerDirective is a directive class which has to have certain properties and methods as described in the Sphinx extension API. The main method, run  , will do the actual work of extracting documentation from ⁴our code.  The sphinx-contrib repositor⁴ has a bunch of small modules that can help ⁴ou de- velop ⁴our own.  Note Even though Sphinx is written in Python and targets it by default, there are extensions  available that allow it to support other languages as well. You can use Sphinx to document  your project in full even if it uses multiple languages at once.    cid:471  Distribution  It’s a safe bet ⁴ou’ll want to distribute ⁴our sotware at some point. As tempted as ⁴ou might be to just ⁵ip up ⁴our code and upload it to the Internet, P⁴thon provides tools to help ⁴ou make sure ⁴our end users will have no trouble getting ⁴our sot- ware to work. You should alread⁴ be familiar with using setup.py to install P⁴thon applications and libraries, but ⁴ou’ve probabl⁴ never delved into how it actuall⁴ works behind the scenes, or how to make a setup.py of ⁴our own.  4.1 A bit of history  distutils has been part of the standard P⁴thon librar⁴ since  cid:468  cid:476  cid:476  cid:475 . It was originall⁴ developed b⁴ Greg Ward, who sought to create an eas⁴ wa⁴ for developers to auto- mate the installation process for their end users: Example  cid:471 . cid:468  setup.py using distutils  ! usr bin python from distutils.core import setup  setup name="rebuildd",  description="Debian packages rebuild tool", author="Julien Danjou", author_email="acid@debian.org",    cid:471 . cid:468 . A BIT OF HISTORY   cid:472  cid:468   url="http:  julien.danjou.info software rebuildd.html", packages=['rebuildd']   And that’s it. All users have to do to build or install ⁴our sotware is run setup.py with the appropriate command. If ⁴our distribution includes C modules in addition to native P⁴thon ones, it can even handle those automaticall⁴ as well.  Development on distutils was abandoned in  cid:469  cid:467  cid:467  cid:467 ; since then, other developers picked up where it let oﬀ, building their own tools based on it. One of the most notable successors to distutils is the packaging librar⁴ known as setuptools, which oﬀered more frequent updates and advanced features such as automatic dependenc⁴ han- dling, the Egg distribution format, and the easy_install command. Since distutils was still the canonical means of packaging sotware included with the P⁴thon Stan- dard Librar⁴, setuptools also provided a degree of backwards compatibilit⁴ with it. Example  cid:471 . cid:469  setup.py using setuptools  ! usr bin env python import setuptools  setuptools.setup   name="pymunincli", version="0.2", author="Julien Danjou", author_email="julien@danjou.info", description="munin client library", license="GPL", url="http:  julien.danjou.info software pymunincli ", packages=['munin'], classifiers=[  "Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers",    cid:471 . cid:468 . A BIT OF HISTORY   cid:472  cid:469   "Intended Audience :: Information Technology", "License :: OSI Approved :: GNU General Public License  GPL ", "Operating System :: OS Independent", "Programming Language :: Python"  ],     Eventuall⁴, development on setuptools slowed down, and people began to consider it a dead project like the original distutils. It wasn’t long before another group of developers forked it to create a new librar⁴ called distribute, which oﬀered several advantages over setuptools, including fewer bugs and P⁴thon  cid:470  support. All the best stories have a twist ending, though, and this one’s no diﬀerent: in March  cid:469  cid:467  cid:468  cid:470 , the teams behind setuptools and distribute decided to merge their code bases under the aegis of the original setuptools project. So distribute is now deprecated, and setuptools is once more the canonical wa⁴ to handle advanced P⁴thon installations.  While all this was happening, another project known as distutils cid:469  was developed with the intention of replacing distutils in the P⁴thon Standard Librar⁴ outright. One of its most notable diﬀerences from both distutils and setuptools was that it stored package metadata in a plain text file, setup.cfg, which was both easier for devel- opers to write and easier for external tools to read. However, it also retained some of the failings of distutils, such as its obtuse command-based design, and lacked support for things like entr⁴ points and native script execution on Windows - both features provided b⁴ setuptools. For these and other reasons, plans to include dis- tutils cid:469  in the P⁴thon  cid:470 . cid:470  Standard Librar⁴ as packaging fell through, and the project was abandoned in  cid:469  cid:467  cid:468  cid:469 .  However, packaging still has a chance to rise from the ashes through distlib, an up- and-coming eﬀort to replace distutils which - hopefull⁴ - will become part of the Standard Librar⁴ in  cid:470 . cid:471 . It includes the best features from packaging and imple- ments the basic groundwork described in the packaging-related PEPs.    cid:471 . cid:469 . PACKAGING WITH PBR   cid:472  cid:470   So, to recap:  stallations.    distutils is part of the P⁴thon standard librar⁴ and can handle simple package in-    setuptools, the standard for advanced package installations, was at first depre-  cated but is now back in active development.    distribute has been merged back into setuptools as of version  cid:467 . cid:474 .    distutils cid:469   a.k.a. packaging  has been abandoned.    distlib might replace distutils in the future.  There are other packaging libraries out there, though these five are the ones ⁴ou’ll encounter the most in practice. Be careful when looking up information about them on the Internet: there’s plent⁴ of documentation out there that’s outdated due to the complicated histor⁴ outlined above. The oﬀicial documentation is, at least, up to date.  The short version of all this is, setuptools is the distribution librar⁴ to use for the time being, but keep an e⁴e out for distlib in the future.  4.2 Packaging with pbr  Now that I’ve spent some pages making ⁴our head confused with a lot of distribu- tion tools, let’s talk, about another tool and alternative, called pbr.  You probabl⁴ alread⁴ have written some package and tried to write a setup.py, ei- ther b⁴ cop⁴ing one from some other project, or b⁴ skimming through the docu- mentation. It isn’t an obvious task, as the various problem we discussed earlier about which tool to use are usuall⁴ a first obstacle. In this section I want to intro- duce ⁴ou to pbr, a tool ⁴ou should use to write ⁴our next setup.py so ⁴ou’ll never have to lose ⁴our time on that part again.    cid:471 . cid:469 . PACKAGING WITH PBR   cid:472  cid:471   pbr stands for Python Build Reasonableness. The project has been started inside OpenStack as a set of tools around setuptools to facilitate installation and deplo⁴- ment of packages. It takes inspiration from distutils cid:469 , using a setup.cfg file to de- scribe the packager’s intents.  This is how a setup.py using pbr looks like: import setuptools  setuptools.setup setup_requires=['pbr'], pbr=True   Two lines of code – it’s that simple. The actual metadata that the setup requires is stored in setup.cfg: [metadata] name = foobar author = Dave Null author-email = foobar@example.org summary = Package doing nifty stuff license = MIT description-file =  README.rst  home-page = http:  pypi.python.org pypi foobar requires-python = >=2.6 classifier =  Development Status :: 4 - Beta Environment :: Console Intended Audience :: Developers Intended Audience :: Information Technology License :: OSI Approved :: Apache Software License Operating System :: OS Independent Programming Language :: Python    cid:471 . cid:470 . THE WHEEL FORMAT   cid:472  cid:472   [files] packages = foobar  Sound familiar? That’s right – this particular wa⁴ of doing things was directl⁴ in- spired b⁴ distutils cid:469 .  pbr also oﬀers other features such as:    automatic dependenc⁴ installation based on requirements.txt    automatic documentation using Sphinx    automatic generation of AUTHORS and ChangeLog files based on git histor⁴    automatic creation of file lists for git    version management based on git tags  And all this with little to no eﬀort on ⁴our part. pbr is well-maintained and in ver⁴ active development, so if ⁴ou have an⁴ plans to distribute ⁴our sotware, ⁴ou should seriousl⁴ consider including pbr in those plans.  4.3 The Wheel format  For most of P⁴thon’s existence, there’s been no oﬀicial standard distribution for- mat. While diﬀerent distribution tools still generall⁴ use some kind of common archive format – even the Egg format introduced b⁴ setuptools is just a ⁵ip file with a diﬀerent extension – their metadata and package structures are incompatible with each other. This problem was compounded when an oﬀicial installation standard was finall⁴ defined in PEP  cid:470  cid:474  cid:473 , which was also incompatible with existing formats.    cid:471 . cid:470 . THE WHEEL FORMAT   cid:472  cid:473   To solve these problems, PEP  cid:471  cid:469  cid:474  was written to define a new standard for P⁴thon distribution packages called Wheel. The reference implementation of this format is available as a tool, also called wheel. Wheel is supported b⁴ pip starting with version  cid:468 . cid:471 . If ⁴ou’re using setuptools and have the wheel package installed, it is automaticall⁴ integrated as a command: python setup.py bdist_wheel  This will create a .whl file in the dist director⁴. Like with the Egg format, a Wheel archive is just a ⁵ip file with a diﬀerent extension, except Wheel archives don’t re- quire installation – ⁴ou can load and run ⁴our code just b⁴ adding a slash followed b⁴ the name of ⁴our module: $ python wheel-0.21.0-py2.py3-none-any.whl wheel -h usage: wheel [-h]  {keygen,sign,unsign,verify,unpack,install,install-scripts, ←֓  convert,help}  ...  positional arguments: [...]  You might be surprised to learn this isn’t a feature introduced b⁴ the Wheel format. P⁴thon can also run regular ⁵ip files as well, just like with Java’s .jar files: python foobar.zip  This is equivalent to: PYTHONPATH=foobar.zip python -m __main__  In other words, the __main__ module for ⁴our program will automaticall⁴ be im- ported from __main__.py. It’s also possible to import __main__ from a module ⁴ou    cid:471 . cid:471 . PACKAGE INSTALLATION   cid:472  cid:474   specif⁴ b⁴ appending a slash followed b⁴ its name, just like with Wheel: python foobar.zip mymod  This is equivalent to: PYTHONPATH=foobar.zip python -m mymod.__main__  One of the advantages of Wheel is that its naming conventions allow ⁴ou to specif⁴ whether ⁴our distribution is intended for a specific architecture and or P⁴thon im- plementation  CP⁴thon, P⁴P⁴, J⁴thon, etc. . This is particularl⁴ useful if ⁴ou need to distribute modules written in C.  4.4 Package installation  setuptools introduced the first useful command for installing packages, easy_install. It allows ⁴ou to install P⁴thon modules from Egg archives with a single command; unfortunatel⁴, easy_install has suﬀered a bad reputation from the beginning due to some of its more questionable behaviors, such as ignoring best practices for s⁴stem administration and its lack of uninstall functionalit⁴.  The pip project oﬀers a much better wa⁴ to handle package installations. It’s ac- tivel⁴ developed, well-maintained, and will be included with P⁴thon starting in  cid:470 . cid:471  ¹. It can install or uninstall packages from P⁴PI, a tarball, or a Wheel  see Section  cid:471 . cid:470   archive.  Its usage is simple: $ pip install --user voluptuous Downloading unpacking voluptuous  Downloading voluptuous-0.8.3.tar.gz Storing download in cache at . .cache pip https%3A%2F%2Fpypi.python.org%2 ←֓  Fpackages%2Fsource%2Fv%2Fvoluptuous%2Fvoluptuous-0.8.3.tar.gz  ¹See PEP  cid:471  cid:472  cid:470  and the ensurepip module    cid:471 . cid:471 . PACKAGE INSTALLATION   cid:472  cid:475   Running setup.py egg_info for package voluptuous  WARNING: Could not locate pandoc, using Markdown long_description.  Requirement already satisfied  use --upgrade to upgrade : distribute in   ←֓  usr lib python2.7 dist-packages  from voluptuous   Installing collected packages: voluptuous Running setup.py install for voluptuous  WARNING: Could not locate pandoc, using Markdown long_description.  Successfully installed voluptuous Cleaning up...  You can also provide a --user option that makes pip install the package in ⁴our home director⁴. This avoids polluting ⁴our operating s⁴stem directories with pack- ages installed s⁴stem-wide.  Tip If you’re using pip to install the same packages over and over, you can make it use a  local cache instead of downloading the packages each time. Just set the environment variable PIP_DOWNLOAD_CACHE to a directory: pip will then use it to store downloaded tarballs and will check that location for packages before downloading them. This is very  useful when using tox  see Section 6.7 , which needs to download packages to build virtual environments. You can also add the download-cache option to your ~ .pip pip. conf file.  You can list the packages that are currentl⁴ installed b⁴ using the pip freeze com- mand: $ pip freeze Babel==1.3 Jinja2==2.7.1    cid:471 . cid:472 . SHARING YOUR WORK WITH THE WORLD   cid:472  cid:476   commando=0.3.4 …  All other installation tools are being deprecated in favor of pip, so ⁴ou shouldn’t have an⁴ trouble if ⁴ou treat it as ⁴our one-stop shop for all ⁴our package manage- ment needs.  4.5 Sharing your work with the world  Once ⁴ou have a proper setup.py file, it’s eas⁴ to build a source tarball that ⁴ou can distribute. Just use the sdist command: Example  cid:471 . cid:470  Using setup.py sdist  $ python setup.py sdist running sdist [pbr] Writing ChangeLog [pbr] Generating AUTHORS running egg_info writing requirements to ceilometer.egg-info requires.txt writing ceilometer.egg-info PKG-INFO writing top-level names to ceilometer.egg-info top_level.txt writing dependency_links to ceilometer.egg-info dependency_links.txt writing entry points to ceilometer.egg-info entry_points.txt [pbr] Processing SOURCES.txt [pbr] In git context, generating filelist from git warning: no previously-included files matching '*.pyc' found anywhere in ←֓  distribution  writing manifest file 'ceilometer.egg-info SOURCES.txt' running check copying setup.cfg -> ceilometer-2014.1.a6.g772e1a7    cid:471 . cid:472 . SHARING YOUR WORK WITH THE WORLD   cid:473  cid:467   Writing ceilometer-2014.1.a6.g772e1a7 setup.cfg  […]  Creating tar archive removing 'ceilometer-2014.1.a6.g772e1a7'  and everything under it   This will create a tarball under the dist director⁴ of ⁴our source tree that contains all ⁴our packages and can be used to install ⁴our sotware. As seen in Section  cid:471 . cid:470 , ⁴ou can also build Wheel archives using the bdist_wheel command.  The final step is to make things eas⁴ on ⁴our end users b⁴ setting things up where ⁴our package can be installed using pip. This means publishing ⁴our project to P⁴PI.  Since ⁴ou’ll probabl⁴ make mistakes if this is ⁴our first time, it pa⁴s to test out the publishing process in a safe sandbox rather than on the production server. You can use the P⁴PI staging server for this purpose: it replicates all the functionalit⁴ of the main index, but it’s used solel⁴ for testing purposes.  The first step is to register ⁴our project on the test server. Start b⁴ opening ⁴our ~  .pypirc file and adding these lines: [distutils] index-servers =  testpypi  [testpypi] username =   password =   repository = https:  testpypi.python.org pypi  Now ⁴ou can register ⁴our project in the index: $ python setup.py register -r testpypi    cid:471 . cid:472 . SHARING YOUR WORK WITH THE WORLD   cid:473  cid:468   running register running egg_info writing requirements to ceilometer.egg-info requires.txt writing ceilometer.egg-info PKG-INFO writing top-level names to ceilometer.egg-info top_level.txt writing dependency_links to ceilometer.egg-info dependency_links.txt writing entry points to ceilometer.egg-info entry_points.txt [pbr] Reusing existing SOURCES.txt running check Registering ceilometer to https:  testpypi.python.org pypi Server response  200 : OK  Finall⁴, ⁴ou can upload a source distribution tarball: % python setup.py sdist upload -r testpypi running sdist [pbr] Writing ChangeLog [pbr] Generating AUTHORS running egg_info writing requirements to ceilometer.egg-info requires.txt writing ceilometer.egg-info PKG-INFO writing top-level names to ceilometer.egg-info top_level.txt writing dependency_links to ceilometer.egg-info dependency_links.txt writing entry points to ceilometer.egg-info entry_points.txt [pbr] Processing SOURCES.txt [pbr] In git context, generating filelist from git warning: no previously-included files matching '*.pyc' found anywhere in ←֓  distribution  writing manifest file 'ceilometer.egg-info SOURCES.txt' running check creating ceilometer-2014.1.a6.g772e1a7    cid:471 . cid:472 . SHARING YOUR WORK WITH THE WORLD   cid:473  cid:469   […]  […]  copying setup.cfg -> ceilometer-2014.1.a6.g772e1a7 Writing ceilometer-2014.1.a6.g772e1a7 setup.cfg Creating tar archive removing 'ceilometer-2014.1.a6.g772e1a7'  and everything under it  running upload Submitting dist ceilometer-2014.1.a6.g772e1a7.tar.gz to https:  testpypi. ←֓  python.org pypi  Server response  200 : OK  As well as a Wheel archive: $ python setup.py bdist_wheel upload -r testpypi running bdist_wheel running build running build_py running egg_info writing requirements to ceilometer.egg-info requires.txt writing ceilometer.egg-info PKG-INFO writing top-level names to ceilometer.egg-info top_level.txt writing dependency_links to ceilometer.egg-info dependency_links.txt writing entry points to ceilometer.egg-info entry_points.txt [pbr] Reusing existing SOURCES.txt installing to build bdist.linux-x86_64 wheel running install running install_lib creating build bdist.linux-x86_64 wheel    cid:471 . cid:472 . SHARING YOUR WORK WITH THE WORLD   cid:473  cid:470   creating build bdist.linux-x86_64 wheel ceilometer-2014.1.a6.g772e1a7.dist- ←֓  info WHEEL running upload Submitting  home jd Source ceilometer dist ceilometer-2014.1.a6.g772e1a7- ←֓  py27-none-any.whl to https:  testpypi.python.org pypi  Server response  200 : OK  You should now be able to search for ⁴our package on the P⁴Pi staging server and see whether it uploaded properl⁴. You can also tr⁴ installing it using pip, specif⁴ing the test server using the -i option: $ pip install -i https:  testpypi.python.org pypi ceilometer  If ever⁴thing checks out, ⁴ou can continue to the next step: uploading ⁴our project to the main P⁴PI server. Just add ⁴our credentials and the details for the server to ⁴our ~ .p⁴pircˋ file: [distutils] index-servers =  pypi testpypi  [pypi] username =   password =    [testpypi] repository = https:  testpypi.python.org pypi username =   password =      cid:471 . cid:473 . INTERVIEW WITH NICK COGHLAN   cid:473  cid:471   Running register and upload with the -r pypi switch will now upload ⁴our package to P⁴PI proper.  4.6 Interview with Nick Coghlan  Nick is a P⁴thon core developer working at Red Hat. He has written several PEP proposals, including PEP  cid:471  cid:469  cid:473   Metadata for Python Sotware Packages  cid:469 . cid:467   for which he is acting as BDFL ² delegate.  The number of packaging solutions  distutils, setuptools, distutils2, distlib, bento, pbr, etc.  for Python is quite impressive. In your opin- ion, what are the  possibly historical  reasons for such fragmentation and divergence? The short answer is that sotware publication, distribution, and integra- tion is a complex problem with plent⁴ of room for multiple solutions tai- lored for diﬀerent use cases. The long answer can be found in the P⁴thon Packaging User Guide. In m⁴ recent talks on this, I have noted that the problem is mainl⁴ one of age and the aforementioned tools being born in a somewhat diﬀerent era of sotware distribution. setuptools is the de facto standard for Python distributions nowadays. Is there anything you think users should be aware of when using it  or not ? setuptools is quite reasonable as a build s⁴stem, especiall⁴ for pure P⁴thon  ²"Benevolent Dictator For Life," title given to Guido van Rossum, author of P⁴thon    cid:471 . cid:473 . INTERVIEW WITH NICK COGHLAN   cid:473  cid:472   projects, or those with onl⁴ simple C extensions. It also oﬀers a powerful s⁴stem for plugin registration and good cross-platform script generation.  While eﬀective, the multi-version support in pkg_resources is also a bit quirk⁴ and trick⁴ to use properl⁴. Unless there’s a reall⁴ compelling rea- son to have conflicting versions in the same environment, it’s much easier to just use virtualenv or zc.buildout. PEP  cid:471  cid:469  cid:473 , which defines a new metadata format for Python packages, is still fairly recent and not yet approved. Is it on good track? What motivated it in the first place, how do you think it’ll tackle the current problems? PEP  cid:471  cid:469  cid:473  originall⁴ started as part of the Wheel format definition, but Daniel Holth eventuall⁴ reali⁵ed that Wheel could work with the existing meta- data format defined b⁴ setuptools. PEP  cid:471  cid:469  cid:473  is thus a consolidation of the existing setuptools metadata with some of the ideas from distutils cid:469  and other packaging s⁴stems  like RPM and npm , and also addresses some of the frustrations encountered with existing tools  like cleanl⁴ separating diﬀerent kinds of dependencies . If PEP  cid:471  cid:469  cid:473  is accepted, what kinds of tools would you to see built to take advantage of what it oﬀers? The main gains will be a REST API on P⁴PI oﬀering full metadata access, as well as  hopefull⁴  the abilit⁴ to automaticall⁴ generate distribution polic⁴-compliant packages from upstream metadata. The Wheel format is fairly recent and not widely used yet, but it seems promising. Is there any reason it isn’t part of the Standard Library, or are there already plans to include it? It turns out the Standard Librar⁴ isn’t reall⁴ a suitable place for packaging standards: it evolves too slowl⁴, and an addition to a later version of the    cid:471 . cid:474 . ENTRY POINTS   cid:473  cid:473   Standard Librar⁴ can’t be used with earlier versions of P⁴thon. So, at the P⁴thon language summit earlier this ⁴ear, we tweaked the PEP process to allow distutils-sig to manage the full approval c⁴cle for packaging-related PEPs. python-dev will onl⁴ be involved for proposals that involve chang- ing CP⁴thon directl⁴  like pip bootstrapping . What kind of future do you envision that would push developers to build and distribute Wheel packages? pip is adopting it at as an alternative to the Egg format, allowing local caching of builds for fast virtual environment creation, and P⁴PI allows uploads of Wheel archives for Windows and Mac OS X. We still have some tweaks to make before it will be suitable for use on Linux.  4.7 Entry points  You ma⁴ have alread⁴ used setuptools entr⁴ points without knowing an⁴thing about them. If ⁴ou haven’t ⁴et decided to use setuptools  or pbr, see Section  cid:471 . cid:469   to pro- vide a setup.py file with ⁴our sotware, here are a few features that might help ⁴ou make up ⁴our mind.  Sotware distributed using setuptools includes important metadata describing things such as its required dependencies and – more relevantl⁴ to this topic – a list of "en- tr⁴ points." These entr⁴ points can be used b⁴ other P⁴thon programs to d⁴nami- call⁴ discover features that a package provides.  In the following sections, we will discuss how we can use entr⁴ points to add exten- sibilit⁴ to our sotware.    cid:471 . cid:474 . ENTRY POINTS   cid:473  cid:474   4.7.1 Visualising entry points  The easiest wa⁴ to visuali⁵e the entr⁴ points available in a package is to use a pack- age called entry_point_inspector.  When installed, it provides a command called epi that ⁴ou can run from ⁴our ter- minal to interactivel⁴ discover the entr⁴ points provided b⁴ installed packages: Example  cid:471 . cid:471  Result of epi group list +--------------------------+  Name  +--------------------------+  console_scripts   distutils.commands   distutils.setup_keywords   egg_info.writers    epi.commands  flake8.extension   setuptools.file_finders   setuptools.installation  +--------------------------+  Example  cid:471 . cid:471  shows that we have man⁴ diﬀerent packages that provide entr⁴ points. You’ll also notice this list includes console_scripts, which we’ll discuss in Section  cid:471 . cid:474 . cid:469 . Example  cid:471 . cid:472  Result of epi group show console_scripts +----------+----------+--------+--------------+-------+  Name  Member  Distribution  Error  +----------+----------+--------+--------------+-------+  coverage  coverage  main  +----------+----------+--------+--------------+-------+   coverage 3.4    Module    cid:471 . cid:474 . ENTRY POINTS   cid:473  cid:475    Value  Example  cid:471 . cid:472  shows us that an entr⁴ point named coverage refers to the member main of the module coverage. This entr⁴ point is provided b⁴ the package coverage  cid:470 . cid:471 . We can obtain more information b⁴ using epi ep show: Example  cid:471 . cid:473  Result of epi ep show console_scripts coverage +--------------+----------------------------------+  Field  +--------------+----------------------------------+  Module    Member  Distribution  coverage 3.4   Path   usr lib python2.7 dist-packages   Error   +--------------+----------------------------------+   coverage  main  The tool we’re using here is just a thin la⁴er on top of a more complete P⁴thon li- brar⁴ which can help us discover entr⁴ points for an⁴ P⁴thon librar⁴ or program. Entr⁴ points are useful for various things, including console scripts and d⁴namic code discover⁴, as we’re going to see in the next few sections.  4.7.2 Using console scripts  When writing a P⁴thon application, ⁴ou almost alwa⁴s have to provide a launchable program – a P⁴thon script that the end user can actuall⁴ run. This program needs to be installed inside a director⁴ somewhere in the s⁴stem path.  Most projects will have something along the lines of this: ! usr bin python import sys import mysoftware    cid:471 . cid:474 . ENTRY POINTS   cid:473  cid:476   mysoftware.SomeClass sys.argv .run    This is actuall⁴ a best-case scenario: man⁴ projects have a much longer script in- stalled in the s⁴stem path. But using such scripts has some major issues:    There’s no wa⁴ the⁴ can know where the P⁴thon interpreter is or which version it    The⁴ leak binar⁴ code that can’t be imported b⁴ sotware or unit tests.    There’s no eas⁴ wa⁴ to define where to install them.    It’s not obvious how to install this in a portable wa⁴  Unix vs Windows for exam-  will be.  ple .  setuptools has a feature that helps us circumvent these problems: console_scripts. console_scripts is an entr⁴ point that can be used to make setuptools install a tin⁴ program in the s⁴stem path which then calls a specific function in one of ⁴our mod- ules.  Let’s imagine a foobar program that consists of a client and a server. Each part is written in its own module – foobar.client and foobar.server, respectivel⁴: foobar client.py def main  :  print "Client started"   foobar server.py def main  :  print "Server started"   Of course, our program doesn’t reall⁴ do much of an⁴thing – our client and server don’t even talk to each other. For the purposes of our example, though, all the⁴ need to do is print a message letting us know the⁴’ve started successfull⁴.    cid:471 . cid:474 . ENTRY POINTS   cid:474  cid:467   We can now write the following setup.py file in the root director⁴: setup.py from setuptools import setup  setup   name="foobar", version="1", description="Foo!", author="Julien Danjou", author_email="julien@danjou.info", packages=["foobar"], entry_points={  "console_scripts": [  "foobard = foobar.server:main", "foobar = foobar.client:main",  ],  },     We define our entr⁴ points using the format package.subpackage:function. When ⁴ou run python setup.py install, setuptools will create a script that will look like this: Example  cid:471 . cid:474  A console script generated b⁴ setuptools ! usr bin python  EASY-INSTALL-ENTRY-SCRIPT: 'foobar==1','console_scripts','foobar' __requires__ = 'foobar==1' import sys from pkg_resources import load_entry_point  if __name__ == '__main__':    cid:474  cid:468    cid:471 . cid:474 . ENTRY POINTS  sys.exit      load_entry_point 'foobar==1', 'console_scripts', 'foobar'     This code scans the entr⁴ points of the foobar package and retrieves the foobar ke⁴ from the console_scripts categor⁴, which is used to locate and run the corre- sponding function.  Using this technique will ensure that ⁴our code sta⁴s in ⁴our P⁴thon package and can be imported  and tested  b⁴ other programs.  Tip If you’re using pbr on top of setuptools, the generated script is simpler  and therefore  faster  than the default one built by setuptools as it will call the function you wrote in the  entry point without having to search the entry point list dynamically at runtime.  4.7.3 Using plugins and drivers  Entr⁴ points make it eas⁴ to discover and d⁴namicall⁴ load code deplo⁴ed b⁴ other packages. You can use pkg_resources to discover and load entr⁴ point files from within ⁴our P⁴thon programs.  You might notice that this is the same package used in the console script that setuptools creates, as seen in Example  cid:471 . cid:474 .   In this section, we’re going to create a cron-st⁴le daemon that will allow an⁴ P⁴thon program to register a command to be run once ever⁴ few seconds b⁴ registering an entr⁴ point in the group pytimed. The attribute this entr⁴ point points to should be an object that returns number_of_seconds, callable.  Here’s our implementation of pycrond using pkg_resources to discover entr⁴ points:  pytimed.py import pkg_resources    cid:471 . cid:474 . ENTRY POINTS  import time  def main  :  seconds_passed = 0 while True:   cid:474  cid:469   for entry_point in pkg_resources.iter_entry_points 'pytimed' :  seconds, callable = entry_point.load      try:  except:  else:   Ignore failure pass  callable    time.sleep 1  seconds_passed += 1  if seconds_passed % seconds == 0:  This is a ver⁴ simple and naive implementation, but it’s suﬀicient for our example. Now we can write another P⁴thon program that needs one of its functions called on a periodic basis: hello.py def print_hello  :  print "Hello, world!"   def say_hello  :  return 2, print_hello  We register the function using the appropriate entr⁴ points: setup.py from setuptools import setup    cid:471 . cid:474 . ENTRY POINTS   cid:474  cid:470   setup   name="hello", version="1", packages=["hello"], entry_points={  "pytimed": [  ],  },   "hello = hello:say_hello",  And now if we run our pytimed script, we’ll see "Hello, world!" printed on the screen ever⁴  cid:469  seconds: Example  cid:471 . cid:475  Running p⁴timed % python3 Python 3.3.2+  default, Aug 4 2013, 15:50:24  [GCC 4.8.1] on linux Type "help", "copyright", "credits" or "license" for more ←֓  information.  >>> import pytimed >>> pytimed.main   Hello, world! Hello, world! Hello, world!  The possibilities this mechanism oﬀers are huge: it allows ⁴ou to build driver s⁴s- tems, hook s⁴stems, and extensions in an eas⁴ and generic wa⁴. Implementing this mechanism b⁴ hand in ever⁴ program ⁴ou make would be tedious, but fortunatel⁴, there’s a P⁴thon librar⁴ that can take care of the boring parts for us.    cid:471 . cid:474 . ENTRY POINTS   cid:474  cid:471   stevedore provides support for d⁴namic plugins based on the exact same mech- anism demonstrated in our previous examples. Our use case in this example isn’t ver⁴ complicated, but we can still simplif⁴ it a bit using stevedore: pytimed_stevedore.py from stevedore.extension import ExtensionManager import time  def main  :  seconds_passed = 0 while True:  for extension in ExtensionManager 'pytimed', invoke_on_load=True :  seconds, callable = extension.obj  try:  except:  else:   Ignore failure pass  callable    time.sleep 1  seconds_passed += 1  if seconds_passed % seconds == 0:  Our example is still ver⁴ simple, but if ⁴ou look through the stevedore documenta- tion, ⁴ou’ll see that ExtensionManager has a variet⁴ of subclasses that can handle diﬀerent situations, such as loading specific extensions based on their names or the result of a function.    cid:472  Virtual environments  When dealing with P⁴thon applications, there’s alwa⁴s a time where ⁴ou’ll have to deplo⁴, use and or test ⁴our application. But doing that can be reall⁴ painful, because of the external dependencies. There’s a lot of reasons for which that ma⁴ fail to deplo⁴ or operate on ⁴our operation s⁴stem, such as:    Your s⁴stem does not have the librar⁴ ⁴ou need packaged.    Your s⁴stem does not have the right version of the librar⁴ ⁴ou need packaged.    You need two diﬀerent versions of the same librar⁴ for two diﬀerent applications.  This can happen right at the time ⁴ou deplo⁴ ⁴our application, or later on while running. Upgrading a P⁴thon librar⁴ installed via ⁴our s⁴stem manager might break ⁴our application in a snap without warning ⁴ou.  The solution to this problem is to use a librar⁴ director⁴ per application, containing its dependencies. This director⁴ will be used rather than the s⁴stem installed ones to load the needed P⁴thon modules.  The tool virtualenv handles these directories automaticall⁴ for ⁴ou. Once installed, ⁴ou just need to run it with a destination director⁴ as argument. $ virtualenv myvenv Using base prefix ' usr' New python executable in myvenv bin python3   CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:474  cid:473   Also creating executable in myvenv bin python Installing Setuptools........................done. Installing Pip...............................done.  Once ran, virtualenv creates a lib pythonX.Y director⁴ and uses it to install setu ptools and pip, that will be necessar⁴ to install further P⁴thon packages.  You can now activate the virtualenv b⁴ "sourcing" the activate command: $ source myvenv bin activate  Once ⁴ou do that, ⁴our shell prompt will be prefixed b⁴ the name of ⁴our virtual en- vironment. Calling python will call the P⁴thon that has been copied into the virtual environment. You can check that its working b⁴ reading the sys.path variable; it will have ⁴our virtual environment director⁴ as its first component.  You can stop and leave the virtual environment at an⁴ time b⁴ calling the deactiv ate command: $ deactivate  That’s it.  Also not that ⁴ou’re not force to run activate if ⁴ou want to use the P⁴thon installed in ⁴our virtual environment just once. Calling the python binar⁴ will also work: $ myvenv bin python  Now, while we’re in our activated virtual environment, we don’t have access to an⁴ of the module installed and available on the s⁴stem. That’s good, but we probabl⁴ need to install them. To do that, ⁴ou just have to use the standard pip command, and that will install the packages in the right place, without changing an⁴thing to ⁴our s⁴stem: $ source myvenv bin activate  myvenv  $ pip install six   CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:474  cid:474   Downloading unpacking six  Downloading six-1.4.1.tar.gz Running setup.py egg_info for package six  Installing collected packages: six Running setup.py install for six  Successfully installed six Cleaning up...  And voilà. We can install all the libraries we need and then run our application from this virtual environment, without breaking our s⁴stem. It’s then easil⁴ imaginable to script this to automati⁵e the installation of a virtual environment based on a list of a dependenc⁴ with something along these lines: Example  cid:472 . cid:468  Automatic virtual environment creation  virtualenv myappvenv source myappvenv bin activate pip install -r requirements.txt deactivate  In certain situation, it’s still useful to have access to ⁴our s⁴stem installed packages. You can enable them when creating ⁴our virtual environment b⁴ passing the --sys tem-site-packages flag to the virtualenv command.  As ⁴ou might guess, virtual environments are utterl⁴ useful for automated run of unit test suite. This is a reall⁴ common pattern, so common that a special tool has been built to solve it, called tox  discussed in Section  cid:473 . cid:474  .  More recentl⁴, the PEP  cid:471  cid:467  cid:472  ¹ which defines a virtual environment mechanism has been accepted and implemented in P⁴thon  cid:470 . cid:470 . Indeed, the usage of virtual envi-  ¹Python Virtual Environments,  cid:468  cid:470 th June  cid:469  cid:467  cid:468  cid:468 , Carl Me⁴er   CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:474  cid:475   ronment became so popular that it is now part of the standard P⁴thon librar⁴.  The venv module is now part of P⁴thon  cid:470 . cid:470  and above, and allows to handle virtual environment without using the virtualenv package or an⁴ other one. You can call it using the -m flag of P⁴thon, which loads a module: $ python3.3 -m venv usage: venv [-h] [--system-site-packages] [--symlinks] [--clear] [--upgrade ←֓  ]  ENV_DIR [ENV_DIR ...]  venv: error: the following arguments are required: ENV_DIR  Building virtual environment is then reall⁴ simple: $ python3.3 -m venv myvenv  And that’s it. Inside myvenv, ⁴ou will find a pyvenv.cfg, the configuration file for this environment. It doesn’t have a lot of configuration option b⁴ default. You’ll recogni⁵e include-system-site-package, whose purpose is the same as the --sys tem-site-packages of virtualenv that we described earlier.  The mechanism to activate the virtual environment is the same as described earlier, "sourcing" the activate script: $ source myvenv bin activate  myvenv  $  Also here, ⁴ou can call deactivate to leave the virtual environment.  The downside of this venv module is that it doesn’t install setuptools nor pip b⁴ default. We will have to bootstrap the environment b⁴ ourself, contrar⁴ to virtual env that does that for us. Example  cid:472 . cid:469  Boostraping a venv environment   myvenv  $ wget https:  bitbucket.org pypa setuptools raw bootstrap  ←֓  ez_setup.py -O -  python    ez_setup.py  connected.  in 0s  CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:474  cid:476   -2013-09-02 22:26:07-- https:  bitbucket.org pypa setuptools raw bootstrap ←֓  Resolving bitbucket.org  bitbucket.org ... 131.103.20.168, 131.103.20.167 Connecting to bitbucket.org  bitbucket.org 131.103.20.168:443... ←֓  HTTP request sent, awaiting response... 200 OK Length: 11835  12K  [text plain] Saving to: ‘STDOUT’  100%[============================================>] 11,835  --.-K s  ←֓  2013-09-02 22:26:08  184 MB s  - written to stdout [11835 11835]  Downloading https:  pypi.python.org packages source s setuptools setuptools ←֓  -1.1.tar.gz  Extracting in  tmp tmp228fqm Now working in  tmp tmp228fqm setuptools-1.1 Installing Setuptools running install running bdist_egg running egg_info writing dependency_links to setuptools.egg-i […] Adding setuptools 1.1 to easy-install.pth file Installing easy_install script to  home jd myvenv bin Installing easy_install-3.3 script to  home jd myvenv bin  Installed  home jd myvenv lib python3.3 site-packages setuptools-1.1-py3.3. ←֓  egg   CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:475  cid:467   Processing dependencies for setuptools==1.1 Finished processing dependencies for setuptools==1.1  We can then install pip via easy_install:  myvenv  $ easy_install pip Searching for pip Reading https:  pypi.python.org simple pip  Best match: pip 1.4.1 Downloading https:  pypi.python.org packages source p pip pip-1.4.1.tar.gz ←֓  md5=6afbb46aeb48abac658d4df742bff714  Processing pip-1.4.1.tar.gz Writing  tmp easy_install-hxo3b0 pip-1.4.1 setup.cfg Running pip-1.4.1 setup.py -q bdist_egg --dist-dir  tmp easy_install-hxo3b0 ←֓   pip-1.4.1 egg-dist-tmp-efgi80  warning: no files found matching '*.html' under directory 'docs' warning: no previously-included files matching '*.rst' found under ←֓  directory 'docs _build'  no previously-included directories found matching 'docs _build _sources' Adding pip 1.4.1 to easy-install.pth file Installing pip script to  home jd myvenv bin Installing pip-3.3 script to  home jd myvenv bin  Installed  home jd myvenv lib python3.3 site-packages pip-1.4.1-py3.3.egg Processing dependencies for pip Finished processing dependencies for pip  We can then use pip to install an⁴ further package we would need.  So while P⁴thon  cid:470 . cid:470  includes venv b⁴ default, one has to admit that it has this little drawback to not come with what ⁴ou would expect b⁴ default. It’s eas⁴ enough to write a tool using the venv librar⁴ that would mimic the default behaviour of virtu   CHAPTER  cid:472 . VIRTUAL ENVIRONMENTS   cid:475  cid:468   alenv, but on the other side, there’s little point working on that unless ⁴ou are onl⁴ targeting P⁴thon  cid:470 . cid:470  and above. On the other hand, the pip bootstrapping code has been merged into P⁴thon  cid:470 . cid:471 , meaning that this bootstrap problem is solved b⁴ the latest P⁴thon version.  An⁴wa⁴, since like most projects, ⁴ou probabl⁴ target P⁴thon  cid:469  and P⁴thon  cid:470 , re- l⁴ing onl⁴ on the venv module isn’t reall⁴ an option. Sticking with virtualenv for now is probabl⁴ the best solution. Considering that the⁴ both function in an iden- tical manner, this shouldn’t be a problem.    cid:473  Unit testing  Breaking news! It’s  cid:469  cid:467  cid:468  cid:470  and there are still people who don’t have a polic⁴ of test- ing their projects. Now, the purpose of this book is not to convince ⁴ou to jump in and start unit testing. If ⁴ou need to be convinced, I suggest ⁴ou start b⁴ reading about the benefits of test-driven development. Writing code that is not tested is essentiall⁴ useless, as there’s no wa⁴ to conclusivel⁴ prove that it works.  This section will cover the P⁴thon tools ⁴ou can use to construct a great suite of tests. We’ll talk about how ⁴ou can utilise them to enhance ⁴our sotware, making it rock-solid and regression free!  6.1 The basics  Contrar⁴ to what ⁴ou ma⁴ believe, the writing and running of unit tests is reall⁴ simple in P⁴thon. It’s not intrusive or disruptive, and it’s going to help ⁴ou and other developers a lot in maintaining ⁴our sotware.  Your tests should be stored inside a tests submodule of ⁴our application or librar⁴. This allows ⁴ou to ship the tests as part of ⁴our module, so that the⁴ can be run or reused b⁴ an⁴one – even once ⁴our sotware is installed – without necessaril⁴ using the source package. This also prevents them from being installed b⁴ mistake in a top-level tests module.    cid:473 . cid:468 . THE BASICS   cid:475  cid:470   It’s usuall⁴ simpler to use a hierarch⁴ in ⁴our test tree that mimics the hierarch⁴ ⁴ou have in ⁴our module tree. This means that the tests covering the code of mylib foo bar.py should be inside mylib tests test_foobar.py; this makes things simpler when looking for the tests relating to a particular file. Example  cid:473 . cid:468  A reall⁴ simple test in test_true.py  def test_true  : assert True  This is the most simple unit test that can be written. To run it, ⁴ou simpl⁴ need to load the test_true.py file and run the test_true function defined within.  Obviousl⁴, following these steps for all of ⁴our test files and functions would be a pain. This is where the nose package comes to the rescue – once installed, it pro- vides the nosetests command, which loads ever⁴ file whose name starts with test_ and then executes all functions within that start with test_.  Therefore, with the test_true.py file in our source tree, running nosetests will give us the following output: $ nosetests -v test_true.test_true ... ok  --------------------------------------------------------- Ran 1 test in 0.003s  OK  On the other hand, as soon as a test fails, the output changes to indicate the failure, accompanied b⁴ the whole traceback. % nosetests -v test_true.test_true ... ok test_true.test_false ... FAIL    cid:473 . cid:468 . THE BASICS   cid:475  cid:471   ========================================================= FAIL: test_true.test_false  Traceback  most recent call last :  File " usr lib python2.7 dist-packages nose case.py", line 197, in ←֓  runTest self.test *self.arg   assert False  File " home jd test_true.py", line 5, in test_false  AssertionError --------------------------------------------------------- Ran 2 tests in 0.003s  FAILED  failures=1   A test fails as soon as an AssertionError exception is raised; assert does indeed raise an AssertionError as soon as its argument is evaluated to something false  False, None,  cid:467 … . If an⁴ other exception is raised, the test also errors out.  Simple, isn’t it? While simplistic, this approach is used b⁴ a lot of small projects, and works ver⁴ well. The⁴ don’t require tools or libraries other than than nose, and rel⁴ing on assert is good enough.  However, as ⁴ou start to write more sophisticated tests, ⁴ou’ll start to become frus- trated b⁴ things like the use of assert. Consider the following test: def test_key  :  a = ['a', 'b'] b = ['b'] assert a == b  When running nosetests, it gives the following output:    cid:473 . cid:468 . THE BASICS   cid:475  cid:472   $ nosetests -v test_complicated.test_key ... FAIL  ========================================================== FAIL: test_complicated.test_key Traceback  most recent call last :  File " usr lib python2.7 dist-packages nose case.py", line 197, in ←֓  runTest self.test *self.arg   assert a == b  AssertionError  File " home jd test_complicated.py", line 4, in test_key  --------------------------------------------------------- Ran 1 test in 0.001s  FAILED  failures=1   Alright, so a and b are diﬀerent and this test doesn’t pass. But how are the⁴ diﬀer- ent? assert doesn’t give us this information, just states that the assertion is wrong – not particularl⁴ useful.  Also, with such a basic ⁵ero framework approach, advanced usage such as skipping tests or executing actions before or ater running ever⁴ test can become painful.  This is where the unittest package comes in hand⁴. It provides tools that will help covering all of that – and good news is that unittest is part of the P⁴thon standard librar⁴.    cid:473 . cid:468 . THE BASICS   cid:475  cid:473   Warning unittest has been largely improved starting with Python 2.7, so if you are supporting earlier version of Python you may want to use its backport named unittest2. If you need to support Python 2.6, you can then use the following snippet to import the correct  module for any Python versions at runtime:  try:  import unittest2 as unittest  except ImportError: import unittest  If we rewrite the previous example using unittest, this is what it will look like: import unittest  class TestKey unittest.TestCase :  def test_key self : a = ['a', 'b'] b = ['b'] self.assertEqual a, b   As ⁴ou can see, the implementation isn’t much more complicated. All ⁴ou have to do is create a class that inherits from unittest.TestCase, and write a method that runs a test. Instead of using assert, we rel⁴ on a method provided b⁴ unittest. TestCase that provides an equalit⁴ tester. When run, it outputs the following: $ nosetests -v test_key  test_complicated.TestKey  ... FAIL  ========================================================= FAIL: test_key  test_complicated.TestKey  Traceback  most recent call last :    cid:473 . cid:468 . THE BASICS   cid:475  cid:474   File " home jd Source python-book test_complicated.py", line 7, in ←֓  test_key self.assertEqual a, b   AssertionError: Lists differ: ['a', 'b'] != ['b']  First differing element 0: a b  First list contains 1 additional elements. First extra element 1: b  - ['a', 'b'] + ['b']  FAILED  failures=1   --------------------------------------------------------- Ran 1 test in 0.001s  As ⁴ou can see, the output is much more useful. An assertion error is still raised, and the test is still being failed, but at least we have real information about wh⁴ it’s failing, which can help us to fix the problem. This is wh⁴ ⁴ou should definitel⁴ never use assert when writing test cases. An⁴one who tries to hack ⁴our code and ends up failing a test will definitel⁴ thank ⁴ou for having not used assert, and having thereb⁴ providing him her with debugging information right awa⁴.  unittest provides a few test functions that ⁴ou can use to speciali⁵e ⁴our tests, such as: assertDictEqual, assertEqual, assertTrue, assertFalse, assertGreater, assertGreaterEqual, assertIn, assertIs, assertIsIntance, assertIsNone, asser    cid:473 . cid:468 . THE BASICS   cid:475  cid:475   tIsNot, assertIsNotNone, assertItemsEqual, assertLess, assertLessEqual, asse rtListEqual, assertMultiLineEqual, assertNotAlmostEqual, assertNotEqual, ass ertTupleEqual, assertRaises, assertRaisesRegexp, assertRegexpMatches, etc. It would be a good idea to go through pydoc unittest and discover them all.  It’s also possible to deliberatel⁴ fail a test right awa⁴ using the fail msg  method. This can be convenient when ⁴ou know that a particular part of ⁴our code will def- initel⁴ raise an error if executed, but there isn’t a particular assertion to check for. Example  cid:473 . cid:469  Failing a test  import unittest  class TestFail unittest.TestCase :  def test_range self : for x in range 5 :  if x > 4:  self.fail "Range returned a too big value: %d" % x   It’s sometimes useful skip a test if it can’t be run – for example, ⁴ou ma⁴ wish to run a test conditionall⁴ based on the presence or absence of a particular librar⁴. To that end, ⁴ou can raise the unittest.SkipTest exception. When the test is raised, it is simpl⁴ marked as having been skipped. The convenient method unittest.Tes tCase.skipTest   can be used rather than raising the exception manuall⁴, as can the unittest.skip decorator: Example  cid:473 . cid:470  Skipping tests  import unittest  try:  import mylib  except ImportError:  mylib = None    cid:473 . cid:468 . THE BASICS   cid:475  cid:476   class TestSkipped unittest.TestCase : @unittest.skip "Do not run this"  def test_fail self :  self.fail "This should not be run"   @unittest.skipIf mylib is None, "mylib is not available"  def test_mylib self :  self.assertEqual mylib.foobar  , 42   def test_skip_at_runtime self :  if True:  self.skipTest "Finally I don't want to run it"   When executed, this test file will output the following: $ python -m unittest -v test_skip test_fail  test_skip.TestSkipped  ... skipped 'Do not run this' test_mylib  test_skip.TestSkipped  ... skipped 'mylib is not available' test_skip_at_runtime  test_skip.TestSkipped  ... skipped "Finally I don't ←֓  want to run it"  --------------------------------------------------------- Ran 3 tests in 0.000s  OK  skipped=3     cid:473 . cid:468 . THE BASICS   cid:476  cid:467   Tip As you may have noticed in Example 6.3, the unittest module provides a way to ex- ecute a Python module that contains tests. It is less convenient than using nosetests, as it does not discover test files on its own, but it can still be useful for running a particular  test module.  In man⁴ cases, there’s a need to execute a set of common actions before and ater running a test. unittest provides two particular methods called setUp and tearD own that are executed each time one of the test methods of a class is about to, or has been, called. Example  cid:473 . cid:471  Using setUp with unittest  import unittest  class TestMe unittest.TestCase :  def setUp self :  self.list = [1, 2, 3]  def test_length self : self.list.append 4  self.assertEqual len self.list , 4   def test_has_one self :  self.assertEqual len self.list , 3  self.assertIn 1, self.list   In this case, setUp is called before running test_length and before running test_ has_one. It can be reall⁴ hand⁴ to create objects that are worked with during each test; but ⁴ou need to be sure that the⁴ get recreated in a clean state before each test method is called. This is reall⁴ useful for creating test environments, oten referred    cid:473 . cid:469 . FIXTURES  to as "fixtures"  see Section  cid:473 . cid:469  .   cid:476  cid:468   Tip When using nosetests, you often might want You can select which test you want  to run only one particular  test.  to run by passing it as an argument – the  syntax is: path.to.your.module:ClassOfYourTest.test_method.  Be sure that  there’s  a colon between the module path and the class name.  You can also specify  path.to.your.module:ClassOfYourTest to execute an entire class, or path.to.your.module  to execute an entire module.  Tip It’s possible to run tests in parallel to speed things up. Simply add the --processes=N option to your nosetests invocation to spawn several nosetests processes. However, testrepository is a better alternative – this is discussed in Section 6.5.  6.2 Fixtures  In unit testing, fixtures represent components that are set up before a test, and cleaned up ater the test is done. It’s usuall⁴ a good idea to build a special kind of component for them, as the⁴ are reused in a lot of diﬀerent places. For exam- ple, if ⁴ou need an object which represents the configuration state of ⁴our applica- tion, there’s a chance ⁴ou ma⁴ want it to be initiali⁵ed before each test, and reset to its default values when the test is done. Rel⁴ing on temporar⁴ file creation also requires that the file is created before the test starts, and deleted once the test is done.  unittest onl⁴ provides the setUp and tearDown functions we alread⁴ evoked. How- ever, a mechanism exists to hook into these. The fixtures P⁴thon module  not part of the standard librar⁴  provides an eas⁴ mechanism for creating fixture classes and objects, such as the useFixture method.    cid:473 . cid:470 . MOCKING   cid:476  cid:469   The fixtures modules provides a few built-in fixtures, like fixtures.Environment Variable – useful for adding or changing a variable in os.environ that will be reset upon test exit. Example  cid:473 . cid:472  Using fixtures.EnvironmentVariable  import fixtures import os  class TestEnviron fixtures.TestWithFixtures :  def test_environ self :  fixture = self.useFixture   fixtures.EnvironmentVariable "FOOBAR", "42"   self.assertEqual os.environ.get "FOOBAR" , "42"   def test_environ_no_fixture self :  self.assertEqual os.environ.get "FOOBAR" , None   When ⁴ou can identif⁴ common patterns like these, it’s a good idea to create a fix- ture that ⁴ou can reuse over all ⁴our test cases. This greatl⁴ simplifies the logic, and shows exactl⁴ what ⁴ou are testing and in what manner.  Note If you’re wondering why the base class unittest.TestCase isn’t used in the examples in this section, it’s because fixtures.TestWithFixtures inherits from it.  6.3 Mocking  Mock objects are simulated objects that mimic the behaviour of real application objects, but in particular and controlled wa⁴s. These are especiall⁴ useful in creat-    cid:473 . cid:470 . MOCKING   cid:476  cid:470   ing environments that describe precisel⁴ the conditions for which ⁴ou would like to test code.  If ⁴ou are writing an HTTP client, it’s likel⁴ impossible  or at least extremel⁴ compli- cated  to spawn the HTTP server and test it through all scenarios, making it return ever⁴ possible value. It’s especiall⁴ diﬀicult to test for all failure scenarios.  A much simpler option is to build a set of mock objects that model these particular scenarios, and to use them as environment for testing ⁴our code.  The standard librar⁴ for creating mock objects in P⁴thon is mock. Starting with P⁴thon  cid:470 . cid:470 , it has been merged into the P⁴thon standard librar⁴ as unittest.mock. You can therefore use a snippet like: try:  To maintain backward compatibilit⁴ between P⁴thon  cid:470 . cid:470  and earlier versions.  from unittest import mock  except ImportError:  import mock  Mock is prett⁴ simple to use: Example  cid:473 . cid:473  Basic mock usage  >>> import mock >>> m = mock.Mock   >>> m.some_method.return_value = 42 >>> m.some_method   42 >>> def print_hello  : ... ... >>> m.some_method.side_effect = print_hello >>> m.some_method    print "hello world!"     cid:473 . cid:470 . MOCKING   cid:476  cid:471   print "hello world!"  return 43  hello world! >>> def print_hello  : ... ... ... >>> m.some_method.side_effect = print_hello >>> m.some_method   hello world! 43 >>> m.some_method.call_count 3  Even using just this set of features, ⁴ou should be able to mimic a lot of ⁴our internal objects in order to fake various data scenarios. Mock uses the action assertion pattern: this means that once ⁴our test has run, ⁴ou will have to check that the actions ⁴ou are mocking were correctl⁴ executed. Example  cid:473 . cid:474  Checking method calls >>> import mock >>> m = mock.Mock   >>> m.some_method 'foo', 'bar'    >>> m.some_method.assert_called_once_with 'foo', 'bar'  >>> m.some_method.assert_called_once_with 'foo', mock.ANY  >>> m.some_method.assert_called_once_with 'foo', 'baz'  Traceback  most recent call last :  File " ", line 1, in   File " usr lib python2.7 dist-packages mock.py", line 846, in ←֓  assert_called_once_with return self.assert_called_with *args, **kwargs   File " usr lib python2.7 dist-packages mock.py", line 835, in ←֓    cid:473 . cid:470 . MOCKING   cid:476  cid:472   assert_called_with raise AssertionError msg   AssertionError: Expected call: some_method 'foo', 'baz'  Actual call: some_method 'foo', 'bar'   As ⁴ou can see, it’s eas⁴ enough to pass a mock object to an⁴ part of ⁴our code, and to check later if the code has been called with whatever argument it was supposed to have. If ⁴ou don’t know what arguments ma⁴ have been passed, ⁴ou can use mock.ANY as a value; that will match an⁴ argument passed to ⁴our mock method.  Sometimes ⁴ou ma⁴ need to a some function, method or object from an external module. mock provides a set of patching functions to that end. Example  cid:473 . cid:475  Using mock.patch  raise IOError "Testing!"   >>> import mock >>> import os >>> def fake_os_unlink path : ... ... >>> with mock.patch 'os.unlink', fake_os_unlink : ... ... Traceback  most recent call last :  os.unlink 'foobar'   File " ", line 2, in   File " ", line 2, in fake_os_unlink  IOError: Testing!  With the mock.patch method, it’s possible to change an⁴ part of an external piece of code – making it behave in the required wa⁴ in order to test all conditions in ⁴our sotware. Example  cid:473 . cid:476  Using mock.patch to test a set of behaviour    cid:476  cid:473    cid:473 . cid:470 . MOCKING  import requests import unittest import mock  pass  try:  except IOError:  pass  else:  class WhereIsPythonError Exception :  def is_python_still_a_programming_language  :  r = requests.get "http:  python.org"   def get_fake_get status_code, content :  m = mock.Mock   m.status_code = status_code m.content = content def fake_get url :  return m  return fake_get  def raise_get url :  raise IOError "Unable to fetch url %s" % url   class TestPython unittest.TestCase :  @mock.patch 'requests.get', get_fake_get   if r.status_code == 200:  return 'Python is a programming language' in r.content  raise WhereIsPythonError "Something bad happened"     cid:473 . cid:470 . MOCKING   cid:476  cid:474   200, 'Python is a programming language for sure'    def test_python_is self :  self.assertTrue is_python_still_a_programming_language     @mock.patch 'requests.get', get_fake_get   200, 'Python is no more a programming language'    def test_python_is_not self :  self.assertFalse is_python_still_a_programming_language     @mock.patch 'requests.get', get_fake_get   404, 'Whatever'    def test_bad_status_code self :  self.assertRaises WhereIsPythonError,  is_python_still_a_programming_language   @mock.patch 'requests.get', raise_get  def test_ioerror self :  self.assertRaises WhereIsPythonError,  is_python_still_a_programming_language   Example  cid:473 . cid:476  uses the decorator version of mock.patch, this does not change its be- haviour, but is easier to use when ⁴ou need to use mocking within the context of an entire test function.  B⁴ using mocking we can simulate an⁴ problem – such as a Web server returning a  cid:471  cid:467  cid:471  error, or network issues arising. We can make sure that our code returns the correct values, or raises the correct exception in ever⁴ case – ensuring that our code alwa⁴s behaves as expected.    cid:473 . cid:471 . SCENARIOS  6.4 Scenarios   cid:476  cid:475   When unit testing, it is common to require that a set of tests be run against diﬀerent versions of an object. You ma⁴ want to run the same error-handling test with a bunch of diﬀerent objects that trigger that error; or ⁴ou ma⁴ want to run an entire test suite against diﬀerent drivers.  This last case is one that we heavil⁴ relied on in Ceilometer. Ceilometer provides an abstract class that we call the storage API. An⁴ driver can implement this base abstract class and register itself to become a driver. The sotware loads the config- ured storage driver when required, and uses the implemented storage API to store or retrieve data. In this case, what need is a class of unit tests that runs against each driver – meaning against each implementation of this storage API – to be sure that the⁴ conform to what the callers expect.  The natural wa⁴ of doing this is to use mixin classes; on one side, ⁴ou would have a class with unit tests, and on the other side a class with the specific driver usage setup. import unittest  class MongoDBBaseTest unittest.TestCase :  def setUp self :  self.connection = connect_to_mongodb    class MySQLBaseTest unittest.TestCase :  def setUp self :  self.connection = connect_to_mysql    class TestDatabase unittest.TestCase :  def test_connected self :  self.assertTrue self.connection.is_connected       cid:473 . cid:471 . SCENARIOS   cid:476  cid:476   class TestMongoDB TestDatabase, MongoDBBaseTest :  class TestMySQL TestDatabase, MySQLBaseTest :  pass  pass  Unfortunatel⁴, in the long run this method is far from convenient or scalable.  A better technique does exist, using the testscenarios package. This package pro- vides an eas⁴ wa⁴ to run a class test against a diﬀerent set of scenarios generated at run-time. Using testscenarios, I have rewritten part of Example  cid:473 . cid:476  to illustrate mocking as covered in Section  cid:473 . cid:470 . Example  cid:473 . cid:468  cid:467  testscenarios basic usage  import mock import requests import testscenarios  class WhereIsPythonError Exception :  pass  def is_python_still_a_programming_language  :  r = requests.get "http:  python.org"  if r.status_code == 200:  return 'Python is a programming language' in r.content  raise WhereIsPythonError "Something bad happened"   def get_fake_get status_code, content :  m = mock.Mock   m.status_code = status_code    cid:473 . cid:471 . SCENARIOS   cid:468  cid:467  cid:467   m.content = content def fake_get url :  return m  return fake_get  class TestPythonErrorCode testscenarios.TestWithScenarios :  scenarios = [   'Not found', dict status=404  ,  'Client error', dict status=400  ,  'Server error', dict status=500  ,  ]  ok  ok  ok  def test_python_status_code_handling self :  with mock.patch 'requests.get',  get_fake_get   self.status, 'Python is a programming language for sure'  :  self.assertRaises WhereIsPythonError,  is_python_still_a_programming_language   Even though onl⁴ one test seems to be defined, testscenarios runs the test three times – because we have defined three scenarios. % python -m unittest -v test_scenario test_python_status_code_handling  test_scenario.TestPythonErrorCode  ... ←֓  test_python_status_code_handling  test_scenario.TestPythonErrorCode  ... ←֓  test_python_status_code_handling  test_scenario.TestPythonErrorCode  ... ←֓    cid:473 . cid:471 . SCENARIOS   cid:468  cid:467  cid:468   --------------------------------------------------------- Ran 3 tests in 0.001s  OK  As can see, all we need to construct the scenario list is a tuple list that consists of the scenario name as first argument, and as a second argument the dictionar⁴ of attributes to be added to the test class for this scenario.  It is eas⁴ enough to imagine another use: where instead of storing a single value as an attribute for each test, ⁴ou could instantiate a particular driver and run all the tests of the class against it. Example  cid:473 . cid:468  cid:468  Using testscenarios to test drivers  import testscenarios from myapp import storage  class TestPythonErrorCode testscenarios.TestWithScenarios :  scenarios = [   'MongoDB', dict driver=storage.MongoDBStorage    ,  'SQL', dict driver=storage.SQLStorage    ,  'File', dict driver=storage.FileStorage    ,  ]  def test_storage self :  self.assertTrue self.driver.store {'foo': 'bar'}    def test_fetch self :  self.assertEqual self.driver.fetch 'foo' , 'bar'     cid:473 . cid:472 . TEST STREAMING AND PARALLELISM   cid:468  cid:467  cid:469   Note If you wonder why there is no need to use the base class unittest.TestCase in the previous examples, it’s because testscenarios.TestWithScenarios inherits from it.  6.5 Test streaming and parallelism  When performing a lot of tests, it can be useful to anal⁴⁵e them as the⁴ are run. The default behaviour of tools like nosetests is to output the result to stdout – which is not reall⁴ convenient to parse or anal⁴⁵e.  subunit is a P⁴thon module that provides a streaming protocol for test results. It allows for a number of interesting things, such as aggregating test results ¹ or to record and archive test runs, etc.  Running a test using subunit is simple enough: $ python -m subunit.run test_scenario  The output of this command is binar⁴ data, so unless ⁴ou have the abilit⁴ to sight- read the subunit protocol, it wouldn’t be interesting to reproduce it’s output directl⁴ here. However, subunit also comes with a set of tools to transform this binar⁴ stream into something smoother: Example  cid:473 . cid:468  cid:469  Using subunit2pyunit  $ python -m subunit.run test_scenario  subunit2pyunit test_scenario.TestPythonErrorCode.test_python_status_code_handling Not ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Not ←֓  found   found  ... ok  ¹Even from diﬀerent source programs or languages    cid:473 . cid:472 . TEST STREAMING AND PARALLELISM   cid:468  cid:467  cid:470   test_scenario.TestPythonErrorCode.test_python_status_code_handling Client ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Client ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Server ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Server ←֓  --------------------------------------------------------- Ran 3 tests in 0.061s  error   error   error  ... ok  error  ... ok  OK  Now this is something that we can understand – ⁴ou should recogni⁵e the test suite with scenarios from Section  cid:473 . cid:471 . Other tools worth mentioning include subunit2 csv, subunit2gtk and subunit2junitxml.  subunit is also able to automaticall⁴ discover which test to run, when it is passed the discover argument. $ python -m subunit.run discover  subunit2pyunit test_scenario.TestPythonErrorCode.test_python_status_code_handling Not ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Not ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Client ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Client ←֓  test_scenario.TestPythonErrorCode.test_python_status_code_handling Server ←֓  found  ... ok  error  ... ok  found   error   error     cid:473 . cid:472 . TEST STREAMING AND PARALLELISM   cid:468  cid:467  cid:471   test_scenario.TestPythonErrorCode.test_python_status_code_handling Server ←֓  error  ... ok  --------------------------------------------------------- Ran 3 tests in 0.061s  OK  You can list tests, rather than running them, b⁴ passing the argument --list. To view the results, ⁴ou can use subunit-ls: $ python -m subunit.run discover --list  subunit-ls --exists test_request.TestPython.test_bad_status_code test_request.TestPython.test_ioerror test_request.TestPython.test_python_is test_request.TestPython.test_python_is_not test_scenario.TestPythonErrorCode.test_python_status_code_handling  Tip You can also load a list of tests that you want to run – rather than running all tests – by using the --load-list option.  In large applications the number of tests can be overwhelming, so having programs to handle the stream of results is ver⁴ useful. The testrepository package is in- tended to do just that; it provides the testr program, which ⁴ou can use to handle a database of ⁴our test run. $ testr init $ touch .testr.conf % python -m subunit.run test_scenario  testr load Ran 4 tests in 0.001s    cid:473 . cid:472 . TEST STREAMING AND PARALLELISM   cid:468  cid:467  cid:472   PASSED  id=0  $ testr failing PASSED  id=0  $ testr last Ran 3 tests in 0.001s PASSED  id=0  $ testr slowest Test id Runtime  s  ---------------------------------------------- ----------- test_python_status_code_handling Not found  0.000 test_python_status_code_handling Server error  0.000 test_python_status_code_handling Client error  0.000 $ testr stats runs=1  Once the subunit stream of tests has been run and loaded inside testrepository, it is possible to manipulate it easil⁴ using the testr command.  Obviousl⁴, this is tedious to do b⁴ hand each time ⁴ou want to run tests. Instead, ⁴ou should teach testr how it should run ⁴our tests, so that it can load the results itself. This can be accomplished b⁴ editing the .testr.conf file at the root of ⁴our project. Example  cid:473 . cid:468  cid:470  A .testr.conf file [DEFAULT] test_command=python -m subunit.run discover . $LISTOPT $IDOPTION ②1 test_id_option=--load-list $IDFILE ②2 test_list_option=--list ②3  ②1  ②2  Command to run when calling testr run  Command to run to load a test list    cid:473 . cid:472 . TEST STREAMING AND PARALLELISM   cid:468  cid:467  cid:473   ②3  Command to run to list tests  The first line, test_command, is the one that is the most interesting. Now, all that we need to do to load tests into testrepository and perform them is to run testr run.  Note If you’re accustomed to running nosetests, testr run is now the equivalent com- mand.  Two other options enable us to run the tests in parallel. This is simple enough to do – all ⁴ou need to do is add the --parallel switch to testr run. Running ⁴our tests in parallel can speed up the process considerabl⁴. Example  cid:473 . cid:468  cid:471  Running testr run --parallel  $ testr run --parallel running=python -m subunit.run discover . --list running=python -m subunit.run discover . --load-list  tmp tmpiMq5Q1 running=python -m subunit.run discover . --load-list  tmp tmp7hYEkP running=python -m subunit.run discover . --load-list  tmp tmpP_9zBc running=python -m subunit.run discover . --load-list  tmp tmpTejc5J Ran 26  +10  tests in 0.029s  -0.001s  PASSED  id=7, skips=3   Under the hood, testr runs the test listing operation, splits the test list into several sublists, and creates a separate P⁴thon process to run each sublist of test. B⁴ de- fault, the number of sublists is equal to the number of CPUs in the machine being used. You can override the number of processes that b⁴ adding the --concurrency flag. $ testr run --parallel --concurrency=2    cid:473 . cid:473 . COVERAGE   cid:468  cid:467  cid:474   As ⁴ou can imagine, there’s a lot of possibilities opened up b⁴ tools such as subunit and testrepository that have onl⁴ be skimmed through in this section. I believe it’s worth being familiar with them, because testing can greatl⁴ influence the qualit⁴ of the sotware ⁴ou will produce and release. Having powerful tools like these can save a lot of time.  testrepository also integrates with setuptools and deplo⁴s a testr command for it. This provides easier integration with setup.py-based workflows – ⁴ou can, for ex- ample, document ⁴our entire project around setup.py. The command setup.py testr accepts a few options, such as --testr-args – which adds more options to the testr run, or --coverage, which will be covered in the next section.  6.6 Coverage  Code coverage is a tool which complements unit testing. It uses code anal⁴sis tools and tracing hooks to determine which lines of ⁴our code have been executed; when used during a unit test run, it can show ⁴ou which parts of ⁴our code base have been crossed over and which parts have not.  Writing tests is useful; but having a wa⁴ to know what part of ⁴our code ⁴ou ma⁴ have missed is the cherr⁴ on the cake.  Obviousl⁴, the first thing to do is to install the coverage P⁴thon module on ⁴our s⁴stem. Once this is done ⁴ou will have access to the coverage program command from ⁴our shell.²  Using coverage in standalone mode is straightforward, and can be useful- it could lead ⁴ou to part of ⁴our programs that are never run, and which might be "dead code". In addition, using it while ⁴our unit tests are running provides an obvious benefit: ⁴ou’ll know which parts of the code are not being tested. The test tools ²The command ma⁴ also be named python-coverage, if ⁴ou install coverage through ⁴our oper-  ating s⁴stem installation sotware. That is the case on Debian, for example.    cid:473 . cid:473 . COVERAGE   cid:468  cid:467  cid:475   we’ve talked about so far are all integrated with coverage.  When using nose, ⁴ou onl⁴ need to add a few option switches to generate a nice code coverage output: Example  cid:473 . cid:468  cid:472  Using nosetests --with-coverage  $ nosetests --cover-package=ceilometer --with-coverage tests test_pipeline ←֓  .py  .............................................. Name ceilometer ceilometer.pipeline  Stmts 0 152  Miss Cover 100% 87%  0 20  Missing  49, 59, 113, ←֓  127-128, 188-192, 275-280, 350-362  ceilometer.publisher ceilometer.sample ceilometer.transformer ceilometer.transformer.accumulator ceilometer.transformer.conversions  12 31 15 17 59  32-34 81-84 26-32, 35  3 4 3 0 0  75% 87% 80% 100% 100%  TOTAL  888  393  56%  --------------------------------------------------------- Ran 46 tests in 0.170s  OK  Adding the --cover-package option is important, since otherwise ⁴ou will see ev- ery P⁴thon package used, including standard librar⁴ or third-part⁴ modules. The output includes the lines of code that are were not run – and which therefore have no tests. All ⁴ou need to do now is spawn ⁴our favorite text editor and start writing some.    cid:473 . cid:473 . COVERAGE   cid:468  cid:467  cid:476   But ⁴ou can do better, and make coverage generate nice HTML reports. Simpl⁴ add the --cover-html flag, and the cover director⁴ from which ⁴ou ran the command will be populated with HTML pages. Each page will show ⁴ou which parts of ⁴our source code were or were not run.    cid:473 . cid:473 . COVERAGE   cid:468  cid:468  cid:467   Figure  cid:473 . cid:468 : Coverage of ceilometer.publisher  If ⁴ou want to be that gu⁴, ⁴ou can use the option --cover-min-percentage=COVE    cid:473 . cid:474 . USING VIRTUALENV WITH TOX   cid:468  cid:468  cid:468   R_MIN_PERCENTAGE, which will make the test suite fail if a minimum percentage of the code is not executed when the test suite is run.  Warning A code coverage score of 100% doesn’t necessarily mean that the code is entirely tested  and that you can rest.  It only proves that your whole code path has been run; there is  no indication that every possible condition has been tested. So while being a respectable  goal, it doesn’t indicate anything conclusive.  When using testrepository, coverage can be run using setuptools integration. Example  cid:473 . cid:468  cid:473  Using coverage with testrepository  $ python setup.py testr --coverage  This will automaticall⁴ run ⁴our test suite with coverage and generate an HTML re- port in the cover director⁴.  You should then use this information to consolidate ⁴our test suite and add tests for an⁴ code that is currentl⁴ not being run. This is important; it facilitates later project maintenance, and increases ⁴our code’s overall qualit⁴.  6.7 Using virtualenv with tox  In Chapter  cid:472 , the use of virtual environments is presented and discussed. One of their main uses is to provide a clean environment for running unit tests. It would be reall⁴ sad if ⁴ou thought that ⁴our tests were working, when in fact ⁴ou were not, for example, respecting the dependenc⁴ list.  You could write a script to deplo⁴ a virtual environment, install setuptools, and then install all of the dependencies required for both ⁴our application librar⁴ run- time and unit tests. But this is such a common use case that an application dedi- cated to this task has alread⁴ been built: tox.    cid:473 . cid:474 . USING VIRTUALENV WITH TOX   cid:468  cid:468  cid:469   Tox aims to automate and standardi⁵e how tests are run in P⁴thon. To that end, it provides ever⁴thing needed to run an entire test suite in a clean virtual environ- ment, while also installing ⁴our application to check that the installation works fine.  Before using tox, ⁴ou need to provide a configuration file. This file is named tox. ini and should be placed in the root director⁴ of ⁴our project, beside ⁴our setup. py file. $ touch tox.ini  You can now run tox successfull⁴: % tox GLOB sdist-make:  home jd project setup.py python create:  home jd project .tox python python inst:  home jd project .tox dist project-1.zip ____________________ summary _____________________  python: commands succeeded congratulations :   Obviousl⁴ this alone is not ver⁴ useful. In this instance, tox creates a virtual envi- ronment in .tox python using its default P⁴thon version, uses setup.py to create a distribution of ⁴our package and then installs it inside this virtual environment. No commands are then run, because we didn’t specif⁴ an⁴ in the configuration file.  We can change this default behaviour b⁴ adding a command that will be run inside our test environment. Editing tox.ini to include the following: [testenv] commands=nosetests  will run the command nosetests will likel⁴ fail, since we don’t have nosetests in- stalled in the virtual environment. We need to list it as part of the dependencies to be installed.    cid:473 . cid:474 . USING VIRTUALENV WITH TOX   cid:468  cid:468  cid:470   [testenv] deps=nose commands=nosetests  When run, tox will now recreate the environment, install the new dependenc⁴ and run the command nosetests, which will execute all of our unit tests. Obviousl⁴, we might want to add more dependencies – ⁴ou can list them in the deps configuration option, but ⁴ou can also use the -rfile s⁴ntax to read from a file. If ⁴ou’re using pbr to manage ⁴our setup.py file, ⁴ou know that it reads the dependencies from a file called requirements.txt. It is therefore a good idea to tell tox to use that file too: [testenv] deps=nose  -rrequirements.txt  commands=nosetests  The [testenv] section of the file defines the parameters for all virtual environments managed b⁴ tox. But as mentioned previousl⁴, tox can manage multiple P⁴thon virtual environments – indeed, it’s possible to run our tests under a P⁴thon version other than the default one b⁴ passing the -e flag to tox: % tox -e py26 GLOB sdist-make:  home jd project setup.py py26 create:  home jd project .tox py26 py26 installdeps: nose py26 inst:  home jd project .tox dist rebuildd-1.zip py26 runtests: commands[0]  nosetests .......  ---------------------------------------------------------    cid:473 . cid:474 . USING VIRTUALENV WITH TOX   cid:468  cid:468  cid:471   Ran 7 tests in 0.029s  OK ____________________ summary _____________________  py26: commands succeeded congratulations :   B⁴ default, tox can simulate man⁴ environments: py cid:469  cid:471 , py cid:469  cid:472 , py cid:469  cid:473 , py cid:469  cid:474 , py cid:470  cid:467 , py cid:470  cid:468 , py cid:470  cid:469 , py cid:470  cid:470 , jython and pypy! You can even add ⁴our own. To add an environment or to create a new one, ⁴ou just need to add another section named [testenv:_envn ame_]. If we want to run a diﬀerent command for one of the environments, it’s eas⁴ with the following tox.ini file: [testenv] deps=nose commands=nosetests  [testenv:py27] commands=pytest  This onl⁴ overrides the commands for the py27 environment; so nose will still be installed as part of the dependencies when running tox -e py27, but the command pytest will be run instead. We can create a new environment with an unsupported version of P⁴thon right awa⁴: [testenv] deps=nose commands=nosetests  [testenv:py21] basepython=python2.1    cid:473 . cid:474 . USING VIRTUALENV WITH TOX   cid:468  cid:468  cid:472   We can now  attempt to  use P⁴thon  cid:469 . cid:468  to run our test suite – although I don’t think it will work.  Now, it is likel⁴ that ⁴ou will want to support multiple P⁴thon versions. So it would be great to have tox run all the tests for all the P⁴thon versions ⁴ou want to support b⁴ default. This can be done b⁴ specif⁴ing the environment list ⁴ou want to use when tox is run without arguments: [tox] envlist=py26,py27,py33,pypy  When tox is launched without an⁴ further arguments, all four environments listed will be created, populated with the dependencies and the application, and then the command nosetests will be run.  We can also use tox to integrate other tests like flake8, as discussed in Section  cid:468 . cid:471 . [tox] envlist=py26,py27,py33,pypy,pep8  [testenv] deps=nose commands=nosetests  [testenv] deps=nose commands=nosetests  [testenv:pep8] deps=flake8 commands=flake8  In this case, the pep cid:475  environment will be run using the default version of P⁴thon,    cid:473 . cid:475 . TESTING POLICY  which is probabl⁴ fine.³   cid:468  cid:468  cid:473   Tip When running tox, you will spot that all of the environments are built and run in sequence. This can often make the process very long. Since the virtual environments are isolated, nothing prevents you from running tox commands in parallel. This is exactly what the detox package does, by providing a detox command which runs all of the default envi- ronments from envlist in parallel. You should pip install it!  6.8 Testing policy  Having testing code embedded in ⁴our project is wonderful, but how ⁴ou run it is also extremel⁴ important. There are too man⁴ projects that have test code which la⁴s around, but which fails to be run for some reason.  While this topic is not strictl⁴ limited to P⁴thon, I consider it important enough to emphasi⁵e here: ⁴ou should have a ⁵ero tolerance polic⁴ on untested code. No code should be merged unless there is a proper set of unit tests to cover it.  The minimum that ⁴ou should aim for is to be sure that each of the commits ⁴ou push pass all the tests. Having an automated wa⁴ to do that is even better.  For example, OpenStack relies on a specific workflow based on Gerrit, Jenkins and Zuul. Each commit pushed goes through the code review s⁴stem provided b⁴ Gerrit, and Zuul is in charge of running a set of testing jobs against it using Jenkins. Jenkins runs the unit testing, and various higher-level functional tests for each project. This ensures that the submitted patches pass all tests. Code reviewing b⁴ a couple of developers makes sure that all code that is committed has associated unit tests.  If ⁴ou are using the popular GitHub hosting service, Travis CI provides a wa⁴ to run a test ater each push or merge, or against pull requests that are submitted. While it is  ³You can still specif⁴ the basepython option if ⁴ou want to change that    cid:473 . cid:476 . INTERVIEW WITH ROBERT COLLINS   cid:468  cid:468  cid:474   unfortunate that this done post-push, it’s still a fantastic wa⁴ to track regressions. Travis supports all significant P⁴thon versions out of the box, and it’s possible to customi⁵e it to a high degree. Once ⁴ou’ve activated Travis on ⁴our project via their Web interface, adding a file is simple: .travis.yml does the job for ⁴ou. Example  cid:473 . cid:468  cid:474  A .travis.yml example file  language: python python:  - "2.7" - "3.3"   command to install dependencies install: "pip install -r requirements.txt --use-mirrors"  command to run tests script: nosetests  Wherever ⁴our code is hosted, these da⁴s it is alwa⁴s possible to aim for some sort of automatic testing of ⁴our sotware, and to make sure that ⁴ou are going forward with ⁴our project – not going backward b⁴ adding more bugs.  6.9 Interview with Robert Collins  You ma⁴ have alread⁴ used one of Robert’s programs, without knowing – he is, among other things, the original author of the Bazaar distributed version control s⁴stem. Toda⁴, he is a Distinguished Technologist at HP Cloud Services, where he works on OpenStack. Robert has written a lot of the P⁴thon tools described in this book, such as fixtures, testscenarios, testrespository and even python-subunit.    cid:473 . cid:476 . INTERVIEW WITH ROBERT COLLINS   cid:468  cid:468  cid:475   What kind of testing policy would you advise using? When is it accept- able not to test code? I think it’s an engineering trade-oﬀ – considering the likelihood of fail- ure slipping through to production undetected, the cost of an undetected failure of that component, the si⁵e and cohesion of the team doing the work… Take OpenStack –  cid:468  cid:473  cid:467  cid:467  contributors – a nuanced polic⁴ is ver⁴ hard to work with there, as so man⁴ people have opinions. Generall⁴ speaking, there should be some automated check as part of landing in trunk that the code will do what it is intended to do and that what it is in- tended to do is what is needed. Oten that speaks to requiring functional tests that might be in diﬀerent code bases. Unit tests are great for speed and pinning down corner cases. I think it’s ok to var⁴ the balance between st⁴les of testing, as long as there is testing.  Where the cost of testing is ver⁴ high and the returns are ver⁴ low, I think it’s fine to make an informed decision not to test, but that’s a relativel⁴ rare situation: most things can be tested fairl⁴ cheapl⁴, and the benefit of catching errors earl⁴ is usuall⁴ quite high. What are the best strategies to put in place when writing Python code in order to make testing easier, and improve its quality? Separate out concerns – don’t do multiple things in one place; this makes reuse easier, and that makes it easier to put test doubles in place. Take a pure functional approach when ⁴ou can  e.g. in a single method either cal- culate something, or change some state, but where possible avoid doing    cid:473 . cid:476 . INTERVIEW WITH ROBERT COLLINS   cid:468  cid:468  cid:476   both . That wa⁴ ⁴ou can test all of the calculating behaviour without deal- ing with state changes – such as writing to a database, talking to an HTTP server, etc. The benefit works the other wa⁴ around too – ⁴ou can replace the calculation logic for tests to provoke corner case behaviour and detect via mocks   test doubles that the expected state propagation happens as desired. The most heinous stuﬀ to test IME is deepl⁴ la⁴ered stacks with complex cross-la⁴er behavioural dependencies. There ⁴ou want to evolve the code so that the contract between la⁴ers is simple, predictable, and most usefull⁴ for testing – replaceable. In your opinion, what’s the best way to organize unit tests in source code? Having a hierarch⁴ like $ROOT $PACKAGE tests – but I do just one for a whole source tree  vs e.g. $ROOT $PACKAGE $SUBPACKAGE tests .  Within tests, I oten mirror the structure of the rest of the source tree: $ROOT $PACKAGE foo.py would be tested in $ROOT $PACKAGE tests tes t_foo.py.  There should be no imports from tests b⁴ the rest of the tree except per- haps a test_suite load_tests function in the top level __init__. This per- mits easil⁴ detaching the tests for small footprint installations. What are the tools that can be employed to build functional tests in Python? I just use whichever flavour of unittest is in use in the project: it’s suf- ficientl⁴ flexible  particularl⁴ with things like testresources and parallel runners  to cater for most needs. How do you envision the future of unit testing libraries and frame- works in Python? The big challenges I see are:    cid:473 . cid:476 . INTERVIEW WITH ROBERT COLLINS   cid:468  cid:469  cid:467     the continued expansion of parallel capabilities in new machines –  cid:471  CPU phones now. Existing unit test internal APIs aren’t optimised for parallel workloads. M⁴ StreamResult work is aimed directl⁴ at this;    more complex scheduling support – a less ugl⁴ solution for the problems  that class and module scoped setup aim at;    finding some wa⁴ to consolidate the large variet⁴ of frameworks we have toda⁴: it would be great to be able to get a consolidated view across mul- tiple projects – for integration testing – that have diﬀerent test runners in use.    cid:474  Methods and decorators  P⁴thon provides decorators as a hand⁴ wa⁴ to modif⁴ functions. The⁴ were first introduced with classmethod   and staticmethod   in P⁴thon  cid:469 . cid:469 , but were over- hauled through PEP  cid:470  cid:468  cid:475  into something more flexible and readable. P⁴thon pro- vides a few decorators  including the two mentioned above  right out of the box, but it seems that most developers don’t understand how the⁴ actuall⁴ work behind the scenes. This chapter aims to change that.  7.1 Creating decorators  A decorator is essentiall⁴ a function that takes another function as an argument and replaces it with a new, modified function. Odds are good ⁴ou’ve alread⁴ used decorators to make ⁴our own wrapper functions. The simplest possible decorator is the identit⁴ function, which does nothing except return the original function: def identity f :  return f  You can then use ⁴our decorator like this: @identity def foo  :  return 'bar'    cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:469   Which is the same as: def foo  :  return 'bar'  foo = identity foo   This decorator is useless, but it works. It just does nothing. Example  cid:474 . cid:468  A registering decorator _functions = {} def register f :  global _functions _functions[f.__name__] = f return f  @register def foo  : return bar  In this example, we register and store functions in a dictionar⁴ so we can retrieve them b⁴ their name later from that dictionar⁴.  In the following sections, I’ll explain the standard decorators that P⁴thon provides and how  and when  to use them.  The primar⁴ use case for decorators is factoring common code that needs to be called before, ater, or around multiple function. If ⁴ou ever wrote Emacs Lisp code ⁴ou ma⁴ have used defadvice that allows ⁴ou to define code called around a func- tion. Same things appl⁴ for developers having used the fabulous method combina- tions brought b⁴ CLOS ¹.  Consider a set of functions that are called and need to check that the user name that the⁴ receive as argument: class Store object :  def get_food self, username, food :  ¹The Common Lisp Object S⁴stem    cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:470   if username != 'admin':  raise Exception "This user is not allowed to get food"   return self.storage.get food   def put_food self, username, food :  if username != 'admin':  raise Exception "This user is not allowed to get food"   self.storage.put food   The obvious first step here is to factor the checking code: def check_is_admin username :  if username != 'admin':  raise Exception "This user is not allowed to get food"   class Store object :  def get_food self, username, food :  check_is_admin username  return self.storage.get food   def put_food self, username, food :  check_is_admin username  self.storage.put food   Now our code looks a bit cleaner. But we can do even better if we use a decorator: def check_is_admin f :  def wrapper *args, **kwargs :  if kwargs.get 'username'  != 'admin':  raise Exception "This user is not allowed to get food"   return f *args, **kwargs   return wrapper    cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:471   class Store object : @check_is_admin def get_food self, username, food :  return self.storage.get food   @check_is_admin def put_food self, username, food :  self.storage.put food   Using decorators like this makes it easier to manage common functionalit⁴. This is probabl⁴ old hat to ⁴ou if ⁴ou have an⁴ serious P⁴thon experience, but what ⁴ou might not reali⁵e is that this naive approach to implementing decorators has some major drawbacks.  return f *args, **kwargs   def wrapper *args, **kwargs :  if kwargs.get 'username'  != 'admin':  raise Exception "This user is not allowed to get food"   As mentioned before, a decorator replaces the original function with a new one built on-the-fl⁴. However, this new function lacks man⁴ of the attributes of the original function, such as its docstring and its name: >>> def is_admin f : ... ... ... ... ... ... >>> def foobar username="someone" : ... ... ... >>> foobar.func_doc 'Do crazy stuff.' >>> foobar.__name__  """Do crazy stuff.""" pass  return wrapper    cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:472   """Do crazy stuff.""" pass  'foobar' >>> @is_admin ... def foobar username="someone" : ... ... ... >>> foobar.__doc__ >>> foobar.__name__ 'wrapper'  Fortunatel⁴, the functools module included in P⁴thon solves this problem with the update_wrapper function, which copies these attributes to the wrapper itself. The source code of update_wrapper is self-explanator⁴: Example  cid:474 . cid:469  Source code of functools.update_wrapper in P⁴thon  cid:470 . cid:470   WRAPPER_ASSIGNMENTS =  '__module__', '__name__', '__qualname__', '__doc__',  '__annotations__'   WRAPPER_UPDATES =  '__dict__',  def update_wrapper wrapper, wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES :  wrapper.__wrapped__ = wrapped for attr in assigned:  value = getattr wrapped, attr   except AttributeError:  try:  pass  else:  setattr wrapper, attr, value   for attr in updated:    cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:473   getattr wrapper, attr .update getattr wrapped, attr, {}     Return the wrapper so this can be used as a decorator via partial   return wrapper  """Do crazy stuff.""" pass  If we take our previous example and use this function to update our wrapper, things work much more nicel⁴: >>> def foobar username="someone" : ... ... ... >>> foobar = functools.update_wrapper is_admin, foobar  >>> foobar.__name__ 'foobar' >>> foobar.__doc__ 'Do crazy stuff.'  It can get tedious to use update_wrapper manuall⁴ when creating decorators, so functools provides a decorator for decorators called wraps: Example  cid:474 . cid:470  Using functools.wraps  import functools  def check_is_admin f : @functools.wraps f  def wrapper *args, **kwargs :  return f *args, **kwargs   return wrapper  class Store object :  if kwargs.get 'username'  != 'admin':  raise Exception "This user is not allowed to get food"     cid:474 . cid:468 . CREATING DECORATORS   cid:468  cid:469  cid:474   @check_is_admin def get_food self, username, food :  return self.storage.get food   In our examples so far, we’ve alwa⁴s assumed that the decorated function would have a username passed to it as a ke⁴word argument, but that might not alwa⁴s be the case. With this in mind, it’s a better idea to build a smarter version of our decorator that can look at the decorated function’s arguments and pull out what it needs. To that end, the inspect module allows us to retrieve a function’s signature and operate on it: Example  cid:474 . cid:471  Retrieving function arguments using inspect import functools import inspect  def check_is_admin f : @functools.wraps f  def wrapper *args, **kwargs :  func_args = inspect.getcallargs f, *args, **kwargs  if func_args.get 'username'  != 'admin':  raise Exception "This user is not allowed to get food"   return f *args, **kwargs   return wrapper  @check_is_admin def get_food username, type='chocolate' :  return type + " nom nom nom!"  The function that does the heav⁴ liting here is inspect.getcallargs, which returns a dictionar⁴ containing the names and values of the arguments as ke⁴-value pairs.    cid:474 . cid:469 . HOW METHODS WORK IN PYTHON   cid:468  cid:469  cid:475   In our example, this function returns {'username':'admin', 'type':'chocolat e'}. This means that our decorator doesn’t have to check if the username parameter is a positional or a ke⁴word argument: all it has to do is look for it in the dictionar⁴.  7.2 How methods work in Python  You’ve probabl⁴ written do⁵ens of methods and thought nothing of them before now, but to understand what certain decorators do, ⁴ou need to know how methods work behind the scenes.  def __init__ self, size :  A method is a function that is stored as a class attribute. Let’s have a look at what happens when we tr⁴ to access such an attribute directl⁴: Example  cid:474 . cid:472  A P⁴thon  cid:469  method >>> class Pizza object : ... ... ... ... ... >>> Pizza.get_size    self.size = size def get_size self : return self.size  P⁴thon  cid:469  tells us that the get_size attribute of the Pizza class is anunbound method. Example  cid:474 . cid:473  A P⁴thon  cid:470  method >>> class Pizza object : ... ... ... ... ...  self.size = size def get_size self : return self.size  def __init__ self, size :    cid:474 . cid:469 . HOW METHODS WORK IN PYTHON   cid:468  cid:469  cid:476   >>> Pizza.get_size    In P⁴thon  cid:470 , the concept of unbound method has been removed entirel⁴, and we’re told get_size is a function.  The principle is the same in both cases: get_size is a function that is not tied to an⁴ particular object, and P⁴thon will raise an error if we tr⁴ to call it: Example  cid:474 . cid:474  Calling unbound get_si⁵e in P⁴thon  cid:469  >>> Pizza.get_size   Traceback  most recent call last :  TypeError: unbound method get_size   must be called with Pizza instance as ←֓  File " ", line 1, in    first argument  got nothing instead   Example  cid:474 . cid:475  Calling unbound get_si⁵e in P⁴thon  cid:470  >>> Pizza.get_size   Traceback  most recent call last :  File " ", line 1, in    TypeError: get_size   missing 1 required positional argument: 'self'  P⁴thon  cid:469  rejects the method call because it’s unbound; P⁴thon  cid:470  permits the call, but complains that we haven’t provided the necessar⁴ self argument. This makes P⁴thon  cid:470  a bit more flexible: not onl⁴ can we pass an arbitrar⁴ instance of the class to the method if we want to, but we can pass any object as long as it has the prop- erties that the method expects to find: >>> Pizza.get_size Pizza 42   42  And it works, just as promised, though it’s not ver⁴ convenient: we have to refer to the class ever⁴ time we want to call one of its methods.    cid:474 . cid:469 . HOW METHODS WORK IN PYTHON   cid:468  cid:470  cid:467   So P⁴thon goes the extra mile for us b⁴ binding a class’s methods to its instances. In other words, we can access get_size from an⁴ Pizza, and better still, P⁴thon will automaticall⁴ pass the object itself to the method’s self parameter: Example  cid:474 . cid:476  Calling bound get_size  >>> Pizza 42 .get_size  > >>> Pizza 42 .get_size   42  As expected, we don’t have to provide an⁴ argument to get_size, since it’s a bound method: its self argument is automaticall⁴ set to our Pizza instance. Here’s a even better example: >>> m = Pizza 42 .get_size >>> m   42  You don’t even have to keep a reference to ⁴our Pizza object as long as ⁴ou have a reference to the bound method. And if ⁴ou have a reference to a method but ⁴ou want to find out which object it’s bound to, ⁴ou can just check the method’s __sel f__ propert⁴: >>> m = Pizza 42 .get_size >>> m.__self__   >>> m == m.__self__.get_size True  Obviousl⁴, we still have a reference to our object, and we can find it back if we want.    cid:468  cid:470  cid:468   Static methods are methods which belong to a class, but don’t actuall⁴ operate on class instances. For example: Example  cid:474 . cid:468  cid:467  @staticmethod usage   cid:474 . cid:470 . STATIC METHODS  7.3 Static methods  class Pizza object :  @staticmethod def mix_ingredients x, y :  return x + y  def cook self :  return self.mix_ingredients self.cheese, self.vegetables   You could write mix_ingredients as a non-static method if ⁴ou wanted to, but it would take a self argument that would never actuall⁴ be used. The @staticmethod decorator gives us several things:    P⁴thon doesn’t have to instantiate a bound method for each Pizza object we cre- ate. Bound methods are objects, too, and creating them has a cost. Using a static method lets us avoid that:  >>> Pizza  .cook is Pizza  .cook False >>> Pizza  .mix_ingredients is Pizza.mix_ingredients True >>> Pizza  .mix_ingredients is Pizza  .mix_ingredients True    It improves the readabilit⁴ of the code: when we see @staticmethod, we know  that the method does not depend on the state of the object.    cid:474 . cid:471 . CLASS METHOD   cid:468  cid:470  cid:469     We can override our static methods in subclasses.  If we used a mix_ingredie nts function defined at the top level of our module, a class inheriting from Pizza wouldn’t be able to change the wa⁴ we mix ingredients for our pi⁵⁵a without over- riding the cook method itself.  7.4 Class method  radius = 42 @classmethod def get_radius cls : return cls.radius  Class methods are methods that are bound directl⁴ to a class rather than its in- stances: >>> class Pizza object : ... ... ... ... ... >>> Pizza.get_radius  > >>> Pizza  .get_radius  > >>> Pizza.get_radius is Pizza  .get_radius True >>> Pizza.get_radius   42  However ⁴ou choose to access this method, it will be alwa⁴s bound to the class it is attached to, and its first argument will be the class itself  remember, classes are objects too!   Class methods are mostl⁴ useful for creating factory methods – methods which in- stantiate objects in a specific fashion. If we used a @staticmethod instead, we would    cid:474 . cid:472 . ABSTRACT METHODS   cid:468  cid:470  cid:470   have to hard-code the Pizza class name in our method, making an⁴ class inheriting from Pizza unable to use our factor⁴ for its own purposes. class Pizza object :  def __init__ self, ingredients :  self.ingredients = ingredients  @classmethod def from_fridge cls, fridge :  return cls fridge.get_cheese   + fridge.get_vegetables     In this case, we provide a from_fridge factor⁴ method that we can pass a Fridge object to. If we call this method with something like Pizza.from_fridge myfrid ge , it will return a brand-new Pizza with ingredients taken from what’s available in myfridge.  7.5 Abstract methods  An abstract method is a method defined in a base class which ma⁴ or ma⁴ not ac- tuall⁴ provide an⁴ implementation. The simplest wa⁴ to write an abstract method in P⁴thon is: class Pizza object :  @staticmethod def get_radius  :  raise NotImplementedError  An⁴ class inheriting from Pizza should implement and override the get_radius method; otherwise, calling the method will raise an exception. This particular wa⁴ of implementing abstract methods has a drawback: if ⁴ou write a class that inherits from Pizza and forget to implement get_radius, the error will onl⁴ be raised if ⁴ou tr⁴ to use that method at runtime.    cid:474 . cid:472 . ABSTRACT METHODS   cid:468  cid:470  cid:471   Example  cid:474 . cid:468  cid:468  Implementing an abstract method  >>> Pizza     >>> Pizza  .get_radius   Traceback  most recent call last :  File " ", line 1, in   File " ", line 3, in get_radius  NotImplementedError  import abc  class BasePizza object :  __metaclass__ = abc.ABCMeta  @abc.abstractmethod def get_radius self :  """Method that should do something."""  If ⁴ou implement ⁴our abstract methods using P⁴thon’s built-in abc module instead, ⁴ou’ll get an earl⁴ warning if ⁴ou tr⁴ to instantiate an object with abstract methods: Example  cid:474 . cid:468  cid:469  Implementing an abstract method using abc  When ⁴ou use abc and its special class, if ⁴ou tr⁴ to instantiate a BasePizza or a class inheriting from it that doesn’t override get_radius, ⁴ou’ll get a TypeError: >>> BasePizza   Traceback  most recent call last :  File " ", line 1, in    TypeError: Can't instantiate abstract class BasePizza with abstract methods ←֓  get_radius    cid:474 . cid:473 . MIXING STATIC, CLASS, AND ABSTRACT METHODS   cid:468  cid:470  cid:472   Note The metaclass declaration changed between Python 2 and Python 3. The previous ex-  amples only work with Python 2 for this reason.  7.6 Mixing static, class, and abstract methods  Each of these decorators is useful on its own, but the time ma⁴ come when ⁴ou’ll have to use them together. Here are some tips that will help ⁴ou with that.  An abstract method’s protot⁴pe isn’t set in stone. When ⁴ou actuall⁴ implement the method, there’s nothing stopping ⁴ou from extending the argument list as ⁴ou see fit: import abc  class BasePizza object :  __metaclass__ = abc.ABCMeta  @abc.abstractmethod def get_ingredients self :  """Returns the ingredient list."""  class Calzone BasePizza :  def get_ingredients self, with_egg=False :  egg = Egg   if with_egg else None return self.ingredients + [egg]  We can define Calzone's methods an⁴ wa⁴ we like, as long as the⁴ still support the interface we define in the BasePizza class. This includes implementing them as class or static methods:    cid:474 . cid:473 . MIXING STATIC, CLASS, AND ABSTRACT METHODS   cid:468  cid:470  cid:473   import abc  class BasePizza object :  __metaclass__ = abc.ABCMeta  @abc.abstractmethod def get_ingredients self :  """Returns the ingredient list."""  class DietPizza BasePizza :  @staticmethod def get_ingredients  :  return None  Even though our static get_ingredients method doesn’t return a result based on the object’s state, it still supports our abstract BasePizza class’s interface, so it’s still valid.  Starting with P⁴thon  cid:470   this won’t work as expected in P⁴thon  cid:469 ; see issue  cid:472  cid:475  cid:473  cid:474  , it’s also possible to use the @staticmethod and @classmethod decorators on top of @abstractmethod: Example  cid:474 . cid:468  cid:470  Mixing @classmethod and @abstractmethod  import abc  class BasePizza object :  __metaclass__ = abc.ABCMeta  ingredients = ['cheese']  @classmethod    cid:474 . cid:473 . MIXING STATIC, CLASS, AND ABSTRACT METHODS   cid:468  cid:470  cid:474   @abc.abstractmethod def get_ingredients cls :  """Returns the ingredient list.""" return cls.ingredients  Note that defining get_ingredients as a class method in BasePizza like this doesn’t force its subclasses to define it as a class method as well. The same would appl⁴ if we’d defined it as a static method: there’s no wa⁴ to force subclasses to implement abstract methods as a specific kind of method.  But wait – here we have an implementation in an abstract method. Can we do that? Yep – P⁴thon doesn’t have a problem with it! Unlike Java, ⁴ou can put code in ⁴our abstract methods and call it using super  : Example  cid:474 . cid:468  cid:471  Using super   with abstract methods  import abc  class BasePizza object :  __metaclass__ = abc.ABCMeta  default_ingredients = ['cheese']  @classmethod @abc.abstractmethod def get_ingredients cls :  """Returns the default ingredient list.""" return cls.default_ingredients  class DietPizza BasePizza :  def get_ingredients self :  return [Egg  ] + super DietPizza, self .get_ingredients      cid:474 . cid:474 . THE TRUTH ABOUT SUPER   cid:468  cid:470  cid:475   In this example, ever⁴ Pizza ⁴ou make that inherits from BasePizza will have to override the get_ingredients method, but it will have access to the base class’s default mechanism for getting the ingredients list.  7.7 The truth about super  From the earliest da⁴s of P⁴thon, developers have been able to use both single and multiple inheritance to extend their classes. However, man⁴ developers don’t seem to understand how these mechanisms actuall⁴ work, and the associated super   method that is associated with it.  There is pros and cons of single and multiple inheritance, composition or even duck t⁴ping would be out of topic for this book, though if ⁴ou are not familiar with these notions I suggest that ⁴ou read about them to have a view – and build ⁴our own opinion.  Multiple inheritance is still used in man⁴ places, and especiall⁴ in code where the mixin pattern is involved. That’s wh⁴ it’s still important to know about it, and be- cause it is part of P⁴thon’s core.  Note A mixin is a class that inherits from two or more other classes, combining their features  together.  As ⁴ou should know b⁴ now, classes are objects in P⁴thon. The construct used to create a class is a special statement that ⁴ou should be well familiar with: class classname expression of inheritance .  The part in parentheses is a P⁴thon expression that returns the list of class objects to be used as the class’s parents. Normall⁴ ⁴ou’d specif⁴ them directl⁴, but ⁴ou could also write something like:    cid:474 . cid:474 . THE TRUTH ABOUT SUPER   cid:468  cid:470  cid:476   return object  >>> def parent  : ... ... >>> class A parent   : ... ... >>> A.mro   [ ,  ]  pass  And it works as expected: class A is defined with object as its parent class. The class method mro   returns the method resolution order used to resolve attributes. The current MRO s⁴stem was first implemented in P⁴thon  cid:469 . cid:470 , and its internal workings are described in the P⁴thon  cid:469 . cid:470  release notes.  You alread⁴ know that the canonical wa⁴ to call a method in a parent class is b⁴ using the super   function, but what ⁴ou probabl⁴ don’t know is that super   is actuall⁴ a constructor, and ⁴ou instantiate a super object each time ⁴ou call it. It takes either one or two arguments: the first argument is a class, and the second argument is either a subclass or an instance of the first argument.  The object returned b⁴ the constructor functions as a prox⁴ for the parent classes of the first argument. It has its own __getattribute__ method that iterates over the classes in the MRO list and returns the first matching attribute it finds: >>> class A object : ... ... ... ... >>> class B object : ... ...  bar = 42 def foo self :  bar = 0  pass    cid:474 . cid:474 . THE TRUTH ABOUT SUPER   cid:468  cid:471  cid:467   >>> class C A, B : ... xyz = 'abc' ... >>> C.mro   [ ,  ,  , <type ' ←֓  object'>]  >>> super C, C   .bar 42 >>> super C, C   .foo  > >>> super B .__self__ >>> super B, B   .__self__ <__main__.B object at  When requesting an attribute of the super object of an instance of C, it walks through the MRO list and return the attribute from the first class having it.  In the previous example, we used a bound super object; i.e., we called super with two arguments. If we call super   with onl⁴ one argument, it returns an unbound super object instead: >>> super C   , NULL>  Since this object is unbound, ⁴ou can’t use it to access class attributes: >>> super C .foo Traceback  most recent call last :  File " ", line 1, in    AttributeError: 'super' object has no attribute 'foo' >>> super C .bar Traceback  most recent call last :  File " ", line 1, in      cid:474 . cid:474 . THE TRUTH ABOUT SUPER   cid:468  cid:471  cid:468   AttributeError: 'super' object has no attribute 'bar' >>> super C .xyz Traceback  most recent call last :  File " ", line 1, in    AttributeError: 'super' object has no attribute 'xyz'  sup = super C   At first glance, it might seem like this kind of super object is useless, but the su- per class implements the descriptor protocol  i.e. __get__  in a wa⁴ that makes unbound super objects useful as class attributes: >>> class D C : ... ... >>> D  .sup  ,  > >>> D  .sup.foo  > >>> D  .sup.bar 42  The unbound super object’s __get__ method is called using the instance and the attribute name as arguments  super C .__get__ D  , 'foo'  , allowing it to find and resolve foo.  Note Even if you’ve never heard of the descriptor protocol, you’ve probably used it through the @property decorator without knowing it. an object that’s stored as an attribute to return something other than itself. This protocol  It’s the mechanism in Python that allows  isn’t covered in this book, but you can find out more about it in the Python data model  documentation.  There are plent⁴ of situations where using super can be trick⁴, such as handling    cid:474 . cid:474 . THE TRUTH ABOUT SUPER   cid:468  cid:471  cid:469   diﬀerent method signatures along the inheritance chain. Unfortunatel⁴, there’s no silver bullet for that, apart from using tricks like having all ⁴our methods accept their arguments using *args, **kwargs.  In P⁴thon  cid:470 , super   picked up a little bit of magic: it can now be called from within a method without an⁴ arguments. When no arguments are passed to super  , it automaticall⁴ searches the stack frame for them: class B A :  def foo self :  super  .foo    super is the standard wa⁴ of accessing parent attributes in subclasses, and ⁴ou should alwa⁴s use it. It allows cooperative calls of parent methods without an⁴ sur- prises, such as parent methods not being called or being called twice when using multiple inheritance.    cid:475  Functional programming  Functional programming might not be the first thing ⁴ou think of when ⁴ou think of P⁴thon, but the support is there, and it’s quite extensive. Man⁴ P⁴thon developers don’t seem to reali⁵e this, though, which is a shame: with few exceptions, functional programming allows ⁴ou to write more concise and eﬀicient code. When ⁴ou write code using functional st⁴le, ⁴our functions are designed not to have side eﬀects: the⁴ take an input and produce an output without keeping state or modif⁴ing an⁴thing not reflected in the return value. Functions that follow this ideal are referred to as purely functional: A non-pure function def remove_last_item mylist :  """Removes the last item from a list.""" mylist.pop -1   This modifies mylist  A pure function def butlast mylist :  """Like butlast in Lisp; returns the list without the last element.""" return mylist[:-1]  This returns a copy of mylist  The practical advantages of functional programming include:    Formal provability; admittedl⁴, this is a pure theoretical advantages, nobod⁴ is  going to mathematicall⁴ prove a P⁴thon program.    cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:471     Modularity; writing functionall⁴ forces a certain degree of separation in solving  ⁴our problems and eases reuse in other contexts.    Brevity. Functional programming is oten less verbose than other paradigms.    Concurrency. Purel⁴ functional functions are thread-safe and can run concur- rentl⁴. While it’s not ⁴et the case in P⁴thon, some functional languages do this automaticall⁴, which can be a big help if ⁴ou ever need to scale ⁴our application.    Testability. It’s a simple matter to test a functional program: all ⁴ou need is a set  of inputs and an expected set of outputs. The⁴ are idempotent.  Tip If you want to get serious about functional programming, take my advice: take a break  from Python and learn Lisp. I know it might sound strange to talk about Lisp in a Python  book, but playing with Lisp for several years is what taught me how to "think functional."  You simply won’t develop the thought processes necessary to make full use of functional  programming if all your experience comes from imperative and object-oriented program-  ming. Lisp isn’t purely functional itself, but there’s more focus on functional programming  than you’ll find in Python.  8.1 Generators  A generator is an object that returns a value on each call of its next   method until it raises StopIteration. The⁴ were first introduced in PEP  cid:469  cid:472  cid:472  and oﬀer an eas⁴ wa⁴ to create objects that implement the iterator protocol.  All ⁴ou have to do to create a generator is write a normal P⁴thon function that con- tains a yield statement. P⁴thon will detect the use of yield and tag the function as a generator. When the function’s execution reaches a yield statement, it returns a value as with a return statement, but with one notable diﬀerence: the interpreter    cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:472   will save a stack reference, which will be used to resume the function’s execution the next time next is called.  yield 1 yield 2 yield 'a'  Creating a generator >> def mygenerator  : ... ... ... ... >>> mygenerator     >>> g = mygenerator   >>> next g  1 >>> next g  2 >>> next g  'a' >>> next g  Traceback  most recent call last :  File " ", line 1, in    StopIteration  You can check whether a function is a generator or not ⁴ourself b⁴ using inspect. isgeneratorfunction: >>> import inspect >>> def mygenerator  : ... ... >>> inspect.isgeneratorfunction mygenerator  True  yield 1    cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:473   >>> inspect.isgeneratorfunction sum  False  Reading the source code of inspect.isgeneratorfunction gives us some insight into the tagging mentioned earlier:  Source code of inspect.isgeneratorfunction def isgeneratorfunction object :  """Return true if the object is a user-defined generator function.  Generator function objects provides same attributes as functions.  See help isfunction  for attributes listing.""" return bool  isfunction object  or ismethod object   and  object.func_code.co_flags & CO_GENERATOR   yield 1  P⁴thon  cid:470  provides another useful function, inspect.getgeneratorstate: >>> import inspect >>> def mygenerator  : ... ... >>> gen = mygenerator   >>> gen   >>> inspect.getgeneratorstate gen  'GEN_CREATED' >>> next gen  1 >>> inspect.getgeneratorstate gen  'GEN_SUSPENDED' >>> next gen     cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:474   Traceback  most recent call last :  File " ", line 1, in    StopIteration >>> inspect.getgeneratorstate gen  'GEN_CLOSED'  This function gives us the current state of a generator, allowing us to determine whether it’s waiting to be run for the first time  GEN_CREATED , currentl⁴ being exe- cuted b⁴ the interpreter  GEN_RUNNING , waiting to be resumed b⁴ a call to next    GEN_SUSPENDED , or finished running  GEN_CLOSED .  In P⁴thon, generators are built b⁴ keeping a reference of the stack when a function yield something, resuming this stack when needed, i.e. when a call to next   is executed again.  When ⁴ou iterate over an⁴ kind of data, the obvious approach is to build the entire list first, which is oten wasteful in terms of memor⁴ consumption. Sa⁴ we want to find the first number between  cid:468  and  cid:468  cid:467 , cid:467  cid:467  cid:467 , cid:467  cid:467  cid:467  that’s equal to  cid:472  cid:467 , cid:467  cid:467  cid:467 . Sounds eas⁴, doesn’t it? Let’s make this a challenge. We’ll run P⁴thon with a memor⁴ constraint of  cid:468  cid:469  cid:475  MB: $ ulimit -v 131072 $ python >>> a = list range 10000000   Traceback  most recent call last :  File " ", line 1, in    MemoryError  Uh-oh. Turns out we can’t build a list of ten million items with onl⁴  cid:468  cid:469  cid:475 MB of mem- or⁴!    cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:475   Warning In Python 3, range   returns a generator; to get a generator in Python 2, you have to use xrange   instead.  This function doesn’t exist in Python 3, since it’s redundant.   Let’s tr⁴ using a generator instead: $ python >>> for value in xrange 10000000 : ... ... ... ... Found it  print "Found it"  break  if value == 50000:  This time, our program executes without issue. The range   function returns an iterable object that d⁴namicall⁴ generates our list of integers. Better still, since we were onl⁴ interested in the  cid:472  cid:467 , cid:467  cid:467  cid:467 th number, the generator onl⁴ had to generate  cid:472  cid:467 , cid:467  cid:467  cid:467  numbers.  Generators allow ⁴ou to handle large data sets with minimal consumption of mem- or⁴ and processing c⁴cles b⁴ generating values on-the-fl⁴. Whenever ⁴ou need to work with a huge number of values, generators can help ensure ⁴ou handle them eﬀicientl⁴.  yield also has a less commonl⁴ used feature: it can return a value like a function call. This allows us to pass a value to a generator b⁴ calling its send   method: Example  cid:475 . cid:468  yield returning a value  def shorten string_list :  length = len string_list[0]  for s in string_list:  length = yield s[:length]    cid:475 . cid:468 . GENERATORS   cid:468  cid:471  cid:476   mystringlist = ['loremipsum', 'dolorsit', 'ametfoobar'] shortstringlist = shorten mystringlist  result = [] try:  s = next shortstringlist  result.append s  while True:  number_of_vowels = len filter lambda letter: letter in 'aeiou', s    Truncate the next string depending  on the number of vowels in the previous one s = shortstringlist.send number_of_vowels  result.append s   except StopIteration:  pass  In this example, we’ve written a function called shorten that takes a list of strings and returns a list consisting of those same strings, onl⁴ truncated. The length of each string is determined b⁴ the number of vowels in the previous string: "loremip- sum" has four vowels, so the second value returned b⁴ the generator will be the first four letters of "dolorsit"; "dolo" has onl⁴ two vowels, so "ametfoobar" will be truncated to its first two letters  "am" . The generator then stops and raises StopIteration. Our generator thus returns: ['loremipsum', 'dolo', 'am']  Using yield and send   in this fashion allows P⁴thon generators to function like coroutines seen in Lua and other languages.    cid:475 . cid:469 . LIST COMPREHENSIONS   cid:468  cid:472  cid:467   Tip PEP 289 introduced generator expressions, making it possible to build one-line generators  using a syntax similar to list comprehension:  >>>  x.upper   for x in ['hello', 'world']    at 0x7ffab3832fa0> >>> gen =  x.upper   for x in ['hello', 'world']  >>> list gen  ['HELLO', 'WORLD']  8.2 List comprehensions  List comprehension, or listcomp for short, allows ⁴ou to define a list’s contents in- line with its declaration:  Without list comprehension >>> x = [] >>> for i in  1, 2, 3 : ... ... >>> x [1, 2, 3]  x.append i   With list comprehension >>> x = [i for i in  1, 2, 3 ] >>> x [1, 2, 3]  You can use multiple for statements together and use if statements to filter out items:    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:468   x = [word.capitalize    for line in  "hello world?", "world!", "or not"  for word in line.split   if not word.startswith "or" ]  >>> x ['Hello', 'World?', 'World!', 'Not']  Using list comprehension rather than for loops is a neat wa⁴ to quickl⁴ define lists. Since we’re still talking about functional programming, it’s worth noting that lists built through list comprehension can’t rel⁴ on the program’s state. ¹ This generall⁴ makes them more concise and easier to read than lists made without list compre- hension.  Note There’s also syntax for building dictionaries or sets in the same fashion:  >>> {x:x.upper   for x in ['hello', 'world']} {'world': 'WORLD', 'hello': 'HELLO'} >>> {x.upper   for x in ['hello', 'world']} set ['WORLD', 'HELLO']   Note that this only works in Python 2.7 and onward.  8.3 Functional functions functioning  P⁴thon includes a number of tools for functional programming. These built-in func- tions cover the basics:    map function, iterable  applies function to each item in iterable and returns  either a list in P⁴thon  cid:469  or an iterable map object in P⁴thon  cid:470 : ¹Technicall⁴ the⁴ can, but that’s reall⁴ not how the⁴’re supposed to work.    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:469   map usage in Python  cid:470  >>> map lambda x: x + "bzz!", ["I think", "I'm good"]    >>> list map lambda x: x + "bzz!", ["I think", "I'm good"]   ['I thinkbzz!', "I'm goodbzz!"]    filter function or None, iterable  filters the items in iterable based on the result returned b⁴ function, and returns either a list in P⁴thon  cid:469 , or better, an iterable filter object in P⁴thon  cid:470 :  Example  cid:475 . cid:469  filter usage in P⁴thon  cid:470   >>> filter lambda x: x.startswith "I " , ["I think", "I'm good"]    >>> list filter lambda x: x.startswith "I " , ["I think", "I'm good"]   ['I think']    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:470   Tip You can write a function equivalent to filter or map using generators and list compre- hension: Equivalent of map using list comprehension >>>  x + "bzz!" for x in ["I think", "I'm good"]    at 0x7f9a0d697dc0> >>> [x + "bzz!" for x in ["I think", "I'm good"]] ['I thinkbzz!', "I'm goodbzz!"]  Equivalent of filter using list comprehension >>>  x for x in ["I think", "I'm good"] if x.startswith "I "     at 0x7f9a0d697dc0> >>> [x for x in ["I think", "I'm good"] if x.startswith "I " ] ['I think']  Using generators like this in Python 2 will give you an iterable object rather than a list, just like the map and filter functions in Python 3.    enumerate iterable[, start]  returns an iterable enumerate object that ⁴ields a sequence of tuples, each consisting of an integer index  starting with start, if provided  and the corresponding item in iterable. It’s useful when ⁴ou need to write code that refers to arra⁴ indexes. For example, instead of writing this:  i = 0 while i < len mylist :  print "Item %d: %s" %  i, mylist[i]   i += 1  You could write this: for i, item in enumerate mylist :  print "Item %d: %s" %  i, item      cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:471     sorted iterable, key=None, reverse=False  returns a sorted version of itera ble. The key argument allows ⁴ou to provide a function that returns the value to sort on.    any iterable  and all iterable  both return a boolean depending on the val-  ues returned b⁴ iterable. These functions are equivalent to:  def all iterable :  for x in iterable:  if not x:  return False  return True  def any iterable :  for x in iterable:  if x:  return True  return False  These functions are useful for checking whether an⁴ or all of the values in an iterable satisf⁴ a given condition: mylist = [0, 1, 3, -1] if all map lambda x: x > 0, mylist  :  print "All items are greater than 0"   if any map lambda x: x > 0, mylist  :  print "At least one item is greater than 0"     zip iter1 [,iter2 [...]]  takes multiple sequences and combines them into tuples. It’s useful when ⁴ou need to combine a list of ke⁴s and a list of values into a dict. Like the other functions described above, it returns a list in P⁴thon  cid:469  and an iterable in P⁴thon  cid:470 :    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:472   >>> keys = ["foobar", "barzz", "ba!"] >>> map len, keys    >>> zip keys, map len, keys     >>> list zip keys, map len, keys    [ 'foobar', 6 ,  'barzz', 5 ,  'ba!', 3 ] >>> dict zip keys, map len, keys    {'foobar': 6, 'barzz': 5, 'ba!': 3}  You might have noticed b⁴ now how the return t⁴pes diﬀer between P⁴thon  cid:469  and P⁴thon  cid:470 . Most of P⁴thon’s purel⁴ functional built-in functions return a list rather than an iterable in P⁴thon  cid:469 , making them less memor⁴-eﬀicient than their P⁴thon  cid:470 .x equivalents. If ⁴ou’re planning to write code using these functions, keep in mind that ⁴ou’ll get the most benefit out of them in P⁴thon  cid:470 . If ⁴ou’re stuck to P⁴thon  cid:469 , don’t despair ⁴et: the itertools module from the standard librar⁴ provides an it- erator based version of man⁴ of these functions  itertools.izip, itertoolz.imap, itertools.ifilter, etc .  There’s still one important tool missing from this list, however. One common task when working with lists is finding the first item that satisfies a specific condition. This is usuall⁴ accomplished with a function like this: def first_positive_number numbers :  for n in numbers:  if n > 0:  return n  We can also write this in functional st⁴le: def first predicate, items :  for item in items:    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:473   if predicate item :  return item  first lambda x: x > 0, [-1, 0, 1, 2]   Or more concisel⁴:  Less efficient list filter lambda x: x > 0, [-1, 0, 1, 2]  [0] ②1  Efficient but for Python 3 next filter lambda x: x > 0, [-1, 0, 1, 2]    Efficient but for Python 2 next itertools.ifilter lambda x: x > 0, [-1, 0, 1, 2]    ②1  Note that this ma⁴ raise an IndexError if no items satisf⁴ the condition, causing list filter    to return an empt⁴ list.  Instead of writing this same function in ever⁴ program ⁴ou make, ⁴ou can include the small but ver⁴ useful P⁴thon package first: Example  cid:475 . cid:470  Using first  >>> from first import first >>> first [0, False, None, [],   , 42]  42 >>> first [-1, 0, 1, 2]  -1 >>> first [-1, 0, 1, 2], key=lambda x: x > 0  1  The key argument can be used to provide a function which receives each item as an argument and returns a boolean indicating whether it satisfies the condition.    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:474   You’ll notice that we’ve used lambda in a good portion of the examples so far in this chapter. lambda was actuall⁴ added to P⁴thon in the first place to facilitate func- tional programming functions such as map   and filter  , which otherwise would have required writing an entirel⁴ new function ever⁴ time ⁴ou wanted to check a diﬀerent condition: import operator from first import first  def greater_than_zero number :  return number > 0  first [-1, 0, 1, 2], key=greater_than_zero   This code works identicall⁴ to the previous example, but it’s a good deal more cum- bersome: if we wanted to get the first number in the sequence that’s greater than, sa⁴,  cid:471  cid:469 , then we’d need to def an appropriate function rather than defining it in-line with our call to first.  But despite its usefulness in helping us avoid situations like this, lambda still has its problems. First and most obviousl⁴, we can’t pass a key function using lambda if it would require more than a single line of code. In this event, we’re back to the cumbersome pattern of writing new function definitions for each key we need. Or are we?  functools.partial is our first step towards replacing lambda with a more flexible alternative. It allows us to create a wrapper function with a twist: rather than chang- ing the behavior of a function, it instead changes the arguments it receives: from functools import partial from first import first  def greater_than number, min=0 :    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:475   return number > min  first [-1, 0, 1, 2], key=partial greater_than, min=42    Our new greater_than function works just like the old greater_than_zero b⁴ de- fault, but now we can specif⁴ the value we want to compare our numbers to. In this case, we pass functools.partial our function and the value we want for min, and we get back a new function that has min set to  cid:471  cid:469 , just like we want. In other words, we can write a function and use functools.partial to customi⁵e what it does to our needs in an⁴ given situation.  This is still a couple lines more than we strictl⁴ need in this case, though. All we’re doing in this example is comparing two numbers; what if P⁴thon had built-in func- tions for these kinds of comparisons? As it turns out, the operator module has just what we’re looking for: import operator from functools import partial from first import first  first [-1, 0, 1, 2], key=partial operator.le, 0    Here we see that functools.partial also works with positional arguments. In this case, operator.le a, b  takes two numbers and returns whether the first is less than or equal to the second: the  cid:467  we pass to functools.partial gets sent to a, and the argument passed to the function returned b⁴ functools.partial gets sent to b. So this works identicall⁴ to our initial example, without using lambda or defining an⁴ additional functions.    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:472  cid:476   Note functools.partial is typically useful in replacement of lambda, and is to be consid- ered as a superior alternative. lambda is to be considered an anomaly in Python lan- guage ᵃ, due to its limited body size of one line long single expression. On the other hand, functools.partial is built as a nice wrapper around the original function.  ᵃAnd was once even planned to be removed in P⁴thon  cid:470 , but finall⁴ escaped from its fate.  The itertools module in the P⁴thon Standard Librar⁴ also provides a bunch of use- ful functions that ⁴ou’ll want to keep in mind. I’ve seen too man⁴ programmers end up writing their own versions of these functions even though P⁴thon itself provides them out-of-the-box:    chain *iterables  iterates over multiple iterables one ater each other without  building an intermediate list of all items.    combinations iterable, r  generates all combination of length r from the given  iterable.    compress data, selectors  applies a boolean mask from selectors to data and returns onl⁴ the values from data where the corresponding element of selectors is true.    count start, step  generates an endless sequence of values, starting from start  and incrementing b⁴ step with each call.    cycle iterable  loops repeatedl⁴ over the values in iterable.    dropwhile predicate, iterable  filters elements of an iterable starting from the  beginning until predicate is false.    groupby iterable, keyfunc  creates an iterator grouping items b⁴ the result re-  turned b⁴ the keyfunc function.    cid:475 . cid:470 . FUNCTIONAL FUNCTIONS FUNCTIONING   cid:468  cid:473  cid:467     permutations iterable[, r]  returns successive r-length permutations of the  items in iterable.    product *iterables  returns an iterable of the cartesian product of iterables  without using a nested for loop.    takewhile predicate, iterable  returns elements of an iterable starting from  the beginning until predicate is false.  These functions are particularl⁴ useful in conjunction with the operator module. When used together, itertools and operator can handle most situations that pro- grammers t⁴picall⁴ rel⁴ on lambda for: Example  cid:475 . cid:471  Using the operator module with itertools.groupby  >>> import itertools >>> a = [{'foo': 'bar'}, {'foo': 'bar', 'x': 42}, {'foo': 'baz', 'y': 43}] >>> import operator >>> list itertools.groupby a, operator.itemgetter 'foo'    [ 'bar',   ,  'baz', <itertools. ←֓  _grouper object at 0xb00110> ]  >>> [ key, list group   for key, group in list itertools.groupby a, ←֓  operator.itemgetter 'foo'   ]  [ 'bar', [] ,  'baz', [{'y': 43, 'foo': 'baz'}] ]  In this case, we could have also written lambda x:x['foo'], but using operator lets us avoid having to use lambda at all.    cid:476  The AST  AST stands for Abstract Syntax Tree. It is a tree representation of the abstract struc- ture of the source code of an⁴ programming language, including P⁴thon. P⁴thon as its own AST that is built upon parsing a P⁴thon source file.  This area of P⁴thon is not heavil⁴ documented, and not eas⁴ to deal with at first glance. Still, its is ver⁴ interesting to know and understand some deeper construc- tion of P⁴thon as a programming language to masteri⁵e its usage.  The easiest wa⁴ to have a view of what the P⁴thon AST looks like is to parse a P⁴thon code and dumps the generated AST. To do that, the P⁴thon ast module provides ever⁴thing ⁴ou need for. Example  cid:476 . cid:468  Parsing P⁴thon code to AST  >>> import ast >>> ast.parse   >>> ast.parse "x = 42"    >>> ast.dump ast.parse "x = 42"   "Module body=[Assign targets=[Name id='x', ctx=Store   ], value=Num n=42   ←֓  ] "  The ast.parse function returns a _ast.Module object that is the root of the tree.   CHAPTER  cid:476 . THE AST   cid:468  cid:473  cid:469   The tree can be entirel⁴ dumped using the ast.dump module, and in this case is the following:  An AST construction alwa⁴s starts with a root element, which is usuall⁴ an ast. Module object. This object contains a list of statements or expressions to evaluate in its body attribute. It usuall⁴ represents the content of a file.  As ⁴ou can guess, the ast.Assign object represents an assignment, that is mapped to the = sign in the P⁴thon s⁴ntax. Assign has a list of targets, and a value it assig- nates to it. The list of target in this case consists of one object, ast.Name, which represents a variable named x. The value is a number with value being  cid:471  cid:469 .  This AST can be passed to P⁴thon to be compiled and then evaluated. The compile function provided as a P⁴thon built-in allows that. >>> compile ast.parse "x = 42" , ' ', 'exec'    at 0x111b3b0, file " ", line 1> >>> eval compile ast.parse "x = 42" , ' ', 'exec'   >>> x 42  An abstract s⁴ntax tree can be built manuall⁴ using the classes provided in the ast   CHAPTER  cid:476 . THE AST   cid:468  cid:473  cid:470   module. Obviousl⁴, this is a ver⁴ long wa⁴ to write P⁴thon code, not a method I would recommend! But it’s still interesting to use. Let’s write a good old "Hello world!" in P⁴thon using the AST. Example  cid:476 . cid:469  Hello world using P⁴thon AST >>> hello_world = ast.Str s='hello world!', lineno=1, col_offset=1  >>> print_call = ast.Print values=[hello_world], lineno=1, col_offset=1, nl ←֓  =True   >>> module = ast.Module body=[print_call]  >>> code = compile module, '', 'exec'  >>> eval code  hello world!  Note lineno and col_offset represents the line number and column offset of the source code that has been used to generate the AST. This doesn’t have much sense to set them in  this context since we are not parsing any source file, but it’s useful to find back the position  of the code that generated this AST. It’s for example used by Python when generating  backtraces. Anyway, Python refused to compile any AST object that doesn’t provide this information, this is why we pass it fake values of 1 here. The ast.fix_missing_loc ations   function can fix it for you by setting the missing values to the ones set on the parent node.  The whole list of objects that are available in the AST is easil⁴ available b⁴ reading the _ast module documentation  note the underscore . The first two categories ⁴ou should consider are statement and expressions. State- ments cover t⁴pes like assert, assign  = , augmented assigned  +=,  =, etc , global, def, if, return, for, class, pass, import, etc. The⁴ all inherit from ast.stmt. Expres- sions cover t⁴pes like lambda, number, yield, name  variable , compare or call. The⁴ all inherit from ast.expr.   CHAPTER  cid:476 . THE AST   cid:468  cid:473  cid:471   There’s also a few other categories, such as ast.operator defining standard oper- ator such as add  + , div    , right shit  >> , etc, or ast.cmpop defining comparisons operator.  You can easil⁴ imagine that it is then possible to leverage this AST to construct a compiler that would parse strings and generate code b⁴ building a P⁴thon AST. This is exactl⁴ what led to the H⁴ project discussed in Section  cid:476 . cid:468 .  In case ⁴ou need to walk through ⁴our tree, the ast.walk function will help ⁴ou with that. But the ast module also provides NodeTransformer, a class that can be subclassed to walk an AST to modif⁴ some nodes. It’s therefore eas⁴ to use it to change code d⁴namicall⁴. Example  cid:476 . cid:470  Changing all binar⁴ operation to addition  import ast  class ReplaceBinOp ast.NodeTransformer :  """Replace operation by addition in binary operation""" def visit_BinOp self, node :  return ast.BinOp left=node.left,  op=ast.Add  , right=node.right   tree = ast.parse "x = 1 3"  ast.fix_missing_locations tree  eval compile tree, '', 'exec'   print ast.dump tree   print x  tree = ReplaceBinOp  .visit tree  ast.fix_missing_locations tree  print ast.dump tree   eval compile tree, '', 'exec'      cid:468  cid:473  cid:472   Which executes to the following: Module body=[Assign targets=[Name id='x', ctx=Store   ],  value=BinOp left=Num n=1 , op=Div  , right=Num n=3   ]   0.3333333333333333 Module body=[Assign targets=[Name id='x', ctx=Store   ],  value=BinOp left=Num n=1 , op=Add  , right=Num n=3   ]   Tip If you need to evaluate a string of Python that should return a simple data type, you can use ast.literal_eval. Contrary to eval, it disallows the input string to execute any code. It’s a safer alternative to eval.   cid:476 . cid:468 . HY  print x   4  9.1 Hy  Now that ⁴ou know about the AST, ⁴ou can easil⁴ dream of creating a new s⁴ntax for P⁴thon that ⁴ou would parse and compile down to a standard P⁴thon AST. The H⁴ programming language is doing exactl⁴ that. It is a Lisp dialect that parses a Lisp like language and converts it to regular P⁴thon AST. It is therefore full⁴ compatible with the P⁴thon ecos⁴stem. You could compare it to what Clojure is to Java. H⁴ could deserve a book for itself, so we will onl⁴ fl⁴ over it in this section.  If ⁴ou alread⁴ wrote Lisp ¹, the H⁴ s⁴ntax will reall⁴ look familiar. Once installed, launching the hy interpreter will give ⁴ou a standard REPL prompt where ⁴ou can start interact with the interpreter.  ¹If not, ⁴ou should consider it.    cid:476 . cid:468 . HY  % hy hy 0.9.10 =>  + 1 1  2   cid:468  cid:473  cid:473   For those not familiar with the Lisp s⁴ntax, the parentheses denote a list, the first element is a function, and the rest of the list are the arguments. Here the code is equivalent to P⁴thon 1 + 1.  Most constructs are mapped from P⁴thon directl⁴, such as function definition. Set- ting a variable relies on the setv function. =>  defn hello [name] ...  print "Hello world!"  ...  print  % "Nice to meet you %s" name    =>  hello "jd"  Hello world! Nice to meet you jd  Internall⁴, Hy parses the code that is provided and compiles it down to P⁴thon AST. Luckil⁴, Lisp is an eas⁴ to parse tree, as each pair of parentheses represents a node of the list tree. All is needed to be done is to convert this Lisp tree to a P⁴thon ab- stract s⁴ntax tree.  Class definition is supported through the defclass construct, that is inspired from CLOS ².  defclass A [object]  [[x 42] [y  fn [self value]   + self.x value  ]]   ²Common Lisp Object S⁴stem    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:473  cid:474   This defines a class named A, inheriting from object, with a class attribute x whose value is  cid:471  cid:469  and a method y that returns the x attribute plus the value passed as argument. What’s reall⁴ wonderful, is that ⁴ou can import any Python library directl⁴ into H⁴ and use it with no penalt⁴. =>  import uuid  =>  uuid.uuid4  UUID 'f823a749-a65a-4a62-b853-2687c69d0e1e'  =>  str  uuid.uuid4   '4efa60f2-23a4-4fc1-8134-00f5c271f809'  Hy also has more advanced construct and macros. If ⁴ou ever wanted to have a case or switch statement in P⁴thon, admire what cond can do for ⁴ou:  cond   > somevar 50   print "That variable is too big!"     < somevar 10   print "That variable is too small!"    true  print "That variable is jusssst right!"     Hy is a ver⁴ nice project that allows ⁴ou to jump into Lisp world without leaving ⁴our comfort ⁵one too far behind ⁴ou, as ⁴ou are still writing P⁴thon. The hy2py tool can even show ⁴ou what ⁴our H⁴ code would look like once translated into P⁴thon ³.  9.2 Interview with Paul Tagliamonte  Paul is a Debian developer, who’s working at Sunlight Foundation. He created H⁴ in  cid:469  cid:467  cid:468  cid:470  and, as a Lisp lover, I joined him in this fabulous adventure some time later.  ³Though it has some restrictions.    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:473  cid:475   Why did you create Hy in the first place? Initiall⁴, I created H⁴ following a conversation about how someone should write a Lisp that compiles to P⁴thon rather than Java’s JVM  Clojure . A few short da⁴s later, and I had the first version of H⁴ – something which resembled a lisp, and even worked like a proper lisp, but it was slow. I mean, reall⁴ slow. It took about an order of magnitude slower than native P⁴thon, since the Lisp runtime itself was implemented in P⁴thon. Frustrated, I almost gave up, onl⁴ to be pushed forward b⁴ a coworker the promise of using AST to implement the runtime, rather than imple- ment the runtime in P⁴thon. This insane idea started to reall⁴ spark the entire project. This set in shortl⁴ before the holida⁴s in  cid:469  cid:467  cid:468  cid:469 , leading me to spend m⁴ entire break from work hacking on H⁴. A week or so later, and I ended up with something that resembled the current H⁴ codebase quite closel⁴ – most H⁴ devs would even know their wa⁴ around the compiler. Just ater getting enough working to implement a basic Flask app, I gave a talk at Boston P⁴thon about this project, and the reception was incredibl⁴ warm – so warm, in fact, that I’d started to view H⁴ as a good wa⁴ to teach people about P⁴thon internals, such as how the REPL works ⁛, PEP  cid:470  cid:467  cid:469  import hooks, and P⁴thon AST – a good introduction to the concept of code that writes code. Ater the talk, I was a bit disappointed in a few sections, so I rewrote chunks of the compiler to fix some philosophical issues in the process, leading us to the current iteration of the codebase – which has stood up quite well!  ⁛code.InteractiveConsole    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:473  cid:476   In addition, H⁴  the Language  is a good wa⁴ to get people to understand how to read Lisp, since the⁴ can get comfortable with s-expressions in an environment the⁴ know  even using libraries the⁴ have l⁴ing around , eas- ing the transition to other  “real”  Lisps, such as Common Lisp, Scheme or Clojure, as well as experiment with new ideas  such as macro s⁴stems, ho- moiconicit⁴, and working without the concept of a statement . How did you find out about using the AST correctly? What are the tips and tricks, advice you can give to people looking at it? P⁴thon’s AST is quite interesting. It’s not quite private  in fact, it’s ex- plicitl⁴ not private , but it’s also not a public interface either. No stabil- it⁴ is guaranteed from version to version – in fact, there are some rather anno⁴ing diﬀerences between P⁴thon  cid:469  and  cid:470 , and even within diﬀerent P⁴thon  cid:470  releases. In addition, diﬀerent implementations ma⁴ interpret the AST diﬀerentl⁴, or even have a unique AST. Nothing sa⁴s J⁴thon, P⁴P⁴, or CP⁴thon must deal with P⁴thon AST in the same wa⁴. For instance, CP⁴thon can deal with slightl⁴ out of order AST entries  b⁴ the lineno and col_oﬀset , whereas P⁴P⁴ will throw an assertion error. While sometimes anno⁴ing, the AST is generall⁴ sane. It’s not impossible to build AST that works on a vast number of P⁴thon instances. With a conditional or two, it’s onl⁴ mildl⁴ anno⁴ing to create AST that works on CP⁴thon  cid:469 . cid:473  through  cid:470 . cid:470  and P⁴P⁴, making this tool quite hand⁴. The AST is extremel⁴ under-documented, so most knowledge comes from reverse engineering generated AST. B⁴ writing up simple P⁴thon scripts, one can use something similar to import ast;ast.dump ast.parse "pri nt foo"   to generate equivalent AST to help with the task. With a bit of guesswork, and some persistence, it’s not untenable to build up a basic understanding this wa⁴. At some point, I’ll take on the task of documenting m⁴ understanding of    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:474  cid:467   the AST module, but I find writing code is the best wa⁴ to learn the AST. What’s the current status, and future goals of Hy? H⁴ is currentl⁴ in development. It has a few subtle issues that need to be addressed, and fixing the bugs to make H⁴ virtuall⁴ indistinguishable from an⁴ other LISP- cid:468  variant. This is a monumental task, but it’s one that it’s ripe for hacking.  I’m also interested in keeping H⁴ eﬀicient, in so far as it can be.  I hope, in the long run, that H⁴ will become a sort of teaching tool – one wa⁴ to explain some of the concepts that are quite foreign to even expe- rienced P⁴thonistas. I hope it also proves interesting enough to P⁴thon- istas that the⁴ take an interest in these tools at our disposal, and continue pushing the bounds of what I think H⁴ is.  M⁴ hope is that people see H⁴ for what it is – an ama⁵ing teaching tool. A wa⁴ to get people interested in Common Lisp, Clojure or Scheme. I want people to go home and read about wh⁴ Lisp variants do things the wa⁴ the⁴ do, and how the⁴ can borrow this philosoph⁴ in their da⁴-to-da⁴ cod- ing. How interoperable with Python is Hy? What about code distribution and packaging? Ama⁵ingl⁴ interoperable. Stunningl⁴ interoperable, reall⁴. So well, in fact, that pdb can properl⁴ debug H⁴ without an⁴ changes at all. To reall⁴ drive this point home, I’ve written Flask apps, Django apps and modules of all sorts. P⁴thon can import P⁴thon, H⁴ can import H⁴, H⁴ can import P⁴thon and P⁴thon can import H⁴. This is what reall⁴ makes H⁴ unique – even variants like Clojure can’t do this, the interop is purel⁴ unidirectional  Clo- jure can import Java, but Java has one hell of a time importing Clojure . This was done to reall⁴ bring home how powerful these tools we have are.    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:474  cid:468   H⁴ works b⁴ translating H⁴ code  in s-expressions  into P⁴thon AST almost directl⁴. This compilation step means the generated b⁴tecode is fairl⁴ sane stuﬀ  so much so that debugging H⁴ b⁴ looking at P⁴thon source gen- erated from P⁴thon AST is a good wa⁴ of tracking down pesk⁴ AST errors , which means P⁴thon has a ver⁴ hard time of even telling the module isn’t written in P⁴thon at all.  Common Lisp-isms, such as *earmuffs* or using-dashes are full⁴ sup- ported b⁴ translating them to a P⁴thon equivalent  in this case, *earmuf fs* becomes EARMUFFS, and using-dashes becomes using_dashes , which means P⁴thon doesn’t have a hard time of using them at all.  Ensuring that we have reall⁴ good interoperabilit⁴ is one of our highest priorities, so if ⁴ou see an⁴ bugs – file them! What are the upside and downside of choosing Hy over Python? This is an interesting question. I’m quite partial, so take this with a grain of salt!  H⁴ outshines P⁴thon in a few special wa⁴s because we’ve taken a bit of eﬀort to smooth behavior over P⁴thon versions to allow the new P⁴thon  cid:470  future happen sooner. This was done b⁴ doing things like using future division in P⁴thon  cid:469 , and ensuring the s⁴ntax is normali⁵ed between the two versions.  In addition, H⁴ has something P⁴thon has a ver⁴ hard time with  even with the outstanding AST module , which is a full macro s⁴stem. Macros are ver⁴ special functions that alter the code during it’s compile step – not unlike having ast.NodeVisitor as a first-class function of the language. This leads to eas⁴ creation of new domain-specific languages, which is composed of the base language  in this case, H⁴   P⁴thon , with the addi- tion of man⁴ macros which allow uniquel⁴ expressive and succinct code.    cid:476 . cid:469 . INTERVIEW WITH PAUL TAGLIAMONTE   cid:468  cid:474  cid:469   Oten times, clever DSLs can replace languages designed to perform this role, such as Lua.  As for downsides, what gives H⁴ it’s power can also hurt it. Not techni- call⁴, but sociall⁴. H⁴, b⁴ virtue of being a Lisp written in s-expressions, suﬀers from the stigma of being hard to learn, read or maintain. People might be averse to working on projects using H⁴ due to the fear of H⁴ being extremel⁴ complex.  H⁴ is the Lisp ever⁴one loves to hate – P⁴thon folks tend to not enjo⁴ its s⁴ntax, and Lispers tend to avoid H⁴ due to, well, being P⁴thon. H⁴ uses P⁴thon objects directl⁴, so the behavior of fundamental objects can sometimes be surprising to the seasoned Lisper.  Hopefull⁴ people will look past it’s s⁴ntax and consider using it for a project to expand one’s hori⁵ons, and explore parts of P⁴thon previousl⁴ untouched.    cid:468  cid:467  Performances and optimizations  Premature optimi⁵ation is the root of all evil.  --- Donald Knuth Structured Programming with go to Statements  10.1 Data structures  Most computer problems can be solved in an elegant and simple manner, provided that ⁴ou use the right data structures – and P⁴thon provides man⁴ data structures to choose from.  Oten, there is a temptation to code ⁴our own custom data structures – this is invari- abl⁴ a vain, useless, doomed idea. P⁴thon almost alwa⁴s has better data structures and code to oﬀer – learn to use them.  For example, ever⁴bod⁴ uses dict, but how man⁴ times have ⁴ou seen code like this: def get_fruits basket, fruit :   A variation is to use "if fruit in basket:" try:  return basket[fruit]  except KeyError:    cid:468  cid:467 . cid:468 . DATA STRUCTURES  return set     cid:468  cid:474  cid:471   It’s much more eas⁴ to use the get method alread⁴ provided b⁴ the dict structure: def get_fruits basket, fruit :  return basket.get fruit, set     It’s not uncommon for people to use basic P⁴thon data structures without being aware of all the methods the⁴ provide. This is also true for sets – for example: def has_invalid_fields fields :  for field in fields:  if field not in ['foo', 'bar']:  return True  return False  This can be written without a loop: def has_invalid_fields fields :  return bool set fields  - set ['foo', 'bar']    The set data structures have methods which can solve man⁴ problems that would otherwise need to be addressed b⁴ writing nested for if blocks.  There are also more advanced data structures that can greatl⁴ reduce the burden of code maintenance. For example, take a look at the following code: def add_animal_in_family species, animal, family :  if family not in species:  species[family] = set   species[family].add animal   species = {} add_animal_in_family species, 'cat', 'felidea'     cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:474  cid:472   Sure, this code is perfectl⁴ valid, but how man⁴ times will ⁴our program require a variation of the above? Tens? Hundreds?  P⁴thon provides the collections.defaultdict structure, which solves the prob- lem in an elegant wa⁴. import collections  def add_animal_in_family species, animal, family :  species[family].add animal   species = collections.defaultdict set  add_animal_in_family species, 'cat', 'felidea'   Each time that ⁴ou tr⁴ to access a non-existent item from ⁴our dict, the defaultdict will use the function that was passed as argument to its constructor to build a new value – instead than raising a KeyError. In this case, the set function is used to build a new set each time we need it.  B⁴ the wa⁴, the collections module oﬀers a few useful data structures that can solve other kinds of problems, such as OrderedDict or Counter.  It’s reall⁴ important to look for the right data structure in P⁴thon, as the correct choice will save ⁴ou time, and lessen code maintenance.  10.2 Profiling  P⁴thon provides a few tools to profile ⁴our program. The standard one is cProfile and is eas⁴ enough to use. Example  cid:468  cid:467 . cid:468  Using the cProfile module  $ python -m cProfile myscript.py  343 function calls  342 primitive calls  in 0.000 seconds    cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:474  cid:473   Ordered by: standard name  ncalls tottime percall cumtime percall filename:lineno function   1 1 104 1 1 2 1 1 1  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 :0 _getframe  0.000 :0 len  0.000 :0 setattr  0.000 :0 setprofile  0.000 :0 startswith  0.000  :1    0.000 StringIO.py:30    0.000 StringIO.py:42 StringIO   The results list indicates the number of calls each function was called, and the time spent on its execution. You can use the -s option to sort b⁴ other fields; e.g. -s time will sort b⁴ internal time.  If ⁴ou’ve coded in C, as I did ⁴ears ago, ⁴ou probabl⁴ alread⁴ know the fantastic Valgrind tool, that – among other things – is able to provide profiling data for C programs. The data that it provides can then be visuali⁵ed b⁴ another great tool named KCacheGrind.  You’ll be happ⁴ to know that the profiling information generated b⁴ cProfile can eas- il⁴ be converted to a call tree that can be read b⁴ KCacheGrind. The cProfile mod- ule has a -o option that allows ⁴ou to save the profiling data, and p⁴prof cid:469 calltree can convert from one format to the other. Example  cid:468  cid:467 . cid:469  Using KCacheGrind to visuali⁵e P⁴thon profiling data  $ python -m cProfile -o myscript.cprof myscript.py $ pyprof2calltree -k -i myscript.cprof    cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:474  cid:474   Figure  cid:468  cid:467 . cid:468 : KCacheGrind example  This provides a lot of information that will allow ⁴ou to determine what part of ⁴our program might be consuming too much resources.  While this clearl⁴ works well for a macroscopic view of ⁴our program, it sometimes helps to have a microscopic view of some part of the code. In such a context, I find it better to rel⁴ on the dis module to find out what’s going on behind the scenes. The dis module is a disassembler of P⁴thon b⁴te code. It’s simple enough to use: >>> def x  : ... ... >>> import dis >>> dis.dis x   return 42  2  0 LOAD_CONST  1  42     cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:474  cid:475   3 RETURN_VALUE  The dis.dis function disassembles the function that ⁴ou passed as a parameter, and prints the list of b⁴tecode instructions that are run b⁴ the function. It can be useful to understand what’s reall⁴ behind each line of code that ⁴ou write, in order to be able to properl⁴ optimi⁵e ⁴our code.  The following code defines two functions, each of which does the same thing – con- catenates three letters: abc =  'a', 'b', 'c'   def concat_a_1  :  for letter in abc:  abc[0] + letter  def concat_a_2  :  a = abc[0] for letter in abc: a + letter  Both appear to do exactl⁴ the same thing, but if we disassemble them, we’ll see that the generated b⁴tecode is a bit diﬀerent: >>> dis.dis concat_a_1   2  3  >>  0 SETUP_LOOP 3 LOAD_GLOBAL 6 GET_ITER 7 FOR_ITER 10 STORE_FAST  13 LOAD_GLOBAL 16 LOAD_CONST  26  to 29  0  abc   18  to 28  0  letter   0  abc  1  0     cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:474  cid:476   >>> dis.dis concat_a_2   19 BINARY_SUBSCR 20 LOAD_FAST 23 BINARY_ADD 24 POP_TOP 25 JUMP_ABSOLUTE 28 POP_BLOCK 29 LOAD_CONST 32 RETURN_VALUE  0 LOAD_GLOBAL 3 LOAD_CONST 6 BINARY_SUBSCR 7 STORE_FAST  10 SETUP_LOOP 13 LOAD_GLOBAL 16 GET_ITER 17 FOR_ITER 20 STORE_FAST  23 LOAD_FAST 26 LOAD_FAST 29 BINARY_ADD 30 POP_TOP 31 JUMP_ABSOLUTE 34 POP_BLOCK 35 LOAD_CONST 38 RETURN_VALUE  >> >>  >>  >> >>  2  3  4  0  letter   7  0  None   0  abc  1  0   0  a   22  to 35  0  abc   14  to 34  1  letter   0  a  1  letter   17  0  None   As ⁴ou can see, in the second version we store abc[0] in a temporar⁴ variable be-    cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:475  cid:467   fore running the loop. This makes the b⁴tecode executed inside the loop a little smaller, as we avoid having to do the abc[0] lookup for each iteration. Measured using timeit, the second version is  cid:468  cid:467 % faster than the first one; it takes a whole microsecond less to execute! Obviousl⁴ this microsecond is not worth the optimi⁵a- tion unless ⁴ou call this function millions of times – but this is kind of insight that the dis module can provide.  Whether ⁴ou should need to rel⁴ on such "tricks" as storing the value outside the loop is debatable – ultimatel⁴, it should be the compiler’s work to optimi⁵e this kind of thing. On the other hand, as the language is heavil⁴ d⁴namic, it’s diﬀicult for the compiler to be sure that optimi⁵ation wouldn’t result in negative side eﬀects. So be careful when writing ⁴our code!  Another wrong habit I’ve oten encountered when reviewing code is the defining of functions inside functions for no reason. This has a cost – as the function is going to be redefined over and over for no reason. Example  cid:468  cid:467 . cid:470  A function defined in a function, disassembled  0 LOAD_CONST 3 RETURN_VALUE  1  42   >> import dis >>> def x  : ... ... >>> dis.dis x   return 42  2  2  def y  :  >>> def x  : ... ... ... ... >>> dis.dis x   return y    return 42  0 LOAD_CONST  1  <code object y at 0x100ce7e30, ←֓    cid:468  cid:467 . cid:469 . PROFILING   cid:468  cid:475  cid:468   file " ", line 2>  3 MAKE_FUNCTION 6 STORE_FAST  9 LOAD_FAST 12 CALL_FUNCTION 15 RETURN_VALUE  0 0  y   0  y  0  We can see here that it is needlessl⁴ complicated, calling MAKE_FUNCTION, STORE_F AST, LOAD_FAST and CALL_FUNCTION instead of just LOAD_CONST. That requires man⁴ more opcodes for no good reason – and function calling in P⁴thon is alread⁴ ineﬀi- cient.  The onl⁴ case in which it is required to define a function within a function is when building a function closure, and this is a perfectl⁴ identified use case in P⁴thon’s opcodes. Example  cid:468  cid:467 . cid:471  Disassembling a closure  4  2  3  a = 42 def y  :  >>> def x  : ... ... ... ... ... >>> dis.dis x   return y    return a  1  42  0  a   0 LOAD_CONST 3 STORE_DEREF  6 LOAD_CLOSURE 9 BUILD_TUPLE 12 LOAD_CONST  0  a  1 2  <code object y at 0x100d139b0, ←֓    cid:468  cid:467 . cid:470 . ORDERED LIST AND BISECT   cid:468  cid:475  cid:469   file " ", line 3>   5  15 MAKE_CLOSURE 18 STORE_FAST  21 LOAD_FAST 24 CALL_FUNCTION 27 RETURN_VALUE  0 0  y   0  y  0  10.3 Ordered list and bisect  When manipulating large lists, the use of sorted lists has a few advantages over non-sorted lists – for example, sorted lists have a retrieve time of O log n .  A couple of times, however, I’ve seen people tr⁴ing to implement their own data structures and algorithms to handle such cases. This is a bad idea – ⁴ou shouldn’t spend time on problems alread⁴ solved.  Firstl⁴, P⁴thon provides a bisect module which contains a bisection algorithm. It’s eas⁴ enough to use: Example  cid:468  cid:467 . cid:472  Usage of bisect  >>> farm = sorted ['haystack', 'needle', 'cow', 'pig']  >>> bisect.bisect farm, 'needle'  3 >>> bisect.bisect_left farm, 'needle'  2 >>> bisect.bisect farm, 'chicken'  0 >>> bisect.bisect_left farm, 'chicken'  0 >>> bisect.bisect farm, 'eggs'     cid:468  cid:467 . cid:470 . ORDERED LIST AND BISECT   cid:468  cid:475  cid:470   1 >>> bisect.bisect_left farm, 'eggs'  1  The bisect function allows ⁴ou to retrieve the index where a new list element should be inserted, while keeping the list sorted.  If ⁴ou wish to insert the element immediatel⁴, the bisect module provides the ins ort_left and insort_right functions that do exactl⁴ that. Example  cid:468  cid:467 . cid:473  Usage of bisect.insort  >>> farm ['cow', 'haystack', 'needle', 'pig'] >>> bisect.insort farm, 'eggs'  >>> farm ['cow', 'eggs', 'haystack', 'needle', 'pig'] >>> bisect.insort farm, 'turkey'  >>> farm ['cow', 'eggs', 'haystack', 'needle', 'pig', 'turkey']  You can then use these functions to create a list that is alwa⁴s sorted: Example  cid:468  cid:467 . cid:474  A SortedList implementation  import bisect  class SortedList list :  def __init__ self, iterable :  def insort self, item :  bisect.insort self, item   super SortedList, self .__init__ sorted iterable      cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:471   def index self, value, start=None, stop=None :  place = bisect.bisect_left self[start:stop], value  if start:  place += start  end = stop or len self  if place < end and self[place] == value:  return place  raise ValueError "%s is not in list" % value   Obviousl⁴, one shouldn’t use the direct functions append or extend on this list – or the list will no longer be sorted.  Man⁴ P⁴thon libraries exist which implement various versions of the above code – and man⁴ more data t⁴pes, such as binar⁴ or red-black tree structures. The blist and bintree P⁴thon packages contain code that ⁴ou can be use for these purposes, rather than implementing and debugging ⁴our own version.  10.4 Namedtuple and slots  Sometimes it’s useful to have the abilit⁴ to create ver⁴ simple objects which onl⁴ possess a few fixed attributes. A simple implementation would be something along these lines: class Point object :  def __init__ self, x, y :  self.x = x self.y = y  This definitel⁴ gets the job done – however, there is a downside to this approach: it creates a class which inherits from object. In using this Point class, ⁴ou be instanti- ating objects.    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:472   One propert⁴ of such objects in P⁴thon, is that the⁴ store all of their attributes inside a dictionar⁴; this dictionar⁴ is itself stored in the __dict__ attribute: >>> p = Point 1, 2  >>> p.__dict__ {'y': 2, 'x': 1} >>> p.z = 42 >>> p.z 42 >>> p.__dict__ {'y': 2, 'x': 1, 'z': 42}  The advantage is that ⁴ou can add as man⁴ attributes as ⁴ou want to an object. The drawback, however, is that using a dictionar⁴ to store these attributes is quite expensive in terms of memor⁴ – ⁴ou need to store the object, the ke⁴s, the value references, etc. It’s slow to create and slow to manipulate, with a high memor⁴ cost. Consider the following simple class: [source,python] class Foobar object :  def __init__ self, x :  self.x = x  Let’s check the memor⁴ usage using the memory_profiler P⁴thon package: $ python -m memory_profiler object.py Filename: object.py  Mem usage  Line  Line Contents ================================================  Increment  5 6  9.879 MB  0.000 MB  @profile def main  :    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:473   7  50.289 MB  100000  ]  40.410 MB  f = [ Foobar 42  for i in range ←֓  Therefore, it exists a wa⁴ to use objects without this default behaviour. Classes in P⁴thon can define a __slots__ attribute that will list the onl⁴ attributes allowed for instances of this class. The power of this is that instead of allocating a whole dictionar⁴ object to store all of the object attributes, the⁴ can now be stored in a list object. If ⁴ou go through the CP⁴thon source code and take a look at the Obje cts typeobject.c file, it is quite eas⁴ to understand what P⁴thon does in this case. Here is a cut down version of the function which handles this: static PyObject * type_new PyTypeObject *metatype, PyObject *args, PyObject *kwds  {  […]  * Check for a __slots__ sequence variable in dict, and count it *  slots = _PyDict_GetItemId dict, &PyId___slots__ ; nslots = 0; if  slots == NULL  { if  may_add_dict   add_dict++;  if  may_add_weak   add_weak++;  } else {   * Have slots *   * Make it into a tuple *  if  PyUnicode_Check slots    slots = PyTuple_Pack 1, slots ;  else  slots = PySequence_Tuple slots ;    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:474    * Are slots allowed? *  nslots = PyTuple_GET_SIZE slots ; if  nslots > 0 && base->tp_itemsize != 0  {  PyErr_Format PyExc_TypeError,  "nonempty __slots__ " "not supported for subtype of '%s'", base->tp_name ;  goto error;  }  * Copy slots into a list, mangle names and sort them.  Sorted names are needed for __class__ assignment. Convert them back to tuple at the end.a  *  newslots = PyList_New nslots - add_dict - add_weak ; if  newslots == NULL   goto error;  if  PyList_Sort newslots  == -1  {  Py_DECREF newslots ; goto error;  } slots = PyList_AsTuple newslots ; Py_DECREF newslots ; if  slots == NULL   goto error;  }  * Allocate the type object *  type =  PyTypeObject * metatype->tp_alloc metatype, nslots ; […]  * Keep name and slots alive in the extended type object *  et =  PyHeapTypeObject * type;    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:475   Py_INCREF name ; et->ht_name = name; et->ht_slots = slots; slots = NULL; […] return  PyObject * type;  class Foobar object :  __slots__ = 'x'  def __init__ self, x :  self.x = x  As ⁴ou can see, P⁴thon converts the content of __slots__ into a tuple, then a list that it builds and sorts, before converting it back into a tuple to use and store it in the class. This wa⁴, P⁴thon can retrieve the values quickl⁴, without having to allocate and use an entire dictionar⁴.  It’s eas⁴ enough to declare such a class: Example  cid:468  cid:467 . cid:475  A class declaration using __slots__  We can easil⁴ compare the memor⁴ usage of the two approaches using the memory _profiler P⁴thon package: Example  cid:468  cid:467 . cid:476  Memor⁴ usage of objects using __slots__  % python -m memory_profiler slots.py Filename: slots.py  Mem usage  Line  Line Contents ================================================  Increment  7 8  9.879 MB  0.000 MB  @profile def main  :    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:475  cid:476   9  21.609 MB  100000  ]  11.730 MB  f = [ Foobar 42  for i in range ←֓  So it seems that b⁴ using the __slots__ attribute of P⁴thon classes, we can halve our memor⁴ usage – this means that when creating a large amount of simple ob- jects, the __slots__ attribute is an eﬀective and eﬀicient choice. However, the tech- nique shouldn’t be misused in order to perform static t⁴ping or the like. This isn’t in the spirit of P⁴thon programs.  Due to the fixed nature of the attribute list, it’s eas⁴ enough to imagine classes where the attributes listed would alwa⁴s have a value, and where the fields would alwa⁴s be sorted in some wa⁴.  That’s exactl⁴ the nature of the namedtuple class from the collection module. It al- lows us to d⁴namicall⁴ create a class that will inherit from tuple, therefore sharing its characteristics – such as being immutable, and having a fixed number of entries. What namedtuple provides is the abilit⁴ to retrieve the tuple elements b⁴ referenc- ing a named attribute, rather than just referencing b⁴ index. Example  cid:468  cid:467 . cid:468  cid:467  Declaring a class using namedtuple  >>> import collections >>> Foobar = collections.namedtuple 'Foobar', ['x']  >>> Foobar = collections.namedtuple 'Foobar', ['x', 'y']  >>> Foobar 42, 43  Foobar x=42, y=43  >>> Foobar 42, 43 .x 42 >>> Foobar 42, 43 .x = 44 Traceback  most recent call last :  File " ", line 1, in    AttributeError: can't set attribute >>> Foobar 42, 43 .z = 0    cid:468  cid:467 . cid:471 . NAMEDTUPLE AND SLOTS   cid:468  cid:476  cid:467   Traceback  most recent call last :  File " ", line 1, in    AttributeError: 'Foobar' object has no attribute 'z' >>> list Foobar 42, 43   [42, 43]  Since a class like this would inherit from tuple, we can easil⁴ convert it to a list. We can’t change or add an⁴ attributes on objects of this class, because on one hand it inherits from tuple, and also because the __slots__ value is set to an empt⁴ tuple – thereb⁴ avoiding the creating of the __dict__. Example  cid:468  cid:467 . cid:468  cid:468  Memor⁴ usage of a class built from collections.namedtuple  % python -m memory_profiler namedtuple.py Filename: namedtuple.py  Mem usage  Line Contents Line  ================================================  Increment  4 5 6  9.895 MB 23.184 MB  100000  ]  @profile def main  :  0.000 MB 13.289 MB  f = [ Foobar 42  for i in range ←֓  Therefore, usage of the namedtuple class factor⁴ is as almost as eﬀicient as using an object with __slots__, the onl⁴ diﬀerence being that it is compatible with the tuple class. It can therefore be passed to man⁴ native P⁴thon functions and libraries that expect an iterable t⁴pe as an argument. It also enjo⁴s the various optimi⁵ations that exist for tuples ¹.  namedtuple also provides a few extra methods that, even if prefixed b⁴ an under- score, are actuall⁴ intended to be public. _asdict can convert the namedtuple to ¹For example, tuples smaller than PyTuple_MAXSAVESIZE   cid:469  cid:467  b⁴ default  will use a faster memor⁴  allocator in CP⁴thon    cid:468  cid:467 . cid:472 . MEMOIZATION   cid:468  cid:476  cid:468   a dict instance, _make allows us to convert an existing iterable object to this class, and _replace returns a new instance of the object with some fields replaced.  10.5 Memoization  Memoi⁵ation is a technique used to speed up function calls b⁴ caching their result. The results can be cached onl⁴ if the function is pure – meaning that it has no side eﬀects or outputs, and that it does not depend on an⁴ global state.  A trivial function that can be memoi⁵ed is the sine function sin. Example  cid:468  cid:467 . cid:468  cid:469  A basic memoi⁵ation technique  _SIN_MEMOIZED_VALUES[x] = math.sin x   return _SIN_MEMOIZED_VALUES[x]  if x not in _SIN_MEMOIZED_VALUES:  >>> import math >>> _SIN_MEMOIZED_VALUES = {} >>> def memoized_sin x : ... ... ... >>> memoized_sin 1  0.8414709848078965 >>> _SIN_MEMOIZED_VALUES {1: 0.8414709848078965} >>> memoized_sin 2  0.9092974268256817 >>> memoized_sin 2  0.9092974268256817 >>> _SIN_MEMOIZED_VALUES {1: 0.8414709848078965, 2: 0.9092974268256817} >>> memoized_sin 1  0.8414709848078965 >>> _SIN_MEMOIZED_VALUES    cid:468  cid:467 . cid:472 . MEMOIZATION   cid:468  cid:476  cid:469   {1: 0.8414709848078965, 2: 0.9092974268256817}  The first time that memoized_sin is called with an argument that is not stored in _SI N_MEMOIZED_VALUES, the value will be computed and stored in this dictionar⁴. Later on, if we call the function with the same value again, the result will be retrieved from the dictionar⁴ rather than computed again. While sin is a function which computes ver⁴ quickl⁴, this ma⁴ not be true of some advanced functions which involve more complicated computations.  If ⁴ou’ve alread⁴ read about decorators  if not, go to Section  cid:474 . cid:468  , ⁴ou must be think- ing that there is a perfect opportunit⁴ to use them here – and ⁴ou’d be right. P⁴PI lists a few implementations of memoi⁵ation through decorators, from ver⁴ simple cases to the most complex and complete.  Starting with P⁴thon  cid:470 . cid:470 , the functools module provides a LRU  Least-Recentl⁴- Used  cache decorator. This provides the same functionalit⁴ as the memoi⁵ation described here, but with the benefit that it limits the number of entries in the cache, removing the least recentl⁴ used one when the cache si⁵e reaches its maximum si⁵e.  The module also provides statistics on cache hits, misses, etc. In m⁴ opinion, these are a must-haves when implementing such a cache. There’s no point in using mem- oi⁵ation – or an⁴ caching technique – if ⁴ou are unable to meter its usage and use- fulness.  Here’s an example of the memoized_sin function above, using functools.lru_ca che: Example  cid:468  cid:467 . cid:468  cid:470  Using functools.lru_cache  >>> import functools >>> import math >>> @functools.lru_cache maxsize=2  ... def memoized_sin x : ...  return math.sin x     cid:468  cid:467 . cid:473 . PYPY   cid:468  cid:476  cid:470   ... >>> memoized_sin 2  0.9092974268256817 >>> memoized_sin.cache_info   CacheInfo hits=0, misses=1, maxsize=2, currsize=1  >>> memoized_sin 2  0.9092974268256817 >>> memoized_sin.cache_info   CacheInfo hits=1, misses=1, maxsize=2, currsize=1  >>> memoized_sin 3  0.1411200080598672 >>> memoized_sin.cache_info   CacheInfo hits=1, misses=2, maxsize=2, currsize=2  >>> memoized_sin 4  -0.7568024953079282 >>> memoized_sin.cache_info   CacheInfo hits=1, misses=3, maxsize=2, currsize=2  >>> memoized_sin 3  0.1411200080598672 >>> memoized_sin.cache_info   CacheInfo hits=2, misses=3, maxsize=2, currsize=2  >>> memoized_sin.cache_clear   >>> memoized_sin.cache_info   CacheInfo hits=0, misses=0, maxsize=2, currsize=0   10.6 PyPy  P⁴P⁴ is an eﬀicient implementation of the P⁴thon language which complies with standards. Indeed, the canonical implementation of P⁴thon, CP⁴thon – so called    cid:468  cid:467 . cid:473 . PYPY   cid:468  cid:476  cid:471   because it’s written in C – can be ver⁴ slow. The idea behind P⁴P⁴ was to write a P⁴thon interpreter in P⁴thon itself. In time it evolved to be written in RP⁴thon, which is a restricted subset of the P⁴thon language.  RP⁴thon places constraints on the P⁴thon language in such a wa⁴ that a variable’s t⁴pe can be inferred at compile time. The RP⁴thon code is translated to C code that is compiled to build the interpreter – RP⁴thon could of course be used to implement other languages than P⁴thon.  What’s interesting in P⁴P⁴, besides the technical challenge, is that it is now at a stage where it can act as a faster replacement for CP⁴thon. P⁴P⁴ has a JIT  Just- In-Time  compiler built-in – long stor⁴ short, it allows the code to be run in a faster wa⁴ b⁴ combining the speed of compiled code with the flexibilit⁴ of interpretation.  How fast? That depends, but for pure algorithmic code it is much faster. For more general code, P⁴P⁴ claims to achieve  cid:470  times the speed, most of the time. Though don’t start dreaming too much about it ⁴et – P⁴P⁴ also has some of the CP⁴thon limitations, such as the hated GIL. ²  While not being a strict optimi⁵ation technique, targeting P⁴P⁴ as one of ⁴our sup- ported P⁴thon implementations is probabl⁴ a good idea. Achieving this goal re- quires the same kind of coding polic⁴ that is required for support of other P⁴thon versions – basicall⁴, ⁴ou need to make sure that ⁴ou are testing ⁴our sotware un- der P⁴P⁴ like ⁴ou do under CP⁴thon. tox  see Section  cid:473 . cid:474   supports the building of virtual environments using P⁴P⁴, just as it does for CP⁴thon  cid:469  or CP⁴thon  cid:470 , so it should be prett⁴ straightforward to put this in place.  Doing so at the beginning of the project will make sure that there’s not too much work to do at a later stage if ⁴ou wish to be able to run ⁴our sotware with P⁴P⁴.  ²Global Interpreter Lock    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:468  cid:476  cid:472   Note For the Hy project, we successfully adopted such a strategy from the beginning. Hy always  has supported PyPy and all CPython versions without much trouble. On the other hand,  we failed to do so in all of our OpenStack projects, and we are now blocked by various  code paths and dependencies that don’t work on PyPy for various reasons, as they weren’t  fully tested in the early stages.  P⁴P⁴ is compatible with P⁴thon  cid:469 . cid:474 , and its JIT compiler works on  cid:470  cid:469 - and  cid:473  cid:471 -bit, x cid:475  cid:473  and ARM architectures, and under various operating s⁴stems  Linux, Windows, Mac OS X… . Support for P⁴thon  cid:470  is underwa⁴.  10.7 Achieving zero copy with the buffer protocol  Oten programs have to deal with a huge amount of data in the form of large arra⁴s of b⁴tes. Handling such a large amount of data in strings can be ver⁴ ineﬀective once ⁴ou start manipulating it b⁴ cop⁴ing, slicing, and modif⁴ing them.  Let’s consider a small program which reads a large file of binar⁴ data, and copies it partiall⁴ into another file. To examine out our memor⁴ usage, we will use mem- or⁴_profiler, a nice P⁴thon package that allows us to see the memor⁴ usage of a program line b⁴ line. @profile def read_random  :  with open " dev urandom", "rb"  as source:  content = source.read 1024 * 10000  content_to_write = content[1024:]  print "Content length: %d, content to write length %d" %   len content , len content_to_write     with open " dev null", "wb"  as target:    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:468  cid:476  cid:473   target.write content_to_write   if __name__ == '__main__':  read_random    We then run the above program using memory_profiler: $ python -m memory_profiler memoryview copy.py Content length: 10240000, content to write length 10238976 Filename: memoryview copy.py  Line Contents Mem usage ======================================  Increment  @profile def read_random  :  9.883 MB 9.887 MB 19.656 MB 29.422 MB 29.422 MB  29.434 MB 29.434 MB 29.434 MB  0.000 MB 0.004 MB 9.770 MB 9.766 MB 0.000 MB  0.012 MB 0.000 MB 0.000 MB  length %d" %  with open " dev urandom", "rb"  as source: content = source.read 1024 * 10000  ②1 content_to_write = content[1024:] ②2  print "Content length: %d, content to write ←֓   len content , len content_to_write     with open " dev null", "wb"  as target:  target.write content_to_write   ②1 We are reading  cid:468  cid:467  MB from  dev urandom and not doing much with it. P⁴thon  needs to allocate around  cid:468  cid:467  MB of memor⁴ to store this data as a string.  ②2 We cop⁴ the entire block of data minus the first KB – because we won’t be writ-  ing to that first KB to the target file.  What’s interesting in this example is that, as ⁴ou can see, the memor⁴ usage of the program is increased b⁴ about  cid:468  cid:467  MB when building the variable content_to_write.    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:468  cid:476  cid:474   In fact, the slice operator is cop⁴ing the entiret⁴ of content, minus the first KB, into a new string object.  When dealing with large data, performing this kind of operation on large b⁴te arra⁴s is going to be a disaster. If ⁴ou happen to have written C code alread⁴, ⁴ou know that using memcpy   has a significant cost, both in term of memor⁴ usage and in terms of general performance: cop⁴ing memor⁴ is slow.  But as a C programmer ⁴ou’ll also know that strings are arra⁴s of characters, and that nothing stops ⁴ou from looking at onl⁴ part of this arra⁴ without cop⁴ing it, through the use of basic pointer arithmetic ³.  This is possible in P⁴thon using objects which implement the buﬀer protocol. The buﬀer protocol is defined in PEP  cid:470  cid:468  cid:468  cid:475 , which explains the C API used to provide this protocol to various t⁴pes, such as strings.  When an object implements this protocol, ⁴ou can use the memoryview class con- structor on it to build a new memoryview object that will reference the original ob- ject memor⁴.  Here’s an example: >>> s = b"abcdefgh" >>> view = memoryview s  >>> view[1] 98 ②1 >>> limited = view[1:3]   >>> bytes view[1:3]  b'bc'  ②1  This is the ASCII code for the letter b.  ³Assuming that the entire string is in a contiguous memor⁴ area.    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:468  cid:476  cid:475   Figure  cid:468  cid:467 . cid:469 : Using slice on memoryview objects  In this case, we are going to make use of the fact that the memoryview object’s slice operator itself returns a memoryview object. That means it does not cop⁴ an⁴ data, but merel⁴ references a particular slice of it.  With this in mind, we now can rewrite the program, this time referencing the data we want to write using a memoryview object. @profile def read_random  :  with open " dev urandom", "rb"  as source:  content = source.read 1024 * 10000  content_to_write = memoryview content [1024:]  print "Content length: %d, content to write length %d" %   len content , len content_to_write     with open " dev null", "wb"  as target:  target.write content_to_write   if __name__ == '__main__':  read_random    And this program will have half the memor⁴ usage of the first version: $ python -m memory_profiler memoryview copy-memoryview.py Content length: 10240000, content to write length 10238976 Filename: memoryview copy-memoryview.py    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:468  cid:476  cid:476   Line Contents Mem usage ======================================  Increment  @profile def read_random  :  9.887 MB 9.891 MB 19.660 MB 19.660 MB  0.000 MB 0.004 MB 9.770 MB 0.000 MB  [1024:] ②2  length %d" %  19.672 MB 19.672 MB 19.672 MB  0.012 MB 0.000 MB 0.000 MB  with open " dev urandom", "rb"  as source: content = source.read 1024 * 10000  ②1 content_to_write = memoryview content  ←֓   len content , len content_to_write     with open " dev null", "wb"  as target:  target.write content_to_write   19.660 MB  0.000 MB  print "Content length: %d, content to write ←֓  ②1 We are reading  cid:468  cid:467  MB from  dev urandom and not doing much with it. P⁴thon  needs to allocate around  cid:468  cid:467  MB of memor⁴ to store this data as a string.  ②2 We reference the entire block of data minus the first KB – because we won’t be writing to that first KB to the target file. No cop⁴ing means that no more memor⁴ is used!  This kind of trick is especiall⁴ useful when dealing with sockets. As ⁴ou ma⁴ know, when data is sent over a socket, it might not send all the data in a single call. A simple implementation would be to write: import socket s = socket.socket …  s.connect …  data = b"a" *  1024 * 100000  ②1 while data:    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:469  cid:467  cid:467   sent = s.send data  data = data[sent:] ②2  ②1  ②2  ②1  ②2  Build a b⁴tes object with more than  cid:468  cid:467  cid:467  millions times the letter a.  Remove the first sent b⁴tes sent.  Obviousl⁴, using such a mechanism, ⁴ou are going to cop⁴ the data over and over until the socket has sent ever⁴thing. Using memoryview, we can achieve the same functionalit⁴ without cop⁴ing data – hence, ⁵ero cop⁴: import socket s = socket.socket …  s.connect …  data = b"a" *  1024 * 100000  ②1 mv = memoryview data  while mv:  sent = s.send mv  mv = mv[sent:] ②2  Build a b⁴tes object with more than  cid:468  cid:467  cid:467  millions times the letter a.  Build a new memor⁴view object pointing to the data which remains to be sent.  This won’t cop⁴ an⁴thing, and won’t use an⁴ more memor⁴ than the  cid:468  cid:467  cid:467  MB initiall⁴ needed for our data variable.  We’ve now seen memor⁴view objects used to write data eﬀicientl⁴, but the same method can also be used to read data. Most I O operations in P⁴thon know how to deal with objects implementing the buﬀer protocol. The⁴ can read from it, but also write to it. In this case, we don’t need memoryview objects – we can just ask an I O function to write into our pre-allocated object:    cid:468  cid:467 . cid:474 . ACHIEVING ZERO COPY WITH THE BUFFER PROTOCOL   cid:469  cid:467  cid:468   >>> ba = bytearray 8  >>> ba bytearray b'\x00\x00\x00\x00\x00\x00\x00\x00'  >>> with open " dev urandom", "rb"  as source: ... ... 8 >>> ba bytearray b'`m.z\x8d\x0fp\xa1'   source.readinto ba   With such techniques, it’s eas⁴ to pre-allocate a buﬀer  as ⁴ou would do in C to mit- igate the number of calls to malloc    and fill it at ⁴our convenience. Using memo- ryview, ⁴ou can even place data at an⁴ point in the memor⁴ area: >>> ba = bytearray 8  >>> ba_at_4 = memoryview ba [4:] ②1 >>> with open " dev urandom", "rb"  as source: ... ... 4 >>> ba bytearray b'\x00\x00\x00\x00\x0b\x19\xae\xb2'   source.readinto ba_at_4  ②2  ②1 We reference the bytearray from oﬀset  cid:471  to its end.  ②2 We write the content of  dev urandom from oﬀset  cid:471  to the end of the bytearray,  eﬀectivel⁴ reading  cid:471  b⁴tes onl⁴.  Tip Both the objects in the array module and the functions in the struct module can handle the  buffer protocol correctly, and can therefore perform efficiently when targeting zero copy.    cid:468  cid:467 . cid:475 . INTERVIEW WITH VICTOR STINNER   cid:469  cid:467  cid:469   10.8 Interview with Victor Stinner  Victor is a long time P⁴thon hacker, a core contributor and the author of man⁴ P⁴thon modules. He recentl⁴ authored PEP  cid:471  cid:472  cid:471 , which proposes a new tracemal loc module to trace memor⁴ block allocation inside P⁴thon, and also wrote a sim- ple AST optimi⁵er.  What’s a good starting strategy to optimize Python code? Well, the strateg⁴ is the same in P⁴thon as in other languages. First ⁴ou need a well-defined use case, in order to get a stable and reproducible benchmark. Without a reliable benchmark, tr⁴ing diﬀerent optimi⁵ations ma⁴ result in a wasting time and premature optimi⁵ations. Useless op- timi⁵ations ma⁴ make the code worse, less readable, or even slower. A useful optimi⁵ation must speed the program up b⁴ at least  cid:472 %.  If a specific part of the code is identified as being "slow", a benchmark should be prepared on this code. A benchmark on a short function is usu- all⁴ called a "micro-benchmark". The speedup should be at least  cid:469  cid:467 %, ma⁴be  cid:469  cid:472 %, to justif⁴ an optimi⁵ation on a micro-benchmark.  It ma⁴ be interesting to run a benchmark on diﬀerent computers, diﬀer- ent operating s⁴stems, diﬀerent compilers. For example, performances of realloc   ma⁴ var⁴ between Linux and Windows. Even if it should be avoided, sometimes, the implementation ma⁴ depend on the platform. There’s a lot of diﬀerent tools around for profiling or optimizing Python code; what are your weapons of choice?    cid:468  cid:467 . cid:475 . INTERVIEW WITH VICTOR STINNER   cid:469  cid:467  cid:470   P⁴thon  cid:470 . cid:470  has a new time.perf_counter   function to measure elapsed time for a benchmark. It has the best resolution available.  A test should be run more than once;  cid:470  times is a minimum,  cid:472  ma⁴ be enough. Repeating a test fills disk cache and CPU caches. I prefer to keep the minimum timing, other developers prefer the geometric mean.  For micro-benchmarks, the timeit module is eas⁴ to use and gives results quickl⁴, but the results are not reliable using default parameters. Tests should be repeated manuall⁴ to get stable results.  Optimi⁵ing can take a lot of time, so it’s better to focus on functions which use the most CPU power. To find these functions, P⁴thon has cProfile and profile modules which record the amount of time spent in each func- tion. What are the interesting Python tricks to know that could improve performance? The standard librar⁴ should be reused as much as possible – it’s well tested, and also usuall⁴ eﬀicient. P⁴thon built-in t⁴pes are implemented in C and have good performance. Use the correct container to get the best per- formance; P⁴thon provides man⁴ diﬀerent kind of containers – dict, list, deque, set, etc.  There are some hacks to optimi⁵e P⁴thon, but the⁴ should be avoided because the⁴ make the code less readable in exchange for onl⁴ a minor speed-up.  The Zen of P⁴thon  PEP  cid:469  cid:467   sa⁴s "There should be one – and preferabl⁴ onl⁴ one – obvious wa⁴ to do it." In practice, there are diﬀerent wa⁴s to write P⁴thon code, and performances are not the same. Onl⁴ trust bench- marks on ⁴our use case. In which areas does Python have poor performance? Which areas should    cid:468  cid:467 . cid:475 . INTERVIEW WITH VICTOR STINNER   cid:469  cid:467  cid:471   be used with care? In general, I prefer not to worr⁴ about performance while developing a new application. Premature optimi⁵ation is the root of all evil. When slow functions are identified, the algorithm should be changed. If the al- gorithm and the container t⁴pes are well chosen, it’s possible to rewrite short functions in C to get best performances.  A bottleneck in CP⁴thon is the Global Interpreter Lock known as the "GIL". Two threads cannot execute P⁴thon b⁴tecode at the same time. However, this limitation onl⁴ matters if two threads are executing pure P⁴thon code. If most processing time is spent in function calls, and these functions re- lease the GIL, then the GIL is not the bottleneck. For example, most I O functions release the GIL.  The multiprocessing module can easil⁴ be used to workaround the GIL. Another option, more complex to implement, is to write as⁴nchronous code. Twisted, Tornado and Tulip projects, which are network-oriented libraries, make use of this technique. What "mistakes" that contribute to poor performance do you see most oten? When P⁴thon is not well understood, ineﬀicient code can be written. For example, I have seen copy.deepcopy   misused, when no cop⁴ was re- quired.  Another performance-killer is an ineﬀicient data structure. With less than one hundred items, the container t⁴pe has no impact on performance. With more items, the complexit⁴ of each operation  add, get, delete  and it’s eﬀects must be known.    cid:468  cid:468  Scaling and architecture  Nowada⁴s all the h⁴pe is about resilienc⁴ and scalabilit⁴, so I assume this is some- thing that ⁴our development process is going to have to take into account sooner or later. Man⁴ sides of the issue are not particularl⁴ tied to P⁴thon itself, while some are onl⁴ relevant to its main implementation, CP⁴thon.  The scalabilit⁴, concurrenc⁴ and parallelism of an application largel⁴ depend on the choices made about its initial architecture and design. As ⁴ou’ll see, there are some paradigms – like multi-threading – that don’t appl⁴ correctl⁴ to P⁴thon, whereas other techniques, such as service oriented architecture, work better.  11.1 A note on multi-threading  What is multi-threading? It’s the abilit⁴ to run code on separate processors ¹ inside a single P⁴thon process. This means that diﬀerent parts of ⁴our code will be run in parallel.  Wh⁴ is this needed? The most common cases are:   cid:468 . You need to run background tasks without stopping ⁴our main thread’s exe- in the case of a graphical user interface where the main loop is  cution, e.g. waiting for events.  ¹Or sequentiall⁴ on one, if multiple CPUs aren’t present    cid:468  cid:468 . cid:468 . A NOTE ON MULTI-THREADING   cid:469  cid:467  cid:473    cid:469 . You need to spread ⁴our work-load across several CPUs.  So at first, it ma⁴ seem that multi-threading looks like a good wa⁴ to scale and par- alleli⁵e ⁴our application, solving these problems. When ⁴ou want to spread a work- load, ⁴ou start a new thread for each new request instead of handling them one at a time.  Wonderful. Job done. We can move on.  No – sorr⁴! First, if ⁴ou’ve been in the P⁴thon world for a long time, ⁴ou’ve probabl⁴ encountered the word GIL, and know how hated it is. The GIL is the P⁴thon Global Interpreter Lock, a lock that must be acquired each time CPython ² needs to execute b⁴te-code. Unfortunatel⁴, this means that if ⁴ou tr⁴ to scale ⁴our application b⁴ making it run multiple threads, ⁴ou’ll alwa⁴s be limited b⁴ this global lock.  So while using threads seems like the ideal solution, in fact most applications I’ve seen running requests in multiple threads struggle to attain  cid:468  cid:472  cid:467 % CPU usage – i.e.  cid:468 . cid:472  cores used. With computing nodes nowada⁴s not usuall⁴ having less than  cid:469  or  cid:471  cores, it’s a shame. Blame the GIL.  There isn’t currentl⁴ an⁴ work being done to remove the GIL in CPython, because nobod⁴ thinks the solution is worth the diﬀicult⁴ of implementing and maintaining it.  However, CPython is just one ³ of the available P⁴thon implementations. J⁴thon, for example, doesn’t have a global interpreter lock, which means that it can run multiple threads in parallel eﬀicientl⁴. Unfortunatel⁴, these projects b⁴ their ver⁴ nature lag behind CPython, and so are not reall⁴ useful targets.  ²The reference implementation of P⁴thon written in C that ⁴ou run b⁴ t⁴ping python in ⁴our shell. ³although the most commonl⁴ used.    cid:468  cid:468 . cid:468 . A NOTE ON MULTI-THREADING   cid:469  cid:467  cid:474   Note PyPy is another Python implementation, but is written in Python  see Section 10.6 . PyPy  has a GIL too, but very interesting work is happening right now to replace it with a STM   Software Transactional Memory -based implementation. This is something very exciting  that’s going to change how we build and run multi-threading software in the future. Hard-  ware support is starting to appear in some processors, and Linux kernel developers are  looking at ways to suppress kernel locks too. These are good signs.  So are we back to our initial use cases, with no good solutions on oﬀer? Not true – there’s  at least  two solutions ⁴ou can use:   cid:468 . If ⁴ou need to run background tasks, the easiest wa⁴ to do that is to build ⁴our application around an event loop. There’s a lot of diﬀerent P⁴thon modules which provide for this, even a standard one called asyncore, which is an ef- fort to standardi⁵e this functionalit⁴ as part of PEP  cid:470  cid:468  cid:472  cid:473 . Some frameworks such as Twisted are built around this concept. The most advanced ones should give ⁴ou access to events based on signals, timers and file descriptors activit⁴ – we’ll talk about this in Section  cid:468  cid:468 . cid:470 .   cid:469 . If ⁴ou need to spread the work-load, using multiple processes is going to be  more eﬀicient and easier. See Section  cid:468  cid:468 . cid:469 .  For us developers, mere mortals, it all means that we should think twice before us- ing multi-threading. I’ve used multi-threading to dispatch jobs in rebuildd, a De- bian build daemon I wrote a few ⁴ears ago. While it seemed hand⁴ to have a thread to control each running build job, I ver⁴ quickl⁴ fell into the concurrenc⁴ trap. If I had the chance to begin again, I’d build something based on as⁴nchronous events handling or multi-processing, and not have to worr⁴ about this problem.  Getting multi-threaded applications right is hard. The level of complexit⁴ means that it is a larger source of bugs than most others – and considering the little to be    cid:468  cid:468 . cid:469 . MULTIPROCESSING VS MULTITHREADING   cid:469  cid:467  cid:475   gained generall⁴, it’s better not to waste too much eﬀort on it.  11.2 Multiprocessing vs multithreading  As explained earlier, multi-threading is not a good scalabilit⁴ solution because of the GIL. A better solution is themultiprocessing package that is provided with P⁴thon. It provides the same kind of interface that ⁴ou would have using the multithread- ing module, except that it starts new processes  via fork  cid:469    rather than new s⁴stem threads. The below program is a simple example, which sums one million random integers  cid:475  times, spread across  cid:475  threads at the same time. Worker using multithreading import random import threading  results = []  def compute  :  results.append sum   [random.randint 1, 100  for i in range 1000000 ]    workers = [threading.Thread target=compute  for x in range 8 ] for worker in workers:  worker.start    for worker in workers:  worker.join    print "Results: %s" % results   Running this program returns the following:    cid:468  cid:468 . cid:469 . MULTIPROCESSING VS MULTITHREADING   cid:469  cid:467  cid:476   Example  cid:468  cid:468 . cid:468  Result of time python worker.py $ time python worker.py Results: [50517927, 50496846, 50494093, 50503078, 50512047, ←֓  50482863, 50543387, 50511493]  python worker.py 13.04s user 2.11s system 129% cpu 11.662 total  This has been run on an idle  cid:471  cores CPU, which means that P⁴thon could have used up to  cid:471  cid:467  cid:467 % CPU power. But it was clearl⁴ unable to do that, even with  cid:475  threads run- ning in parallel – it stuck at  cid:468  cid:469  cid:476 %, which is just  cid:470  cid:469 % of the hardware’s capabilities.  Now, let’s rewrite this implementation using multiprocessing. For a simple case like this, it’s prett⁴ straightforward: Example  cid:468  cid:468 . cid:469  Worker using multiprocessing  import multiprocessing import random  def compute n : return sum   [random.randint 1, 100  for i in range 1000000 ]    Start 8 workers pool = multiprocessing.Pool 8  print "Results: %s" % pool.map compute, range 8     Running this program under the exact same conditions gives the following result: Example  cid:468  cid:468 . cid:470  Result of time python worker.py $ time python workermp.py Results: [50495989, 50566997, 50474532, 50531418, 50522470, ←֓  50488087, 50498016, 50537899]    cid:468  cid:468 . cid:470 . ASYNCHRONOUS AND EVENT-DRIVEN ARCHITECTURE   cid:469  cid:468  cid:467   python workermp.py 16.53s user 0.12s system 363% cpu 4.581 total  The execution time has been reduced b⁴  cid:473  cid:467 %; this time, we have been able to con- sume up to  cid:470  cid:473  cid:470 % of CPU power, which is more than  cid:476  cid:467 % of the computer’s CPU capacit⁴.  A further note – the multithreading module is not onl⁴ able to eﬀicientl⁴ spread a work-loads over several local processors, but can also do so over a network, through its multithreading.managers objects. It also provides bi-directional communica- tion transports so ⁴our processes can exchange information with each other.  Each time ⁴ou think that ⁴ou can parallelize some work for a certain amount of time, it’s much better to rel⁴ on multi-processing and to fork ⁴our jobs, in order to spread the workload among several CPU cores.  11.3 Asynchronous and event-driven architecture  Event-driven programming is a good solution to organi⁵e program flow in a wa⁴ which listens for various events at once, without using a multi-threaded approach.  Consider an application that wants to listen for connection on a socket and then process the connection it receives. There are basicall⁴ three wa⁴s to approach the problem:   cid:468 . Fork a new process each time a new connection is established, rel⁴ing on some-  thing like the multiprocessing module.   cid:469 . Start a new thread each time a new connection is established, rel⁴ing on some-  thing like the threading module.   cid:470 . Add this new connection to ⁴our event loop, and react to the event it will gen-  erate when it occurs.    cid:468  cid:468 . cid:470 . ASYNCHRONOUS AND EVENT-DRIVEN ARCHITECTURE   cid:469  cid:468  cid:468   It is  now  well known that listening to hundreds of event sources is going to scale much better when using an event-driven approach than, sa⁴, a thread-per-event approach ⁛. This doesn’t mean that the two techniques are not compatible, but it does mean that ⁴ou can usuall⁴ get rid of multiple threads b⁴ using an event-driven mechanism.  We’ve alread⁴ covered the pros and cons of the first options; in this section, onl⁴ the event-driven mechanism will be discussed.  The technique behind event-driven architecture is the building of an event loop. Your program calls a function that blocks until an event is received. The idea behind this is that ⁴our program can be kept bus⁴ while waiting for inputs and outputs to complete; the most basic events are "I have data read⁴ to be read" or "I can now write data without blocking".  In Unix, the standard functions used to build such an event loop are the s⁴stem calls select 2  or poll 2 . The⁴ expect a few file descriptors to listen for, and will react when one of them is read⁴ to be read from or written to.  In P⁴thon, these s⁴stem calls are exposed through the select module. enough to build an event-driven s⁴stem with them, though it can be tedious. Example  cid:468  cid:468 . cid:471  Basic example of using select  It’s eas⁴  import select import socket  server = socket.socket socket.AF_INET,  socket.SOCK_STREAM    Never block on read write operations server.setblocking 0    Bind the socket to the port  ⁛For further reading on this, take a look at the C cid:468  cid:467 K problem.    cid:468  cid:468 . cid:470 . ASYNCHRONOUS AND EVENT-DRIVEN ARCHITECTURE   cid:469  cid:468  cid:469    select   returns 3 arrays containing the object  sockets, files…  ←֓  server.bind  'localhost', 10000   server.listen 8   while True:  that   are ready to be read, written to or raised an error inputs, outputs, excepts = select.select   [server], [], [server]   if server in inputs:  connection, client_address = server.accept   connection.send "hello!\n"   A wrapper around these low-level interfaces was added to P⁴thon in the earl⁴ da⁴s, called asyncore. It is not widel⁴ used, and hasn’t evolved much.  Alternativel⁴, there are man⁴ frameworks which provide this kind of functionalit⁴ in a more integrated manner, such as Twisted or Tornado. Twisted has been almost a de-facto standard for ⁴ears in this regard. C libraries that export P⁴thon interfaces, such as libevent, libev or libuv, also provides ver⁴ eﬀicient event loops.  While the⁴ all solve the same problem, the downside is that nowada⁴s there are too man⁴ choices, and most of them are not interoperable. Also, most of them are callback based – which means that the program flow is not reall⁴ clear when reading the code.  What about gevent or Greenlet? The⁴ avoid the use of callback, but the imple- mentation details are scar⁴, and include CP⁴thon x cid:475  cid:473  specific code and monke⁴- patching of standard functions. Not something ⁴ou want to use and maintain on the long term, reall⁴.  Recentl⁴, Guido Van Rossum started to work on a solution code-named tulip, which    cid:468  cid:468 . cid:470 . ASYNCHRONOUS AND EVENT-DRIVEN ARCHITECTURE   cid:469  cid:468  cid:470   is documented under PEP  cid:470  cid:468  cid:472  cid:473 .⁜ The goal of this package is to provide a standard event loop interface. In the future, all frameworks and libraries would be compati- ble with it and would be able to interoperate.  tulip has been renamed and merged into P⁴thon  cid:470 . cid:471  as the asyncio package. If ⁴ou don’t plan to depend on P⁴thon  cid:470 . cid:471 , it’s also possible to install it for P⁴thon  cid:470 . cid:470  us- ing the version provided on P⁴PI – simpl⁴ running pip install asyncio will do the job. Victor Stinner started a backport of tulip named trollius, which aims to be compatible with P⁴thon  cid:469 . cid:473  and superior versions.  Now that ⁴ou’ve got all the cards in ⁴our hand, no doubt ⁴ou’re wondering: but what should I use to build an event loop in my event-driven application? At this point in P⁴thon’s development, it’s a reall⁴ tough question. The language is still in a transition phase. As of the time of this writing, nothing ⁴et uses the asyncio module. That means that using is going to be a real challenge.  Here are m⁴ recommendations at this point:    If ⁴ou target P⁴thon  cid:469  onl⁴, asyncio is out of reach for ⁴ou. For me, the next best  choice would be something based on libev, like p⁴ev.    If ⁴ou target both major P⁴thon versions –  cid:469  and  cid:470  – ⁴ou’d better use something that is compatible with both, such as p⁴ev. However, I would strongl⁴ advise ⁴ou to keep in mind that ⁴ou might have to transition later to asyncio. It ma⁴ be useful to have a minimal abstraction la⁴er, and not to spread the internal guts of ⁴our eventing-dependenc⁴ over the entire program. If ⁴ou’re adventurous, tr⁴ing to mix asyncio trollius can be a nice solution too.    If ⁴ou onl⁴ target version  cid:470 , go ahead with asyncio. It’ll be a pain to start with, as there are still not a lot of examples or documentation, but it’s a safe bet. You’ll be a pioneer.  ⁜Asynchronous IO Support Rebooted: the "asyncio" Module, Guido van Rossum,  cid:469  cid:467  cid:468  cid:469     cid:468  cid:468 . cid:470 . ASYNCHRONOUS AND EVENT-DRIVEN ARCHITECTURE   cid:469  cid:468  cid:471   Example  cid:468  cid:468 . cid:472  Example with pyev  import pyev import socket  server = socket.socket socket.AF_INET,  socket.SOCK_STREAM    Never block on read write operations server.setblocking 0    Bind the socket to the port server.bind  'localhost', 10000   server.listen 8   def server_activity watcher, revents :  connection, client_address = server.accept   connection.send "hello!\n"  connection.close    loop = pyev.default_loop   watcher = pyev.Io server, pyev.EV_READ, loop, server_activity  watcher.start   loop.start    As ⁴ou can see here, the pyev interface is prett⁴ eas⁴ to grasp. Via its libev usage, it supports an Io object for input output, but also the tracking of child processes, timers, signals and even callbacks to call when idle. libev also automaticall⁴ relies on the best interface for polling – epoll 2  on Linux or kqueue 2  on BSD.    cid:468  cid:468 . cid:471 . SERVICE-ORIENTED ARCHITECTURE   cid:469  cid:468  cid:472   11.4 Service-oriented architecture  Considering the previousl⁴ stated problems and solutions, the shortcomings of P⁴thon in terms of scalabilit⁴ and usage in large, complex applications can seem trick⁴ to circumvent. However it appears that P⁴thon is reall⁴ good at implementing Service- Oriented Architecture  SOA  – if ⁴ou’re not ⁴et familiar with this, there’s plent⁴ of documentation and opinions that ⁴ou can read online.  SOA is the architecture t⁴pe used b⁴ OpenStack in all its components. Components use HTTP REST to communicate with external clients  end-users  and an abstracted RPC mechanism that can support several wire protocols, the most commonl⁴ used one being AMQP.  In ⁴our own case, the choice of which communication channels to use between those blocks is mainl⁴ a matter of knowing with whom ⁴ou will be communicating.  When exposing an API to the outside world, the preferred channel nowada⁴s is HTTP, and especiall⁴ stateless designs such as REST ⁝ st⁴le architectures. These kinds of architectures are eas⁴ to implement, scale, deplo⁴ and comprehend.  However, when exposing and using ⁴our API internall⁴, using HTTP ma⁴ be not the best protocol. A large panel of communication protocols for applications exist, and a full description of an⁴ of them would likel⁴ fill an entire book.  In P⁴thon, there’s plent⁴ of libraries to build RPC ⁞ s⁴stems. Kombu – among others – is interesting because it provides an RPC mechanism on top of a lot of back-ends; AMQ protocol being the main one. But support for Redis, MongoDB, BeanStalk, Ama⁵on SQS, CouchDB, or ZooKeeper are also provided.  In the end, there’s a huge amount to be gained indirectl⁴ from using such loosel⁴ coupled architecture. If we consider that each module provides and exposes an API,  ⁝Representational state transfer ⁞Remote Procedure Call    cid:468  cid:468 . cid:471 . SERVICE-ORIENTED ARCHITECTURE   cid:469  cid:468  cid:473   we can run multiple daemons exposing this API. For example, Apache httpd would create a new worker using a new s⁴stem process that handles new connections; we can then dispatch our connection to a diﬀerent worker running on the same compute node. All we need to have is a s⁴stem of dispatching the work between our workers, which provides this API. Each block will be a diﬀerent P⁴thon process, and as we’ve seen above, this is better than multi-threading to spread ⁴our work-load. You’ll be able to start multiple workers on each computing node ⁴ou have. Even if not strictl⁴ necessar⁴, using stateless blocks should be favored an⁴ time ⁴ou have the choice.  ZeroMQ is a socket librar⁴ that can act as a concurrenc⁴ framework. The follow- ing example implements the same worker seen in the previous examples, but uses ZeroMQ as a wa⁴ to dispatch and communicate.  Workers using ZeroMQ import multiprocessing import random import zmq  def compute  : return sum   def worker  :  [random.randint 1, 100  for i in range 1000000 ]   context = zmq.Context   work_receiver = context.socket zmq.PULL  work_receiver.connect "tcp:  0.0.0.0:5555"  result_sender = context.socket zmq.PUSH  result_sender.connect "tcp:  0.0.0.0:5556"  poller = zmq.Poller   poller.register work_receiver, zmq.POLLIN     cid:468  cid:468 . cid:471 . SERVICE-ORIENTED ARCHITECTURE   cid:469  cid:468  cid:474   while True:  socks = dict poller.poll    if socks.get work_receiver  == zmq.POLLIN:  obj = work_receiver.recv_pyobj   result_sender.send_pyobj obj     context = zmq.Context    Build a channel to send work to be done work_sender = context.socket zmq.PUSH  work_sender.bind "tcp:  0.0.0.0:5555"   Build a channel to receive computed results result_receiver = context.socket zmq.PULL  result_receiver.bind "tcp:  0.0.0.0:5556"   Start 8 workers processes = [] for x in range 8 :  p = multiprocessing.Process target=worker  p.start   processes.append p   work_sender.send_pyobj compute    Start 8 jobs for x in range 8 :   Read 8 results results = [] for x in range 8 :   Terminate all processes for p in processes:  p.terminate    results.append result_receiver.recv_pyobj       cid:468  cid:468 . cid:471 . SERVICE-ORIENTED ARCHITECTURE   cid:469  cid:468  cid:475   print "Results: %s" % results   As ⁴ou can see, ZeroMQ provides an eas⁴ wa⁴ to build communication channels. I’ve chosen the TCP transport la⁴er here to illustrate the fact that we could run this over a network. It should be noted that ZeroMQ also provides a inproc communi- cation channel that works b⁴ using Unix sockets. Obviousl⁴ the communication protocol built upon ZeroMQ in this example is ver⁴ simplistic – in order to keep this book’s examples clear and concise; but it shouldn’t be hard to imagine building a more sophisticated communication la⁴er on top of it.  With such a protocol, it’s eas⁴ to imagine building a entirel⁴ distributed application communication with a network message bus – ZeroMQ, AMQP, or something else.  Note also that protocols like HTTP, ZeroMQ or AMQP are language agnostic; ⁴ou can use diﬀerent languages and platforms to implement each part of ⁴our s⁴stem. While we all agree that P⁴thon is a good language, other teams might have other preferences; or another language might be a better solution for some part of a prob- lem.  In the end, using a transport bus to decouple ⁴our application is a good option. It allows ⁴ou to build both s⁴nchronous and as⁴nchronous APIs that can be spread from one computer to several thousand. It doesn’t tie ⁴ou to a particular technol- og⁴ or language – and these da⁴s, there’s no longer a reason not to be read⁴ to distribute ⁴our sotware, or to be constrained b⁴ an⁴ particular language.    cid:468  cid:469  RDBMS and ORM  RDBMSs ¹ and ORM ² are touch⁴ subjects, but there’s no wa⁴ to avoid having to deal with them sooner or later. Man⁴ applications have to store data of some kind, and developers oten choose to do so using relational databases. And when a developer chooses to use a relational database, the tool the⁴ almost alwa⁴s choose to use for it is an ORM librar⁴ of some kind.  Note This chapter will be a little less Python-centric than others; bear with me. I’ll only be talking  about relational databases here, but many of the things we’ll cover here can also apply to  other kinds of databases.  RDBMSs are about storing relational data using normal form, while SQL is about dealing with relational algebra. Together, the⁴ allow ⁴ou to store data and an- swer questions about that data. However, there are a number of common diﬀicul- ties with using ORM in object-oriented programs, known collectivel⁴ as the object- relational impedance mismatch. The bottom line is, relational databases and object- oriented programs have diﬀerent representations of data which don’t map properl⁴ to one another: mapping SQL tables to P⁴thon classes won’t give ⁴ou optimal re- sults, no matter what ⁴ou do.  ¹Relational database management s⁴stems ²Object-relational mapping   CHAPTER  cid:468  cid:469 . RDBMS AND ORM   cid:469  cid:469  cid:467   ORM is supposed to make database s⁴stems easier to access: these tools abstract the process of creating queries, generating SQL so ⁴ou don’t have to. Unfortunatel⁴, more likel⁴ sooner than later, ⁴ou’ll want to do something with ⁴our database onl⁴ to discover that the abstraction la⁴er simpl⁴ won’t allow it. To make the most ef- ficient use of ⁴our database, ⁴ou absolutel⁴ have to have an understanding of SQL and RDBMSs so that ⁴ou can write ⁴our own queries directl⁴ without having to rel⁴ on the abstraction la⁴er for ever⁴thing.  But that’s not to sa⁴ ⁴ou should avoid ORM entirel⁴. ORM libraries can help with rapid protot⁴ping of ⁴our application model, and some even provide useful tools such as schema upgrades downgrades. The important thing is that ⁴ou understand that it’s not a substitute for a proper grasp of RDBMSs: man⁴ developers tr⁴ to solve problems in the language of their choice rather than using their model API, and the solutions the⁴ come up with are inelegant at best.  Imagine a SQL table for keeping track of messages. It has a single column named "id," which is the primar⁴ ke⁴, and a string containing the message: CREATE TABLE message    id serial PRIMARY KEY, content text   ;  We want to avoid duplicates when receiving a message, so a t⁴pical developer would write something like this: if message_table.select_by_id message.id :   We already have the message, it's a duplicate, ignore and raise raise DuplicateMessage message   else:   Insert the message message_table.insert message    CHAPTER  cid:468  cid:469 . RDBMS AND ORM   cid:469  cid:469  cid:468   This would definitel⁴ work in most cases, but it has some major drawbacks:    It implements a constraint alread⁴ expressed in the SQL schema, so it is a sort of  code duplication.    It execute  cid:469  SQL queries; executing SQL quer⁴ might be long and requires round-  trip to the SQL server, introducing extraneous dela⁴.    It doesn’t take into account the possibilit⁴ of someone else inserting a duplicate message ater we call select_by_id but before we call insert, which would cause the program to raise an exception.  There’s a much better wa⁴ to write this code, but it requires cooperation with the RDBMS server rather than treating it like dumb storage: try:   Insert the message message_table.insert message   except UniqueViolationError:   Duplicate raise DuplicateMessage message   This achieves the exact same eﬀect in a more eﬀicient fashion and without an⁴ race condition. This is a ver⁴ simple pattern, and it doesn’t conflict with ORM in an⁴ wa⁴. The problem is that developers tend to treat SQL databases as dumb storage and duplicate the constraints the⁴ wrote  or could write  in SQL in their controller code rather than in their model.  Treating ⁴our SQL backend as a model API is good wa⁴ to make eﬀicient use of it. You can manipulate the data stored in ⁴our RDBMS with simple function calls pro- grammed in its own procedural language.  Another point that needs to be raised about ORM is support for multiple database backends. Man⁴ ORM libraries tout it as a feature, but it’s reall⁴ a trap waiting to   CHAPTER  cid:468  cid:469 . RDBMS AND ORM   cid:469  cid:469  cid:469   ensnare unsuspecting developers. No ORM librar⁴ provides a complete abstraction of all RDBMS features, so ⁴ou’ll have to dumb down ⁴our code to the most basic RDBMS available  or that ⁴ou want to put up with , and ⁴ou’ll be unable to use an⁴ advanced RDBMS functions without breaking the abstraction la⁴er.  Simple things that aren’t standardi⁵ed in SQL, such as handling timestamp oper- ations, are a pain to deal with when using an ORM; even more so if ⁴our code is written to be RDBMS-agnostic. With this in mind, be sure to choose an RDBMS that suits ⁴our application well ³.  A good wa⁴ to mitigate the problems with ORM libraries is to isolate them as pre- scribed in Section  cid:469 . cid:470 . This approach not onl⁴ allows ⁴ou to easil⁴ swap ⁴our ORM librar⁴ for a diﬀerent one should the need arise, but it also allows ⁴ou to optimi⁵e ⁴our SQL usage b⁴ identif⁴ing places with ineﬀicient usage of queries, b⁴passing most of the ORM boilerplate.  An eas⁴ wa⁴ to build such isolation is to for example onl⁴ use ⁴our ORM in a module of ⁴our application, for example myapp.storage. This module should onl⁴ exports functions and methods that allow ⁴ou to manipulate the data at a high level of ab- straction. The ORM should be onl⁴ used from that module. At an⁴ point later, ⁴ou will be able to drop in an⁴ module providing the same API to replace myapp.storage.  In the end, this section’s goal isn’t to take a side in the debate over whether to use ORM; there’s alread⁴ plent⁴ of discussion on the Internet arguing over the pros and cons. The point of this section is to help ⁴ou understand how important it is to know enough about SQL and RDBMS to make use of their full potential in ⁴our applica- tion.  The most commonl⁴ used ORM librar⁴ in P⁴thon  and arguabl⁴ the de facto stan- dard   is SQLAlchem⁴. It supports a huge number of diﬀerent backends and pro- vides abstraction for most common operations. Schema upgrades can be handled b⁴ third-part⁴ packages such as alembic.  ³When in doubt, pick PostgreSQL.    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:470   Some frameworks, such as Django, provide their own ORM libraries. If ⁴ou choose to use a framework, it’s a smart idea to use the built-in librar⁴, which will  obviousl⁴  have better integration with the framework than an external one.  Warning The MVC ᵃ architecture that most frameworks rely on can be easily misused. They imple- ment  or make it easy to implement  ORM in their model directly, but without abstracting  enough of it: any code you have in your view and controllers that uses the model will also  be using ORM directly. This is something that you need to avoid. You should write a  data model that includes the ORM library rather than consists of it: this will provide better  testability and better isolation, as well as make it easier to swap out with another storage  technology should the need arise.  ᵃModel View Controller  12.1 Streaming data with Flask and PostgreSQL  In the previous section, we talked about how important it can be to masteri⁵e ⁴our data storage s⁴stem. Here, I’ll show ⁴ou how ⁴ou can use one of PostgreSQL's ad- vanced features to build an HTTP event streaming s⁴stem.  The purpose of this micro-application is to store messages in a SQL table and pro- vide access to those messages via an HTTP REST API. Each message consists of a channel number, a source string, and a content string. The code that creates this table is quite simple: Example  cid:468  cid:469 . cid:468  Creating the message table  CREATE TABLE message    id SERIAL PRIMARY KEY, channel INTEGER NOT NULL, source TEXT NOT NULL,    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:471   content TEXT NOT NULL   ;  What we also want to do is stream these messages to the client so that it can process them in real time. To do this, we’re going to use the LISTEN and NOTIFY features of PostgreSQL. These features allow us to listen for messages sent b⁴ a function we provide that PostgreSQL will execute: Example  cid:468  cid:469 . cid:469  The notify_on_insert function  CREATE OR REPLACE FUNCTION notify_on_insert   RETURNS trigger AS $$ BEGIN  PERFORM pg_notify 'channel_'  NEW.channel,  CAST row_to_json NEW  AS TEXT  ;  RETURN NULL;  END; $$ LANGUAGE plpgsql;  This creates a trigger function written in pl pgsql, a language that onl⁴ PostgreSQL understands. Note that we could also write this function in other languages, such as P⁴thon itself, as PostgreSQL provides a pl python language b⁴ embedding the P⁴thon interpreter.  This function performs a call to pg_notify. This is the function that actuall⁴ sends the notification. The first argument is a string that represents a channel, while the second is a string carr⁴ing the actual payload. We define the channel d⁴namicall⁴ based on the value of the channel column in the row. In this case, the pa⁴load will be the entire row in JSON format. Yes, PostgreSQL knows how to convert a row to JSON nativel⁴!  We want to send a notification message on each INSERT performed in the message table, so we need to trigger this function on such events:    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:472   Example  cid:468  cid:469 . cid:470  The trigger for notify_on_insert  CREATE TRIGGER notify_on_message_insert AFTER INSERT ON message FOR EACH ROW EXECUTE PROCEDURE notify_on_insert  ;  And we’re done: the function is now plugged in and will be executed upon each successful INSERT performed in the message table.  We can check that it works b⁴ using the LISTEN operation in psql: $ psql psql  9.3rc1  SSL connection  cipher: DHE-RSA-AES256-SHA, bits: 256  Type "help" for help.  mydatabase=> LISTEN channel_1; LISTEN mydatabase=> INSERT INTO message channel, source, content  mydatabase-> VALUES 1, 'jd', 'hello world' ; INSERT 0 1 Asynchronous notification "channel_1" with payload "{"id":1,"channel":1,"source":"jd","content":"hello world"}" received from server process with PID 26393.  As soon as the row is inserted, the notification is sent and we’re able to receive it through the PostgreSQL client. Now all we have to do is build the P⁴thon applica- tion that streams this event: Example  cid:468  cid:469 . cid:471  Receiving notifications in P⁴thon  import psycopg2 import psycopg2.extensions import select    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:473   conn = psycopg2.connect database='mydatabase', user='myuser',  password='idkfa', host='localhost'   conn.set_isolation_level   psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT   curs = conn.cursor   curs.execute "LISTEN channel_1;"   while True:  select.select [conn], [], []  conn.poll   while conn.notifies:  notify = conn.notifies.pop   print "Got NOTIFY:", notify.pid, notify.channel, notify.payload   The above code connects to PostgreSQL using the psycopg cid:469  librar⁴. We could have used a librar⁴ that provides an abstraction la⁴er, such as SQLAlchemy, but none of them provide access to the LISTEN NOTIFY functionalit⁴ of PostgreSQL. It’s still pos- sible to access the underl⁴ing database connection to execute the code, but there would be no point in doing that for this example, since we don’t need an⁴ of the other features the ORM librar⁴ would provide.  The program listens on channel_ cid:468 . As soon as it receives a notification, it prints it to the screen. If we run the program and insert a row in the message table, we get this output: $ python3 listen.py Got NOTIFY: 28797 channel_1 {"id":10,"channel":1,"source":"jd","content":"hello world"}  Now, we’ll use Flask, a simple HTTP micro-framework, to build our application.    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:474   We’re going to send the data using the Server-Sent Events message protocol de- fined b⁴ HTML cid:472  ⁛. Example  cid:468  cid:469 . cid:472  Flask streamer application  import flask import psycopg2 import psycopg2.extensions import select  app = flask.Flask __name__   def stream_messages channel :  conn = psycopg2.connect database='mydatabase', user='mydatabase', password='mydatabase', host='localhost'   conn.set_isolation_level   psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT   curs = conn.cursor   curs.execute "LISTEN channel_%d;" % int channel    while True:  select.select [conn], [], []  conn.poll   while conn.notifies:  notify = conn.notifies.pop   yield "data: " + notify.payload + "\n\n"  @app.route " message  ", methods=['GET']  def get_messages channel :  return flask.Response stream_messages channel ,  ⁛An alternative would be to use Transfer-Encoding: chunked defined b⁴ HTTP  cid:468 . cid:468 .    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:475   mimetype='text event-stream'   if __name__ == "__main__":  app.run    This application is quite simple and onl⁴ supports streaming for the sake of the ex- ample. We use Flask to route a request to GET  message  ; as soon as the code is called, it returns a response with the mimet⁴pe text event-stream, sending back a generator function instead of a string. Flask will then call this function and send results each time the generator ⁴ields something.  The generator, stream_messages, reuses the code we wrote earlier to listen to Post- greSQL notifications. It receives the channel identifier as an argument, listens to that channel, and then ⁴ields the pa⁴load. Remember that we used PostgreSQL’s JSON encoding function in the trigger function, so we’re alread⁴ receiving JSON data from PostgreSQL: there’s no need for us to transcode it, since we’re fine with sending JSON data to the HTTP client.  Note For the sake of simplicity, this example application has been written in a single file.  It  isn’t easy to depict examples spanning multiple modules in a book.  If this were a real  application, it would be a good idea to move the storage handling implementation into its  own Python module.  We can now run the server: $ python listen+http.py * Running on http:  127.0.0.1:5000   On another terminal, we can connect and retrieve the events as the⁴’re entered. Upon connection, no data is received and the connection is kept open:    cid:468  cid:469 . cid:468 . STREAMING DATA WITH FLASK AND POSTGRESQL   cid:469  cid:469  cid:476   Trying 127.0.0.1...  $ curl -v http:  127.0.0.1:5000 message 1 * About to connect   to 127.0.0.1 port 5000  0  * * Adding handle: conn: 0x1d46e90 * Adding handle: send: 0 * Adding handle: recv: 0 * Curl_addHandleToPipeline: length: 1 * - Conn 0  0x1d46e90  send_pipe: 1, recv_pipe: 0 * Connected to 127.0.0.1  127.0.0.1  port 5000  0  > GET  message 1 HTTP 1.1 > User-Agent: curl 7.32.0 > Host: 127.0.0.1:5000 > Accept: * * >  But as soon as we insert some rows in the message table: mydatabase=> INSERT INTO message channel, source, content  mydatabase-> VALUES 1, 'jd', 'hello world' ; INSERT 0 1 mydatabase=> INSERT INTO message channel, source, content  mydatabase-> VALUES 1, 'jd', 'it works' ; INSERT 0 1  Data starts coming in through the terminal where curl is running: data: {"id":71,"channel":1,"source":"jd","content":"hello world"}  data: {"id":72,"channel":1,"source":"jd","content":"it works"}  A naive and arguabl⁴ more portable implementation of this application ⁜ would in-  ⁜It would be compatible with other RDBMS servers, such as M⁴SQL    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:467   stead loop over a SELECT statement over and over to poll for new data inserted in the table. However, there’s no need to demonstrate that a push s⁴stem like this one is much more eﬀicient than constantl⁴ polling the database.  12.2 Interview with Dimitri Fontaine  I first met Dimitri a decade ago. He is a skilled PostgreSQL Major Contributor who works at  cid:469 ndQuadrant and argues with other database gurus on the pgsql-hackers mailing-list. We’ve shared a lot of open source adventures, and he’s been kind enough to answer some questions about what ⁴ou should do when dealing with databases.  What advice would you give to developers using RDBMS as their stor- age backends? What should they know about?* That’s a ver⁴ good question, mainl⁴ because it oﬀers more than one op- portunit⁴ to clarif⁴ assumptions that I want to highlight as ver⁴ wrong here. If ⁴ou think the question as asked makes sense, ⁴ou reall⁴ need to be reading m⁴ answer now! Let’s start with something reall⁴ boring: RDBMS stands for Relational DataBase Management S⁴stem. Those beasts have been invented in the  cid:474  cid:467 s to an- swer some common needs that ever⁴ application developer needed to solve themselves at that time, and the main services RDBMS have been implementing are not data storage, as ever⁴one knew how to implement that alread⁴. The main services oﬀered b⁴ a RDBMS are the following:    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:468     Concurrenc⁴: access ⁴our data for read or write with as man⁴ concurrent threads of execution as ⁴ou want to, the RDBMS is there to handle that correctl⁴ for ⁴ou. That’s the main feature ⁴ou want out of a RDBMS.    Concurrenc⁴ semantics: the details about the concurrenc⁴ behaviour when using a RDBMS are proposed with a high-level specification in terms of Atomicity and Isolation, that are ma⁴be the most crucial parts of ACID. Atomicity is the propert⁴ that in between the time ⁴ou BEGIN a transaction and the time ⁴ou’re done with it  either COMMIT or ROLLBACK , no other concurrent activit⁴ on the s⁴stem is allowed to know what ⁴ou’re doing, whatever that is. When using a proper RDBMS that includes Data Definition Language  or DDL, e.g. CREATE TABLE or ALTER TABLE . Isola- tion is all about what ⁴ou’re allowed to notice of the concurrent activit⁴ of the s⁴stem from within ⁴our own transaction. The SQL standard de- fines  cid:471  level of isolation, as described in transaction isolation documen- tation  The RDBMS takes full responsibilit⁴ for ⁴our data. So it allows the devel- oper to describe its own rules for consistenc⁴ and then it will check that those rules are valid at crucial times such as transaction commit or state- ments boundaries, depending on the deferability of ⁴our constraints dec- larations. The first constraint ⁴ou can place on ⁴our data is about its expected input and output formatting, using the proper data type. A proper RDBMS will know how to work with much more than text, numbers and dates, and will properl⁴ handle dates that actuall⁴ appear in a calendar in use toda⁴  Julian is not huge nowada⁴s, ⁴ou probabl⁴ want Gregorian unless doing histor⁴ . Data T⁴pes are not just about input and output formats, though. The⁴ also allow to implement behaviours and some level of polymorphism, as we    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:469   all expect the basic equalit⁴ tests to be data t⁴pe specific: we don’t com- pare text and numbers, dates and IP addresses, points boxes and lines, booleans and circles, UUIDs and XML, Arra⁴s and Ranges in the same wa⁴, to name but a few. Protecting ⁴our data also means that the onl⁴ choice for a proper RDBMS is to activel⁴ refuse data that won’t match with ⁴our consistenc⁴ rules, the first of which is the data t⁴pe ⁴ou’ve chosen. If ⁴ou think it’s OK to have to deal with a date such as 0000-00-00 that never existed in the calendar, then ⁴ou need to rethink. The other part of the consistency guarantees is expressed in terms of con- straints as in CHECK constraints, NOT NULL constraints and constraint trig- gers, one of which is known as foreign key. All of that can be though as a user level extension of the data t⁴pe definition and behavior, the main diﬀerence being that ⁴ou can choose to DEFER checking those constraints from being enforced at the end of each statement to being enforced at the end of the current transaction. The relational bits of an RDBMS is all about modeling ⁴our data and the guarantee that all tuples found in a relation share a common set of rules: structure and constraints. When enforcing that, we are enforcing the use of a proper explicit schema to handle our data. Working on a proper schema for ⁴our data is a process known as Normal- ization and ⁴ou can aim for a number of subtl⁴ diﬀerent Normal Forms in ⁴our design. Sometimes though, ⁴ou need more flexibilit⁴ than given b⁴ the result of ⁴our Normalization process. Common wisdom is to first normali⁵e ⁴our data schema and onl⁴ then see about how to denormal- ize it in order to get back the flexibilit⁴ ⁴ou think ⁴ou need. Chances are that ⁴ou reali⁵e ⁴ou actuall⁴ don’t need an⁴. When ⁴ou do need more flexibilit⁴, using PostgreSQL ⁴ou can pick from    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:470   a number of denormalisation options: composite t⁴pes, records, arra⁴s, hstore, json or XML, for starters. There’s a ver⁴ important drawback to denormalisation though, which is that the Query Language we’re going to talk about next is designed to handle rather normalized data. With PostgreSQL of course the Quer⁴ Language has been extended to support as much denormalisation as possible when using composite t⁴pes, arra⁴s or hstore, and even json in recent releases. The RDBMS knows ver⁴ much about ⁴our data and can help ⁴ou imple- ment a ver⁴ fined grain securit⁴ model, should ⁴ou need to do so. The access patterns are managed at the relation and column level, and Post- greSQL also implements SECURITY DEFINER stored procedure, allowing ⁴ou to oﬀer access to sensible data in a ver⁴ controlled wa⁴, much the same as with using suid programs. The RDBMS oﬀers ⁴ou to access ⁴our data using a Structured Query Lan- guage which became a de-facto standard in the  cid:475  cid:467 s and is now driven b⁴ a commitee. In the case of PostgreSQL, lots of extensions are being added with each and ever⁴ major release each ⁴ear allowing ⁴ou to have access to a ver⁴ rich DSL language. All the work of quer⁴ planning and optimisa- tion is done for ⁴ou b⁴ the RDBMS so that ⁴ou can focus on a declarative quer⁴ where ⁴ou onl⁴ describe the result ⁴ou want from the data ⁴ou have. And that’s also wh⁴ ⁴ou need to pa⁴ close attention to the NoSQL oﬀerings here, as most of those trend⁴ products are in fact not just removing the Structured Query Language out of the oﬀering, but a whole lot of other foundations that ⁴ou’ve been trained to expect. M⁴ advice to developers is to remember the diﬀerences between a storage backend and a RDBMS. Those are ver⁴ diﬀerent services, and if all ⁴ou need actuall⁴ is a storage backend, ma⁴be consider not using a RDBMS.    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:471   Most oten though, what ⁴ou reall⁴ need is a full blown RDBMS. In that case, the best option ⁴ou have is PostgreSQL. Go read its documentation, see the list of data t⁴pes, operators, functions, features and extensions it provides. Read some usage examples on blog posts.  Then consider PostgreSQL as a tool ⁴ou can leverage in ⁴our develop- ment, and include it in ⁴our application architecture. Parts of the services ⁴ou need to implement are best oﬀered at the RDBMS la⁴er, and Post- greSQL excels at being that trustworth⁴ part of ⁴our whole implementa- tion. What’s the best way to use or not use ORM? SQL stands for Structured Query Language and in the case of PostgreSQL has been proven to be Turing Complete. Its implementation and opti- mi⁵er are far from trivial. As ORM stands for Object Relational Mapper, the idea is that ⁴ou can deal with a one-to-one mapping of database relations with classes and database tuples with objects, or class instances.  Even when a RDBMS, like PostgreSQL, implements strong static t⁴ping, re- lation definitions are built on the fl⁴: each quer⁴ result is a new relation. Each subquer⁴ result is a new relation that might exists onl⁴ for the dura- tion of the subquer⁴. Each JOIN, either INNER or OUTER, will result in a new relation d⁴namicall⁴ built for solving just that JOIN.  As a direct consequence of that, it’s eas⁴ to understand that where the ORM will be able to best work for ⁴ou is for what’s called CRUD appli- cations: Create, Read, Update and Delete. The Read part should then onl⁴ be limited to a ver⁴ simple SELECT statement targeting a single ta- ble. If ⁴ou compare non-trivial output lists ⁴ou can measure the impact of retrieving more columns than necessar⁴ on quer⁴ performances. Now,    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:472   if ⁴our ORM is including all the known fields in its projections  or output list , then it will force ⁴our RDBMS to fetch external data  and decompress  it before sending it, ma⁴be onl⁴ to compress it again if ⁴ou’re using SSL in between the RDBMS and ⁴our application. Also, just think about network bandwidth usage and remember than we’re measuring simple primary key based lookup queries in fractions of a millisecond. So an⁴ column ⁴ou retrieve from the RDBMS and that ⁴ou end-up not us- ing is pure waste of precious resources, a first scalabilit⁴ killer. Even when ⁴our ORM of choice is well able to onl⁴ fetch the data ⁴ou’re asking for, then ⁴ou have to somehow manage the exact list of columns ⁴ou want in each situation, and avoid using a simple abstract magic method that will automaticall⁴ compute the fields list for ⁴ou. The next part of the CRUD queries are simple INSERT, UPDATE and DELETE statements. First, all those commands accept joins and sub-select when ⁴ou’re using an advanced RDBMS, such as PostgreSQL. Then again, for example PostgreSQL implements the RETURNING clause, allowing ⁴ou to return to the client an⁴ data that’s just been edited, such as default  t⁴p- icall⁴ sequence numbers for surrogate ke⁴s  and other values computed automaticall⁴ on the RDBMS  t⁴picall⁴ with BEFORE   triggers . Is ⁴our ORM aware of that? What’s the s⁴ntax there to benefit from that? In the general case, a relation is either a table, the result of calling a Set REturning Function, or the result of an⁴ quer⁴. It’s common practice when using an ORM to build a relational mapping in between defined tables and some model classes, or some other helper stubs. If ⁴ou consider the whole SQL semantics in their generalities, then the re- lational mapper should reall⁴ be able to map an⁴ quer⁴ against a class. You would then presumabl⁴ have to build a new class for each quer⁴ ⁴ou    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:473   want to run.  The legend of the Suﬀicientl⁴ Smart Compiler applies to ORMs too. For more details about what that legend is, read On Being Suﬀicientl⁴ Smart b⁴ James Hague. The idea when applied to our ver⁴ case is that ⁴ou trust ⁴our ORM to do a better job than ⁴ou at writing eﬀicient SQL queries, even when ⁴ou’re not giving it enough information to even work out the exact set of data ⁴ou are interested into. It’s true that at times, SQL can get quite complex. You’re not going to get an⁴where near simpler b⁴ using an API to SQL generator that ⁴ou can’t control, though. Ater having said all that against the t⁴pical ORM, something needs to be said against the alternatives. Building SQL queries as a string is not scalable. You want to be able to compose several restrictions  the WHERE clauses  and d⁴namicall⁴ add some joins right into a subquer⁴ just so that ⁴ou can optionall⁴ fetch some more detailed data, etc. M⁴ current thinking is that the tool ⁴ou reall⁴ want to have is not an ORM, it’s a nice wa⁴ to compose a SQL quer⁴ from a programmatic interface. There’s a PostgreSQL driver proposing exactl⁴ the right abstraction to that problem, it’s the Common Lisp librar⁴ Postmodern with the S-SQL solu- tion. Of course, Lisp lends itself reall⁴ well to allow for eas⁴ to program composable components. Actuall⁴ in two cases ⁴ou can relax and use ⁴our ORM, provided that ⁴ou’re willing to accept the following compromise: as soon as possible ⁴ou will need to edit ⁴our ORM usage out of ⁴our code base.    Time To Market; When ⁴ou’re reall⁴ in a hurr⁴ and want to gain market    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:474   share as soon as possible, the onl⁴ wa⁴ to get there is to release a first version of ⁴our application and idea. If ⁴our team is more proficient at using an ORM when compared to hand crating SQL queries, then b⁴ all means just do that. You have to reali⁵e, though, that as soon as ⁴ou’re successful with ⁴our application, one of the first scalabilit⁴ problems ⁴ou will have to solve is going to be related to ⁴our ORM producing reall⁴ bad queries, and ⁴our usage of the ORM having painted ⁴ou into a cor- ner and bad code design decisions. But if ⁴ou’re there, ⁴ou’re successful enough to spend some refactoring mone⁴ and remove an⁴ dependenc⁴ toward the ORM, right?    CRUD Application; the real thing, where ⁴ou are onl⁴ editing a single tuple at a time, and ⁴ou don’t reall⁴ care about performances. Like for the basic admin application interface.  Are there any pros or cons to choosing PostgreSQL over other databases when working with Python? Here are m⁴ top reasons for choosing PostgreSQL as a developer:    Communit⁴ support: the PostgreSQL communit⁴ reall⁴ is welcoming to new users, and will t⁴picall⁴ spend the time it takes to full⁴ understand ⁴our question before to answer the best possible answer. The mailing lists are still the best wa⁴ to communicate with the communit⁴. See PostgreSQL Mailing Lists for details.    Data integrit⁴ and durabilit⁴: an⁴ data ⁴ou send to PostgreSQL is safe in  its definition and ⁴our abilit⁴ to fetch it again later.    Data T⁴pes, function, operators, arra⁴s and ranges: PostgreSQL has a ver⁴ rich set of data t⁴pes that are reall⁴ useful and come with a host of operators and functions to process them. It’s even possible to de- normali⁵e using arrays or JSON data t⁴pes, and still be able to write    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:475   advanced queries including joins against those. For example, did ⁴ou know about the ~ regular expression operator? and the regexp_split_ to_array and regexp_split_to_table functions?    The planner and optimi⁵er: ⁴ou have to tr⁴ to push the limits ⁴ou know about those to reall⁴ understand how complex and powerful the⁴ are. I’ve repeatedl⁴ seen  cid:469  to  cid:470  pages long queries run to complement in a small number of milliseconds.    Transactional DDL: it’s possible to ROLLBACK almost an⁴ command. Tr⁴ it now, just open ⁴our psql shell against a database ⁴ou have and t⁴pe in BEGIN;DROP TABLE foo;ROLLBACK; where ⁴ou replace foo with the name of a table that exists in ⁴our local instance. Ama⁵ing, right?    INSERT INTO ...RETURNING: ⁴ou can return an⁴thing from the INSERT statement directl⁴, like for example the id value that got derived from a sequence. You win a network round-trip and get the result with the same protocol and tools as when issuing a SELECT statement.    WITH  DELETE FROM ...RETURNING *  INSERT INTO ...SELECT: Post- greSQL supportCommon Table Expression in queries, which are known as WITH queries, and thanks to its support for the RETURNING clause, it also supports DML commands there. That’s just awesome, rith?    Window Functions, CREATE AGGREGATE: if ⁴ou don’t know what a window function is, go read about it in the PostgreSQL Manual or in m⁴ blog at Understanding Window Functions. Then ⁴ou have to realise that Post- greSQL allows ⁴ou to use an⁴ existing aggregate as a window function, and allows ⁴ou to d⁴namicall⁴ define new aggregates online in SQL.    PL P⁴thon  and others such as C, SQL, Javascript or Lua : ⁴ou can run ⁴our own code on the server, right where the data is, so that ⁴ou don’t have to fetch it over the network just to process it then send it back in a quer⁴ to do the next level of JOIN. Whatever it is, ⁴ou can do it all on the    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:470  cid:476   server.    Specific Indexing  GiST, GIN, SP-GiST, partial & functional : did ⁴ou know that ⁴ou can create P⁴thon functions to process ⁴our data from within PostgreSQL, then index the result of calling that function? So that when ⁴ou issue a quer⁴ with a WHERE clause calling that function, it’s called onl⁴ once with the data from the quer⁴, then it’s matched directl⁴ with the contents of the index? PostgreSQL implements index frameworks for non sortable data t⁴pes, like  cid:469  dimensional t⁴pes  ranges, geometr⁴, etc ; and for container data t⁴pes. Lots of cases are alread⁴ supported out of the box, and a host more thanks to the Extension s⁴stem. Have a look at the Additional Supplied Modules and the PostgreSQL Extension Network.    Extensions: such extensions include hstore, a full blown ke⁴ value store with flexible indexing, ltree for indexing nested tags, pg_trgm as a poor man’s full text search solution, that supports indexing regular expres- sion searches and unanchored LIKE queries, ip cid:471 r for quick searches of an IP address in a range, and a lot more.    Foreign Data Wrappers: the foreign data wrappers are a whole class of extensions, implementing the SQL MED standard  Management of Ex- ternal Data . The idea is to embed a connection driver right into the PostgreSQL server then expose it through the CREATE SERVER command. PostgreSQL provides an API to foreign data wrapper authors that al- lows them to implement read and write access to the remote data, and also where clauses push-down for eﬀicient joining capabilities. You can even use the advanced SQL capabilities of PostgreSQL against data that ⁴ou maintain with another piece of technolog⁴!    LISTEN NOTIFY: PostgreSQL implements an as⁴nchronous server-to-client  protocol called LISTEN NOTIFY. The application ma⁴ receive unsolicited    cid:468  cid:469 . cid:469 . INTERVIEW WITH DIMITRI FONTAINE   cid:469  cid:471  cid:467   messages from the server when something interesting happens, for ex- ample an UPDATE of some data. The NOTIFY command accepts a data pa⁴load so that ⁴ou can e.g. notif⁴ ⁴our cache application the object id’s to purge when the object just has been removed or updated. Of course, the notification onl⁴ happens if the transaction actuall⁴ did a successful COMMIT.    COPY Streaming protocol: PostgreSQL implements a streaming protocol and uses it to implement its full⁴ integrated replication solution. Now, that protocol is quite eas⁴ to use from an application and allows im- pressive performance boosts. As soon as ⁴ou’re working on more than a do⁵en row at a time, sometimes before, thing about using COPY against a temporary table then issuing a single statement joining to that tem- porar⁴ table: PostgreSQL knows how to join against other tables in all data modif⁴ing statements  insert, update, delete , and batch opera- tion usuall⁴ are wa⁴ faster.    cid:468  cid:470  Python  cid:470  support strategies  As far as I’m aware, P⁴thon  cid:470  is still not the default P⁴thon interpreter in an⁴ s⁴stem that I’m aware of at the moment, despite having been released in December  cid:469  cid:467  cid:467  cid:475  – five ⁴ears ago!  The problem, as ⁴ou know, is that P⁴thon  cid:470  broke compatibilit⁴ with P⁴thon  cid:469 . At the time that P⁴thon  cid:470 . cid:467  arrived, the gap between it and P⁴thon  cid:469 . cid:473  was so huge that people weren’t even beginning to think about bridging it. Scared. Shrugging.  But then things changed: P⁴thon  cid:469 . cid:474  back-ported a lot of features from P⁴thon  cid:470 . cid:468 , narrowing the gap. Much sanit⁴ returned through subsequent versions of P⁴thon, and I am happ⁴ to state that it is now possible to support both P⁴thon  cid:469 . cid:474  and P⁴thon  cid:470 . cid:470 … almost without diﬀicult⁴!  There is oﬀicial documentation on porting applications, but I wouldn’t recommend following it to the letter. It talks a lot about the  cid:469 to cid:470  tool – which converts P⁴thon  cid:469  code to P⁴thon  cid:470  – and contains proposals like starting a special P⁴thon  cid:470  branch for ⁴our project.  In m⁴ opinion, this is terrible advice nowada⁴s. It ma⁴ have been the most appro- priate advice a few ⁴ears ago, but considering the current state of "compatibilit⁴" between P⁴thon  cid:469 . cid:474  and P⁴thon  cid:470 . cid:470 , it’s better to forget about this approach.   CHAPTER  cid:468  cid:470 . PYTHON  cid:470  SUPPORT STRATEGIES   cid:469  cid:471  cid:469   Note Note that a 3to2 tool also exists – but for the same reason given above, I wouldn’t encour-  age its use.  Firstl⁴,  cid:469 to cid:470  doesn’t do alwa⁴s the right thing – it’s not magic. It onl⁴ deals with s⁴ntax changes, which covers a lot; but it doesn’t maintain backward compatibilit⁴ with P⁴thon  cid:469  – and in an⁴ case, ⁴ou’ll have to handle semantic changes manuall⁴. Secondl⁴, running  cid:469 to cid:470  is damn slow; and for this reason it’s unlikel⁴ to be a good long-term solution. Some guides even suggest running it at setup.py time, which is somewhat ha⁵ardous.  Some documentation recommends using diﬀerent project branches to support P⁴thon  cid:469  and P⁴thon  cid:470 . Experience shows that this can be terrible to manage, and that users will get confused about which version the⁴ should use. Even worse, ⁴ou will get confused when the⁴ start submitting bug reports without explicitl⁴ stating which branch the⁴ are using.  A better method is to use a single code base that is both P⁴thon  cid:469  and P⁴thon  cid:470  compatible. This is on what we put our eﬀort on with OpenStack.  In the end, the onl⁴ wa⁴ to be sure that ⁴our code works under both P⁴thon versions is to have unit testing. Without unit testing, it is impossible to know if ⁴our code will work in both contexts and across versions. If ⁴ou do not have an⁴ test in ⁴our application ¹ the first thing to do is to increase ⁴our code coverage dramaticall⁴; ⁴ou ma⁴ want to jump to Chapter  cid:473  right ahead.  Tox is a great tool for automating tests run against multiple P⁴thon versions, and we’ll talk about it in Section  cid:473 . cid:474 .  Once ⁴ou have unit tests and tox set up, it’s eas⁴ enough to run ⁴our tests against both P⁴thon versions using:  ¹I have heard that such projects exist.    cid:468  cid:470 . cid:468 . LANGUAGE AND STANDARD LIBRARY   cid:469  cid:471  cid:470   tox -e py27,py33  See what’s broken, fix it, and launch tox again. Repeat until all tests pass. If ⁴ou’re doing it correctl⁴, the number of errors will decrease slowl⁴ but steadil⁴, to the point where all of ⁴our code base will be full⁴ P⁴thon  cid:469  and  cid:470  compatible.  If ⁴ou have a C module written for P⁴thon that ⁴ou would like to port, I’m sorr⁴ to inform ⁴ou that there’s not much to sa⁴ – other than to tell ⁴ou to read the doc- umentation and port ⁴our code. It ma⁴ be a useful option to rewrite using cﬀi if possible.  In the following sections I will discuss some points ⁴ou will encounter while porting between P⁴thon versions. I will assume that ⁴ou alread⁴ have a P⁴thon  cid:469  code base. While most of what follows could in theor⁴ also be applied to the porting of a P⁴thon  cid:470  project to P⁴thon  cid:469 , I have never personall⁴ encountered such a case.  13.1 Language and standard library  The language hasn’t changed radicall⁴; I’m sure ⁴ou’ve alread⁴ taken a look. This book won’t cover the entire list of changes – it would be much too boring, and in an⁴ case can be found online. The book Porting to P⁴thon  cid:470  gives a prett⁴ good overview of what ⁴ou ma⁴ need to change in order to support P⁴thon  cid:470 .  If ⁴ou haven’t ⁴et taken a look at the language changes made in P⁴thon  cid:470 , I invite ⁴ou to do so. It’s a great language, with a lot less corner cases, and much cleaner interfaces on various object bases. You’ll love P⁴thon  cid:470 .  But it raises strong compatibilit⁴ problems. The s⁴ntax changes to some state- ments  e.g. exception catching  have removed old P⁴thon version compatibilities, and the⁴ can be a pain to tackle if ⁴ou used them. The hacking tool that we’ll dis- cuss in section Section  cid:468 . cid:471  can help ⁴ou to fix these incompatible usages, and stop    cid:468  cid:470 . cid:468 . LANGUAGE AND STANDARD LIBRARY   cid:469  cid:471  cid:471   ⁴ou from adding more.  When supporting multiple versions of P⁴thon, ⁴ou shouldn’t tr⁴ to support an⁴thing older than  cid:469 . cid:473  and  cid:470 . cid:470  at the same time. P⁴thon  cid:469 . cid:473  is the first version which has enough compatibilit⁴ with P⁴thon  cid:470  to be eas⁴ enough to port forward.  The changes that might impact ⁴ou the most are in the area of string handling. In P⁴thon  cid:470  what was called unicode is now str. That means that ever⁴ string is Uni- code – i.e. that u’foobar' ² and 'foobar' mean the same thing.  Figure  cid:468  cid:470 . cid:468 : P⁴thon  cid:469  base classes  ²The u prefix was removed in P⁴thon  cid:470 . cid:467  but reintroduced in P⁴thon  cid:470 . cid:470  – see PEP  cid:471  cid:468  cid:471     cid:468  cid:470 . cid:468 . LANGUAGE AND STANDARD LIBRARY   cid:469  cid:471  cid:472   Figure  cid:468  cid:470 . cid:469 : P⁴thon  cid:470  base classes  Classes implementing unicode should rename that function to str, since the former isn’t used an⁴more; ⁴ou can automate this with a class decorator along these lines:  -*- encoding: utf-8 -*- import six   This backports your Python 3 __str__ for Python 2 def unicode_compat klass :  klass.__unicode__ = klass.__str__ klass.__str__ = lambda self: self.__unicode__  .encode 'utf-8'   if not six.PY3:  return klass  @unicode_compat class Square object : def __str__ self :    cid:468  cid:470 . cid:469 . EXTERNAL LIBRARIES   cid:469  cid:471  cid:473   return u"  " + str id self    That wa⁴ ⁴ou implement just one method for all P⁴thon versions returning Unicode, and the decorator handles the compatibilit⁴ issue.  Another trick that can be hand⁴ when dealing with P⁴thon and Unicode is to use the unicode_literals function, which is available starting with P⁴thon  cid:469 . cid:473  ³. >>> 'foobar' 'foobar' >>> from __future__ import unicode_literals >>> 'foobar' u'foobar'  Various functions no longer return lists, instead returning iterable objects  such as range ; in addition, dictionar⁴ methods like keys or items now return iterable ob- jects, and functions like iterkeys and iteritems have been removed. This is a big change, but six  discussed in Section  cid:468  cid:470 . cid:470   can help ⁴ou with handling it.  Obviousl⁴, the standard librar⁴ has evolved between P⁴thon  cid:469  and P⁴thon  cid:470 , but that shouldn’t be a huge concern. Some modules have been renamed or moved, but in the end the result is a clearer la⁴out. There’s no oﬀicial listing that I’m aware of, but ⁴ou can find a prett⁴ good list here, or use a search engine.  The six module, which we will discuss in Section  cid:468  cid:470 . cid:470 , will also help a lot when tr⁴ing to maintain compatibilit⁴ between P⁴thon  cid:469  &  cid:470 .  13.2 External libraries  Your first enemies are the external libraries ⁴ou depend on. If ⁴ou read m⁴ advice in Section  cid:469 . cid:470  and followed m⁴ check-list, ⁴ou won’t have a problem here – since  ³Another reason not to support older versions?    cid:468  cid:470 . cid:470 . USING SIX   cid:469  cid:471  cid:474   that check-list included a P⁴thon  cid:470  support requirement. However, ⁴ou ma⁴ have started a project earlier and have alread⁴ made the mistake. Unfortunatel⁴ there isn’t an⁴ magic trick than can resolve the problem. Luckil⁴, if ⁴ou followed m⁴ other advice, ⁴ou isolated this librar⁴ enough that it is not spread across ⁴our whole code base; so ⁴ou can think about replacing it. Indeed, this ma⁴ be ⁴our best move if the librar⁴ does not show a strong possibilit⁴ of supporting P⁴thon  cid:470 . However, small and medium-si⁵ed libraries might be more easil⁴ ported to P⁴thon  cid:470  than big frameworks, so ⁴ou ma⁴ want to cut ⁴our teeth on them. When looking for packages on P⁴PI, ⁴ou can check for the trove classifiers "Pro- gramming Language :: Python ::  cid:469 " and "Programming Language :: Python ::  cid:470 ", which indicate which version of P⁴thon the package supports. However, be careful that these ma⁴ not be up to date. One of the external librar⁴ choices made at the beginning of the OpenStack project was eventlet, a concurrent networking librar⁴. It has no support for P⁴thon  cid:470 , and still tries to support P⁴thon  cid:469 . cid:472  – which, as ⁴ou imagine, does not facilitate an⁴ tran- sition. This choice was made a long time ago in OpenStack, before an⁴ kind of checks for P⁴thon  cid:470  compatibilit⁴ were done; and we alread⁴ know that this mod- ule is going a big issue in the months ahead. As of ⁴et, we have no concrete plan on how to fix it. Don’t make the same mistake!  13.3 Using six  As we have seen, P⁴thon  cid:470  breaks compatibilit⁴ with earlier versions and shits things around. However, the basics of the language haven’t changed, so it is possible to have a sort of transition la⁴er; a module that can implement forward and backward compatibilit⁴ – a bridge between P⁴thon  cid:469  and P⁴thon  cid:470 . This module exists, and it’s called six – because two times three equals six.    cid:468  cid:470 . cid:470 . USING SIX   cid:469  cid:471  cid:475   The first thing that six provides is the six.PY cid:470  variable. This is a boolean which in- dicates whether we are running P⁴thon  cid:470  or not. This is the pivot variable for an⁴ of ⁴our code base that has two versions, one for P⁴thon  cid:469  and one for P⁴thon  cid:470 . How- ever, be careful not to abuse it; scattering ⁴our code base with if six.PY cid:470  is going to be diﬀicult to work with later.  As we discussed in Section  cid:475 . cid:468 , which concerned generators, P⁴thon  cid:470  has a great feature whereb⁴ iterable objects are returned instead of lists. That means that meth- ods like dict.iteritems are gone, and that dict.items returns an iterator rather than a list. Obviousl⁴ this can break ⁴our code. six provides six.iteritems for such cases, so that all ⁴ou have to do is to replace the following code: for k, v in mydict.iteritems  :  print k, v   with: import six  for k, v in six.iteritems mydict :  print k, v   And voilà, P⁴thon  cid:470  compliance achieved in a snap! six provides a lot of similar helper functions that can increase compatibilit⁴ across P⁴thon versions. The raise s⁴ntax also changed in P⁴thon  cid:470  ⁛, so re-raising exceptions should be done using six.reraise.  If ⁴ou are using metaclasses, P⁴thon  cid:470  has also changed this completel⁴. Six has a nice trick for handling the transition – for example, if ⁴ou are using the abc abstract base classes metaclass, here’s how ⁴ou would use six: import abc from six import with_metaclass  ⁛It now onl⁴ accepts one argument, an exception.    cid:468  cid:470 . cid:470 . USING SIX   cid:469  cid:471  cid:476   class MyClass with_metaclass abc.ABCMeta, object  :  pass  One cannot discuss P⁴thon  cid:470  without touching on the string and unicode mess that it solved. In P⁴thon  cid:469 , the basic t⁴pe for string is str which can handle onl⁴ ba- sic ASCII strings, and the t⁴pe unicode, added later, handles real string of text. In P⁴thon  cid:470 , the basic t⁴pe is still str, but it shares the properties of the P⁴thon  cid:469  unicode class and can handle advanced encodings. The bytes t⁴pe replaces the str t⁴pe for handling basic characters stream.  six provides a nice set of functions and constants to handle the transition, such as six.u and six.string_types. The same compatibilit⁴ is provided for integers, with six.integer_types that will handle the long t⁴pe that has been removed from P⁴thon  cid:470 .  As discussed in Section  cid:468  cid:470 . cid:468 , some modules have moved, and six provides a nice module called six.moves that handles a lot of these moves transparentl⁴.  For example, the ConfigParser module in P⁴thon  cid:470  has been renamed to config- parser. Code using ConfigParser under P⁴thon  cid:469 : from ConfigParser import ConfigParser  can be ported and made compatible with both major P⁴thon versions: from six.moves.configparser import ConfigParser  conf = ConfigParser    conf = ConfigParser      cid:468  cid:470 . cid:470 . USING SIX   cid:469  cid:472  cid:467   Tip It is also possible to add your own moves via six.add_move to handle other transitions.  The six librar⁴ might not be enough or cover all ⁴our use case. In this case, building a compatibilit⁴ module encapsulating six itself might be worth it. B⁴ isolating the this in one particular module, ⁴ou are assuring that ⁴ou’ll be able to enhance it for future version of P⁴thon, or dispose  part of  it when ⁴ou’ll want to stop supporting a particular version of P⁴thon. Also note that six is open source and that ⁴ou can contribute to it rather than maintaining ⁴our own hacks.  The last thing I’ll mention, is the moderni⁵e module. It’s a thin wrapper around  cid:469 to cid:470  that "moderni⁵es" code b⁴ porting to P⁴thon  cid:470 ; but rather than convert the s⁴ntax to P⁴thon  cid:470  code onl⁴, it uses the six module. It’s a better choice than the standard  cid:469 to cid:470  tool, and get ⁴our port oﬀ to a strong start b⁴ carr⁴ing out most of the grunt work for ⁴ou. It’s worth a shot.    cid:468  cid:471  Write less, code more  In this section I’ve compiled a few of the more advanced features that I find inter- esting – the⁴’ll help ⁴ou to write better code.  14.1 Single dispatcher  I oten like to sa⁴ that P⁴thon is a good subset of Lisp, and as time passes I find this to be more and more true. Recentl⁴ I stumbled across the PEP  cid:471  cid:471  cid:470 , which describes a wa⁴ to dispatch generic functions in a similar manner to that provided b⁴ CLOS, the Common Lisp Object S⁴stem.  If ⁴ou’re familiar with Lisp, this won’t be new to ⁴ou. The Lisp object s⁴stem, which is one of the basic components of Common Lisp, provides a good wa⁴ to define and handle method dispatching. I’ll show ⁴ou how generic methods work in Lisp first – even if onl⁴ for the pleasure of including Lisp code in a book on P⁴thon!  To begin with, let’s define a few ver⁴ simple classes, without an⁴ parent classes or attributes  defclass snare-drum                defclass cymbal       cid:468  cid:471 . cid:468 . SINGLE DISPATCHER   cid:469  cid:472  cid:469    defclass stick      defclass brushes               This defines a few classes: snare-drum, symbal, stick and brushes, without an⁴ parent class nor attribute. These classes compose a drum kit, and we can combine them to pla⁴ sound. So we define a play method that takes two arguments, and returns a sound  as a string .  defgeneric play  instrument accessory    :documentation "Play sound with instrument and accessory."    This onl⁴ defines a generic method: it isn’t attached to an⁴ class, and so cannot ⁴et be called. At this stage, we’ve onl⁴ informed the object s⁴stem that the method is generic and can be called with various arguments. Now we’ll implement versions of this method that simulate pla⁴ing our snare-drum.  defmethod play   instrument snare-drum   accessory stick    "POC!"   "SHHHH!"    defmethod play   instrument snare-drum   accessory brushes    Now we’ve defined concrete methods in code. The⁴ take two arguments: instru ment, which is an instance of snare-drum; and accessory, which is an instance of stick or brushes.  At this stage, ⁴ou should see the first major diﬀerence between this s⁴stem and the P⁴thon  or similar  object s⁴stems: the method isn’t tied to an⁴ particular class. The methods are generic, and an⁴ class can implement them.    cid:468  cid:471 . cid:468 . SINGLE DISPATCHER   cid:469  cid:472  cid:470   Let’s tr⁴ it. *  play  make-instance 'snare-drum   make-instance 'stick   "POC!"  *  play  make-instance 'snare-drum   make-instance 'brushes   "SHHHH!"  *  play  make-instance 'cymbal   make-instance 'stick   debugger invoked on a SIMPLE-ERROR in thread  :  There is no applicable method for the generic function     when called with arguments       .  Type HELP for debugger help, or  SB-EXT:EXIT  to exit from SBCL.  restarts  invokable by number or by possibly-abbreviated name :  0: [RETRY] Retry calling the generic function. 1: [ABORT] Exit debugger, returning to top level.    :METHOD NO-APPLICABLE-METHOD  T     ←֓       [fast-method]  As ⁴ou can see, which function is called depends on the class of the arguments – the object s⁴stems dispatch the function calls to the right function for us, depending which classes we pass as arguments. If we call play with instances that are not known to the object s⁴stem, an error will be thrown.  Inheritance is also supported and, the  more powerful and less error prone  equiv- alent of P⁴thon’s super   is available via  call-next-method .    cid:468  cid:471 . cid:468 . SINGLE DISPATCHER   cid:469  cid:472  cid:471    defclass snare-drum         defclass cymbal          defclass accessory         defclass stick  accessory       defclass brushes  accessory        defmethod play   c cymbal   a accessory    "BIIING!"    defmethod play   c cymbal   b brushes     concatenate 'string "SSHHHH!"  call-next-method     In this example, we define the stick and brushes classes as subclasses of access ory. The play method defined will return the sound BIIING!, regardless of what kind of accessor⁴ instance is used to pla⁴ the c⁴mbal – except if it’s a brushes instance; the most precise method is alwa⁴s called. The  call-next-method  function is used to call the closest parent method, and in this case that would be the method which returns "BIIING!". *  play  make-instance 'cymbal   make-instance 'stick   "BIIING!"  *  play  make-instance 'cymbal   make-instance 'brushes   "SSHHHH!BIIING!"  Note that CLOS can define speciali⁵ed methods which appl⁴ to onl⁴ one instance of a class- using the eql speciali⁵er.  But if ⁴ou’re reall⁴ curious about the man⁴ features CLOS provides, I suggest that ⁴ou read the brief guide to CLOS b⁴ Jeﬀ Dalton as a starter.    cid:468  cid:471 . cid:468 . SINGLE DISPATCHER   cid:469  cid:472  cid:472   P⁴thon implements a simpler version of this workflow with the singledispatch function, which will is with P⁴thon  cid:470 . cid:471  as part of the functools module. Here’s the rough equivalent of the Lisp program above: import functools  class SnareDrum object : pass class Cymbal object : pass class Stick object : pass class Brushes object : pass  @functools.singledispatch def play instrument, accessory :  raise NotImplementedError "Cannot play these"   @play.register SnareDrum  def _ instrument, accessory :  if isinstance accessory, Stick :  if isinstance accessory, Brushes :  return "POC!"  return "SHHHH!"  raise NotImplementedError "Cannot play these"   We define our four classes, and a base play function that raises NotImplemented Error, indicating that b⁴ default we don’t know what to do. We can then write a speciali⁵ed version of this function for a specific instrument, the SnareDrum. This function checks which accessor⁴ t⁴pe has been passed, and returns the appropriate sound – or raises NotImplementedError again if it doesn’t recognise the accessor⁴.  If we run the program, it should work as follows: >>> play SnareDrum  , Stick    'POC!'    cid:468  cid:471 . cid:468 . SINGLE DISPATCHER   cid:469  cid:472  cid:473   >>> play SnareDrum  , Brushes    'SHHHH!' >>> play Cymbal  , Brushes    Traceback  most recent call last :  File " ", line 1, in   File " home jd Source cpython Lib functools.py", line 562, in wrapper  return dispatch args[0].__class__  *args, **kw   File " home jd sd.py", line 10, in play  raise NotImplementedError "Cannot play these"   NotImplementedError: Cannot play these >>> play SnareDrum  , Cymbal    Traceback  most recent call last :  File " ", line 1, in   File " home jd Source cpython Lib functools.py", line 562, in wrapper  return dispatch args[0].__class__  *args, **kw   File " home jd sd.py", line 18, in _  raise NotImplementedError "Cannot play these"   NotImplementedError: Cannot play these  The singledispatch module checks the class of the first argument passed, and calls the appropriate version of the play function. For the object class, the first-defined version of the function is alwa⁴s the one which is run – so, if our instrument is an instance of a class that we did not register, this base function will be called.  For those eager to tr⁴ it out, the singledispatch function is provided in P⁴thon  cid:469 . cid:473  to  cid:470 . cid:470 , through the P⁴thon Package Index.  As we saw in the Lisp version of the code, CLOS provides a multiple dispatcher that can dispatch depending on the t⁴pe of any of the arguments defined in the method protot⁴pe, not just the first one. Unfortunatel⁴, the P⁴thon dispatcher is named singledispatch for a good reason: it onl⁴ knows how to dispatch based on the first    cid:468  cid:471 . cid:469 . CONTEXT MANAGERS   cid:469  cid:472  cid:474   argument. Guido van Rossum wrote a short article called multimethod about this subject a few ⁴ears ago.  In addition, there’s no wa⁴ to call the parent function directl⁴ – no equivalent of either  call-next-method  from Lisp, or the P⁴thon super   function. You’ll have to use various tricks to b⁴pass this limitation.  To conclude: while I am reall⁴ glad that P⁴thon is heading in this direction, as it’s a reall⁴ powerful wa⁴ to enhance an object s⁴stem, it still lacks a lot of the more advanced features that CLOS provides out of the box.  14.2 Context managers  The with statement introduced in P⁴thon  cid:469 . cid:473  is likel⁴ to remind old time Lispers of the various with-* macros that are oten used in the language. P⁴thon provides a similar-looking mechanism, with the use of objects which implement the context management protocol.  Objects like those returned b⁴ open support this protocol; that’s wh⁴ ⁴ou can write code along these lines: with open "myfile", "r"  as f:  line = f.readline    The object returned b⁴ open has two methods, one called __enter__ and one called __exit__; these are called at the start of the with block and at the end of it, respec- tivel⁴.  A simple implementation of a context object would be: Example  cid:468  cid:471 . cid:468  Simple implementation of a context object class MyContext object : def __enter__ self :  pass    cid:468  cid:471 . cid:469 . CONTEXT MANAGERS   cid:469  cid:472  cid:475   def __exit__ self, exc_type, exc_value, traceback :  pass  It wouldn’t do an⁴thing, but is valid.  When do ⁴ou want to use context managers? The use of context management pro- tocol might be appropriate if ⁴ou identif⁴ the following pattern in ⁴our object:   cid:468 . Call method A;   cid:469 . Execute some code;   cid:470 . Call method B.  Where it is expected that a call to method B must always be done ater a call to A. The open function illustrates this pattern well – in this case, the constructor that opens the file and allocates a file descriptor internall⁴ is method A. The close method that releases the file descriptor corresponds to method B. Obviousl⁴, the close function is alwa⁴s meant to be called ater ⁴ou instantiate the file object. The contextlib standard librar⁴ provides contextmanager to ease the implemen- tation of such a mechanism, b⁴ rel⁴ing on a generator to construct the __enter__ and __exit__ methods for ⁴ou. We can use this to implement our simple context manager: Example  cid:468  cid:471 . cid:469  Simplest usage of contextlib.contextmanager  import contextlib  @contextlib.contextmanager def MyContext  :  yield  For example, I’ve been using this design pattern in Ceilometer for the pipeline in- frastructure we set up. Basicall⁴, a pipeline is a tube into which objects are put, and    cid:468  cid:471 . cid:469 . CONTEXT MANAGERS   cid:469  cid:472  cid:476   from which the⁴ are dispatched to various places. The steps to send data this wa⁴ are as follows:   cid:468 . Call the publish objects  method of a pipeline, with ⁴our objects as argu-  ments – as man⁴ times as ⁴ou need.   cid:469 . Once done, call the flush   method to indicate that ⁴ou’re done publishing  for now.  Note that if ⁴ou never call the flush   method, ⁴our objects will never be sent down the tube; or at least not completel⁴. It can be ver⁴ eas⁴ for a programmer to forget about a flush   call, which breaks the program without giving an⁴ clues as to what might be wrong.  It’s much better if ⁴our API provides a context manager object that will not allow the API user to make this mistake. This can be done prett⁴ easil⁴ with the following code: Example  cid:468  cid:471 . cid:470  Using a context manager on a pipeline object  import contextlib  class Pipeline object :  def _publish self, objects :   Imagine publication code here pass  def _flush self :   Imagine flushing code here pass  @contextlib.contextmanager def publisher self :    cid:468  cid:471 . cid:469 . CONTEXT MANAGERS   cid:469  cid:473  cid:467   try:  finally:  yield self._publish  self._flush    Now, when users of our API wants to publish something in our pipeline, the⁴ don’t have to use _publish or _flush. The⁴ just request a publisher using the epon⁴m function, and uses it. pipeline = Pipeline   with pipeline.publisher   as publisher:  publisher [1, 2, 3, 4]   When ⁴ou provide an API like this, there’s no place for user error. Alwa⁴s use context managers when ⁴ou see that it suits the design pattern.  In some contexts, it might be useful to use several context managers at the same time – for example, opening two files at the same time to cop⁴ their content: Example  cid:468  cid:471 . cid:471  Opening two files at the same time  with open "file1", "r"  as source:  with open "file2", "w"  as destination:  destination.write source.read     Remember that the with statement supports having multiple arguments – so ⁴ou should write: Example  cid:468  cid:471 . cid:472  Opening two files at the same time with one with statement  with open "file1", "r"  as source, open "file2", "w"  as destination:  destination.write source.read
