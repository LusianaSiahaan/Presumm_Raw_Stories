Data Science from Scratch  SECOND EDITION  First Principles with Python  Joel Grus   Data Science from Scratch by Joel Grus Copyright   2019 Joel Grus. All rights reserved. Printed in the United States of America. Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472. O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles  http:  oreilly.com . For more information, contact our corporate institutional sales department: 800-998-9938 or corporate@oreilly.com.  Editor: Michele Cronin  Production Editor: Deborah Baker  Copy Editor: Rachel Monaghan  Proofreader: Rachel Head  Indexer: Judy McConville  Interior Designer: David Futato  Cover Designer: Karen Montgomery  Illustrator: Rebecca Demarest  April 2015: First Edition May 2019: Second Edition  Revision History for the Second Edition   2019-04-10: First Release  See http:  oreilly.com catalog errata.csp?isbn=9781492041139 for release details. The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Data Science from Scratch, Second Edition, the cover image of a rock ptarmigan, and related trade dress are trademarks of O’Reilly Media, Inc. While the publisher and the author have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the author disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work. Use of the information and instructions contained in this work is at your own risk. If any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and or rights. 978-1-492-04113-9 [LSI]   Preface to the Second Edition  I am exceptionally proud of the first edition of Data Science from Scratch. It turned out very much the book I wanted it to be. But several years of developments in data science, of progress in the Python ecosystem, and of personal growth as a developer and educator have changed what I think a first book in data science should look like. In life, there are no do-overs. In writing, however, there are second editions. Accordingly, I’ve rewritten all the code and examples using Python 3.6  and many of its newly introduced features, like type annotations . I’ve woven into the book an emphasis on writing clean code. I’ve replaced some of the first edition’s toy examples with more realistic ones using “real” datasets. I’ve added new material on topics such as deep learning, statistics, and natural language processing, corresponding to things that today’s data scientists are likely to be working with.  I’ve also removed some material that seems less relevant.  And I’ve gone over the book with a fine-toothed comb, fixing bugs, rewriting explanations that are less clear than they could be, and freshening up some of the jokes. The first edition was a great book, and this edition is even better. Enjoy!  Joel Grus  Seattle, WA  2019  Conventions Used in This Book The following typographical conventions are used in this book: Italic   Indicates new terms, URLs, email addresses, filenames, and file extensions.  Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.  Shows commands or other text that should be typed literally by the user.  Shows text that should be replaced with user-supplied values or by values determined by context.  This element signifies a tip or suggestion.  TIP  NOTE  This element signifies a general note.  This element indicates a warning or caution.  WARNING  Using Code Examples Supplemental material  code examples, exercises, etc.  is available for download at https:  github.com joelgrus data-science-from-scratch.  C o n s t a n t   w i d t h C o n s t a n t   w i d t h   b o l d C o n s t a n t   w i d t h   i t a l i c  This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission. We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “Data Science from Scratch, Second Edition, by Joel Grus  O’Reilly . Copyright 2019 Joel Grus, 978-1-492-04113-9.” If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at permissions@oreilly.com.  O’Reilly Online Learning  NOTE  For almost 40 years, O’Reilly Media has provided technology and business training, knowledge, and insight to help companies succeed.  Our unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, please visit http:  oreilly.com.   How to Contact Us Please address comments and questions concerning this book to the publisher:  O’Reilly Media, Inc.  1005 Gravenstein Highway North  Sebastopol, CA 95472  800-998-9938  in the United States or Canada   707-829-0515  international or local   707-829-0104  fax   We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at http:  bit.ly data- science-from-scratch-2e. To comment or ask technical questions about this book, send email to bookquestions@oreilly.com. For more information about our books, courses, conferences, and news, see our website at http:  www.oreilly.com. Find us on Facebook: http:  facebook.com oreilly Follow us on Twitter: http:  twitter.com oreillymedia Watch us on YouTube: http:  www.youtube.com oreillymedia  Acknowledgments First, I would like to thank Mike Loukides for accepting my proposal for this book  and for insisting that I pare it down to a reasonable size . It would have been very easy for him to say, “Who’s this person who keeps   emailing me sample chapters, and how do I get him to go away?” I’m grateful he didn’t. I’d also like to thank my editors, Michele Cronin and Marie Beaugureau, for guiding me through the publishing process and getting the book in a much better state than I ever would have gotten it on my own. I couldn’t have written this book if I’d never learned data science, and I probably wouldn’t have learned data science if not for the influence of Dave Hsu, Igor Tatarinov, John Rauser, and the rest of the Farecast gang.  So long ago that it wasn’t even called data science at the time!  The good folks at Coursera and DataTau deserve a lot of credit, too. I am also grateful to my beta readers and reviewers. Jay Fundling found a ton of mistakes and pointed out many unclear explanations, and the book is much better  and much more correct  thanks to him. Debashis Ghosh is a hero for sanity-checking all of my statistics. Andrew Musselman suggested toning down the “people who prefer R to Python are moral reprobates” aspect of the book, which I think ended up being pretty good advice. Trey Causey, Ryan Matthew Balfanz, Loris Mularoni, Núria Pujol, Rob Jefferson, Mary Pat Campbell, Zach Geary, Denise Mauldin, Jimmy O’Donnell, and Wendy Grus also provided invaluable feedback. Thanks to everyone who read the first edition and helped make this a better book. Any errors remaining are of course my responsibility. I owe a lot to the Twitter datascience commmunity, for exposing me to a ton of new concepts, introducing me to a lot of great people, and making me feel like enough of an underachiever that I went out and wrote a book to compensate. Special thanks to Trey Causey  again , for  inadvertently  reminding me to include a chapter on linear algebra, and to Sean J. Taylor, for  inadvertently  pointing out a couple of huge gaps in the “Working with Data” chapter. Above all, I owe immense thanks to Ganga and Madeline. The only thing harder than writing a book is living with someone who’s writing a book, and I couldn’t have pulled it off without their support.   Preface to the First Edition  Data Science Data scientist has been called “the sexiest job of the 21st century,” presumably by someone who has never visited a fire station. Nonetheless, data science is a hot and growing field, and it doesn’t take a great deal of sleuthing to find analysts breathlessly prognosticating that over the next 10 years, we’ll need billions and billions more data scientists than we currently have. But what is data science? After all, we can’t produce data scientists if we don’t know what data science is. According to a Venn diagram that is somewhat famous in the industry, data science lies at the intersection of:  Hacking skills Math and statistics knowledge Substantive expertise  Although I originally intended to write a book covering all three, I quickly realized that a thorough treatment of “substantive expertise” would require tens of thousands of pages. At that point, I decided to focus on the first two. My goal is to help you develop the hacking skills that you’ll need to get started doing data science. And my goal is to help you get comfortable with the mathematics and statistics that are at the core of data science. This is a somewhat heavy aspiration for a book. The best way to learn hacking skills is by hacking on things. By reading this book, you will get a good understanding of the way I hack on things, which may not necessarily be the best way for you to hack on things. You will get a good understanding of some of the tools I use, which will not necessarily be the best tools for you to use. You will get a good understanding of the way I approach data problems, which may not necessarily be the best way for you   to approach data problems. The intent  and the hope  is that my examples will inspire you to try things your own way. All the code and data from the book is available on GitHub to get you started. Similarly, the best way to learn mathematics is by doing mathematics. This is emphatically not a math book, and for the most part, we won’t be “doing mathematics.” However, you can’t really do data science without some understanding of probability and statistics and linear algebra. This means that, where appropriate, we will dive into mathematical equations, mathematical intuition, mathematical axioms, and cartoon versions of big mathematical ideas. I hope that you won’t be afraid to dive in with me. Throughout it all, I also hope to give you a sense that playing with data is fun, because, well, playing with data is fun!  Especially compared to some of the alternatives, like tax preparation or coal mining.   From Scratch There are lots and lots of data science libraries, frameworks, modules, and toolkits that efficiently implement the most common  as well as the least common  data science algorithms and techniques. If you become a data scientist, you will become intimately familiar with NumPy, with scikit- learn, with pandas, and with a panoply of other libraries. They are great for doing data science. But they are also a good way to start doing data science without actually understanding data science. In this book, we will be approaching data science from scratch. That means we’ll be building tools and implementing algorithms by hand in order to better understand them. I put a lot of thought into creating implementations and examples that are clear, well commented, and readable. In most cases, the tools we build will be illuminating but impractical. They will work well on small toy datasets but fall over on “web-scale” ones. Throughout the book, I will point you to libraries you might use to apply these techniques to larger datasets. But we won’t be using them here.   There is a healthy debate raging over the best language for learning data science. Many people believe it’s the statistical programming language R.  We call those people wrong.  A few people suggest Java or Scala. However, in my opinion, Python is the obvious choice. Python has several features that make it well suited for learning  and doing  data science:  It’s free. It’s relatively simple to code in  and, in particular, to understand . It has lots of useful data science–related libraries.  I am hesitant to call Python my favorite programming language. There are other languages I find more pleasant, better designed, or just more fun to code in. And yet pretty much every time I start a new data science project, I end up using Python. Every time I need to quickly prototype something that just works, I end up using Python. And every time I want to demonstrate data science concepts in a clear, easy-to-understand way, I end up using Python. Accordingly, this book uses Python. The goal of this book is not to teach you Python.  Although it is nearly certain that by reading this book you will learn some Python.  I’ll take you through a chapter-long crash course that highlights the features that are most important for our purposes, but if you know nothing about programming in Python  or about programming at all , then you might want to supplement this book with some sort of “Python for Beginners” tutorial. The remainder of our introduction to data science will take this same approach—going into detail where going into detail seems crucial or illuminating, at other times leaving details for you to figure out yourself  or look up on Wikipedia . Over the years, I’ve trained a number of data scientists. While not all of them have gone on to become world-changing data ninja rockstars, I’ve left them all better data scientists than I found them. And I’ve grown to believe that anyone who has some amount of mathematical aptitude and some   amount of programming skill has the necessary raw materials to do data science. All she needs is an inquisitive mind, a willingness to work hard, and this book. Hence this book.   Chapter 1. Introduction  “Data! Data! Data!” he cried impatiently. “I can’t make bricks without clay.”  —Arthur Conan Doyle  The Ascendance of Data We live in a world that’s drowning in data. Websites track every user’s every click. Your smartphone is building up a record of your location and speed every second of every day. “Quantified selfers” wear pedometers-on- steroids that are always recording their heart rates, movement habits, diet, and sleep patterns. Smart cars collect driving habits, smart homes collect living habits, and smart marketers collect purchasing habits. The internet itself represents a huge graph of knowledge that contains  among other things  an enormous cross-referenced encyclopedia; domain-specific databases about movies, music, sports results, pinball machines, memes, and cocktails; and too many government statistics  some of them nearly true!  from too many governments to wrap your head around. Buried in these data are answers to countless questions that no one’s ever thought to ask. In this book, we’ll learn how to find them.  What Is Data Science? There’s a joke that says a data scientist is someone who knows more statistics than a computer scientist and more computer science than a statistician.  I didn’t say it was a good joke.  In fact, some data scientists are —for all practical purposes—statisticians, while others are fairly indistinguishable from software engineers. Some are machine learning experts, while others couldn’t machine-learn their way out of kindergarten. Some are PhDs with impressive publication records, while others have   never read an academic paper  shame on them, though . In short, pretty much no matter how you define data science, you’ll find practitioners for whom the definition is totally, absolutely wrong. Nonetheless, we won’t let that stop us from trying. We’ll say that a data scientist is someone who extracts insights from messy data. Today’s world is full of people trying to turn data into insight. For instance, the dating site OkCupid asks its members to answer thousands of questions in order to find the most appropriate matches for them. But it also analyzes these results to figure out innocuous-sounding questions you can ask someone to find out how likely someone is to sleep with you on the first date. Facebook asks you to list your hometown and your current location, ostensibly to make it easier for your friends to find and connect with you. But it also analyzes these locations to identify global migration patterns and where the fanbases of different football teams live. As a large retailer, Target tracks your purchases and interactions, both online and in-store. And it uses the data to predictively model which of its customers are pregnant, to better market baby-related purchases to them. In 2012, the Obama campaign employed dozens of data scientists who data- mined and experimented their way to identifying voters who needed extra attention, choosing optimal donor-specific fundraising appeals and programs, and focusing get-out-the-vote efforts where they were most likely to be useful. And in 2016 the Trump campaign tested a staggering variety of online ads and analyzed the data to find what worked and what didn’t. Now, before you start feeling too jaded: some data scientists also occasionally use their skills for good—using data to make government more effective, to help the homeless, and to improve public health. But it certainly won’t hurt your career if you like figuring out the best way to get people to click on advertisements.  Motivating Hypothetical: DataSciencester   Congratulations! You’ve just been hired to lead the data science efforts at DataSciencester, the social network for data scientists.  NOTE  When I wrote the first edition of this book, I thought that “a social network for data scientists” was a fun, silly hypothetical. Since then people have actually created social networks for data scientists, and have raised much more money from venture capitalists than I made from my book. Most likely there is a valuable lesson here about silly data science hypotheticals and or book publishing.  Despite being for data scientists, DataSciencester has never actually invested in building its own data science practice.  In fairness, DataSciencester has never really invested in building its product either.  That will be your job! Throughout the book, we’ll be learning about data science concepts by solving problems that you encounter at work. Sometimes we’ll look at data explicitly supplied by users, sometimes we’ll look at data generated through their interactions with the site, and sometimes we’ll even look at data from experiments that we’ll design. And because DataSciencester has a strong “not-invented-here” mentality, we’ll be building our own tools from scratch. At the end, you’ll have a pretty solid understanding of the fundamentals of data science. And you’ll be ready to apply your skills at a company with a less shaky premise, or to any other problems that happen to interest you. Welcome aboard, and good luck!  You’re allowed to wear jeans on Fridays, and the bathroom is down the hall on the right.   Finding Key Connectors It’s your first day on the job at DataSciencester, and the VP of Networking is full of questions about your users. Until now he’s had no one to ask, so he’s very excited to have you aboard.   In particular, he wants you to identify who the “key connectors” are among data scientists. To this end, he gives you a dump of the entire DataSciencester network.  In real life, people don’t typically hand you the data you need. Chapter 9 is devoted to getting data.  What does this data dump look like? It consists of a list of users, each represented by a d  t that contains that user’s i  d  which is a number  and  e  which, in one of the great cosmic coincidences, rhymes with the  user’s i  d :  He also gives you the “friendship” data, represented as a list of pairs of IDs:  For example, the tuple    Hero  and the data scientist with i illustrated in Figure 1-1.    indicates that the data scientist with i  d 0  d 1  Dunn  are friends. The network is  i c n a m u s e r s   =   [           {   " i d " :   0 ,   " n a m e " :   " H e r o "   } ,           {   " i d " :   1 ,   " n a m e " :   " D u n n "   } ,           {   " i d " :   2 ,   " n a m e " :   " S u e "   } ,           {   " i d " :   3 ,   " n a m e " :   " C h i "   } ,           {   " i d " :   4 ,   " n a m e " :   " T h o r "   } ,           {   " i d " :   5 ,   " n a m e " :   " C l i v e "   } ,           {   " i d " :   6 ,   " n a m e " :   " H i c k s "   } ,           {   " i d " :   7 ,   " n a m e " :   " D e v i n "   } ,           {   " i d " :   8 ,   " n a m e " :   " K a t e "   } ,           {   " i d " :   9 ,   " n a m e " :   " K l e i n "   }   ] f r i e n d s h i p _ p a i r s   =   [   0 ,   1   ,     0 ,   2   ,     1 ,   2   ,     1 ,   3   ,     2 ,   3   ,     3 ,   4   ,                                             4 ,   5   ,     5 ,   6   ,     5 ,   7   ,     6 ,   8   ,     7 ,   8   ,     8 ,   9   ] 0 ,   1  Figure 1-1. The DataSciencester network  Having friendships represented as a list of pairs is not the easiest way to work with them. To find all the friendships for user 1, you have to iterate over every pair looking for pairs containing 1. If you had a lot of pairs, this would take a long time. Instead, let’s create a d lists of friend i  ds.  Looking things up in a d  t where the keys are user i  ds and the values are  t is very fast.   NOTE  Don’t get too hung up on the details of the code right now. In Chapter 2, I’ll take you through a crash course in Python. For now just try to get the general flavor of what we’re doing.  We’ll still have to look at every pair to create the d do that once, and we’ll get cheap lookups after that:  t, but we only have to  Now that we have the friendships in a d our graph, like “What’s the average number of connections?”  t, we can easily ask questions of  i c i c i c    I n i t i a l i z e   t h e   d i c t   w i t h   a n   e m p t y   l i s t   f o r   e a c h   u s e r   i d :   f r i e n d s h i p s   =   { u s e r [ " i d " ] :   [ ]   f o r   u s e r   i n   u s e r s }        A n d   l o o p   o v e r   t h e   f r i e n d s h i p   p a i r s   t o   p o p u l a t e   i t :   f o r   i ,   j   i n   f r i e n d s h i p _ p a i r s :           f r i e n d s h i p s [ i ] . a p p e n d   j          A d d   j   a s   a   f r i e n d   o f   u s e r   i           f r i e n d s h i p s [ j ] . a p p e n d   i          A d d   i   a s   a   f r i e n d   o f   u s e r   j i c  First we find the total number of connections, by summing up the lengths of all the f  s lists:  And then we just divide by the number of users:  It’s also easy to find the most connected people—they’re the people who have the largest numbers of friends. Since there aren’t very many users, we can simply sort them from “most friends” to “least friends”:  One way to think of what we’ve done is as a way of identifying people who are somehow central to the network. In fact, what we’ve just computed is the network metric degree centrality  Figure 1-2 .  r i e n d d e f   n u m b e r _ o f _ f r i e n d s   u s e r   :           " " " H o w   m a n y   f r i e n d s   d o e s   _ u s e r _   h a v e ? " " "           u s e r _ i d   =   u s e r [ " i d " ]           f r i e n d _ i d s   =   f r i e n d s h i p s [ u s e r _ i d ]           r e t u r n   l e n   f r i e n d _ i d s       t o t a l _ c o n n e c t i o n s   =   s u m   n u m b e r _ o f _ f r i e n d s   u s e r                                                     f o r   u s e r   i n   u s e r s                      2 4 n u m _ u s e r s   =   l e n   u s e r s                                                              l e n g t h   o f   t h e   u s e r s   l i s t   a v g _ c o n n e c t i o n s   =   t o t a l _ c o n n e c t i o n s       n u m _ u s e r s          2 4       1 0   = =   2 . 4    C r e a t e   a   l i s t     u s e r _ i d ,   n u m b e r _ o f _ f r i e n d s   .   n u m _ f r i e n d s _ b y _ i d   =   [   u s e r [ " i d " ] ,   n u m b e r _ o f _ f r i e n d s   u s e r                                                 f o r   u s e r   i n   u s e r s ]     n u m _ f r i e n d s _ b y _ i d . s o r t                                                                      S o r t   t h e   l i s t                 k e y = l a m b d a   i d _ a n d _ f r i e n d s :   i d _ a n d _ f r i e n d s [ 1 ] ,          b y   n u m _ f r i e n d s                 r e v e r s e = T r u e                                                                            l a r g e s t   t o   s m a l l e s t        E a c h   p a i r   i s     u s e r _ i d ,   n u m _ f r i e n d s   :      [   1 ,   3   ,     2 ,   3   ,     3 ,   3   ,     5 ,   3   ,     8 ,   3   ,          0 ,   2   ,     4 ,   2   ,     6 ,   2   ,     7 ,   2   ,     9 ,   1   ]  Figure 1-2. The DataSciencester network sized by degree  d 4  only has two connections, while Dunn  i  This has the virtue of being pretty easy to calculate, but it doesn’t always give the results you’d want or expect. For example, in the DataSciencester network Thor  i Yet when we look at the network, it intuitively seems like Thor should be more central. In Chapter 22, we’ll investigate networks in more detail, and we’ll look at more complex notions of centrality that may or may not accord better with our intuition.  d 1  has three.  Data Scientists You May Know While you’re still filling out new-hire paperwork, the VP of Fraternization comes by your desk. She wants to encourage more connections among your members, and she asks you to design a “Data Scientists You May Know” suggester. Your first instinct is to suggest that users might know the friends of their friends. So you write some code to iterate over their friends and collect the friends’ friends:  When we call this on u  ]  Hero , it produces:  d e f   f o a f _ i d s _ b a d   u s e r   :           " " " f o a f   i s   s h o r t   f o r   " f r i e n d   o f   a   f r i e n d "   " " "           r e t u r n   [ f o a f _ i d                           f o r   f r i e n d _ i d   i n   f r i e n d s h i p s [ u s e r [ " i d " ] ]                           f o r   f o a f _ i d   i n   f r i e n d s h i p s [ f r i e n d _ i d ] ] s e r s [ 0  It includes user 0 twice, since Hero is indeed friends with both of his friends. It includes users 1 and 2, although they are both friends with Hero already. And it includes user 3 twice, as Chi is reachable through two different friends:  Knowing that people are friends of friends in multiple ways seems like interesting information, so maybe instead we should produce a count of mutual friends. And we should probably exclude people already known to the user:  d 3  that she has two mutual friends with Hero  i  This correctly tells Chi  i 0  but only one mutual friend with Clive  i As a data scientist, you know that you also might enjoy meeting users with similar interests.  This is a good example of the “substantive expertise” aspect of data science.  After asking around, you manage to get your hands on this data, as a list of pairs    d 5 .   :  [ 0 ,   2 ,   3 ,   0 ,   1 ,   3 ] p r i n t   f r i e n d s h i p s [ 0 ]          [ 1 ,   2 ]   p r i n t   f r i e n d s h i p s [ 1 ]          [ 0 ,   2 ,   3 ]   p r i n t   f r i e n d s h i p s [ 2 ]          [ 0 ,   1 ,   3 ] f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r                                          n o t   l o a d e d   b y   d e f a u l t     d e f   f r i e n d s _ o f _ f r i e n d s   u s e r   :           u s e r _ i d   =   u s e r [ " i d " ]           r e t u r n   C o u n t e r                     f o a f _ i d                   f o r   f r i e n d _ i d   i n   f r i e n d s h i p s [ u s e r _ i d ]              F o r   e a c h   o f   m y   f r i e n d s ,                   f o r   f o a f _ i d   i n   f r i e n d s h i p s [ f r i e n d _ i d ]              f i n d   t h e i r   f r i e n d s                   i f   f o a f _ i d   ! =   u s e r _ i d                                              w h o   a r e n ' t   m e                   a n d   f o a f _ i d   n o t   i n   f r i e n d s h i p s [ u s e r _ i d ]          a n d   a r e n ' t   m y   f r i e n d s .                   p r i n t   f r i e n d s _ o f _ f r i e n d s   u s e r s [ 3 ]                                      C o u n t e r   { 0 :   2 ,   5 :   1 }   d u s e r _ i d ,   i n t e r e s t  d 0  has no friends in common with Klein  i  For example, Hero  i they share interests in Java and big data. It’s easy to build a function that finds users with a certain interest:  d 9 , but  This works, but it has to examine the whole list of interests for every search. If we have a lot of users and interests  or if we just want to do a lot of searches , we’re probably better off building an index from interests to users:  And another from users to interests:  i n t e r e s t s   =   [             0 ,   " H a d o o p "   ,     0 ,   " B i g   D a t a "   ,     0 ,   " H B a s e "   ,     0 ,   " J a v a "   ,             0 ,   " S p a r k "   ,     0 ,   " S t o r m "   ,     0 ,   " C a s s a n d r a "   ,             1 ,   " N o S Q L "   ,     1 ,   " M o n g o D B "   ,     1 ,   " C a s s a n d r a "   ,     1 ,   " H B a s e "   ,             1 ,   " P o s t g r e s "   ,     2 ,   " P y t h o n "   ,     2 ,   " s c i k i t - l e a r n "   ,     2 ,   " s c i p y "   ,             2 ,   " n u m p y "   ,     2 ,   " s t a t s m o d e l s "   ,     2 ,   " p a n d a s "   ,     3 ,   " R "   ,     3 ,   " P y t h o n "   ,             3 ,   " s t a t i s t i c s "   ,     3 ,   " r e g r e s s i o n "   ,     3 ,   " p r o b a b i l i t y "   ,             4 ,   " m a c h i n e   l e a r n i n g "   ,     4 ,   " r e g r e s s i o n "   ,     4 ,   " d e c i s i o n   t r e e s "   ,             4 ,   " l i b s v m "   ,     5 ,   " P y t h o n "   ,     5 ,   " R "   ,     5 ,   " J a v a "   ,     5 ,   " C + + "   ,             5 ,   " H a s k e l l "   ,     5 ,   " p r o g r a m m i n g   l a n g u a g e s "   ,     6 ,   " s t a t i s t i c s "   ,             6 ,   " p r o b a b i l i t y "   ,     6 ,   " m a t h e m a t i c s "   ,     6 ,   " t h e o r y "   ,             7 ,   " m a c h i n e   l e a r n i n g "   ,     7 ,   " s c i k i t - l e a r n "   ,     7 ,   " M a h o u t "   ,             7 ,   " n e u r a l   n e t w o r k s "   ,     8 ,   " n e u r a l   n e t w o r k s "   ,     8 ,   " d e e p   l e a r n i n g "   ,             8 ,   " B i g   D a t a "   ,     8 ,   " a r t i f i c i a l   i n t e l l i g e n c e "   ,     9 ,   " H a d o o p "   ,             9 ,   " J a v a "   ,     9 ,   " M a p R e d u c e "   ,     9 ,   " B i g   D a t a "     ] d e f   d a t a _ s c i e n t i s t s _ w h o _ l i k e   t a r g e t _ i n t e r e s t   :           " " " F i n d   t h e   i d s   o f   a l l   u s e r s   w h o   l i k e   t h e   t a r g e t   i n t e r e s t . " " "           r e t u r n   [ u s e r _ i d                           f o r   u s e r _ i d ,   u s e r _ i n t e r e s t   i n   i n t e r e s t s                           i f   u s e r _ i n t e r e s t   = =   t a r g e t _ i n t e r e s t ] f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t        K e y s   a r e   i n t e r e s t s ,   v a l u e s   a r e   l i s t s   o f   u s e r _ i d s   w i t h   t h a t   i n t e r e s t   u s e r _ i d s _ b y _ i n t e r e s t   =   d e f a u l t d i c t   l i s t       f o r   u s e r _ i d ,   i n t e r e s t   i n   i n t e r e s t s :           u s e r _ i d s _ b y _ i n t e r e s t [ i n t e r e s t ] . a p p e n d   u s e r _ i d    Now it’s easy to find who has the most interests in common with a given user:  Iterate over the user’s interests. For each interest, iterate over the other users with that interest. Keep count of how many times we see each other user.  In code:  We could then use this to build a richer “Data Scientists You May Know” feature based on a combination of mutual friends and mutual interests. We’ll explore these kinds of applications in Chapter 23.  Salaries and Experience Right as you’re about to head to lunch, the VP of Public Relations asks if you can provide some fun facts about how much data scientists earn. Salary data is of course sensitive, but he manages to provide you an anonymous dataset containing each user’s s e as a data scientist  in years :  y  in dollars  and t     K e y s   a r e   u s e r _ i d s ,   v a l u e s   a r e   l i s t s   o f   i n t e r e s t s   f o r   t h a t   u s e r _ i d .   i n t e r e s t s _ b y _ u s e r _ i d   =   d e f a u l t d i c t   l i s t       f o r   u s e r _ i d ,   i n t e r e s t   i n   i n t e r e s t s :           i n t e r e s t s _ b y _ u s e r _ i d [ u s e r _ i d ] . a p p e n d   i n t e r e s t   d e f   m o s t _ c o m m o n _ i n t e r e s t s _ w i t h   u s e r   :           r e t u r n   C o u n t e r                     i n t e r e s t e d _ u s e r _ i d                   f o r   i n t e r e s t   i n   i n t e r e s t s _ b y _ u s e r _ i d [ u s e r [ " i d " ] ]                   f o r   i n t e r e s t e d _ u s e r _ i d   i n   u s e r _ i d s _ b y _ i n t e r e s t [ i n t e r e s t ]                   i f   i n t e r e s t e d _ u s e r _ i d   ! =   u s e r [ " i d " ]             a l a r e n u r s a l a r i e s _ a n d _ t e n u r e s   =   [   8 3 0 0 0 ,   8 . 7   ,     8 8 0 0 0 ,   8 . 1   ,                                                     4 8 0 0 0 ,   0 . 7   ,     7 6 0 0 0 ,   6   ,                                                     6 9 0 0 0 ,   6 . 5   ,     7 6 0 0 0 ,   7 . 5   ,    The natural first step is to plot the data  which we’ll see how to do in Chapter 3 . You can see the results in Figure 1-3.  Figure 1-3. Salary by years of experience  It seems clear that people with more experience tend to earn more. How can you turn this into a fun fact? Your first idea is to look at the average salary for each tenure:                                                    6 0 0 0 0 ,   2 . 5   ,     8 3 0 0 0 ,   1 0   ,                                                     4 8 0 0 0 ,   1 . 9   ,     6 3 0 0 0 ,   4 . 2   ]    K e y s   a r e   y e a r s ,   v a l u e s   a r e   l i s t s   o f   t h e   s a l a r i e s   f o r   e a c h   t e n u r e .   s a l a r y _ b y _ t e n u r e   =   d e f a u l t d i c t   l i s t       f o r   s a l a r y ,   t e n u r e   i n   s a l a r i e s _ a n d _ t e n u r e s :           s a l a r y _ b y _ t e n u r e [ t e n u r e ] . a p p e n d   s a l a r y          K e y s   a r e   y e a r s ,   e a c h   v a l u e   i s   a v e r a g e   s a l a r y   f o r   t h a t   t e n u r e .   a v e r a g e _ s a l a r y _ b y _ t e n u r e   =   {    This turns out to be not particularly useful, as none of the users have the same tenure, which means we’re just reporting the individual users’ salaries:  It might be more helpful to bucket the tenures:  Then we can group together the salaries corresponding to each bucket:  And finally compute the average salary for each group:          t e n u r e :   s u m   s a l a r i e s         l e n   s a l a r i e s             f o r   t e n u r e ,   s a l a r i e s   i n   s a l a r y _ b y _ t e n u r e . i t e m s       } { 0 . 7 :   4 8 0 0 0 . 0 ,     1 . 9 :   4 8 0 0 0 . 0 ,     2 . 5 :   6 0 0 0 0 . 0 ,     4 . 2 :   6 3 0 0 0 . 0 ,     6 :   7 6 0 0 0 . 0 ,     6 . 5 :   6 9 0 0 0 . 0 ,     7 . 5 :   7 6 0 0 0 . 0 ,     8 . 1 :   8 8 0 0 0 . 0 ,     8 . 7 :   8 3 0 0 0 . 0 ,     1 0 :   8 3 0 0 0 . 0 } d e f   t e n u r e _ b u c k e t   t e n u r e   :           i f   t e n u r e   <   2 :                   r e t u r n   " l e s s   t h a n   t w o "           e l i f   t e n u r e   <   5 :                   r e t u r n   " b e t w e e n   t w o   a n d   f i v e "           e l s e :                   r e t u r n   " m o r e   t h a n   f i v e "    K e y s   a r e   t e n u r e   b u c k e t s ,   v a l u e s   a r e   l i s t s   o f   s a l a r i e s   f o r   t h a t   b u c k e t .   s a l a r y _ b y _ t e n u r e _ b u c k e t   =   d e f a u l t d i c t   l i s t       f o r   s a l a r y ,   t e n u r e   i n   s a l a r i e s _ a n d _ t e n u r e s :           b u c k e t   =   t e n u r e _ b u c k e t   t e n u r e             s a l a r y _ b y _ t e n u r e _ b u c k e t [ b u c k e t ] . a p p e n d   s a l a r y      K e y s   a r e   t e n u r e   b u c k e t s ,   v a l u e s   a r e   a v e r a g e   s a l a r y   f o r   t h a t   b u c k e t .   a v e r a g e _ s a l a r y _ b y _ b u c k e t   =   {    Which is more interesting:  And you have your soundbite: “Data scientists with more than five years’ experience earn 65% more than data scientists with little or no experience!” But we chose the buckets in a pretty arbitrary way. What we’d really like is to make some statement about the salary effect—on average—of having an additional year of experience. In addition to making for a snappier fun fact, this allows us to make predictions about salaries that we don’t know. We’ll explore this idea in Chapter 14.  Paid Accounts When you get back to your desk, the VP of Revenue is waiting for you. She wants to better understand which users pay for accounts and which don’t.  She knows their names, but that’s not particularly actionable information.  You notice that there seems to be a correspondence between years of experience and paid accounts:      t e n u r e _ b u c k e t :   s u m   s a l a r i e s         l e n   s a l a r i e s         f o r   t e n u r e _ b u c k e t ,   s a l a r i e s   i n   s a l a r y _ b y _ t e n u r e _ b u c k e t . i t e m s       } { ' b e t w e e n   t w o   a n d   f i v e ' :   6 1 5 0 0 . 0 ,     ' l e s s   t h a n   t w o ' :   4 8 0 0 0 . 0 ,     ' m o r e   t h a n   f i v e ' :   7 9 1 6 6 . 6 6 6 6 6 6 6 6 6 6 7 } 0 . 7     p a i d   1 . 9     u n p a i d   2 . 5     p a i d   4 . 2     u n p a i d   6 . 0     u n p a i d   6 . 5     u n p a i d   7 . 5     u n p a i d   8 . 1     u n p a i d   8 . 7     p a i d   1 0 . 0   p a i d  Users with very few and very many years of experience tend to pay; users with average amounts of experience don’t. Accordingly, if you wanted to create a model—though this is definitely not enough data to base a model on—you might try to predict “paid” for users with very few and very many years of experience, and “unpaid” for users with middling amounts of experience:  Of course, we totally eyeballed the cutoffs. With more data  and more mathematics , we could build a model predicting the likelihood that a user would pay based on his years of experience. We’ll investigate this sort of problem in Chapter 16.  Topics of Interest As you’re wrapping up your first day, the VP of Content Strategy asks you for data about what topics users are most interested in, so that she can plan out her blog calendar accordingly. You already have the raw data from the friend-suggester project:  d e f   p r e d i c t _ p a i d _ o r _ u n p a i d   y e a r s _ e x p e r i e n c e   :       i f   y e a r s _ e x p e r i e n c e   <   3 . 0 :           r e t u r n   " p a i d "       e l i f   y e a r s _ e x p e r i e n c e   <   8 . 5 :           r e t u r n   " u n p a i d "       e l s e :           r e t u r n   " p a i d " i n t e r e s t s   =   [             0 ,   " H a d o o p "   ,     0 ,   " B i g   D a t a "   ,     0 ,   " H B a s e "   ,     0 ,   " J a v a "   ,             0 ,   " S p a r k "   ,     0 ,   " S t o r m "   ,     0 ,   " C a s s a n d r a "   ,             1 ,   " N o S Q L "   ,     1 ,   " M o n g o D B "   ,     1 ,   " C a s s a n d r a "   ,     1 ,   " H B a s e "   ,             1 ,   " P o s t g r e s "   ,     2 ,   " P y t h o n "   ,     2 ,   " s c i k i t - l e a r n "   ,     2 ,   " s c i p y "   ,             2 ,   " n u m p y "   ,     2 ,   " s t a t s m o d e l s "   ,     2 ,   " p a n d a s "   ,     3 ,   " R "   ,     3 ,   " P y t h o n "   ,             3 ,   " s t a t i s t i c s "   ,     3 ,   " r e g r e s s i o n "   ,     3 ,   " p r o b a b i l i t y "   ,             4 ,   " m a c h i n e   l e a r n i n g "   ,     4 ,   " r e g r e s s i o n "   ,     4 ,   " d e c i s i o n   t r e e s "   ,             4 ,   " l i b s v m "   ,     5 ,   " P y t h o n "   ,     5 ,   " R "   ,     5 ,   " J a v a "   ,     5 ,   " C + + "   ,             5 ,   " H a s k e l l "   ,     5 ,   " p r o g r a m m i n g   l a n g u a g e s "   ,     6 ,   " s t a t i s t i c s "   ,             6 ,   " p r o b a b i l i t y "   ,     6 ,   " m a t h e m a t i c s "   ,     6 ,   " t h e o r y "   ,             7 ,   " m a c h i n e   l e a r n i n g "   ,     7 ,   " s c i k i t - l e a r n "   ,     7 ,   " M a h o u t "   ,             7 ,   " n e u r a l   n e t w o r k s "   ,     8 ,   " n e u r a l   n e t w o r k s "   ,     8 ,   " d e e p   l e a r n i n g "   ,    One simple  if not particularly exciting  way to find the most popular interests is to count the words:  1. Lowercase each interest  since different users may or may not  capitalize their interests .  2. Split it into words. 3. Count the results.  In code:  This makes it easy to list out the words that occur more than once:  which gives the results you’d expect  unless you expect “scikit-learn” to get split into two words, in which case it doesn’t give the results you expect :            8 ,   " B i g   D a t a "   ,     8 ,   " a r t i f i c i a l   i n t e l l i g e n c e "   ,     9 ,   " H a d o o p "   ,             9 ,   " J a v a "   ,     9 ,   " M a p R e d u c e "   ,     9 ,   " B i g   D a t a "     ] w o r d s _ a n d _ c o u n t s   =   C o u n t e r   w o r d                                                         f o r   u s e r ,   i n t e r e s t   i n   i n t e r e s t s                                                         f o r   w o r d   i n   i n t e r e s t . l o w e r     . s p l i t       f o r   w o r d ,   c o u n t   i n   w o r d s _ a n d _ c o u n t s . m o s t _ c o m m o n     :           i f   c o u n t   >   1 :                   p r i n t   w o r d ,   c o u n t   l e a r n i n g   3   j a v a   3   p y t h o n   3   b i g   3   d a t a   3   h b a s e   2   r e g r e s s i o n   2   c a s s a n d r a   2   s t a t i s t i c s   2   p r o b a b i l i t y   2   h a d o o p   2   n e t w o r k s   2   m a c h i n e   2    We’ll look at more sophisticated ways to extract topics from data in Chapter 21.  Onward It’s been a successful first day! Exhausted, you slip out of the building before anyone can ask you for anything else. Get a good night’s rest, because tomorrow is new employee orientation.  Yes, you went through a full day of work before new employee orientation. Take it up with HR.   n e u r a l   2   s c i k i t - l e a r n   2   r   2  Chapter 2. A Crash Course in Python  People are still crazy about Python after twenty-five years, which I find hard to believe.  —Michael Palin  All new employees at DataSciencester are required to go through new employee orientation, the most interesting part of which is a crash course in Python. This is not a comprehensive Python tutorial but instead is intended to highlight the parts of the language that will be most important to us  some of which are often not the focus of Python tutorials . If you have never used Python before, you probably want to supplement this with some sort of beginner tutorial.  The Zen of Python Python has a somewhat Zen description of its design principles, which you can also find inside the Python interpreter itself by typing “import this.” One of the most discussed of these is:  There should be one—and preferably only one—obvious way to do it. Code written in accordance with this “obvious” way  which may not be obvious at all to a newcomer  is often described as “Pythonic.” Although this is not a book about Python, we will occasionally contrast Pythonic and non-Pythonic ways of accomplishing the same things, and we will generally favor Pythonic solutions to our problems. Several others touch on aesthetics:   Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. and represent ideals that we will strive for in our code.  Getting Python  NOTE  As instructions about how to install things can change, while printed books cannot, up- to-date instructions on how to install Python can be found in the book’s GitHub repo. If the ones printed here don’t work for you, check those.  You can download Python from Python.org. But if you don’t already have Python, I recommend instead installing the Anaconda distribution, which already includes most of the libraries that you need to do data science. When I wrote the first version of Data Science from Scratch, Python 2.7 was still the preferred version of most data scientists. Accordingly, the first edition of the book was based on Python 2.7. In the last several years, however, pretty much everyone who counts has migrated to Python 3. Recent versions of Python have many features that make it easier to write clean code, and we’ll be taking ample advantage of features that are only available in Python 3.6 or later. This means that you should get Python 3.6 or later.  In addition, many useful libraries are ending support for Python 2.7, which is another reason to switch.   Virtual Environments Starting in the next chapter, we’ll be using the matplotlib library to generate plots and charts. This library is not a core part of Python; you have to install it yourself. Every data science project you do will require some combination of external libraries, sometimes with specific versions that   differ from the specific versions you used for other projects. If you were to have a single Python installation, these libraries would conflict and cause you all sorts of problems. The standard solution is to use virtual environments, which are sandboxed Python environments that maintain their own versions of Python libraries  and, depending on how you set up the environment, of Python itself . I recommended you install the Anaconda Python distribution, so in this section I’m going to explain how Anaconda’s environments work. If you are not using Anaconda, you can either use the built-in v install v instead. To create an  Anaconda  virtual environment, you just do the following:  v module or v. In which case you should follow their instructions  Follow the prompts, and you’ll have a virtual environment called “dsfs,” with the instructions:  As indicated, you then activate the environment using:  at which point your command prompt should change to indicate the active environment. On my MacBook the prompt now looks like:  e n i r t u a l e n    c r e a t e   a   P y t h o n   3 . 6   e n v i r o n m e n t   n a m e d   " d s f s "   c o n d a   c r e a t e   - n   d s f s   p y t h o n = 3 . 6       T o   a c t i v a t e   t h i s   e n v i r o n m e n t ,   u s e :      >   s o u r c e   a c t i v a t e   d s f s         T o   d e a c t i v a t e   a n   a c t i v e   e n v i r o n m e n t ,   u s e :      >   s o u r c e   d e a c t i v a t e    s o u r c e   a c t i v a t e   d s f s   d s f s     i p - 1 0 - 0 - 0 - 1 9 8 : ~   j o e l g $  As long as this environment is active, any libraries you install will be installed only in the dsfs environment. Once you finish this book and go on to your own projects, you should create your own environments for them. Now that you have your environment, it’s worth installing IPython, which is a full-featured Python shell:  NOTE Anaconda comes with its own package manager, c standard Python package manager p  a, but you can also just use the  p, which is what we’ll be doing.  The rest of this book will assume that you have created and activated such a Python 3.6 virtual environment  although you can call it whatever you want , and later chapters may rely on the libraries that I told you to install in earlier chapters. As a matter of good discipline, you should always work in a virtual environment, and never using the “base” Python installation.  Whitespace Formatting Many languages use curly braces to delimit blocks of code. Python uses indentation:  p y t h o n   - m   p i p   i n s t a l l   i p y t h o n o n d i    T h e   p o u n d   s i g n   m a r k s   t h e   s t a r t   o f   a   c o m m e n t .   P y t h o n   i t s e l f      i g n o r e s   t h e   c o m m e n t s ,   b u t   t h e y ' r e   h e l p f u l   f o r   a n y o n e   r e a d i n g   t h e   c o d e .   f o r   i   i n   [ 1 ,   2 ,   3 ,   4 ,   5 ] :           p r i n t   i                                              f i r s t   l i n e   i n   " f o r   i "   b l o c k           f o r   j   i n   [ 1 ,   2 ,   3 ,   4 ,   5 ] :                   p r i n t   j                                      f i r s t   l i n e   i n   " f o r   j "   b l o c k                   p r i n t   i   +   j                              l a s t   l i n e   i n   " f o r   j "   b l o c k           p r i n t   i                                              l a s t   l i n e   i n   " f o r   i "   b l o c k   p r i n t   " d o n e   l o o p i n g "    This makes Python code very readable, but it also means that you have to be very careful with your formatting.  WARNING  Programmers will often argue over whether to use tabs or spaces for indentation. For many languages it doesn’t matter that much; however, Python considers tabs and spaces different indentation and will not be able to run your code if you mix the two. When writing Python you should always use spaces, never tabs.  If you write code in an editor you can configure it so that the Tab key just inserts spaces.   Whitespace is ignored inside parentheses and brackets, which can be helpful for long-winded computations:  and for making code easier to read:  You can also use a backslash to indicate that a statement continues onto the next line, although we’ll rarely do this:  One consequence of whitespace formatting is that it can be hard to copy and paste code into the Python shell. For example, if you tried to paste the code:  l o n g _ w i n d e d _ c o m p u t a t i o n   =     1   +   2   +   3   +   4   +   5   +   6   +   7   +   8   +   9   +   1 0   +   1 1   +   1 2   +                                                         1 3   +   1 4   +   1 5   +   1 6   +   1 7   +   1 8   +   1 9   +   2 0   l i s t _ o f _ l i s t s   =   [ [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ] ,   [ 7 ,   8 ,   9 ] ]     e a s i e r _ t o _ r e a d _ l i s t _ o f _ l i s t s   =   [ [ 1 ,   2 ,   3 ] ,                                                                   [ 4 ,   5 ,   6 ] ,                                                                   [ 7 ,   8 ,   9 ] ] t w o _ p l u s _ t h r e e   =   2   +   \                                     3 f o r   i   i n   [ 1 ,   2 ,   3 ,   4 ,   5 ] :                n o t i c e   t h e   b l a n k   l i n e           p r i n t   i    into the ordinary Python shell, you would receive the complaint:  because the interpreter thinks the blank line signals the end of the f loop’s block. IPython has a magic function called % whatever is on your clipboard, whitespace and all. This alone is a good reason to use IPython.  e, which correctly pastes  Modules Certain features of Python are not loaded by default. These include both features that are included as part of the language as well as third-party features that you download yourself. In order to use these features, you’ll need to i One approach is to simply i  t the modules that contain them.  t the module itself:  e is the module containing functions and constants for working with  t you must prefix those  Here, r regular expressions. After this type of i functions with r If you already had a different r  . in order to access them.  e in your code, you could use an alias:  You might also do this if your module has an unwieldy name or if you’re going to be typing it a lot. For example, a standard convention when visualizing data with matplotlib is:  I n d e n t a t i o n E r r o r :   e x p e c t e d   a n   i n d e n t e d   b l o c k o r p a s t m p o r m p o r i m p o r t   r e   m y _ r e g e x   =   r e . c o m p i l e   " [ 0 - 9 ] + " ,   r e . I   m p o r e i m p o r t   r e   a s   r e g e x   m y _ r e g e x   =   r e g e x . c o m p i l e   " [ 0 - 9 ] + " ,   r e g e x . I    If you need a few specific values from a module, you can import them explicitly and use them without qualification:  If you were a bad person, you could import the entire contents of a module into your namespace, which might inadvertently overwrite variables you’ve already defined:  However, since you are not a bad person, you won’t ever do this.  Functions A function is a rule for taking zero or more inputs and returning a corresponding output. In Python, we typically define functions using d  f:  Python functions are first-class, which means that we can assign them to variables and pass them into functions just like any other arguments:  i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t     p l t . p l o t   . . .   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t ,   C o u n t e r   l o o k u p   =   d e f a u l t d i c t   i n t     m y _ c o u n t e r   =   C o u n t e r     m a t c h   =   1 0   f r o m   r e   i m p o r t   *            u h   o h ,   r e   h a s   a   m a t c h   f u n c t i o n   p r i n t   m a t c h                      " < f u n c t i o n   m a t c h   a t   0 x 1 0 2 8 1 e 6 a 8 > " e d e f   d o u b l e   x   :           " " "           T h i s   i s   w h e r e   y o u   p u t   a n   o p t i o n a l   d o c s t r i n g   t h a t   e x p l a i n s   w h a t   t h e           f u n c t i o n   d o e s .   F o r   e x a m p l e ,   t h i s   f u n c t i o n   m u l t i p l i e s   i t s   i n p u t   b y   2 .           " " "           r e t u r n   x   *   2 d e f   a p p l y _ t o _ o n e   f   :           " " " C a l l s   t h e   f u n c t i o n   f   w i t h   1   a s   i t s   a r g u m e n t " " "           r e t u r n   f   1      It is also easy to create short anonymous functions, or lambdas:  You can assign lambdas to variables, although most people will tell you that you should just use d  f instead:  Function parameters can also be given default arguments, which only need to be specified when you want a value other than the default:  It is sometimes useful to specify arguments by name:  We will be creating many, many functions.  Strings    m y _ d o u b l e   =   d o u b l e                              r e f e r s   t o   t h e   p r e v i o u s l y   d e f i n e d   f u n c t i o n   x   =   a p p l y _ t o _ o n e   m y _ d o u b l e              e q u a l s   2 y   =   a p p l y _ t o _ o n e   l a m b d a   x :   x   +   4                  e q u a l s   5 e a n o t h e r _ d o u b l e   =   l a m b d a   x :   2   *   x                  d o n ' t   d o   t h i s     d e f   a n o t h e r _ d o u b l e   x   :           " " " D o   t h i s   i n s t e a d " " "           r e t u r n   2   *   x d e f   m y _ p r i n t   m e s s a g e   =   " m y   d e f a u l t   m e s s a g e "   :           p r i n t   m e s s a g e       m y _ p r i n t   " h e l l o "            p r i n t s   ' h e l l o '   m y _ p r i n t                            p r i n t s   ' m y   d e f a u l t   m e s s a g e ' d e f   f u l l _ n a m e   f i r s t   =   " W h a t ' s - h i s - n a m e " ,   l a s t   =   " S o m e t h i n g "   :           r e t u r n   f i r s t   +   "   "   +   l a s t     f u l l _ n a m e   " J o e l " ,   " G r u s "                " J o e l   G r u s "   f u l l _ n a m e   " J o e l "                                " J o e l   S o m e t h i n g "   f u l l _ n a m e   l a s t = " G r u s "                      " W h a t ' s - h i s - n a m e   G r u s "  Strings can be delimited by single or double quotation marks  but the quotes have to match :  Python uses backslashes to encode special characters. For example:  If you want backslashes as backslashes  which you might in Windows directory names or in regular expressions , you can create raw strings using  ":  You can create multiline strings using three double quotes:  A new feature in Python 3.6 is the f-string, which provides a simple way to substitute values into strings. For example, if we had the first name and last name given separately:  we might want to combine them into a full name. There are multiple ways to construct such a f  e string:  but the f-string way is much less unwieldy:  s i n g l e _ q u o t e d _ s t r i n g   =   ' d a t a   s c i e n c e '   d o u b l e _ q u o t e d _ s t r i n g   =   " d a t a   s c i e n c e " t a b _ s t r i n g   =   " \ t "                  r e p r e s e n t s   t h e   t a b   c h a r a c t e r   l e n   t a b _ s t r i n g                        i s   1 r " n o t _ t a b _ s t r i n g   =   r " \ t "        r e p r e s e n t s   t h e   c h a r a c t e r s   ' \ '   a n d   ' t '   l e n   n o t _ t a b _ s t r i n g                i s   2 m u l t i _ l i n e _ s t r i n g   =   " " " T h i s   i s   t h e   f i r s t   l i n e .   a n d   t h i s   i s   t h e   s e c o n d   l i n e   a n d   t h i s   i s   t h e   t h i r d   l i n e " " " f i r s t _ n a m e   =   " J o e l "   l a s t _ n a m e   =   " G r u s " u l l _ n a m f u l l _ n a m e 1   =   f i r s t _ n a m e   +   "   "   +   l a s t _ n a m e                              s t r i n g   a d d i t i o n   f u l l _ n a m e 2   =   " { 0 }   { 1 } " . f o r m a t   f i r s t _ n a m e ,   l a s t _ n a m e          s t r i n g . f o r m a t  and we’ll prefer it throughout the book.  Exceptions When something goes wrong, Python raises an exception. Unhandled, exceptions will cause your program to crash. You can handle them using  y and e  t:  Although in many languages exceptions are considered bad, in Python there is no shame in using them to make your code cleaner, and we will sometimes do so.  Lists Probably the most fundamental data structure in Python is the list, which is simply an ordered collection  it is similar to what in other languages might be called an array, but with some added functionality :  You can get or set the nth element of a list with square brackets:  f u l l _ n a m e 3   =   f " { f i r s t _ n a m e }   { l a s t _ n a m e } " t r x c e p t r y :           p r i n t   0       0     e x c e p t   Z e r o D i v i s i o n E r r o r :           p r i n t   " c a n n o t   d i v i d e   b y   z e r o "   i n t e g e r _ l i s t   =   [ 1 ,   2 ,   3 ]   h e t e r o g e n e o u s _ l i s t   =   [ " s t r i n g " ,   0 . 1 ,   T r u e ]   l i s t _ o f _ l i s t s   =   [ i n t e g e r _ l i s t ,   h e t e r o g e n e o u s _ l i s t ,   [ ] ]     l i s t _ l e n g t h   =   l e n   i n t e g e r _ l i s t                e q u a l s   3   l i s t _ s u m         =   s u m   i n t e g e r _ l i s t                e q u a l s   6 x   =   [ 0 ,   1 ,   2 ,   3 ,   4 ,   5 ,   6 ,   7 ,   8 ,   9 ]     z e r o   =   x [ 0 ]                        e q u a l s   0 ,   l i s t s   a r e   0 - i n d e x e d   o n e   =   x [ 1 ]                          e q u a l s   1    You can also use square brackets to slice lists. The slice i elements from i  inclusive  to j  not inclusive . If you leave off the start of the slice, you’ll slice from the beginning of the list, and if you leave of the end of the slice, you’ll slice until the end of the list:  j means all  You can similarly slice strings and other “sequential” types. A slice can take a third argument to indicate its stride, which can be negative:  Python has an i  n operator to check for list membership:  This check involves examining the elements of the list one at a time, which means that you probably shouldn’t use it unless you know your list is pretty small  or unless you don’t care how long the check takes . It is easy to concatenate lists together. If you want to modify a list in place, you can use e  d to add items from another collection:  n i n e   =   x [ - 1 ]                      e q u a l s   9 ,   ' P y t h o n i c '   f o r   l a s t   e l e m e n t   e i g h t   =   x [ - 2 ]                    e q u a l s   8 ,   ' P y t h o n i c '   f o r   n e x t - t o - l a s t   e l e m e n t   x [ 0 ]   =   - 1                            n o w   x   i s   [ - 1 ,   1 ,   2 ,   3 ,   . . . ,   9 ] : f i r s t _ t h r e e   =   x [ : 3 ]                                      [ - 1 ,   1 ,   2 ]   t h r e e _ t o _ e n d   =   x [ 3 : ]                                    [ 3 ,   4 ,   . . . ,   9 ]   o n e _ t o _ f o u r   =   x [ 1 : 5 ]                                    [ 1 ,   2 ,   3 ,   4 ]   l a s t _ t h r e e   =   x [ - 3 : ]                                      [ 7 ,   8 ,   9 ]   w i t h o u t _ f i r s t _ a n d _ l a s t   =   x [ 1 : - 1 ]            [ 1 ,   2 ,   . . . ,   8 ]   c o p y _ o f _ x   =   x [ : ]                                            [ - 1 ,   1 ,   2 ,   . . . ,   9 ] e v e r y _ t h i r d   =   x [ : : 3 ]                                      [ - 1 ,   3 ,   6 ,   9 ]   f i v e _ t o _ t h r e e   =   x [ 5 : 2 : - 1 ]                            [ 5 ,   4 ,   3 ] 1   i n   [ 1 ,   2 ,   3 ]            T r u e   0   i n   [ 1 ,   2 ,   3 ]            F a l s e x t e n x   =   [ 1 ,   2 ,   3 ]   x . e x t e n d   [ 4 ,   5 ,   6 ]                x   i s   n o w   [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ]  If you don’t want to modify x, you can use list addition:  More frequently we will append to lists one item at a time:  It’s often convenient to unpack lists when you know how many elements they contain:  although you will get a V elements on both sides. A common idiom is to use an underscore for a value you’re going to throw away:  r if you don’t have the same number of  Tuples Tuples are lists’ immutable cousins. Pretty much anything you can do to a list that doesn’t involve modifying it, you can do to a tuple. You specify a tuple by using parentheses  or nothing  instead of square brackets:  x   =   [ 1 ,   2 ,   3 ]   y   =   x   +   [ 4 ,   5 ,   6 ]                  y   i s   [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ] ;   x   i s   u n c h a n g e d x   =   [ 1 ,   2 ,   3 ]   x . a p p e n d   0                  x   i s   n o w   [ 1 ,   2 ,   3 ,   0 ]   y   =   x [ - 1 ]                    e q u a l s   0   z   =   l e n   x                    e q u a l s   4 x ,   y   =   [ 1 ,   2 ]            n o w   x   i s   1 ,   y   i s   2 a l u e E r r o _ ,   y   =   [ 1 ,   2 ]            n o w   y   = =   2 ,   d i d n ' t   c a r e   a b o u t   t h e   f i r s t   e l e m e n t m y _ l i s t   =   [ 1 ,   2 ]   m y _ t u p l e   =     1 ,   2     o t h e r _ t u p l e   =   3 ,   4   m y _ l i s t [ 1 ]   =   3                m y _ l i s t   i s   n o w   [ 1 ,   3 ]     t r y :           m y _ t u p l e [ 1 ]   =   3    Tuples are a convenient way to return multiple values from functions:  Tuples  and lists  can also be used for multiple assignment:  Dictionaries Another fundamental data structure is a dictionary, which associates values with keys and allows you to quickly retrieve the value corresponding to a given key:  You can look up the value for a key using square brackets:  But you’ll get a K  r if you ask for a key that’s not in the dictionary:  You can check for the existence of a key using i  n:  e x c e p t   T y p e E r r o r :           p r i n t   " c a n n o t   m o d i f y   a   t u p l e "   d e f   s u m _ a n d _ p r o d u c t   x ,   y   :           r e t u r n     x   +   y   ,     x   *   y       s p   =   s u m _ a n d _ p r o d u c t   2 ,   3                s p   i s     5 ,   6     s ,   p   =   s u m _ a n d _ p r o d u c t   5 ,   1 0          s   i s   1 5 ,   p   i s   5 0 x ,   y   =   1 ,   2              n o w   x   i s   1 ,   y   i s   2   x ,   y   =   y ,   x              P y t h o n i c   w a y   t o   s w a p   v a r i a b l e s ;   n o w   x   i s   2 ,   y   i s   1 e m p t y _ d i c t   =   { }                                              P y t h o n i c   e m p t y _ d i c t 2   =   d i c t                                        l e s s   P y t h o n i c   g r a d e s   =   { " J o e l " :   8 0 ,   " T i m " :   9 5 }            d i c t i o n a r y   l i t e r a l j o e l s _ g r a d e   =   g r a d e s [ " J o e l " ]                    e q u a l s   8 0 e y E r r o t r y :           k a t e s _ g r a d e   =   g r a d e s [ " K a t e " ]   e x c e p t   K e y E r r o r :           p r i n t   " n o   g r a d e   f o r   K a t e ! "    This membership check is fast even for large dictionaries. Dictionaries have a g raising an exception  when you look up a key that’s not in the dictionary:  t method that returns a default value  instead of  You can assign key value pairs using the same square brackets:  As you saw in Chapter 1, you can use dictionaries to represent structured data:  although we’ll soon see a better approach. Besides looking for specific keys, we can look at all of them:  j o e l _ h a s _ g r a d e   =   " J o e l "   i n   g r a d e s              T r u e   k a t e _ h a s _ g r a d e   =   " K a t e "   i n   g r a d e s              F a l s e e j o e l s _ g r a d e   =   g r a d e s . g e t   " J o e l " ,   0            e q u a l s   8 0   k a t e s _ g r a d e   =   g r a d e s . g e t   " K a t e " ,   0            e q u a l s   0   n o _ o n e s _ g r a d e   =   g r a d e s . g e t   " N o   O n e "          d e f a u l t   i s   N o n e g r a d e s [ " T i m " ]   =   9 9                                            r e p l a c e s   t h e   o l d   v a l u e   g r a d e s [ " K a t e " ]   =   1 0 0                                        a d d s   a   t h i r d   e n t r y   n u m _ s t u d e n t s   =   l e n   g r a d e s                              e q u a l s   3 t w e e t   =   {           " u s e r "   :   " j o e l g r u s " ,           " t e x t "   :   " D a t a   S c i e n c e   i s   A w e s o m e " ,           " r e t w e e t _ c o u n t "   :   1 0 0 ,           " h a s h t a g s "   :   [ "  d a t a " ,   "  s c i e n c e " ,   "  d a t a s c i e n c e " ,   "  a w e s o m e " ,   "  y o l o " ]   } t w e e t _ k e y s       =   t w e e t . k e y s                  i t e r a b l e   f o r   t h e   k e y s   t w e e t _ v a l u e s   =   t w e e t . v a l u e s              i t e r a b l e   f o r   t h e   v a l u e s   t w e e t _ i t e m s     =   t w e e t . i t e m s                i t e r a b l e   f o r   t h e     k e y ,   v a l u e     t u p l e s     " u s e r "   i n   t w e e t _ k e y s                            T r u e ,   b u t   n o t   P y t h o n i c   " u s e r "   i n   t w e e t                                      P y t h o n i c   w a y   o f   c h e c k i n g   f o r   k e y s   " j o e l g r u s "   i n   t w e e t _ v a l u e s                T r u e     s l o w   b u t   t h e   o n l y   w a y   t o   c h e c k    Dictionary keys must be “hashable”; in particular, you cannot use lists as keys. If you need a multipart key, you should probably use a tuple or figure out a way to turn the key into a string.  defaultdict Imagine that you’re trying to count the words in a document. An obvious approach is to create a dictionary in which the keys are words and the values are counts. As you check each word, you can increment its count if it’s already in the dictionary and add it to the dictionary if it’s not:  You could also use the “forgiveness is better than permission” approach and just handle the exception from trying to look up a missing key:  A third approach is to use g  t, which behaves gracefully for missing keys:  Every one of these is slightly unwieldy, which is why d useful. A d to look up a key it doesn’t contain, it first adds a value for it using a zero-  t is like a regular dictionary, except that when you try  t is  w o r d _ c o u n t s   =   { }   f o r   w o r d   i n   d o c u m e n t :           i f   w o r d   i n   w o r d _ c o u n t s :                   w o r d _ c o u n t s [ w o r d ]   + =   1           e l s e :                   w o r d _ c o u n t s [ w o r d ]   =   1 w o r d _ c o u n t s   =   { }   f o r   w o r d   i n   d o c u m e n t :           t r y :                   w o r d _ c o u n t s [ w o r d ]   + =   1           e x c e p t   K e y E r r o r :                   w o r d _ c o u n t s [ w o r d ]   =   1 e w o r d _ c o u n t s   =   { }   f o r   w o r d   i n   d o c u m e n t :           p r e v i o u s _ c o u n t   =   w o r d _ c o u n t s . g e t   w o r d ,   0             w o r d _ c o u n t s [ w o r d ]   =   p r e v i o u s _ c o u n t   +   1 e f a u l t d i c e f a u l t d i c  argument function you provided when you created it. In order to use  ts, you have to import them from c  s:  They can also be useful with l  t or d  t, or even your own functions:  These will be useful when we’re using dictionaries to “collect” results by some key and don’t want to have to check every time to see if the key exists yet.  Counters A C mapping keys to counts:  r turns a sequence of values into a d   -like object  This gives us a very simple way to solve our w  s problem:  A C  r instance has a m  n method that is frequently useful:  d e f a u l t d i c o l l e c t i o n f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     w o r d _ c o u n t s   =   d e f a u l t d i c t   i n t                          i n t       p r o d u c e s   0   f o r   w o r d   i n   d o c u m e n t :           w o r d _ c o u n t s [ w o r d ]   + =   1 i s i c d d _ l i s t   =   d e f a u l t d i c t   l i s t                                l i s t       p r o d u c e s   a n   e m p t y   l i s t   d d _ l i s t [ 2 ] . a p p e n d   1                                              n o w   d d _ l i s t   c o n t a i n s   { 2 :   [ 1 ] }     d d _ d i c t   =   d e f a u l t d i c t   d i c t                                d i c t       p r o d u c e s   a n   e m p t y   d i c t   d d _ d i c t [ " J o e l " ] [ " C i t y " ]   =   " S e a t t l e "              { " J o e l "   :   { " C i t y " :   S e a t t l e " } }     d d _ p a i r   =   d e f a u l t d i c t   l a m b d a :   [ 0 ,   0 ]     d d _ p a i r [ 2 ] [ 1 ]   =   1                                                  n o w   d d _ p a i r   c o n t a i n s   { 2 :   [ 0 ,   1 ] } o u n t e e f a u l t d i c t   i n t f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r   c   =   C o u n t e r   [ 0 ,   1 ,   2 ,   0 ]                          c   i s     b a s i c a l l y     { 0 :   2 ,   1 :   1 ,   2 :   1 } o r d _ c o u n t    r e c a l l ,   d o c u m e n t   i s   a   l i s t   o f   w o r d s   w o r d _ c o u n t s   =   C o u n t e r   d o c u m e n t   o u n t e o s t _ c o m m o  Sets Another useful data structure is set, which represents a collection of distinct elements. You can define a set by listing its elements between curly braces:  However, that doesn’t work for empty s t.” In that case you’ll need to use s  ts, as {   itself:  } already means “empty  We’ll use sets for two main reasons. The first is that i operation on sets. If we have a large collection of items that we want to use for a membership test, a set is more appropriate than a list:  n is a very fast  The second reason is to find the distinct items in a collection:     p r i n t   t h e   1 0   m o s t   c o m m o n   w o r d s   a n d   t h e i r   c o u n t s   f o r   w o r d ,   c o u n t   i n   w o r d _ c o u n t s . m o s t _ c o m m o n   1 0   :           p r i n t   w o r d ,   c o u n t   p r i m e s _ b e l o w _ 1 0   =   { 2 ,   3 ,   5 ,   7 } e d i c e t   s   =   s e t       s . a d d   1                    s   i s   n o w   { 1 }   s . a d d   2                    s   i s   n o w   { 1 ,   2 }   s . a d d   2                    s   i s   s t i l l   { 1 ,   2 }   x   =   l e n   s                e q u a l s   2   y   =   2   i n   s              e q u a l s   T r u e   z   =   3   i n   s              e q u a l s   F a l s e s t o p w o r d s _ l i s t   =   [ " a " ,   " a n " ,   " a t " ]   +   h u n d r e d s _ o f _ o t h e r _ w o r d s   +   [ " y e t " ,   " y o u " ]     " z i p "   i n   s t o p w o r d s _ l i s t              F a l s e ,   b u t   h a v e   t o   c h e c k   e v e r y   e l e m e n t     s t o p w o r d s _ s e t   =   s e t   s t o p w o r d s _ l i s t     " z i p "   i n   s t o p w o r d s _ s e t                v e r y   f a s t   t o   c h e c k i t e m _ l i s t   =   [ 1 ,   2 ,   3 ,   1 ,   2 ,   3 ]   n u m _ i t e m s   =   l e n   i t e m _ l i s t                                      6   i t e m _ s e t   =   s e t   i t e m _ l i s t                                        { 1 ,   2 ,   3 }   n u m _ d i s t i n c t _ i t e m s   =   l e n   i t e m _ s e t                      3   d i s t i n c t _ i t e m _ l i s t   =   l i s t   i t e m _ s e t                    [ 1 ,   2 ,   3 ]  We’ll use sets less frequently than dictionaries and lists.  Control Flow As in most programming languages, you can perform an action conditionally using i  f:  You can also write a ternary if-then-else on one line, which we will do occasionally:  Python has a w  e loop:  although more often we’ll use f  r and i  n:  If you need more complex logic, you can use c  e and b  k:  i f   1   >   2 :           m e s s a g e   =   " i f   o n l y   1   w e r e   g r e a t e r   t h a n   t w o . . . "   e l i f   1   >   3 :           m e s s a g e   =   " e l i f   s t a n d s   f o r   ' e l s e   i f ' "   e l s e :           m e s s a g e   =   " w h e n   a l l   e l s e   f a i l s   u s e   e l s e     i f   y o u   w a n t   t o   " p a r i t y   =   " e v e n "   i f   x   %   2   = =   0   e l s e   " o d d " h i l x   =   0   w h i l e   x   <   1 0 :           p r i n t   f " { x }   i s   l e s s   t h a n   1 0 "             x   + =   1 o    r a n g e   1 0     i s   t h e   n u m b e r s   0 ,   1 ,   . . . ,   9   f o r   x   i n   r a n g e   1 0   :           p r i n t   f " { x }   i s   l e s s   t h a n   1 0 "   o n t i n u r e a f o r   x   i n   r a n g e   1 0   :           i f   x   = =   3 :                   c o n t i n u e        g o   i m m e d i a t e l y   t o   t h e   n e x t   i t e r a t i o n           i f   x   = =   5 :    This will print 0, 1, 2, and 4.  Truthiness Booleans in Python work as in most other languages, except that they’re capitalized:  Python uses the value N other languages’ n l:  e to indicate a nonexistent value. It is similar to  Python lets you use any value where it expects a Boolean. The following are all “falsy”:  ]  an empty l  }  an empty d  t   t                   b r e a k              q u i t   t h e   l o o p   e n t i r e l y           p r i n t   x   o n e _ i s _ l e s s _ t h a n _ t w o   =   1   <   2                        e q u a l s   T r u e   t r u e _ e q u a l s _ f a l s e   =   T r u e   = =   F a l s e              e q u a l s   F a l s e o n u l x   =   N o n e   a s s e r t   x   = =   N o n e ,   " t h i s   i s   t h e   n o t   t h e   P y t h o n i c   w a y   t o   c h e c k   f o r   N o n e "   a s s e r t   x   i s   N o n e ,   " t h i s   i s   t h e   P y t h o n i c   w a y   t o   c h e c k   f o r   N o n e " F a l s e N o n e [ i s { i c " " s e t     0 0 . 0  Pretty much anything else gets treated as T use i f statements to test for empty lists, empty strings, empty dictionaries, and so on. It also sometimes causes tricky bugs if you’re not expecting this behavior:  e. This allows you to easily  A shorter  but possibly more confusing  way of doing the same is:  since a value when it’s not. Similarly, if x is either a number or possibly N  d returns its second value when the first is “truthy,” and the first e:  is definitely a number, although:  is possibly more readable. Python has an a precisely when every element is truthy, and an a  l function, which takes an iterable and returns T  y function, which returns  e when at least one element is truthy:  Sorting  r u s   =   s o m e _ f u n c t i o n _ t h a t _ r e t u r n s _ a _ s t r i n g       i f   s :           f i r s t _ c h a r   =   s [ 0 ]   e l s e :           f i r s t _ c h a r   =   " " f i r s t _ c h a r   =   s   a n d   s [ 0 ] n o n s a f e _ x   =   x   o r   0 s a f e _ x   =   x   i f   x   i s   n o t   N o n e   e l s e   0 l r u e n T r u a l l   [ T r u e ,   1 ,   { 3 } ]            T r u e ,   a l l   a r e   t r u t h y   a l l   [ T r u e ,   1 ,   { } ]              F a l s e ,   { }   i s   f a l s y   a n y   [ T r u e ,   1 ,   { } ]              T r u e ,   T r u e   i s   t r u t h y   a l l   [ ]                                    T r u e ,   n o   f a l s y   e l e m e n t s   i n   t h e   l i s t   a n y   [ ]                                    F a l s e ,   n o   t r u t h y   e l e m e n t s   i n   t h e   l i s t  Every Python list has a s to mess up your list, you can use the s list:  t method that sorts it in place. If you don’t want d function, which returns a new  t  and s  By default, s naively comparing the elements to one another. If you want elements sorted from largest to smallest, you can specify a  d  sort a list from smallest to largest based on  e parameter. And instead of comparing the elements  themselves, you can compare the results of a function that you specify with  y:  List Comprehensions Frequently, you’ll want to transform a list into another list by choosing only certain elements, by transforming elements, or both. The Pythonic way to do this is with list comprehensions:  You can similarly turn lists into dictionaries or sets:  o r o r t e x   =   [ 4 ,   1 ,   2 ,   3 ]   y   =   s o r t e d   x                y   i s   [ 1 ,   2 ,   3 ,   4 ] ,   x   i s   u n c h a n g e d   x . s o r t                            n o w   x   i s   [ 1 ,   2 ,   3 ,   4 ] o r o r t e r e v e r s e = T r u k e    s o r t   t h e   l i s t   b y   a b s o l u t e   v a l u e   f r o m   l a r g e s t   t o   s m a l l e s t   x   =   s o r t e d   [ - 4 ,   1 ,   - 2 ,   3 ] ,   k e y = a b s ,   r e v e r s e = T r u e          i s   [ - 4 ,   3 ,   - 2 ,   1 ]        s o r t   t h e   w o r d s   a n d   c o u n t s   f r o m   h i g h e s t   c o u n t   t o   l o w e s t   w c   =   s o r t e d   w o r d _ c o u n t s . i t e m s     ,                           k e y = l a m b d a   w o r d _ a n d _ c o u n t :   w o r d _ a n d _ c o u n t [ 1 ] ,                           r e v e r s e = T r u e   e v e n _ n u m b e r s   =   [ x   f o r   x   i n   r a n g e   5     i f   x   %   2   = =   0 ]        [ 0 ,   2 ,   4 ]   s q u a r e s             =   [ x   *   x   f o r   x   i n   r a n g e   5   ]                            [ 0 ,   1 ,   4 ,   9 ,   1 6 ]   e v e n _ s q u a r e s   =   [ x   *   x   f o r   x   i n   e v e n _ n u m b e r s ]                    [ 0 ,   4 ,   1 6 ] s q u a r e _ d i c t   =   { x :   x   *   x   f o r   x   i n   r a n g e   5   }        { 0 :   0 ,   1 :   1 ,   2 :   4 ,   3 :   9 ,   4 :   1 6 }   s q u a r e _ s e t     =   { x   *   x   f o r   x   i n   [ 1 ,   - 1 ] }                { 1 }  If you don’t need the value from the list, it’s common to use an underscore as the variable:  A list comprehension can include multiple f  rs:  and later f  rs can use the results of earlier ones:  We will use list comprehensions a lot.  Automated Testing and assert As data scientists, we’ll be writing a lot of code. How can we be confident our code is correct? One way is with types  discussed shortly , but another way is with automated tests. There are elaborate frameworks for writing and running tests, but in this book we’ll restrict ourselves to using a your code to raise an A truthy:  r if your specified condition is not  t statements, which will cause  As you can see in the second case, you can optionally add a message to be printed if the assertion fails.  z e r o s   =   [ 0   f o r   _   i n   e v e n _ n u m b e r s ]                h a s   t h e   s a m e   l e n g t h   a s   e v e n _ n u m b e r s o p a i r s   =   [   x ,   y                       f o r   x   i n   r a n g e   1 0                       f o r   y   i n   r a n g e   1 0   ]          1 0 0   p a i r s     0 , 0       0 , 1     . . .     9 , 8   ,     9 , 9   o i n c r e a s i n g _ p a i r s   =   [   x ,   y                                                    o n l y   p a i r s   w i t h   x   <   y ,                                           f o r   x   i n   r a n g e   1 0                            r a n g e   l o ,   h i     e q u a l s                                           f o r   y   i n   r a n g e   x   +   1 ,   1 0   ]          [ l o ,   l o   +   1 ,   . . . ,   h i   -   1 ] s s e r s s e r t i o n E r r o a s s e r t   1   +   1   = =   2   a s s e r t   1   +   1   = =   2 ,   " 1   +   1   s h o u l d   e q u a l   2   b u t   d i d n ' t "  It’s not particularly interesting to assert that 1 + 1 = 2. What’s more interesting is to assert that functions you write are doing what you expect them to:  t in this way. It is a good  Throughout the book we’ll be using a practice, and I strongly encourage you to make liberal use of it in your own code.  If you look at the book’s code on GitHub, you will see that it contains many, many more a This helps me be confident that the code I’ve written for you is correct.  Another less common use is to assert things about inputs to functions:  t statements than are printed in the book.  We’ll occasionally do this, but more often we’ll use a our code is correct.  t to check that  Object-Oriented Programming Like many languages, Python allows you to define classes that encapsulate data and the functions that operate on them. We’ll use them sometimes to make our code cleaner and simpler. It’s probably simplest to explain them by constructing a heavily annotated example. Here we’ll construct a class representing a “counting clicker,” the sort that is used at the door to track how many people have shown up for the “advanced topics in data science” meetup.  d e f   s m a l l e s t _ i t e m   x s   :           r e t u r n   m i n   x s       a s s e r t   s m a l l e s t _ i t e m   [ 1 0 ,   2 0 ,   5 ,   4 0 ]     = =   5   a s s e r t   s m a l l e s t _ i t e m   [ 1 ,   0 ,   - 1 ,   2 ]     = =   - 1 s s e r s s e r d e f   s m a l l e s t _ i t e m   x s   :           a s s e r t   x s ,   " e m p t y   l i s t   h a s   n o   s m a l l e s t   i t e m "           r e t u r n   m i n   x s   s s e r  It maintains a c  t, can be c  t, and can be r  ked to increment the count, allows you to t back to zero.  In real life one of these rolls  over from 9999 to 0000, but we won’t bother with that.  To define a class, you use the c  s keyword and a PascalCase name:  f, that refers to the particular class instance.  A class contains zero or more member functions. By convention, each takes a first parameter, s Normally, a class has a constructor, named _ parameters you need to construct an instance of your class and does whatever setup you need:  _. It takes whatever  Although the constructor has a funny name, we construct instances of the clicker using just the class name:  _ method name starts and ends with double Notice that the _ underscores. These “magic” methods are sometimes called “dunder” methods  double-UNDERscore, get it?  and represent “special” behaviors.  NOTE  Class methods whose names start with an underscore are—by convention—considered “private,” and users of the class are not supposed to directly call them. However, Python will not stop users from calling them.  o u n l i c r e a d _ c o u n e s e l a s c l a s s   C o u n t i n g C l i c k e r :           " " " A   c l a s s   c a n   s h o u l d   h a v e   a   d o c s t r i n g ,   j u s t   l i k e   a   f u n c t i o n " " " e l _ i n i t _         d e f   _ _ i n i t _ _   s e l f ,   c o u n t   =   0   :                   s e l f . c o u n t   =   c o u n t c l i c k e r 1   =   C o u n t i n g C l i c k e r                              i n i t i a l i z e d   t o   0   c l i c k e r 2   =   C o u n t i n g C l i c k e r   1 0 0                      s t a r t s   w i t h   c o u n t = 1 0 0   c l i c k e r 3   =   C o u n t i n g C l i c k e r   c o u n t = 1 0 0          m o r e   e x p l i c i t   w a y   o f   d o i n g   t h e   s a m e _ i n i t _  Another such method is _ of a class instance:  _, which produces the string representation  And finally we need to implement the public API of our class:  Having defined it, let’s use a  t to write some test cases for our clicker:  Writing tests like these help us be confident that our code is working the way it’s designed to, and that it remains doing so whenever we make changes to it. We’ll also occasionally create subclasses that inherit some of their functionality from a parent class. For example, we could create a non-reset- able clicker by using C r as the base class and overriding the  t method to do nothing:  _ r e p r _         d e f   _ _ r e p r _ _   s e l f   :                   r e t u r n   f " C o u n t i n g C l i c k e r   c o u n t = { s e l f . c o u n t }   "         d e f   c l i c k   s e l f ,   n u m _ t i m e s   =   1   :                   " " " C l i c k   t h e   c l i c k e r   s o m e   n u m b e r   o f   t i m e s . " " "                   s e l f . c o u n t   + =   n u m _ t i m e s             d e f   r e a d   s e l f   :                   r e t u r n   s e l f . c o u n t             d e f   r e s e t   s e l f   :                   s e l f . c o u n t   =   0 s s e r c l i c k e r   =   C o u n t i n g C l i c k e r       a s s e r t   c l i c k e r . r e a d       = =   0 ,   " c l i c k e r   s h o u l d   s t a r t   w i t h   c o u n t   0 "   c l i c k e r . c l i c k       c l i c k e r . c l i c k       a s s e r t   c l i c k e r . r e a d       = =   2 ,   " a f t e r   t w o   c l i c k s ,   c l i c k e r   s h o u l d   h a v e   c o u n t   2 "   c l i c k e r . r e s e t       a s s e r t   c l i c k e r . r e a d       = =   0 ,   " a f t e r   r e s e t ,   c l i c k e r   s h o u l d   b e   b a c k   t o   0 " o u n t i n g C l i c k e r e s e    A   s u b c l a s s   i n h e r i t s   a l l   t h e   b e h a v i o r   o f   i t s   p a r e n t   c l a s s .   c l a s s   N o R e s e t C l i c k e r   C o u n t i n g C l i c k e r   :              T h i s   c l a s s   h a s   a l l   t h e   s a m e   m e t h o d s   a s   C o u n t i n g C l i c k e r      Iterables and Generators One nice thing about a list is that you can retrieve specific elements by their indices. But you don’t always need this! A list of a billion numbers takes up a lot of memory. If you only want the elements one at a time, there’s no good reason to keep them all around. If you only end up needing the first several elements, generating the entire billion is hugely wasteful. Often all we need is to iterate over the collection using f r and i n. In this case we can create generators, which can be iterated over just like lists but generate their values lazily on demand. One way to create generators is with functions and the y  d operator:  The following loop will consume the y none are left:  ded values one at a time until   In fact, r With a generator, you can even create an infinite sequence:  e is itself lazy, so there’s no point in doing this.              E x c e p t   t h a t   i t   h a s   a   r e s e t   m e t h o d   t h a t   d o e s   n o t h i n g .           d e f   r e s e t   s e l f   :                   p a s s     c l i c k e r 2   =   N o R e s e t C l i c k e r       a s s e r t   c l i c k e r 2 . r e a d       = =   0   c l i c k e r 2 . c l i c k       a s s e r t   c l i c k e r 2 . r e a d       = =   1   c l i c k e r 2 . r e s e t       a s s e r t   c l i c k e r 2 . r e a d       = =   1 ,   " r e s e t   s h o u l d n ' t   d o   a n y t h i n g " o i e l d e f   g e n e r a t e _ r a n g e   n   :           i   =   0           w h i l e   i   <   n :                   y i e l d   i          e v e r y   c a l l   t o   y i e l d   p r o d u c e s   a   v a l u e   o f   t h e   g e n e r a t o r                   i   + =   1 i e l f o r   i   i n   g e n e r a t e _ r a n g e   1 0   :           p r i n t   f " i :   { i } "   a n g  although you probably shouldn’t iterate over it without using some kind of  k logic.  TIP  The flip side of laziness is that you can only iterate through a generator once. If you need to iterate through something multiple times, you’ll need to either re-create the generator each time or use a list. If generating the values is expensive, that might be a good reason to use a list instead.  A second way to create generators is by using f in parentheses:  r comprehensions wrapped  Such a “generator comprehension” doesn’t do any work until you iterate over it  using f r or n processing pipelines:  t . We can use this to build up elaborate data-  Not infrequently, when we’re iterating over a list or a generator we’ll want not just the values but also their indices. For this common case Python provides an e  e function, which turns values into pairs     :  d e f   n a t u r a l _ n u m b e r s     :           " " " r e t u r n s   1 ,   2 ,   3 ,   . . . " " "           n   =   1           w h i l e   T r u e :                   y i e l d   n                   n   + =   1 b r e a o e v e n s _ b e l o w _ 2 0   =     i   f o r   i   i n   g e n e r a t e _ r a n g e   2 0     i f   i   %   2   = =   0   o e x    N o n e   o f   t h e s e   c o m p u t a t i o n s   * d o e s *   a n y t h i n g   u n t i l   w e   i t e r a t e   d a t a   =   n a t u r a l _ n u m b e r s       e v e n s   =     x   f o r   x   i n   d a t a   i f   x   %   2   = =   0     e v e n _ s q u a r e s   =     x   * *   2   f o r   x   i n   e v e n s     e v e n _ s q u a r e s _ e n d i n g _ i n _ s i x   =     x   f o r   x   i n   e v e n _ s q u a r e s   i f   x   %   1 0   = =   6        a n d   s o   o n n u m e r a t i n d e x , v a l u e  We’ll use this a lot.  Randomness As we learn data science, we will frequently need to generate random numbers, which we can do with the r  m module:  The r deterministic  numbers based on an internal state that you can set with  m module actually produces pseudorandom  that is,  d if you want to get reproducible results:  n a m e s   =   [ " A l i c e " ,   " B o b " ,   " C h a r l i e " ,   " D e b b i e " ]        n o t   P y t h o n i c   f o r   i   i n   r a n g e   l e n   n a m e s     :           p r i n t   f " n a m e   { i }   i s   { n a m e s [ i ] } "          a l s o   n o t   P y t h o n i c   i   =   0   f o r   n a m e   i n   n a m e s :           p r i n t   f " n a m e   { i }   i s   { n a m e s [ i ] } "             i   + =   1        P y t h o n i c   f o r   i ,   n a m e   i n   e n u m e r a t e   n a m e s   :           p r i n t   f " n a m e   { i }   i s   { n a m e } "   a n d o i m p o r t   r a n d o m   r a n d o m . s e e d   1 0          t h i s   e n s u r e s   w e   g e t   t h e   s a m e   r e s u l t s   e v e r y   t i m e     f o u r _ u n i f o r m _ r a n d o m s   =   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   4   ]        [ 0 . 5 7 1 4 0 2 5 9 4 6 8 9 9 1 3 5 ,                  r a n d o m . r a n d o m       p r o d u c e s   n u m b e r s        0 . 4 2 8 8 8 9 0 5 4 6 7 5 1 1 4 6 ,                  u n i f o r m l y   b e t w e e n   0   a n d   1 .        0 . 5 7 8 0 9 1 3 0 1 1 3 4 4 7 0 4 ,                  I t ' s   t h e   r a n d o m   f u n c t i o n   w e ' l l   u s e        0 . 2 0 6 0 9 8 2 3 2 1 3 9 5 0 1 7 4 ]                m o s t   o f t e n . a n d o r a n d o m . s e e r a n d o m . s e e d   1 0                        s e t   t h e   s e e d   t o   1 0   p r i n t   r a n d o m . r a n d o m              0 . 5 7 1 4 0 2 5 9 4 6 9   r a n d o m . s e e d   1 0                        r e s e t   t h e   s e e d   t o   1 0   p r i n t   r a n d o m . r a n d o m              0 . 5 7 1 4 0 2 5 9 4 6 9   a g a i n  We’ll sometimes use r arguments and returns an element chosen randomly from the corresponding  e, which takes either one or two  e:  There are a few more methods that we’ll sometimes find convenient. For example, r  e randomly reorders the elements of a list:  If you need to randomly pick one element from a list, you can use  e:  And if you need to randomly choose a sample of elements without e: replacement  i.e., with no duplicates , you can use r  To choose a sample of elements with replacement  i.e., allowing duplicates , you can just make multiple calls to r  e:  Regular Expressions Regular expressions provide a way of searching text. They are incredibly useful, but also fairly complicated—so much so that there are entire books  a n d o m . r a n d r a n g r a n g r a n d o m . r a n d r a n g e   1 0              c h o o s e   r a n d o m l y   f r o m   r a n g e   1 0     =   [ 0 ,   1 ,   . . . ,   9 ]   r a n d o m . r a n d r a n g e   3 ,   6          c h o o s e   r a n d o m l y   f r o m   r a n g e   3 ,   6     =   [ 3 ,   4 ,   5 ] a n d o m . s h u f f l u p _ t o _ t e n   =   [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ,   7 ,   8 ,   9 ,   1 0 ]   r a n d o m . s h u f f l e   u p _ t o _ t e n     p r i n t   u p _ t o _ t e n        [ 7 ,   2 ,   6 ,   8 ,   9 ,   4 ,   1 0 ,   1 ,   3 ,   5 ]         y o u r   r e s u l t s   w i l l   p r o b a b l y   b e   d i f f e r e n t   r a n d o m . c h o i c m y _ b e s t _ f r i e n d   =   r a n d o m . c h o i c e   [ " A l i c e " ,   " B o b " ,   " C h a r l i e " ]                " B o b "   f o r   m e a n d o m . s a m p l l o t t e r y _ n u m b e r s   =   r a n g e   6 0     w i n n i n g _ n u m b e r s   =   r a n d o m . s a m p l e   l o t t e r y _ n u m b e r s ,   6          [ 1 6 ,   3 6 ,   1 0 ,   6 ,   2 5 ,   9 ] a n d o m . c h o i c f o u r _ w i t h _ r e p l a c e m e n t   =   [ r a n d o m . c h o i c e   r a n g e   1 0       f o r   _   i n   r a n g e   4   ]   p r i n t   f o u r _ w i t h _ r e p l a c e m e n t          [ 9 ,   4 ,   4 ,   2 ]  written about them. We will get into their details the few times we encounter them; here are a few examples of how to use them in Python:  h checks whether the beginning One important thing to note is that r of a string matches a regular expression, while r h checks whether any part of a string matches a regular expression. At some point you will mix these two up and it will cause you grief. The official documentation goes into much more detail.  Functional Programming  NOTE  The first edition of this book introduced the Python functions p and f functions are best avoided, and their uses in the book have been replaced with list comprehensions, f  r at this point. On my journey toward enlightenment I have realized that these  r loops, and other, more Pythonic constructs.  p, r  l, m  e,  zip and Argument Unpacking Often we will need to zip two or more iterables together. The z transforms multiple iterables into a single iterable of tuples of  p function  i m p o r t   r e     r e _ e x a m p l e s   =   [                                                    A l l   o f   t h e s e   a r e   T r u e ,   b e c a u s e           n o t   r e . m a t c h   " a " ,   " c a t "   ,                                  ' c a t '   d o e s n ' t   s t a r t   w i t h   ' a '           r e . s e a r c h   " a " ,   " c a t "   ,                                        ' c a t '   h a s   a n   ' a '   i n   i t           n o t   r e . s e a r c h   " c " ,   " d o g "   ,                                ' d o g '   d o e s n ' t   h a v e   a   ' c '   i n   i t .           3   = =   l e n   r e . s p l i t   " [ a b ] " ,   " c a r b s "     ,            S p l i t   o n   a   o r   b   t o   [ ' c ' , ' r ' , ' s ' ] .           " R - D - "   = =   r e . s u b   " [ 0 - 9 ] " ,   " - " ,   " R 2 D 2 "          R e p l a c e   d i g i t s   w i t h   d a s h e s .           ]     a s s e r t   a l l   r e _ e x a m p l e s   ,   " a l l   t h e   r e g e x   e x a m p l e s   s h o u l d   b e   T r u e " e . m a t c e . s e a r c a r t i a a e d u c i l t e o i  corresponding function:  If the lists are different lengths, z You can also “unzip” a list using a strange trick:  p stops as soon as the first list ends.  The asterisk  *  performs argument unpacking, which uses the elements of  s as individual arguments to z  p. It ends up the same as if you’d  called:  You can use argument unpacking with any function:  It is rare that we’ll find this useful, but when we do it’s a neat trick.  args and kwargs Let’s say we want to create a higher-order function that takes as input some function f and returns a new function that for any input returns twice the  l i s t 1   =   [ ' a ' ,   ' b ' ,   ' c ' ]   l i s t 2   =   [ 1 ,   2 ,   3 ]        z i p   i s   l a z y ,   s o   y o u   h a v e   t o   d o   s o m e t h i n g   l i k e   t h e   f o l l o w i n g   [ p a i r   f o r   p a i r   i n   z i p   l i s t 1 ,   l i s t 2   ]            i s   [   ' a ' ,   1   ,     ' b ' ,   2   ,     ' c ' ,   3   ] i p a i r s   =   [   ' a ' ,   1   ,     ' b ' ,   2   ,     ' c ' ,   3   ]   l e t t e r s ,   n u m b e r s   =   z i p   * p a i r s   p a i r i l e t t e r s ,   n u m b e r s   =   z i p     ' a ' ,   1   ,     ' b ' ,   2   ,     ' c ' ,   3     d e f   a d d   a ,   b   :   r e t u r n   a   +   b     a d d   1 ,   2                  r e t u r n s   3   t r y :           a d d   [ 1 ,   2 ]     e x c e p t   T y p e E r r o r :           p r i n t   " a d d   e x p e c t s   t w o   i n p u t s "     a d d   * [ 1 ,   2 ]            r e t u r n s   3  value of f:  This works in some cases:  However, it doesn’t work with functions that take more than a single argument:  What we need is a way to specify a function that takes arbitrary arguments. We can do this with argument unpacking and a little bit of magic:  d e f   d o u b l e r   f   :              H e r e   w e   d e f i n e   a   n e w   f u n c t i o n   t h a t   k e e p s   a   r e f e r e n c e   t o   f           d e f   g   x   :                   r e t u r n   2   *   f   x                  A n d   r e t u r n   t h a t   n e w   f u n c t i o n           r e t u r n   g d e f   f 1   x   :           r e t u r n   x   +   1     g   =   d o u b l e r   f 1     a s s e r t   g   3     = =   8 ,     "   3   +   1     *   2   s h o u l d   e q u a l   8 "   a s s e r t   g   - 1     = =   0 ,   "   - 1   +   1     *   2   s h o u l d   e q u a l   0 " d e f   f 2   x ,   y   :           r e t u r n   x   +   y     g   =   d o u b l e r   f 2     t r y :           g   1 ,   2     e x c e p t   T y p e E r r o r :           p r i n t   " a s   d e f i n e d ,   g   o n l y   t a k e s   o n e   a r g u m e n t "   d e f   m a g i c   * a r g s ,   * * k w a r g s   :           p r i n t   " u n n a m e d   a r g s : " ,   a r g s             p r i n t   " k e y w o r d   a r g s : " ,   k w a r g s       m a g i c   1 ,   2 ,   k e y = " w o r d " ,   k e y 2 = " w o r d 2 "          p r i n t s    That is, when we define a function like this, a arguments and k way too, if you want to use a l to a function:  s is a tuple of its unnamed t of its named arguments. It works the other t to supply arguments  e  and d  s is a d  t  or t  You could do all sorts of strange tricks with this; we will only use it to produce higher-order functions whose inputs can accept arbitrary arguments:  As a general rule, your code will be more correct and more readable if you are explicit about what sorts of arguments your functions require; accordingly, we will use a option.  s only when we have no other  s and k  Type Annotations Python is a dynamically typed language. That means that it in general it doesn’t care about the types of objects we use, as long as we use them in       u n n a m e d   a r g s :     1 ,   2          k e y w o r d   a r g s :   { ' k e y ' :   ' w o r d ' ,   ' k e y 2 ' :   ' w o r d 2 ' } r g w a r g i c i s u p l i c d e f   o t h e r _ w a y _ m a g i c   x ,   y ,   z   :           r e t u r n   x   +   y   +   z     x _ y _ l i s t   =   [ 1 ,   2 ]   z _ d i c t   =   { " z " :   3 }   a s s e r t   o t h e r _ w a y _ m a g i c   * x _ y _ l i s t ,   * * z _ d i c t     = =   6 ,   " 1   +   2   +   3   s h o u l d   b e   6 " d e f   d o u b l e r _ c o r r e c t   f   :           " " " w o r k s   n o   m a t t e r   w h a t   k i n d   o f   i n p u t s   f   e x p e c t s " " "           d e f   g   * a r g s ,   * * k w a r g s   :                   " " " w h a t e v e r   a r g u m e n t s   g   i s   s u p p l i e d ,   p a s s   t h e m   t h r o u g h   t o   f " " "                   r e t u r n   2   *   f   * a r g s ,   * * k w a r g s             r e t u r n   g     g   =   d o u b l e r _ c o r r e c t   f 2     a s s e r t   g   1 ,   2     = =   6 ,   " d o u b l e r   s h o u l d   w o r k   n o w " r g w a r g  valid ways:  whereas in a statically typed language our functions and objects would have specific types:  In fact, recent versions of Python do  sort of  have this functionality. The preceding version of a However, these type annotations don’t actually do anything. You can still use the annotated a  d function to add strings, and the call to a  t type annotations is valid Python 3.6!  d with the i    will still raise the exact same T  r.  That said, there are still  at least  four good reasons to use type annotations in your Python code:  Types are an important form of documentation. This is doubly true in a book that is using code to teach you theoretical and mathematical concepts. Compare the following two function stubs:  d e f   a d d   a ,   b   :           r e t u r n   a   +   b     a s s e r t   a d d   1 0 ,   5     = =   1 5 ,                                     " +   i s   v a l i d   f o r   n u m b e r s "   a s s e r t   a d d   [ 1 ,   2 ] ,   [ 3 ]     = =   [ 1 ,   2 ,   3 ] ,           " +   i s   v a l i d   f o r   l i s t s "   a s s e r t   a d d   " h i   " ,   " t h e r e "     = =   " h i   t h e r e " ,   " +   i s   v a l i d   f o r   s t r i n g s "     t r y :           a d d   1 0 ,   " f i v e "     e x c e p t   T y p e E r r o r :           p r i n t   " c a n n o t   a d d   a n   i n t   t o   a   s t r i n g "   d e f   a d d   a :   i n t ,   b :   i n t     - >   i n t :           r e t u r n   a   +   b     a d d   1 0 ,   5                            y o u ' d   l i k e   t h i s   t o   b e   O K   a d d   " h i   " ,   " t h e r e "          y o u ' d   l i k e   t h i s   t o   b e   n o t   O K d n d d d   1 0 , " f i v e " y p e E r r o d e f   d o t _ p r o d u c t   x ,   y   :   . . .      I find the second one exceedingly more informative; hopefully you do too.  At this point I have gotten so used to type hinting that I now find untyped Python difficult to read.   There are external tools  the most popular is m y  that will read your code, inspect the type annotations, and let you know about type errors before you ever run your code. For example, if you ran  , it would warn  y over a file containing a  you:  t testing, this is a good way to find mistakes in your  Like a code before you ever run it. The narrative in the book will not involve such a type checker; however, behind the scenes I will be running one, which will help ensure that the book itself is correct. Having to think about the types in your code forces you to design cleaner functions and interfaces:  Here we have a function whose o be a s l. It is highly likely that this function is fragile and difficult to use, but it becomes far  n parameter is allowed to  g, or an i  t, or a b  t, or a f     w e   h a v e   n o t   y e t   d e f i n e d   V e c t o r ,   b u t   i m a g i n e   w e   h a d   d e f   d o t _ p r o d u c t   x :   V e c t o r ,   y :   V e c t o r     - >   f l o a t :   . . . y p m y p d d   " h i   " ,   " t h e r e " e r r o r :   A r g u m e n t   1   t o   " a d d "   h a s   i n c o m p a t i b l e   t y p e   " s t r " ;   e x p e c t e d   " i n t " s s e r f r o m   t y p i n g   i m p o r t   U n i o n     d e f   s e c r e t l y _ u g l y _ f u n c t i o n   v a l u e ,   o p e r a t i o n   :   . . .     d e f   u g l y _ f u n c t i o n   v a l u e :   i n t ,                                       o p e r a t i o n :   U n i o n [ s t r ,   i n t ,   f l o a t ,   b o o l ]     - >   i n t :           . . . p e r a t i o t r i n n l o a o o  more clear when the types are made explicit. Doing so, then, will force us to design in a less clunky way, for which our users will thank us. Using types allows your editor to help you with things like autocomplete  Figure 2-1  and to get angry at type errors.  Figure 2-1. VSCode, but likely your editor does the same  Sometimes people insist that type hints may be valuable on large projects but are not worth the time for small ones. However, since type hints take almost no additional time to type and allow your editor to save you time, I maintain that they actually allow you to write code more quickly, even for small projects. For all these reasons, all of the code in the remainder of the book will use type annotations. I expect that some readers will be put off by the use of type annotations; however, I suspect by the end of the book they will have changed their minds.  How to Write Type Annotations As we’ve seen, for built-in types like i l and f the type itself as the annotation. What if you had  say  a l  t and b  t, you just use t?  n o o l o a i s  s to be a l  This isn’t wrong, but the type is not specific enough. It’s clear we really want x The t use to do just this:  g module provides a number of parameterized types that we can  s, not  say  a l  t of strings.  t of f  Up until now we’ve only specified annotations for function parameters and return types. For variables themselves it’s usually obvious what the type is:  However, sometimes it’s not obvious:  In such cases we will supply inline type hints:  The t ever use:  g module contains many other types, only a few of which we’ll  d e f   t o t a l   x s :   l i s t     - >   f l o a t :           r e t u r n   s u m   t o t a l   i s l o a t i s y p i n f r o m   t y p i n g   i m p o r t   L i s t        n o t e   c a p i t a l   L     d e f   t o t a l   x s :   L i s t [ f l o a t ]     - >   f l o a t :           r e t u r n   s u m   t o t a l      T h i s   i s   h o w   t o   t y p e - a n n o t a t e   v a r i a b l e s   w h e n   y o u   d e f i n e   t h e m .      B u t   t h i s   i s   u n n e c e s s a r y ;   i t ' s   " o b v i o u s "   x   i s   a n   i n t .   x :   i n t   =   5 v a l u e s   =   [ ]                      w h a t ' s   m y   t y p e ?   b e s t _ s o _ f a r   =   N o n e        w h a t ' s   m y   t y p e ? f r o m   t y p i n g   i m p o r t   O p t i o n a l     v a l u e s :   L i s t [ i n t ]   =   [ ]   b e s t _ s o _ f a r :   O p t i o n a l [ f l o a t ]   =   N o n e        a l l o w e d   t o   b e   e i t h e r   a   f l o a t   o r   N o n e y p i n    t h e   t y p e   a n n o t a t i o n s   i n   t h i s   s n i p p e t   a r e   a l l   u n n e c e s s a r y   f r o m   t y p i n g   i m p o r t   D i c t ,   I t e r a b l e ,   T u p l e        k e y s   a r e   s t r i n g s ,   v a l u e s   a r e   i n t s    Finally, since Python has first-class functions, we need a type to represent those as well. Here’s a pretty contrived example:  As type annotations are just Python objects, we can assign them to variables to make them easier to refer to:  By the time you get to the end of the book, you’ll be quite familiar with reading and writing type annotations, and I hope you’ll use them in your code.  Welcome to DataSciencester!  c o u n t s :   D i c t [ s t r ,   i n t ]   =   { ' d a t a ' :   1 ,   ' s c i e n c e ' :   2 }        l i s t s   a n d   g e n e r a t o r s   a r e   b o t h   i t e r a b l e   i f   l a z y :           e v e n s :   I t e r a b l e [ i n t ]   =     x   f o r   x   i n   r a n g e   1 0     i f   x   %   2   = =   0     e l s e :           e v e n s   =   [ 0 ,   2 ,   4 ,   6 ,   8 ]        t u p l e s   s p e c i f y   a   t y p e   f o r   e a c h   e l e m e n t   t r i p l e :   T u p l e [ i n t ,   f l o a t ,   i n t ]   =     1 0 ,   2 . 3 ,   5   f r o m   t y p i n g   i m p o r t   C a l l a b l e        T h e   t y p e   h i n t   s a y s   t h a t   r e p e a t e r   i s   a   f u n c t i o n   t h a t   t a k e s      t w o   a r g u m e n t s ,   a   s t r i n g   a n d   a n   i n t ,   a n d   r e t u r n s   a   s t r i n g .   d e f   t w i c e   r e p e a t e r :   C a l l a b l e [ [ s t r ,   i n t ] ,   s t r ] ,   s :   s t r     - >   s t r :           r e t u r n   r e p e a t e r   s ,   2       d e f   c o m m a _ r e p e a t e r   s :   s t r ,   n :   i n t     - >   s t r :           n _ c o p i e s   =   [ s   f o r   _   i n   r a n g e   n   ]           r e t u r n   ' ,   ' . j o i n   n _ c o p i e s       a s s e r t   t w i c e   c o m m a _ r e p e a t e r ,   " t y p e   h i n t s "     = =   " t y p e   h i n t s ,   t y p e   h i n t s " N u m b e r   =   i n t   N u m b e r s   =   L i s t [ N u m b e r ]     d e f   t o t a l   x s :   N u m b e r s     - >   N u m b e r :           r e t u r n   s u m   x s    This concludes new employee orientation. Oh, and also: try not to embezzle anything.  For Further Exploration  There is no shortage of Python tutorials in the world. The official one is not a bad place to start. The official IPython tutorial will help you get started with IPython, if you decide to use it. Please use it.  y documentation will tell you more than you ever wanted  The m to know about Python type annotations and type checking.  y p  Chapter 3. Visualizing Data  I believe that visualization is one of the most powerful means of achieving personal goals.  —Harvey Mackay  A fundamental part of the data scientist’s toolkit is data visualization. Although it is very easy to create visualizations, it’s much harder to produce good ones. There are two primary uses for data visualization:  To explore data To communicate data  In this chapter, we will concentrate on building the skills that you’ll need to start exploring your own data and to produce the visualizations we’ll be using throughout the rest of the book. Like most of our chapter topics, data visualization is a rich field of study that deserves its own book. Nonetheless, I’ll try to give you a sense of what makes for a good visualization and what doesn’t.  matplotlib A wide variety of tools exist for visualizing data. We will be using the matplotlib library, which is widely used  although sort of showing its age . If you are interested in producing elaborate interactive visualizations for the web, it is likely not the right choice, but for simple bar charts, line charts, and scatterplots, it works pretty well. As mentioned earlier, matplotlib is not part of the core Python library. With your virtual environment activated  to set one up, go back to “Virtual Environments” and follow the instructions , install it using this command:   We will be using the m  t module. In its simplest use,  t maintains an internal state in which you build up a visualization  step by step. Once you’re done, you can save it with s with s For example, making simple plots  like Figure 3-1  is pretty simple:  w.  g or display it  p y t h o n   - m   p i p   i n s t a l l   m a t p l o t l i b a t p l o t l i b . p y p l o p y p l o a v e f i h o f r o m   m a t p l o t l i b   i m p o r t   p y p l o t   a s   p l t     y e a r s   =   [ 1 9 5 0 ,   1 9 6 0 ,   1 9 7 0 ,   1 9 8 0 ,   1 9 9 0 ,   2 0 0 0 ,   2 0 1 0 ]   g d p   =   [ 3 0 0 . 2 ,   5 4 3 . 3 ,   1 0 7 5 . 9 ,   2 8 6 2 . 5 ,   5 9 7 9 . 6 ,   1 0 2 8 9 . 7 ,   1 4 9 5 8 . 3 ]        c r e a t e   a   l i n e   c h a r t ,   y e a r s   o n   x - a x i s ,   g d p   o n   y - a x i s   p l t . p l o t   y e a r s ,   g d p ,   c o l o r = ' g r e e n ' ,   m a r k e r = ' o ' ,   l i n e s t y l e = ' s o l i d '          a d d   a   t i t l e   p l t . t i t l e   " N o m i n a l   G D P "          a d d   a   l a b e l   t o   t h e   y - a x i s   p l t . y l a b e l   " B i l l i o n s   o f   $ "     p l t . s h o w      Figure 3-1. A simple line chart  Making plots that look publication-quality good is more complicated and beyond the scope of this chapter. There are many ways you can customize your charts with, for example, axis labels, line styles, and point markers. Rather than attempt a comprehensive treatment of these options, we’ll just use  and call attention to  some of them in our examples.  NOTE  Although we won’t be using much of this functionality, matplotlib is capable of producing complicated plots within plots, sophisticated formatting, and interactive visualizations. Check out its documentation if you want to go deeper than we do in this book.  Bar Charts   A bar chart is a good choice when you want to show how some quantity varies among some discrete set of items. For instance, Figure 3-2 shows how many Academy Awards were won by each of a variety of movies:  Figure 3-2. A simple bar chart  m o v i e s   =   [ " A n n i e   H a l l " ,   " B e n - H u r " ,   " C a s a b l a n c a " ,   " G a n d h i " ,   " W e s t   S i d e   S t o r y " ]   n u m _ o s c a r s   =   [ 5 ,   1 1 ,   3 ,   8 ,   1 0 ]        p l o t   b a r s   w i t h   l e f t   x - c o o r d i n a t e s   [ 0 ,   1 ,   2 ,   3 ,   4 ] ,   h e i g h t s   [ n u m _ o s c a r s ]   p l t . b a r   r a n g e   l e n   m o v i e s     ,   n u m _ o s c a r s       p l t . t i t l e   " M y   F a v o r i t e   M o v i e s "                a d d   a   t i t l e   p l t . y l a b e l   "    o f   A c a d e m y   A w a r d s "            l a b e l   t h e   y - a x i s        l a b e l   x - a x i s   w i t h   m o v i e   n a m e s   a t   b a r   c e n t e r s   p l t . x t i c k s   r a n g e   l e n   m o v i e s     ,   m o v i e s       p l t . s h o w      A bar chart can also be a good choice for plotting histograms of bucketed numeric values, as in Figure 3-3, in order to visually explore how the values are distributed:  f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r   g r a d e s   =   [ 8 3 ,   9 5 ,   9 1 ,   8 7 ,   7 0 ,   0 ,   8 5 ,   8 2 ,   1 0 0 ,   6 7 ,   7 3 ,   7 7 ,   0 ]        B u c k e t   g r a d e s   b y   d e c i l e ,   b u t   p u t   1 0 0   i n   w i t h   t h e   9 0 s   h i s t o g r a m   =   C o u n t e r   m i n   g r a d e         1 0   *   1 0 ,   9 0     f o r   g r a d e   i n   g r a d e s       p l t . b a r   [ x   +   5   f o r   x   i n   h i s t o g r a m . k e y s     ] ,        S h i f t   b a r s   r i g h t   b y   5                   h i s t o g r a m . v a l u e s     ,                                      G i v e   e a c h   b a r   i t s   c o r r e c t   h e i g h t                   1 0 ,                                                                      G i v e   e a c h   b a r   a   w i d t h   o f   1 0                   e d g e c o l o r =   0 ,   0 ,   0                                        B l a c k   e d g e s   f o r   e a c h   b a r     p l t . a x i s   [ - 5 ,   1 0 5 ,   0 ,   5 ]                                          x - a x i s   f r o m   - 5   t o   1 0 5 ,                                                                                            y - a x i s   f r o m   0   t o   5     p l t . x t i c k s   [ 1 0   *   i   f o r   i   i n   r a n g e   1 1   ]              x - a x i s   l a b e l s   a t   0 ,   1 0 ,   . . . ,   1 0 0   p l t . x l a b e l   " D e c i l e "     p l t . y l a b e l   "    o f   S t u d e n t s "     p l t . t i t l e   " D i s t r i b u t i o n   o f   E x a m   1   G r a d e s "     p l t . s h o w      Figure 3-3. Using a bar chart for a histogram  r specifies the bar width. Here we chose a  The third argument to p width of 10, to fill the entire decile. We also shifted the bars right by 5, so that, for example, the “10” bar  which corresponds to the decile 10–20  would have its center at 15 and hence occupy the correct range. We also added a black edge to each bar to make them visually distinct. The call to p 105  just to leave a little space on the left and right , and that the y-axis should range from 0 to 5. And the call to p 0, 10, 20, …, 100. Be judicious when using p considered especially bad form for your y-axis not to start at 0, since this is an easy way to mislead people  Figure 3-4 :  s indicates that we want the x-axis to range from –5 to  s. When creating bar charts it is  s puts x-axis labels at  l t . b a l t . a x i l t . x t i c k l t . a x i  Figure 3-4. A chart with a misleading y-axis  In Figure 3-5, we use more sensible axes, and it looks far less impressive:  m e n t i o n s   =   [ 5 0 0 ,   5 0 5 ]   y e a r s   =   [ 2 0 1 7 ,   2 0 1 8 ]     p l t . b a r   y e a r s ,   m e n t i o n s ,   0 . 8     p l t . x t i c k s   y e a r s     p l t . y l a b e l   "    o f   t i m e s   I   h e a r d   s o m e o n e   s a y   ' d a t a   s c i e n c e ' "          i f   y o u   d o n ' t   d o   t h i s ,   m a t p l o t l i b   w i l l   l a b e l   t h e   x - a x i s   0 ,   1      a n d   t h e n   a d d   a   + 2 . 0 1 3 e 3   o f f   i n   t h e   c o r n e r     b a d   m a t p l o t l i b !     p l t . t i c k l a b e l _ f o r m a t   u s e O f f s e t = F a l s e          m i s l e a d i n g   y - a x i s   o n l y   s h o w s   t h e   p a r t   a b o v e   5 0 0   p l t . a x i s   [ 2 0 1 6 . 5 ,   2 0 1 8 . 5 ,   4 9 9 ,   5 0 6 ]     p l t . t i t l e   " L o o k   a t   t h e   ' H u g e '   I n c r e a s e ! "     p l t . s h o w     p l t . a x i s   [ 2 0 1 6 . 5 ,   2 0 1 8 . 5 ,   0 ,   5 5 0 ]     p l t . t i t l e   " N o t   S o   H u g e   A n y m o r e "      Figure 3-5. The same chart with a nonmisleading y-axis  Line Charts As we saw already, we can make line charts using p good choice for showing trends, as illustrated in Figure 3-6:  t. These are a  p l t . s h o w     l t . p l o v a r i a n c e           =   [ 1 ,   2 ,   4 ,   8 ,   1 6 ,   3 2 ,   6 4 ,   1 2 8 ,   2 5 6 ]   b i a s _ s q u a r e d   =   [ 2 5 6 ,   1 2 8 ,   6 4 ,   3 2 ,   1 6 ,   8 ,   4 ,   2 ,   1 ]   t o t a l _ e r r o r     =   [ x   +   y   f o r   x ,   y   i n   z i p   v a r i a n c e ,   b i a s _ s q u a r e d   ]   x s   =   [ i   f o r   i ,   _   i n   e n u m e r a t e   v a r i a n c e   ]        W e   c a n   m a k e   m u l t i p l e   c a l l s   t o   p l t . p l o t      t o   s h o w   m u l t i p l e   s e r i e s   o n   t h e   s a m e   c h a r t   p l t . p l o t   x s ,   v a r i a n c e ,           ' g - ' ,     l a b e l = ' v a r i a n c e '              g r e e n   s o l i d   l i n e   p l t . p l o t   x s ,   b i a s _ s q u a r e d ,   ' r - . ' ,   l a b e l = ' b i a s ^ 2 '                  r e d   d o t - d a s h e d   l i n e   p l t . p l o t   x s ,   t o t a l _ e r r o r ,     ' b : ' ,     l a b e l = ' t o t a l   e r r o r '        b l u e   d o t t e d   l i n e    Figure 3-6. Several line charts with a legend  Scatterplots A scatterplot is the right choice for visualizing the relationship between two paired sets of data. For example, Figure 3-7 illustrates the relationship between the number of friends your users have and the number of minutes they spend on the site every day:       B e c a u s e   w e ' v e   a s s i g n e d   l a b e l s   t o   e a c h   s e r i e s ,      w e   c a n   g e t   a   l e g e n d   f o r   f r e e     l o c = 9   m e a n s   " t o p   c e n t e r "     p l t . l e g e n d   l o c = 9     p l t . x l a b e l   " m o d e l   c o m p l e x i t y "     p l t . x t i c k s   [ ]     p l t . t i t l e   " T h e   B i a s - V a r i a n c e   T r a d e o f f "     p l t . s h o w      Figure 3-7. A scatterplot of friends and time on the site  If you’re scattering comparable variables, you might get a misleading picture if you let matplotlib choose the scale, as in Figure 3-8.  f r i e n d s   =   [   7 0 ,     6 5 ,     7 2 ,     6 3 ,     7 1 ,     6 4 ,     6 0 ,     6 4 ,     6 7 ]   m i n u t e s   =   [ 1 7 5 ,   1 7 0 ,   2 0 5 ,   1 2 0 ,   2 2 0 ,   1 3 0 ,   1 0 5 ,   1 4 5 ,   1 9 0 ]   l a b e l s   =     [ ' a ' ,   ' b ' ,   ' c ' ,   ' d ' ,   ' e ' ,   ' f ' ,   ' g ' ,   ' h ' ,   ' i ' ]     p l t . s c a t t e r   f r i e n d s ,   m i n u t e s          l a b e l   e a c h   p o i n t   f o r   l a b e l ,   f r i e n d _ c o u n t ,   m i n u t e _ c o u n t   i n   z i p   l a b e l s ,   f r i e n d s ,   m i n u t e s   :           p l t . a n n o t a t e   l a b e l ,                   x y =   f r i e n d _ c o u n t ,   m i n u t e _ c o u n t   ,      P u t   t h e   l a b e l   w i t h   i t s   p o i n t                   x y t e x t =   5 ,   - 5   ,                                        b u t   s l i g h t l y   o f f s e t                   t e x t c o o r d s = ' o f f s e t   p o i n t s '       p l t . t i t l e   " D a i l y   M i n u t e s   v s .   N u m b e r   o f   F r i e n d s "     p l t . x l a b e l   "    o f   f r i e n d s "     p l t . y l a b e l   " d a i l y   m i n u t e s   s p e n t   o n   t h e   s i t e "     p l t . s h o w      Figure 3-8. A scatterplot with uncomparable axes  If we include a call to p accurately shows that most of the variation occurs on test 2. That’s enough to get you started doing visualization. We’ll learn much more about visualization throughout the book.   , the plot  Figure 3-9  more  t e s t _ 1 _ g r a d e s   =   [   9 9 ,   9 0 ,   8 5 ,   9 7 ,   8 0 ]   t e s t _ 2 _ g r a d e s   =   [ 1 0 0 ,   8 5 ,   6 0 ,   9 0 ,   7 0 ]     p l t . s c a t t e r   t e s t _ 1 _ g r a d e s ,   t e s t _ 2 _ g r a d e s     p l t . t i t l e   " A x e s   A r e n ' t   C o m p a r a b l e "     p l t . x l a b e l   " t e s t   1   g r a d e "     p l t . y l a b e l   " t e s t   2   g r a d e "     p l t . s h o w     l t . a x i s   " e q u a l "  Figure 3-9. The same scatterplot with equal axes  For Further Exploration  The matplotlib Gallery will give you a good idea of the sorts of things you can do with matplotlib  and how to do them . seaborn is built on top of matplotlib and allows you to easily produce prettier  and more complex  visualizations. Altair is a newer Python library for creating declarative visualizations. D3.js is a JavaScript library for producing sophisticated interactive visualizations for the web. Although it is not in Python, it is widely used, and it is well worth your while to be familiar with it. Bokeh is a library that brings D3-style visualizations into Python.   Chapter 4. Linear Algebra  Is there anything more useless or less useful than algebra?  —Billy Connolly  Linear algebra is the branch of mathematics that deals with vector spaces. Although I can’t hope to teach you linear algebra in a brief chapter, it underpins a large number of data science concepts and techniques, which means I owe it to you to at least try. What we learn in this chapter we’ll use heavily throughout the rest of the book.  Vectors Abstractly, vectors are objects that can be added together to form new vectors and that can be multiplied by scalars  i.e., numbers , also to form new vectors. Concretely  for us , vectors are points in some finite-dimensional space. Although you might not think of your data as vectors, they are often a useful way to represent numeric data. For example, if you have the heights, weights, and ages of a large number of people, you can treat your data as three-dimensional vectors [  ]. If you’re teaching a class with four exams, you can treat  student grades as four-dimensional vectors [  The simplest from-scratch approach is to represent vectors as lists of numbers. A list of three numbers corresponds to a vector in three- dimensional space, and vice versa. We’ll accomplish this with a type alias that says a V  r is just a l  t of  ].  ts:  h e i g h t , w e i g h t ,   a g e e x a m 1 ,   e x a m 2 ,   e x a m 3 , e x a m 4 e c t o i s f l o a  We’ll also want to perform arithmetic on vectors. Because Python l ts aren’t vectors  and hence provide no facilities for vector arithmetic , we’ll need to build these arithmetic tools ourselves. So let’s start with that. To begin with, we’ll frequently need to add two vectors. Vectors add componentwise. This means that if two vectors v and w are the same length, their sum is just the vector whose first element is v second element is v then we’re not allowed to add them.  For example, adding the vectors [  ], and so on.  If they’re not the same length,  ] results in [  ], whose  ] and [  ] or [  ], as shown in Figure 4-1.  f r o m   t y p i n g   i m p o r t   L i s t     V e c t o r   =   L i s t [ f l o a t ]     h e i g h t _ w e i g h t _ a g e   =   [ 7 0 ,        i n c h e s ,                                             1 7 0 ,      p o u n d s ,                                             4 0   ]      y e a r s     g r a d e s   =   [ 9 5 ,          e x a m 1                       8 0 ,          e x a m 2                       7 5 ,          e x a m 3                       6 2   ]        e x a m 4 i s [ 0 ]   +   w [ 0 [ 1 ]   +   w [ 1 1 ,   2 2 ,   1 1   +   2 ,   2 +   1 3 ,   3  Figure 4-1. Adding two vectors  We can easily implement this by z list comprehension to add the corresponding elements:  p-ing the vectors together and using a  Similarly, to subtract two vectors we just subtract the corresponding elements:  i d e f   a d d   v :   V e c t o r ,   w :   V e c t o r     - >   V e c t o r :           " " " A d d s   c o r r e s p o n d i n g   e l e m e n t s " " "           a s s e r t   l e n   v     = =   l e n   w   ,   " v e c t o r s   m u s t   b e   t h e   s a m e   l e n g t h "             r e t u r n   [ v _ i   +   w _ i   f o r   v _ i ,   w _ i   i n   z i p   v ,   w   ]     a s s e r t   a d d   [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ]     = =   [ 5 ,   7 ,   9 ] d e f   s u b t r a c t   v :   V e c t o r ,   w :   V e c t o r     - >   V e c t o r :           " " " S u b t r a c t s   c o r r e s p o n d i n g   e l e m e n t s " " "           a s s e r t   l e n   v     = =   l e n   w   ,   " v e c t o r s   m u s t   b e   t h e   s a m e   l e n g t h "      We’ll also sometimes want to componentwise sum a list of vectors—that is, create a new vector whose first element is the sum of all the first elements, whose second element is the sum of all the second elements, and so on:  We’ll also need to be able to multiply a vector by a scalar, which we do simply by multiplying each element of the vector by that number:  This allows us to compute the componentwise means of a list of  same- sized  vectors:          r e t u r n   [ v _ i   -   w _ i   f o r   v _ i ,   w _ i   i n   z i p   v ,   w   ]     a s s e r t   s u b t r a c t   [ 5 ,   7 ,   9 ] ,   [ 4 ,   5 ,   6 ]     = =   [ 1 ,   2 ,   3 ] d e f   v e c t o r _ s u m   v e c t o r s :   L i s t [ V e c t o r ]     - >   V e c t o r :           " " " S u m s   a l l   c o r r e s p o n d i n g   e l e m e n t s " " "              C h e c k   t h a t   v e c t o r s   i s   n o t   e m p t y           a s s e r t   v e c t o r s ,   " n o   v e c t o r s   p r o v i d e d ! "                C h e c k   t h e   v e c t o r s   a r e   a l l   t h e   s a m e   s i z e           n u m _ e l e m e n t s   =   l e n   v e c t o r s [ 0 ]             a s s e r t   a l l   l e n   v     = =   n u m _ e l e m e n t s   f o r   v   i n   v e c t o r s   ,   " d i f f e r e n t   s i z e s ! "                t h e   i - t h   e l e m e n t   o f   t h e   r e s u l t   i s   t h e   s u m   o f   e v e r y   v e c t o r [ i ]           r e t u r n   [ s u m   v e c t o r [ i ]   f o r   v e c t o r   i n   v e c t o r s                             f o r   i   i n   r a n g e   n u m _ e l e m e n t s   ]     a s s e r t   v e c t o r _ s u m   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ,   [ 5 ,   6 ] ,   [ 7 ,   8 ] ]     = =   [ 1 6 ,   2 0 ] d e f   s c a l a r _ m u l t i p l y   c :   f l o a t ,   v :   V e c t o r     - >   V e c t o r :           " " " M u l t i p l i e s   e v e r y   e l e m e n t   b y   c " " "           r e t u r n   [ c   *   v _ i   f o r   v _ i   i n   v ]     a s s e r t   s c a l a r _ m u l t i p l y   2 ,   [ 1 ,   2 ,   3 ]     = =   [ 2 ,   4 ,   6 ] d e f   v e c t o r _ m e a n   v e c t o r s :   L i s t [ V e c t o r ]     - >   V e c t o r :           " " " C o m p u t e s   t h e   e l e m e n t - w i s e   a v e r a g e " " "           n   =   l e n   v e c t o r s             r e t u r n   s c a l a r _ m u l t i p l y   1   n ,   v e c t o r _ s u m   v e c t o r s         a s s e r t   v e c t o r _ m e a n   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ,   [ 5 ,   6 ] ]     = =   [ 3 ,   4 ]  A less obvious tool is the dot product. The dot product of two vectors is the sum of their componentwise products:  If w has magnitude 1, the dot product measures how far the vector v extends in the w direction. For example, if w   is just the first component of v. Another way of saying this is that it’s the length of the vector you’d get if you projected v onto w  Figure 4-2 .  ], then d  Figure 4-2. The dot product as vector projection  d e f   d o t   v :   V e c t o r ,   w :   V e c t o r     - >   f l o a t :           " " " C o m p u t e s   v _ 1   *   w _ 1   +   . . .   +   v _ n   *   w _ n " " "           a s s e r t   l e n   v     = =   l e n   w   ,   " v e c t o r s   m u s t   b e   s a m e   l e n g t h "             r e t u r n   s u m   v _ i   *   w _ i   f o r   v _ i ,   w _ i   i n   z i p   v ,   w         a s s e r t   d o t   [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ]     = =   3 2        1   *   4   +   2   *   5   +   3   *   6   =   [ 1 ,   0 o t   v ,   w  Using this, it’s easy to compute a vector’s sum of squares:  which we can use to compute its magnitude  or length :  We now have all the pieces we need to compute the distance between two vectors, defined as:  In code:  This is possibly clearer if we write it as  the equivalent :  That should be plenty to get us started. We’ll be using these functions heavily throughout the book.  d e f   s u m _ o f _ s q u a r e s   v :   V e c t o r     - >   f l o a t :           " " " R e t u r n s   v _ 1   *   v _ 1   +   . . .   +   v _ n   *   v _ n " " "           r e t u r n   d o t   v ,   v       a s s e r t   s u m _ o f _ s q u a r e s   [ 1 ,   2 ,   3 ]     = =   1 4        1   *   1   +   2   *   2   +   3   *   3 i m p o r t   m a t h     d e f   m a g n i t u d e   v :   V e c t o r     - >   f l o a t :           " " " R e t u r n s   t h e   m a g n i t u d e     o r   l e n g t h     o f   v " " "           r e t u r n   m a t h . s q r t   s u m _ o f _ s q u a r e s   v              m a t h . s q r t   i s   s q u a r e   r o o t   f u n c t i o n     a s s e r t   m a g n i t u d e   [ 3 ,   4 ]     = =   5 √   v 1 − w 1   2 + . . . +   v n − w n   2 d e f   s q u a r e d _ d i s t a n c e   v :   V e c t o r ,   w :   V e c t o r     - >   f l o a t :           " " " C o m p u t e s     v _ 1   -   w _ 1     * *   2   +   . . .   +     v _ n   -   w _ n     * *   2 " " "           r e t u r n   s u m _ o f _ s q u a r e s   s u b t r a c t   v ,   w         d e f   d i s t a n c e   v :   V e c t o r ,   w :   V e c t o r     - >   f l o a t :           " " " C o m p u t e s   t h e   d i s t a n c e   b e t w e e n   v   a n d   w " " "           r e t u r n   m a t h . s q r t   s q u a r e d _ d i s t a n c e   v ,   w     d e f   d i s t a n c e   v :   V e c t o r ,   w :   V e c t o r     - >   f l o a t :           r e t u r n   m a g n i t u d e   s u b t r a c t   v ,   w      NOTE  Using lists as vectors is great for exposition but terrible for performance. In production code, you would want to use the NumPy library, which includes a high- performance array class with all sorts of arithmetic operations included.  Matrices A matrix is a two-dimensional collection of numbers. We will represent matrices as lists of lists, with each inner list having the same size and representing a row of the matrix. If A is a matrix, then A ] is the element in the ith row and the jth column. Per mathematical convention, we will frequently use capital letters to represent matrices. For example:  NOTE  In mathematics, you would usually name the first row of the matrix “row 1” and the first column “column 1.” Because we’re representing matrices with Python l ts, which are zero-indexed, we’ll call the first row of a matrix “row 0” and the first column “column 0.”  Given this list-of-lists representation, the matrix A has l    rows and    columns, which we consider its s  e:  [ i ] [ j    A n o t h e r   t y p e   a l i a s   M a t r i x   =   L i s t [ L i s t [ f l o a t ] ]     A   =   [ [ 1 ,   2 ,   3 ] ,        A   h a s   2   r o w s   a n d   3   c o l u m n s             [ 4 ,   5 ,   6 ] ]     B   =   [ [ 1 ,   2 ] ,              B   h a s   3   r o w s   a n d   2   c o l u m n s             [ 3 ,   4 ] ,             [ 5 ,   6 ] ] i s e n   A l e n   A [ 0 ] h a p f r o m   t y p i n g   i m p o r t   T u p l e      If a matrix has n rows and k columns, we will refer to it as an n × k matrix. We can  and sometimes will  think of each row of an n × k matrix as a vector of length k, and each column as a vector of length n:  We’ll also want to be able to create a matrix given its shape and a function for generating its elements. We can do this using a nested list comprehension:  Given this function, you could make a 5 × 5 identity matrix  with 1s on the diagonal and 0s elsewhere  like so:  d e f   s h a p e   A :   M a t r i x     - >   T u p l e [ i n t ,   i n t ] :           " " " R e t u r n s        o f   r o w s   o f   A ,      o f   c o l u m n s   o f   A   " " "           n u m _ r o w s   =   l e n   A             n u m _ c o l s   =   l e n   A [ 0 ]     i f   A   e l s e   0          n u m b e r   o f   e l e m e n t s   i n   f i r s t   r o w           r e t u r n   n u m _ r o w s ,   n u m _ c o l s     a s s e r t   s h a p e   [ [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ] ]     = =     2 ,   3          2   r o w s ,   3   c o l u m n s d e f   g e t _ r o w   A :   M a t r i x ,   i :   i n t     - >   V e c t o r :           " " " R e t u r n s   t h e   i - t h   r o w   o f   A     a s   a   V e c t o r   " " "           r e t u r n   A [ i ]                              A [ i ]   i s   a l r e a d y   t h e   i t h   r o w     d e f   g e t _ c o l u m n   A :   M a t r i x ,   j :   i n t     - >   V e c t o r :           " " " R e t u r n s   t h e   j - t h   c o l u m n   o f   A     a s   a   V e c t o r   " " "           r e t u r n   [ A _ i [ j ]                        j t h   e l e m e n t   o f   r o w   A _ i                           f o r   A _ i   i n   A ]          f o r   e a c h   r o w   A _ i f r o m   t y p i n g   i m p o r t   C a l l a b l e     d e f   m a k e _ m a t r i x   n u m _ r o w s :   i n t ,                                   n u m _ c o l s :   i n t ,                                   e n t r y _ f n :   C a l l a b l e [ [ i n t ,   i n t ] ,   f l o a t ]     - >   M a t r i x :           " " "           R e t u r n s   a   n u m _ r o w s   x   n u m _ c o l s   m a t r i x           w h o s e     i , j   - t h   e n t r y   i s   e n t r y _ f n   i ,   j             " " "           r e t u r n   [ [ e n t r y _ f n   i ,   j                                g i v e n   i ,   c r e a t e   a   l i s t                             f o r   j   i n   r a n g e   n u m _ c o l s   ]            [ e n t r y _ f n   i ,   0   ,   . . .   ]                           f o r   i   i n   r a n g e   n u m _ r o w s   ]          c r e a t e   o n e   l i s t   f o r   e a c h   i  Matrices will be important to us for several reasons. First, we can use a matrix to represent a dataset consisting of multiple vectors, simply by considering each vector as a row of the matrix. For example, if you had the heights, weights, and ages of 1,000 people, you could put them in a 1,000 × 3 matrix:  Second, as we’ll see later, we can use an n × k matrix to represent a linear function that maps k-dimensional vectors to n-dimensional vectors. Several of our techniques and concepts will involve such functions. Third, matrices can be used to represent binary relationships. In Chapter 1, we represented the edges of a network as a collection of pairs    . An alternative representation would be to create a matrix A such that A is 1 if nodes i and j are connected and 0 otherwise. Recall that before we had:  We could also represent this as:  d e f   i d e n t i t y _ m a t r i x   n :   i n t     - >   M a t r i x :           " " " R e t u r n s   t h e   n   x   n   i d e n t i t y   m a t r i x " " "           r e t u r n   m a k e _ m a t r i x   n ,   n ,   l a m b d a   i ,   j :   1   i f   i   = =   j   e l s e   0       a s s e r t   i d e n t i t y _ m a t r i x   5     = =   [ [ 1 ,   0 ,   0 ,   0 ,   0 ] ,                                                               [ 0 ,   1 ,   0 ,   0 ,   0 ] ,                                                               [ 0 ,   0 ,   1 ,   0 ,   0 ] ,                                                               [ 0 ,   0 ,   0 ,   1 ,   0 ] ,                                                               [ 0 ,   0 ,   0 ,   0 ,   1 ] ] d a t a   =   [ [ 7 0 ,   1 7 0 ,   4 0 ] ,                   [ 6 5 ,   1 2 0 ,   2 6 ] ,                   [ 7 7 ,   2 5 0 ,   1 9 ] ,                      . . . .                 ] i ,   j [ i ] [ j ] f r i e n d s h i p s   =   [   0 ,   1   ,     0 ,   2   ,     1 ,   2   ,     1 ,   3   ,     2 ,   3   ,     3 ,   4   ,                                   4 ,   5   ,     5 ,   6   ,     5 ,   7   ,     6 ,   8   ,     7 ,   8   ,     8 ,   9   ]                          u s e r   0     1     2     3     4     5     6     7     8     9       If there are very few connections, this is a much more inefficient representation, since you end up having to store a lot of zeros. However, with the matrix representation it is much quicker to check whether two nodes are connected—you just have to do a matrix lookup instead of  potentially  inspecting every edge:  Similarly, to find a node’s connections, you only need to inspect the column  or the row  corresponding to that node:  With a small graph you could just add a list of connections to each node object to speed up this process; but for a large, evolving graph that would probably be too expensive and difficult to maintain. We’ll revisit matrices throughout the book.  For Further Exploration  Linear algebra is widely used by data scientists  frequently implicitly, and not infrequently by people who don’t understand it .  f r i e n d _ m a t r i x   =   [ [ 0 ,   1 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ] ,        u s e r   0                                     [ 1 ,   0 ,   1 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ] ,        u s e r   1                                     [ 1 ,   1 ,   0 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ] ,        u s e r   2                                     [ 0 ,   1 ,   1 ,   0 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ] ,        u s e r   3                                     [ 0 ,   0 ,   0 ,   1 ,   0 ,   1 ,   0 ,   0 ,   0 ,   0 ] ,        u s e r   4                                     [ 0 ,   0 ,   0 ,   0 ,   1 ,   0 ,   1 ,   1 ,   0 ,   0 ] ,        u s e r   5                                     [ 0 ,   0 ,   0 ,   0 ,   0 ,   1 ,   0 ,   0 ,   1 ,   0 ] ,        u s e r   6                                     [ 0 ,   0 ,   0 ,   0 ,   0 ,   1 ,   0 ,   0 ,   1 ,   0 ] ,        u s e r   7                                     [ 0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   1 ,   1 ,   0 ,   1 ] ,        u s e r   8                                     [ 0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   1 ,   0 ] ]        u s e r   9 a s s e r t   f r i e n d _ m a t r i x [ 0 ] [ 2 ]   = =   1 ,   " 0   a n d   2   a r e   f r i e n d s "   a s s e r t   f r i e n d _ m a t r i x [ 0 ] [ 8 ]   = =   0 ,   " 0   a n d   8   a r e   n o t   f r i e n d s "    o n l y   n e e d   t o   l o o k   a t   o n e   r o w   f r i e n d s _ o f _ f i v e   =   [ i                                         f o r   i ,   i s _ f r i e n d   i n   e n u m e r a t e   f r i e n d _ m a t r i x [ 5 ]                                           i f   i s _ f r i e n d ]  It wouldn’t be a bad idea to read a textbook. You can find several freely available online:  Linear Algebra, by Jim Hefferon  Saint Michael’s College  Linear Algebra, by David Cherney, Tom Denton, Rohit Thomas, and Andrew Waldron  UC Davis  If you are feeling adventurous, Linear Algebra Done Wrong, by Sergei Treil  Brown University , is a more advanced introduction.  All of the machinery we built in this chapter you get for free if you use NumPy.  You get a lot more too, including much better performance.    Chapter 5. Statistics  Facts are stubborn, but statistics are more pliable.  —Mark Twain  Statistics refers to the mathematics and techniques with which we understand data. It is a rich, enormous field, more suited to a shelf  or room  in a library than a chapter in a book, and so our discussion will necessarily not be a deep one. Instead, I’ll try to teach you just enough to be dangerous, and pique your interest just enough that you’ll go off and learn more.  Describing a Single Set of Data Through a combination of word of mouth and luck, DataSciencester has grown to dozens of members, and the VP of Fundraising asks you for some sort of description of how many friends your members have that he can include in his elevator pitches. Using techniques from Chapter 1, you are easily able to produce this data. But now you are faced with the problem of how to describe it. One obvious description of any dataset is simply the data itself:  For a small enough dataset, this might even be the best description. But for a larger dataset, this is unwieldy and probably opaque.  Imagine staring at a list of 1 million numbers.  For that reason, we use statistics to distill and communicate relevant features of our data.  n u m _ f r i e n d s   =   [ 1 0 0 ,   4 9 ,   4 1 ,   4 0 ,   2 5 ,                                    . . .   a n d   l o t s   m o r e                               ]  As a first approach, you put the friend counts into a histogram using  r and p  r  Figure 5-1 :  Figure 5-1. A histogram of friend counts  C o u n t e l t . b a f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r   i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t     f r i e n d _ c o u n t s   =   C o u n t e r   n u m _ f r i e n d s     x s   =   r a n g e   1 0 1                                                        l a r g e s t   v a l u e   i s   1 0 0   y s   =   [ f r i e n d _ c o u n t s [ x ]   f o r   x   i n   x s ]              h e i g h t   i s   j u s t      o f   f r i e n d s   p l t . b a r   x s ,   y s     p l t . a x i s   [ 0 ,   1 0 1 ,   0 ,   2 5 ]     p l t . t i t l e   " H i s t o g r a m   o f   F r i e n d   C o u n t s "     p l t . x l a b e l   "    o f   f r i e n d s "     p l t . y l a b e l   "    o f   p e o p l e "     p l t . s h o w      Unfortunately, this chart is still too difficult to slip into conversations. So you start generating some statistics. Probably the simplest statistic is the number of data points:  You’re probably also interested in the largest and smallest values:  which are just special cases of wanting to know the values in specific positions:  But we’re only getting started.  Central Tendencies Usually, we’ll want some notion of where our data is centered. Most commonly we’ll use the mean  or average , which is just the sum of the data divided by its count:  If you have two data points, the mean is simply the point halfway between them. As you add more points, the mean shifts around, but it always depends on the value of every point. For example, if you have 10 data points, and you increase the value of any of them by 1, you increase the mean by 0.1.  n u m _ p o i n t s   =   l e n   n u m _ f r i e n d s                                    2 0 4 l a r g e s t _ v a l u e   =   m a x   n u m _ f r i e n d s                              1 0 0   s m a l l e s t _ v a l u e   =   m i n   n u m _ f r i e n d s                            1 s o r t e d _ v a l u e s   =   s o r t e d   n u m _ f r i e n d s     s m a l l e s t _ v a l u e   =   s o r t e d _ v a l u e s [ 0 ]                          1   s e c o n d _ s m a l l e s t _ v a l u e   =   s o r t e d _ v a l u e s [ 1 ]            1   s e c o n d _ l a r g e s t _ v a l u e   =   s o r t e d _ v a l u e s [ - 2 ]            4 9 d e f   m e a n   x s :   L i s t [ f l o a t ]     - >   f l o a t :           r e t u r n   s u m   x s         l e n   x s       m e a n   n u m _ f r i e n d s            7 . 3 3 3 3 3 3  We’ll also sometimes be interested in the median, which is the middle-most value  if the number of data points is odd  or the average of the two middle- most values  if the number of data points is even . For instance, if we have five data points in a sorted vector x, the median is  ] or x  ]. If we have six data points, we want the average of  ]  the third point  and x  ]  the fourth point .  Notice that—unlike the mean—the median doesn’t fully depend on every value in your data. For example, if you make the largest point larger  or the smallest point smaller , the middle points remain unchanged, which means so does the median. We’ll write different functions for the even and odd cases and combine them:  And now we can compute the median number of friends:  x [ 5         2 [ 2 x [ 2 [ 3    T h e   u n d e r s c o r e s   i n d i c a t e   t h a t   t h e s e   a r e   " p r i v a t e "   f u n c t i o n s ,   a s   t h e y ' r e      i n t e n d e d   t o   b e   c a l l e d   b y   o u r   m e d i a n   f u n c t i o n   b u t   n o t   b y   o t h e r   p e o p l e      u s i n g   o u r   s t a t i s t i c s   l i b r a r y .   d e f   _ m e d i a n _ o d d   x s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " I f   l e n   x s     i s   o d d ,   t h e   m e d i a n   i s   t h e   m i d d l e   e l e m e n t " " "           r e t u r n   s o r t e d   x s   [ l e n   x s           2 ]     d e f   _ m e d i a n _ e v e n   x s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " I f   l e n   x s     i s   e v e n ,   i t ' s   t h e   a v e r a g e   o f   t h e   m i d d l e   t w o   e l e m e n t s " " "           s o r t e d _ x s   =   s o r t e d   x s             h i _ m i d p o i n t   =   l e n   x s           2        e . g .   l e n g t h   4   = >   h i _ m i d p o i n t   2           r e t u r n     s o r t e d _ x s [ h i _ m i d p o i n t   -   1 ]   +   s o r t e d _ x s [ h i _ m i d p o i n t ]         2     d e f   m e d i a n   v :   L i s t [ f l o a t ]     - >   f l o a t :           " " " F i n d s   t h e   ' m i d d l e - m o s t '   v a l u e   o f   v " " "           r e t u r n   _ m e d i a n _ e v e n   v     i f   l e n   v     %   2   = =   0   e l s e   _ m e d i a n _ o d d   v       a s s e r t   m e d i a n   [ 1 ,   1 0 ,   2 ,   9 ,   5 ]     = =   5   a s s e r t   m e d i a n   [ 1 ,   9 ,   2 ,   1 0 ]     = =     2   +   9         2 p r i n t   m e d i a n   n u m _ f r i e n d s            6  Clearly, the mean is simpler to compute, and it varies smoothly as our data changes. If we have n data points and one of them increases by some small amount e, then necessarily the mean will increase by e   n.  This makes the mean amenable to all sorts of calculus tricks.  In order to find the median, however, we have to sort our data. And changing one of our data points by a small amount e might increase the median by e, by some number less than e, or not at all  depending on the rest of the data .  NOTE  There are, in fact, nonobvious tricks to efficiently compute medians without sorting the data. However, they are beyond the scope of this book, so we have to sort the data.  At the same time, the mean is very sensitive to outliers in our data. If our friendliest user had 200 friends  instead of 100 , then the mean would rise to 7.82, while the median would stay the same. If outliers are likely to be bad data  or otherwise unrepresentative of whatever phenomenon we’re trying to understand , then the mean can sometimes give us a misleading picture. For example, the story is often told that in the mid-1980s, the major at the University of North Carolina with the highest average starting salary was geography, mostly because of NBA star  and outlier  Michael Jordan. A generalization of the median is the quantile, which represents the value under which a certain percentile of the data lies  the median represents the value under which 50% of the data lies :  d e f   q u a n t i l e   x s :   L i s t [ f l o a t ] ,   p :   f l o a t     - >   f l o a t :           " " " R e t u r n s   t h e   p t h - p e r c e n t i l e   v a l u e   i n   x " " "           p _ i n d e x   =   i n t   p   *   l e n   x s               r e t u r n   s o r t e d   x s   [ p _ i n d e x ]     a s s e r t   q u a n t i l e   n u m _ f r i e n d s ,   0 . 1 0     = =   1   a s s e r t   q u a n t i l e   n u m _ f r i e n d s ,   0 . 2 5     = =   3   a s s e r t   q u a n t i l e   n u m _ f r i e n d s ,   0 . 7 5     = =   9   a s s e r t   q u a n t i l e   n u m _ f r i e n d s ,   0 . 9 0     = =   1 3  Less commonly you might want to look at the mode, or most common value s :  But most frequently we’ll just use the mean.  Dispersion Dispersion refers to measures of how spread out our data is. Typically they’re statistics for which values near zero signify not spread out at all and for which large values  whatever that means  signify very spread out. For instance, a very simple measure is the range, which is just the difference between the largest and smallest elements:  x and m  n are equal, which can only  The range is zero precisely when the m happen if the elements of x are all the same, which means the data is as undispersed as possible. Conversely, if the range is large, then the m x is much larger than the m Like the median, the range doesn’t really depend on the whole dataset. A dataset whose points are all either 0 or 100 has the same range as a dataset whose values are 0, 100, and lots of 50s. But it seems like the first dataset “should” be more spread out.  n and the data is more spread out.  d e f   m o d e   x :   L i s t [ f l o a t ]     - >   L i s t [ f l o a t ] :           " " " R e t u r n s   a   l i s t ,   s i n c e   t h e r e   m i g h t   b e   m o r e   t h a n   o n e   m o d e " " "           c o u n t s   =   C o u n t e r   x             m a x _ c o u n t   =   m a x   c o u n t s . v a l u e s                 r e t u r n   [ x _ i   f o r   x _ i ,   c o u n t   i n   c o u n t s . i t e m s                               i f   c o u n t   = =   m a x _ c o u n t ]     a s s e r t   s e t   m o d e   n u m _ f r i e n d s       = =   { 1 ,   6 }    " r a n g e "   a l r e a d y   m e a n s   s o m e t h i n g   i n   P y t h o n ,   s o   w e ' l l   u s e   a   d i f f e r e n t   n a m e   d e f   d a t a _ r a n g e   x s :   L i s t [ f l o a t ]     - >   f l o a t :           r e t u r n   m a x   x s     -   m i n   x s       a s s e r t   d a t a _ r a n g e   n u m _ f r i e n d s     = =   9 9 a i a i  A more complex measure of dispersion is the variance, which is computed as:  NOTE  This looks like it is almost the average squared deviation from the mean, except that we’re dividing by n larger population, x average   mean, which is why we divide by n  1 instead of n. In fact, when we’re dealing with a sample from a r is only an estimate of the actual mean, which means that on  i’s squared deviation from the  1 instead of n. See Wikipedia.  2 is an underestimate of x  Now, whatever units our data is in  e.g., “friends” , all of our measures of central tendency are in that same unit. The range will similarly be in that same unit. The variance, on the other hand, has units that are the square of the original units  e.g., “friends squared” . As it can be hard to make sense of these, we often look instead at the standard deviation:  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s u m _ o f _ s q u a r e s     d e f   d e _ m e a n   x s :   L i s t [ f l o a t ]     - >   L i s t [ f l o a t ] :           " " " T r a n s l a t e   x s   b y   s u b t r a c t i n g   i t s   m e a n     s o   t h e   r e s u l t   h a s   m e a n   0   " " "           x _ b a r   =   m e a n   x s             r e t u r n   [ x   -   x _ b a r   f o r   x   i n   x s ]     d e f   v a r i a n c e   x s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " A l m o s t   t h e   a v e r a g e   s q u a r e d   d e v i a t i o n   f r o m   t h e   m e a n " " "           a s s e r t   l e n   x s     > =   2 ,   " v a r i a n c e   r e q u i r e s   a t   l e a s t   t w o   e l e m e n t s "             n   =   l e n   x s             d e v i a t i o n s   =   d e _ m e a n   x s             r e t u r n   s u m _ o f _ s q u a r e s   d e v i a t i o n s           n   -   1       a s s e r t   8 1 . 5 4   <   v a r i a n c e   n u m _ f r i e n d s     <   8 1 . 5 5   -   _ b a x _ i   -   x _ b a r     * *   _   -   i m p o r t   m a t h     d e f   s t a n d a r d _ d e v i a t i o n   x s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " T h e   s t a n d a r d   d e v i a t i o n   i s   t h e   s q u a r e   r o o t   o f   t h e   v a r i a n c e " " "           r e t u r n   m a t h . s q r t   v a r i a n c e   x s        Both the range and the standard deviation have the same outlier problem that we saw earlier for the mean. Using the same example, if our friendliest user had instead 200 friends, the standard deviation would be 14.89—more than 60% higher! A more robust alternative computes the difference between the 75th percentile value and the 25th percentile value:  which is quite plainly unaffected by a small number of outliers.  Correlation DataSciencester’s VP of Growth has a theory that the amount of time people spend on the site is related to the number of friends they have on the site  she’s not a VP for nothing , and she’s asked you to verify this. After digging through traffic logs, you’ve come up with a list called  s that shows how many minutes per day each user spends on  DataSciencester, and you’ve ordered it so that its elements correspond to the elements of our previous n relationship between these two metrics. We’ll first look at covariance, the paired analogue of variance. Whereas variance measures how a single variable deviates from its mean, covariance measures how two variables vary in tandem from their means:  s list. We’d like to investigate the    a s s e r t   9 . 0 2   <   s t a n d a r d _ d e v i a t i o n   n u m _ f r i e n d s     <   9 . 0 4 d e f   i n t e r q u a r t i l e _ r a n g e   x s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " R e t u r n s   t h e   d i f f e r e n c e   b e t w e e n   t h e   7 5 % - i l e   a n d   t h e   2 5 % - i l e " " "           r e t u r n   q u a n t i l e   x s ,   0 . 7 5     -   q u a n t i l e   x s ,   0 . 2 5       a s s e r t   i n t e r q u a r t i l e _ r a n g e   n u m _ f r i e n d s     = =   6 d a i l y _ m i n u t e u m _ f r i e n d f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t     d e f   c o v a r i a n c e   x s :   L i s t [ f l o a t ] ,   y s :   L i s t [ f l o a t ]     - >   f l o a t :    t sums up the products of corresponding pairs of elements.  Recall that d When corresponding elements of x and y are either both above their means or both below their means, a positive number enters the sum. When one is above its mean and the other below, a negative number enters the sum. Accordingly, a “large” positive covariance means that x tends to be large when y is large and small when y is small. A “large” negative covariance means the opposite—that x tends to be small when y is large and vice versa. A covariance close to zero means that no such relationship exists. Nonetheless, this number can be hard to interpret, for a couple of reasons:  Its units are the product of the inputs’ units  e.g., friend-minutes- per-day , which can be hard to make sense of.  What’s a “friend- minute-per-day”?  If each user had twice as many friends  but the same number of minutes , the covariance would be twice as large. But in a sense, the variables would be just as interrelated. Said differently, it’s hard to say what counts as a “large” covariance.  For this reason, it’s more common to look at the correlation, which divides out the standard deviations of both variables:          a s s e r t   l e n   x s     = =   l e n   y s   ,   " x s   a n d   y s   m u s t   h a v e   s a m e   n u m b e r   o f   e l e m e n t s "             r e t u r n   d o t   d e _ m e a n   x s   ,   d e _ m e a n   y s             l e n   x s     -   1       a s s e r t   2 2 . 4 2   <   c o v a r i a n c e   n u m _ f r i e n d s ,   d a i l y _ m i n u t e s     <   2 2 . 4 3   a s s e r t   2 2 . 4 2       6 0   <   c o v a r i a n c e   n u m _ f r i e n d s ,   d a i l y _ h o u r s     <   2 2 . 4 3       6 0 o d e f   c o r r e l a t i o n   x s :   L i s t [ f l o a t ] ,   y s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " M e a s u r e s   h o w   m u c h   x s   a n d   y s   v a r y   i n   t a n d e m   a b o u t   t h e i r   m e a n s " " "           s t d e v _ x   =   s t a n d a r d _ d e v i a t i o n   x s             s t d e v _ y   =   s t a n d a r d _ d e v i a t i o n   y s             i f   s t d e v _ x   >   0   a n d   s t d e v _ y   >   0 :                   r e t u r n   c o v a r i a n c e   x s ,   y s         s t d e v _ x       s t d e v _ y           e l s e :                   r e t u r n   0            i f   n o   v a r i a t i o n ,   c o r r e l a t i o n   i s   z e r o      n is unitless and always lies between –1  perfect  The c anticorrelation  and 1  perfect correlation . A number like 0.25 represents a relatively weak positive correlation. However, one thing we neglected to do was examine our data. Check out Figure 5-2.  Figure 5-2. Correlation with an outlier  The person with 100 friends  who spends only 1 minute per day on the site  is a huge outlier, and correlation can be very sensitive to outliers. What happens if we ignore him?  a s s e r t   0 . 2 4   <   c o r r e l a t i o n   n u m _ f r i e n d s ,   d a i l y _ m i n u t e s     <   0 . 2 5   a s s e r t   0 . 2 4   <   c o r r e l a t i o n   n u m _ f r i e n d s ,   d a i l y _ h o u r s     <   0 . 2 5 o r r e l a t i o o u t l i e r   =   n u m _ f r i e n d s . i n d e x   1 0 0              i n d e x   o f   o u t l i e r      Without the outlier, there is a much stronger correlation  Figure 5-3 .  Figure 5-3. Correlation after removing the outlier  You investigate further and discover that the outlier was actually an internal test account that no one ever bothered to remove. So you feel justified in excluding it.  n u m _ f r i e n d s _ g o o d   =   [ x                                           f o r   i ,   x   i n   e n u m e r a t e   n u m _ f r i e n d s                                             i f   i   ! =   o u t l i e r ]     d a i l y _ m i n u t e s _ g o o d   =   [ x                                               f o r   i ,   x   i n   e n u m e r a t e   d a i l y _ m i n u t e s                                                 i f   i   ! =   o u t l i e r ]     d a i l y _ h o u r s _ g o o d   =   [ d m       6 0   f o r   d m   i n   d a i l y _ m i n u t e s _ g o o d ]     a s s e r t   0 . 5 7   <   c o r r e l a t i o n   n u m _ f r i e n d s _ g o o d ,   d a i l y _ m i n u t e s _ g o o d     <   0 . 5 8   a s s e r t   0 . 5 7   <   c o r r e l a t i o n   n u m _ f r i e n d s _ g o o d ,   d a i l y _ h o u r s _ g o o d     <   0 . 5 8  Simpson’s Paradox One not uncommon surprise when analyzing data is Simpson’s paradox, in which correlations can be misleading when confounding variables are ignored. For example, imagine that you can identify all of your members as either East Coast data scientists or West Coast data scientists. You decide to examine which coast’s data scientists are friendlier:  Coast   of members Avg.  of friends  West Coast 101  East Coast 103  8.2  6.5  It certainly looks like the West Coast data scientists are friendlier than the East Coast data scientists. Your coworkers advance all sorts of theories as to why this might be: maybe it’s the sun, or the coffee, or the organic produce, or the laid-back Pacific vibe? But when playing with the data, you discover something very strange. If you look only at people with PhDs, the East Coast data scientists have more friends on average. And if you look only at people without PhDs, the East Coast data scientists also have more friends on average!  Coast  Degree  of members Avg.  of friends  West Coast PhD  East Coast PhD  35  70  West Coast No PhD 66  East Coast No PhD 33  3.1  3.2  10.9  13.4  Once you account for the users’ degrees, the correlation goes in the opposite direction! Bucketing the data as East Coast West Coast disguised   the fact that the East Coast data scientists skew much more heavily toward PhD types. This phenomenon crops up in the real world with some regularity. The key issue is that correlation is measuring the relationship between your two variables all else being equal. If your dataclasses are assigned at random, as they might be in a well-designed experiment, “all else being equal” might not be a terrible assumption. But when there is a deeper pattern to class assignments, “all else being equal” can be an awful assumption. The only real way to avoid this is by knowing your data and by doing what you can to make sure you’ve checked for possible confounding factors. Obviously, this is not always possible. If you didn’t have data on the educational attainment of these 200 data scientists, you might simply conclude that there was something inherently more sociable about the West Coast.  Some Other Correlational Caveats A correlation of zero indicates that there is no linear relationship between the two variables. However, there may be other sorts of relationships. For example, if:  then x and y have zero correlation. But they certainly have a relationship— each element of y equals the absolute value of the corresponding element of x. What they don’t have is a relationship in which knowing how x compares to m    gives us information about how y  i compares to   . That is the sort of relationship that correlation looks for.  In addition, correlation tells you nothing about how large the relationship is. The variables:  x   =   [ - 2 ,   - 1 ,   0 ,   1 ,   2 ]   y   =   [   2 ,     1 ,   0 ,   1 ,   2 ] _ i e a n   x _ m e a n   y  are perfectly correlated, but  depending on what you’re measuring  it’s quite possible that this relationship isn’t all that interesting.  s and d  Correlation and Causation You have probably heard at some point that “correlation is not causation,” most likely from someone looking at data that posed a challenge to parts of his worldview that he was reluctant to question. Nonetheless, this is an important point—if x and y are strongly correlated, that might mean that x causes y, that y causes x, that each causes the other, that some third factor causes both, or nothing at all. Consider the relationship between n s. It’s possible that having more friends on the site causes DataSciencester users to spend more time on the site. This might be the case if each friend posts a certain amount of content each day, which means that the more friends you have, the more time it takes to stay current with their updates. However, it’s also possible that the more time users spend arguing in the DataSciencester forums, the more they encounter and befriend like-minded people. That is, spending more time on the site causes users to have more friends. A third possibility is that the users who are most passionate about data science spend more time on the site  because they find it more interesting  and more actively collect data science friends  because they don’t want to associate with anyone else . One way to feel more confident about causality is by conducting randomized trials. If you can randomly split your users into two groups with similar demographics and give one of the groups a slightly different experience, then you can often feel pretty good that the different experiences are causing the different outcomes.  x   =   [ - 2 ,   - 1 ,   0 ,   1 ,   2 ]   y   =   [ 9 9 . 9 8 ,   9 9 . 9 9 ,   1 0 0 ,   1 0 0 . 0 1 ,   1 0 0 . 0 2 ] u m _ f r i e n d a i l y _ m i n u t e  For instance, if you don’t mind being angrily accused of https:  www.nytimes.com 2014 06 30 technology facebook-tinkers-with- users-emotions-in-news-feed-experiment-stirring-outcry.html? r=0[experimenting on your users], you could randomly choose a subset of your users and show them content from only a fraction of their friends. If this subset subsequently spent less time on the site, this would give you some confidence that having more friends _causes more time to be spent on the site.  For Further Exploration  SciPy, pandas, and StatsModels all come with a wide variety of statistical functions. Statistics is important.  Or maybe statistics are important?  If you want to be a better data scientist, it would be a good idea to read a statistics textbook. Many are freely available online, including:  Introductory Statistics, by Douglas Shafer and Zhiyi Zhang  Saylor Foundation  OnlineStatBook, by David Lane  Rice University  Introductory Statistics, by OpenStax  OpenStax College    Chapter 6. Probability  The laws of probability, so true in general, so fallacious in particular.  —Edward Gibbon  It is hard to do data science without some sort of understanding of probability and its mathematics. As with our treatment of statistics in Chapter 5, we’ll wave our hands a lot and elide many of the technicalities. For our purposes you should think of probability as a way of quantifying the uncertainty associated with events chosen from some universe of events. Rather than getting technical about what these terms mean, think of rolling a die. The universe consists of all possible outcomes. And any subset of these outcomes is an event; for example, “the die rolls a 1” or “the die rolls an even number.” Notationally, we write P E  to mean “the probability of the event E.” We’ll use probability theory to build models. We’ll use probability theory to evaluate models. We’ll use probability theory all over the place. One could, were one so inclined, get really deep into the philosophy of what probability theory means.  This is best done over beers.  We won’t be doing that.  Dependence and Independence Roughly speaking, we say that two events E and F are dependent if knowing something about whether E happens gives us information about whether F happens  and vice versa . Otherwise, they are independent. For instance, if we flip a fair coin twice, knowing whether the first flip is heads gives us no information about whether the second flip is heads. These events are independent. On the other hand, knowing whether the first flip is heads certainly gives us information about whether both flips are tails.  If   the first flip is heads, then definitely it’s not the case that both flips are tails.  These two events are dependent. Mathematically, we say that two events E and F are independent if the probability that they both happen is the product of the probabilities that each one happens:  In the example, the probability of “first flip heads” is 1 2, and the probability of “both flips tails” is 1 4, but the probability of “first flip heads and both flips tails” is 0.  Conditional Probability When two events E and F are independent, then by definition we have:  If they are not necessarily independent  and if the probability of F is not zero , then we define the probability of E “conditional on F” as:  You should think of this as the probability that E happens, given that we know that F happens. We often rewrite this as:  When E and F are independent, you can check that this gives:  which is the mathematical way of expressing that knowing F occurred gives us no additional information about whether E occurred.  P   E , F   = P   E   P   F   P   E , F   = P   E   P   F   P   E  F   = P   E , F     P   F   P   E , F   = P   E  F   P   F   P   E  F   = P   E    One common tricky example involves a family with two  unknown  children. If we assume that:  Each child is equally likely to be a boy or a girl. The gender of the second child is independent of the gender of the first child.  Then the event “no girls” has probability 1 4, the event “one girl, one boy” has probability 1 2, and the event “two girls” has probability 1 4. Now we can ask what is the probability of the event “both children are girls”  B  conditional on the event “the older child is a girl”  G ? Using the definition of conditional probability:  since the event B and G  “both children are girls and the older child is a girl”  is just the event B.  Once you know that both children are girls, it’s necessarily true that the older child is a girl.  Most likely this result accords with your intuition. We could also ask about the probability of the event “both children are girls” conditional on the event “at least one of the children is a girl”  L . Surprisingly, the answer is different from before! As before, the event B and L  “both children are girls and at least one of the children is a girl”  is just the event B. This means we have:  How can this be the case? Well, if all you know is that at least one of the children is a girl, then it is twice as likely that the family has one boy and one girl than that it has both girls. We can check this by “generating” a lot of families:  P   B  G   = P   B , G     P   G   = P   B     P   G   = 1   2 P   B  L   = P   B , L     P   L   = P   B     P   L   = 1   3 i m p o r t   e n u m ,   r a n d o m      Bayes’s Theorem One of the data scientist’s best friends is Bayes’s theorem, which is a way of “reversing” conditional probabilities. Let’s say we need to know the probability of some event E conditional on some other event F occurring. But we only have information about the probability of F conditional on E occurring. Using the definition of conditional probability twice tells us that:  The event F can be split into the two mutually exclusive events “F and E” and “F and not E.” If we write ¬ E for “not E”  i.e., “E doesn’t happen” , then:     A n   E n u m   i s   a   t y p e d   s e t   o f   e n u m e r a t e d   v a l u e s .   W e   c a n   u s e   t h e m      t o   m a k e   o u r   c o d e   m o r e   d e s c r i p t i v e   a n d   r e a d a b l e .   c l a s s   K i d   e n u m . E n u m   :           B O Y   =   0           G I R L   =   1     d e f   r a n d o m _ k i d       - >   K i d :           r e t u r n   r a n d o m . c h o i c e   [ K i d . B O Y ,   K i d . G I R L ]       b o t h _ g i r l s   =   0   o l d e r _ g i r l   =   0   e i t h e r _ g i r l   =   0     r a n d o m . s e e d   0       f o r   _   i n   r a n g e   1 0 0 0 0   :           y o u n g e r   =   r a n d o m _ k i d               o l d e r   =   r a n d o m _ k i d               i f   o l d e r   = =   K i d . G I R L :                   o l d e r _ g i r l   + =   1           i f   o l d e r   = =   K i d . G I R L   a n d   y o u n g e r   = =   K i d . G I R L :                   b o t h _ g i r l s   + =   1           i f   o l d e r   = =   K i d . G I R L   o r   y o u n g e r   = =   K i d . G I R L :                   e i t h e r _ g i r l   + =   1     p r i n t   " P   b o t h      o l d e r   : " ,   b o t h _ g i r l s       o l d e r _ g i r l                0 . 5 1 4   ~   1   2   p r i n t   " P   b o t h      e i t h e r   :   " ,   b o t h _ g i r l s       e i t h e r _ g i r l          0 . 3 4 2   ~   1   3 P   E  F   = P   E , F     P   F   = P   F  E   P   E     P   F    so that:  which is how Bayes’s theorem is often stated. This theorem often gets used to demonstrate why data scientists are smarter than doctors. Imagine a certain disease that affects 1 in every 10,000 people. And imagine that there is a test for this disease that gives the correct result  “diseased” if you have the disease, “nondiseased” if you don’t  99% of the time. What does a positive test mean? Let’s use T for the event “your test is positive” and D for the event “you have the disease.” Then Bayes’s theorem says that the probability that you have the disease, conditional on testing positive, is:   , the probability that someone with the disease  Here we know that P tests positive, is 0.99. P D , the probability that any given person has the disease, is 1 10,000 = 0.0001. P without the disease tests positive, is 0.01. And P  , the probability that any given person doesn’t have the disease, is 0.9999. If you substitute these numbers into Bayes’s theorem, you find:   , the probability that someone  That is, less than 1% of the people who test positive actually have the disease.  P   F   = P   F , E   + P   F , ¬ E   P   E  F   = P   F  E   P   E     [ P   F  E   P   E   + P   F  ¬ E   P   ¬ E   ] P   D  T   = P   T  D   P   D     [ P   T  D   P   D   + P   T  ¬ D   P   ¬ D   ]   T  D   T  ¬ D   ¬ D P   D  T   = 0 . 9 8 %  NOTE  This assumes that people take the test more or less at random. If only people with certain symptoms take the test, we would instead have to condition on the event “positive test and symptoms” and the number would likely be a lot higher.  A more intuitive way to see this is to imagine a population of 1 million people. You’d expect 100 of them to have the disease, and 99 of those 100 to test positive. On the other hand, you’d expect 999,900 of them not to have the disease, and 9,999 of those to test positive. That means you’d expect only 99 out of  99 + 9999  positive testers to actually have the disease.  Random Variables A random variable is a variable whose possible values have an associated probability distribution. A very simple random variable equals 1 if a coin flip turns up heads and 0 if the flip turns up tails. A more complicated one might measure the number of heads you observe when flipping a coin 10 times or a value picked from r likely. The associated distribution gives the probabilities that the variable realizes each of its possible values. The coin flip variable equals 0 with probability 0.5 and 1 with probability 0.5. The r   variable has a distribution that assigns probability 0.1 to each of the numbers from 0 to 9. We will sometimes talk about the expected value of a random variable, which is the average of its values weighted by their probabilities. The coin flip variable has an expected value of 1 2  = 0 * 1 2 + 1 * 1 2 , and the    where each number is equally    variable has an expected value of 4.5.  Random variables can be conditioned on events just as other events can. Going back to the two-child example from “Conditional Probability”, if X is  a n g e   1 0 a n g e   1 0 r a n g e   1 0  the random variable representing the number of girls, X equals 0 with probability 1 4, 1 with probability 1 2, and 2 with probability 1 4. We can define a new random variable Y that gives the number of girls conditional on at least one of the children being a girl. Then Y equals 1 with probability 2 3 and 2 with probability 1 3. And a variable Z that’s the number of girls conditional on the older child being a girl equals 1 with probability 1 2 and 2 with probability 1 2. For the most part, we will be using random variables implicitly in what we do without calling special attention to them. But if you look deeply you’ll see them.  Continuous Distributions A coin flip corresponds to a discrete distribution—one that associates positive probability with discrete outcomes. Often we’ll want to model distributions across a continuum of outcomes.  For our purposes, these outcomes will always be real numbers, although that’s not always the case in real life.  For example, the uniform distribution puts equal weight on all the numbers between 0 and 1. Because there are infinitely many numbers between 0 and 1, this means that the weight it assigns to individual points must necessarily be zero. For this reason, we represent a continuous distribution with a probability density function  PDF  such that the probability of seeing a value in a certain interval equals the integral of the density function over the interval.  NOTE  If your integral calculus is rusty, a simpler way of understanding this is that if a distribution has density function f, then the probability of seeing a value between x and x + h is approximately h * f x  if h is small.  The density function for the uniform distribution is just:   The probability that a random variable following that distribution is between 0.2 and 0.3 is 1 10, as you’d expect. Python’s r  pseudo random variable with a uniform density. We will often be more interested in the cumulative distribution function  CDF , which gives the probability that a random variable is less than or equal to a certain value. It’s not hard to create the CDF for the uniform distribution  Figure 6-1 :  m is a  d e f   u n i f o r m _ p d f   x :   f l o a t     - >   f l o a t :           r e t u r n   1   i f   0   < =   x   <   1   e l s e   0 a n d o m . r a n d o d e f   u n i f o r m _ c d f   x :   f l o a t     - >   f l o a t :           " " " R e t u r n s   t h e   p r o b a b i l i t y   t h a t   a   u n i f o r m   r a n d o m   v a r i a b l e   i s   < =   x " " "           i f   x   <   0 :       r e t u r n   0            u n i f o r m   r a n d o m   i s   n e v e r   l e s s   t h a n   0           e l i f   x   <   1 :   r e t u r n   x            e . g .   P   X   < =   0 . 4     =   0 . 4           e l s e :               r e t u r n   1            u n i f o r m   r a n d o m   i s   a l w a y s   l e s s   t h a n   1  Figure 6-1. The uniform CDF  The Normal Distribution The normal distribution is the classic bell curve–shaped distribution and is completely determined by two parameters: its mean μ  mu  and its standard deviation σ  sigma . The mean indicates where the bell is centered, and the standard deviation how “wide” it is. It has the PDF:  which we can implement as:  f   x  μ , σ   = e x p   −   1 √ 2 π σ   x − μ   2 2 σ 2  In Figure 6-2, we plot some of these PDFs to see what they look like:  Figure 6-2. Various normal PDFs  i m p o r t   m a t h   S Q R T _ T W O _ P I   =   m a t h . s q r t   2   *   m a t h . p i       d e f   n o r m a l _ p d f   x :   f l o a t ,   m u :   f l o a t   =   0 ,   s i g m a :   f l o a t   =   1     - >   f l o a t :           r e t u r n     m a t h . e x p   -   x - m u     * *   2       2       s i g m a   * *   2           S Q R T _ T W O _ P I   *   s i g m a     i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t   x s   =   [ x       1 0 . 0   f o r   x   i n   r a n g e   - 5 0 ,   5 0   ]   p l t . p l o t   x s , [ n o r m a l _ p d f   x , s i g m a = 1     f o r   x   i n   x s ] , ' - ' , l a b e l = ' m u = 0 , s i g m a = 1 '     p l t . p l o t   x s , [ n o r m a l _ p d f   x , s i g m a = 2     f o r   x   i n   x s ] , ' - - ' , l a b e l = ' m u = 0 , s i g m a = 2 '     p l t . p l o t   x s , [ n o r m a l _ p d f   x , s i g m a = 0 . 5     f o r   x   i n   x s ] , ' : ' , l a b e l = ' m u = 0 , s i g m a = 0 . 5 '     p l t . p l o t   x s , [ n o r m a l _ p d f   x , m u = - 1         f o r   x   i n   x s ] , ' - . ' , l a b e l = ' m u = - 1 , s i g m a = 1 '     p l t . l e g e n d       p l t . t i t l e   " V a r i o u s   N o r m a l   p d f s "     p l t . s h o w      When μ = 0 and σ = 1, it’s called the standard normal distribution. If Z is a standard normal random variable, then it turns out that:  is also normal but with mean μ and standard deviation σ. Conversely, if X is a normal random variable with mean μ and standard deviation σ,  is a standard normal variable. The CDF for the normal distribution cannot be written in an “elementary” manner, but we can write it using Python’s m  f error function:  Again, in Figure 6-3, we plot a few CDFs:  X = σ Z + μ Z =   X − μ     σ a t h . e r d e f   n o r m a l _ c d f   x :   f l o a t ,   m u :   f l o a t   =   0 ,   s i g m a :   f l o a t   =   1     - >   f l o a t :           r e t u r n     1   +   m a t h . e r f     x   -   m u         m a t h . s q r t   2         s i g m a           2 x s   =   [ x       1 0 . 0   f o r   x   i n   r a n g e   - 5 0 ,   5 0   ]   p l t . p l o t   x s , [ n o r m a l _ c d f   x , s i g m a = 1     f o r   x   i n   x s ] , ' - ' , l a b e l = ' m u = 0 , s i g m a = 1 '     p l t . p l o t   x s , [ n o r m a l _ c d f   x , s i g m a = 2     f o r   x   i n   x s ] , ' - - ' , l a b e l = ' m u = 0 , s i g m a = 2 '     p l t . p l o t   x s , [ n o r m a l _ c d f   x , s i g m a = 0 . 5     f o r   x   i n   x s ] , ' : ' , l a b e l = ' m u = 0 , s i g m a = 0 . 5 '     p l t . p l o t   x s , [ n o r m a l _ c d f   x , m u = - 1     f o r   x   i n   x s ] , ' - . ' , l a b e l = ' m u = - 1 , s i g m a = 1 '     p l t . l e g e n d   l o c = 4        b o t t o m   r i g h t   p l t . t i t l e   " V a r i o u s   N o r m a l   c d f s "     p l t . s h o w      Figure 6-3. Various normal CDFs  Sometimes we’ll need to invert n f to find the value corresponding to a specified probability. There’s no simple way to compute its inverse, but  f is continuous and strictly increasing, so we can use a binary  search:  o r m a l _ c d n o r m a l _ c d d e f   i n v e r s e _ n o r m a l _ c d f   p :   f l o a t ,                                                 m u :   f l o a t   =   0 ,                                                 s i g m a :   f l o a t   =   1 ,                                                 t o l e r a n c e :   f l o a t   =   0 . 0 0 0 0 1     - >   f l o a t :           " " " F i n d   a p p r o x i m a t e   i n v e r s e   u s i n g   b i n a r y   s e a r c h " " "                i f   n o t   s t a n d a r d ,   c o m p u t e   s t a n d a r d   a n d   r e s c a l e           i f   m u   ! =   0   o r   s i g m a   ! =   1 :                   r e t u r n   m u   +   s i g m a   *   i n v e r s e _ n o r m a l _ c d f   p ,   t o l e r a n c e = t o l e r a n c e               l o w _ z   =   - 1 0 . 0                                                n o r m a l _ c d f   - 1 0     i s     v e r y   c l o s e   t o     0           h i _ z     =     1 0 . 0                                                n o r m a l _ c d f   1 0       i s     v e r y   c l o s e   t o     1    The function repeatedly bisects intervals until it narrows in on a Z that’s close enough to the desired probability.  The Central Limit Theorem One reason the normal distribution is so useful is the central limit theorem, which says  in essence  that a random variable defined as the average of a large number of independent and identically distributed random variables is itself approximately normally distributed. In particular, if x deviation σ, and if n is large, then:  n are random variables with mean μ and standard  is approximately normally distributed with mean μ and standard deviation   n. Equivalently  but often more usefully ,  is approximately normally distributed with mean 0 and standard deviation 1. An easy way to illustrate this is by looking at binomial random variables, which have two parameters n and p. A Binomial n,p  random variable is          w h i l e   h i _ z   -   l o w _ z   >   t o l e r a n c e :                   m i d _ z   =     l o w _ z   +   h i _ z         2              C o n s i d e r   t h e   m i d p o i n t                   m i d _ p   =   n o r m a l _ c d f   m i d _ z                  a n d   t h e   C D F ' s   v a l u e   t h e r e                   i f   m i d _ p   <   p :                           l o w _ z   =   m i d _ z                                M i d p o i n t   t o o   l o w ,   s e a r c h   a b o v e   i t                   e l s e :                           h i _ z   =   m i d _ z                                  M i d p o i n t   t o o   h i g h ,   s e a r c h   b e l o w   i t             r e t u r n   m i d _ z 1 , . . . , x   x 1 + . . . + x n   σ   √ 1 n   x 1 + . . . + x n   − μ n σ √ n  simply the sum of n independent Bernoulli p  random variables, each of which equals 1 with probability p and 0 with probability 1 – p:  The mean of a Bernoulli p  variable is p, and its standard deviation is    . The central limit theorem says that as n gets large, a  Binomial n,p  variable is approximately a normal random variable with mean μ  . If we plot both, you can easily see the resemblance:  p and standard deviation σ  d e f   b e r n o u l l i _ t r i a l   p :   f l o a t     - >   i n t :           " " " R e t u r n s   1   w i t h   p r o b a b i l i t y   p   a n d   0   w i t h   p r o b a b i l i t y   1 - p " " "           r e t u r n   1   i f   r a n d o m . r a n d o m       <   p   e l s e   0     d e f   b i n o m i a l   n :   i n t ,   p :   f l o a t     - >   i n t :           " " " R e t u r n s   t h e   s u m   o f   n   b e r n o u l l i   p     t r i a l s " " "           r e t u r n   s u m   b e r n o u l l i _ t r i a l   p     f o r   _   i n   r a n g e   n     √ p   1 − p = n = √ n p   1 − p f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     d e f   b i n o m i a l _ h i s t o g r a m   p :   f l o a t ,   n :   i n t ,   n u m _ p o i n t s :   i n t     - >   N o n e :           " " " P i c k s   p o i n t s   f r o m   a   B i n o m i a l   n ,   p     a n d   p l o t s   t h e i r   h i s t o g r a m " " "           d a t a   =   [ b i n o m i a l   n ,   p     f o r   _   i n   r a n g e   n u m _ p o i n t s   ]                u s e   a   b a r   c h a r t   t o   s h o w   t h e   a c t u a l   b i n o m i a l   s a m p l e s           h i s t o g r a m   =   C o u n t e r   d a t a             p l t . b a r   [ x   -   0 . 4   f o r   x   i n   h i s t o g r a m . k e y s     ] ,                           [ v       n u m _ p o i n t s   f o r   v   i n   h i s t o g r a m . v a l u e s     ] ,                           0 . 8 ,                           c o l o r = ' 0 . 7 5 '               m u   =   p   *   n           s i g m a   =   m a t h . s q r t   n   *   p   *     1   -   p                    u s e   a   l i n e   c h a r t   t o   s h o w   t h e   n o r m a l   a p p r o x i m a t i o n           x s   =   r a n g e   m i n   d a t a   ,   m a x   d a t a     +   1             y s   =   [ n o r m a l _ c d f   i   +   0 . 5 ,   m u ,   s i g m a     -   n o r m a l _ c d f   i   -   0 . 5 ,   m u ,   s i g m a                         f o r   i   i n   x s ]           p l t . p l o t   x s , y s             p l t . t i t l e   " B i n o m i a l   D i s t r i b u t i o n   v s .   N o r m a l   A p p r o x i m a t i o n "             p l t . s h o w      For example, when you call m graph in Figure 6-4.   , you get the  Figure 6-4. The output from binomial_histogram  The moral of this approximation is that if you want to know the probability that  say  a fair coin turns up more than 60 heads in 100 flips, you can estimate it as the probability that a Normal 50,5  is greater than 60, which is easier than computing the Binomial 100,0.5  CDF.  Although in most applications you’d probably be using statistical software that would gladly compute whatever probabilities you want.   For Further Exploration  scipy.stats contains PDF and CDF functions for most of the popular probability distributions.  a k e _ h i s t   0 . 7 5 ,   1 0 0 ,   1 0 0 0 0  Remember how, at the end of Chapter 5, I said that it would be a good idea to study a statistics textbook? It would also be a good idea to study a probability textbook. The best one I know that’s available online is Introduction to Probability, by Charles M. Grinstead and J. Laurie Snell  American Mathematical Society .   Chapter 7. Hypothesis and Inference  It is the mark of a truly intelligent person to be moved by statistics.  —George Bernard Shaw  What will we do with all this statistics and probability theory? The science part of data science frequently involves forming and testing hypotheses about our data and the processes that generate it.  Statistical Hypothesis Testing Often, as data scientists, we’ll want to test whether a certain hypothesis is likely to be true. For our purposes, hypotheses are assertions like “this coin is fair” or “data scientists prefer Python to R” or “people are more likely to navigate away from the page without ever reading the content if we pop up an irritating interstitial advertisement with a tiny, hard-to-find close button” that can be translated into statistics about data. Under various assumptions, those statistics can be thought of as observations of random variables from known distributions, which allows us to make statements about how likely those assumptions are to hold. In the classical setup, we have a null hypothesis, H default position, and some alternative hypothesis, H compare it with. We use statistics to decide whether we can reject H false or not. This will probably make more sense with an example.  0, that represents some 1, that we’d like to 0 as  Example: Flipping a Coin Imagine we have a coin and we want to test whether it’s fair. We’ll make the assumption that the coin has some probability p of landing heads, and so   our null hypothesis is that the coin is fair—that is, that p = 0.5. We’ll test this against the alternative hypothesis p ≠ 0.5. In particular, our test will involve flipping the coin some number, n, times and counting the number of heads, X. Each coin flip is a Bernoulli trial, which means that X is a Binomial n,p  random variable, which  as we saw in Chapter 6  we can approximate using the normal distribution:  Whenever a random variable follows a normal distribution, we can use  f to figure out the probability that its realized value lies within  or outside a particular interval:  f r o m   t y p i n g   i m p o r t   T u p l e   i m p o r t   m a t h     d e f   n o r m a l _ a p p r o x i m a t i o n _ t o _ b i n o m i a l   n :   i n t ,   p :   f l o a t     - >   T u p l e [ f l o a t ,   f l o a t ] :           " " " R e t u r n s   m u   a n d   s i g m a   c o r r e s p o n d i n g   t o   a   B i n o m i a l   n ,   p   " " "           m u   =   p   *   n           s i g m a   =   m a t h . s q r t   p   *     1   -   p     *   n             r e t u r n   m u ,   s i g m a n o r m a l _ c d f r o m   s c r a t c h . p r o b a b i l i t y   i m p o r t   n o r m a l _ c d f        T h e   n o r m a l   c d f   _ i s _   t h e   p r o b a b i l i t y   t h e   v a r i a b l e   i s   b e l o w   a   t h r e s h o l d   n o r m a l _ p r o b a b i l i t y _ b e l o w   =   n o r m a l _ c d f        I t ' s   a b o v e   t h e   t h r e s h o l d   i f   i t ' s   n o t   b e l o w   t h e   t h r e s h o l d   d e f   n o r m a l _ p r o b a b i l i t y _ a b o v e   l o :   f l o a t ,                                                             m u :   f l o a t   =   0 ,                                                             s i g m a :   f l o a t   =   1     - >   f l o a t :           " " " T h e   p r o b a b i l i t y   t h a t   a n   N   m u ,   s i g m a     i s   g r e a t e r   t h a n   l o . " " "           r e t u r n   1   -   n o r m a l _ c d f   l o ,   m u ,   s i g m a          I t ' s   b e t w e e n   i f   i t ' s   l e s s   t h a n   h i ,   b u t   n o t   l e s s   t h a n   l o   d e f   n o r m a l _ p r o b a b i l i t y _ b e t w e e n   l o :   f l o a t ,                                                                 h i :   f l o a t ,                                                                 m u :   f l o a t   =   0 ,                                                                 s i g m a :   f l o a t   =   1     - >   f l o a t :           " " " T h e   p r o b a b i l i t y   t h a t   a n   N   m u ,   s i g m a     i s   b e t w e e n   l o   a n d   h i . " " "           r e t u r n   n o r m a l _ c d f   h i ,   m u ,   s i g m a     -   n o r m a l _ c d f   l o ,   m u ,   s i g m a          I t ' s   o u t s i d e   i f   i t ' s   n o t   b e t w e e n   d e f   n o r m a l _ p r o b a b i l i t y _ o u t s i d e   l o :   f l o a t ,    We can also do the reverse—find either the nontail region or the  symmetric  interval around the mean that accounts for a certain level of likelihood. For example, if we want to find an interval centered at the mean and containing 60% probability, then we find the cutoffs where the upper and lower tails each contain 20% of the probability  leaving 60% :                                                                h i :   f l o a t ,                                                                 m u :   f l o a t   =   0 ,                                                                 s i g m a :   f l o a t   =   1     - >   f l o a t :           " " " T h e   p r o b a b i l i t y   t h a t   a n   N   m u ,   s i g m a     i s   n o t   b e t w e e n   l o   a n d   h i . " " "           r e t u r n   1   -   n o r m a l _ p r o b a b i l i t y _ b e t w e e n   l o ,   h i ,   m u ,   s i g m a   f r o m   s c r a t c h . p r o b a b i l i t y   i m p o r t   i n v e r s e _ n o r m a l _ c d f     d e f   n o r m a l _ u p p e r _ b o u n d   p r o b a b i l i t y :   f l o a t ,                                                 m u :   f l o a t   =   0 ,                                                 s i g m a :   f l o a t   =   1     - >   f l o a t :           " " " R e t u r n s   t h e   z   f o r   w h i c h   P   Z   < =   z     =   p r o b a b i l i t y " " "           r e t u r n   i n v e r s e _ n o r m a l _ c d f   p r o b a b i l i t y ,   m u ,   s i g m a       d e f   n o r m a l _ l o w e r _ b o u n d   p r o b a b i l i t y :   f l o a t ,                                                 m u :   f l o a t   =   0 ,                                                 s i g m a :   f l o a t   =   1     - >   f l o a t :           " " " R e t u r n s   t h e   z   f o r   w h i c h   P   Z   > =   z     =   p r o b a b i l i t y " " "           r e t u r n   i n v e r s e _ n o r m a l _ c d f   1   -   p r o b a b i l i t y ,   m u ,   s i g m a       d e f   n o r m a l _ t w o _ s i d e d _ b o u n d s   p r o b a b i l i t y :   f l o a t ,                                                           m u :   f l o a t   =   0 ,                                                           s i g m a :   f l o a t   =   1     - >   T u p l e [ f l o a t ,   f l o a t ] :           " " "           R e t u r n s   t h e   s y m m e t r i c     a b o u t   t h e   m e a n     b o u n d s           t h a t   c o n t a i n   t h e   s p e c i f i e d   p r o b a b i l i t y           " " "           t a i l _ p r o b a b i l i t y   =     1   -   p r o b a b i l i t y         2                u p p e r   b o u n d   s h o u l d   h a v e   t a i l _ p r o b a b i l i t y   a b o v e   i t           u p p e r _ b o u n d   =   n o r m a l _ l o w e r _ b o u n d   t a i l _ p r o b a b i l i t y ,   m u ,   s i g m a                  l o w e r   b o u n d   s h o u l d   h a v e   t a i l _ p r o b a b i l i t y   b e l o w   i t           l o w e r _ b o u n d   =   n o r m a l _ u p p e r _ b o u n d   t a i l _ p r o b a b i l i t y ,   m u ,   s i g m a               r e t u r n   l o w e r _ b o u n d ,   u p p e r _ b o u n d  In particular, let’s say that we choose to flip the coin n = 1,000 times. If our hypothesis of fairness is true, X should be distributed approximately normally with mean 500 and standard deviation 15.8:  We need to make a decision about significance—how willing we are to make a type 1 error  “false positive” , in which we reject H 0 even though it’s true. For reasons lost to the annals of history, this willingness is often set at 5% or 1%. Let’s choose 5%. Consider the test that rejects H  0 if X falls outside the bounds given by:  Assuming p really equals 0.5  i.e., H 0 is true , there is just a 5% chance we observe an X that lies outside this interval, which is the exact significance we wanted. Said differently, if H 0 is true, then, approximately 19 times out of 20, this test will give the correct result. We are also often interested in the power of a test, which is the probability of not making a type 2 error  “false negative” , in which we fail to reject  0 even though it’s false. In order to measure this, we have to specify what  0 being false means.  Knowing merely that p is not 0.5 doesn’t  exactly H give us a ton of information about the distribution of X.  In particular, let’s check what happens if p is really 0.55, so that the coin is slightly biased toward heads. In that case, we can calculate the power of the test with:  m u _ 0 ,   s i g m a _ 0   =   n o r m a l _ a p p r o x i m a t i o n _ t o _ b i n o m i a l   1 0 0 0 ,   0 . 5        4 6 9 ,   5 3 1     l o w e r _ b o u n d ,   u p p e r _ b o u n d   =   n o r m a l _ t w o _ s i d e d _ b o u n d s   0 . 9 5 ,   m u _ 0 ,   s i g m a _ 0   H    9 5 %   b o u n d s   b a s e d   o n   a s s u m p t i o n   p   i s   0 . 5   l o ,   h i   =   n o r m a l _ t w o _ s i d e d _ b o u n d s   0 . 9 5 ,   m u _ 0 ,   s i g m a _ 0          a c t u a l   m u   a n d   s i g m a   b a s e d   o n   p   =   0 . 5 5   m u _ 1 ,   s i g m a _ 1   =   n o r m a l _ a p p r o x i m a t i o n _ t o _ b i n o m i a l   1 0 0 0 ,   0 . 5 5          a   t y p e   2   e r r o r   m e a n s   w e   f a i l   t o   r e j e c t   t h e   n u l l   h y p o t h e s i s ,      w h i c h   w i l l   h a p p e n   w h e n   X   i s   s t i l l   i n   o u r   o r i g i n a l   i n t e r v a l    Imagine instead that our null hypothesis was that the coin is not biased toward heads, or that p 5. In that case we want a one-sided test that rejects the null hypothesis when X is much larger than 500 but not when X is smaller than 500. So, a 5% significance test involves using  w to find the cutoff below which 95% of the  probability lies:  0 when X is below This is a more powerful test, since it no longer rejects H 469  which is very unlikely to happen if H 1 is true  and instead rejects H when X is between 526 and 531  which is somewhat likely to happen if H is true .  p-Values An alternative way of thinking about the preceding test involves p-values. Instead of choosing bounds based on some probability cutoff, we compute the probability—assuming H 0 is true—that we would see a value at least as extreme as the one we actually observed. For our two-sided test of whether the coin is fair, we compute:  t y p e _ 2 _ p r o b a b i l i t y   =   n o r m a l _ p r o b a b i l i t y _ b e t w e e n   l o ,   h i ,   m u _ 1 ,   s i g m a _ 1     p o w e r   =   1   -   t y p e _ 2 _ p r o b a b i l i t y                0 . 8 8 7 ≤ 0 . n o r m a l _ p r o b a b i l i t y _ b e l o h i   =   n o r m a l _ u p p e r _ b o u n d   0 . 9 5 ,   m u _ 0 ,   s i g m a _ 0        i s   5 2 6     <   5 3 1 ,   s i n c e   w e   n e e d   m o r e   p r o b a b i l i t y   i n   t h e   u p p e r   t a i l       t y p e _ 2 _ p r o b a b i l i t y   =   n o r m a l _ p r o b a b i l i t y _ b e l o w   h i ,   m u _ 1 ,   s i g m a _ 1     p o w e r   =   1   -   t y p e _ 2 _ p r o b a b i l i t y                0 . 9 3 6 0 1 d e f   t w o _ s i d e d _ p _ v a l u e   x :   f l o a t ,   m u :   f l o a t   =   0 ,   s i g m a :   f l o a t   =   1     - >   f l o a t :           " " "           H o w   l i k e l y   a r e   w e   t o   s e e   a   v a l u e   a t   l e a s t   a s   e x t r e m e   a s   x     i n   e i t h e r           d i r e c t i o n     i f   o u r   v a l u e s   a r e   f r o m   a n   N   m u ,   s i g m a   ?           " " "           i f   x   > =   m u :                      x   i s   g r e a t e r   t h a n   t h e   m e a n ,   s o   t h e   t a i l   i s   e v e r y t h i n g   g r e a t e r   t h a n   x                   r e t u r n   2   *   n o r m a l _ p r o b a b i l i t y _ a b o v e   x ,   m u ,   s i g m a             e l s e :    If we were to see 530 heads, we would compute:  NOTE  Why did we use a value of 5 continuity correction. It reflects the fact that n  5 rather than using 5  0? This is what’s called a    is a better estimate of the probability of seeing 530 heads  than n    is.  Correspondingly, n   is a better estimate of the probability of seeing at least 530 heads. You may have noticed that we also used this in the code that produced Figure 6-4.  One way to convince yourself that this is a sensible estimate is with a simulation:  Since the p-value is greater than our 5% significance, we don’t reject the null. If we instead saw 532 heads, the p-value would be:                     x   i s   l e s s   t h a n   t h e   m e a n ,   s o   t h e   t a i l   i s   e v e r y t h i n g   l e s s   t h a n   x                   r e t u r n   2   *   n o r m a l _ p r o b a b i l i t y _ b e l o w   x ,   m u ,   s i g m a   t w o _ s i d e d _ p _ v a l u e   5 2 9 . 5 ,   m u _ 0 ,   s i g m a _ 0            0 . 0 6 2 2 9 . 3 o r m a l _ p r o b a b i l i t y _ b e t w e e n   5 2 9 . 5 , 5 3 0 . 5 ,   m u _ 0 ,   s i g m a _ 0 o r m a l _ p r o b a b i l i t y _ b e t w e e n   5 3 0 ,   5 3 1 ,   m u _ 0 ,   s i g m a _ 0 o r m a l _ p r o b a b i l i t y _ a b o v e   5 2 9 . 5 ,   m u _ 0 ,   s i g m a _ 0 i m p o r t   r a n d o m     e x t r e m e _ v a l u e _ c o u n t   =   0   f o r   _   i n   r a n g e   1 0 0 0   :           n u m _ h e a d s   =   s u m   1   i f   r a n d o m . r a n d o m       <   0 . 5   e l s e   0            C o u n t      o f   h e a d s                                           f o r   _   i n   r a n g e   1 0 0 0                                        i n   1 0 0 0   f l i p s ,           i f   n u m _ h e a d s   > =   5 3 0   o r   n u m _ h e a d s   < =   4 7 0 :                              a n d   c o u n t   h o w   o f t e n                   e x t r e m e _ v a l u e _ c o u n t   + =   1                                                      t h e      i s   ' e x t r e m e '        p - v a l u e   w a s   0 . 0 6 2   = >   ~ 6 2   e x t r e m e   v a l u e s   o u t   o f   1 0 0 0   a s s e r t   5 9   <   e x t r e m e _ v a l u e _ c o u n t   <   6 5 ,   f " { e x t r e m e _ v a l u e _ c o u n t } " t w o _ s i d e d _ p _ v a l u e   5 3 1 . 5 ,   m u _ 0 ,   s i g m a _ 0            0 . 0 4 6 3  which is smaller than the 5% significance, which means we would reject the null. It’s the exact same test as before. It’s just a different way of approaching the statistics. Similarly, we would have:  For our one-sided test, if we saw 525 heads we would compute:  which means we wouldn’t reject the null. If we saw 527 heads, the computation would be:  and we would reject the null.  WARNING  Make sure your data is roughly normally distributed before using  e to compute p-values. The annals of bad data science are  filled with examples of people opining that the chance of some observed event occurring at random is one in a million, when what they really mean is “the chance, assuming the data is distributed normally,” which is fairly meaningless if the data isn’t. There are various statistical tests for normality, but even plotting the data is a good start.  Confidence Intervals We’ve been testing hypotheses about the value of the heads probability p, which is a parameter of the unknown “heads” distribution. When this is the case, a third approach is to construct a confidence interval around the observed value of the parameter.  u p p e r _ p _ v a l u e   =   n o r m a l _ p r o b a b i l i t y _ a b o v e   l o w e r _ p _ v a l u e   =   n o r m a l _ p r o b a b i l i t y _ b e l o w u p p e r _ p _ v a l u e   5 2 4 . 5 ,   m u _ 0 ,   s i g m a _ 0        0 . 0 6 1 u p p e r _ p _ v a l u e   5 2 6 . 5 ,   m u _ 0 ,   s i g m a _ 0        0 . 0 4 7 n o r m a l _ p r o b a b i l i t y _ a b o v  For example, we can estimate the probability of the unfair coin by looking at the average value of the Bernoulli variables corresponding to each flip— 1 if heads, 0 if tails. If we observe 525 heads out of 1,000 flips, then we estimate p equals 0.525. How confident can we be about this estimate? Well, if we knew the exact value of p, the central limit theorem  recall “The Central Limit Theorem”  tells us that the average of those Bernoulli variables should be approximately normal, with mean p and standard deviation:  Here we don’t know p, so instead we use our estimate:  This is not entirely justified, but people seem to do it anyway. Using the normal approximation, we conclude that we are “95% confident” that the following interval contains the true parameter p:  NOTE  This is a statement about the interval, not about p. You should understand it as the assertion that if you were to repeat the experiment many times, 95% of the time the “true” parameter  which is the same every time  would lie within the observed confidence interval  which might be different every time .  In particular, we do not conclude that the coin is unfair, since 0.5 falls within our confidence interval. If instead we’d seen 540 heads, then we’d have:  m a t h . s q r t   p   *     1   -   p         1 0 0 0   p _ h a t   =   5 2 5       1 0 0 0   m u   =   p _ h a t   s i g m a   =   m a t h . s q r t   p _ h a t   *     1   -   p _ h a t         1 0 0 0            0 . 0 1 5 8 n o r m a l _ t w o _ s i d e d _ b o u n d s   0 . 9 5 ,   m u ,   s i g m a                      [ 0 . 4 9 4 0 ,   0 . 5 5 6 0 ]  Here, “fair coin” doesn’t lie in the confidence interval.  The “fair coin” hypothesis doesn’t pass a test that you’d expect it to pass 95% of the time if it were true.   p-Hacking A procedure that erroneously rejects the null hypothesis only 5% of the time will—by definition—5% of the time erroneously reject the null hypothesis:  What this means is that if you’re setting out to find “significant” results, you usually can. Test enough hypotheses against your dataset, and one of them will almost certainly appear significant. Remove the right outliers, and you can probably get your p-value below 0.05.  We did something vaguely similar in “Correlation”; did you notice?   p _ h a t   =   5 4 0       1 0 0 0   m u   =   p _ h a t   s i g m a   =   m a t h . s q r t   p _ h a t   *     1   -   p _ h a t         1 0 0 0        0 . 0 1 5 8   n o r m a l _ t w o _ s i d e d _ b o u n d s   0 . 9 5 ,   m u ,   s i g m a        [ 0 . 5 0 9 1 ,   0 . 5 7 0 9 ] f r o m   t y p i n g   i m p o r t   L i s t     d e f   r u n _ e x p e r i m e n t       - >   L i s t [ b o o l ] :           " " " F l i p s   a   f a i r   c o i n   1 0 0 0   t i m e s ,   T r u e   =   h e a d s ,   F a l s e   =   t a i l s " " "           r e t u r n   [ r a n d o m . r a n d o m       <   0 . 5   f o r   _   i n   r a n g e   1 0 0 0   ]     d e f   r e j e c t _ f a i r n e s s   e x p e r i m e n t :   L i s t [ b o o l ]     - >   b o o l :           " " " U s i n g   t h e   5 %   s i g n i f i c a n c e   l e v e l s " " "           n u m _ h e a d s   =   l e n   [ f l i p   f o r   f l i p   i n   e x p e r i m e n t   i f   f l i p ]             r e t u r n   n u m _ h e a d s   <   4 6 9   o r   n u m _ h e a d s   >   5 3 1     r a n d o m . s e e d   0     e x p e r i m e n t s   =   [ r u n _ e x p e r i m e n t       f o r   _   i n   r a n g e   1 0 0 0   ]   n u m _ r e j e c t i o n s   =   l e n   [ e x p e r i m e n t                                               f o r   e x p e r i m e n t   i n   e x p e r i m e n t s                                               i f   r e j e c t _ f a i r n e s s   e x p e r i m e n t   ]       a s s e r t   n u m _ r e j e c t i o n s   = =   4 6  This is sometimes called p-hacking and is in some ways a consequence of the “inference from p-values framework.” A good article criticizing this approach is “The Earth Is Round”, by Jacob Cohen. If you want to do good science, you should determine your hypotheses before looking at the data, you should clean your data without the hypotheses in mind, and you should keep in mind that p-values are not substitutes for common sense.  An alternative approach is discussed in “Bayesian Inference”.   Example: Running an A B Test One of your primary responsibilities at DataSciencester is experience optimization, which is a euphemism for trying to get people to click on advertisements. One of your advertisers has developed a new energy drink targeted at data scientists, and the VP of Advertisements wants your help choosing between advertisement A  “tastes great!”  and advertisement B  “less bias!” . Being a scientist, you decide to run an experiment by randomly showing site visitors one of the two advertisements and tracking how many people click on each one. If 990 out of 1,000 A-viewers click their ad, while only 10 out of 1,000 B- viewers click their ad, you can be pretty confident that A is the better ad. But what if the differences are not so stark? Here’s where you’d use statistical inference. Let’s say that N think of each ad view as a Bernoulli trial where p someone clicks ad A. Then  if N  A of them click it. We can A is the probability that A is large, which it is here  we know that   A people see ad A, and that n  A is approximately a normal random variable with mean p  A and  standard deviation σ Similarly, n B and standard deviation σ  B is approximately a normal random variable with mean  B. We can express this  A.  n A   N A = √ p A   1 − p A     N B   N p B = √ p B   1 − p B     N  in code as:  If we assume those two normals are independent  which seems reasonable, since the individual Bernoulli trials ought to be , then their difference should also be normal with mean p  A and standard deviation   .  NOTE  This is sort of cheating. The math only works out exactly like this if you know the standard deviations. Here we’re estimating them from the data, which means that we really should be using a t-distribution. But for large enough datasets, it’s close enough that it doesn’t make much of a difference.  This means we can test the null hypothesis that p is, that p  B is 0  by using the statistic:  A and p  B are the same  that  which should approximately be a standard normal. For example, if “tastes great” gets 200 clicks out of 1,000 views and “less bias” gets 180 clicks out of 1,000 views, the statistic equals:  The probability of seeing such a large difference if the means were actually equal would be:  d e f   e s t i m a t e d _ p a r a m e t e r s   N :   i n t ,   n :   i n t     - >   T u p l e [ f l o a t ,   f l o a t ] :           p   =   n       N           s i g m a   =   m a t h . s q r t   p   *     1   -   p         N             r e t u r n   p ,   s i g m a B − p √ σ 2 A + σ 2 B A − p d e f   a _ b _ t e s t _ s t a t i s t i c   N _ A :   i n t ,   n _ A :   i n t ,   N _ B :   i n t ,   n _ B :   i n t     - >   f l o a t :           p _ A ,   s i g m a _ A   =   e s t i m a t e d _ p a r a m e t e r s   N _ A ,   n _ A             p _ B ,   s i g m a _ B   =   e s t i m a t e d _ p a r a m e t e r s   N _ B ,   n _ B             r e t u r n     p _ B   -   p _ A         m a t h . s q r t   s i g m a _ A   * *   2   +   s i g m a _ B   * *   2   z   =   a _ b _ t e s t _ s t a t i s t i c   1 0 0 0 ,   2 0 0 ,   1 0 0 0 ,   1 8 0              - 1 . 1 4  which is large enough that we can’t conclude there’s much of a difference. On the other hand, if “less bias” only got 150 clicks, we’d have:  which means there’s only a 0.003 probability we’d see such a large difference if the ads were equally effective.  Bayesian Inference The procedures we’ve looked at have involved making probability statements about our tests: e.g., “There’s only a 3% chance you’d observe such an extreme statistic if our null hypothesis were true.” An alternative approach to inference involves treating the unknown parameters themselves as random variables. The analyst  that’s you  starts with a prior distribution for the parameters and then uses the observed data and Bayes’s theorem to get an updated posterior distribution for the parameters. Rather than making probability judgments about the tests, you make probability judgments about the parameters. For example, when the unknown parameter is a probability  as in our coin- flipping example , we often use a prior from the Beta distribution, which puts all its probability between 0 and 1:  Generally speaking, this distribution centers its weight at:  t w o _ s i d e d _ p _ v a l u e   z                                                              0 . 2 5 4 z   =   a _ b _ t e s t _ s t a t i s t i c   1 0 0 0 ,   2 0 0 ,   1 0 0 0 ,   1 5 0              - 2 . 9 4   t w o _ s i d e d _ p _ v a l u e   z                                                              0 . 0 0 3 d e f   B   a l p h a :   f l o a t ,   b e t a :   f l o a t     - >   f l o a t :           " " " A   n o r m a l i z i n g   c o n s t a n t   s o   t h a t   t h e   t o t a l   p r o b a b i l i t y   i s   1 " " "           r e t u r n   m a t h . g a m m a   a l p h a     *   m a t h . g a m m a   b e t a         m a t h . g a m m a   a l p h a   +   b e t a       d e f   b e t a _ p d f   x :   f l o a t ,   a l p h a :   f l o a t ,   b e t a :   f l o a t     - >   f l o a t :           i f   x   < =   0   o r   x   > =   1 :                        n o   w e i g h t   o u t s i d e   o f   [ 0 ,   1 ]                   r e t u r n   0           r e t u r n   x   * *     a l p h a   -   1     *     1   -   x     * *     b e t a   -   1         B   a l p h a ,   b e t a    a and b  a are, the “tighter” the distribution is.  and the larger a For example, if a  centered at 0.5, very dispersed . If a the weight is near 1. And if a weight is near 0. Figure 7-1 shows several different Beta distributions.  a are both 1, it’s just the uniform distribution a, most of  a is much smaller than b  a is much larger than b  a, most of the  a and b  Figure 7-1. Example Beta distributions  Say we assume a prior distribution on p. Maybe we don’t want to take a stand on whether the coin is fair, and we choose a a to both equal 1. Or maybe we have a strong belief that the coin lands heads 55% of the time, and we choose a  a equals 55, b  a equals 45.  a and b  a l p h a         a l p h a   +   b e t a   l p h e t l p h e t l p h e t l p h e t l p h e t l p h e t  Then we flip our coin a bunch of times and see h heads and t tails. Bayes’s theorem  and some mathematics too tedious for us to go through here  tells us that the posterior distribution for p is again a Beta distribution, but with parameters a  h and b  t.  NOTE  It is no coincidence that the posterior distribution was again a Beta distribution. The number of heads is given by a Binomial distribution, and the Beta is the conjugate prior to the Binomial distribution. This means that whenever you update a Beta prior using observations from the corresponding binomial, you will get back a Beta posterior.  Let’s say you flip the coin 10 times and see only 3 heads. If you started with the uniform prior  in some sense refusing to take a stand about the coin’s fairness , your posterior distribution would be a Beta 4, 8 , centered around 0.33. Since you considered all probabilities equally likely, your best guess is close to the observed probability. If you started with a Beta 20, 20   expressing a belief that the coin was roughly fair , your posterior distribution would be a Beta 23, 27 , centered around 0.46, indicating a revised belief that maybe the coin is slightly biased toward tails. And if you started with a Beta 30, 10   expressing a belief that the coin was biased to flip 75% heads , your posterior distribution would be a Beta 33, 17 , centered around 0.66. In that case you’d still believe in a heads bias, but less strongly than you did initially. These three different posteriors are plotted in Figure 7-2.  l p h a   +   e t a   +    Figure 7-2. Posteriors arising from different priors  If you flipped the coin more and more times, the prior would matter less and less until eventually you’d have  nearly  the same posterior distribution no matter which prior you started with. For example, no matter how biased you initially thought the coin was, it would be hard to maintain that belief after seeing 1,000 heads out of 2,000 flips  unless you are a lunatic who picks something like a Beta 1000000,1  prior . What’s interesting is that this allows us to make probability statements about hypotheses: “Based on the prior and the observed data, there is only a 5% likelihood the coin’s heads probability is between 49% and 51%.” This is philosophically very different from a statement like “If the coin were fair, we would expect to observe data so extreme only 5% of the time.”   Using Bayesian inference to test hypotheses is considered somewhat controversial—in part because the mathematics can get somewhat complicated, and in part because of the subjective nature of choosing a prior. We won’t use it any further in this book, but it’s good to know about.  For Further Exploration  We’ve barely scratched the surface of what you should know about statistical inference. The books recommended at the end of Chapter 5 go into a lot more detail. Coursera offers a Data Analysis and Statistical Inference course that covers many of these topics.   Chapter 8. Gradient Descent  Those who boast of their descent, brag on what they owe to others.  —Seneca  Frequently when doing data science, we’ll be trying to the find the best model for a certain situation. And usually “best” will mean something like “minimizes the error of its predictions” or “maximizes the likelihood of the data.” In other words, it will represent the solution to some sort of optimization problem. This means we’ll need to solve a number of optimization problems. And in particular, we’ll need to solve them from scratch. Our approach will be a technique called gradient descent, which lends itself pretty well to a from- scratch treatment. You might not find it super-exciting in and of itself, but it will enable us to do exciting things throughout the book, so bear with me.  The Idea Behind Gradient Descent Suppose we have some function f that takes as input a vector of real numbers and outputs a single real number. One simple such function is:  We’ll frequently need to maximize or minimize such functions. That is, we need to find the input v that produces the largest  or smallest  possible value. For functions like ours, the gradient  if you remember your calculus, this is the vector of partial derivatives  gives the input direction in which the  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r ,   d o t     d e f   s u m _ o f _ s q u a r e s   v :   V e c t o r     - >   f l o a t :           " " " C o m p u t e s   t h e   s u m   o f   s q u a r e d   e l e m e n t s   i n   v " " "           r e t u r n   d o t   v ,   v    function most quickly increases.  If you don’t remember your calculus, take my word for it or look it up on the internet.  Accordingly, one approach to maximizing a function is to pick a random starting point, compute the gradient, take a small step in the direction of the gradient  i.e., the direction that causes the function to increase the most , and repeat with the new starting point. Similarly, you can try to minimize a function by taking small steps in the opposite direction, as shown in Figure 8-1.  Figure 8-1. Finding a minimum using gradient descent  NOTE  If a function has a unique global minimum, this procedure is likely to find it. If a function has multiple  local  minima, this procedure might “find” the wrong one of them, in which case you might rerun the procedure from different starting points. If a function has no minimum, then it’s possible the procedure might go on forever.   Estimating the Gradient If f is a function of one variable, its derivative at a point x measures how   changes when we make a very small change to x. The derivative is  defined as the limit of the difference quotients:  as h approaches zero.  Many a would-be calculus student has been stymied by the mathematical definition of limit, which is beautiful but can seem somewhat forbidding. Here we’ll cheat and simply say that “limit” means what you think it means.  The derivative is the slope of the tangent line at    , while the difference quotient is the slope of the not-quite-tangent line that runs through   tangent line gets closer and closer to the tangent line  Figure 8-2 .   . As h gets smaller and smaller, the not-quite-  f   x f r o m   t y p i n g   i m p o r t   C a l l a b l e     d e f   d i f f e r e n c e _ q u o t i e n t   f :   C a l l a b l e [ [ f l o a t ] ,   f l o a t ] ,                                                   x :   f l o a t ,                                                   h :   f l o a t     - >   f l o a t :           r e t u r n     f   x   +   h     -   f   x           h x , f   x   x + h , f   x + h    Figure 8-2. Approximating a derivative with a difference quotient  For many functions it’s easy to exactly calculate derivatives. For example, the s  e function:  has the derivative:  which is easy for us to check by explicitly computing the difference quotient and taking the limit.  Doing so requires nothing more than high school algebra.  What if you couldn’t  or didn’t want to  find the gradient? Although we can’t take limits in Python, we can estimate derivatives by evaluating the  q u a r d e f   s q u a r e   x :   f l o a t     - >   f l o a t :           r e t u r n   x   *   x d e f   d e r i v a t i v e   x :   f l o a t     - >   f l o a t :           r e t u r n   2   *   x  difference quotient for a very small e. Figure 8-3 shows the results of one such estimation:  Figure 8-3. Goodness of difference quotient approximation  When f is a function of many variables, it has multiple partial derivatives, each indicating how f changes when we make small changes in just one of  x s   =   r a n g e   - 1 0 ,   1 1     a c t u a l s   =   [ d e r i v a t i v e   x     f o r   x   i n   x s ]   e s t i m a t e s   =   [ d i f f e r e n c e _ q u o t i e n t   s q u a r e ,   x ,   h = 0 . 0 0 1     f o r   x   i n   x s ]        p l o t   t o   s h o w   t h e y ' r e   b a s i c a l l y   t h e   s a m e   i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t   p l t . t i t l e   " A c t u a l   D e r i v a t i v e s   v s .   E s t i m a t e s "     p l t . p l o t   x s ,   a c t u a l s ,   ' r x ' ,   l a b e l = ' A c t u a l '                    r e d     x   p l t . p l o t   x s ,   e s t i m a t e s ,   ' b + ' ,   l a b e l = ' E s t i m a t e '            b l u e   +   p l t . l e g e n d   l o c = 9     p l t . s h o w      the input variables. We calculate its ith partial derivative by treating it as a function of just its ith variable, holding the other variables fixed:  after which we can estimate the gradient the same way:  NOTE  A major drawback to this “estimate using difference quotients” approach is that it’s computationally expensive. If v has length n, e t has to evaluate f on 2n different inputs. If you’re repeatedly estimating gradients, you’re doing a whole lot of extra work. In everything we do, we’ll use math to calculate our gradient functions explicitly.  Using the Gradient s function is smallest when its input It’s easy to see that the s v is a vector of zeros. But imagine we didn’t know that. Let’s use gradients to find the minimum among all three-dimensional vectors. We’ll just pick a random starting point and then take tiny steps in the opposite direction of the gradient until we reach a point where the gradient is very small:  d e f   p a r t i a l _ d i f f e r e n c e _ q u o t i e n t   f :   C a l l a b l e [ [ V e c t o r ] ,   f l o a t ] ,                                                                   v :   V e c t o r ,                                                                   i :   i n t ,                                                                   h :   f l o a t     - >   f l o a t :           " " " R e t u r n s   t h e   i - t h   p a r t i a l   d i f f e r e n c e   q u o t i e n t   o f   f   a t   v " " "           w   =   [ v _ j   +     h   i f   j   = =   i   e l s e   0              a d d   h   t o   j u s t   t h e   i t h   e l e m e n t   o f   v                     f o r   j ,   v _ j   i n   e n u m e r a t e   v   ]             r e t u r n     f   w     -   f   v           h d e f   e s t i m a t e _ g r a d i e n t   f :   C a l l a b l e [ [ V e c t o r ] ,   f l o a t ] ,                                               v :   V e c t o r ,                                               h :   f l o a t   =   0 . 0 0 0 1   :           r e t u r n   [ p a r t i a l _ d i f f e r e n c e _ q u o t i e n t   f ,   v ,   i ,   h                             f o r   i   i n   r a n g e   l e n   v     ] s t i m a t e _ g r a d i e n u m _ o f _ s q u a r e  If you run this, you’ll find that it always ends up with a v that’s very close to [  ]. The more epochs you run it for, the closer it will get.  Choosing the Right Step Size Although the rationale for moving against the gradient is clear, how far to move is not. Indeed, choosing the right step size is more of an art than a science. Popular options include:  Using a fixed step size Gradually shrinking the step size over time At each step, choosing the step size that minimizes the value of the objective function  The last approach sounds great but is, in practice, a costly computation. To keep things simple, we’ll mostly just use a fixed step size. The step size that “works” depends on the problem—too small, and your gradient descent will  i m p o r t   r a n d o m   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d i s t a n c e ,   a d d ,   s c a l a r _ m u l t i p l y     d e f   g r a d i e n t _ s t e p   v :   V e c t o r ,   g r a d i e n t :   V e c t o r ,   s t e p _ s i z e :   f l o a t     - >   V e c t o r :           " " " M o v e s   ` s t e p _ s i z e `   i n   t h e   ` g r a d i e n t `   d i r e c t i o n   f r o m   ` v ` " " "           a s s e r t   l e n   v     = =   l e n   g r a d i e n t             s t e p   =   s c a l a r _ m u l t i p l y   s t e p _ s i z e ,   g r a d i e n t             r e t u r n   a d d   v ,   s t e p       d e f   s u m _ o f _ s q u a r e s _ g r a d i e n t   v :   V e c t o r     - >   V e c t o r :           r e t u r n   [ 2   *   v _ i   f o r   v _ i   i n   v ]    p i c k   a   r a n d o m   s t a r t i n g   p o i n t   v   =   [ r a n d o m . u n i f o r m   - 1 0 ,   1 0     f o r   i   i n   r a n g e   3   ]     f o r   e p o c h   i n   r a n g e   1 0 0 0   :           g r a d   =   s u m _ o f _ s q u a r e s _ g r a d i e n t   v              c o m p u t e   t h e   g r a d i e n t   a t   v           v   =   g r a d i e n t _ s t e p   v ,   g r a d ,   - 0 . 0 1              t a k e   a   n e g a t i v e   g r a d i e n t   s t e p           p r i n t   e p o c h ,   v       a s s e r t   d i s t a n c e   v ,   [ 0 ,   0 ,   0 ]     <   0 . 0 0 1            v   s h o u l d   b e   c l o s e   t o   0 0 , 0 , 0  take forever; too big, and you’ll take giant steps that might make the function you care about get larger or even be undefined. So we’ll need to experiment.  Using Gradient Descent to Fit Models In this book, we’ll be using gradient descent to fit parameterized models to data. In the usual case, we’ll have some dataset and some  hypothesized  model for the data that depends  in a differentiable way  on one or more parameters. We’ll also have a loss function that measures how well the model fits our data.  Smaller is better.  If we think of our data as being fixed, then our loss function tells us how good or bad any particular model parameters are. This means we can use gradient descent to find the model parameters that make the loss as small as possible. Let’s look at a simple example:  In this case we know the parameters of the linear relationship between x and y, but imagine we’d like to learn them from the data. We’ll use gradient descent to find the slope and intercept that minimize the average squared error. We’ll start off with a function that determines the gradient based on the error from a single data point:     x   r a n g e s   f r o m   - 5 0   t o   4 9 ,   y   i s   a l w a y s   2 0   *   x   +   5   i n p u t s   =   [   x ,   2 0   *   x   +   5     f o r   x   i n   r a n g e   - 5 0 ,   5 0   ] d e f   l i n e a r _ g r a d i e n t   x :   f l o a t ,   y :   f l o a t ,   t h e t a :   V e c t o r     - >   V e c t o r :           s l o p e ,   i n t e r c e p t   =   t h e t a           p r e d i c t e d   =   s l o p e   *   x   +   i n t e r c e p t            T h e   p r e d i c t i o n   o f   t h e   m o d e l .           e r r o r   =     p r e d i c t e d   -   y                                  e r r o r   i s     p r e d i c t e d   -   a c t u a l   .           s q u a r e d _ e r r o r   =   e r r o r   * *   2                          W e ' l l   m i n i m i z e   s q u a r e d   e r r o r           g r a d   =   [ 2   *   e r r o r   *   x ,   2   *   e r r o r ]            u s i n g   i t s   g r a d i e n t .           r e t u r n   g r a d  r, is positive, which reflects the fact that small  Let’s think about what that gradient means. Imagine for some x our prediction is too large. In that case the e r is positive. The second gradient term, 2 increases in the intercept will make the  already too large  prediction even larger, which will cause the squared error  for this x  to get even bigger. The first gradient term, 2 enough, if x is positive, small increases in the slope will again make the prediction  and hence the error  larger. If x is negative, though, small increases in the slope will make the prediction  and hence the error  smaller. Now, that computation was for a single data point. For the whole dataset we’ll look at the mean squared error. And the gradient of the mean squared error is just the mean of the individual gradients. So, here’s what we’re going to do:  x, has the same sign as x. Sure  a. 1. Start with a random value for t 2. Compute the mean of the gradients.  3. Adjust t 4. Repeat.  a in that direction.  After a lot of epochs  what we call each pass through the dataset , we should learn something like the correct parameters:  r r o   *   e r r o   *   e r r o r   *   h e t h e t f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   v e c t o r _ m e a n        S t a r t   w i t h   r a n d o m   v a l u e s   f o r   s l o p e   a n d   i n t e r c e p t   t h e t a   =   [ r a n d o m . u n i f o r m   - 1 ,   1   ,   r a n d o m . u n i f o r m   - 1 ,   1   ]     l e a r n i n g _ r a t e   =   0 . 0 0 1     f o r   e p o c h   i n   r a n g e   5 0 0 0   :              C o m p u t e   t h e   m e a n   o f   t h e   g r a d i e n t s           g r a d   =   v e c t o r _ m e a n   [ l i n e a r _ g r a d i e n t   x ,   y ,   t h e t a     f o r   x ,   y   i n   i n p u t s ]                T a k e   a   s t e p   i n   t h a t   d i r e c t i o n           t h e t a   =   g r a d i e n t _ s t e p   t h e t a ,   g r a d ,   - l e a r n i n g _ r a t e             p r i n t   e p o c h ,   t h e t a      Minibatch and Stochastic Gradient Descent One drawback of the preceding approach is that we had to evaluate the gradients on the entire dataset before we could take a gradient step and update our parameters. In this case it was fine, because our dataset was only 100 pairs and the gradient computation was cheap. Your models, however, will frequently have large datasets and expensive gradient computations. In that case you’ll want to take gradient steps more often. We can do this using a technique called minibatch gradient descent, in which we compute the gradient  and take a gradient step  based on a “minibatch” sampled from the larger dataset:    s l o p e ,   i n t e r c e p t   =   t h e t a   a s s e r t   1 9 . 9   <   s l o p e   <   2 0 . 1 ,       " s l o p e   s h o u l d   b e   a b o u t   2 0 "   a s s e r t   4 . 9   <   i n t e r c e p t   <   5 . 1 ,   " i n t e r c e p t   s h o u l d   b e   a b o u t   5 " f r o m   t y p i n g   i m p o r t   T y p e V a r ,   L i s t ,   I t e r a t o r     T   =   T y p e V a r   ' T '          t h i s   a l l o w s   u s   t o   t y p e   " g e n e r i c "   f u n c t i o n s     d e f   m i n i b a t c h e s   d a t a s e t :   L i s t [ T ] ,                                   b a t c h _ s i z e :   i n t ,                                   s h u f f l e :   b o o l   =   T r u e     - >   I t e r a t o r [ L i s t [ T ] ] :           " " " G e n e r a t e s   ` b a t c h _ s i z e ` - s i z e d   m i n i b a t c h e s   f r o m   t h e   d a t a s e t " " "              s t a r t   i n d e x e s   0 ,   b a t c h _ s i z e ,   2   *   b a t c h _ s i z e ,   . . .           b a t c h _ s t a r t s   =   [ s t a r t   f o r   s t a r t   i n   r a n g e   0 ,   l e n   d a t a s e t   ,   b a t c h _ s i z e   ]             i f   s h u f f l e :   r a n d o m . s h u f f l e   b a t c h _ s t a r t s          s h u f f l e   t h e   b a t c h e s             f o r   s t a r t   i n   b a t c h _ s t a r t s :                   e n d   =   s t a r t   +   b a t c h _ s i z e                   y i e l d   d a t a s e t [ s t a r t : e n d ]  NOTE  The T be a list of any single type—s outputs will be batches of it.    allows us to create a “generic” function. It says that our d  t can  rs, i  ts, l  ts, whatever—but whatever that type is, the  Now we can solve our problem again using minibatches:  Another variation is stochastic gradient descent, in which you take gradient steps based on one training example at a time:  On this problem, stochastic gradient descent finds the optimal parameters in a much smaller number of epochs. But there are always tradeoffs. Basing gradient steps on small minibatches  or on single data points  allows you to take more of them, but the gradient for a single point might lie in a very different direction from the gradient for the dataset as a whole.  y p e V a r   T a t a s e t n i s t h e t a   =   [ r a n d o m . u n i f o r m   - 1 ,   1   ,   r a n d o m . u n i f o r m   - 1 ,   1   ]     f o r   e p o c h   i n   r a n g e   1 0 0 0   :           f o r   b a t c h   i n   m i n i b a t c h e s   i n p u t s ,   b a t c h _ s i z e = 2 0   :                   g r a d   =   v e c t o r _ m e a n   [ l i n e a r _ g r a d i e n t   x ,   y ,   t h e t a     f o r   x ,   y   i n   b a t c h ]                     t h e t a   =   g r a d i e n t _ s t e p   t h e t a ,   g r a d ,   - l e a r n i n g _ r a t e             p r i n t   e p o c h ,   t h e t a       s l o p e ,   i n t e r c e p t   =   t h e t a   a s s e r t   1 9 . 9   <   s l o p e   <   2 0 . 1 ,       " s l o p e   s h o u l d   b e   a b o u t   2 0 "   a s s e r t   4 . 9   <   i n t e r c e p t   <   5 . 1 ,   " i n t e r c e p t   s h o u l d   b e   a b o u t   5 " t h e t a   =   [ r a n d o m . u n i f o r m   - 1 ,   1   ,   r a n d o m . u n i f o r m   - 1 ,   1   ]     f o r   e p o c h   i n   r a n g e   1 0 0   :           f o r   x ,   y   i n   i n p u t s :                   g r a d   =   l i n e a r _ g r a d i e n t   x ,   y ,   t h e t a                     t h e t a   =   g r a d i e n t _ s t e p   t h e t a ,   g r a d ,   - l e a r n i n g _ r a t e             p r i n t   e p o c h ,   t h e t a       s l o p e ,   i n t e r c e p t   =   t h e t a   a s s e r t   1 9 . 9   <   s l o p e   <   2 0 . 1 ,       " s l o p e   s h o u l d   b e   a b o u t   2 0 "   a s s e r t   4 . 9   <   i n t e r c e p t   <   5 . 1 ,   " i n t e r c e p t   s h o u l d   b e   a b o u t   5 "  In addition, if we weren’t doing our linear algebra from scratch, there would be performance gains from “vectorizing” our computations across batches rather than computing the gradient one point at a time. Throughout the book, we’ll play around to find optimal batch sizes and step sizes.  NOTE  The terminology for the various flavors of gradient descent is not uniform. The “compute the gradient for the whole dataset” approach is often called batch gradient descent, and some people say stochastic gradient descent when referring to the minibatch version  of which the one-point-at-a-time version is a special case .  For Further Exploration  Keep reading! We’ll be using gradient descent to solve problems throughout the rest of the book. At this point, you’re undoubtedly sick of me recommending that you read textbooks. If it’s any consolation, Active Calculus 1.0, by Matthew Boelkins, David Austin, and Steven Schlicker  Grand Valley State University Libraries , seems nicer than the calculus textbooks I learned from. Sebastian Ruder has an epic blog post comparing gradient descent and its many variants.   Chapter 9. Getting Data  To write it, it took three months; to conceive it, three minutes; to collect the data in it, all my life.  —F. Scott Fitzgerald  In order to be a data scientist you need data. In fact, as a data scientist you will spend an embarrassingly large fraction of your time acquiring, cleaning, and transforming data. In a pinch, you can always type the data in yourself  or if you have minions, make them do it , but usually this is not a good use of your time. In this chapter, we’ll look at different ways of getting data into Python and into the right formats.  stdin and stdout If you run your Python scripts at the command line, you can pipe data t. For example, here is a through them using s script that reads in lines of text and spits back out the ones that match a regular expression:  n and s  y s . s t d i y s . s t d o u    e g r e p . p y   i m p o r t   s y s ,   r e        s y s . a r g v   i s   t h e   l i s t   o f   c o m m a n d - l i n e   a r g u m e n t s      s y s . a r g v [ 0 ]   i s   t h e   n a m e   o f   t h e   p r o g r a m   i t s e l f      s y s . a r g v [ 1 ]   w i l l   b e   t h e   r e g e x   s p e c i f i e d   a t   t h e   c o m m a n d   l i n e   r e g e x   =   s y s . a r g v [ 1 ]        f o r   e v e r y   l i n e   p a s s e d   i n t o   t h e   s c r i p t   f o r   l i n e   i n   s y s . s t d i n :              i f   i t   m a t c h e s   t h e   r e g e x ,   w r i t e   i t   t o   s t d o u t           i f   r e . s e a r c h   r e g e x ,   l i n e   :                   s y s . s t d o u t . w r i t e   l i n e    And here’s one that counts the lines it receives and then writes out the count:  You could then use these to count how many lines of a file contain numbers. In Windows, you’d use:  whereas in a Unix system you’d use:  The  is the pipe character, which means “use the output of the left command as the input of the right command.” You can build pretty elaborate data-processing pipelines this way.  If you are using Windows, you can probably leave out the p  n part of this command:  NOTE  If you are on a Unix system, doing so requires a couple more steps. First add a “shebang” as the first line of your script  n. Then, at the command line, use c   x egrep.py++ to make the file executable.     l i n e _ c o u n t . p y   i m p o r t   s y s     c o u n t   =   0   f o r   l i n e   i n   s y s . s t d i n :           c o u n t   + =   1        p r i n t   g o e s   t o   s y s . s t d o u t   p r i n t   c o u n t   t y p e   S o m e F i l e . t x t      p y t h o n   e g r e p . p y   " [ 0 - 9 ] "      p y t h o n   l i n e _ c o u n t . p y c a t   S o m e F i l e . t x t      p y t h o n   e g r e p . p y   " [ 0 - 9 ] "      p y t h o n   l i n e _ c o u n t . p y y t h o t y p e   S o m e F i l e . t x t      e g r e p . p y   " [ 0 - 9 ] "      l i n e _ c o u n t . p y !   u s r   b i n   e n v   p y t h o h m o d  Similarly, here’s a script that counts the words in its input and writes out the most common ones:  after which you could do something like:   If you are using Windows, then use t  e instead of c  t.      m o s t _ c o m m o n _ w o r d s . p y   i m p o r t   s y s   f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r        p a s s   i n   n u m b e r   o f   w o r d s   a s   f i r s t   a r g u m e n t   t r y :           n u m _ w o r d s   =   i n t   s y s . a r g v [ 1 ]     e x c e p t :           p r i n t   " u s a g e :   m o s t _ c o m m o n _ w o r d s . p y   n u m _ w o r d s "             s y s . e x i t   1            n o n z e r o   e x i t   c o d e   i n d i c a t e s   e r r o r     c o u n t e r   =   C o u n t e r   w o r d . l o w e r                                                    l o w e r c a s e   w o r d s                                       f o r   l i n e   i n   s y s . s t d i n                                       f o r   w o r d   i n   l i n e . s t r i p     . s p l i t            s p l i t   o n   s p a c e s                                       i f   w o r d                                                          s k i p   e m p t y   ' w o r d s '     f o r   w o r d ,   c o u n t   i n   c o u n t e r . m o s t _ c o m m o n   n u m _ w o r d s   :           s y s . s t d o u t . w r i t e   s t r   c o u n t               s y s . s t d o u t . w r i t e   " \ t "             s y s . s t d o u t . w r i t e   w o r d             s y s . s t d o u t . w r i t e   " \ n "   $   c a t   t h e _ b i b l e . t x t      p y t h o n   m o s t _ c o m m o n _ w o r d s . p y   1 0   3 6 3 9 7   t h e   3 0 0 3 1   a n d   2 0 1 6 3   o f   7 1 5 4   t o   6 4 8 4   i n   5 8 5 6   t h a t   5 4 2 1   h e   5 2 2 6   h i s   5 0 6 0   u n t o   4 2 9 7   s h a l l y p a  NOTE  If you are a seasoned Unix programmer, you are probably familiar with a wide variety of command-line tools  for example, e p  that are built into your operating system and are preferable to building your own from scratch. Still, it’s good to know you can if you need to.  Reading Files You can also explicitly read from and write to files directly in your code. Python makes working with files pretty simple.  The Basics of Text Files The first step to working with a text file is to obtain a file object using o  n:  Because it is easy to forget to close your files, you should always use them in a w  h block, at the end of which they will be closed automatically:  g r e p e    ' r '   m e a n s   r e a d - o n l y ,   i t ' s   a s s u m e d   i f   y o u   l e a v e   i t   o u t   f i l e _ f o r _ r e a d i n g   =   o p e n   ' r e a d i n g _ f i l e . t x t ' ,   ' r '     f i l e _ f o r _ r e a d i n g 2   =   o p e n   ' r e a d i n g _ f i l e . t x t '          ' w '   i s   w r i t e   - -   w i l l   d e s t r o y   t h e   f i l e   i f   i t   a l r e a d y   e x i s t s !   f i l e _ f o r _ w r i t i n g   =   o p e n   ' w r i t i n g _ f i l e . t x t ' ,   ' w '          ' a '   i s   a p p e n d   - -   f o r   a d d i n g   t o   t h e   e n d   o f   t h e   f i l e   f i l e _ f o r _ a p p e n d i n g   =   o p e n   ' a p p e n d i n g _ f i l e . t x t ' ,   ' a '          d o n ' t   f o r g e t   t o   c l o s e   y o u r   f i l e s   w h e n   y o u ' r e   d o n e   f i l e _ f o r _ w r i t i n g . c l o s e     i t w i t h   o p e n   f i l e n a m e     a s   f :           d a t a   =   f u n c t i o n _ t h a t _ g e t s _ d a t a _ f r o m   f          a t   t h i s   p o i n t   f   h a s   a l r e a d y   b e e n   c l o s e d ,   s o   d o n ' t   t r y   t o   u s e   i t   p r o c e s s   d a t a    If you need to read a whole text file, you can just iterate over the lines of the file using f  r:  p it before doing anything with it.  Every line you get this way ends in a newline character, so you’ll often want to s For example, imagine you have a file full of email addresses, one per line, and you need to generate a histogram of the domains. The rules for correctly extracting domains are somewhat subtle—see, e.g., the Public Suffix List—but a good first approximation is to just take the parts of the email addresses that come after the @  this gives the wrong answer for email addresses like joel@mail.datasciencester.com, but for the purposes of this example we’re willing to live with that :  Delimited Files The hypothetical email addresses file we just processed had one address per line. More frequently you’ll work with files with lots of data on each line.  o s t a r t s _ w i t h _ h a s h   =   0     w i t h   o p e n   ' i n p u t . t x t '     a s   f :           f o r   l i n e   i n   f :                                        l o o k   a t   e a c h   l i n e   i n   t h e   f i l e                   i f   r e . m a t c h   " ^  " , l i n e   :              u s e   a   r e g e x   t o   s e e   i f   i t   s t a r t s   w i t h   '  '                           s t a r t s _ w i t h _ h a s h   + =   1          i f   i t   d o e s ,   a d d   1   t o   t h e   c o u n t t r i d e f   g e t _ d o m a i n   e m a i l _ a d d r e s s :   s t r     - >   s t r :           " " " S p l i t   o n   ' @ '   a n d   r e t u r n   t h e   l a s t   p i e c e " " "           r e t u r n   e m a i l _ a d d r e s s . l o w e r     . s p l i t   " @ "   [ - 1 ]        a   c o u p l e   o f   t e s t s   a s s e r t   g e t _ d o m a i n   ' j o e l g r u s @ g m a i l . c o m '     = =   ' g m a i l . c o m '   a s s e r t   g e t _ d o m a i n   ' j o e l @ m . d a t a s c i e n c e s t e r . c o m '     = =   ' m . d a t a s c i e n c e s t e r . c o m '     f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     w i t h   o p e n   ' e m a i l _ a d d r e s s e s . t x t ' ,   ' r '     a s   f :           d o m a i n _ c o u n t s   =   C o u n t e r   g e t _ d o m a i n   l i n e . s t r i p                                                                 f o r   l i n e   i n   f                                                           i f   " @ "   i n   l i n e    These files are very often either comma-separated or tab-separated: each line has several fields, with a comma or a tab indicating where one field ends and the next field starts. This starts to get complicated when you have fields with commas and tabs and newlines in them  which you inevitably will . For this reason, you should never try to parse them yourself. Instead, you should use Python’s v module  or the pandas library, or some other library that’s designed to  read comma-separated or tab-delimited files .  Never parse a comma-separated file yourself. You will screw up the edge cases!  WARNING  If your file has no headers  which means you probably want each row as a t, and which places the burden on you to know what’s in each column , r to iterate over the rows, each of which will be an  you can use c appropriately split list. For example, if we had a tab-delimited file of stock prices:  we could process them with:  c s l i s s v . r e a d e 6   2 0   2 0 1 4       A A P L         9 0 . 9 1   6   2 0   2 0 1 4       M S F T         4 1 . 6 8   6   2 0   2 0 1 4       F B     6 4 . 5   6   1 9   2 0 1 4       A A P L         9 1 . 8 6   6   1 9   2 0 1 4       M S F T         4 1 . 5 1   6   1 9   2 0 1 4       F B     6 4 . 3 4 i m p o r t   c s v     w i t h   o p e n   ' t a b _ d e l i m i t e d _ s t o c k _ p r i c e s . t x t '     a s   f :           t a b _ r e a d e r   =   c s v . r e a d e r   f ,   d e l i m i t e r = ' \ t '             f o r   r o w   i n   t a b _ r e a d e r :                   d a t e   =   r o w [ 0 ]                   s y m b o l   =   r o w [ 1 ]    If your file has headers:  you can either skip the header row with an initial call to r get each row as a d t  with the headers as keys  by using r:  t, or  Even if your file doesn’t have headers, you can still use D passing it the keys as a f You can similarly write out delimited data using c  s parameter.  r:  r by  r will do the right thing if your fields themselves have commas in them. Your own hand-rolled writer probably won’t. For example, if you attempt:                  c l o s i n g _ p r i c e   =   f l o a t   r o w [ 2 ]                     p r o c e s s   d a t e ,   s y m b o l ,   c l o s i n g _ p r i c e   d a t e : s y m b o l : c l o s i n g _ p r i c e   6   2 0   2 0 1 4 : A A P L : 9 0 . 9 1   6   2 0   2 0 1 4 : M S F T : 4 1 . 6 8   6   2 0   2 0 1 4 : F B : 6 4 . 5 e a d e r . n e x i c c s v . D i c t R e a d e w i t h   o p e n   ' c o l o n _ d e l i m i t e d _ s t o c k _ p r i c e s . t x t '     a s   f :           c o l o n _ r e a d e r   =   c s v . D i c t R e a d e r   f ,   d e l i m i t e r = ' : '             f o r   d i c t _ r o w   i n   c o l o n _ r e a d e r :                   d a t e   =   d i c t _ r o w [ " d a t e " ]                   s y m b o l   =   d i c t _ r o w [ " s y m b o l " ]                   c l o s i n g _ p r i c e   =   f l o a t   d i c t _ r o w [ " c l o s i n g _ p r i c e " ]                     p r o c e s s   d a t e ,   s y m b o l ,   c l o s i n g _ p r i c e   i c t R e a d e i e l d n a m e s v . w r i t e t o d a y s _ p r i c e s   =   { ' A A P L ' :   9 0 . 9 1 ,   ' M S F T ' :   4 1 . 6 8 ,   ' F B ' :   6 4 . 5   }     w i t h   o p e n   ' c o m m a _ d e l i m i t e d _ s t o c k _ p r i c e s . t x t ' ,   ' w '     a s   f :           c s v _ w r i t e r   =   c s v . w r i t e r   f ,   d e l i m i t e r = ' , '             f o r   s t o c k ,   p r i c e   i n   t o d a y s _ p r i c e s . i t e m s     :                   c s v _ w r i t e r . w r i t e r o w   [ s t o c k ,   p r i c e ]   c s v . w r i t e r e s u l t s   =   [ [ " t e s t 1 " ,   " s u c c e s s " ,   " M o n d a y " ] ,                         [ " t e s t 2 " ,   " s u c c e s s ,   k i n d   o f " ,   " T u e s d a y " ] ,    You will end up with a .csv file that looks like this:  and that no one will ever be able to make sense of.  Scraping the Web Another way to get data is by scraping it from web pages. Fetching web pages, it turns out, is pretty easy; getting meaningful structured information out of them less so.  HTML and the Parsing Thereof Pages on the web are written in HTML, in which text is  ideally  marked up into elements and their attributes:                        [ " t e s t 3 " ,   " f a i l u r e ,   k i n d   o f " ,   " W e d n e s d a y " ] ,                         [ " t e s t 4 " ,   " f a i l u r e ,   u t t e r " ,   " T h u r s d a y " ] ]        d o n ' t   d o   t h i s !   w i t h   o p e n   ' b a d _ c s v . t x t ' ,   ' w '     a s   f :           f o r   r o w   i n   r e s u l t s :                   f . w r i t e   " , " . j o i n   m a p   s t r ,   r o w            m i g h t   h a v e   t o o   m a n y   c o m m a s   i n   i t !                   f . w r i t e   " \ n "                                              r o w   m i g h t   h a v e   n e w l i n e s   a s   w e l l ! t e s t 1 , s u c c e s s , M o n d a y   t e s t 2 , s u c c e s s ,   k i n d   o f , T u e s d a y   t e s t 3 , f a i l u r e ,   k i n d   o f , W e d n e s d a y   t e s t 4 , f a i l u r e ,   u t t e r , T h u r s d a y < h t m l >       < h e a d >           < t i t l e > A   w e b   p a g e <   t i t l e >       <   h e a d >       < b o d y >           < p   i d = " a u t h o r " > J o e l   G r u s <   p >           < p   i d = " s u b j e c t " > D a t a   S c i e n c e <   p >       <   b o d y >   <   h t m l >  d is s  In a perfect world, where all web pages were marked up semantically for our benefit, we would be able to extract data using rules like “find the < t and return the text it contains.” In the actual element whose i world, HTML is not generally well formed, let alone annotated. This means we’ll need help making sense of it. To get data out of HTML, we will use the Beautiful Soup library, which builds a tree out of the various elements on a web page and provides a simple interface for accessing them. As I write this, the latest version is Beautiful Soup 4.6.0, which is what we’ll be using. We’ll also be using the Requests library, which is a much nicer way of making HTTP requests than anything that’s built into Python. Python’s built-in HTML parser is not that lenient, which means that it doesn’t always cope well with HTML that’s not perfectly formed. For that reason, we’ll also install the h Making sure you’re in the correct virtual environment, install the libraries:  b parser.  To use Beautiful Soup, we pass a string containing HTML into the  p function. In our examples, this will be the result of a call to t:  after which we can get pretty far using a few simple methods.  p > u b j e c t m l 5 l i p y t h o n   - m   p i p   i n s t a l l   b e a u t i f u l s o u p 4   r e q u e s t s   h t m l 5 l i b B e a u t i f u l S o u r e q u e s t s . g e f r o m   b s 4   i m p o r t   B e a u t i f u l S o u p   i m p o r t   r e q u e s t s        I   p u t   t h e   r e l e v a n t   H T M L   f i l e   o n   G i t H u b .   I n   o r d e r   t o   f i t      t h e   U R L   i n   t h e   b o o k   I   h a d   t o   s p l i t   i t   a c r o s s   t w o   l i n e s .      R e c a l l   t h a t   w h i t e s p a c e - s e p a r a t e d   s t r i n g s   g e t   c o n c a t e n a t e d .   u r l   =     " h t t p s :     r a w . g i t h u b u s e r c o n t e n t . c o m   "                 " j o e l g r u s   d a t a   m a s t e r   g e t t i n g - d a t a . h t m l "     h t m l   =   r e q u e s t s . g e t   u r l   . t e x t   s o u p   =   B e a u t i f u l S o u p   h t m l ,   ' h t m l 5 l i b '    We’ll typically work with T representing the structure of an HTML page. For example, to find the first <  g objects, which correspond to the tags  > tag  and its contents , you can use:  You can get the text contents of a T  g using its t  t property:  And you can extract a tag’s attributes by treating it like a d  t:  You can get multiple tags at once as follows:  Frequently, you’ll want to find tags with a specific c  s:  And you can combine these methods to implement more elaborate logic. For example, if you want to find every < > element that is contained inside a <  > element, you could do this:  a p f i r s t _ p a r a g r a p h   =   s o u p . f i n d   ' p '                      o r   j u s t   s o u p . p a e x f i r s t _ p a r a g r a p h _ t e x t   =   s o u p . p . t e x t   f i r s t _ p a r a g r a p h _ w o r d s   =   s o u p . p . t e x t . s p l i t     i c f i r s t _ p a r a g r a p h _ i d   =   s o u p . p [ ' i d ' ]                  r a i s e s   K e y E r r o r   i f   n o   ' i d '   f i r s t _ p a r a g r a p h _ i d 2   =   s o u p . p . g e t   ' i d '          r e t u r n s   N o n e   i f   n o   ' i d ' a l l _ p a r a g r a p h s   =   s o u p . f i n d _ a l l   ' p '          o r   j u s t   s o u p   ' p '     p a r a g r a p h s _ w i t h _ i d s   =   [ p   f o r   p   i n   s o u p   ' p '     i f   p . g e t   ' i d '   ] l a s i m p o r t a n t _ p a r a g r a p h s   =   s o u p   ' p ' ,   { ' c l a s s '   :   ' i m p o r t a n t ' }     i m p o r t a n t _ p a r a g r a p h s 2   =   s o u p   ' p ' ,   ' i m p o r t a n t '     i m p o r t a n t _ p a r a g r a p h s 3   =   [ p   f o r   p   i n   s o u p   ' p '                                                       i f   ' i m p o r t a n t '   i n   p . g e t   ' c l a s s ' ,   [ ]   ] s p a n d i v    W a r n i n g :   w i l l   r e t u r n   t h e   s a m e   < s p a n >   m u l t i p l e   t i m e s      i f   i t   s i t s   i n s i d e   m u l t i p l e   < d i v > s .      B e   m o r e   c l e v e r   i f   t h a t ' s   t h e   c a s e .   s p a n s _ i n s i d e _ d i v s   =   [ s p a n                                             f o r   d i v   i n   s o u p   ' d i v '                f o r   e a c h   < d i v >   o n   t h e   p a g e                                             f o r   s p a n   i n   d i v   ' s p a n '   ]          f i n d   e a c h   < s p a n >   i n s i d e   i t  Just this handful of features will allow us to do quite a lot. If you end up needing to do more complicated things  or if you’re just curious , check the documentation. Of course, the important data won’t typically be labeled as  ". You’ll need to carefully inspect the source HTML, reason through your selection logic, and worry about edge cases to make sure your data is correct. Let’s look at an example.  Example: Keeping Tabs on Congress The VP of Policy at DataSciencester is worried about potential regulation of the data science industry and asks you to quantify what Congress is saying on the topic. In particular, he wants you to find all the representatives who have press releases about “data.” At the time of publication, there is a page with links to all of the representatives’ websites at https:  www.house.gov representatives. And if you “view source,” all of the links to the websites look like:  Let’s start by collecting all of the URLs linked to from that page:  c l a s s = " i m p o r t a n t < t d >       < a   h r e f = " h t t p s :     j a y a p a l . h o u s e . g o v " > J a y a p a l ,   P r a m i l a <   a >   <   t d > f r o m   b s 4   i m p o r t   B e a u t i f u l S o u p   i m p o r t   r e q u e s t s     u r l   =   " h t t p s :     w w w . h o u s e . g o v   r e p r e s e n t a t i v e s "   t e x t   =   r e q u e s t s . g e t   u r l   . t e x t   s o u p   =   B e a u t i f u l S o u p   t e x t ,   " h t m l 5 l i b "       a l l _ u r l s   =   [ a [ ' h r e f ' ]                           f o r   a   i n   s o u p   ' a '                             i f   a . h a s _ a t t r   ' h r e f '   ]     p r i n t   l e n   a l l _ u r l s            9 6 5   f o r   m e ,   w a y   t o o   m a n y  This returns way too many URLs. If you look at them, the ones we want start with either http:   or https:  , have some kind of name, and end with either .house.gov or .house.gov . This is a good place to use a regular expression:  That’s still way too many, as there are only 435 representatives. If you look at the list, there are a lot of duplicates. Let’s use s  t to get rid of them:  There are always a couple of House seats empty, or maybe there’s a representative without a website. In any case, this is good enough. When we look at the sites, most of them have a link to press releases. For example:  i m p o r t   r e        M u s t   s t a r t   w i t h   h t t p :       o r   h t t p s :          M u s t   e n d   w i t h   . h o u s e . g o v   o r   . h o u s e . g o v     r e g e x   =   r " ^ h t t p s ? :     . * \ . h o u s e \ . g o v   ? $ "        L e t ' s   w r i t e   s o m e   t e s t s !   a s s e r t   r e . m a t c h   r e g e x ,   " h t t p :     j o e l . h o u s e . g o v "     a s s e r t   r e . m a t c h   r e g e x ,   " h t t p s :     j o e l . h o u s e . g o v "     a s s e r t   r e . m a t c h   r e g e x ,   " h t t p :     j o e l . h o u s e . g o v   "     a s s e r t   r e . m a t c h   r e g e x ,   " h t t p s :     j o e l . h o u s e . g o v   "     a s s e r t   n o t   r e . m a t c h   r e g e x ,   " j o e l . h o u s e . g o v "     a s s e r t   n o t   r e . m a t c h   r e g e x ,   " h t t p :     j o e l . h o u s e . c o m "     a s s e r t   n o t   r e . m a t c h   r e g e x ,   " h t t p s :     j o e l . h o u s e . g o v   b i o g r a p h y "          A n d   n o w   a p p l y   g o o d _ u r l s   =   [ u r l   f o r   u r l   i n   a l l _ u r l s   i f   r e . m a t c h   r e g e x ,   u r l   ]     p r i n t   l e n   g o o d _ u r l s            s t i l l   8 6 2   f o r   m e e g o o d _ u r l s   =   l i s t   s e t   g o o d _ u r l s         p r i n t   l e n   g o o d _ u r l s            o n l y   4 3 1   f o r   m e h t m l   =   r e q u e s t s . g e t   ' h t t p s :     j a y a p a l . h o u s e . g o v '   . t e x t   s o u p   =   B e a u t i f u l S o u p   h t m l ,   ' h t m l 5 l i b '          U s e   a   s e t   b e c a u s e   t h e   l i n k s   m i g h t   a p p e a r   m u l t i p l e   t i m e s .   l i n k s   =   { a [ ' h r e f ' ]   f o r   a   i n   s o u p   ' a '     i f   ' p r e s s   r e l e a s e s '   i n   a . t e x t . l o w e r     }    Notice that this is a relative link, which means we need to remember the originating site. Let’s do some scraping:  NOTE  Normally it is impolite to scrape a site freely like this. Most sites will have a robots.txt file that indicates how frequently you may scrape the site  and which paths you’re not supposed to scrape , but since it’s Congress we don’t need to be particularly polite.  If you watch these as they scroll by, you’ll see a lot of  media press-releases and media-center press-releases, as well as various other addresses. One of these URLs is https:  jayapal.house.gov media press-releases. Remember that our goal is to find out which congresspeople have press releases mentioning “data.” We’ll write a slightly more general function that checks whether a page of press releases mentions any given term. If you visit the site and view the source, it seems like there’s a snippet from each press release inside a <  > tag, so we’ll use that as our first attempt:    p r i n t   l i n k s        { '   m e d i a   p r e s s - r e l e a s e s ' } f r o m   t y p i n g   i m p o r t   D i c t ,   S e t     p r e s s _ r e l e a s e s :   D i c t [ s t r ,   S e t [ s t r ] ]   =   { }     f o r   h o u s e _ u r l   i n   g o o d _ u r l s :           h t m l   =   r e q u e s t s . g e t   h o u s e _ u r l   . t e x t           s o u p   =   B e a u t i f u l S o u p   h t m l ,   ' h t m l 5 l i b '             p r _ l i n k s   =   { a [ ' h r e f ' ]   f o r   a   i n   s o u p   ' a '     i f   ' p r e s s   r e l e a s e s '                                                                                             i n   a . t e x t . l o w e r     }           p r i n t   f " { h o u s e _ u r l } :   { p r _ l i n k s } "             p r e s s _ r e l e a s e s [ h o u s e _ u r l ]   =   p r _ l i n k s p d e f   p a r a g r a p h _ m e n t i o n s   t e x t :   s t r ,   k e y w o r d :   s t r     - >   b o o l :           " " "           R e t u r n s   T r u e   i f   a   < p >   i n s i d e   t h e   t e x t   m e n t i o n s   { k e y w o r d }           " " "           s o u p   =   B e a u t i f u l S o u p   t e x t ,   ' h t m l 5 l i b '      Let’s write a quick test for it:  At last we’re ready to find the relevant congresspeople and give their names to the VP:  When I run this I get a list of about 20 representatives. Your results will probably be different.  NOTE  If you look at the various “press releases” pages, most of them are paginated with only 5 or 10 press releases per page. This means that we only retrieved the few most recent press releases for each congressperson. A more thorough solution would have iterated over the pages and retrieved the full text of each press release.  Using APIs Many websites and web services provide application programming interfaces  APIs , which allow you to explicitly request data in a structured format. This saves you the trouble of having to scrape them!          p a r a g r a p h s   =   [ p . g e t _ t e x t       f o r   p   i n   s o u p   ' p '   ]             r e t u r n   a n y   k e y w o r d . l o w e r       i n   p a r a g r a p h . l o w e r                                     f o r   p a r a g r a p h   i n   p a r a g r a p h s   t e x t   =   " " " < b o d y > < h 1 > F a c e b o o k <   h 1 > < p > T w i t t e r <   p > " " "   a s s e r t   p a r a g r a p h _ m e n t i o n s   t e x t ,   " t w i t t e r "                    i s   i n s i d e   a   < p >   a s s e r t   n o t   p a r a g r a p h _ m e n t i o n s   t e x t ,   " f a c e b o o k "          n o t   i n s i d e   a   < p > f o r   h o u s e _ u r l ,   p r _ l i n k s   i n   p r e s s _ r e l e a s e s . i t e m s     :           f o r   p r _ l i n k   i n   p r _ l i n k s :                   u r l   =   f " { h o u s e _ u r l }   { p r _ l i n k } "                   t e x t   =   r e q u e s t s . g e t   u r l   . t e x t                     i f   p a r a g r a p h _ m e n t i o n s   t e x t ,   ' d a t a '   :                           p r i n t   f " { h o u s e _ u r l } "                             b r e a k        d o n e   w i t h   t h i s   h o u s e _ u r l  JSON and XML Because HTTP is a protocol for transferring text, the data you request through a web API needs to be serialized into a string format. Often this serialization uses JavaScript Object Notation  JSON . JavaScript objects look quite similar to Python d easy to interpret:  ts, which makes their string representations  n module. In particular, we will use s function, which deserializes a string representing a JSON object  We can parse JSON using Python’s j its l into a Python object:  Sometimes an API provider hates you and provides only responses in XML:  i c {   " t i t l e "   :   " D a t a   S c i e n c e   B o o k " ,       " a u t h o r "   :   " J o e l   G r u s " ,       " p u b l i c a t i o n Y e a r "   :   2 0 1 9 ,       " t o p i c s "   :   [   " d a t a " ,   " s c i e n c e " ,   " d a t a   s c i e n c e " ]   } s o o a d i m p o r t   j s o n   s e r i a l i z e d   =   " " " {   " t i t l e "   :   " D a t a   S c i e n c e   B o o k " ,                                       " a u t h o r "   :   " J o e l   G r u s " ,                                       " p u b l i c a t i o n Y e a r "   :   2 0 1 9 ,                                       " t o p i c s "   :   [   " d a t a " ,   " s c i e n c e " ,   " d a t a   s c i e n c e " ]   } " " "        p a r s e   t h e   J S O N   t o   c r e a t e   a   P y t h o n   d i c t   d e s e r i a l i z e d   =   j s o n . l o a d s   s e r i a l i z e d     a s s e r t   d e s e r i a l i z e d [ " p u b l i c a t i o n Y e a r " ]   = =   2 0 1 9   a s s e r t   " d a t a   s c i e n c e "   i n   d e s e r i a l i z e d [ " t o p i c s " ] < B o o k >       < T i t l e > D a t a   S c i e n c e   B o o k <   T i t l e >       < A u t h o r > J o e l   G r u s <   A u t h o r >       < P u b l i c a t i o n Y e a r > 2 0 1 4 <   P u b l i c a t i o n Y e a r >       < T o p i c s >           < T o p i c > d a t a <   T o p i c >           < T o p i c > s c i e n c e <   T o p i c >           < T o p i c > d a t a   s c i e n c e <   T o p i c >       <   T o p i c s >   <   B o o k >  You can use Beautiful Soup to get data from XML similarly to how we used it to get data from HTML; check its documentation for details.  Using an Unauthenticated API Most APIs these days require that you first authenticate yourself before you can use them. While we don’t begrudge them this policy, it creates a lot of extra boilerplate that muddies up our exposition. Accordingly, we’ll start by taking a look at GitHub’s API, with which you can do some simple things unauthenticated:  s is a l  t of Python d  At this point r ts, each representing a public repository in my GitHub account.  Feel free to substitute your username and get your GitHub repository data instead. You do have a GitHub account, right?  We can use this to figure out which months and days of the week I’m most likely to create a repository. The only issue is that the dates in the response are strings:  Python doesn’t come with a great date parser, so we’ll need to install one:  from which you’ll probably only ever need the d function:  i m p o r t   r e q u e s t s ,   j s o n     g i t h u b _ u s e r   =   " j o e l g r u s "   e n d p o i n t   =   f " h t t p s :     a p i . g i t h u b . c o m   u s e r s   { g i t h u b _ u s e r }   r e p o s "     r e p o s   =   j s o n . l o a d s   r e q u e s t s . g e t   e n d p o i n t   . t e x t   e p o i s i c " c r e a t e d _ a t " :   " 2 0 1 3 - 0 7 - 0 5 T 0 2 : 0 2 : 2 8 Z " p y t h o n   - m   p i p   i n s t a l l   p y t h o n - d a t e u t i l a t e u t i l . p a r s e r . p a r s e f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r   f r o m   d a t e u t i l . p a r s e r   i m p o r t   p a r s e    Similarly, you can get the languages of my last five repositories:  Typically we won’t be working with APIs at this low “make the requests and parse the responses ourselves” level. One of the benefits of using Python is that someone has already built a library for pretty much any API you’re interested in accessing. When they’re done well, these libraries can save you a lot of the trouble of figuring out the hairier details of API access.  When they’re not done well, or when it turns out they’re based on defunct versions of the corresponding APIs, they can cause you enormous headaches.  Nonetheless, you’ll occasionally have to roll your own API access library  or, more likely, debug why someone else’s isn’t working , so it’s good to know some of the details.  Finding APIs If you need data from a specific site, look for a “developers” or “API” section of the site for details, and try searching the web for “python   api” to find a library. There are libraries for the Yelp API, for the Instagram API, for the Spotify API, and so on. If you’re looking for a list of APIs that have Python wrappers, there’s a nice one from Real Python on GitHub.    d a t e s   =   [ p a r s e   r e p o [ " c r e a t e d _ a t " ]     f o r   r e p o   i n   r e p o s ]   m o n t h _ c o u n t s   =   C o u n t e r   d a t e . m o n t h   f o r   d a t e   i n   d a t e s     w e e k d a y _ c o u n t s   =   C o u n t e r   d a t e . w e e k d a y       f o r   d a t e   i n   d a t e s   l a s t _ 5 _ r e p o s i t o r i e s   =   s o r t e d   r e p o s ,                                                             k e y = l a m b d a   r :   r [ " p u s h e d _ a t " ] ,                                                             r e v e r s e = T r u e   [ : 5 ]     l a s t _ 5 _ l a n g u a g e s   =   [ r e p o [ " l a n g u a g e " ]                                           f o r   r e p o   i n   l a s t _ 5 _ r e p o s i t o r i e s ]  And if you can’t find what you need, there’s always scraping, the last refuge of the data scientist.  Example: Using the Twitter APIs Twitter is a fantastic source of data to work with. You can use it to get real- time news. You can use it to measure reactions to current events. You can use it to find links related to specific topics. You can use it for pretty much anything you can imagine, just as long as you can get access to its data. And you can get access to its data through its APIs. To interact with the Twitter APIs, we’ll be using the Twython library  p n . There are quite a few Python Twitter libraries out there, but this is the one that I’ve had the most success working with. You are encouraged to explore the others as well!  Getting Credentials In order to use Twitter’s APIs, you need to get some credentials  for which you need a Twitter account, which you should have anyway so that you can be part of the lively and friendly Twitter datascience community .  WARNING  Like all instructions that relate to websites that I don’t control, these may become obsolete at some point but will hopefully work for a while.  Although they have already changed multiple times since I originally started writing this book, so good luck!   Here are the steps:  1. Go to https:  developer.twitter.com . 2. If you are not signed in, click “Sign in” and enter your Twitter  username and password.  3. Click Apply to apply for a developer account.  y t h o n   - m   p i p   i n s t a l l   t w y t h o  4. Request access for your own personal use. 5. Fill out the application. It requires 300 words  really  on why you need access, so to get over the limit you could tell them about this book and how much you’re enjoying it.  6. Wait some indefinite amount of time. 7. If you know someone who works at Twitter, email them and ask  them if they can expedite your application. Otherwise, keep waiting.  8. Once you get approved, go back to developer.twitter.com, find the  “Apps” section, and click “Create an app.”  9. Fill out all the required fields  again, if you need extra characters  for the description, you could talk about this book and how edifying you’re finding it .  10. Click CREATE.  Now your app should have a “Keys and tokens” tab with a “Consumer API keys” section that lists an “API key” and an “API secret key.” Take note of those keys; you’ll need them.  Also, keep them secret! They’re like passwords.   CAUTION  Don’t share the keys, don’t publish them in your book, and don’t check them into your public GitHub repository. One simple solution is to store them in a credentials.json file that doesn’t get checked in, and to have your code use j Another solution is to store them in environment variables and use o retrieve them.  s to retrieve them.  n to  Using Twython The trickiest part of using the Twitter API is authenticating yourself.  Indeed, this is the trickiest part of using a lot of APIs.  API providers want  s o n . l o a d s . e n v i r o  to make sure that you’re authorized to access their data and that you don’t exceed their usage limits. They also want to know who’s accessing their data. Authentication is kind of a pain. There is a simple way, OAuth 2, that suffices when you just want to do simple searches. And there is a complex way, OAuth 1, that’s required when you want to perform actions  e.g., tweeting  or  in particular for us  connect to the Twitter stream. So we’re stuck with the more complicated way, which we’ll try to automate as much as we can. First, you need your API key and API secret key  sometimes known as the consumer key and consumer secret, respectively . I’ll be getting mine from environment variables, but feel free to substitute in yours however you wish:  Now we can instantiate the client:  i m p o r t   o s        F e e l   f r e e   t o   p l u g   y o u r   k e y   a n d   s e c r e t   i n   d i r e c t l y   C O N S U M E R _ K E Y   =   o s . e n v i r o n . g e t   " T W I T T E R _ C O N S U M E R _ K E Y "     C O N S U M E R _ S E C R E T   =   o s . e n v i r o n . g e t   " T W I T T E R _ C O N S U M E R _ S E C R E T "   i m p o r t   w e b b r o w s e r   f r o m   t w y t h o n   i m p o r t   T w y t h o n        G e t   a   t e m p o r a r y   c l i e n t   t o   r e t r i e v e   a n   a u t h e n t i c a t i o n   U R L   t e m p _ c l i e n t   =   T w y t h o n   C O N S U M E R _ K E Y ,   C O N S U M E R _ S E C R E T     t e m p _ c r e d s   =   t e m p _ c l i e n t . g e t _ a u t h e n t i c a t i o n _ t o k e n s       u r l   =   t e m p _ c r e d s [ ' a u t h _ u r l ' ]        N o w   v i s i t   t h a t   U R L   t o   a u t h o r i z e   t h e   a p p l i c a t i o n   a n d   g e t   a   P I N   p r i n t   f " g o   v i s i t   { u r l }   a n d   g e t   t h e   P I N   c o d e   a n d   p a s t e   i t   b e l o w "     w e b b r o w s e r . o p e n   u r l     P I N _ C O D E   =   i n p u t   " p l e a s e   e n t e r   t h e   P I N   c o d e :   "          N o w   w e   u s e   t h a t   P I N _ C O D E   t o   g e t   t h e   a c t u a l   t o k e n s   a u t h _ c l i e n t   =   T w y t h o n   C O N S U M E R _ K E Y ,                                               C O N S U M E R _ S E C R E T ,                                               t e m p _ c r e d s [ ' o a u t h _ t o k e n ' ] ,    TIP  At this point you may want to consider saving the A  N and  T somewhere safe, so that next time you don’t have to go through  this rigmarole.  Once we have an authenticated T searches:  n instance, we can start performing  If you run this, you should get some tweets back like:  This isn’t that interesting, largely because the Twitter Search API just shows you whatever handful of recent results it feels like. When you’re doing data science, more often you want a lot of tweets. This is where the Streaming API is useful. It allows you to connect to  a sample of  the great                                              t e m p _ c r e d s [ ' o a u t h _ t o k e n _ s e c r e t ' ]     f i n a l _ s t e p   =   a u t h _ c l i e n t . g e t _ a u t h o r i z e d _ t o k e n s   P I N _ C O D E     A C C E S S _ T O K E N   =   f i n a l _ s t e p [ ' o a u t h _ t o k e n ' ]   A C C E S S _ T O K E N _ S E C R E T   =   f i n a l _ s t e p [ ' o a u t h _ t o k e n _ s e c r e t ' ]        A n d   g e t   a   n e w   T w y t h o n   i n s t a n c e   u s i n g   t h e m .   t w i t t e r   =   T w y t h o n   C O N S U M E R _ K E Y ,                                       C O N S U M E R _ S E C R E T ,                                       A C C E S S _ T O K E N ,                                       A C C E S S _ T O K E N _ S E C R E T   C C E S S _ T O K E A C C E S S _ T O K E N _ S E C R E w y t h o    S e a r c h   f o r   t w e e t s   c o n t a i n i n g   t h e   p h r a s e   " d a t a   s c i e n c e "   f o r   s t a t u s   i n   t w i t t e r . s e a r c h   q = ' " d a t a   s c i e n c e " '   [ " s t a t u s e s " ] :           u s e r   =   s t a t u s [ " u s e r " ] [ " s c r e e n _ n a m e " ]           t e x t   =   s t a t u s [ " t e x t " ]           p r i n t   f " { u s e r } :   { t e x t } \ n "   h a i t h e m n y c :   D a t a   s c i e n t i s t s   w i t h   t h e   t e c h n i c a l   s a v v y   & a m p ;   a n a l y t i c a l   c h o p s   t o   d e r i v e   m e a n i n g   f r o m   b i g   d a t a   a r e   i n   d e m a n d .   h t t p :     t . c o   H s F 9 Q 0 d S h P     R P u b s R e c e n t :   D a t a   S c i e n c e   h t t p :     t . c o   6 h c H U z 2 P H M     s p l e o n a r d 1 :   U s i n g    d p l y r   i n    R   t o   w o r k   t h r o u g h   a   p r o c r a s t i n a t e d   a s s i g n m e n t   f o r   @ r d p e n g   i n   @ c o u r s e r a   d a t a   s c i e n c e   s p e c i a l i z a t i o n .   S o   e a s y   a n d   A w e s o m e .  Twitter firehose. To use it, you’ll need to authenticate using your access tokens. In order to access the Streaming API with Twython, we need to define a class that inherits from T  r and that overrides its  s method, and possibly its o  r method:  r will connect to the Twitter stream and wait for Twitter to feed  s method, which appends it to s list if its language is English, and then disconnects the streamer  it data. Each time it receives some data  here, a tweet represented as a Python object , it passes it to the o our t after it’s collected 1,000 tweets. All that’s left is to initialize it and start it running:  w y t h o n S t r e a m e o n _ s u c c e s n _ e r r o f r o m   t w y t h o n   i m p o r t   T w y t h o n S t r e a m e r        A p p e n d i n g   d a t a   t o   a   g l o b a l   v a r i a b l e   i s   p r e t t y   p o o r   f o r m      b u t   i t   m a k e s   t h e   e x a m p l e   m u c h   s i m p l e r   t w e e t s   =   [ ]     c l a s s   M y S t r e a m e r   T w y t h o n S t r e a m e r   :           d e f   o n _ s u c c e s s   s e l f ,   d a t a   :                   " " "                   W h a t   d o   w e   d o   w h e n   T w i t t e r   s e n d s   u s   d a t a ?                   H e r e   d a t a   w i l l   b e   a   P y t h o n   d i c t   r e p r e s e n t i n g   a   t w e e t .                   " " "                      W e   o n l y   w a n t   t o   c o l l e c t   E n g l i s h - l a n g u a g e   t w e e t s                   i f   d a t a . g e t   ' l a n g '     = =   ' e n ' :                           t w e e t s . a p p e n d   d a t a                             p r i n t   f " r e c e i v e d   t w e e t    { l e n   t w e e t s   } "                          S t o p   w h e n   w e ' v e   c o l l e c t e d   e n o u g h                   i f   l e n   t w e e t s     > =   1 0 0 :                           s e l f . d i s c o n n e c t                 d e f   o n _ e r r o r   s e l f ,   s t a t u s _ c o d e ,   d a t a   :                   p r i n t   s t a t u s _ c o d e ,   d a t a                     s e l f . d i s c o n n e c t     M y S t r e a m e n _ s u c c e s w e e t s t r e a m   =   M y S t r e a m e r   C O N S U M E R _ K E Y ,   C O N S U M E R _ S E C R E T ,                                           A C C E S S _ T O K E N ,   A C C E S S _ T O K E N _ S E C R E T      This will run until it collects 100 tweets  or until it encounters an error  and stop, at which point you can start analyzing those tweets. For instance, you could find the most common hashtags with:  Each tweet contains a lot of data. You can either poke around yourself or dig through the Twitter API documentation.  NOTE  In a non-toy project, you probably wouldn’t want to rely on an in-memory l storing the tweets. Instead you’d want to save them to a file or a database, so that you’d have them permanently.  t for  For Further Exploration  pandas is the primary library that data science types use for working with—and, in particular, importing—data. Scrapy is a full-featured library for building complicated web scrapers that do things like follow unknown links. Kaggle hosts a large collection of datasets.       s t a r t s   c o n s u m i n g   p u b l i c   s t a t u s e s   t h a t   c o n t a i n   t h e   k e y w o r d   ' d a t a '   s t r e a m . s t a t u s e s . f i l t e r   t r a c k = ' d a t a '          i f   i n s t e a d   w e   w a n t e d   t o   s t a r t   c o n s u m i n g   a   s a m p l e   o f   * a l l *   p u b l i c   s t a t u s e s      s t r e a m . s t a t u s e s . s a m p l e     t o p _ h a s h t a g s   =   C o u n t e r   h a s h t a g [ ' t e x t ' ] . l o w e r                                                     f o r   t w e e t   i n   t w e e t s                                                 f o r   h a s h t a g   i n   t w e e t [ " e n t i t i e s " ] [ " h a s h t a g s " ]       p r i n t   t o p _ h a s h t a g s . m o s t _ c o m m o n   5     i s  Chapter 10. Working with Data  Experts often possess more data than judgment.  —Colin Powell  Working with data is both an art and a science. We’ve mostly been talking about the science part, but in this chapter we’ll look at some of the art.  Exploring Your Data After you’ve identified the questions you’re trying to answer and have gotten your hands on some data, you might be tempted to dive in and immediately start building models and getting answers. But you should resist this urge. Your first step should be to explore your data.  Exploring One-Dimensional Data The simplest case is when you have a one-dimensional dataset, which is just a collection of numbers. For example, these could be the daily average number of minutes each user spends on your site, the number of times each of a collection of data science tutorial videos was watched, or the number of pages of each of the data science books in your data science library. An obvious first step is to compute a few summary statistics. You’d like to know how many data points you have, the smallest, the largest, the mean, and the standard deviation. But even these don’t necessarily give you a great understanding. A good next step is to create a histogram, in which you group your data into discrete buckets and count how many points fall into each bucket:  f r o m   t y p i n g   i m p o r t   L i s t ,   D i c t   f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r   i m p o r t   m a t h      For example, consider the two following sets of data:  Both have means close to 0 and standard deviations close to 58. However, they have very different distributions. Figure 10-1 shows the distribution of  m:  while Figure 10-2 shows the distribution of n  l:  i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t     d e f   b u c k e t i z e   p o i n t :   f l o a t ,   b u c k e t _ s i z e :   f l o a t     - >   f l o a t :           " " " F l o o r   t h e   p o i n t   t o   t h e   n e x t   l o w e r   m u l t i p l e   o f   b u c k e t _ s i z e " " "           r e t u r n   b u c k e t _ s i z e   *   m a t h . f l o o r   p o i n t       b u c k e t _ s i z e       d e f   m a k e _ h i s t o g r a m   p o i n t s :   L i s t [ f l o a t ] ,   b u c k e t _ s i z e :   f l o a t     - >   D i c t [ f l o a t ,   i n t ] :           " " " B u c k e t s   t h e   p o i n t s   a n d   c o u n t s   h o w   m a n y   i n   e a c h   b u c k e t " " "           r e t u r n   C o u n t e r   b u c k e t i z e   p o i n t ,   b u c k e t _ s i z e     f o r   p o i n t   i n   p o i n t s       d e f   p l o t _ h i s t o g r a m   p o i n t s :   L i s t [ f l o a t ] ,   b u c k e t _ s i z e :   f l o a t ,   t i t l e :   s t r   =   " "   :           h i s t o g r a m   =   m a k e _ h i s t o g r a m   p o i n t s ,   b u c k e t _ s i z e             p l t . b a r   h i s t o g r a m . k e y s     ,   h i s t o g r a m . v a l u e s     ,   w i d t h = b u c k e t _ s i z e             p l t . t i t l e   t i t l e   i m p o r t   r a n d o m   f r o m   s c r a t c h . p r o b a b i l i t y   i m p o r t   i n v e r s e _ n o r m a l _ c d f     r a n d o m . s e e d   0          u n i f o r m   b e t w e e n   - 1 0 0   a n d   1 0 0   u n i f o r m   =   [ 2 0 0   *   r a n d o m . r a n d o m       -   1 0 0   f o r   _   i n   r a n g e   1 0 0 0 0   ]        n o r m a l   d i s t r i b u t i o n   w i t h   m e a n   0 ,   s t a n d a r d   d e v i a t i o n   5 7   n o r m a l   =   [ 5 7   *   i n v e r s e _ n o r m a l _ c d f   r a n d o m . r a n d o m                             f o r   _   i n   r a n g e   1 0 0 0 0   ] u n i f o r p l o t _ h i s t o g r a m   u n i f o r m ,   1 0 ,   " U n i f o r m   H i s t o g r a m "   o r m a p l o t _ h i s t o g r a m   n o r m a l ,   1 0 ,   " N o r m a l   H i s t o g r a m "    Figure 10-1. Histogram of uniform  In this case the two distributions have a pretty different m n, but even knowing that wouldn’t have been sufficient to understand how they differed.  x and m  Two Dimensions Now imagine you have a dataset with two dimensions. Maybe in addition to daily minutes you have years of data science experience. Of course you’d want to understand each dimension individually. But you probably also want to scatter the data. For example, consider another fake dataset:  a i d e f   r a n d o m _ n o r m a l       - >   f l o a t :           " " " R e t u r n s   a   r a n d o m   d r a w   f r o m   a   s t a n d a r d   n o r m a l   d i s t r i b u t i o n " " "           r e t u r n   i n v e r s e _ n o r m a l _ c d f   r a n d o m . r a n d o m            If you were to run p 2, you’d get similar- looking plots  indeed, both are normally distributed with the same mean and standard deviation .  1 and y  m on y  Figure 10-2. Histogram of normal  But each has a very different joint distribution with x Figure 10-3:  s, as shown in  x s   =   [ r a n d o m _ n o r m a l       f o r   _   i n   r a n g e   1 0 0 0   ]   y s 1   =   [   x   +   r a n d o m _ n o r m a l           2   f o r   x   i n   x s ]   y s 2   =   [ - x   +   r a n d o m _ n o r m a l           2   f o r   x   i n   x s ] l o t _ h i s t o g r a s s p l t . s c a t t e r   x s ,   y s 1 ,   m a r k e r = ' . ' ,   c o l o r = ' b l a c k ' ,   l a b e l = ' y s 1 '     p l t . s c a t t e r   x s ,   y s 2 ,   m a r k e r = ' . ' ,   c o l o r = ' g r a y ' ,     l a b e l = ' y s 2 '     p l t . x l a b e l   ' x s '     p l t . y l a b e l   ' y s '     p l t . l e g e n d   l o c = 9     p l t . t i t l e   " V e r y   D i f f e r e n t   J o i n t   D i s t r i b u t i o n s "     p l t . s h o w      Figure 10-3. Scattering two different ys  This difference would also be apparent if you looked at the correlations:  Many Dimensions With many dimensions, you’d like to know how all the dimensions relate to one another. A simple approach is to look at the correlation matrix, in which the entry in row i and column j is the correlation between the ith dimension and the jth dimension of the data:  f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   c o r r e l a t i o n     p r i n t   c o r r e l a t i o n   x s ,   y s 1                    a b o u t   0 . 9   p r i n t   c o r r e l a t i o n   x s ,   y s 2                    a b o u t   - 0 . 9 f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   M a t r i x ,   V e c t o r ,   m a k e _ m a t r i x     d e f   c o r r e l a t i o n _ m a t r i x   d a t a :   L i s t [ V e c t o r ]     - >   M a t r i x :    A more visual approach  if you don’t have too many dimensions  is to make a scatterplot matrix  Figure 10-4  showing all the pairwise scatterplots. To do that we’ll use p s, which allows us to create subplots of our chart. We give it the number of rows and the number of columns, and it returns a f of a  e object  which we won’t use  and a two-dimensional array  s objects  each of which we’ll plot to :          " " "           R e t u r n s   t h e   l e n   d a t a     x   l e n   d a t a     m a t r i x   w h o s e     i ,   j   - t h   e n t r y           i s   t h e   c o r r e l a t i o n   b e t w e e n   d a t a [ i ]   a n d   d a t a [ j ]           " " "           d e f   c o r r e l a t i o n _ i j   i :   i n t ,   j :   i n t     - >   f l o a t :                   r e t u r n   c o r r e l a t i o n   d a t a [ i ] ,   d a t a [ j ]               r e t u r n   m a k e _ m a t r i x   l e n   d a t a   ,   l e n   d a t a   ,   c o r r e l a t i o n _ i j   l t . s u b p l o t i g u r x e    c o r r _ d a t a   i s   a   l i s t   o f   f o u r   1 0 0 - d   v e c t o r s   n u m _ v e c t o r s   =   l e n   c o r r _ d a t a     f i g ,   a x   =   p l t . s u b p l o t s   n u m _ v e c t o r s ,   n u m _ v e c t o r s       f o r   i   i n   r a n g e   n u m _ v e c t o r s   :           f o r   j   i n   r a n g e   n u m _ v e c t o r s   :                        S c a t t e r   c o l u m n _ j   o n   t h e   x - a x i s   v s .   c o l u m n _ i   o n   t h e   y - a x i s                   i f   i   ! =   j :   a x [ i ] [ j ] . s c a t t e r   c o r r _ d a t a [ j ] ,   c o r r _ d a t a [ i ]                          u n l e s s   i   = =   j ,   i n   w h i c h   c a s e   s h o w   t h e   s e r i e s   n a m e                   e l s e :   a x [ i ] [ j ] . a n n o t a t e   " s e r i e s   "   +   s t r   i   ,     0 . 5 ,   0 . 5   ,                                                                   x y c o o r d s = ' a x e s   f r a c t i o n ' ,                                                                   h a = " c e n t e r " ,   v a = " c e n t e r "                          T h e n   h i d e   a x i s   l a b e l s   e x c e p t   l e f t   a n d   b o t t o m   c h a r t s                   i f   i   <   n u m _ v e c t o r s   -   1 :   a x [ i ] [ j ] . x a x i s . s e t _ v i s i b l e   F a l s e                     i f   j   >   0 :   a x [ i ] [ j ] . y a x i s . s e t _ v i s i b l e   F a l s e          F i x   t h e   b o t t o m - r i g h t   a n d   t o p - l e f t   a x i s   l a b e l s ,   w h i c h   a r e   w r o n g   b e c a u s e      t h e i r   c h a r t s   o n l y   h a v e   t e x t   i n   t h e m   a x [ - 1 ] [ - 1 ] . s e t _ x l i m   a x [ 0 ] [ - 1 ] . g e t _ x l i m         a x [ 0 ] [ 0 ] . s e t _ y l i m   a x [ 0 ] [ 1 ] . g e t _ y l i m           p l t . s h o w      Figure 10-4. Scatterplot matrix  Looking at the scatterplots, you can see that series 1 is very negatively correlated with series 0, series 2 is positively correlated with series 1, and series 3 only takes on the values 0 and 6, with 0 corresponding to small values of series 2 and 6 corresponding to large values. This is a quick way to get a rough sense of which of your variables are correlated  unless you spend hours tweaking matplotlib to display things exactly the way you want them to, in which case it’s not a quick way .  Using NamedTuples One common way of representing data is using d  ts:  i c i m p o r t   d a t e t i m e     s t o c k _ p r i c e   =   { ' c l o s i n g _ p r i c e ' :   1 0 2 . 0 6 ,    There are several reasons why this is less than ideal, however. This is a slightly inefficient representation  a d if you have a lot of stock prices they’ll take up more memory than they have to. For the most part, this is a minor consideration. A larger issue is that accessing things by d following code will run without error and just do the wrong thing:  t key is error-prone. The  t involves some overhead , so that  Finally, while we can type-annotate uniform dictionaries:  there’s no helpful way to annotate dictionaries-as-data that have lots of different value types. So we also lose the power of type hints. As an alternative, Python includes a n  e class, which is like a  e but with named slots:  es, n  es are immutable, which means that you  Like regular t can’t modify their values once they’re created. Occasionally this will get in our way, but mostly that’s a good thing. You’ll notice that we still haven’t solved the type annotation issue. We do that by using the typed variant, N  e:                                ' d a t e ' :   d a t e t i m e . d a t e   2 0 1 4 ,   8 ,   2 9   ,                                 ' s y m b o l ' :   ' A A P L ' } i c i c    o o p s ,   t y p o   s t o c k _ p r i c e [ ' c o s i n g _ p r i c e ' ]   =   1 0 3 . 0 6 p r i c e s :   D i c t [ d a t e t i m e . d a t e ,   f l o a t ]   =   { } a m e d t u p l t u p l f r o m   c o l l e c t i o n s   i m p o r t   n a m e d t u p l e     S t o c k P r i c e   =   n a m e d t u p l e   ' S t o c k P r i c e ' ,   [ ' s y m b o l ' ,   ' d a t e ' ,   ' c l o s i n g _ p r i c e ' ]     p r i c e   =   S t o c k P r i c e   ' M S F T ' ,   d a t e t i m e . d a t e   2 0 1 8 ,   1 2 ,   1 4   ,   1 0 6 . 0 3       a s s e r t   p r i c e . s y m b o l   = =   ' M S F T '   a s s e r t   p r i c e . c l o s i n g _ p r i c e   = =   1 0 6 . 0 3 u p l a m e d t u p l a m e d T u p l  And now your editor can help you out, as shown in Figure 10-5.  Figure 10-5. Helpful editor  NOTE  Very few people use N  e in this way. But they should!  Dataclasses Dataclasses are  sort of  a mutable version of N because N dataclasses are regular Python classes that simply generate some methods for you automatically.   es represent their data compactly as tuples, whereas  e.  I say “sort of”  f r o m   t y p i n g   i m p o r t   N a m e d T u p l e     c l a s s   S t o c k P r i c e   N a m e d T u p l e   :           s y m b o l :   s t r           d a t e :   d a t e t i m e . d a t e           c l o s i n g _ p r i c e :   f l o a t             d e f   i s _ h i g h _ t e c h   s e l f     - >   b o o l :                   " " " I t ' s   a   c l a s s ,   s o   w e   c a n   a d d   m e t h o d s   t o o " " "                   r e t u r n   s e l f . s y m b o l   i n   [ ' M S F T ' ,   ' G O O G ' ,   ' F B ' ,   ' A M Z N ' ,   ' A A P L ' ]     p r i c e   =   S t o c k P r i c e   ' M S F T ' ,   d a t e t i m e . d a t e   2 0 1 8 ,   1 2 ,   1 4   ,   1 0 6 . 0 3       a s s e r t   p r i c e . s y m b o l   = =   ' M S F T '   a s s e r t   p r i c e . c l o s i n g _ p r i c e   = =   1 0 6 . 0 3   a s s e r t   p r i c e . i s _ h i g h _ t e c h     a m e d T u p l a m e d T u p l a m e d T u p l  NOTE  Dataclasses are new in Python 3.7. If you’re using an older version, this section won’t work for you.  The syntax is very similar to N base class, we use a decorator:  e. But instead of inheriting from a  As mentioned, the big difference is that we can modify a dataclass instance’s values:  If we tried to modify a field of the N  e version, we’d get an  r.  This also leaves us susceptible to the kind of errors we were hoping to avoid by not using d  ts:  a m e d T u p l f r o m   d a t a c l a s s e s   i m p o r t   d a t a c l a s s     @ d a t a c l a s s   c l a s s   S t o c k P r i c e 2 :           s y m b o l :   s t r           d a t e :   d a t e t i m e . d a t e           c l o s i n g _ p r i c e :   f l o a t             d e f   i s _ h i g h _ t e c h   s e l f     - >   b o o l :                   " " " I t ' s   a   c l a s s ,   s o   w e   c a n   a d d   m e t h o d s   t o o " " "                   r e t u r n   s e l f . s y m b o l   i n   [ ' M S F T ' ,   ' G O O G ' ,   ' F B ' ,   ' A M Z N ' ,   ' A A P L ' ]     p r i c e 2   =   S t o c k P r i c e 2   ' M S F T ' ,   d a t e t i m e . d a t e   2 0 1 8 ,   1 2 ,   1 4   ,   1 0 6 . 0 3       a s s e r t   p r i c e 2 . s y m b o l   = =   ' M S F T '   a s s e r t   p r i c e 2 . c l o s i n g _ p r i c e   = =   1 0 6 . 0 3   a s s e r t   p r i c e 2 . i s _ h i g h _ t e c h        s t o c k   s p l i t   p r i c e 2 . c l o s i n g _ p r i c e     =   2   a s s e r t   p r i c e 2 . c l o s i n g _ p r i c e   = =   5 1 . 0 3 a m e d T u p l A t t r i b u t e E r r o i c  We won’t be using dataclasses, but you may encounter them out in the wild.  Cleaning and Munging Real-world data is dirty. Often you’ll have to do some work on it before you can use it. We saw examples of this in Chapter 9. We have to convert strings to f ts before we can use them. We have to check for missing values and outliers and bad data. Previously, we did that right before using the data:  ts or i  But it’s probably less error-prone to do the parsing in a function that we can test:  What if there’s bad data? A “float” value that doesn’t actually represent a number? Maybe you’d rather get a N  e than crash your program?     I t ' s   a   r e g u l a r   c l a s s ,   s o   a d d   n e w   f i e l d s   h o w e v e r   y o u   l i k e !   p r i c e 2 . c o s i n g _ p r i c e   =   7 5        o o p s l o a n c l o s i n g _ p r i c e   =   f l o a t   r o w [ 2 ]   f r o m   d a t e u t i l . p a r s e r   i m p o r t   p a r s e     d e f   p a r s e _ r o w   r o w :   L i s t [ s t r ]     - >   S t o c k P r i c e :           s y m b o l ,   d a t e ,   c l o s i n g _ p r i c e   =   r o w           r e t u r n   S t o c k P r i c e   s y m b o l = s y m b o l ,                                               d a t e = p a r s e   d a t e   . d a t e     ,                                               c l o s i n g _ p r i c e = f l o a t   c l o s i n g _ p r i c e            N o w   t e s t   o u r   f u n c t i o n   s t o c k   =   p a r s e _ r o w   [ " M S F T " ,   " 2 0 1 8 - 1 2 - 1 4 " ,   " 1 0 6 . 0 3 " ]       a s s e r t   s t o c k . s y m b o l   = =   " M S F T "   a s s e r t   s t o c k . d a t e   = =   d a t e t i m e . d a t e   2 0 1 8 ,   1 2 ,   1 4     a s s e r t   s t o c k . c l o s i n g _ p r i c e   = =   1 0 6 . 0 3 o n f r o m   t y p i n g   i m p o r t   O p t i o n a l   i m p o r t   r e      For example, if we have comma-delimited stock prices with bad data:  we can now read and return only the valid rows:  d e f   t r y _ p a r s e _ r o w   r o w :   L i s t [ s t r ]     - >   O p t i o n a l [ S t o c k P r i c e ] :           s y m b o l ,   d a t e _ ,   c l o s i n g _ p r i c e _   =   r o w                S t o c k   s y m b o l   s h o u l d   b e   a l l   c a p i t a l   l e t t e r s           i f   n o t   r e . m a t c h   r " ^ [ A - Z ] + $ " ,   s y m b o l   :                   r e t u r n   N o n e             t r y :                   d a t e   =   p a r s e   d a t e _   . d a t e               e x c e p t   V a l u e E r r o r :                   r e t u r n   N o n e             t r y :                   c l o s i n g _ p r i c e   =   f l o a t   c l o s i n g _ p r i c e _             e x c e p t   V a l u e E r r o r :                   r e t u r n   N o n e             r e t u r n   S t o c k P r i c e   s y m b o l ,   d a t e ,   c l o s i n g _ p r i c e          S h o u l d   r e t u r n   N o n e   f o r   e r r o r s   a s s e r t   t r y _ p a r s e _ r o w   [ " M S F T 0 " ,   " 2 0 1 8 - 1 2 - 1 4 " ,   " 1 0 6 . 0 3 " ]     i s   N o n e   a s s e r t   t r y _ p a r s e _ r o w   [ " M S F T " ,   " 2 0 1 8 - 1 2 - - 1 4 " ,   " 1 0 6 . 0 3 " ]     i s   N o n e   a s s e r t   t r y _ p a r s e _ r o w   [ " M S F T " ,   " 2 0 1 8 - 1 2 - 1 4 " ,   " x " ]     i s   N o n e        B u t   s h o u l d   r e t u r n   s a m e   a s   b e f o r e   i f   d a t a   i s   g o o d   a s s e r t   t r y _ p a r s e _ r o w   [ " M S F T " ,   " 2 0 1 8 - 1 2 - 1 4 " ,   " 1 0 6 . 0 3 " ]     = =   s t o c k A A P L , 6   2 0   2 0 1 4 , 9 0 . 9 1   M S F T , 6   2 0   2 0 1 4 , 4 1 . 6 8   F B , 6   2 0   3 0 1 4 , 6 4 . 5   A A P L , 6   1 9   2 0 1 4 , 9 1 . 8 6   M S F T , 6   1 9   2 0 1 4 , n   a   F B , 6   1 9   2 0 1 4 , 6 4 . 3 4 i m p o r t   c s v     d a t a :   L i s t [ S t o c k P r i c e ]   =   [ ]     w i t h   o p e n   " c o m m a _ d e l i m i t e d _ s t o c k _ p r i c e s . c s v "     a s   f :           r e a d e r   =   c s v . r e a d e r   f             f o r   r o w   i n   r e a d e r :    and decide what we want to do about the invalid ones. Generally speaking, the three options are to get rid of them, to go back to the source and try to fix the bad missing data, or to do nothing and cross our fingers. If there’s one bad row out of millions, it’s probably okay to ignore it. But if half your rows have bad data, that’s something you need to fix. A good next step is to check for outliers, using techniques from “Exploring Your Data” or by ad hoc investigating. For example, did you notice that one of the dates in the stocks file had the year 3014? That won’t  necessarily  give you an error, but it’s quite plainly wrong, and you’ll get screwy results if you don’t catch it. Real-world datasets have missing decimal points, extra zeros, typographical errors, and countless other problems that it’s your job to catch.  Maybe it’s not officially your job, but who else is going to do it?   Manipulating Data One of the most important skills of a data scientist is manipulating data. It’s more of a general approach than a specific technique, so we’ll just work through a handful of examples to give you the flavor of it. Imagine we have a bunch of stock price data that looks like this:  Let’s start asking questions about this data. Along the way we’ll try to notice patterns in what we’re doing and abstract out some tools to make the manipulation easier.                  m a y b e _ s t o c k   =   t r y _ p a r s e _ r o w   r o w                     i f   m a y b e _ s t o c k   i s   N o n e :                           p r i n t   f " s k i p p i n g   i n v a l i d   r o w :   { r o w } "                     e l s e :                           d a t a . a p p e n d   m a y b e _ s t o c k   d a t a   =   [           S t o c k P r i c e   s y m b o l = ' M S F T ' ,                                 d a t e = d a t e t i m e . d a t e   2 0 1 8 ,   1 2 ,   2 4   ,                                 c l o s i n g _ p r i c e = 1 0 6 . 0 3   ,              . . .   ]  For instance, suppose we want to know the highest-ever closing price for AAPL. Let’s break this down into concrete steps:  1. Restrict ourselves to AAPL rows.  2. Grab the c  e from each row.  3. Take the m  x of those prices.  We can do all three at once using a comprehension:  More generally, we might want to know the highest-ever closing price for each stock in our dataset. One way to do this is:  1. Create a d  t to keep track of highest prices  we’ll use a t that returns minus infinity for missing values, since  any price will be greater than that .  2. Iterate over our data, updating it.  Here’s the code:  We can now start to ask more complicated things, like what are the largest and smallest one-day percent changes in our dataset. The percent change is 1, which means we need some way of associating today’s price and yesterday’s price. One approach is to group the prices by symbol, and then, within each group:  l o s i n g _ p r i c a m a x _ a a p l _ p r i c e   =   m a x   s t o c k _ p r i c e . c l o s i n g _ p r i c e                                             f o r   s t o c k _ p r i c e   i n   d a t a                                             i f   s t o c k _ p r i c e . s y m b o l   = =   " A A P L "   i c d e f a u l t d i c f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     m a x _ p r i c e s :   D i c t [ s t r ,   f l o a t ]   =   d e f a u l t d i c t   l a m b d a :   f l o a t   ' - i n f '         f o r   s p   i n   d a t a :           s y m b o l ,   c l o s i n g _ p r i c e   =   s p . s y m b o l ,   s p . c l o s i n g _ p r i c e           i f   c l o s i n g _ p r i c e   >   m a x _ p r i c e s [ s y m b o l ] :                   m a x _ p r i c e s [ s y m b o l ]   =   c l o s i n g _ p r i c e p r i c e _ t o d a y       p r i c e _ y e s t e r d a y   -    1. Order the prices by date.  p to get  previous, current  pairs.  2. Use z 3. Turn the pairs into new “percent change” rows.  Let’s start by grouping the prices by symbol:  Since the prices are tuples, they’ll get sorted by their fields in order: first by symbol, then by date, then by price. This means that if we have some prices t will sort them by date  and then by price, all with the same symbol, s which does nothing, since we only have one per date , which is what we want.  which we can use to compute a sequence of day-over-day changes:  i f r o m   t y p i n g   i m p o r t   L i s t   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t        C o l l e c t   t h e   p r i c e s   b y   s y m b o l   p r i c e s :   D i c t [ s t r ,   L i s t [ S t o c k P r i c e ] ]   =   d e f a u l t d i c t   l i s t       f o r   s p   i n   d a t a :           p r i c e s [ s p . s y m b o l ] . a p p e n d   s p   o r    O r d e r   t h e   p r i c e s   b y   d a t e   p r i c e s   =   { s y m b o l :   s o r t e d   s y m b o l _ p r i c e s                         f o r   s y m b o l ,   s y m b o l _ p r i c e s   i n   p r i c e s . i t e m s     } d e f   p c t _ c h a n g e   y e s t e r d a y :   S t o c k P r i c e ,   t o d a y :   S t o c k P r i c e     - >   f l o a t :           r e t u r n   t o d a y . c l o s i n g _ p r i c e       y e s t e r d a y . c l o s i n g _ p r i c e   -   1     c l a s s   D a i l y C h a n g e   N a m e d T u p l e   :           s y m b o l :   s t r           d a t e :   d a t e t i m e . d a t e           p c t _ c h a n g e :   f l o a t     d e f   d a y _ o v e r _ d a y _ c h a n g e s   p r i c e s :   L i s t [ S t o c k P r i c e ]     - >   L i s t [ D a i l y C h a n g e ] :           " " "           A s s u m e s   p r i c e s   a r e   f o r   o n e   s t o c k   a n d   a r e   i n   o r d e r           " " "           r e t u r n   [ D a i l y C h a n g e   s y m b o l = t o d a y . s y m b o l ,    and then collect them all:  At which point it’s easy to find the largest and smallest:  We can now use this new a s dataset to find which month is the best to invest in tech stocks. We’ll just look at the average daily change by month:                                                  d a t e = t o d a y . d a t e ,                                                   p c t _ c h a n g e = p c t _ c h a n g e   y e s t e r d a y ,   t o d a y                               f o r   y e s t e r d a y ,   t o d a y   i n   z i p   p r i c e s ,   p r i c e s [ 1 : ]   ] a l l _ c h a n g e s   =   [ c h a n g e                                 f o r   s y m b o l _ p r i c e s   i n   p r i c e s . v a l u e s                                     f o r   c h a n g e   i n   d a y _ o v e r _ d a y _ c h a n g e s   s y m b o l _ p r i c e s   ] m a x _ c h a n g e   =   m a x   a l l _ c h a n g e s ,   k e y = l a m b d a   c h a n g e :   c h a n g e . p c t _ c h a n g e        s e e   e . g .   h t t p :     n e w s . c n e t . c o m   2 1 0 0 - 1 0 0 1 - 2 0 2 1 4 3 . h t m l   a s s e r t   m a x _ c h a n g e . s y m b o l   = =   ' A A P L '   a s s e r t   m a x _ c h a n g e . d a t e   = =   d a t e t i m e . d a t e   1 9 9 7 ,   8 ,   6     a s s e r t   0 . 3 3   <   m a x _ c h a n g e . p c t _ c h a n g e   <   0 . 3 4     m i n _ c h a n g e   =   m i n   a l l _ c h a n g e s ,   k e y = l a m b d a   c h a n g e :   c h a n g e . p c t _ c h a n g e        s e e   e . g .   h t t p :     m o n e y . c n n . c o m   2 0 0 0   0 9   2 9   m a r k e t s   t e c h w r a p     a s s e r t   m i n _ c h a n g e . s y m b o l   = =   ' A A P L '   a s s e r t   m i n _ c h a n g e . d a t e   = =   d a t e t i m e . d a t e   2 0 0 0 ,   9 ,   2 9     a s s e r t   - 0 . 5 2   <   m i n _ c h a n g e . p c t _ c h a n g e   <   - 0 . 5 1 l l _ c h a n g e c h a n g e s _ b y _ m o n t h :   L i s t [ D a i l y C h a n g e ]   =   { m o n t h :   [ ]   f o r   m o n t h   i n   r a n g e   1 ,   1 3   }     f o r   c h a n g e   i n   a l l _ c h a n g e s :           c h a n g e s _ b y _ m o n t h [ c h a n g e . d a t e . m o n t h ] . a p p e n d   c h a n g e       a v g _ d a i l y _ c h a n g e   =   {           m o n t h :   s u m   c h a n g e . p c t _ c h a n g e   f o r   c h a n g e   i n   c h a n g e s         l e n   c h a n g e s             f o r   m o n t h ,   c h a n g e s   i n   c h a n g e s _ b y _ m o n t h . i t e m s       }        O c t o b e r   i s   t h e   b e s t   m o n t h   a s s e r t   a v g _ d a i l y _ c h a n g e [ 1 0 ]   = =   m a x   a v g _ d a i l y _ c h a n g e . v a l u e s        We’ll be doing these sorts of manipulations throughout the book, usually without calling too much explicit attention to them.  Rescaling Many techniques are sensitive to the scale of your data. For example, imagine that you have a dataset consisting of the heights and weights of hundreds of data scientists, and that you are trying to identify clusters of body sizes. Intuitively, we’d like clusters to represent points near each other, which means that we need some notion of distance between points. We already have a Euclidean d  height, weight  pairs as points in two-dimensional space. Consider the people listed in Table 10-1.  e function, so a natural approach might be to treat  Table 10-1. Heights and weights Person Height  inches  Height  centimeters  Weight  pounds   A  B  C  63  67  70  160  170.2  177.8  150  160  171  If we measure height in inches, then B’s nearest neighbor is A:  However, if we measure height in centimeters, then B’s nearest neighbor is instead C:  i s t a n c f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d i s t a n c e     a _ t o _ b   =   d i s t a n c e   [ 6 3 ,   1 5 0 ] ,   [ 6 7 ,   1 6 0 ]                      1 0 . 7 7   a _ t o _ c   =   d i s t a n c e   [ 6 3 ,   1 5 0 ] ,   [ 7 0 ,   1 7 1 ]                      2 2 . 1 4   b _ t o _ c   =   d i s t a n c e   [ 6 7 ,   1 6 0 ] ,   [ 7 0 ,   1 7 1 ]                      1 1 . 4 0  Obviously it’s a problem if changing units can change results like this. For this reason, when dimensions aren’t comparable with one another, we will sometimes rescale our data so that each dimension has mean 0 and standard deviation 1. This effectively gets rid of the units, converting each dimension to “standard deviations from the mean.” To start with, we’ll need to compute the m n for each position:  n and the  We can then use them to create a new dataset:  a _ t o _ b   =   d i s t a n c e   [ 1 6 0 ,   1 5 0 ] ,   [ 1 7 0 . 2 ,   1 6 0 ]              1 4 . 2 8   a _ t o _ c   =   d i s t a n c e   [ 1 6 0 ,   1 5 0 ] ,   [ 1 7 7 . 8 ,   1 7 1 ]              2 7 . 5 3   b _ t o _ c   =   d i s t a n c e   [ 1 7 0 . 2 ,   1 6 0 ] ,   [ 1 7 7 . 8 ,   1 7 1 ]          1 3 . 3 7 e a s t a n d a r d _ d e v i a t i o f r o m   t y p i n g   i m p o r t   T u p l e     f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   v e c t o r _ m e a n   f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   s t a n d a r d _ d e v i a t i o n     d e f   s c a l e   d a t a :   L i s t [ V e c t o r ]     - >   T u p l e [ V e c t o r ,   V e c t o r ] :           " " " r e t u r n s   t h e   m e a n   a n d   s t a n d a r d   d e v i a t i o n   f o r   e a c h   p o s i t i o n " " "           d i m   =   l e n   d a t a [ 0 ]               m e a n s   =   v e c t o r _ m e a n   d a t a             s t d e v s   =   [ s t a n d a r d _ d e v i a t i o n   [ v e c t o r [ i ]   f o r   v e c t o r   i n   d a t a ]                                 f o r   i   i n   r a n g e   d i m   ]             r e t u r n   m e a n s ,   s t d e v s     v e c t o r s   =   [ [ - 3 ,   - 1 ,   1 ] ,   [ - 1 ,   0 ,   1 ] ,   [ 1 ,   1 ,   1 ] ]   m e a n s ,   s t d e v s   =   s c a l e   v e c t o r s     a s s e r t   m e a n s   = =   [ - 1 ,   0 ,   1 ]   a s s e r t   s t d e v s   = =   [ 2 ,   1 ,   0 ] d e f   r e s c a l e   d a t a :   L i s t [ V e c t o r ]     - >   L i s t [ V e c t o r ] :           " " "           R e s c a l e s   t h e   i n p u t   d a t a   s o   t h a t   e a c h   p o s i t i o n   h a s           m e a n   0   a n d   s t a n d a r d   d e v i a t i o n   1 .     L e a v e s   a   p o s i t i o n           a s   i s   i f   i t s   s t a n d a r d   d e v i a t i o n   i s   0 .             " " "           d i m   =   l e n   d a t a [ 0 ]             m e a n s ,   s t d e v s   =   s c a l e   d a t a      Of course, let’s write a test to conform that r should:  e does what we think it  As always, you need to use your judgment. If you were to take a huge dataset of heights and weights and filter it down to only the people with heights between 69.5 inches and 70.5 inches, it’s quite likely  depending on the question you’re trying to answer  that the variation remaining is simply noise, and you might not want to put its standard deviation on equal footing with other dimensions’ deviations.  An Aside: tqdm Frequently we’ll end up doing computations that take a long time. When you’re doing such work, you’d like to know that you’re making progress and how long you should expect to wait. One way of doing this is with the t m library, which generates custom progress bars. We’ll use it some throughout the rest of the book, so let’s take this chance to learn how it works. To start with, you’ll need to install it:               M a k e   a   c o p y   o f   e a c h   v e c t o r           r e s c a l e d   =   [ v [ : ]   f o r   v   i n   d a t a ]             f o r   v   i n   r e s c a l e d :                   f o r   i   i n   r a n g e   d i m   :                           i f   s t d e v s [ i ]   >   0 :                                   v [ i ]   =     v [ i ]   -   m e a n s [ i ]         s t d e v s [ i ]             r e t u r n   r e s c a l e d e s c a l m e a n s ,   s t d e v s   =   s c a l e   r e s c a l e   v e c t o r s       a s s e r t   m e a n s   = =   [ 0 ,   0 ,   1 ]   a s s e r t   s t d e v s   = =   [ 1 ,   1 ,   0 ] q d p y t h o n   - m   p i p   i n s t a l l   t q d m  There are only a few features you need to know about. The first is that an iterable wrapped in t  m will produce a progress bar:  which produces an output that looks like this:  In particular, it shows you what fraction of your loop is done  though it can’t do this if you use a generator , how long it’s been running, and how long it expects to run. In this case  where we are just wrapping a call to r  e  you can just use  e.  You can also set the description of the progress bar while it’s running. To do that, you need to capture the t  m iterator in a w  h statement:  q d m . t q d i m p o r t   t q d m     f o r   i   i n   t q d m . t q d m   r a n g e   1 0 0     :              d o   s o m e t h i n g   s l o w           _   =   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   1 0 0 0 0 0 0   ]   5 6 %  █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █                                5 6   1 0 0   [ 0 0 : 0 8 < 0 0 : 0 6 ,     6 . 4 9 i t   s ] a n g t q d m . t r a n g q d i t f r o m   t y p i n g   i m p o r t   L i s t     d e f   p r i m e s _ u p _ t o   n :   i n t     - >   L i s t [ i n t ] :           p r i m e s   =   [ 2 ]             w i t h   t q d m . t r a n g e   3 ,   n     a s   t :                   f o r   i   i n   t :                              i   i s   p r i m e   i f   n o   s m a l l e r   p r i m e   d i v i d e s   i t                           i _ i s _ p r i m e   =   n o t   a n y   i   %   p   = =   0   f o r   p   i n   p r i m e s                             i f   i _ i s _ p r i m e :                                   p r i m e s . a p p e n d   i                               t . s e t _ d e s c r i p t i o n   f " { l e n   p r i m e s   }   p r i m e s "               r e t u r n   p r i m e s     m y _ p r i m e s   =   p r i m e s _ u p _ t o   1 0 0 _ 0 0 0    This adds a description like the following, with a counter that updates as new primes are discovered:  m will occasionally make your code flaky—sometimes the screen  Using t redraws poorly, and sometimes the loop will simply hang. And if you accidentally wrap a t m loop, strange things might happen. Typically its benefits outweigh these downsides, though, so we’ll try to use it whenever we have slow-running computations.  m loop inside another t  Dimensionality Reduction Sometimes the “actual”  or useful  dimensions of the data might not correspond to the dimensions we have. For example, consider the dataset pictured in Figure 10-6.  5 1 1 6   p r i m e s :     5 0 %  █ █ █ █ █ █ █ █                    4 9 5 2 9   9 9 9 9 7   [ 0 0 : 0 3 < 0 0 : 0 3 ,   1 5 9 0 5 . 9 0 i t   s ] q d q d q d  Figure 10-6. Data with the “wrong” axes  Most of the variation in the data seems to be along a single dimension that doesn’t correspond to either the x-axis or the y-axis. When this is the case, we can use a technique called principal component analysis  PCA  to extract one or more dimensions that capture as much of the variation in the data as possible.  NOTE  In practice, you wouldn’t use this technique on such a low-dimensional dataset. Dimensionality reduction is mostly useful when your dataset has a large number of dimensions and you want to find a small subset that captures most of the variation. Unfortunately, that case is difficult to illustrate in a two-dimensional book format.   As a first step, we’ll need to translate the data so that each dimension has mean 0:   If we don’t do this, our techniques are likely to identify the mean itself rather than the variation in the data.  Figure 10-7 shows the example data after de-meaning.  Figure 10-7. Data after de-meaning  Now, given a de-meaned matrix X, we can ask which is the direction that captures the greatest variance in the data.  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s u b t r a c t     d e f   d e _ m e a n   d a t a :   L i s t [ V e c t o r ]     - >   L i s t [ V e c t o r ] :           " " " R e c e n t e r s   t h e   d a t a   t o   h a v e   m e a n   0   i n   e v e r y   d i m e n s i o n " " "           m e a n   =   v e c t o r _ m e a n   d a t a             r e t u r n   [ s u b t r a c t   v e c t o r ,   m e a n     f o r   v e c t o r   i n   d a t a ]  Specifically, given a direction d  a vector of magnitude 1 , each row x in the matrix extends d determines a direction if we rescale it to have magnitude 1:    in the d direction. And every nonzero vector w  Therefore, given a nonzero vector w, we can compute the variance of our dataset in the direction determined by w:  We’d like to find the direction that maximizes this variance. We can do this using gradient descent, as soon as we have the gradient function:  And now the first principal component that we have is just the direction that maximizes the d  e function:  o t   x ,   d f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   m a g n i t u d e     d e f   d i r e c t i o n   w :   V e c t o r     - >   V e c t o r :           m a g   =   m a g n i t u d e   w             r e t u r n   [ w _ i       m a g   f o r   w _ i   i n   w ] f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t     d e f   d i r e c t i o n a l _ v a r i a n c e   d a t a :   L i s t [ V e c t o r ] ,   w :   V e c t o r     - >   f l o a t :           " " "           R e t u r n s   t h e   v a r i a n c e   o f   x   i n   t h e   d i r e c t i o n   o f   w           " " "           w _ d i r   =   d i r e c t i o n   w             r e t u r n   s u m   d o t   v ,   w _ d i r     * *   2   f o r   v   i n   d a t a   d e f   d i r e c t i o n a l _ v a r i a n c e _ g r a d i e n t   d a t a :   L i s t [ V e c t o r ] ,   w :   V e c t o r     - >   V e c t o r :           " " "           T h e   g r a d i e n t   o f   d i r e c t i o n a l   v a r i a n c e   w i t h   r e s p e c t   t o   w           " " "           w _ d i r   =   d i r e c t i o n   w             r e t u r n   [ s u m   2   *   d o t   v ,   w _ d i r     *   v [ i ]   f o r   v   i n   d a t a                             f o r   i   i n   r a n g e   l e n   w     ] i r e c t i o n a l _ v a r i a n c f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p     d e f   f i r s t _ p r i n c i p a l _ c o m p o n e n t   d a t a :   L i s t [ V e c t o r ] ,                                                               n :   i n t   =   1 0 0 ,                                                               s t e p _ s i z e :   f l o a t   =   0 . 1     - >   V e c t o r :    On the de-meaned dataset, this returns the direction [ which does appear to capture the primary axis along which our data varies  Figure 10-8 .  ],  Figure 10-8. First principal component  Once we’ve found the direction that’s the first principal component, we can project our data onto it to find the values of that component:             S t a r t   w i t h   a   r a n d o m   g u e s s           g u e s s   =   [ 1 . 0   f o r   _   i n   d a t a [ 0 ] ]             w i t h   t q d m . t r a n g e   n     a s   t :                   f o r   _   i n   t :                           d v   =   d i r e c t i o n a l _ v a r i a n c e   d a t a ,   g u e s s                             g r a d i e n t   =   d i r e c t i o n a l _ v a r i a n c e _ g r a d i e n t   d a t a ,   g u e s s                             g u e s s   =   g r a d i e n t _ s t e p   g u e s s ,   g r a d i e n t ,   s t e p _ s i z e                             t . s e t _ d e s c r i p t i o n   f " d v :   { d v : . 3 f } "               r e t u r n   d i r e c t i o n   g u e s s   0 . 9 2 4 ,   0 . 3 8 3  If we want to find further components, we first remove the projections from the data:  Because this example dataset is only two-dimensional, after we remove the first component, what’s left will be effectively one-dimensional  Figure 10- 9 .  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s c a l a r _ m u l t i p l y     d e f   p r o j e c t   v :   V e c t o r ,   w :   V e c t o r     - >   V e c t o r :           " " " r e t u r n   t h e   p r o j e c t i o n   o f   v   o n t o   t h e   d i r e c t i o n   w " " "           p r o j e c t i o n _ l e n g t h   =   d o t   v ,   w             r e t u r n   s c a l a r _ m u l t i p l y   p r o j e c t i o n _ l e n g t h ,   w   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s u b t r a c t     d e f   r e m o v e _ p r o j e c t i o n _ f r o m _ v e c t o r   v :   V e c t o r ,   w :   V e c t o r     - >   V e c t o r :           " " " p r o j e c t s   v   o n t o   w   a n d   s u b t r a c t s   t h e   r e s u l t   f r o m   v " " "           r e t u r n   s u b t r a c t   v ,   p r o j e c t   v ,   w         d e f   r e m o v e _ p r o j e c t i o n   d a t a :   L i s t [ V e c t o r ] ,   w :   V e c t o r     - >   L i s t [ V e c t o r ] :           r e t u r n   [ r e m o v e _ p r o j e c t i o n _ f r o m _ v e c t o r   v ,   w     f o r   v   i n   d a t a ]  Figure 10-9. Data after removing the first principal component  At that point, we can find the next principal component by repeating the process on the result of r On a higher-dimensional dataset, we can iteratively find as many components as we want:  n  Figure 10-10 .  We can then transform our data into the lower-dimensional space spanned by the components:  e m o v e _ p r o j e c t i o d e f   p c a   d a t a :   L i s t [ V e c t o r ] ,   n u m _ c o m p o n e n t s :   i n t     - >   L i s t [ V e c t o r ] :           c o m p o n e n t s :   L i s t [ V e c t o r ]   =   [ ]           f o r   _   i n   r a n g e   n u m _ c o m p o n e n t s   :                   c o m p o n e n t   =   f i r s t _ p r i n c i p a l _ c o m p o n e n t   d a t a                     c o m p o n e n t s . a p p e n d   c o m p o n e n t                     d a t a   =   r e m o v e _ p r o j e c t i o n   d a t a ,   c o m p o n e n t               r e t u r n   c o m p o n e n t s  This technique is valuable for a couple of reasons. First, it can help us clean our data by eliminating noise dimensions and consolidating highly correlated dimensions.  Figure 10-10. First two principal components  Second, after extracting a low-dimensional representation of our data, we can use a variety of techniques that don’t work as well on high-dimensional data. We’ll see examples of such techniques throughout the book. At the same time, while this technique can help you build better models, it can also make those models harder to interpret. It’s easy to understand conclusions like “every extra year of experience adds an average of $10k in  d e f   t r a n s f o r m _ v e c t o r   v :   V e c t o r ,   c o m p o n e n t s :   L i s t [ V e c t o r ]     - >   V e c t o r :           r e t u r n   [ d o t   v ,   w     f o r   w   i n   c o m p o n e n t s ]     d e f   t r a n s f o r m   d a t a :   L i s t [ V e c t o r ] ,   c o m p o n e n t s :   L i s t [ V e c t o r ]     - >   L i s t [ V e c t o r ] :           r e t u r n   [ t r a n s f o r m _ v e c t o r   v ,   c o m p o n e n t s     f o r   v   i n   d a t a ]  salary.” It’s much harder to make sense of “every increase of 0.1 in the third principal component adds an average of $10k in salary.”  For Further Exploration  As mentioned at the end of Chapter 9, pandas is probably the primary Python tool for cleaning, munging, manipulating, and working with data. All the examples we did by hand in this chapter could be done much more simply using pandas. Python for Data Analysis  O’Reilly , by Wes McKinney, is probably the best way to learn pandas. scikit-learn has a wide variety of matrix decomposition functions, including PCA.   Chapter 11. Machine Learning  I am always ready to learn although I do not always like being taught.  —Winston Churchill  Many people imagine that data science is mostly machine learning and that data scientists mostly build and train and tweak machine learning models all day long.  Then again, many of those people don’t actually know what machine learning is.  In fact, data science is mostly turning business problems into data problems and collecting data and understanding data and cleaning data and formatting data, after which machine learning is almost an afterthought. Even so, it’s an interesting and essential afterthought that you pretty much have to know about in order to do data science.  Modeling Before we can talk about machine learning, we need to talk about models. What is a model? It’s simply a specification of a mathematical  or probabilistic  relationship that exists between different variables. For instance, if you’re trying to raise money for your social networking site, you might build a business model  likely in a spreadsheet  that takes inputs like “number of users,” “ad revenue per user,” and “number of employees” and outputs your annual profit for the next several years. A cookbook recipe entails a model that relates inputs like “number of eaters” and “hungriness” to quantities of ingredients needed. And if you’ve ever watched poker on television, you know that each player’s “win probability” is estimated in real time based on a model that takes into account the cards that have been revealed so far and the distribution of cards in the deck. The business model is probably based on simple mathematical relationships: profit is revenue minus expenses, revenue is units sold times average price, and so on. The recipe model is probably based on trial and   error—someone went in a kitchen and tried different combinations of ingredients until they found one they liked. And the poker model is based on probability theory, the rules of poker, and some reasonably innocuous assumptions about the random process by which cards are dealt.  What Is Machine Learning? Everyone has her own exact definition, but we’ll use machine learning to refer to creating and using models that are learned from data. In other contexts this might be called predictive modeling or data mining, but we will stick with machine learning. Typically, our goal will be to use existing data to develop models that we can use to predict various outcomes for new data, such as:  Whether an email message is spam or not Whether a credit card transaction is fraudulent Which advertisement a shopper is most likely to click on Which football team is going to win the Super Bowl  We’ll look at both supervised models  in which there is a set of data labeled with the correct answers to learn from  and unsupervised models  in which there are no such labels . There are various other types, like semisupervised  in which only some of the data are labeled , online  in which the model needs to continuously adjust to newly arriving data , and reinforcement  in which, after making a series of predictions, the model gets a signal indicating how well it did  that we won’t cover in this book. Now, in even the simplest situation there are entire universes of models that might describe the relationship we’re interested in. In most cases we will ourselves choose a parameterized family of models and then use data to learn parameters that are in some way optimal. For instance, we might assume that a person’s height is  roughly  a linear function of his weight and then use data to learn what that linear function is.   Or we might assume that a decision tree is a good way to diagnose what diseases our patients have and then use data to learn the “optimal” such tree. Throughout the rest of the book, we’ll be investigating different families of models that we can learn. But before we can do that, we need to better understand the fundamentals of machine learning. For the rest of the chapter, we’ll discuss some of those basic concepts, before we move on to the models themselves.  Overfitting and Underfitting A common danger in machine learning is overfitting—producing a model that performs well on the data you train it on but generalizes poorly to any new data. This could involve learning noise in the data. Or it could involve learning to identify specific inputs rather than whatever factors are actually predictive for the desired output. The other side of this is underfitting—producing a model that doesn’t perform well even on the training data, although typically when this happens you decide your model isn’t good enough and keep looking for a better one. In Figure 11-1, I’ve fit three polynomials to a sample of data.  Don’t worry about how; we’ll get to that in later chapters.    Figure 11-1. Overfitting and underfitting  The horizontal line shows the best fit degree 0  i.e., constant  polynomial. It severely underfits the training data. The best fit degree 9  i.e., 10- parameter  polynomial goes through every training data point exactly, but it very severely overfits; if we were to pick a few more data points, it would quite likely miss them by a lot. And the degree 1 line strikes a nice balance; it’s pretty close to every point, and—if these data are representative—the line will likely be close to new data points as well. Clearly, models that are too complex lead to overfitting and don’t generalize well beyond the data they were trained on. So how do we make sure our models aren’t too complex? The most fundamental approach involves using different data to train the model and to test the model. The simplest way to do this is to split the dataset, so that  for example  two- thirds of it is used to train the model, after which we measure the model’s   performance on the remaining third:  Often, we’ll have paired input variables and output variables. In that case, we need to make sure to put corresponding values together in either the training data or the test data:  As always, we want to make sure our code works right:  i m p o r t   r a n d o m   f r o m   t y p i n g   i m p o r t   T y p e V a r ,   L i s t ,   T u p l e   X   =   T y p e V a r   ' X '          g e n e r i c   t y p e   t o   r e p r e s e n t   a   d a t a   p o i n t     d e f   s p l i t _ d a t a   d a t a :   L i s t [ X ] ,   p r o b :   f l o a t     - >   T u p l e [ L i s t [ X ] ,   L i s t [ X ] ] :           " " " S p l i t   d a t a   i n t o   f r a c t i o n s   [ p r o b ,   1   -   p r o b ] " " "           d a t a   =   d a t a [ : ]                                            M a k e   a   s h a l l o w   c o p y           r a n d o m . s h u f f l e   d a t a                                  b e c a u s e   s h u f f l e   m o d i f i e s   t h e   l i s t .           c u t   =   i n t   l e n   d a t a     *   p r o b                    U s e   p r o b   t o   f i n d   a   c u t o f f           r e t u r n   d a t a [ : c u t ] ,   d a t a [ c u t : ]              a n d   s p l i t   t h e   s h u f f l e d   l i s t   t h e r e .     d a t a   =   [ n   f o r   n   i n   r a n g e   1 0 0 0   ]   t r a i n ,   t e s t   =   s p l i t _ d a t a   d a t a ,   0 . 7 5          T h e   p r o p o r t i o n s   s h o u l d   b e   c o r r e c t   a s s e r t   l e n   t r a i n     = =   7 5 0   a s s e r t   l e n   t e s t     = =   2 5 0        A n d   t h e   o r i g i n a l   d a t a   s h o u l d   b e   p r e s e r v e d     i n   s o m e   o r d e r     a s s e r t   s o r t e d   t r a i n   +   t e s t     = =   d a t a Y   =   T y p e V a r   ' Y '          g e n e r i c   t y p e   t o   r e p r e s e n t   o u t p u t   v a r i a b l e s     d e f   t r a i n _ t e s t _ s p l i t   x s :   L i s t [ X ] ,                                             y s :   L i s t [ Y ] ,                                             t e s t _ p c t :   f l o a t     - >   T u p l e [ L i s t [ X ] ,   L i s t [ X ] ,   L i s t [ Y ] ,                                                                                                                                     L i s t [ Y ] ] :              G e n e r a t e   t h e   i n d i c e s   a n d   s p l i t   t h e m           i d x s   =   [ i   f o r   i   i n   r a n g e   l e n   x s     ]           t r a i n _ i d x s ,   t e s t _ i d x s   =   s p l i t _ d a t a   i d x s ,   1   -   t e s t _ p c t               r e t u r n     [ x s [ i ]   f o r   i   i n   t r a i n _ i d x s ] ,        x _ t r a i n                           [ x s [ i ]   f o r   i   i n   t e s t _ i d x s ] ,          x _ t e s t                           [ y s [ i ]   f o r   i   i n   t r a i n _ i d x s ] ,        y _ t r a i n                           [ y s [ i ]   f o r   i   i n   t e s t _ i d x s ]            y _ t e s t  After which you can do something like:  If the model was overfit to the training data, then it will hopefully perform really poorly on the  completely separate  test data. Said differently, if it performs well on the test data, then you can be more confident that it’s fitting rather than overfitting. However, there are a couple of ways this can go wrong. The first is if there are common patterns in the test and training data that wouldn’t generalize to a larger dataset. For example, imagine that your dataset consists of user activity, with one row per user per week. In such a case, most users will appear in both the training data and the test data, and certain models might learn to identify users rather than discover relationships involving attributes. This isn’t a huge worry, although it did happen to me once. A bigger problem is if you use the test train split not just to judge a model but also to choose from among many models. In that case, although each individual model may not be overfit, “choosing a model that performs best on the test set” is a meta-training that makes the test set function as a second training set.  Of course the model that performed best on the test set is going to perform well on the test set.   x s   =   [ x   f o r   x   i n   r a n g e   1 0 0 0   ]        x s   a r e   1   . . .   1 0 0 0   y s   =   [ 2   *   x   f o r   x   i n   x s ]                  e a c h   y _ i   i s   t w i c e   x _ i   x _ t r a i n ,   x _ t e s t ,   y _ t r a i n ,   y _ t e s t   =   t r a i n _ t e s t _ s p l i t   x s ,   y s ,   0 . 2 5          C h e c k   t h a t   t h e   p r o p o r t i o n s   a r e   c o r r e c t   a s s e r t   l e n   x _ t r a i n     = =   l e n   y _ t r a i n     = =   7 5 0   a s s e r t   l e n   x _ t e s t     = =   l e n   y _ t e s t     = =   2 5 0        C h e c k   t h a t   t h e   c o r r e s p o n d i n g   d a t a   p o i n t s   a r e   p a i r e d   c o r r e c t l y   a s s e r t   a l l   y   = =   2   *   x   f o r   x ,   y   i n   z i p   x _ t r a i n ,   y _ t r a i n       a s s e r t   a l l   y   = =   2   *   x   f o r   x ,   y   i n   z i p   x _ t e s t ,   y _ t e s t     m o d e l   =   S o m e K i n d O f M o d e l       x _ t r a i n ,   x _ t e s t ,   y _ t r a i n ,   y _ t e s t   =   t r a i n _ t e s t _ s p l i t   x s ,   y s ,   0 . 3 3     m o d e l . t r a i n   x _ t r a i n ,   y _ t r a i n     p e r f o r m a n c e   =   m o d e l . t e s t   x _ t e s t ,   y _ t e s t    In such a situation, you should split the data into three parts: a training set for building models, a validation set for choosing among trained models, and a test set for judging the final model.  Correctness When I’m not doing data science, I dabble in medicine. And in my spare time I’ve come up with a cheap, noninvasive test that can be given to a newborn baby that predicts—with greater than 98% accuracy—whether the newborn will ever develop leukemia. My lawyer has convinced me the test is unpatentable, so I’ll share with you the details here: predict leukemia if and only if the baby is named Luke  which sounds sort of like “leukemia” . As we’ll see, this test is indeed more than 98% accurate. Nonetheless, it’s an incredibly stupid test, and a good illustration of why we don’t typically use “accuracy” to measure how good a  binary classification  model is. Imagine building a model to make a binary judgment. Is this email spam? Should we hire this candidate? Is this air traveler secretly a terrorist? Given a set of labeled data and such a predictive model, every data point lies in one of four categories: True positive  “This message is spam, and we correctly predicted spam.”  False positive  Type 1 error   “This message is not spam, but we predicted spam.”  False negative  Type 2 error   “This message is spam, but we predicted not spam.”  True negative  “This message is not spam, and we correctly predicted not spam.”  We often represent these as counts in a confusion matrix:   Spam  Not spam  Predict “spam”  True positive  False positive  Predict “not spam” False negative True negative  Let’s see how my leukemia test fits into this framework. These days approximately 5 babies out of 1,000 are named Luke. And the lifetime prevalence of leukemia is about 1.4%, or 14 out of every 1,000 people. If we believe these two factors are independent and apply my “Luke is for leukemia” test to 1 million people, we’d expect to see a confusion matrix like:  Leukemia No leukemia Total  “Luke”  70  4,930  5,000  Not “Luke” 13,930  981,070  995,000  Total  14,000  986,000  1,000,000  We can then use these to compute various statistics about model performance. For example, accuracy is defined as the fraction of correct predictions:  That seems like a pretty impressive number. But clearly this is not a good test, which means that we probably shouldn’t put a lot of credence in raw accuracy. It’s common to look at the combination of precision and recall. Precision measures how accurate our positive predictions were:  d e f   a c c u r a c y   t p :   i n t ,   f p :   i n t ,   f n :   i n t ,   t n :   i n t     - >   f l o a t :           c o r r e c t   =   t p   +   t n           t o t a l   =   t p   +   f p   +   f n   +   t n           r e t u r n   c o r r e c t       t o t a l     a s s e r t   a c c u r a c y   7 0 ,   4 9 3 0 ,   1 3 9 3 0 ,   9 8 1 0 7 0     = =   0 . 9 8 1 1 4  And recall measures what fraction of the positives our model identified:  These are both terrible numbers, reflecting that this is a terrible model. Sometimes precision and recall are combined into the F1 score, which is defined as:  This is the harmonic mean of precision and recall and necessarily lies between them. Usually the choice of a model involves a tradeoff between precision and recall. A model that predicts “yes” when it’s even a little bit confident will probably have a high recall but a low precision; a model that predicts “yes” only when it’s extremely confident is likely to have a low recall and a high precision. Alternatively, you can think of this as a tradeoff between false positives and false negatives. Saying “yes” too often will give you lots of false positives; saying “no” too often will give you lots of false negatives. Imagine that there were 10 risk factors for leukemia, and that the more of them you had the more likely you were to develop leukemia. In that case you can imagine a continuum of tests: “predict leukemia if at least one risk factor,” “predict leukemia if at least two risk factors,” and so on. As you  d e f   p r e c i s i o n   t p :   i n t ,   f p :   i n t ,   f n :   i n t ,   t n :   i n t     - >   f l o a t :           r e t u r n   t p         t p   +   f p       a s s e r t   p r e c i s i o n   7 0 ,   4 9 3 0 ,   1 3 9 3 0 ,   9 8 1 0 7 0     = =   0 . 0 1 4 d e f   r e c a l l   t p :   i n t ,   f p :   i n t ,   f n :   i n t ,   t n :   i n t     - >   f l o a t :           r e t u r n   t p         t p   +   f n       a s s e r t   r e c a l l   7 0 ,   4 9 3 0 ,   1 3 9 3 0 ,   9 8 1 0 7 0     = =   0 . 0 0 5 d e f   f 1 _ s c o r e   t p :   i n t ,   f p :   i n t ,   f n :   i n t ,   t n :   i n t     - >   f l o a t :           p   =   p r e c i s i o n   t p ,   f p ,   f n ,   t n             r   =   r e c a l l   t p ,   f p ,   f n ,   t n               r e t u r n   2   *   p   *   r         p   +   r    increase the threshold, you increase the test’s precision  since people with more risk factors are more likely to develop the disease , and you decrease the test’s recall  since fewer and fewer of the eventual disease-sufferers will meet the threshold . In cases like this, choosing the right threshold is a matter of finding the right tradeoff.  The Bias-Variance Tradeoff Another way of thinking about the overfitting problem is as a tradeoff between bias and variance. Both are measures of what would happen if you were to retrain your model many times on different sets of training data  from the same larger population . For example, the degree 0 model in “Overfitting and Underfitting” will make a lot of mistakes for pretty much any training set  drawn from the same population , which means that it has a high bias. However, any two randomly chosen training sets should give pretty similar models  since any two randomly chosen training sets should have pretty similar average values . So we say that it has a low variance. High bias and low variance typically correspond to underfitting. On the other hand, the degree 9 model fit the training set perfectly. It has very low bias but very high variance  since any two training sets would likely give rise to very different models . This corresponds to overfitting. Thinking about model problems this way can help you figure out what to do when your model doesn’t work so well. If your model has high bias  which means it performs poorly even on your training data , one thing to try is adding more features. Going from the degree 0 model in “Overfitting and Underfitting” to the degree 1 model was a big improvement. If your model has high variance, you can similarly remove features. But another solution is to obtain more data  if you can .   In Figure 11-2, we fit a degree 9 polynomial to different size samples. The model fit based on 10 data points is all over the place, as we saw before. If we instead train on 100 data points, there’s much less overfitting. And the model trained from 1,000 data points looks very similar to the degree 1 model. Holding model complexity constant, the more data you have, the harder it is to overfit. On the other hand, more data won’t help with bias. If your model doesn’t use enough features to capture regularities in the data, throwing more data at it won’t help.  Figure 11-2. Reducing variance with more data  Feature Extraction and Selection As has been mentioned, when your data doesn’t have enough features, your model is likely to underfit. And when your data has too many features, it’s   easy to overfit. But what are features, and where do they come from? Features are whatever inputs we provide to our model. In the simplest case, features are simply given to you. If you want to predict someone’s salary based on her years of experience, then years of experience is the only feature you have.  Although, as we saw in “Overfitting and Underfitting”, you might also consider adding years of experience squared, cubed, and so on if that helps you build a better model.  Things become more interesting as your data becomes more complicated. Imagine trying to build a spam filter to predict whether an email is junk or not. Most models won’t know what to do with a raw email, which is just a collection of text. You’ll have to extract features. For example:  Does the email contain the word Viagra? How many times does the letter d appear? What was the domain of the sender?  The answer to a question like the first question here is simply a yes or no, which we typically encode as a 1 or 0. The second is a number. And the third is a choice from a discrete set of options. Pretty much always, we’ll extract features from our data that fall into one of these three categories. What’s more, the types of features we have constrain the types of models we can use.  The Naive Bayes classifier we’ll build in Chapter 13 is suited to yes-or-no features, like the first one in the preceding list. Regression models, which we’ll study in Chapters 14 and 16, require numeric features  which could include dummy variables that are 0s and 1s . And decision trees, which we’ll look at in Chapter 17, can deal with numeric or categorical data.   Although in the spam filter example we looked for ways to create features, sometimes we’ll instead look for ways to remove features. For example, your inputs might be vectors of several hundred numbers. Depending on the situation, it might be appropriate to distill these down to a handful of important dimensions  as in “Dimensionality Reduction”  and use only that small number of features. Or it might be appropriate to use a technique  like regularization, which we’ll look at in “Regularization”  that penalizes models the more features they use. How do we choose features? That’s where a combination of experience and domain expertise comes into play. If you’ve received lots of emails, then you probably have a sense that the presence of certain words might be a good indicator of spamminess. And you might also get the sense that the number of ds is likely not a good indicator of spamminess. But in general you’ll have to try different things, which is part of the fun.  For Further Exploration  Keep reading! The next several chapters are about different families of machine learning models. The Coursera Machine Learning course is the original MOOC and is a good place to get a deeper understanding of the basics of machine learning. The Elements of Statistical Learning, by Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie  Springer , is a somewhat canonical textbook that can be downloaded online for free. But be warned: it’s very mathy.   Chapter 12. k-Nearest Neighbors  If you want to annoy your neighbors, tell the truth about them. —Pietro Aretino  Imagine that you’re trying to predict how I’m going to vote in the next presidential election. If you know nothing else about me  and if you have the data , one sensible approach is to look at how my neighbors are planning to vote. Living in Seattle, as I do, my neighbors are invariably planning to vote for the Democratic candidate, which suggests that “Democratic candidate” is a good guess for me as well. Now imagine you know more about me than just geography—perhaps you know my age, my income, how many kids I have, and so on. To the extent my behavior is influenced  or characterized  by those things, looking just at my neighbors who are close to me among all those dimensions seems likely to be an even better predictor than looking at all my neighbors. This is the idea behind nearest neighbors classification.  The Model Nearest neighbors is one of the simplest predictive models there is. It makes no mathematical assumptions, and it doesn’t require any sort of heavy machinery. The only things it requires are:  Some notion of distance An assumption that points that are close to one another are similar  Most of the techniques we’ll see in this book look at the dataset as a whole in order to learn patterns in the data. Nearest neighbors, on the other hand,   quite consciously neglects a lot of information, since the prediction for each new point depends only on the handful of points closest to it. What’s more, nearest neighbors is probably not going to help you understand the drivers of whatever phenomenon you’re looking at. Predicting my votes based on my neighbors’ votes doesn’t tell you much about what causes me to vote the way I do, whereas some alternative model that predicted my vote based on  say  my income and marital status very well might. In the general situation, we have some data points and we have a corresponding set of labels. The labels could be T whether each input satisfies some condition like “is spam?” or “is poisonous?” or “would be enjoyable to watch?” Or they could be categories, like movie ratings  G, PG, PG-13, R, NC-17 . Or they could be the names of presidential candidates. Or they could be favorite programming languages. In our case, the data points will be vectors, which means that we can use the  e, indicating  e and F  e function from Chapter 4.  Let’s say we’ve picked a number k like 3 or 5. Then, when we want to classify some new data point, we find the k nearest labeled points and let them vote on the new output. To do this, we’ll need a function that counts votes. One possibility is:  But this doesn’t do anything intelligent with ties. For example, imagine we’re rating movies and the five nearest movies are rated G, G, PG, PG,  r u a l s d i s t a n c f r o m   t y p i n g   i m p o r t   L i s t   f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     d e f   r a w _ m a j o r i t y _ v o t e   l a b e l s :   L i s t [ s t r ]     - >   s t r :           v o t e s   =   C o u n t e r   l a b e l s             w i n n e r ,   _   =   v o t e s . m o s t _ c o m m o n   1   [ 0 ]           r e t u r n   w i n n e r     a s s e r t   r a w _ m a j o r i t y _ v o t e   [ ' a ' ,   ' b ' ,   ' c ' ,   ' b ' ]     = =   ' b '  and R. Then G has two votes and PG also has two votes. In that case, we have several options:  Pick one of the winners at random. Weight the votes by distance and pick the weighted winner. Reduce k until we find a unique winner.  We’ll implement the third:  This approach is sure to work eventually, since in the worst case we go all the way down to just one label, at which point that one label wins. With this function it’s easy to create a classifier:  d e f   m a j o r i t y _ v o t e   l a b e l s :   L i s t [ s t r ]     - >   s t r :           " " " A s s u m e s   t h a t   l a b e l s   a r e   o r d e r e d   f r o m   n e a r e s t   t o   f a r t h e s t . " " "           v o t e _ c o u n t s   =   C o u n t e r   l a b e l s             w i n n e r ,   w i n n e r _ c o u n t   =   v o t e _ c o u n t s . m o s t _ c o m m o n   1   [ 0 ]           n u m _ w i n n e r s   =   l e n   [ c o u n t                                                 f o r   c o u n t   i n   v o t e _ c o u n t s . v a l u e s                                                     i f   c o u n t   = =   w i n n e r _ c o u n t ]               i f   n u m _ w i n n e r s   = =   1 :                   r e t u r n   w i n n e r                                              u n i q u e   w i n n e r ,   s o   r e t u r n   i t           e l s e :                   r e t u r n   m a j o r i t y _ v o t e   l a b e l s [ : - 1 ]        t r y   a g a i n   w i t h o u t   t h e   f a r t h e s t        T i e ,   s o   l o o k   a t   f i r s t   4 ,   t h e n   ' b '   a s s e r t   m a j o r i t y _ v o t e   [ ' a ' ,   ' b ' ,   ' c ' ,   ' b ' ,   ' a ' ]     = =   ' b ' f r o m   t y p i n g   i m p o r t   N a m e d T u p l e   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r ,   d i s t a n c e     c l a s s   L a b e l e d P o i n t   N a m e d T u p l e   :           p o i n t :   V e c t o r           l a b e l :   s t r     d e f   k n n _ c l a s s i f y   k :   i n t ,                                     l a b e l e d _ p o i n t s :   L i s t [ L a b e l e d P o i n t ] ,                                     n e w _ p o i n t :   V e c t o r     - >   s t r :                O r d e r   t h e   l a b e l e d   p o i n t s   f r o m   n e a r e s t   t o   f a r t h e s t .    Let’s take a look at how this works.  Example: The Iris Dataset The Iris dataset is a staple of machine learning. It contains a bunch of measurements for 150 flowers representing three species of iris. For each flower we have its petal length, petal width, sepal length, and sepal width, as well as its species. You can download it from https:  archive.ics.uci.edu ml datasets iris:  The data is comma-separated, with fields:  For example, the first row looks like:  In this section we’ll try to build a model that can predict the class  that is, the species  from the first four measurements.          b y _ d i s t a n c e   =   s o r t e d   l a b e l e d _ p o i n t s ,                                                     k e y = l a m b d a   l p :   d i s t a n c e   l p . p o i n t ,   n e w _ p o i n t                    F i n d   t h e   l a b e l s   f o r   t h e   k   c l o s e s t           k _ n e a r e s t _ l a b e l s   =   [ l p . l a b e l   f o r   l p   i n   b y _ d i s t a n c e [ : k ] ]                a n d   l e t   t h e m   v o t e .           r e t u r n   m a j o r i t y _ v o t e   k _ n e a r e s t _ l a b e l s   i m p o r t   r e q u e s t s     d a t a   =   r e q u e s t s . g e t         " h t t p s :     a r c h i v e . i c s . u c i . e d u   m l   m a c h i n e - l e a r n i n g - d a t a b a s e s   i r i s   i r i s . d a t a "         w i t h   o p e n   ' i r i s . d a t ' ,   ' w '     a s   f :           f . w r i t e   d a t a . t e x t   s e p a l _ l e n g t h ,   s e p a l _ w i d t h ,   p e t a l _ l e n g t h ,   p e t a l _ w i d t h ,   c l a s s 5 . 1 , 3 . 5 , 1 . 4 , 0 . 2 , I r i s - s e t o s a  To start with, let’s load and explore the data. Our nearest neighbors function expects a L  t, so let’s represent our data that way:  We’d like to plot the measurements so we can see how they vary by species. Unfortunately, they are four-dimensional, which makes them tricky to plot. One thing we can do is look at the scatterplots for each of the six pairs of measurements  Figure 12-1 . I won’t explain all the details, but it’s a nice illustration of more complicated things you can do with matplotlib, so it’s worth studying:  a b e l e d P o i n f r o m   t y p i n g   i m p o r t   D i c t   i m p o r t   c s v   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     d e f   p a r s e _ i r i s _ r o w   r o w :   L i s t [ s t r ]     - >   L a b e l e d P o i n t :           " " "           s e p a l _ l e n g t h ,   s e p a l _ w i d t h ,   p e t a l _ l e n g t h ,   p e t a l _ w i d t h ,   c l a s s           " " "           m e a s u r e m e n t s   =   [ f l o a t   v a l u e     f o r   v a l u e   i n   r o w [ : - 1 ] ]              c l a s s   i s   e . g .   " I r i s - v i r g i n i c a " ;   w e   j u s t   w a n t   " v i r g i n i c a "           l a b e l   =   r o w [ - 1 ] . s p l i t   " - "   [ - 1 ]             r e t u r n   L a b e l e d P o i n t   m e a s u r e m e n t s ,   l a b e l       w i t h   o p e n   ' i r i s . d a t a '     a s   f :           r e a d e r   =   c s v . r e a d e r   f             i r i s _ d a t a   =   [ p a r s e _ i r i s _ r o w   r o w     f o r   r o w   i n   r e a d e r ]        W e ' l l   a l s o   g r o u p   j u s t   t h e   p o i n t s   b y   s p e c i e s   l a b e l   s o   w e   c a n   p l o t   t h e m   p o i n t s _ b y _ s p e c i e s :   D i c t [ s t r ,   L i s t [ V e c t o r ] ]   =   d e f a u l t d i c t   l i s t     f o r   i r i s   i n   i r i s _ d a t a :           p o i n t s _ b y _ s p e c i e s [ i r i s . l a b e l ] . a p p e n d   i r i s . p o i n t   f r o m   m a t p l o t l i b   i m p o r t   p y p l o t   a s   p l t   m e t r i c s   =   [ ' s e p a l   l e n g t h ' ,   ' s e p a l   w i d t h ' ,   ' p e t a l   l e n g t h ' ,   ' p e t a l   w i d t h ' ]   p a i r s   =   [   i ,   j     f o r   i   i n   r a n g e   4     f o r   j   i n   r a n g e   4     i f   i   <   j ]   m a r k s   =   [ ' + ' ,   ' . ' ,   ' x ' ]        w e   h a v e   3   c l a s s e s ,   s o   3   m a r k e r s     f i g ,   a x   =   p l t . s u b p l o t s   2 ,   3       f o r   r o w   i n   r a n g e   2   :           f o r   c o l   i n   r a n g e   3   :                   i ,   j   =   p a i r s [ 3   *   r o w   +   c o l ]    Figure 12-1. Iris scatterplots  If you look at those plots, it seems like the measurements really do cluster by species. For example, looking at sepal length and sepal width alone, you probably couldn’t distinguish between versicolor and virginica. But once you add petal length and width into the mix, it seems like you should be able to predict the species based on the nearest neighbors.                  a x [ r o w ] [ c o l ] . s e t _ t i t l e   f " { m e t r i c s [ i ] }   v s   { m e t r i c s [ j ] } " ,   f o n t s i z e = 8                     a x [ r o w ] [ c o l ] . s e t _ x t i c k s   [ ]                     a x [ r o w ] [ c o l ] . s e t _ y t i c k s   [ ]                       f o r   m a r k ,     s p e c i e s ,   p o i n t s     i n   z i p   m a r k s ,   p o i n t s _ b y _ s p e c i e s . i t e m s       :                           x s   =   [ p o i n t [ i ]   f o r   p o i n t   i n   p o i n t s ]                           y s   =   [ p o i n t [ j ]   f o r   p o i n t   i n   p o i n t s ]                           a x [ r o w ] [ c o l ] . s c a t t e r   x s ,   y s ,   m a r k e r = m a r k ,   l a b e l = s p e c i e s       a x [ - 1 ] [ - 1 ] . l e g e n d   l o c = ' l o w e r   r i g h t ' ,   p r o p = { ' s i z e ' :   6 }     p l t . s h o w      To start with, let’s split the data into a test set and a training set:  The training set will be the “neighbors” that we’ll use to classify the points in the test set. We just need to choose a value for k, the number of neighbors who get to vote. Too small  think k = 1 , and we let outliers have too much influence; too large  think k = 105 , and we just predict the most common class in the dataset. In a real application  and with more data , we might create a separate validation set and use it to choose k. Here we’ll just use k = 5:  On this simple dataset, the model predicts almost perfectly. There’s one versicolor for which it predicts virginica, but otherwise it gets things exactly right.  i m p o r t   r a n d o m   f r o m   s c r a t c h . m a c h i n e _ l e a r n i n g   i m p o r t   s p l i t _ d a t a     r a n d o m . s e e d   1 2     i r i s _ t r a i n ,   i r i s _ t e s t   =   s p l i t _ d a t a   i r i s _ d a t a ,   0 . 7 0     a s s e r t   l e n   i r i s _ t r a i n     = =   0 . 7   *   1 5 0   a s s e r t   l e n   i r i s _ t e s t     = =   0 . 3   *   1 5 0 f r o m   t y p i n g   i m p o r t   T u p l e        t r a c k   h o w   m a n y   t i m e s   w e   s e e     p r e d i c t e d ,   a c t u a l     c o n f u s i o n _ m a t r i x :   D i c t [ T u p l e [ s t r ,   s t r ] ,   i n t ]   =   d e f a u l t d i c t   i n t     n u m _ c o r r e c t   =   0     f o r   i r i s   i n   i r i s _ t e s t :           p r e d i c t e d   =   k n n _ c l a s s i f y   5 ,   i r i s _ t r a i n ,   i r i s . p o i n t             a c t u a l   =   i r i s . l a b e l             i f   p r e d i c t e d   = =   a c t u a l :                   n u m _ c o r r e c t   + =   1             c o n f u s i o n _ m a t r i x [   p r e d i c t e d ,   a c t u a l   ]   + =   1     p c t _ c o r r e c t   =   n u m _ c o r r e c t       l e n   i r i s _ t e s t     p r i n t   p c t _ c o r r e c t ,   c o n f u s i o n _ m a t r i x    The Curse of Dimensionality The k-nearest neighbors algorithm runs into trouble in higher dimensions thanks to the “curse of dimensionality,” which boils down to the fact that high-dimensional spaces are vast. Points in high-dimensional spaces tend not to be close to one another at all. One way to see this is by randomly generating pairs of points in the d-dimensional “unit cube” in a variety of dimensions, and calculating the distances between them. Generating random points should be second nature by now:  as is writing a function to generate the distances:  For every dimension from 1 to 100, we’ll compute 10,000 distances and use those to compute the average distance between points and the minimum distance between points in each dimension  Figure 12-2 :  d e f   r a n d o m _ p o i n t   d i m :   i n t     - >   V e c t o r :           r e t u r n   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   d i m   ] d e f   r a n d o m _ d i s t a n c e s   d i m :   i n t ,   n u m _ p a i r s :   i n t     - >   L i s t [ f l o a t ] :           r e t u r n   [ d i s t a n c e   r a n d o m _ p o i n t   d i m   ,   r a n d o m _ p o i n t   d i m                               f o r   _   i n   r a n g e   n u m _ p a i r s   ] i m p o r t   t q d m   d i m e n s i o n s   =   r a n g e   1 ,   1 0 1       a v g _ d i s t a n c e s   =   [ ]   m i n _ d i s t a n c e s   =   [ ]     r a n d o m . s e e d   0     f o r   d i m   i n   t q d m . t q d m   d i m e n s i o n s ,   d e s c = " C u r s e   o f   D i m e n s i o n a l i t y "   :           d i s t a n c e s   =   r a n d o m _ d i s t a n c e s   d i m ,   1 0 0 0 0                  1 0 , 0 0 0   r a n d o m   p a i r s           a v g _ d i s t a n c e s . a p p e n d   s u m   d i s t a n c e s         1 0 0 0 0          t r a c k   t h e   a v e r a g e           m i n _ d i s t a n c e s . a p p e n d   m i n   d i s t a n c e s                            t r a c k   t h e   m i n i m u m  Figure 12-2. The curse of dimensionality  As the number of dimensions increases, the average distance between points increases. But what’s more problematic is the ratio between the closest distance and the average distance  Figure 12-3 :  m i n _ a v g _ r a t i o   =   [ m i n _ d i s t       a v g _ d i s t                                     f o r   m i n _ d i s t ,   a v g _ d i s t   i n   z i p   m i n _ d i s t a n c e s ,   a v g _ d i s t a n c e s   ]  Figure 12-3. The curse of dimensionality again  In low-dimensional datasets, the closest points tend to be much closer than average. But two points are close only if they’re close in every dimension, and every extra dimension—even if just noise—is another opportunity for each point to be farther away from every other point. When you have a lot of dimensions, it’s likely that the closest points aren’t much closer than average, so two points being close doesn’t mean very much  unless there’s a lot of structure in your data that makes it behave as if it were much lower- dimensional . A different way of thinking about the problem involves the sparsity of higher-dimensional spaces. If you pick 50 random numbers between 0 and 1, you’ll probably get a pretty good sample of the unit interval  Figure 12-4 .   Figure 12-4. Fifty random points in one dimension  If you pick 50 random points in the unit square, you’ll get less coverage  Figure 12-5 .   Figure 12-5. Fifty random points in two dimensions  And in three dimensions, less still  Figure 12-6 . matplotlib doesn’t graph four dimensions well, so that’s as far as we’ll go, but you can see already that there are starting to be large empty spaces with no points near them. In more dimensions—unless you get exponentially more data—those large empty spaces represent regions far from all the points you want to use in your predictions. So if you’re trying to use nearest neighbors in higher dimensions, it’s probably a good idea to do some kind of dimensionality reduction first.   Figure 12-6. Fifty random points in three dimensions  For Further Exploration scikit-learn has many nearest neighbor models.   Chapter 13. Naive Bayes  It is well for the heart to be naive and for the mind not to be.  —Anatole France A social network isn’t much good if people can’t network. Accordingly, DataSciencester has a popular feature that allows members to send messages to other members. And while most members are responsible citizens who send only well-received “how’s it going?” messages, a few miscreants persistently spam other members about get-rich schemes, no-prescription-required pharmaceuticals, and for-profit data science credentialing programs. Your users have begun to complain, and so the VP of Messaging has asked you to use data science to figure out a way to filter out these spam messages.  A Really Dumb Spam Filter Imagine a “universe” that consists of receiving a message chosen randomly from all possible messages. Let S be the event “the message is spam” and B be the event “the message contains the word bitcoin.” Bayes’s theorem tells us that the probability that the message is spam conditional on containing the word bitcoin is:  The numerator is the probability that a message is spam and contains bitcoin, while the denominator is just the probability that a message contains bitcoin. Hence, you can think of this calculation as simply representing the proportion of bitcoin messages that are spam. If we have a large collection of messages we know are spam, and a large collection of messages we know are not spam, then we can easily estimate P BS  and P B ¬S . If we further assume that any message is equally likely to be spam or not spam  so that P S  = P ¬S  = 0.5 , then:  For example, if 50% of spam messages have the word bitcoin, but only 1% of nonspam messages do, then the probability that any given bitcoin-containing email  P   S  B   = [ P   B  S   P   S   ]   [ P   B  S   P   S   + P   B  ¬ S   P   ¬ S   ] P   S  B   = P   B  S     [ P   B  S   + P   B  ¬ S   ]  is spam is:  i  i  1  n  A More Sophisticated Spam Filter Imagine now that we have a vocabulary of many words, w  ..., w . To move this into the realm of probability theory, we’ll write X  for the event “a message contains the word w .” Also imagine that  through some unspecified-at-this-point process  we’ve come up with an estimate P X S  for the probability that a spam message contains the ith word, and a similar estimate P X ¬S  for the probability that a nonspam message contains the ith word. The key to Naive Bayes is making the  big  assumption that the presences  or absences  of each word are independent of one another, conditional on a message being spam or not. Intuitively, this assumption means that knowing whether a certain spam message contains the word bitcoin gives you no information about whether that same message contains the word rolex. In math terms, this means that:  i  i  This is an extreme assumption.  There’s a reason the technique has naive in its name.  Imagine that our vocabulary consists only of the words bitcoin and rolex, and that half of all spam messages are for “earn bitcoin” and that the other half are for “authentic rolex.” In this case, the Naive Bayes estimate that a spam message contains both bitcoin and rolex is:  since we’ve assumed away the knowledge that bitcoin and rolex actually never occur together. Despite the unrealisticness of this assumption, this model often performs well and has historically been used in actual spam filters. The same Bayes’s theorem reasoning we used for our “bitcoin-only” spam filter tells us that we can calculate the probability a message is spam using the equation:  The Naive Bayes assumption allows us to compute each of the probabilities on the right simply by multiplying together the individual probability estimates for each  0 . 5     0 . 5 + 0 . 0 1   = 9 8 % P   X 1 = x 1 , . . . , X n = x n  S   = P   X 1 = x 1  S   × ⋯ × P   X n = x n  S   P   X 1 = 1 , X 2 = 1  S   = P   X 1 = 1  S   P   X 2 = 1  S   = . 5 × . 5 = . 2 5 P   S  X = x   = P   X = x  S     [ P   X = x  S   + P   X = x  ¬ S   ]  vocabulary word. In practice, you usually want to avoid multiplying lots of probabilities together, to prevent a problem called underflow, in which computers don’t deal well with floating-point numbers that are too close to 0. Recalling from algebra that   b and that e  x, we usually compute p  as the equivalent  but floating-point-friendlier :  i.    and P  The only challenge left is coming up with estimates for P  , the probabilities that a spam message  or nonspam message  contains the word w i. If we have a fair number of “training” messages labeled as spam and not spam, an obvious first try is to estimate P   simply as the fraction of spam messages containing the word w This causes a big problem, though. Imagine that in our training set the vocabulary word data only occurs in nonspam messages. Then we’d estimate P 0. The result is that our Naive Bayes classifier would always assign spam probability 0 to any message containing the word data, even a message like “data on free bitcoin and authentic rolex watches.” To avoid this problem, we usually use some kind of smoothing. In particular, we’ll choose a pseudocount—k—and estimate the probability of seeing the ith word in a spam message as:   . That is, when computing the spam probabilities for  We do similarly for P the ith word, we assume we also saw k additional nonspams containing the word and k additional nonspams not containing the word. For example, if data occurs in 0 98 spam messages, and if k is 1, we estimate P dataS  as 1 100 = 0.01, which allows our classifier to still assign some nonzero spam probability to messages that contain the word data.  Implementation Now we have all the pieces we need to build our classifier. First, let’s create a simple function to tokenize messages into distinct words. We’ll first convert each  l o g   a b   = l o g a + l o g x p   l o g x   = 1 * ⋯ * p n e x p   l o g   p 1   + ⋯ + l o g   p n       X i  S   X i  ¬ S   X i  S   d a t a  S   = P   X i  S   =   k + n u m b e r o f s p a m s c o n t a i n i n g w i       2 k + n u m b e r o f s p a m s     X i  ¬ S  message to lowercase, then use r numbers, and apostrophes. Finally, we’ll use s  l to extract “words” consisting of letters,  t to get just the distinct words:  We’ll also define a type for our training data:  As our classifier needs to keep track of tokens, counts, and labels from the training data, we’ll make it a class. Following convention, we refer to nonspam emails as ham emails. The constructor will take just one parameter, the pseudocount to use when computing probabilities. It also initializes an empty set of tokens, counters to track how often each token is seen in spam messages and ham messages, and counts of how many spam and ham messages it was trained on:  Next, we’ll give it a method to train it on a bunch of messages. First, we increment the s  s counts. Then we tokenize each message  s and h  e . f i n d a l e f r o m   t y p i n g   i m p o r t   S e t   i m p o r t   r e     d e f   t o k e n i z e   t e x t :   s t r     - >   S e t [ s t r ] :           t e x t   =   t e x t . l o w e r                                                          C o n v e r t   t o   l o w e r c a s e ,           a l l _ w o r d s   =   r e . f i n d a l l   " [ a - z 0 - 9 ' ] + " ,   t e x t          e x t r a c t   t h e   w o r d s ,   a n d           r e t u r n   s e t   a l l _ w o r d s                                                    r e m o v e   d u p l i c a t e s .     a s s e r t   t o k e n i z e   " D a t a   S c i e n c e   i s   s c i e n c e "     = =   { " d a t a " ,   " s c i e n c e " ,   " i s " } f r o m   t y p i n g   i m p o r t   N a m e d T u p l e     c l a s s   M e s s a g e   N a m e d T u p l e   :           t e x t :   s t r           i s _ s p a m :   b o o l f r o m   t y p i n g   i m p o r t   L i s t ,   T u p l e ,   D i c t ,   I t e r a b l e   i m p o r t   m a t h   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     c l a s s   N a i v e B a y e s C l a s s i f i e r :           d e f   _ _ i n i t _ _   s e l f ,   k :   f l o a t   =   0 . 5     - >   N o n e :                   s e l f . k   =   k        s m o o t h i n g   f a c t o r                     s e l f . t o k e n s :   S e t [ s t r ]   =   s e t                       s e l f . t o k e n _ s p a m _ c o u n t s :   D i c t [ s t r ,   i n t ]   =   d e f a u l t d i c t   i n t                     s e l f . t o k e n _ h a m _ c o u n t s :   D i c t [ s t r ,   i n t ]   =   d e f a u l t d i c t   i n t                     s e l f . s p a m _ m e s s a g e s   =   s e l f . h a m _ m e s s a g e s   =   0 p a m _ m e s s a g e a m _ m e s s a g e  text, and for each token we increment the t  s or  s based on the message type:  Ultimately we’ll want to predict P spam  token . As we saw earlier, to apply Bayes’s theorem we need to know P token  spam  and P token  ham  for each token in the vocabulary. So we’ll create a “private” helper function to compute those:  Finally, we’re ready to write our p multiplying together lots of small probabilities, we’ll instead sum up the log probabilities:  t method. As mentioned earlier, rather than  o k e n _ s p a m _ c o u n t t o k e n _ h a m _ c o u n t         d e f   t r a i n   s e l f ,   m e s s a g e s :   I t e r a b l e [ M e s s a g e ]     - >   N o n e :                   f o r   m e s s a g e   i n   m e s s a g e s :                              I n c r e m e n t   m e s s a g e   c o u n t s                           i f   m e s s a g e . i s _ s p a m :                                   s e l f . s p a m _ m e s s a g e s   + =   1                           e l s e :                                   s e l f . h a m _ m e s s a g e s   + =   1                                I n c r e m e n t   w o r d   c o u n t s                           f o r   t o k e n   i n   t o k e n i z e   m e s s a g e . t e x t   :                                   s e l f . t o k e n s . a d d   t o k e n                                     i f   m e s s a g e . i s _ s p a m :                                           s e l f . t o k e n _ s p a m _ c o u n t s [ t o k e n ]   + =   1                                   e l s e :                                           s e l f . t o k e n _ h a m _ c o u n t s [ t o k e n ]   + =   1         d e f   _ p r o b a b i l i t i e s   s e l f ,   t o k e n :   s t r     - >   T u p l e [ f l o a t ,   f l o a t ] :                   " " " r e t u r n s   P   t o k e n      s p a m     a n d   P   t o k e n      h a m   " " "                   s p a m   =   s e l f . t o k e n _ s p a m _ c o u n t s [ t o k e n ]                   h a m   =   s e l f . t o k e n _ h a m _ c o u n t s [ t o k e n ]                     p _ t o k e n _ s p a m   =     s p a m   +   s e l f . k           s e l f . s p a m _ m e s s a g e s   +   2   *   s e l f . k                     p _ t o k e n _ h a m   =     h a m   +   s e l f . k           s e l f . h a m _ m e s s a g e s   +   2   *   s e l f . k                       r e t u r n   p _ t o k e n _ s p a m ,   p _ t o k e n _ h a m r e d i c         d e f   p r e d i c t   s e l f ,   t e x t :   s t r     - >   f l o a t :                   t e x t _ t o k e n s   =   t o k e n i z e   t e x t                     l o g _ p r o b _ i f _ s p a m   =   l o g _ p r o b _ i f _ h a m   =   0 . 0                        I t e r a t e   t h r o u g h   e a c h   w o r d   i n   o u r   v o c a b u l a r y                   f o r   t o k e n   i n   s e l f . t o k e n s :                           p r o b _ i f _ s p a m ,   p r o b _ i f _ h a m   =   s e l f . _ p r o b a b i l i t i e s   t o k e n                                  I f   * t o k e n *   a p p e a r s   i n   t h e   m e s s a g e ,    And now we have a classifier.  Testing Our Model Let’s make sure our model works by writing some unit tests for it.  First, let’s check that it got the counts right:  Now let’s make a prediction. We’ll also  laboriously  go through our Naive Bayes logic by hand, and make sure that we get the same result:                             a d d   t h e   l o g   p r o b a b i l i t y   o f   s e e i n g   i t                           i f   t o k e n   i n   t e x t _ t o k e n s :                                   l o g _ p r o b _ i f _ s p a m   + =   m a t h . l o g   p r o b _ i f _ s p a m                                     l o g _ p r o b _ i f _ h a m   + =   m a t h . l o g   p r o b _ i f _ h a m                                  O t h e r w i s e   a d d   t h e   l o g   p r o b a b i l i t y   o f   _ n o t _   s e e i n g   i t ,                              w h i c h   i s   l o g   1   -   p r o b a b i l i t y   o f   s e e i n g   i t                             e l s e :                                   l o g _ p r o b _ i f _ s p a m   + =   m a t h . l o g   1 . 0   -   p r o b _ i f _ s p a m                                     l o g _ p r o b _ i f _ h a m   + =   m a t h . l o g   1 . 0   -   p r o b _ i f _ h a m                       p r o b _ i f _ s p a m   =   m a t h . e x p   l o g _ p r o b _ i f _ s p a m                     p r o b _ i f _ h a m   =   m a t h . e x p   l o g _ p r o b _ i f _ h a m                     r e t u r n   p r o b _ i f _ s p a m         p r o b _ i f _ s p a m   +   p r o b _ i f _ h a m   m e s s a g e s   =   [ M e s s a g e   " s p a m   r u l e s " ,   i s _ s p a m = T r u e   ,                           M e s s a g e   " h a m   r u l e s " ,   i s _ s p a m = F a l s e   ,                           M e s s a g e   " h e l l o   h a m " ,   i s _ s p a m = F a l s e   ]     m o d e l   =   N a i v e B a y e s C l a s s i f i e r   k = 0 . 5     m o d e l . t r a i n   m e s s a g e s   a s s e r t   m o d e l . t o k e n s   = =   { " s p a m " ,   " h a m " ,   " r u l e s " ,   " h e l l o " }   a s s e r t   m o d e l . s p a m _ m e s s a g e s   = =   1   a s s e r t   m o d e l . h a m _ m e s s a g e s   = =   2   a s s e r t   m o d e l . t o k e n _ s p a m _ c o u n t s   = =   { " s p a m " :   1 ,   " r u l e s " :   1 }   a s s e r t   m o d e l . t o k e n _ h a m _ c o u n t s   = =   { " h a m " :   2 ,   " r u l e s " :   1 ,   " h e l l o " :   1 } t e x t   =   " h e l l o   s p a m "     p r o b s _ i f _ s p a m   =   [             1   +   0 . 5           1   +   2   *   0 . 5   ,                " s p a m "       p r e s e n t             1   -     0   +   0 . 5           1   +   2   *   0 . 5   ,        " h a m "         n o t   p r e s e n t             1   -     1   +   0 . 5           1   +   2   *   0 . 5   ,        " r u l e s "     n o t   p r e s e n t               0   +   0 . 5           1   +   2   *   0 . 5                    " h e l l o "     p r e s e n t     ]    This test passes, so it seems like our model is doing what we think it is. If you look at the actual probabilities, the two big drivers are that our message contains spam  which our lone training spam message did  and that it doesn’t contain ham  which both our training ham messages did . Now let’s try it on some real data.  Using Our Model A popular  if somewhat old  dataset is the SpamAssassin public corpus. We’ll look at the files prefixed with 20021010. Here is a script that will download and unpack them to the directory of your choice  or you can do it manually :  ]   p r o b s _ i f _ h a m   =   [             0   +   0 . 5           2   +   2   *   0 . 5   ,                " s p a m "       p r e s e n t             1   -     2   +   0 . 5           2   +   2   *   0 . 5   ,        " h a m "         n o t   p r e s e n t             1   -     1   +   0 . 5           2   +   2   *   0 . 5   ,        " r u l e s "     n o t   p r e s e n t               1   +   0 . 5           2   +   2   *   0 . 5   ,                " h e l l o "     p r e s e n t     ]     p _ i f _ s p a m   =   m a t h . e x p   s u m   m a t h . l o g   p     f o r   p   i n   p r o b s _ i f _ s p a m       p _ i f _ h a m   =   m a t h . e x p   s u m   m a t h . l o g   p     f o r   p   i n   p r o b s _ i f _ h a m            S h o u l d   b e   a b o u t   0 . 8 3   a s s e r t   m o d e l . p r e d i c t   t e x t     = =   p _ i f _ s p a m         p _ i f _ s p a m   +   p _ i f _ h a m   f r o m   i o   i m p o r t   B y t e s I O        S o   w e   c a n   t r e a t   b y t e s   a s   a   f i l e .   i m p o r t   r e q u e s t s                      T o   d o w n l o a d   t h e   f i l e s ,   w h i c h   i m p o r t   t a r f i l e                        a r e   i n   . t a r . b z   f o r m a t .     B A S E _ U R L   =   " h t t p s :     s p a m a s s a s s i n . a p a c h e . o r g   o l d   p u b l i c c o r p u s "   F I L E S   =   [ " 2 0 0 2 1 0 1 0 _ e a s y _ h a m . t a r . b z 2 " ,                     " 2 0 0 2 1 0 1 0 _ h a r d _ h a m . t a r . b z 2 " ,                     " 2 0 0 2 1 0 1 0 _ s p a m . t a r . b z 2 " ]        T h i s   i s   w h e r e   t h e   d a t a   w i l l   e n d   u p ,      i n     s p a m ,     e a s y _ h a m ,   a n d     h a r d _ h a m   s u b d i r e c t o r i e s .      C h a n g e   t h i s   t o   w h e r e   y o u   w a n t   t h e   d a t a .   O U T P U T _ D I R   =   ' s p a m _ d a t a '     f o r   f i l e n a m e   i n   F I L E S :              U s e   r e q u e s t s   t o   g e t   t h e   f i l e   c o n t e n t s   a t   e a c h   U R L .           c o n t e n t   =   r e q u e s t s . g e t   f " { B A S E _ U R L }   { f i l e n a m e } "   . c o n t e n t      It’s possible the location of the files will change  this happened between the first and second editions of this book , in which case adjust the script accordingly. After downloading the data you should have three folders: spam, easy_ham, and hard_ham. Each folder contains many emails, each contained in a single file. To keep things really simple, we’ll just look at the subject lines of each email. How do we identify the subject line? When we look through the files, they all seem to start with “Subject:”. So we’ll look for that:  Now we can split the data into training data and test data, and then we’re ready to build a classifier:             W r a p   t h e   i n - m e m o r y   b y t e s   s o   w e   c a n   u s e   t h e m   a s   a   " f i l e . "           f i n   =   B y t e s I O   c o n t e n t                  A n d   e x t r a c t   a l l   t h e   f i l e s   t o   t h e   s p e c i f i e d   o u t p u t   d i r .           w i t h   t a r f i l e . o p e n   f i l e o b j = f i n ,   m o d e = ' r : b z 2 '     a s   t f :                   t f . e x t r a c t a l l   O U T P U T _ D I R   i m p o r t   g l o b ,   r e        m o d i f y   t h e   p a t h   t o   w h e r e v e r   y o u ' v e   p u t   t h e   f i l e s   p a t h   =   ' s p a m _ d a t a   *   * '     d a t a :   L i s t [ M e s s a g e ]   =   [ ]        g l o b . g l o b   r e t u r n s   e v e r y   f i l e n a m e   t h a t   m a t c h e s   t h e   w i l d c a r d e d   p a t h   f o r   f i l e n a m e   i n   g l o b . g l o b   p a t h   :           i s _ s p a m   =   " h a m "   n o t   i n   f i l e n a m e                T h e r e   a r e   s o m e   g a r b a g e   c h a r a c t e r s   i n   t h e   e m a i l s ;   t h e   e r r o r s = ' i g n o r e '              s k i p s   t h e m   i n s t e a d   o f   r a i s i n g   a n   e x c e p t i o n .           w i t h   o p e n   f i l e n a m e ,   e r r o r s = ' i g n o r e '     a s   e m a i l _ f i l e :                   f o r   l i n e   i n   e m a i l _ f i l e :                           i f   l i n e . s t a r t s w i t h   " S u b j e c t : "   :                                   s u b j e c t   =   l i n e . l s t r i p   " S u b j e c t :   "                                     d a t a . a p p e n d   M e s s a g e   s u b j e c t ,   i s _ s p a m                                       b r e a k        d o n e   w i t h   t h i s   f i l e i m p o r t   r a n d o m   f r o m   s c r a t c h . m a c h i n e _ l e a r n i n g   i m p o r t   s p l i t _ d a t a     r a n d o m . s e e d   0                  j u s t   s o   y o u   g e t   t h e   s a m e   a n s w e r s   a s   m e   t r a i n _ m e s s a g e s ,   t e s t _ m e s s a g e s   =   s p l i t _ d a t a   d a t a ,   0 . 7 5       m o d e l   =   N a i v e B a y e s C l a s s i f i e r       m o d e l . t r a i n   t r a i n _ m e s s a g e s    Let’s generate some predictions and check how our model does:  This gives 84 true positives  spam classified as “spam” , 25 false positives  ham classified as “spam” , 703 true negatives  ham classified as “ham” , and 44 false negatives  spam classified as “ham” . This means our precision is 84    84 + 25  = 77%, and our recall is 84    84 + 44  = 65%, which are not bad numbers for such a simple model.  Presumably we’d do better if we looked at more than the subject lines.  We can also inspect the model’s innards to see which words are least and most indicative of spam:  The spammiest words include things like sale, mortgage, money, and rates, whereas the hammiest words include things like spambayes, users, apt, and perl. So that also gives us some intuitive confidence that our model is basically doing the right thing. How could we get better performance? One obvious way would be to get more data to train on. There are a number of ways to improve the model as well. Here are some possibilities that you might try:  Look at the message content, not just the subject line. You’ll have to be careful how you deal with the message headers.  f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     p r e d i c t i o n s   =   [   m e s s a g e ,   m o d e l . p r e d i c t   m e s s a g e . t e x t                                     f o r   m e s s a g e   i n   t e s t _ m e s s a g e s ]        A s s u m e   t h a t   s p a m _ p r o b a b i l i t y   >   0 . 5   c o r r e s p o n d s   t o   s p a m   p r e d i c t i o n      a n d   c o u n t   t h e   c o m b i n a t i o n s   o f     a c t u a l   i s _ s p a m ,   p r e d i c t e d   i s _ s p a m     c o n f u s i o n _ m a t r i x   =   C o u n t e r     m e s s a g e . i s _ s p a m ,   s p a m _ p r o b a b i l i t y   >   0 . 5                                                           f o r   m e s s a g e ,   s p a m _ p r o b a b i l i t y   i n   p r e d i c t i o n s       p r i n t   c o n f u s i o n _ m a t r i x   d e f   p _ s p a m _ g i v e n _ t o k e n   t o k e n :   s t r ,   m o d e l :   N a i v e B a y e s C l a s s i f i e r     - >   f l o a t :              W e   p r o b a b l y   s h o u l d n ' t   c a l l   p r i v a t e   m e t h o d s ,   b u t   i t ' s   f o r   a   g o o d   c a u s e .           p r o b _ i f _ s p a m ,   p r o b _ i f _ h a m   =   m o d e l . _ p r o b a b i l i t i e s   t o k e n               r e t u r n   p r o b _ i f _ s p a m         p r o b _ i f _ s p a m   +   p r o b _ i f _ h a m       w o r d s   =   s o r t e d   m o d e l . t o k e n s ,   k e y = l a m b d a   t :   p _ s p a m _ g i v e n _ t o k e n   t ,   m o d e l         p r i n t   " s p a m m i e s t _ w o r d s " ,   w o r d s [ - 1 0 : ]     p r i n t   " h a m m i e s t _ w o r d s " ,   w o r d s [ : 1 0 ]    t threshold and ignore tokens that don’t appear at least  Our classifier takes into account every word that appears in the training set, even words that appear only once. Modify the classifier to accept an optional m that many times. The tokenizer has no notion of similar words  e.g., cheap and cheapest . Modify the classifier to take an optional s r function that converts words to equivalence classes of words. For example, a really simple stemmer function might be:  Creating a good stemmer function is hard. People frequently use the Porter stemmer. Although our features are all of the form “message contains word w i,” there’s no reason why this has to be the case. In our implementation, we could add extra features like “message contains a number” by creating phony tokens like contains:number and modifying the t them when appropriate.  r to emit  For Further Exploration  Paul Graham’s articles “A Plan for Spam” and “Better Bayesian Filtering” are interesting and give more insight into the ideas behind building spam filters.  scikit-learn contains a B Naive Bayes algorithm we implemented here, as well as other variations on the model.  B model that implements the same  i n _ c o u n t e m m e d e f   d r o p _ f i n a l _ s   w o r d   :           r e t u r n   r e . s u b   " s $ " ,   " " ,   w o r d   o k e n i z e e r n o u l l i N  Chapter 14. Simple Linear Regression  Art, like morality, consists in drawing the line somewhere.  —G. K. Chesterton  In Chapter 5, we used the c the linear relationship between two variables. For most applications, knowing that such a linear relationship exists isn’t enough. We’ll want to understand the nature of the relationship. This is where we’ll use simple linear regression.  n function to measure the strength of  The Model Recall that we were investigating the relationship between a DataSciencester user’s number of friends and the amount of time the user spends on the site each day. Let’s assume that you’ve convinced yourself that having more friends causes people to spend more time on the site, rather than one of the alternative explanations we discussed. The VP of Engagement asks you to build a model describing this relationship. Since you found a pretty strong linear relationship, a natural place to start is a linear model. In particular, you hypothesize that there are constants α  alpha  and β  beta  such that:  where y i is the number of minutes user i spends on the site daily, x number of friends user i has, and ε is a  hopefully small  error term representing the fact that there are other factors not accounted for by this simple model.  i is the  o r r e l a t i o y i = β x i + α + ε i  Assuming we’ve determined such an a predictions simply with:  a and b  a, then we make  How do we choose a gives us a predicted output for each input x output y  i, we can compute the error for each pair:  a and b  a? Well, any choice of a  i. Since we know the actual  a and b  What we’d really like to know is the total error over the entire dataset. But we don’t want to just add the errors—if the prediction for x 1 is too high and the prediction for x So instead we add up the squared errors:  2 is too low, the errors may just cancel out.  The least squares solution is to choose the a  a and b  a that make  s as small as possible.  Using calculus  or tedious algebra , the error-minimizing a are given by:  a and b  l p h e t d e f   p r e d i c t   a l p h a :   f l o a t ,   b e t a :   f l o a t ,   x _ i :   f l o a t     - >   f l o a t :           r e t u r n   b e t a   *   x _ i   +   a l p h a l p h e t l p h e t a _ _ d e f   e r r o r   a l p h a :   f l o a t ,   b e t a :   f l o a t ,   x _ i :   f l o a t ,   y _ i :   f l o a t     - >   f l o a t :           " " "           T h e   e r r o r   f r o m   p r e d i c t i n g   b e t a   *   x _ i   +   a l p h a           w h e n   t h e   a c t u a l   v a l u e   i s   y _ i           " " "           r e t u r n   p r e d i c t   a l p h a ,   b e t a ,   x _ i     -   y _ i _ _ f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r     d e f   s u m _ o f _ s q e r r o r s   a l p h a :   f l o a t ,   b e t a :   f l o a t ,   x :   V e c t o r ,   y :   V e c t o r     - >   f l o a t :           r e t u r n   s u m   e r r o r   a l p h a ,   b e t a ,   x _ i ,   y _ i     * *   2                                 f o r   x _ i ,   y _ i   i n   z i p   x ,   y     l p h e t s u m _ o f _ s q e r r o r l p h e t a f r o m   t y p i n g   i m p o r t   T u p l e   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r   f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   c o r r e l a t i o n ,   s t a n d a r d _ d e v i a t i o n ,   m e a n     d e f   l e a s t _ s q u a r e s _ f i t   x :   V e c t o r ,   y :   V e c t o r     - >   T u p l e [ f l o a t ,   f l o a t ] :    Without going through the exact mathematics, let’s think about why this might be a reasonable solution. The choice of a we see the average value of the independent variable x, we predict the average value of the dependent variable y. The choice of b  a means that when the input value increases by  a simply says that when   , the prediction then increases by   . In the case where x and y are perfectly correlated, a one-standard-deviation increase in x results in a one-standard-deviation-of-y increase in the prediction. When they’re perfectly anticorrelated, the increase in x results in a decrease in the prediction. And when the correlation is 0, b changes in x don’t affect the prediction at all. As usual, let’s write a quick test for this:  a is 0, which means that  Now it’s easy to apply this to the outlierless data from Chapter 5:          " " "           G i v e n   t w o   v e c t o r s   x   a n d   y ,           f i n d   t h e   l e a s t - s q u a r e s   v a l u e s   o f   a l p h a   a n d   b e t a           " " "           b e t a   =   c o r r e l a t i o n   x ,   y     *   s t a n d a r d _ d e v i a t i o n   y         s t a n d a r d _ d e v i a t i o n   x             a l p h a   =   m e a n   y     -   b e t a   *   m e a n   x             r e t u r n   a l p h a ,   b e t a l p h e t s t a n d a r d _ d e v i a t i o n   x c o r r e l a t i o n   x ,   y     *   s t a n d a r d _ d e v i a t i o n   y e t x   =   [ i   f o r   i   i n   r a n g e   - 1 0 0 ,   1 1 0 ,   1 0   ]   y   =   [ 3   *   i   -   5   f o r   i   i n   x ]        S h o u l d   f i n d   t h a t   y   =   3 x   -   5   a s s e r t   l e a s t _ s q u a r e s _ f i t   x ,   y     = =     - 5 ,   3   f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   n u m _ f r i e n d s _ g o o d ,   d a i l y _ m i n u t e s _ g o o d     a l p h a ,   b e t a   =   l e a s t _ s q u a r e s _ f i t   n u m _ f r i e n d s _ g o o d ,   d a i l y _ m i n u t e s _ g o o d     a s s e r t   2 2 . 9   <   a l p h a   <   2 3 . 0   a s s e r t   0 . 9   <   b e t a   <   0 . 9 0 5  a = 22.95 and b  This gives values of a a = 0.903. So our model says that we expect a user with n friends to spend 22.95 + n * 0.903 minutes on the site each day. That is, we predict that a user with no friends on DataSciencester would still spend about 23 minutes a day on the site. And for each additional friend, we expect a user to spend almost a minute more on the site each day. In Figure 14-1, we plot the prediction line to get a sense of how well the model fits the observed data.  Figure 14-1. Our simple linear model  Of course, we need a better way to figure out how well we’ve fit the data than staring at the graph. A common measure is the coefficient of determination  or R-squared , which measures the fraction of the total variation in the dependent variable that is captured by the model:  l p h e t  a and b  a = mean y  and b   ”  corresponding to a  a that minimized the sum of the  Recall that we chose the a squared prediction errors. A linear model we could have chosen is “always predict m a = 0 , whose sum of squared errors exactly equals its total sum of squares. This means an R-squared of 0, which indicates a model that  obviously, in this case  performs no better than just predicting the mean. Clearly, the least squares model must be at least as good as that one, which means that the sum of the squared errors is at most the total sum of squares, which means that the R-squared must be at least 0. And the sum of squared errors must be at least 0, which means that the R-squared can be at most 1. The higher the number, the better our model fits the data. Here we calculate an R-squared of 0.329, which tells us that our model is only sort of okay at fitting the data, and that clearly there are other factors at play.  Using Gradient Descent If we write t descent:  ], we can also solve this using gradient  f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   d e _ m e a n     d e f   t o t a l _ s u m _ o f _ s q u a r e s   y :   V e c t o r     - >   f l o a t :           " " " t h e   t o t a l   s q u a r e d   v a r i a t i o n   o f   y _ i ' s   f r o m   t h e i r   m e a n " " "           r e t u r n   s u m   v   * *   2   f o r   v   i n   d e _ m e a n   y         d e f   r _ s q u a r e d   a l p h a :   f l o a t ,   b e t a :   f l o a t ,   x :   V e c t o r ,   y :   V e c t o r     - >   f l o a t :           " " "           t h e   f r a c t i o n   o f   v a r i a t i o n   i n   y   c a p t u r e d   b y   t h e   m o d e l ,   w h i c h   e q u a l s           1   -   t h e   f r a c t i o n   o f   v a r i a t i o n   i n   y   n o t   c a p t u r e d   b y   t h e   m o d e l           " " "           r e t u r n   1 . 0   -     s u m _ o f _ s q e r r o r s   a l p h a ,   b e t a ,   x ,   y                                             t o t a l _ s u m _ o f _ s q u a r e s   y         r s q   =   r _ s q u a r e d   a l p h a ,   b e t a ,   n u m _ f r i e n d s _ g o o d ,   d a i l y _ m i n u t e s _ g o o d     a s s e r t   0 . 3 2 8   <   r s q   <   0 . 3 3 0 l p h e t e a n   y l p h e t h e t a   =   [ a l p h a ,   b e t a i m p o r t   r a n d o m   i m p o r t   t q d m    If you run this you’ll get the same values for a using the exact formula.  a and b  a as we did  Maximum Likelihood Estimation Why choose least squares? One justification involves maximum likelihood estimation. Imagine that we have a sample of data v  n that comes  f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p     n u m _ e p o c h s   =   1 0 0 0 0   r a n d o m . s e e d   0       g u e s s   =   [ r a n d o m . r a n d o m     ,   r a n d o m . r a n d o m     ]        c h o o s e   r a n d o m   v a l u e   t o   s t a r t     l e a r n i n g _ r a t e   =   0 . 0 0 0 0 1     w i t h   t q d m . t r a n g e   n u m _ e p o c h s     a s   t :           f o r   _   i n   t :                   a l p h a ,   b e t a   =   g u e s s                        P a r t i a l   d e r i v a t i v e   o f   l o s s   w i t h   r e s p e c t   t o   a l p h a                   g r a d _ a   =   s u m   2   *   e r r o r   a l p h a ,   b e t a ,   x _ i ,   y _ i                                               f o r   x _ i ,   y _ i   i n   z i p   n u m _ f r i e n d s _ g o o d ,                                                                                     d a i l y _ m i n u t e s _ g o o d                            P a r t i a l   d e r i v a t i v e   o f   l o s s   w i t h   r e s p e c t   t o   b e t a                   g r a d _ b   =   s u m   2   *   e r r o r   a l p h a ,   b e t a ,   x _ i ,   y _ i     *   x _ i                                             f o r   x _ i ,   y _ i   i n   z i p   n u m _ f r i e n d s _ g o o d ,                                                                                     d a i l y _ m i n u t e s _ g o o d                            C o m p u t e   l o s s   t o   s t i c k   i n   t h e   t q d m   d e s c r i p t i o n                   l o s s   =   s u m _ o f _ s q e r r o r s   a l p h a ,   b e t a ,                                                                 n u m _ f r i e n d s _ g o o d ,   d a i l y _ m i n u t e s _ g o o d                     t . s e t _ d e s c r i p t i o n   f " l o s s :   { l o s s : . 3 f } "                          F i n a l l y ,   u p d a t e   t h e   g u e s s                   g u e s s   =   g r a d i e n t _ s t e p   g u e s s ,   [ g r a d _ a ,   g r a d _ b ] ,   - l e a r n i n g _ r a t e          W e   s h o u l d   g e t   p r e t t y   m u c h   t h e   s a m e   r e s u l t s :   a l p h a ,   b e t a   =   g u e s s   a s s e r t   2 2 . 9   <   a l p h a   <   2 3 . 0   a s s e r t   0 . 9   <   b e t a   <   0 . 9 0 5 l p h e t 1 , . . . , v  from a distribution that depends on some unknown parameter θ  theta :  If we didn’t know θ, we could turn around and think of this quantity as the likelihood of θ given the sample:  Under this approach, the most likely θ is the value that maximizes this likelihood function—that is, the value that makes the observed data the most probable. In the case of a continuous distribution, in which we have a probability distribution function rather than a probability mass function, we can do the same thing. Back to regression. One assumption that’s often made about the simple regression model is that the regression errors are normally distributed with mean 0 and some  known  standard deviation σ. If that’s the case, then the likelihood based on seeing a pair      is:  The likelihood based on the entire dataset is the product of the individual likelihoods, which is largest precisely when a a are chosen to minimize the sum of squared errors. That is, in this case  with these assumptions , minimizing the sum of squared errors is equivalent to maximizing the likelihood of the observed data.  a and b  For Further Exploration Continue reading about multiple regression in Chapter 15!  p   v 1 , . . . , v n  θ   L   θ  v 1 , . . . , v n   x _ i ,   y _ i L   α , β  x i , y i , σ   = e x p   −   y i − α − β x i   2   2 σ 2   l p h e t 1 √ 2 π σ  Chapter 15. Multiple Regression  I don’t look at a problem and put variables in there that don’t affect it.  —Bill Parcells  Although the VP is pretty impressed with your predictive model, she thinks you can do better. To that end, you’ve collected additional data: you know how many hours each of your users works each day, and whether they have a PhD. You’d like to use this additional data to improve your model. Accordingly, you hypothesize a linear model with more independent variables:  Obviously, whether a user has a PhD is not a number—but, as we mentioned in Chapter 11, we can introduce a dummy variable that equals 1 for users with PhDs and 0 for users without, after which it’s just as numeric as the other variables.  The Model Recall that in Chapter 14 we fit a model of the form:  Now imagine that each input x k numbers, x  i is not a single number but rather a vector of  k. The multiple regression model assumes that:  In multiple regression the vector of parameters is usually called β. We’ll want this to include the constant term as well, which we can achieve by adding a column of 1s to our data:  m i n u t e s = α + β 1 f r i e n d s + β 2 w o r k h o u r s + β 3 p h d + ε y i = α + β x i + ε i i 1 , . . . , x i y i = α + β 1 x i 1 + . . . + β k x i k + ε i  and:  Then our model is just:  In this particular case, our independent variable x will be a list of vectors, each of which looks like this:  Further Assumptions of the Least Squares Model There are a couple of further assumptions that are required for this model  and our solution  to make sense. The first is that the columns of x are linearly independent—that there’s no way to write any one as a weighted sum of some of the others. If this assumption fails, it’s impossible to estimate b case, imagine we had an extra field n every user was exactly equal to n Then, starting with any b coefficient and subtract that same amount from the n coefficient, the model’s predictions will remain unchanged. This means that  a. To see this in an extreme s in our data that for  a, if we add any amount to the n  s.  b e t a   =   [ a l p h a ,   b e t a _ 1 ,   . . . ,   b e t a _ k ] x _ i   =   [ 1 ,   x _ i 1 ,   . . . ,   x _ i k ] f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t ,   V e c t o r     d e f   p r e d i c t   x :   V e c t o r ,   b e t a :   V e c t o r     - >   f l o a t :           " " " a s s u m e s   t h a t   t h e   f i r s t   e l e m e n t   o f   x   i s   1 " " "           r e t u r n   d o t   x ,   b e t a   [ 1 ,            c o n s t a n t   t e r m     4 9 ,          n u m b e r   o f   f r i e n d s     4 ,            w o r k   h o u r s   p e r   d a y     0 ]            d o e s n ' t   h a v e   P h D e t u m _ a c q u a i n t a n c e u m _ f r i e n d e t u m _ f r i e n d s u m _ a c q u a i n t a n c e s  there’s no way to find the coefficient for n of this assumption won’t be so obvious.  The second important assumption is that the columns of x are all uncorrelated with the errors ε. If this fails to be the case, our estimates of  s.  Usually violations  a will be systematically wrong.  For instance, in Chapter 14, we built a model that predicted that each additional friend was associated with an extra 0.90 daily minutes on the site. Imagine it’s also the case that:  People who work more hours spend less time on the site. People with more friends tend to work more hours.  That is, imagine that the “actual” model is:  2 is negative, and that work hours and friends are positively  where β correlated. In that case, when we minimize the errors of the single-variable model:  1.  we will underestimate β Think about what would happen if we made predictions using the single- variable model with the “actual” value of β 1.  That is, the value that arises from minimizing the errors of what we called the “actual” model.  The predictions would tend to be way too large for users who work many hours and a little too large for users who work few hours, because β 0 and we “forgot” to include it. Because work hours is positively correlated with number of friends, this means the predictions tend to be way too large for users with many friends, and only slightly too large for users with few friends.  u m _ f r i e n d b e t m i n u t e s = α + β 1 f r i e n d s + β 2 w o r k h o u r s + ε m i n u t e s = α + β 1 f r i e n d s + ε 2 <  The result of this is that we can reduce the errors  in the single-variable model  by decreasing our estimate of β minimizing β single-variable least squares solution is biased to underestimate β 1. And, in general, whenever the independent variables are correlated with the errors like this, our least squares solution will give us a biased estimate of β  1 is smaller than the “actual” value. That is, in this case the  1, which means that the error-  1.  Fitting the Model As we did in the simple linear model, we’ll choose b sum of squared errors. Finding an exact solution is not simple to do by hand, which means we’ll need to use gradient descent. Again we’ll want to minimize the sum of the squared errors. The error function is almost identical to the one we used in Chapter 14, except that instead of expecting parameters [  ] it will take a vector of arbitrary length:  a to minimize the  If you know calculus, it’s easy to compute the gradient:  e t a l p h a ,   b e t a f r o m   t y p i n g   i m p o r t   L i s t     d e f   e r r o r   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r     - >   f l o a t :           r e t u r n   p r e d i c t   x ,   b e t a     -   y     d e f   s q u a r e d _ e r r o r   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r     - >   f l o a t :           r e t u r n   e r r o r   x ,   y ,   b e t a     * *   2     x   =   [ 1 ,   2 ,   3 ]   y   =   3 0   b e t a   =   [ 4 ,   4 ,   4 ]        s o   p r e d i c t i o n   =   4   +   8   +   1 2   =   2 4     a s s e r t   e r r o r   x ,   y ,   b e t a     = =   - 6   a s s e r t   s q u a r e d _ e r r o r   x ,   y ,   b e t a     = =   3 6 d e f   s q e r r o r _ g r a d i e n t   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r     - >   V e c t o r :           e r r   =   e r r o r   x ,   y ,   b e t a             r e t u r n   [ 2   *   e r r   *   x _ i   f o r   x _ i   i n   x ]     a s s e r t   s q e r r o r _ g r a d i e n t   x ,   y ,   b e t a     = =   [ - 1 2 ,   - 2 4 ,   - 3 6 ]  Otherwise, you’ll need to take my word for it. At this point, we’re ready to find the optimal b Let’s first write out a l dataset:  a using gradient descent. t function that can work with any  We can then apply that to our data:  e t e a s t _ s q u a r e s _ f i i m p o r t   r a n d o m   i m p o r t   t q d m   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   v e c t o r _ m e a n   f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p       d e f   l e a s t _ s q u a r e s _ f i t   x s :   L i s t [ V e c t o r ] ,                                               y s :   L i s t [ f l o a t ] ,                                               l e a r n i n g _ r a t e :   f l o a t   =   0 . 0 0 1 ,                                               n u m _ s t e p s :   i n t   =   1 0 0 0 ,                                               b a t c h _ s i z e :   i n t   =   1     - >   V e c t o r :           " " "           F i n d   t h e   b e t a   t h a t   m i n i m i z e s   t h e   s u m   o f   s q u a r e d   e r r o r s           a s s u m i n g   t h e   m o d e l   y   =   d o t   x ,   b e t a   .           " " "              S t a r t   w i t h   a   r a n d o m   g u e s s           g u e s s   =   [ r a n d o m . r a n d o m       f o r   _   i n   x s [ 0 ] ]             f o r   _   i n   t q d m . t r a n g e   n u m _ s t e p s ,   d e s c = " l e a s t   s q u a r e s   f i t "   :                   f o r   s t a r t   i n   r a n g e   0 ,   l e n   x s   ,   b a t c h _ s i z e   :                           b a t c h _ x s   =   x s [ s t a r t : s t a r t + b a t c h _ s i z e ]                           b a t c h _ y s   =   y s [ s t a r t : s t a r t + b a t c h _ s i z e ]                             g r a d i e n t   =   v e c t o r _ m e a n   [ s q e r r o r _ g r a d i e n t   x ,   y ,   g u e s s                                                                             f o r   x ,   y   i n   z i p   b a t c h _ x s ,   b a t c h _ y s   ]                             g u e s s   =   g r a d i e n t _ s t e p   g u e s s ,   g r a d i e n t ,   - l e a r n i n g _ r a t e               r e t u r n   g u e s s f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   d a i l y _ m i n u t e s _ g o o d   f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p     r a n d o m . s e e d   0        I   u s e d   t r i a l   a n d   e r r o r   t o   c h o o s e   n u m _ i t e r s   a n d   s t e p _ s i z e .      T h i s   w i l l   r u n   f o r   a   w h i l e .   l e a r n i n g _ r a t e   =   0 . 0 0 1      In practice, you wouldn’t estimate a linear regression using gradient descent; you’d get the exact coefficients using linear algebra techniques that are beyond the scope of this book. If you did so, you’d find the equation:  which is pretty close to what we found.  Interpreting the Model You should think of the coefficients of the model as representing all-else- being-equal estimates of the impacts of each factor. All else being equal, each additional friend corresponds to an extra minute spent on the site each day. All else being equal, each additional hour in a user’s workday corresponds to about two fewer minutes spent on the site each day. All else being equal, having a PhD is associated with spending an extra minute on the site each day. What this doesn’t  directly  tell us is anything about the interactions among the variables. It’s possible that the effect of work hours is different for people with many friends than it is for people with few friends. This model doesn’t capture that. One way to handle this case is to introduce a new variable that is the product of “friends” and “work hours.” This effectively allows the “work hours” coefficient to increase  or decrease  as the number of friends increases. Or it’s possible that the more friends you have, the more time you spend on the site up to a point, after which further friends cause you to spend less time on the site.  Perhaps with too many friends the experience is just too overwhelming?  We could try to capture this in our model by adding another variable that’s the square of the number of friends.  b e t a   =   l e a s t _ s q u a r e s _ f i t   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5     a s s e r t   3 0 . 5 0   <   b e t a [ 0 ]   <   3 0 . 7 0        c o n s t a n t   a s s e r t     0 . 9 6   <   b e t a [ 1 ]   <     1 . 0 0        n u m   f r i e n d s   a s s e r t   - 1 . 8 9   <   b e t a [ 2 ]   <   - 1 . 8 5        w o r k   h o u r s   p e r   d a y   a s s e r t     0 . 9 1   <   b e t a [ 3 ]   <     0 . 9 4        h a s   P h D m i n u t e s = 3 0 . 5 8 + 0 . 9 7 2 f r i e n d s − 1 . 8 7 w o r k h o u r s + 0 . 9 2 3 p h d  Once we start adding variables, we need to worry about whether their coefficients “matter.” There are no limits to the numbers of products, logs, squares, and higher powers we could add.  Goodness of Fit Again we can look at the R-squared:  which has now increased to 0.68:  Keep in mind, however, that adding new variables to a regression will necessarily increase the R-squared. After all, the simple regression model is just the special case of the multiple regression model where the coefficients on “work hours” and “PhD” both equal 0. The optimal multiple regression model will necessarily have an error at least as small as that one. Because of this, in a multiple regression, we also need to look at the standard errors of the coefficients, which measure how certain we are about our estimates of each β well, but if some of the independent variables are correlated  or irrelevant , their coefficients might not mean much. The typical approach to measuring these errors starts with another assumption—that the errors ε with mean 0 and some shared  unknown  standard deviation σ. In that case, we  or, more likely, our statistical software  can use some linear algebra to find the standard error of each coefficient. The larger it is, the less sure our  i. The regression as a whole may fit our data very  i are independent normal random variables  f r o m   s c r a t c h . s i m p l e _ l i n e a r _ r e g r e s s i o n   i m p o r t   t o t a l _ s u m _ o f _ s q u a r e s     d e f   m u l t i p l e _ r _ s q u a r e d   x s :   L i s t [ V e c t o r ] ,   y s :   V e c t o r ,   b e t a :   V e c t o r     - >   f l o a t :           s u m _ o f _ s q u a r e d _ e r r o r s   =   s u m   e r r o r   x ,   y ,   b e t a     * *   2                                                                   f o r   x ,   y   i n   z i p   x s ,   y s               r e t u r n   1 . 0   -   s u m _ o f _ s q u a r e d _ e r r o r s       t o t a l _ s u m _ o f _ s q u a r e s   y s   a s s e r t   0 . 6 7   <   m u l t i p l e _ r _ s q u a r e d   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   b e t a     <   0 . 6 8  model is about that coefficient. Unfortunately, we’re not set up to do that kind of linear algebra from scratch.  Digression: The Bootstrap Imagine that we have a sample of n data points, generated by some  unknown to us  distribution:  n of the  In Chapter 5, we wrote a function that could compute the m sample, which we can use as an estimate of the median of the distribution itself. But how confident can we be about our estimate? If all the data points in the sample are very close to 100, then it seems likely that the actual median is close to 100. If approximately half the data points in the sample are close to 0 and the other half are close to 200, then we can’t be nearly as certain about the median. If we could repeatedly get new samples, we could compute the medians of many samples and look at the distribution of those medians. Often we can’t. In that case we can bootstrap new datasets by choosing n data points with replacement from our data. And then we can compute the medians of those synthetic datasets:  d a t a   =   g e t _ s a m p l e   n u m _ p o i n t s = n   e d i a f r o m   t y p i n g   i m p o r t   T y p e V a r ,   C a l l a b l e     X   =   T y p e V a r   ' X '                      G e n e r i c   t y p e   f o r   d a t a   S t a t   =   T y p e V a r   ' S t a t '          G e n e r i c   t y p e   f o r   " s t a t i s t i c "     d e f   b o o t s t r a p _ s a m p l e   d a t a :   L i s t [ X ]     - >   L i s t [ X ] :           " " " r a n d o m l y   s a m p l e s   l e n   d a t a     e l e m e n t s   w i t h   r e p l a c e m e n t " " "           r e t u r n   [ r a n d o m . c h o i c e   d a t a     f o r   _   i n   d a t a ]     d e f   b o o t s t r a p _ s t a t i s t i c   d a t a :   L i s t [ X ] ,                                                   s t a t s _ f n :   C a l l a b l e [ [ L i s t [ X ] ] ,   S t a t ] ,                                                   n u m _ s a m p l e s :   i n t     - >   L i s t [ S t a t ] :    For example, consider the two following datasets:  If you compute the m 100. However, if you look at:  ns of the two datasets, both will be very close to  you will mostly see numbers really close to 100. But if you look at:  you will see a lot of numbers close to 0 and a lot of numbers close to 200. The s n of the first set of medians is close to 0, while that of the second set of medians is close to 100:   This extreme a case would be pretty easy to figure out by manually inspecting the data, but in general that won’t be true.   Standard Errors of Regression Coefficients          " " " e v a l u a t e s   s t a t s _ f n   o n   n u m _ s a m p l e s   b o o t s t r a p   s a m p l e s   f r o m   d a t a " " "           r e t u r n   [ s t a t s _ f n   b o o t s t r a p _ s a m p l e   d a t a       f o r   _   i n   r a n g e   n u m _ s a m p l e s   ]    1 0 1   p o i n t s   a l l   v e r y   c l o s e   t o   1 0 0   c l o s e _ t o _ 1 0 0   =   [ 9 9 . 5   +   r a n d o m . r a n d o m       f o r   _   i n   r a n g e   1 0 1   ]        1 0 1   p o i n t s ,   5 0   o f   t h e m   n e a r   0 ,   5 0   o f   t h e m   n e a r   2 0 0   f a r _ f r o m _ 1 0 0   =     [ 9 9 . 5   +   r a n d o m . r a n d o m     ]   +                                   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   5 0   ]   +                                   [ 2 0 0   +   r a n d o m . r a n d o m       f o r   _   i n   r a n g e   5 0   ]   e d i a f r o m   s c r a t c h . s t a t i s t i c s   i m p o r t   m e d i a n ,   s t a n d a r d _ d e v i a t i o n     m e d i a n s _ c l o s e   =   b o o t s t r a p _ s t a t i s t i c   c l o s e _ t o _ 1 0 0 ,   m e d i a n ,   1 0 0   m e d i a n s _ f a r   =   b o o t s t r a p _ s t a t i s t i c   f a r _ f r o m _ 1 0 0 ,   m e d i a n ,   1 0 0   t a n d a r d _ d e v i a t i o a s s e r t   s t a n d a r d _ d e v i a t i o n   m e d i a n s _ c l o s e     <   1   a s s e r t   s t a n d a r d _ d e v i a t i o n   m e d i a n s _ f a r     >   9 0  a based on that sample. If the coefficient  We can take the same approach to estimating the standard errors of our regression coefficients. We repeatedly take a b e of our data and estimate b corresponding to one of the independent variables  say, n doesn’t vary much across samples, then we can be confident that our estimate is relatively tight. If the coefficient varies greatly across samples, then we can’t be at all confident in our estimate. The only subtlety is that, before sampling, we’ll need to z y data to make sure that corresponding values of the independent and dependent variables are sampled together. This means that  p our x data and  s   e will return a list of pairs     , which we’ll need  to reassemble into an x  e and a y  e:  After which we can estimate the standard deviation of each coefficient:  o o t s t r a p _ s a m p l e t u m _ f r i e n d i b o o t s t r a p _ s a m p l x _ i ,   y _ i _ s a m p l _ s a m p l f r o m   t y p i n g   i m p o r t   T u p l e     i m p o r t   d a t e t i m e     d e f   e s t i m a t e _ s a m p l e _ b e t a   p a i r s :   L i s t [ T u p l e [ V e c t o r ,   f l o a t ] ]   :           x _ s a m p l e   =   [ x   f o r   x ,   _   i n   p a i r s ]           y _ s a m p l e   =   [ y   f o r   _ ,   y   i n   p a i r s ]           b e t a   =   l e a s t _ s q u a r e s _ f i t   x _ s a m p l e ,   y _ s a m p l e ,   l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5             p r i n t   " b o o t s t r a p   s a m p l e " ,   b e t a             r e t u r n   b e t a     r a n d o m . s e e d   0        s o   t h a t   y o u   g e t   t h e   s a m e   r e s u l t s   a s   m e        T h i s   w i l l   t a k e   a   c o u p l e   o f   m i n u t e s !   b o o t s t r a p _ b e t a s   =   b o o t s t r a p _ s t a t i s t i c   l i s t   z i p   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d     ,                                                                               e s t i m a t e _ s a m p l e _ b e t a ,                                                                               1 0 0   b o o t s t r a p _ s t a n d a r d _ e r r o r s   =   [           s t a n d a r d _ d e v i a t i o n   [ b e t a [ i ]   f o r   b e t a   i n   b o o t s t r a p _ b e t a s ]             f o r   i   i n   r a n g e   4   ]     p r i n t   b o o t s t r a p _ s t a n d a r d _ e r r o r s          [ 1 . 2 7 2 ,            c o n s t a n t   t e r m ,   a c t u a l   e r r o r   =   1 . 1 9     We would likely get better estimates if we collected more than 100 samples and used more than 5,000 iterations to estimate each b have all day.  We can use these to test hypotheses such as “does β null hypothesis β distribution of ε  0  and with our other assumptions about the  i equal 0?” Under the  a, but we don’t  i , the statistic:  k degrees of freedom.”  j divided by our estimate of its standard error,  which is our estimate of β follows a Student’s t-distribution with “n If we had a s f function, we could compute p-values for each least-squares coefficient to indicate how likely we would be to observe such a value if the actual coefficient were 0. Unfortunately, we don’t have such a function.  Although we would if we weren’t working from scratch.  However, as the degrees of freedom get large, the t-distribution gets closer and closer to a standard normal. In a situation like this, where n is much f and still feel good about ourselves: larger than k, we can use n       0 . 1 0 3 ,            n u m _ f r i e n d s ,       a c t u a l   e r r o r   =   0 . 0 8 0        0 . 1 5 5 ,            w o r k _ h o u r s ,         a c t u a l   e r r o r   =   0 . 1 2 7        1 . 2 4 9 ]            p h d ,                       a c t u a l   e r r o r   =   0 . 9 9 8 e t i = t j = ˆ β j   ˆ σ j − t u d e n t s _ t _ c d o r m a l _ c d f r o m   s c r a t c h . p r o b a b i l i t y   i m p o r t   n o r m a l _ c d f     d e f   p _ v a l u e   b e t a _ h a t _ j :   f l o a t ,   s i g m a _ h a t _ j :   f l o a t     - >   f l o a t :           i f   b e t a _ h a t _ j   >   0 :                      i f   t h e   c o e f f i c i e n t   i s   p o s i t i v e ,   w e   n e e d   t o   c o m p u t e   t w i c e   t h e                      p r o b a b i l i t y   o f   s e e i n g   a n   e v e n   * l a r g e r *   v a l u e                   r e t u r n   2   *     1   -   n o r m a l _ c d f   b e t a _ h a t _ j       s i g m a _ h a t _ j               e l s e :                      o t h e r w i s e   t w i c e   t h e   p r o b a b i l i t y   o f   s e e i n g   a   * s m a l l e r *   v a l u e                   r e t u r n   2   *   n o r m a l _ c d f   b e t a _ h a t _ j       s i g m a _ h a t _ j       a s s e r t   p _ v a l u e   3 0 . 5 8 ,   1 . 2 7         <   0 . 0 0 1        c o n s t a n t   t e r m   a s s e r t   p _ v a l u e   0 . 9 7 2 ,   0 . 1 0 3       <   0 . 0 0 1        n u m _ f r i e n d s   a s s e r t   p _ v a l u e   - 1 . 8 6 5 ,   0 . 1 5 5     <   0 . 0 0 1        w o r k _ h o u r s   a s s e r t   p _ v a l u e   0 . 9 2 3 ,   1 . 2 4 9       >   0 . 4            p h d   In a situation not like this, we would probably be using statistical software that knows how to compute the t-distribution, as well as how to compute the exact standard errors.  While most of the coefficients have very small p-values  suggesting that they are indeed nonzero , the coefficient for “PhD” is not “significantly” different from 0, which makes it likely that the coefficient for “PhD” is random rather than meaningful. In more elaborate regression scenarios, you sometimes want to test more elaborate hypotheses about the data, such as “at least one of the β nonzero” or “β test, but alas, that falls outside the scope of this book.  4.” You can do this with an F-  1 equals β  3 equals β  2 and β  j is  Regularization In practice, you’d often like to apply linear regression to datasets with large numbers of variables. This creates a couple of extra wrinkles. First, the more variables you use, the more likely you are to overfit your model to the training set. And second, the more nonzero coefficients you have, the harder it is to make sense of them. If the goal is to explain some phenomenon, a sparse model with three factors might be more useful than a slightly better model with hundreds. Regularization is an approach in which we add to the error term a penalty that gets larger as b a gets larger. We then minimize the combined error and penalty. The more importance we place on the penalty term, the more we discourage large coefficients. For example, in ridge regression, we add a penalty proportional to the sum of the squares of the b  i  except that typically we don’t penalize  0, the constant term :  e t e t a _ b e t a _    a l p h a   i s   a   * h y p e r p a r a m e t e r *   c o n t r o l l i n g   h o w   h a r s h   t h e   p e n a l t y   i s .      S o m e t i m e s   i t ' s   c a l l e d   " l a m b d a "   b u t   t h a t   a l r e a d y   m e a n s   s o m e t h i n g   i n   P y t h o n .   d e f   r i d g e _ p e n a l t y   b e t a :   V e c t o r ,   a l p h a :   f l o a t     - >   f l o a t :           r e t u r n   a l p h a   *   d o t   b e t a [ 1 : ] ,   b e t a [ 1 : ]      We can then plug this into gradient descent in the usual way:  And then we just need to modify the l the s going to repeat the code here.  With a before:  t instead of s  a set to 0, there’s no penalty at all and we get the same results as  t function to use  t.  I’m not    d e f   s q u a r e d _ e r r o r _ r i d g e   x :   V e c t o r ,                                                   y :   f l o a t ,                                                   b e t a :   V e c t o r ,                                                   a l p h a :   f l o a t     - >   f l o a t :           " " " e s t i m a t e   e r r o r   p l u s   r i d g e   p e n a l t y   o n   b e t a " " "           r e t u r n   e r r o r   x ,   y ,   b e t a     * *   2   +   r i d g e _ p e n a l t y   b e t a ,   a l p h a   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   a d d     d e f   r i d g e _ p e n a l t y _ g r a d i e n t   b e t a :   V e c t o r ,   a l p h a :   f l o a t     - >   V e c t o r :           " " " g r a d i e n t   o f   j u s t   t h e   r i d g e   p e n a l t y " " "           r e t u r n   [ 0 . ]   +   [ 2   *   a l p h a   *   b e t a _ j   f o r   b e t a _ j   i n   b e t a [ 1 : ] ]     d e f   s q e r r o r _ r i d g e _ g r a d i e n t   x :   V e c t o r ,                                                         y :   f l o a t ,                                                         b e t a :   V e c t o r ,                                                         a l p h a :   f l o a t     - >   V e c t o r :           " " "           t h e   g r a d i e n t   c o r r e s p o n d i n g   t o   t h e   i t h   s q u a r e d   e r r o r   t e r m           i n c l u d i n g   t h e   r i d g e   p e n a l t y           " " "           r e t u r n   a d d   s q e r r o r _ g r a d i e n t   x ,   y ,   b e t a   ,                                 r i d g e _ p e n a l t y _ g r a d i e n t   b e t a ,   a l p h a     e a s t _ s q u a r e s _ f i q e r r o r _ r i d g e _ g r a d i e n q e r r o r _ g r a d i e n l p h r a n d o m . s e e d   0     b e t a _ 0   =   l e a s t _ s q u a r e s _ f i t _ r i d g e   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   0 . 0 ,        a l p h a                                                                     l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5        [ 3 0 . 5 1 ,   0 . 9 7 ,   - 1 . 8 5 ,   0 . 9 1 ]   a s s e r t   5   <   d o t   b e t a _ 0 [ 1 : ] ,   b e t a _ 0 [ 1 : ]     <   6   a s s e r t   0 . 6 7   <   m u l t i p l e _ r _ s q u a r e d   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   b e t a _ 0     <   0 . 6 9  As we increase a gets smaller:  a, the goodness of fit gets worse, but the size of b  In particular, the coefficient on “PhD” vanishes as we increase the penalty, which accords with our previous result that it wasn’t significantly different from 0.  NOTE  Usually you’d want to r changed years of experience to centuries of experience, its least squares coefficient would increase by a factor of 100 and suddenly get penalized much more, even though it’s the same model.  e your data before using this approach. After all, if you  Another approach is lasso regression, which uses the penalty:  Whereas the ridge penalty shrank the coefficients overall, the lasso penalty tends to force coefficients to be 0, which makes it good for learning sparse  l p h e t a b e t a _ 0 _ 1   =   l e a s t _ s q u a r e s _ f i t _ r i d g e   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   0 . 1 ,        a l p h a                                                                         l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5        [ 3 0 . 8 ,   0 . 9 5 ,   - 1 . 8 3 ,   0 . 5 4 ]   a s s e r t   4   <   d o t   b e t a _ 0 _ 1 [ 1 : ] ,   b e t a _ 0 _ 1 [ 1 : ]     <   5   a s s e r t   0 . 6 7   <   m u l t i p l e _ r _ s q u a r e d   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   b e t a _ 0 _ 1     <   0 . 6 9     b e t a _ 1   =   l e a s t _ s q u a r e s _ f i t _ r i d g e   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   1 ,        a l p h a                                                                     l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5        [ 3 0 . 6 ,   0 . 9 0 ,   - 1 . 6 8 ,   0 . 1 0 ]   a s s e r t   3   <   d o t   b e t a _ 1 [ 1 : ] ,   b e t a _ 1 [ 1 : ]     <   4   a s s e r t   0 . 6 7   <   m u l t i p l e _ r _ s q u a r e d   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   b e t a _ 1     <   0 . 6 9     b e t a _ 1 0   =   l e a s t _ s q u a r e s _ f i t _ r i d g e   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d , 1 0 ,        a l p h a                                                                       l e a r n i n g _ r a t e ,   5 0 0 0 ,   2 5        [ 2 8 . 3 ,   0 . 6 7 ,   - 0 . 9 0 ,   - 0 . 0 1 ]   a s s e r t   1   <   d o t   b e t a _ 1 0 [ 1 : ] ,   b e t a _ 1 0 [ 1 : ]     <   2   a s s e r t   0 . 5   <   m u l t i p l e _ r _ s q u a r e d   i n p u t s ,   d a i l y _ m i n u t e s _ g o o d ,   b e t a _ 1 0     <   0 . 6 e s c a l d e f   l a s s o _ p e n a l t y   b e t a ,   a l p h a   :           r e t u r n   a l p h a   *   s u m   a b s   b e t a _ i     f o r   b e t a _ i   i n   b e t a [ 1 : ]    models. Unfortunately, it’s not amenable to gradient descent, which means that we won’t be able to solve it from scratch.  For Further Exploration  Regression has a rich and expansive theory behind it. This is another place where you should consider reading a textbook, or at least a lot of Wikipedia articles.  scikit-learn has a l  l module that provides a  n model similar to ours, as well as ridge  regression, lasso regression, and other types of regularization. Statsmodels is another Python module that contains  among other things  linear regression models.  i n e a r _ m o d e L i n e a r R e g r e s s i o  Chapter 16. Logistic Regression  A lot of people say there’s a fine line between genius and insanity. I don’t think there’s a fine line, I actually think there’s a yawning gulf. —Bill Bailey  In Chapter 1, we briefly looked at the problem of trying to predict which DataSciencester users paid for premium accounts. Here we’ll revisit that problem.  The Problem We have an anonymized dataset of about 200 users, containing each user’s salary, her years of experience as a data scientist, and whether she paid for a premium account  Figure 16-1 . As is typical with categorical variables, we represent the dependent variable as either 0  no premium account  or 1  premium account . As usual, our data is a list of rows [  ]. Let’s turn it into the format we need:  An obvious first attempt is to use linear regression and find the best model:  e x p e r i e n c e ,   s a l a r y , p a i d _ a c c o u n t x s   =   [ [ 1 . 0 ]   +   r o w [ : 2 ]   f o r   r o w   i n   d a t a ]        [ 1 ,   e x p e r i e n c e ,   s a l a r y ]   y s   =   [ r o w [ 2 ]   f o r   r o w   i n   d a t a ]                          p a i d _ a c c o u n t p a i d a c c o u n t = β 0 + β 1 e x p e r i e n c e + β 2 s a l a r y + ε  Figure 16-1. Paid and unpaid users  And certainly, there’s nothing preventing us from modeling the problem this way. The results are shown in Figure 16-2:  f r o m   m a t p l o t l i b   i m p o r t   p y p l o t   a s   p l t   f r o m   s c r a t c h . w o r k i n g _ w i t h _ d a t a   i m p o r t   r e s c a l e   f r o m   s c r a t c h . m u l t i p l e _ r e g r e s s i o n   i m p o r t   l e a s t _ s q u a r e s _ f i t ,   p r e d i c t   f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p     l e a r n i n g _ r a t e   =   0 . 0 0 1   r e s c a l e d _ x s   =   r e s c a l e   x s     b e t a   =   l e a s t _ s q u a r e s _ f i t   r e s c a l e d _ x s ,   y s ,   l e a r n i n g _ r a t e ,   1 0 0 0 ,   1        [ 0 . 2 6 ,   0 . 4 3 ,   - 0 . 4 3 ]   p r e d i c t i o n s   =   [ p r e d i c t   x _ i ,   b e t a     f o r   x _ i   i n   r e s c a l e d _ x s ]     p l t . s c a t t e r   p r e d i c t i o n s ,   y s     p l t . x l a b e l   " p r e d i c t e d "     p l t . y l a b e l   " a c t u a l "     p l t . s h o w      Figure 16-2. Using linear regression to predict premium accounts  But this approach leads to a couple of immediate problems:  We’d like for our predicted outputs to be 0 or 1, to indicate class membership. It’s fine if they’re between 0 and 1, since we can interpret these as probabilities—an output of 0.25 could mean 25% chance of being a paid member. But the outputs of the linear model can be huge positive numbers or even negative numbers, which it’s not clear how to interpret. Indeed, here a lot of our predictions were negative. The linear regression model assumed that the errors were uncorrelated with the columns of x. But here, the regression coefficient for e e is 0.43, indicating that more experience leads to a greater likelihood of a premium account. This means that our model outputs very large values for people with lots of  x p e r i e n c  experience. But we know that the actual values must be at most 1, which means that necessarily very large outputs  and therefore very large values of e negative values of the error term. Because this is the case, our estimate of b  e  correspond to very large  a is biased.  What we’d like instead is for large positive values of d correspond to probabilities close to 1, and for large negative values to correspond to probabilities close to 0. We can accomplish this by applying another function to the result.    to  The Logistic Function In the case of logistic regression, we use the logistic function, pictured in Figure 16-3:  x p e r i e n c e t o t   x _ i ,   b e t a d e f   l o g i s t i c   x :   f l o a t     - >   f l o a t :           r e t u r n   1 . 0         1   +   m a t h . e x p   - x      Figure 16-3. The logistic function  As its input gets large and positive, it gets closer and closer to 1. As its input gets large and negative, it gets closer and closer to 0. Additionally, it has the convenient property that its derivative is given by:  which we’ll make use of in a bit. We’ll use this to fit a model:  where f is the l Recall that for linear regression we fit the model by minimizing the sum of squared errors, which ended up choosing the β that maximized the  c function.  d e f   l o g i s t i c _ p r i m e   x :   f l o a t     - >   f l o a t :           y   =   l o g i s t i c   x             r e t u r n   y   *     1   -   y   y i = f   x i β   + ε i o g i s t i  likelihood of the data. Here the two aren’t equivalent, so we’ll use gradient descent to maximize the likelihood directly. This means we need to calculate the likelihood function and its gradient. i should equal 1 with probability  Given some β, our model says that each y  .    and 0 with probability 1  In particular, the PDF for y  i can be written as:  since if y  i is 0, this equals:  and if y  i is 1, it equals:  It turns out that it’s actually simpler to maximize the log likelihood:  Because log is a strictly increasing function, any b log likelihood also maximizes the likelihood, and vice versa. Because gradient descent minimizes things, we’ll actually work with the negative log likelihood, since maximizing the likelihood is the same as minimizing its negative:  a that maximizes the  f   x i β − f   x i β p   y i  x i , β   = f   x i β   y i   1 − f   x i β     1 − y i 1 − f   x i β   f   x i β   l o g L   β  x i , y i   = y i l o g f   x i β   +   1 − y i   l o g   1 − f   x i β     e t i m p o r t   m a t h   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r ,   d o t     d e f   _ n e g a t i v e _ l o g _ l i k e l i h o o d   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r     - >   f l o a t :           " " " T h e   n e g a t i v e   l o g   l i k e l i h o o d   f o r   o n e   d a t a   p o i n t " " "           i f   y   = =   1 :                   r e t u r n   - m a t h . l o g   l o g i s t i c   d o t   x ,   b e t a                 e l s e :                   r e t u r n   - m a t h . l o g   1   -   l o g i s t i c   d o t   x ,   b e t a        If we assume different data points are independent from one another, the overall likelihood is just the product of the individual likelihoods. That means the overall log likelihood is the sum of the individual log likelihoods:  A little bit of calculus gives us the gradient:  at which point we have all the pieces we need.  Applying the Model  f r o m   t y p i n g   i m p o r t   L i s t     d e f   n e g a t i v e _ l o g _ l i k e l i h o o d   x s :   L i s t [ V e c t o r ] ,                                                           y s :   L i s t [ f l o a t ] ,                                                           b e t a :   V e c t o r     - >   f l o a t :           r e t u r n   s u m   _ n e g a t i v e _ l o g _ l i k e l i h o o d   x ,   y ,   b e t a                                   f o r   x ,   y   i n   z i p   x s ,   y s     f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   v e c t o r _ s u m     d e f   _ n e g a t i v e _ l o g _ p a r t i a l _ j   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r ,   j :   i n t     - >   f l o a t :           " " "           T h e   j t h   p a r t i a l   d e r i v a t i v e   f o r   o n e   d a t a   p o i n t .           H e r e   i   i s   t h e   i n d e x   o f   t h e   d a t a   p o i n t .           " " "           r e t u r n   -   y   -   l o g i s t i c   d o t   x ,   b e t a         *   x [ j ]     d e f   _ n e g a t i v e _ l o g _ g r a d i e n t   x :   V e c t o r ,   y :   f l o a t ,   b e t a :   V e c t o r     - >   V e c t o r :           " " "           T h e   g r a d i e n t   f o r   o n e   d a t a   p o i n t .           " " "           r e t u r n   [ _ n e g a t i v e _ l o g _ p a r t i a l _ j   x ,   y ,   b e t a ,   j                             f o r   j   i n   r a n g e   l e n   b e t a     ]     d e f   n e g a t i v e _ l o g _ g r a d i e n t   x s :   L i s t [ V e c t o r ] ,                                                       y s :   L i s t [ f l o a t ] ,                                                       b e t a :   V e c t o r     - >   V e c t o r :           r e t u r n   v e c t o r _ s u m   [ _ n e g a t i v e _ l o g _ g r a d i e n t   x ,   y ,   b e t a                                                   f o r   x ,   y   i n   z i p   x s ,   y s   ]    We’ll want to split our data into a training set and a test set:  after which we find that b  a is approximately:  These are coefficients for the r back to the original data as well:  ed data, but we can transform them  Unfortunately, these are not as easy to interpret as linear regression coefficients. All else being equal, an extra year of experience adds 1.6 to the input of l subtracts 2.88 from the input of l  c. All else being equal, an extra $10,000 of salary  c.  f r o m   s c r a t c h . m a c h i n e _ l e a r n i n g   i m p o r t   t r a i n _ t e s t _ s p l i t   i m p o r t   r a n d o m   i m p o r t   t q d m     r a n d o m . s e e d   0     x _ t r a i n ,   x _ t e s t ,   y _ t r a i n ,   y _ t e s t   =   t r a i n _ t e s t _ s p l i t   r e s c a l e d _ x s ,   y s ,   0 . 3 3       l e a r n i n g _ r a t e   =   0 . 0 1        p i c k   a   r a n d o m   s t a r t i n g   p o i n t   b e t a   =   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   3   ]     w i t h   t q d m . t r a n g e   5 0 0 0     a s   t :           f o r   e p o c h   i n   t :                   g r a d i e n t   =   n e g a t i v e _ l o g _ g r a d i e n t   x _ t r a i n ,   y _ t r a i n ,   b e t a                     b e t a   =   g r a d i e n t _ s t e p   b e t a ,   g r a d i e n t ,   - l e a r n i n g _ r a t e                     l o s s   =   n e g a t i v e _ l o g _ l i k e l i h o o d   x _ t r a i n ,   y _ t r a i n ,   b e t a                     t . s e t _ d e s c r i p t i o n   f " l o s s :   { l o s s : . 3 f }   b e t a :   { b e t a } "   e t [ - 2 . 0 ,   4 . 7 ,   - 4 . 5 ] e s c a l f r o m   s c r a t c h . w o r k i n g _ w i t h _ d a t a   i m p o r t   s c a l e     m e a n s ,   s t d e v s   =   s c a l e   x s     b e t a _ u n s c a l e d   =   [   b e t a [ 0 ]                                       -   b e t a [ 1 ]   *   m e a n s [ 1 ]       s t d e v s [ 1 ]                                       -   b e t a [ 2 ]   *   m e a n s [ 2 ]       s t d e v s [ 2 ]   ,                                     b e t a [ 1 ]       s t d e v s [ 1 ] ,                                     b e t a [ 2 ]       s t d e v s [ 2 ] ]      [ 8 . 9 ,   1 . 6 ,   - 0 . 0 0 0 2 8 8 ] o g i s t i o g i s t i  The impact on the output, however, depends on the other inputs as well. If   is already large  corresponding to a probability close to  1 , increasing it even by a lot cannot affect the probability very much. If it’s close to 0, increasing it just a little might increase the probability quite a bit. What we can say is that—all else being equal—people with more experience are more likely to pay for accounts. And that—all else being equal—people with higher salaries are less likely to pay for accounts.  This was also somewhat apparent when we plotted the data.   Goodness of Fit We haven’t yet used the test data that we held out. Let’s see what happens if we predict paid account whenever the probability exceeds 0.5:  This gives a precision of 75%  “when we predict paid account we’re right 75% of the time”  and a recall of 80%  “when a user has a paid account we predict paid account 80% of the time” , which is not terrible considering how little data we have. We can also plot the predictions versus the actuals  Figure 16-4 , which also shows that the model performs well:  d o t   b e t a ,   x _ i t r u e _ p o s i t i v e s   =   f a l s e _ p o s i t i v e s   =   t r u e _ n e g a t i v e s   =   f a l s e _ n e g a t i v e s   =   0     f o r   x _ i ,   y _ i   i n   z i p   x _ t e s t ,   y _ t e s t   :           p r e d i c t i o n   =   l o g i s t i c   d o t   b e t a ,   x _ i                 i f   y _ i   = =   1   a n d   p r e d i c t i o n   > =   0 . 5 :        T P :   p a i d   a n d   w e   p r e d i c t   p a i d                   t r u e _ p o s i t i v e s   + =   1           e l i f   y _ i   = =   1 :                                                F N :   p a i d   a n d   w e   p r e d i c t   u n p a i d                   f a l s e _ n e g a t i v e s   + =   1           e l i f   p r e d i c t i o n   > =   0 . 5 :                              F P :   u n p a i d   a n d   w e   p r e d i c t   p a i d                   f a l s e _ p o s i t i v e s   + =   1           e l s e :                                                                  T N :   u n p a i d   a n d   w e   p r e d i c t   u n p a i d                   t r u e _ n e g a t i v e s   + =   1     p r e c i s i o n   =   t r u e _ p o s i t i v e s         t r u e _ p o s i t i v e s   +   f a l s e _ p o s i t i v e s     r e c a l l   =   t r u e _ p o s i t i v e s         t r u e _ p o s i t i v e s   +   f a l s e _ n e g a t i v e s    Figure 16-4. Logistic regression predicted versus actual  Support Vector Machines The set of points where d our classes. We can plot this to see exactly what our model is doing  Figure 16-5 .    equals 0 is the boundary between  p r e d i c t i o n s   =   [ l o g i s t i c   d o t   b e t a ,   x _ i       f o r   x _ i   i n   x _ t e s t ]   p l t . s c a t t e r   p r e d i c t i o n s ,   y _ t e s t ,   m a r k e r = ' + '     p l t . x l a b e l   " p r e d i c t e d   p r o b a b i l i t y "     p l t . y l a b e l   " a c t u a l   o u t c o m e "     p l t . t i t l e   " L o g i s t i c   R e g r e s s i o n   P r e d i c t e d   v s .   A c t u a l "     p l t . s h o w     o t   b e t a ,   x _ i  Figure 16-5. Paid and unpaid users with decision boundary  This boundary is a hyperplane that splits the parameter space into two half- spaces corresponding to predict paid and predict unpaid. We found it as a side effect of finding the most likely logistic model. An alternative approach to classification is to just look for the hyperplane that “best” separates the classes in the training data. This is the idea behind the support vector machine, which finds the hyperplane that maximizes the distance to the nearest point in each class  Figure 16-6 .   Figure 16-6. A separating hyperplane  Finding such a hyperplane is an optimization problem that involves techniques that are too advanced for us. A different problem is that a separating hyperplane might not exist at all. In our “who pays?” dataset there simply is no line that perfectly separates the paid users from the unpaid users. We can sometimes get around this by transforming the data into a higher- dimensional space. For example, consider the simple one-dimensional dataset shown in Figure 16-7.   Figure 16-7. A nonseparable one-dimensional dataset  It’s clear that there’s no hyperplane that separates the positive examples from the negative ones. However, look at what happens when we map this dataset to two dimensions by sending the point x to    . Suddenly it’s possible to find a hyperplane that splits the data  Figure 16-8 .  x ,   x * * 2  Figure 16-8. Dataset becomes separable in higher dimensions  This is usually called the kernel trick because rather than actually mapping the points into the higher-dimensional space  which could be expensive if there are a lot of points and the mapping is complicated , we can use a “kernel” function to compute dot products in the higher-dimensional space and use those to find a hyperplane. It’s hard  and probably not a good idea  to use support vector machines without relying on specialized optimization software written by people with the appropriate expertise, so we’ll have to leave our treatment here.  For Further Investigation  scikit-learn has modules for both logistic regression and support vector machines.   LIBSVM is the support vector machine implementation that scikit- learn is using behind the scenes. Its website has a variety of useful documentation about support vector machines.   Chapter 17. Decision Trees  A tree is an incomprehensible mystery.  —Jim Woodring  DataSciencester’s VP of Talent has interviewed a number of job candidates from the site, with varying degrees of success. He’s collected a dataset consisting of several  qualitative  attributes of each candidate, as well as whether that candidate interviewed well or poorly. Could you, he asks, use this data to build a model identifying which candidates will interview well, so that he doesn’t have to waste time conducting interviews? This seems like a good fit for a decision tree, another predictive modeling tool in the data scientist’s kit.  What Is a Decision Tree? A decision tree uses a tree structure to represent a number of possible decision paths and an outcome for each path. If you have ever played the game Twenty Questions, then you are familiar with decision trees. For example:  “I am thinking of an animal.” “Does it have more than five legs?” “No.” “Is it delicious?” “No.” “Does it appear on the back of the Australian five-cent coin?” “Yes.”   “Is it an echidna?” “Yes, it is!”  This corresponds to the path: “Not more than 5 legs” → “Not delicious” → “On the 5-cent coin” → “Echidna!” in an idiosyncratic  and not very comprehensive  “guess the animal” decision tree  Figure 17-1 .  Figure 17-1. A “guess the animal” decision tree  Decision trees have a lot to recommend them. They’re very easy to understand and interpret, and the process by which they reach a prediction is completely transparent. Unlike the other models we’ve looked at so far, decision trees can easily handle a mix of numeric  e.g., number of legs  and categorical  e.g., delicious not delicious  attributes and can even classify data for which attributes are missing. At the same time, finding an “optimal” decision tree for a set of training data is computationally a very hard problem.  We will get around this by   trying to build a good-enough tree rather than an optimal one, although for large datasets this can still be a lot of work.  More important, it is very easy  and very bad  to build decision trees that are overfitted to the training data, and that don’t generalize well to unseen data. We’ll look at ways to address this. Most people divide decision trees into classification trees  which produce categorical outputs  and regression trees  which produce numeric outputs . In this chapter, we’ll focus on classification trees, and we’ll work through the ID3 algorithm for learning a decision tree from a set of labeled data, which should help us understand how decision trees actually work. To make things simple, we’ll restrict ourselves to problems with binary outputs like “Should I hire this candidate?” or “Should I show this website visitor advertisement A or advertisement B?” or “Will eating this food I found in the office fridge make me sick?”  Entropy In order to build a decision tree, we will need to decide what questions to ask and in what order. At each stage of the tree there are some possibilities we’ve eliminated and some that we haven’t. After learning that an animal doesn’t have more than five legs, we’ve eliminated the possibility that it’s a grasshopper. We haven’t eliminated the possibility that it’s a duck. Each possible question partitions the remaining possibilities according to its answer. Ideally, we’d like to choose questions whose answers give a lot of information about what our tree should predict. If there’s a single yes no question for which “yes” answers always correspond to T e outputs and “no” answers to F e outputs  or vice versa , this would be an awesome question to pick. Conversely, a yes no question for which neither answer gives you much new information about what the prediction should be is probably not a good choice.  r u a l s  We capture this notion of “how much information” with entropy. You have probably heard this term used to mean disorder. We use it to represent the uncertainty associated with data. Imagine that we have a set S of data, each member of which is labeled as belonging to one of a finite number of classes C n. If all the data points belong to a single class, then there is no real uncertainty, which means we’d like there to be low entropy. If the data points are evenly spread across the classes, there is a lot of uncertainty and we’d like there to be high entropy. In math terms, if p the entropy as:  i is the proportion of data labeled as class c  i, we define  with the  standard  convention that 0 Without worrying too much about the grisly details, each term − is non-negative and is close to 0 precisely when p close to 1  Figure 17-2 .  0.  i is either close to 0 or  1 , . . . , C H   S   = − p 1 l o g 2 p 1 − . . . − p n l o g 2 p n l o g 0 = p i l o g 2 p i  Figure 17-2. A graph of -p log p  This means the entropy will be small when every p i is close to 0 or 1  i.e., when most of the data is in a single class , and it will be larger when many of the p classes . This is exactly the behavior we desire. It is easy enough to roll all of this into a function:  i’s are not close to 0  i.e., when the data is spread across multiple  f r o m   t y p i n g   i m p o r t   L i s t   i m p o r t   m a t h     d e f   e n t r o p y   c l a s s _ p r o b a b i l i t i e s :   L i s t [ f l o a t ]     - >   f l o a t :           " " " G i v e n   a   l i s t   o f   c l a s s   p r o b a b i l i t i e s ,   c o m p u t e   t h e   e n t r o p y " " "           r e t u r n   s u m   - p   *   m a t h . l o g   p ,   2                                   f o r   p   i n   c l a s s _ p r o b a b i l i t i e s                                 i f   p   >   0                                                i g n o r e   z e r o   p r o b a b i l i t i e s     a s s e r t   e n t r o p y   [ 1 . 0 ]     = =   0    Our data will consist of pairs    , which means that we’ll need to compute the class probabilities ourselves. Notice that we don’t actually care which label is associated with each probability, only what the probabilities are:  The Entropy of a Partition What we’ve done so far is compute the entropy  think “uncertainty”  of a single set of labeled data. Now, each stage of a decision tree involves asking a question whose answer partitions data into one or  hopefully  more subsets. For instance, our “does it have more than five legs?” question partitions animals into those that have more than five legs  e.g., spiders  and those that don’t  e.g., echidnas . Correspondingly, we’d like some notion of the entropy that results from partitioning a set of data in a certain way. We want a partition to have low entropy if it splits the data into subsets that themselves have low entropy  i.e., are highly certain , and high entropy if it contains subsets that  are large and  have high entropy  i.e., are highly uncertain .  a s s e r t   e n t r o p y   [ 0 . 5 ,   0 . 5 ]     = =   1   a s s e r t   0 . 8 1   <   e n t r o p y   [ 0 . 2 5 ,   0 . 7 5 ]     <   0 . 8 2 i n p u t ,   l a b e l f r o m   t y p i n g   i m p o r t   A n y   f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     d e f   c l a s s _ p r o b a b i l i t i e s   l a b e l s :   L i s t [ A n y ]     - >   L i s t [ f l o a t ] :           t o t a l _ c o u n t   =   l e n   l a b e l s             r e t u r n   [ c o u n t       t o t a l _ c o u n t                           f o r   c o u n t   i n   C o u n t e r   l a b e l s   . v a l u e s     ]     d e f   d a t a _ e n t r o p y   l a b e l s :   L i s t [ A n y ]     - >   f l o a t :           r e t u r n   e n t r o p y   c l a s s _ p r o b a b i l i t i e s   l a b e l s         a s s e r t   d a t a _ e n t r o p y   [ ' a ' ]     = =   0   a s s e r t   d a t a _ e n t r o p y   [ T r u e ,   F a l s e ]     = =   1   a s s e r t   d a t a _ e n t r o p y   [ 3 ,   4 ,   4 ,   4 ]     = =   e n t r o p y   [ 0 . 2 5 ,   0 . 7 5 ]    1 = {echidna} and S  2 = {everything else}, where S  For example, my “Australian five-cent coin” question was pretty dumb  albeit pretty lucky! , as it partitioned the remaining animals at that point into S high-entropy.  S remaining “classes.”  Mathematically, if we partition our data S into subsets S proportions q partition as a weighted sum:  1 has no entropy, but it represents a small fraction of the  m of the data, then we compute the entropy of the  2 is both large and  m containing  which we can implement as:  NOTE  One problem with this approach is that partitioning by an attribute with many different values will result in a very low entropy due to overfitting. For example, imagine you work for a bank and are trying to build a decision tree to predict which of your customers are likely to default on their mortgages, using some historical data as your training set. Imagine further that the dataset contains each customer’s Social Security number. Partitioning on SSN will produce one-person subsets, each of which necessarily has zero entropy. But a model that relies on SSN is certain not to generalize beyond the training set. For this reason, you should probably try to avoid  or bucket, if appropriate  attributes with large numbers of possible values when creating decision trees.  Creating a Decision Tree The VP provides you with the interviewee data, consisting of  per your specification  a N  e of the relevant attributes for each candidate—  1 , . . . , S 1 , . . . , q H = q 1 H   S 1   + . . . + q m H   S m   d e f   p a r t i t i o n _ e n t r o p y   s u b s e t s :   L i s t [ L i s t [ A n y ] ]     - >   f l o a t :           " " " R e t u r n s   t h e   e n t r o p y   f r o m   t h i s   p a r t i t i o n   o f   d a t a   i n t o   s u b s e t s " " "           t o t a l _ c o u n t   =   s u m   l e n   s u b s e t     f o r   s u b s e t   i n   s u b s e t s               r e t u r n   s u m   d a t a _ e n t r o p y   s u b s e t     *   l e n   s u b s e t         t o t a l _ c o u n t                                 f o r   s u b s e t   i n   s u b s e t s   a m e d T u p l  her level, her preferred language, whether she is active on Twitter, whether she has a PhD, and whether she interviewed well:  Our tree will consist of decision nodes  which ask a question and direct us differently depending on the answer  and leaf nodes  which give us a prediction . We will build it using the relatively simple ID3 algorithm, which operates in the following manner. Let’s say we’re given some labeled data, and a list of attributes to consider branching on:  If the data all have the same label, create a leaf node that predicts that label and then stop. If the list of attributes is empty  i.e., there are no more possible questions to ask , create a leaf node that predicts the most common label and then stop.  f r o m   t y p i n g   i m p o r t   N a m e d T u p l e ,   O p t i o n a l     c l a s s   C a n d i d a t e   N a m e d T u p l e   :           l e v e l :   s t r           l a n g :   s t r           t w e e t s :   b o o l           p h d :   b o o l           d i d _ w e l l :   O p t i o n a l [ b o o l ]   =   N o n e        a l l o w   u n l a b e l e d   d a t a                                              l e v e l           l a n g           t w e e t s     p h d     d i d _ w e l l   i n p u t s   =   [ C a n d i d a t e   ' S e n i o r ' ,   ' J a v a ' ,       F a l s e ,   F a l s e ,   F a l s e   ,                       C a n d i d a t e   ' S e n i o r ' ,   ' J a v a ' ,       F a l s e ,   T r u e ,     F a l s e   ,                       C a n d i d a t e   ' M i d ' ,         ' P y t h o n ' ,   F a l s e ,   F a l s e ,   T r u e   ,                       C a n d i d a t e   ' J u n i o r ' ,   ' P y t h o n ' ,   F a l s e ,   F a l s e ,   T r u e   ,                       C a n d i d a t e   ' J u n i o r ' ,   ' R ' ,             T r u e ,     F a l s e ,   T r u e   ,                       C a n d i d a t e   ' J u n i o r ' ,   ' R ' ,             T r u e ,     T r u e ,     F a l s e   ,                       C a n d i d a t e   ' M i d ' ,         ' R ' ,             T r u e ,     T r u e ,     T r u e   ,                       C a n d i d a t e   ' S e n i o r ' ,   ' P y t h o n ' ,   F a l s e ,   F a l s e ,   F a l s e   ,                       C a n d i d a t e   ' S e n i o r ' ,   ' R ' ,             T r u e ,     F a l s e ,   T r u e   ,                       C a n d i d a t e   ' J u n i o r ' ,   ' P y t h o n ' ,   T r u e ,     F a l s e ,   T r u e   ,                       C a n d i d a t e   ' S e n i o r ' ,   ' P y t h o n ' ,   T r u e ,     T r u e ,     T r u e   ,                       C a n d i d a t e   ' M i d ' ,         ' P y t h o n ' ,   F a l s e ,   T r u e ,     T r u e   ,                       C a n d i d a t e   ' M i d ' ,         ' J a v a ' ,       T r u e ,     F a l s e ,   T r u e   ,                       C a n d i d a t e   ' J u n i o r ' ,   ' P y t h o n ' ,   F a l s e ,   T r u e ,     F a l s e                       ]  Otherwise, try partitioning the data by each of the attributes. Choose the partition with the lowest partition entropy. Add a decision node based on the chosen attribute. Recur on each partitioned subset using the remaining attributes.  This is what’s known as a “greedy” algorithm because, at each step, it chooses the most immediately best option. Given a dataset, there may be a better tree with a worse-looking first move. If so, this algorithm won’t find it. Nonetheless, it is relatively easy to understand and implement, which makes it a good place to begin exploring decision trees. Let’s manually go through these steps on the interviewee dataset. The e labels, and we have four attributes we can dataset has both T split on. So our first step will be to find the partition with the least entropy. We’ll start by writing a function that does the partitioning:  e and F  and one that uses it to compute entropy:  r u a l s f r o m   t y p i n g   i m p o r t   D i c t ,   T y p e V a r   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     T   =   T y p e V a r   ' T '          g e n e r i c   t y p e   f o r   i n p u t s     d e f   p a r t i t i o n _ b y   i n p u t s :   L i s t [ T ] ,   a t t r i b u t e :   s t r     - >   D i c t [ A n y ,   L i s t [ T ] ] :           " " " P a r t i t i o n   t h e   i n p u t s   i n t o   l i s t s   b a s e d   o n   t h e   s p e c i f i e d   a t t r i b u t e . " " "           p a r t i t i o n s :   D i c t [ A n y ,   L i s t [ T ] ]   =   d e f a u l t d i c t   l i s t             f o r   i n p u t   i n   i n p u t s :                   k e y   =   g e t a t t r   i n p u t ,   a t t r i b u t e          v a l u e   o f   t h e   s p e c i f i e d   a t t r i b u t e                   p a r t i t i o n s [ k e y ] . a p p e n d   i n p u t              a d d   i n p u t   t o   t h e   c o r r e c t   p a r t i t i o n           r e t u r n   p a r t i t i o n s d e f   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s :   L i s t [ A n y ] ,                                                     a t t r i b u t e :   s t r ,                                                     l a b e l _ a t t r i b u t e :   s t r     - >   f l o a t :           " " " C o m p u t e   t h e   e n t r o p y   c o r r e s p o n d i n g   t o   t h e   g i v e n   p a r t i t i o n " " "              p a r t i t i o n s   c o n s i s t   o f   o u r   i n p u t s           p a r t i t i o n s   =   p a r t i t i o n _ b y   i n p u t s ,   a t t r i b u t e                  b u t   p a r t i t i o n _ e n t r o p y   n e e d s   j u s t   t h e   c l a s s   l a b e l s    Then we just need to find the minimum-entropy partition for the whole dataset:  The lowest entropy comes from splitting on l subtree for each possible l l value. Every M which means that the M  r candidates, we have a mix of T  es and F  l, so we’ll need to make a e, d candidate is labeled T e. For es, so we need to split  d subtree is simply a leaf node predicting T  again:  s, which results in a r-level candidates, “yes” tweets  This shows us that our next split should be on t zero-entropy partition. For these S always result in T Finally, if we do the same thing for the J splitting on p PhD always results in F Figure 17-3 shows the complete decision tree.  e.  e while “no” tweets always result in F  e.  r candidates, we end up d, after which we find that no PhD always results in T  e and          l a b e l s   =   [ [ g e t a t t r   i n p u t ,   l a b e l _ a t t r i b u t e     f o r   i n p u t   i n   p a r t i t i o n ]                               f o r   p a r t i t i o n   i n   p a r t i t i o n s . v a l u e s     ]             r e t u r n   p a r t i t i o n _ e n t r o p y   l a b e l s   f o r   k e y   i n   [ ' l e v e l ' , ' l a n g ' , ' t w e e t s ' , ' p h d ' ] :           p r i n t   k e y ,   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   k e y ,   ' d i d _ w e l l '         a s s e r t   0 . 6 9   <   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   ' l e v e l ' ,   ' d i d _ w e l l '       <   0 . 7 0   a s s e r t   0 . 8 6   <   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   ' l a n g ' ,   ' d i d _ w e l l '         <   0 . 8 7   a s s e r t   0 . 7 8   <   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   ' t w e e t s ' ,   ' d i d _ w e l l '     <   0 . 7 9   a s s e r t   0 . 8 9   <   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   ' p h d ' ,   ' d i d _ w e l l '           <   0 . 9 0 e v e e v e i r u i r u S e n i o r u a l s s e n i o r _ i n p u t s   =   [ i n p u t   f o r   i n p u t   i n   i n p u t s   i f   i n p u t . l e v e l   = =   ' S e n i o r ' ]     a s s e r t   0 . 4   = =   p a r t i t i o n _ e n t r o p y _ b y   s e n i o r _ i n p u t s ,   ' l a n g ' ,   ' d i d _ w e l l '     a s s e r t   0 . 0   = =   p a r t i t i o n _ e n t r o p y _ b y   s e n i o r _ i n p u t s ,   ' t w e e t s ' ,   ' d i d _ w e l l '     a s s e r t   0 . 9 5   <   p a r t i t i o n _ e n t r o p y _ b y   s e n i o r _ i n p u t s ,   ' p h d ' ,   ' d i d _ w e l l '     <   0 . 9 6 w e e t e n i o r u a l s u n i o h r u a l s  Figure 17-3. The decision tree for hiring  Putting It All Together Now that we’ve seen how the algorithm works, we would like to implement it more generally. This means we need to decide how we want to represent trees. We’ll use pretty much the most lightweight representation possible. We define a tree to be either:  a L  f  that predicts a single value , or  a S t  containing an attribute to split on, subtrees for specific values of that attribute, and possibly a default value to use if we see an unknown value .  e a p l i f r o m   t y p i n g   i m p o r t   N a m e d T u p l e ,   U n i o n ,   A n y     c l a s s   L e a f   N a m e d T u p l e   :           v a l u e :   A n y    With this representation, our hiring tree would look like:  There’s still the question of what to do if we encounter an unexpected  or missing  attribute value. What should our hiring tree do if it encounters a candidate whose l  n? We’ll handle this case by populating the  l is I  e attribute with the most common label.  Given such a representation, we can classify an input with:    c l a s s   S p l i t   N a m e d T u p l e   :           a t t r i b u t e :   s t r           s u b t r e e s :   d i c t           d e f a u l t _ v a l u e :   A n y   =   N o n e     D e c i s i o n T r e e   =   U n i o n [ L e a f ,   S p l i t ] h i r i n g _ t r e e   =   S p l i t   ' l e v e l ' ,   {          f i r s t ,   c o n s i d e r   " l e v e l "           ' J u n i o r ' :   S p l i t   ' p h d ' ,   {              i f   l e v e l   i s   " J u n i o r " ,   n e x t   l o o k   a t   " p h d "                   F a l s e :   L e a f   T r u e   ,                      i f   " p h d "   i s   F a l s e ,   p r e d i c t   T r u e                   T r u e :   L e a f   F a l s e                          i f   " p h d "   i s   T r u e ,   p r e d i c t   F a l s e           }   ,           ' M i d ' :   L e a f   T r u e   ,                          i f   l e v e l   i s   " M i d " ,   j u s t   p r e d i c t   T r u e           ' S e n i o r ' :   S p l i t   ' t w e e t s ' ,   {        i f   l e v e l   i s   " S e n i o r " ,   l o o k   a t   " t w e e t s "                   F a l s e :   L e a f   F a l s e   ,                    i f   " t w e e t s "   i s   F a l s e ,   p r e d i c t   F a l s e                   T r u e :   L e a f   T r u e                            i f   " t w e e t s "   i s   T r u e ,   p r e d i c t   T r u e           }     }   e v e n t e r d e f a u l t _ v a l u d e f   c l a s s i f y   t r e e :   D e c i s i o n T r e e ,   i n p u t :   A n y     - >   A n y :           " " " c l a s s i f y   t h e   i n p u t   u s i n g   t h e   g i v e n   d e c i s i o n   t r e e " " "                I f   t h i s   i s   a   l e a f   n o d e ,   r e t u r n   i t s   v a l u e           i f   i s i n s t a n c e   t r e e ,   L e a f   :                   r e t u r n   t r e e . v a l u e                O t h e r w i s e   t h i s   t r e e   c o n s i s t s   o f   a n   a t t r i b u t e   t o   s p l i t   o n              a n d   a   d i c t i o n a r y   w h o s e   k e y s   a r e   v a l u e s   o f   t h a t   a t t r i b u t e              a n d   w h o s e   v a l u e s   a r e   s u b t r e e s   t o   c o n s i d e r   n e x t           s u b t r e e _ k e y   =   g e t a t t r   i n p u t ,   t r e e . a t t r i b u t e        All that’s left is to build the tree representation from our training data:  In the tree we built, every leaf consisted entirely of T of F  e inputs or entirely e inputs. This means that the tree predicts perfectly on the training          i f   s u b t r e e _ k e y   n o t   i n   t r e e . s u b t r e e s :          I f   n o   s u b t r e e   f o r   k e y ,                   r e t u r n   t r e e . d e f a u l t _ v a l u e                        r e t u r n   t h e   d e f a u l t   v a l u e .             s u b t r e e   =   t r e e . s u b t r e e s [ s u b t r e e _ k e y ]          C h o o s e   t h e   a p p r o p r i a t e   s u b t r e e           r e t u r n   c l a s s i f y   s u b t r e e ,   i n p u t                      a n d   u s e   i t   t o   c l a s s i f y   t h e   i n p u t . d e f   b u i l d _ t r e e _ i d 3   i n p u t s :   L i s t [ A n y ] ,                                         s p l i t _ a t t r i b u t e s :   L i s t [ s t r ] ,                                         t a r g e t _ a t t r i b u t e :   s t r     - >   D e c i s i o n T r e e :              C o u n t   t a r g e t   l a b e l s           l a b e l _ c o u n t s   =   C o u n t e r   g e t a t t r   i n p u t ,   t a r g e t _ a t t r i b u t e                                                           f o r   i n p u t   i n   i n p u t s             m o s t _ c o m m o n _ l a b e l   =   l a b e l _ c o u n t s . m o s t _ c o m m o n   1   [ 0 ] [ 0 ]                I f   t h e r e ' s   a   u n i q u e   l a b e l ,   p r e d i c t   i t           i f   l e n   l a b e l _ c o u n t s     = =   1 :                   r e t u r n   L e a f   m o s t _ c o m m o n _ l a b e l                  I f   n o   s p l i t   a t t r i b u t e s   l e f t ,   r e t u r n   t h e   m a j o r i t y   l a b e l           i f   n o t   s p l i t _ a t t r i b u t e s :                   r e t u r n   L e a f   m o s t _ c o m m o n _ l a b e l                  O t h e r w i s e   s p l i t   b y   t h e   b e s t   a t t r i b u t e             d e f   s p l i t _ e n t r o p y   a t t r i b u t e :   s t r     - >   f l o a t :                   " " " H e l p e r   f u n c t i o n   f o r   f i n d i n g   t h e   b e s t   a t t r i b u t e " " "                   r e t u r n   p a r t i t i o n _ e n t r o p y _ b y   i n p u t s ,   a t t r i b u t e ,   t a r g e t _ a t t r i b u t e               b e s t _ a t t r i b u t e   =   m i n   s p l i t _ a t t r i b u t e s ,   k e y = s p l i t _ e n t r o p y               p a r t i t i o n s   =   p a r t i t i o n _ b y   i n p u t s ,   b e s t _ a t t r i b u t e             n e w _ a t t r i b u t e s   =   [ a   f o r   a   i n   s p l i t _ a t t r i b u t e s   i f   a   ! =   b e s t _ a t t r i b u t e ]                R e c u r s i v e l y   b u i l d   t h e   s u b t r e e s           s u b t r e e s   =   { a t t r i b u t e _ v a l u e   :   b u i l d _ t r e e _ i d 3   s u b s e t ,                                                                                                     n e w _ a t t r i b u t e s ,                                                                                                     t a r g e t _ a t t r i b u t e                                     f o r   a t t r i b u t e _ v a l u e ,   s u b s e t   i n   p a r t i t i o n s . i t e m s     }             r e t u r n   S p l i t   b e s t _ a t t r i b u t e ,   s u b t r e e s ,   d e f a u l t _ v a l u e = m o s t _ c o m m o n _ l a b e l   r u a l s  dataset. But we can also apply it to new data that wasn’t in the training set:  And also to data with unexpected values:  NOTE  Since our goal was mainly to demonstrate how to build a tree, we built the tree using the entire dataset. As always, if we were really trying to create a good model for something, we would have collected more data and split it into train validation test subsets.  Random Forests Given how closely decision trees can fit themselves to their training data, it’s not surprising that they have a tendency to overfit. One way of avoiding this is a technique called random forests, in which we build multiple decision trees and combine their outputs. If they’re classification trees, we might let them vote; if they’re regression trees, we might average their predictions. Our tree-building process was deterministic, so how do we get random trees? One piece involves bootstrapping data  recall “Digression: The Bootstrap” . s in the training set, we train Rather than training each tree on all the i each tree on the result of b  . Since each tree is  t r e e   =   b u i l d _ t r e e _ i d 3   i n p u t s ,                                               [ ' l e v e l ' ,   ' l a n g ' ,   ' t w e e t s ' ,   ' p h d ' ] ,                                               ' d i d _ w e l l '          S h o u l d   p r e d i c t   T r u e   a s s e r t   c l a s s i f y   t r e e ,   C a n d i d a t e   " J u n i o r " ,   " J a v a " ,   T r u e ,   F a l s e            S h o u l d   p r e d i c t   F a l s e   a s s e r t   n o t   c l a s s i f y   t r e e ,   C a n d i d a t e   " J u n i o r " ,   " J a v a " ,   T r u e ,   T r u e        S h o u l d   p r e d i c t   T r u e   a s s e r t   c l a s s i f y   t r e e ,   C a n d i d a t e   " I n t e r n " ,   " J a v a " ,   T r u e ,   T r u e     n p u t o o t s t r a p _ s a m p l e   i n p u t s  built using different data, each tree will be different from every other tree.  A side benefit is that it’s totally fair to use the nonsampled data to test each tree, which means you can get away with using all of your data as the training set if you are clever in how you measure performance.  This technique is known as bootstrap aggregating or bagging. A second source of randomness involves changing the way we choose the  e to split on. Rather than looking at all the remaining attributes, we first choose a random subset of them and then split on whichever of those is best:  This is an example of a broader technique called ensemble learning in which we combine several weak learners  typically high-bias, low-variance models  in order to produce an overall strong model.  For Further Exploration  scikit-learn has many decision tree models. It also has an e module that includes a R ensemble methods. XGBoost is a library for training gradient boosted decision trees that tends to win a lot of Kaggle-style machine learning competitions.  r as well as other  b e s t _ a t t r i b u t            i f   t h e r e   a r e   a l r e a d y   f e w   e n o u g h   s p l i t   c a n d i d a t e s ,   l o o k   a t   a l l   o f   t h e m           i f   l e n   s p l i t _ c a n d i d a t e s     < =   s e l f . n u m _ s p l i t _ c a n d i d a t e s :                   s a m p l e d _ s p l i t _ c a n d i d a t e s   =   s p l i t _ c a n d i d a t e s              o t h e r w i s e   p i c k   a   r a n d o m   s a m p l e           e l s e :                   s a m p l e d _ s p l i t _ c a n d i d a t e s   =   r a n d o m . s a m p l e   s p l i t _ c a n d i d a t e s ,                                                                                                     s e l f . n u m _ s p l i t _ c a n d i d a t e s                  n o w   c h o o s e   t h e   b e s t   a t t r i b u t e   o n l y   f r o m   t h o s e   c a n d i d a t e s           b e s t _ a t t r i b u t e   =   m i n   s a m p l e d _ s p l i t _ c a n d i d a t e s ,   k e y = s p l i t _ e n t r o p y               p a r t i t i o n s   =   p a r t i t i o n _ b y   i n p u t s ,   b e s t _ a t t r i b u t e   n s e m b l e a n d o m F o r e s t C l a s s i f i e  We’ve barely scratched the surface of decision trees and their algorithms. Wikipedia is a good starting point for broader exploration.   Chapter 18. Neural Networks  I like nonsense; it wakes up the brain cells.  —Dr. Seuss  An artificial neural network  or neural network for short  is a predictive model motivated by the way the brain operates. Think of the brain as a collection of neurons wired together. Each neuron looks at the outputs of the other neurons that feed into it, does a calculation, and then either fires  if the calculation exceeds some threshold  or doesn’t  if it doesn’t . Accordingly, artificial neural networks consist of artificial neurons, which perform similar calculations over their inputs. Neural networks can solve a wide variety of problems like handwriting recognition and face detection, and they are used heavily in deep learning, one of the trendiest subfields of data science. However, most neural networks are “black boxes”— inspecting their details doesn’t give you much understanding of how they’re solving a problem. And large neural networks can be difficult to train. For most problems you’ll encounter as a budding data scientist, they’re probably not the right choice. Someday, when you’re trying to build an artificial intelligence to bring about the Singularity, they very well might be.  Perceptrons Pretty much the simplest neural network is the perceptron, which approximates a single neuron with n binary inputs. It computes a weighted sum of its inputs and “fires” if that weighted sum is 0 or greater:  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r ,   d o t     d e f   s t e p _ f u n c t i o n   x :   f l o a t     - >   f l o a t :           r e t u r n   1 . 0   i f   x   > =   0   e l s e   0 . 0     d e f   p e r c e p t r o n _ o u t p u t   w e i g h t s :   V e c t o r ,   b i a s :   f l o a t ,   x :   V e c t o r     - >   f l o a t :    The perceptron is simply distinguishing between the half-spaces separated by the hyperplane of points x for which:  With properly chosen weights, perceptrons can solve a number of simple problems  Figure 18-1 . For example, we can create an AND gate  which returns 1 if both its inputs are 1 but returns 0 if one of its inputs is 0  with:  If both inputs are 1, the c 1. If only one of the inputs is 1, the c the output is 0. And if both of the inputs are 0, the c and the output is 0. Using similar reasoning, we could build an OR gate with:  n equals 2 + 2 – 3 = 1, and the output is n equals 2 + 0 – 3 = –1, and n equals –3,          " " " R e t u r n s   1   i f   t h e   p e r c e p t r o n   ' f i r e s ' ,   0   i f   n o t " " "           c a l c u l a t i o n   =   d o t   w e i g h t s ,   x     +   b i a s           r e t u r n   s t e p _ f u n c t i o n   c a l c u l a t i o n   d o t   w e i g h t s ,   x     +   b i a s   = =   0 a n d _ w e i g h t s   =   [ 2 . ,   2 ]   a n d _ b i a s   =   - 3 .     a s s e r t   p e r c e p t r o n _ o u t p u t   a n d _ w e i g h t s ,   a n d _ b i a s ,   [ 1 ,   1 ]     = =   1   a s s e r t   p e r c e p t r o n _ o u t p u t   a n d _ w e i g h t s ,   a n d _ b i a s ,   [ 0 ,   1 ]     = =   0   a s s e r t   p e r c e p t r o n _ o u t p u t   a n d _ w e i g h t s ,   a n d _ b i a s ,   [ 1 ,   0 ]     = =   0   a s s e r t   p e r c e p t r o n _ o u t p u t   a n d _ w e i g h t s ,   a n d _ b i a s ,   [ 0 ,   0 ]     = =   0 a l c u l a t i o a l c u l a t i o a l c u l a t i o o r _ w e i g h t s   =   [ 2 . ,   2 ]   o r _ b i a s   =   - 1 .     a s s e r t   p e r c e p t r o n _ o u t p u t   o r _ w e i g h t s ,   o r _ b i a s ,   [ 1 ,   1 ]     = =   1   a s s e r t   p e r c e p t r o n _ o u t p u t   o r _ w e i g h t s ,   o r _ b i a s ,   [ 0 ,   1 ]     = =   1   a s s e r t   p e r c e p t r o n _ o u t p u t   o r _ w e i g h t s ,   o r _ b i a s ,   [ 1 ,   0 ]     = =   1   a s s e r t   p e r c e p t r o n _ o u t p u t   o r _ w e i g h t s ,   o r _ b i a s ,   [ 0 ,   0 ]     = =   0  Figure 18-1. Decision space for a two-input perceptron  We could also build a NOT gate  which has one input and converts 1 to 0 and 0 to 1  with:  However, there are some problems that simply can’t be solved by a single perceptron. For example, no matter how hard you try, you cannot use a perceptron to build an XOR gate that outputs 1 if exactly one of its inputs is 1 and 0 otherwise. This is where we start needing more complicated neural networks.  n o t _ w e i g h t s   =   [ - 2 . ]   n o t _ b i a s   =   1 .     a s s e r t   p e r c e p t r o n _ o u t p u t   n o t _ w e i g h t s ,   n o t _ b i a s ,   [ 0 ]     = =   1   a s s e r t   p e r c e p t r o n _ o u t p u t   n o t _ w e i g h t s ,   n o t _ b i a s ,   [ 1 ]     = =   0  Of course, you don’t need to approximate a neuron in order to build a logic gate:  Like real neurons, artificial neurons start getting more interesting when you start connecting them together.  Feed-Forward Neural Networks The topology of the brain is enormously complicated, so it’s common to approximate it with an idealized feed-forward neural network that consists of discrete layers of neurons, each connected to the next. This typically entails an input layer  which receives inputs and feeds them forward unchanged , one or more “hidden layers”  each of which consists of neurons that take the outputs of the previous layer, performs some calculation, and passes the result to the next layer , and an output layer  which produces the final outputs . Just like in the perceptron, each  noninput  neuron has a weight corresponding to each of its inputs and a bias. To make our representation simpler, we’ll add the bias to the end of our weights vector and give each neuron a bias input that always equals 1. As with the perceptron, for each neuron we’ll sum up the products of its inputs and its weights. But here, rather than outputting the s applied to that product, we’ll output a smooth approximation of it. Here we’ll use the s  d function  Figure 18-2 :  a n d _ g a t e   =   m i n   o r _ g a t e   =   m a x   x o r _ g a t e   =   l a m b d a   x ,   y :   0   i f   x   = =   y   e l s e   1 t e p _ f u n c t i o n i g m o i i m p o r t   m a t h     d e f   s i g m o i d   t :   f l o a t     - >   f l o a t :           r e t u r n   1         1   +   m a t h . e x p   - t      Figure 18-2. The sigmoid function  d instead of the simpler s  Why use s n? In order to train a neural network, we need to use calculus, and in order to use calculus, we need smooth functions. s is a good smooth approximation of it.  n isn’t even continuous, and s  NOTE  You may remember s Technically “sigmoid” refers to the shape of the function and “logistic” to this particular function, although people often use the terms interchangeably.  d from Chapter 16, where it was called l  c.  We then calculate the output as:  i g m o i t e p _ f u n c t i o t e p _ f u n c t i o i g m o i d i g m o i o g i s t i  Given this function, we can represent a neuron simply as a vector of weights whose length is one more than the number of inputs to that neuron  because of the bias weight . Then we can represent a neural network as a list of  noninput  layers, where each layer is just a list of the neurons in that layer. That is, we’ll represent a neural network as a list  layers  of lists  neurons  of vectors  weights . Given such a representation, using the neural network is quite simple:  Now it’s easy to build the XOR gate that we couldn’t build with a single perceptron. We just need to scale the weights up so that the  ts are either really close to 0 or really close to 1:  d e f   n e u r o n _ o u t p u t   w e i g h t s :   V e c t o r ,   i n p u t s :   V e c t o r     - >   f l o a t :              w e i g h t s   i n c l u d e s   t h e   b i a s   t e r m ,   i n p u t s   i n c l u d e s   a   1           r e t u r n   s i g m o i d   d o t   w e i g h t s ,   i n p u t s     f r o m   t y p i n g   i m p o r t   L i s t     d e f   f e e d _ f o r w a r d   n e u r a l _ n e t w o r k :   L i s t [ L i s t [ V e c t o r ] ] ,                                     i n p u t _ v e c t o r :   V e c t o r     - >   L i s t [ V e c t o r ] :           " " "           F e e d s   t h e   i n p u t   v e c t o r   t h r o u g h   t h e   n e u r a l   n e t w o r k .           R e t u r n s   t h e   o u t p u t s   o f   a l l   l a y e r s     n o t   j u s t   t h e   l a s t   o n e   .           " " "           o u t p u t s :   L i s t [ V e c t o r ]   =   [ ]             f o r   l a y e r   i n   n e u r a l _ n e t w o r k :                   i n p u t _ w i t h _ b i a s   =   i n p u t _ v e c t o r   +   [ 1 ]                                A d d   a   c o n s t a n t .                   o u t p u t   =   [ n e u r o n _ o u t p u t   n e u r o n ,   i n p u t _ w i t h _ b i a s          C o m p u t e   t h e   o u t p u t                                       f o r   n e u r o n   i n   l a y e r ]                                            f o r   e a c h   n e u r o n .                   o u t p u t s . a p p e n d   o u t p u t                                                              A d d   t o   r e s u l t s .                        T h e n   t h e   i n p u t   t o   t h e   n e x t   l a y e r   i s   t h e   o u t p u t   o f   t h i s   o n e                   i n p u t _ v e c t o r   =   o u t p u t             r e t u r n   o u t p u t s n e u r o n _ o u t p u x o r _ n e t w o r k   =   [    h i d d e n   l a y e r                                 [ [ 2 0 . ,   2 0 ,   - 3 0 ] ,                ' a n d '   n e u r o n    For a given input  which is a two-dimensional vector , the hidden layer produces a two-dimensional vector consisting of the “and” of the two input values and the “or” of the two input values. And the output layer takes a two-dimensional vector and computes “second element but not first element.” The result is a network that performs “or, but not and,” which is precisely XOR  Figure 18-3 .  Figure 18-3. A neural network for XOR  One suggestive way of thinking about this is that the hidden layer is computing features of the input data  in this case “and” and “or”  and the output layer is combining those features in a way that generates the desired output.                                  [ 2 0 . ,   2 0 ,   - 1 0 ] ] ,              ' o r '     n e u r o n                                    o u t p u t   l a y e r                                 [ [ - 6 0 . ,   6 0 ,   - 3 0 ] ] ]            ' 2 n d   i n p u t   b u t   n o t   1 s t   i n p u t '   n e u r o n        f e e d _ f o r w a r d   r e t u r n s   t h e   o u t p u t s   o f   a l l   l a y e r s ,   s o   t h e   [ - 1 ]   g e t s   t h e      f i n a l   o u t p u t ,   a n d   t h e   [ 0 ]   g e t s   t h e   v a l u e   o u t   o f   t h e   r e s u l t i n g   v e c t o r   a s s e r t   0 . 0 0 0   <   f e e d _ f o r w a r d   x o r _ n e t w o r k ,   [ 0 ,   0 ]   [ - 1 ] [ 0 ]   <   0 . 0 0 1   a s s e r t   0 . 9 9 9   <   f e e d _ f o r w a r d   x o r _ n e t w o r k ,   [ 1 ,   0 ]   [ - 1 ] [ 0 ]   <   1 . 0 0 0   a s s e r t   0 . 9 9 9   <   f e e d _ f o r w a r d   x o r _ n e t w o r k ,   [ 0 ,   1 ]   [ - 1 ] [ 0 ]   <   1 . 0 0 0   a s s e r t   0 . 0 0 0   <   f e e d _ f o r w a r d   x o r _ n e t w o r k ,   [ 1 ,   1 ]   [ - 1 ] [ 0 ]   <   0 . 0 0 1  Backpropagation Usually we don’t build neural networks by hand. This is in part because we use them to solve much bigger problems—an image recognition problem might involve hundreds or thousands of neurons. And it’s in part because we usually won’t be able to “reason out” what the neurons should be. Instead  as usual  we use data to train neural networks. The typical approach is an algorithm called backpropagation, which uses gradient descent or one of its variants. Imagine we have a training set that consists of input vectors and corresponding target output vectors. For example, in our previous  k example, the input vector [  ] corresponded to the target  output [ adjust the weights using the following algorithm:  ]. Imagine that our network has some set of weights. We then  1. Run f  d on an input vector to produce the outputs of all  the neurons in the network.  2. We know the target output, so we can compute a loss that’s the sum  of the squared errors.  neuron’s weights.  3. Compute the gradient of this loss as a function of the output  4. “Propagate” the gradients and errors backward to compute the  gradients with respect to the hidden neurons’ weights.  5. Take a gradient descent step.  Typically we run this algorithm many times for our entire training set until the network converges. To start with, let’s write the function to compute the gradients:  x o r _ n e t w o r 1 ,   0 1 e e d _ f o r w a r d e f   s q e r r o r _ g r a d i e n t s   n e t w o r k :   L i s t [ L i s t [ V e c t o r ] ] ,                                               i n p u t _ v e c t o r :   V e c t o r ,                                               t a r g e t _ v e c t o r :   V e c t o r     - >   L i s t [ L i s t [ V e c t o r ] ] :           " " "    The math behind the preceding calculations is not terribly difficult, but it involves some tedious calculus and careful attention to detail, so I’ll leave it as an exercise for you. Armed with the ability to compute gradients, we can now train neural networks. Let’s try to learn the XOR network we previously designed by hand. We’ll start by generating the training data and initializing our neural network with random weights:          G i v e n   a   n e u r a l   n e t w o r k ,   a n   i n p u t   v e c t o r ,   a n d   a   t a r g e t   v e c t o r ,           m a k e   a   p r e d i c t i o n   a n d   c o m p u t e   t h e   g r a d i e n t   o f   t h e   s q u a r e d   e r r o r           l o s s   w i t h   r e s p e c t   t o   t h e   n e u r o n   w e i g h t s .           " " "              f o r w a r d   p a s s           h i d d e n _ o u t p u t s ,   o u t p u t s   =   f e e d _ f o r w a r d   n e t w o r k ,   i n p u t _ v e c t o r                  g r a d i e n t s   w i t h   r e s p e c t   t o   o u t p u t   n e u r o n   p r e - a c t i v a t i o n   o u t p u t s           o u t p u t _ d e l t a s   =   [ o u t p u t   *     1   -   o u t p u t     *     o u t p u t   -   t a r g e t                                               f o r   o u t p u t ,   t a r g e t   i n   z i p   o u t p u t s ,   t a r g e t _ v e c t o r   ]                g r a d i e n t s   w i t h   r e s p e c t   t o   o u t p u t   n e u r o n   w e i g h t s           o u t p u t _ g r a d s   =   [ [ o u t p u t _ d e l t a s [ i ]   *   h i d d e n _ o u t p u t                                             f o r   h i d d e n _ o u t p u t   i n   h i d d e n _ o u t p u t s   +   [ 1 ] ]                                           f o r   i ,   o u t p u t _ n e u r o n   i n   e n u m e r a t e   n e t w o r k [ - 1 ]   ]                g r a d i e n t s   w i t h   r e s p e c t   t o   h i d d e n   n e u r o n   p r e - a c t i v a t i o n   o u t p u t s           h i d d e n _ d e l t a s   =   [ h i d d e n _ o u t p u t   *     1   -   h i d d e n _ o u t p u t     *                                                     d o t   o u t p u t _ d e l t a s ,   [ n [ i ]   f o r   n   i n   n e t w o r k [ - 1 ] ]                                               f o r   i ,   h i d d e n _ o u t p u t   i n   e n u m e r a t e   h i d d e n _ o u t p u t s   ]                g r a d i e n t s   w i t h   r e s p e c t   t o   h i d d e n   n e u r o n   w e i g h t s           h i d d e n _ g r a d s   =   [ [ h i d d e n _ d e l t a s [ i ]   *   i n p u t   f o r   i n p u t   i n   i n p u t _ v e c t o r   +   [ 1 ] ]                                           f o r   i ,   h i d d e n _ n e u r o n   i n   e n u m e r a t e   n e t w o r k [ 0 ]   ]             r e t u r n   [ h i d d e n _ g r a d s ,   o u t p u t _ g r a d s ] i m p o r t   r a n d o m   r a n d o m . s e e d   0          t r a i n i n g   d a t a   x s   =   [ [ 0 . ,   0 ] ,   [ 0 . ,   1 ] ,   [ 1 . ,   0 ] ,   [ 1 . ,   1 ] ]   y s   =   [ [ 0 . ] ,   [ 1 . ] ,   [ 1 . ] ,   [ 0 . ] ]      As usual, we can train it using gradient descent. One difference from our previous examples is that here we have several parameter vectors, each with its own gradient, which means we’ll have to call g of them.  p for each  For me the resulting network has weights that look like:  which is conceptually pretty similar to our previous bespoke network.     s t a r t   w i t h   r a n d o m   w e i g h t s   n e t w o r k   =   [      h i d d e n   l a y e r :   2   i n p u t s   - >   2   o u t p u t s                           [ [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   2   +   1   ] ,          1 s t   h i d d e n   n e u r o n                             [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   2   +   1   ] ] ,        2 n d   h i d d e n   n e u r o n                              o u t p u t   l a y e r :   2   i n p u t s   - >   1   o u t p u t                           [ [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   2   +   1   ] ]          1 s t   o u t p u t   n e u r o n                       ] r a d i e n t _ s t e f r o m   s c r a t c h . g r a d i e n t _ d e s c e n t   i m p o r t   g r a d i e n t _ s t e p   i m p o r t   t q d m     l e a r n i n g _ r a t e   =   1 . 0     f o r   e p o c h   i n   t q d m . t r a n g e   2 0 0 0 0 ,   d e s c = " n e u r a l   n e t   f o r   x o r "   :           f o r   x ,   y   i n   z i p   x s ,   y s   :                   g r a d i e n t s   =   s q e r r o r _ g r a d i e n t s   n e t w o r k ,   x ,   y                          T a k e   a   g r a d i e n t   s t e p   f o r   e a c h   n e u r o n   i n   e a c h   l a y e r                   n e t w o r k   =   [ [ g r a d i e n t _ s t e p   n e u r o n ,   g r a d ,   - l e a r n i n g _ r a t e                                             f o r   n e u r o n ,   g r a d   i n   z i p   l a y e r ,   l a y e r _ g r a d   ]                                         f o r   l a y e r ,   l a y e r _ g r a d   i n   z i p   n e t w o r k ,   g r a d i e n t s   ]        c h e c k   t h a t   i t   l e a r n e d   X O R   a s s e r t   f e e d _ f o r w a r d   n e t w o r k ,   [ 0 ,   0 ]   [ - 1 ] [ 0 ]   <   0 . 0 1   a s s e r t   f e e d _ f o r w a r d   n e t w o r k ,   [ 0 ,   1 ]   [ - 1 ] [ 0 ]   >   0 . 9 9   a s s e r t   f e e d _ f o r w a r d   n e t w o r k ,   [ 1 ,   0 ]   [ - 1 ] [ 0 ]   >   0 . 9 9   a s s e r t   f e e d _ f o r w a r d   n e t w o r k ,   [ 1 ,   1 ]   [ - 1 ] [ 0 ]   <   0 . 0 1 [          h i d d e n   l a y e r           [ [ 7 ,   7 ,   - 3 ] ,              c o m p u t e s   O R             [ 5 ,   5 ,   - 8 ] ] ,            c o m p u t e s   A N D              o u t p u t   l a y e r           [ [ 1 1 ,   - 1 2 ,   - 5 ] ]        c o m p u t e s   " f i r s t   b u t   n o t   s e c o n d "   ]  Example: Fizz Buzz The VP of Engineering wants to interview technical candidates by making them solve “Fizz Buzz,” the following well-trod programming challenge:  He thinks the ability to solve this demonstrates extreme programming skill. You think that this problem is so simple that a neural network could solve it. Neural networks take vectors as inputs and produce vectors as outputs. As stated, the programming problem is to turn an integer into a string. So the first challenge is to come up with a way to recast it as a vector problem. For the outputs it’s not tough: there are basically four classes of outputs, so we can encode the output as a vector of four 0s and 1s:  We’ll use this to generate our target vectors. The input vectors are less obvious. You don’t want to just use a one-dimensional vector containing the input number, for a couple of reasons. A single input captures an “intensity,” but the fact that 2 is twice as much as 1, and that 4 is twice as much again, doesn’t feel relevant to this problem. Additionally, with just  P r i n t   t h e   n u m b e r s   1   t o   1 0 0 ,   e x c e p t   t h a t   i f   t h e   n u m b e r   i s   d i v i s i b l e   b y   3 ,   p r i n t   " f i z z " ;   i f   t h e   n u m b e r   i s   d i v i s i b l e   b y   5 ,   p r i n t   " b u z z " ;   a n d   i f   t h e   n u m b e r   i s   d i v i s i b l e   b y   1 5 ,   p r i n t   " f i z z b u z z " . d e f   f i z z _ b u z z _ e n c o d e   x :   i n t     - >   V e c t o r :           i f   x   %   1 5   = =   0 :                   r e t u r n   [ 0 ,   0 ,   0 ,   1 ]           e l i f   x   %   5   = =   0 :                   r e t u r n   [ 0 ,   0 ,   1 ,   0 ]           e l i f   x   %   3   = =   0 :                   r e t u r n   [ 0 ,   1 ,   0 ,   0 ]           e l s e :                   r e t u r n   [ 1 ,   0 ,   0 ,   0 ]     a s s e r t   f i z z _ b u z z _ e n c o d e   2     = =   [ 1 ,   0 ,   0 ,   0 ]   a s s e r t   f i z z _ b u z z _ e n c o d e   6     = =   [ 0 ,   1 ,   0 ,   0 ]   a s s e r t   f i z z _ b u z z _ e n c o d e   1 0     = =   [ 0 ,   0 ,   1 ,   0 ]   a s s e r t   f i z z _ b u z z _ e n c o d e   3 0     = =   [ 0 ,   0 ,   0 ,   1 ]  one input the hidden layer wouldn’t be able to compute very interesting features, which means it probably wouldn’t be able to solve the problem. It turns out that one thing that works reasonably well is to convert each number to its binary representation of 1s and 0s.  Don’t worry, this isn’t obvious—at least it wasn’t to me.   As the goal is to construct the outputs for the numbers 1 to 100, it would be cheating to train on those numbers. Therefore, we’ll train on the numbers 101 to 1,023  which is the largest number we can represent with 10 binary digits :  Next, let’s create a neural network with random initial weights. It will have 10 input neurons  since we’re representing our inputs as 10-dimensional vectors  and 4 output neurons  since we’re representing our targets as 4- dimensional vectors . We’ll give it 25 hidden units, but we’ll use a variable for that so it’s easy to change:  d e f   b i n a r y _ e n c o d e   x :   i n t     - >   V e c t o r :           b i n a r y :   L i s t [ f l o a t ]   =   [ ]             f o r   i   i n   r a n g e   1 0   :                   b i n a r y . a p p e n d   x   %   2                     x   =   x         2             r e t u r n   b i n a r y                                                                1     2     4     8   1 6   3 2   6 4   1 2 8   2 5 6   5 1 2   a s s e r t   b i n a r y _ e n c o d e   0         = =   [ 0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,     0 ,     0 ]   a s s e r t   b i n a r y _ e n c o d e   1         = =   [ 1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,     0 ,     0 ]   a s s e r t   b i n a r y _ e n c o d e   1 0       = =   [ 0 ,   1 ,   0 ,   1 ,   0 ,   0 ,   0 ,   0 ,     0 ,     0 ]   a s s e r t   b i n a r y _ e n c o d e   1 0 1     = =   [ 1 ,   0 ,   1 ,   0 ,   0 ,   1 ,   1 ,   0 ,     0 ,     0 ]   a s s e r t   b i n a r y _ e n c o d e   9 9 9     = =   [ 1 ,   1 ,   1 ,   0 ,   0 ,   1 ,   1 ,   1 ,     1 ,     1 ] x s   =   [ b i n a r y _ e n c o d e   n     f o r   n   i n   r a n g e   1 0 1 ,   1 0 2 4   ]   y s   =   [ f i z z _ b u z z _ e n c o d e   n     f o r   n   i n   r a n g e   1 0 1 ,   1 0 2 4   ] N U M _ H I D D E N   =   2 5     n e t w o r k   =   [              h i d d e n   l a y e r :   1 0   i n p u t s   - >   N U M _ H I D D E N   o u t p u t s    That’s it. Now we’re ready to train. Because this is a more involved problem  and there are a lot more things to mess up , we’d like to closely monitor the training process. In particular, for each epoch we’ll track the sum of squared errors and print them out. We want to make sure they decrease:  This will take a while to train, but eventually the loss should start to bottom out. At last we’re ready to solve our original problem. We have one remaining issue. Our network will produce a four-dimensional vector of numbers, but we want a single prediction. We’ll do that by taking the a the index of the largest value:  x, which is          [ [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   1 0   +   1   ]   f o r   _   i n   r a n g e   N U M _ H I D D E N   ] ,                o u t p u t _ l a y e r :   N U M _ H I D D E N   i n p u t s   - >   4   o u t p u t s           [ [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   N U M _ H I D D E N   +   1   ]   f o r   _   i n   r a n g e   4   ]   ] f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s q u a r e d _ d i s t a n c e     l e a r n i n g _ r a t e   =   1 . 0     w i t h   t q d m . t r a n g e   5 0 0     a s   t :           f o r   e p o c h   i n   t :                   e p o c h _ l o s s   =   0 . 0                     f o r   x ,   y   i n   z i p   x s ,   y s   :                           p r e d i c t e d   =   f e e d _ f o r w a r d   n e t w o r k ,   x   [ - 1 ]                           e p o c h _ l o s s   + =   s q u a r e d _ d i s t a n c e   p r e d i c t e d ,   y                             g r a d i e n t s   =   s q e r r o r _ g r a d i e n t s   n e t w o r k ,   x ,   y                                  T a k e   a   g r a d i e n t   s t e p   f o r   e a c h   n e u r o n   i n   e a c h   l a y e r                           n e t w o r k   =   [ [ g r a d i e n t _ s t e p   n e u r o n ,   g r a d ,   - l e a r n i n g _ r a t e                                                     f o r   n e u r o n ,   g r a d   i n   z i p   l a y e r ,   l a y e r _ g r a d   ]                                           f o r   l a y e r ,   l a y e r _ g r a d   i n   z i p   n e t w o r k ,   g r a d i e n t s   ]                     t . s e t _ d e s c r i p t i o n   f " f i z z   b u z z     l o s s :   { e p o c h _ l o s s : . 2 f }   "   r g m a d e f   a r g m a x   x s :   l i s t     - >   i n t :           " " " R e t u r n s   t h e   i n d e x   o f   t h e   l a r g e s t   v a l u e " " "    Now we can finally solve “FizzBuzz”:  For me the trained network gets 96 100 correct, which is well above the VP of Engineering’s hiring threshold. Faced with the evidence, he relents and changes the interview challenge to “Invert a Binary Tree.”  For Further Exploration  Keep reading: Chapter 19 will explore these topics in much more detail. My blog post on “Fizz Buzz in Tensorflow” is pretty good.          r e t u r n   m a x   r a n g e   l e n   x s     ,   k e y = l a m b d a   i :   x s [ i ]       a s s e r t   a r g m a x   [ 0 ,   - 1 ]     = =   0                                  i t e m s [ 0 ]   i s   l a r g e s t   a s s e r t   a r g m a x   [ - 1 ,   0 ]     = =   1                                  i t e m s [ 1 ]   i s   l a r g e s t   a s s e r t   a r g m a x   [ - 1 ,   1 0 ,   5 ,   2 0 ,   - 3 ]     = =   3          i t e m s [ 3 ]   i s   l a r g e s t n u m _ c o r r e c t   =   0     f o r   n   i n   r a n g e   1 ,   1 0 1   :           x   =   b i n a r y _ e n c o d e   n             p r e d i c t e d   =   a r g m a x   f e e d _ f o r w a r d   n e t w o r k ,   x   [ - 1 ]             a c t u a l   =   a r g m a x   f i z z _ b u z z _ e n c o d e   n               l a b e l s   =   [ s t r   n   ,   " f i z z " ,   " b u z z " ,   " f i z z b u z z " ]           p r i n t   n ,   l a b e l s [ p r e d i c t e d ] ,   l a b e l s [ a c t u a l ]               i f   p r e d i c t e d   = =   a c t u a l :                   n u m _ c o r r e c t   + =   1     p r i n t   n u m _ c o r r e c t ,   "   " ,   1 0 0    Chapter 19. Deep Learning  A little learning is a dangerous thing; Drink deep, or taste not the Pierian spring.  —Alexander Pope  Deep learning originally referred to the application of “deep” neural networks  that is, networks with more than one hidden layer , although in practice the term now encompasses a wide variety of neural architectures  including the “simple” neural networks we developed in Chapter 18 . In this chapter we’ll build on our previous work and look at a wider variety of neural networks. To do so, we’ll introduce a number of abstractions that allow us to think about neural networks in a more general way.  The Tensor Previously, we made a distinction between vectors  one-dimensional arrays  and matrices  two-dimensional arrays . When we start working with more complicated neural networks, we’ll need to use higher-dimensional arrays as well. In many neural network libraries, n-dimensional arrays are referred to as tensors, which is what we’ll call them too.  There are pedantic mathematical reasons not to refer to n-dimensional arrays as tensors; if you are such a pedant, your objection is noted.  If I were writing an entire book about deep learning, I’d implement a full- featured T could handle a variety of other operations. Such an implementation would take an entire chapter on its own. Here we’ll cheat and say that a T r is t. This is true in one direction—all of our vectors and matrices just a l and higher-dimensional analogues are lists. It is certainly not true in the  r class that overloaded Python’s arithmetic operators and  e n s o e n s o i s  other direction—most Python l sense.  ts are not n-dimensional arrays in our  Ideally you’d like to do something like:  NOTE  However, Python won’t let you define recursive types like that. And even if it did that definition is still not right, as it allows for bad “tensors” like:  whose rows have different sizes, which makes it not an n-dimensional array.  So, like I said, we’ll just cheat:  And we’ll write a helper function to find a tensor’s shape:  Because tensors can have any number of dimensions, we’ll typically need to work with them recursively. We’ll do one thing in the one-dimensional  i s    A   T e n s o r   i s   e i t h e r   a   f l o a t ,   o r   a   L i s t   o f   T e n s o r s   T e n s o r   =   U n i o n [ f l o a t ,   L i s t [ T e n s o r ] ] [ [ 1 . 0 ,   2 . 0 ] ,     [ 3 . 0 ] ] T e n s o r   =   l i s t f r o m   t y p i n g   i m p o r t   L i s t     d e f   s h a p e   t e n s o r :   T e n s o r     - >   L i s t [ i n t ] :           s i z e s :   L i s t [ i n t ]   =   [ ]           w h i l e   i s i n s t a n c e   t e n s o r ,   l i s t   :                   s i z e s . a p p e n d   l e n   t e n s o r                       t e n s o r   =   t e n s o r [ 0 ]           r e t u r n   s i z e s     a s s e r t   s h a p e   [ 1 ,   2 ,   3 ]     = =   [ 3 ]   a s s e r t   s h a p e   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ,   [ 5 ,   6 ] ]     = =   [ 3 ,   2 ]  case and recurse in the higher-dimensional case:  which we can use to write a recursive t  m function:  If you’re not used to thinking recursively, you should ponder this until it makes sense, because we’ll use the same logic throughout this chapter. However, we’ll create a couple of helper functions so that we don’t have to rewrite this logic everywhere. The first applies a function elementwise to a single tensor:  d e f   i s _ 1 d   t e n s o r :   T e n s o r     - >   b o o l :           " " "           I f   t e n s o r [ 0 ]   i s   a   l i s t ,   i t ' s   a   h i g h e r - o r d e r   t e n s o r .           O t h e r w i s e ,   t e n s o r   i s   1 - d i m e n s i o n a l     t h a t   i s ,   a   v e c t o r   .           " " "           r e t u r n   n o t   i s i n s t a n c e   t e n s o r [ 0 ] ,   l i s t       a s s e r t   i s _ 1 d   [ 1 ,   2 ,   3 ]     a s s e r t   n o t   i s _ 1 d   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ]   e n s o r _ s u d e f   t e n s o r _ s u m   t e n s o r :   T e n s o r     - >   f l o a t :           " " " S u m s   u p   a l l   t h e   v a l u e s   i n   t h e   t e n s o r " " "           i f   i s _ 1 d   t e n s o r   :                   r e t u r n   s u m   t e n s o r          j u s t   a   l i s t   o f   f l o a t s ,   u s e   P y t h o n   s u m           e l s e :                   r e t u r n   s u m   t e n s o r _ s u m   t e n s o r _ i                  C a l l   t e n s o r _ s u m   o n   e a c h   r o w                                         f o r   t e n s o r _ i   i n   t e n s o r            a n d   s u m   u p   t h o s e   r e s u l t s .     a s s e r t   t e n s o r _ s u m   [ 1 ,   2 ,   3 ]     = =   6   a s s e r t   t e n s o r _ s u m   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ]     = =   1 0 f r o m   t y p i n g   i m p o r t   C a l l a b l e     d e f   t e n s o r _ a p p l y   f :   C a l l a b l e [ [ f l o a t ] ,   f l o a t ] ,   t e n s o r :   T e n s o r     - >   T e n s o r :           " " " A p p l i e s   f   e l e m e n t w i s e " " "           i f   i s _ 1 d   t e n s o r   :                   r e t u r n   [ f   x     f o r   x   i n   t e n s o r ]           e l s e :                   r e t u r n   [ t e n s o r _ a p p l y   f ,   t e n s o r _ i     f o r   t e n s o r _ i   i n   t e n s o r ]     a s s e r t   t e n s o r _ a p p l y   l a m b d a   x :   x   +   1 ,   [ 1 ,   2 ,   3 ]     = =   [ 2 ,   3 ,   4 ]   a s s e r t   t e n s o r _ a p p l y   l a m b d a   x :   2   *   x ,   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ]     = =   [ [ 2 ,   4 ] ,   [ 6 ,   8 ] ]  We can use this to write a function that creates a zero tensor with the same shape as a given tensor:  We’ll also need to apply a function to corresponding elements from two tensors  which had better be the exact same shape, although we won’t check that :  The Layer Abstraction In the previous chapter we built a simple neural net that allowed us to stack two layers of neurons, each of which computed s   .  Although that’s perhaps an idealized representation of what an actual neuron does, in practice we’d like to allow a wider variety of things. Perhaps we’d like the neurons to remember something about their previous inputs. Perhaps we’d like to use a different activation function than  d. And frequently we’d like to use more than two layers.  Our  d e f   z e r o s _ l i k e   t e n s o r :   T e n s o r     - >   T e n s o r :           r e t u r n   t e n s o r _ a p p l y   l a m b d a   _ :   0 . 0 ,   t e n s o r       a s s e r t   z e r o s _ l i k e   [ 1 ,   2 ,   3 ]     = =   [ 0 ,   0 ,   0 ]   a s s e r t   z e r o s _ l i k e   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ]     = =   [ [ 0 ,   0 ] ,   [ 0 ,   0 ] ] d e f   t e n s o r _ c o m b i n e   f :   C a l l a b l e [ [ f l o a t ,   f l o a t ] ,   f l o a t ] ,                                         t 1 :   T e n s o r ,                                         t 2 :   T e n s o r     - >   T e n s o r :           " " " A p p l i e s   f   t o   c o r r e s p o n d i n g   e l e m e n t s   o f   t 1   a n d   t 2 " " "           i f   i s _ 1 d   t 1   :                   r e t u r n   [ f   x ,   y     f o r   x ,   y   i n   z i p   t 1 ,   t 2   ]           e l s e :                   r e t u r n   [ t e n s o r _ c o m b i n e   f ,   t 1 _ i ,   t 2 _ i                                     f o r   t 1 _ i ,   t 2 _ i   i n   z i p   t 1 ,   t 2   ]     i m p o r t   o p e r a t o r   a s s e r t   t e n s o r _ c o m b i n e   o p e r a t o r . a d d ,   [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ]     = =   [ 5 ,   7 ,   9 ]   a s s e r t   t e n s o r _ c o m b i n e   o p e r a t o r . m u l ,   [ 1 ,   2 ,   3 ] ,   [ 4 ,   5 ,   6 ]     = =   [ 4 ,   1 0 ,   1 8 ] i g m o i d   d o t   w e i g h t s , i n p u t s   s i g m o i  d function actually handled any number of layers, but our  gradient computations did not.  In this chapter we’ll build machinery for implementing such a variety of neural networks. Our fundamental abstraction will be the L r, something that knows how to apply some function to its inputs and that knows how to backpropagate gradients. One way of thinking about the neural networks we built in Chapter 18 is as a “linear” layer, followed by a “sigmoid” layer, then another linear layer and another sigmoid layer. We didn’t distinguish them in these terms, but doing so will allow us to experiment with much more general structures:  f e e d _ f o r w a r a y e f r o m   t y p i n g   i m p o r t   I t e r a b l e ,   T u p l e     c l a s s   L a y e r :           " " "           O u r   n e u r a l   n e t w o r k s   w i l l   b e   c o m p o s e d   o f   L a y e r s ,   e a c h   o f   w h i c h           k n o w s   h o w   t o   d o   s o m e   c o m p u t a t i o n   o n   i t s   i n p u t s   i n   t h e   " f o r w a r d "           d i r e c t i o n   a n d   p r o p a g a t e   g r a d i e n t s   i n   t h e   " b a c k w a r d "   d i r e c t i o n .           " " "           d e f   f o r w a r d   s e l f ,   i n p u t   :                   " " "                   N o t e   t h e   l a c k   o f   t y p e s .   W e ' r e   n o t   g o i n g   t o   b e   p r e s c r i p t i v e                   a b o u t   w h a t   k i n d s   o f   i n p u t s   l a y e r s   c a n   t a k e   a n d   w h a t   k i n d s                   o f   o u t p u t s   t h e y   c a n   r e t u r n .                   " " "                   r a i s e   N o t I m p l e m e n t e d E r r o r             d e f   b a c k w a r d   s e l f ,   g r a d i e n t   :                   " " "                   S i m i l a r l y ,   w e ' r e   n o t   g o i n g   t o   b e   p r e s c r i p t i v e   a b o u t   w h a t   t h e                   g r a d i e n t   l o o k s   l i k e .   I t ' s   u p   t o   y o u   t h e   u s e r   t o   m a k e   s u r e                   t h a t   y o u ' r e   d o i n g   t h i n g s   s e n s i b l y .                   " " "                   r a i s e   N o t I m p l e m e n t e d E r r o r             d e f   p a r a m s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   " " "                   R e t u r n s   t h e   p a r a m e t e r s   o f   t h i s   l a y e r .   T h e   d e f a u l t   i m p l e m e n t a t i o n                   r e t u r n s   n o t h i n g ,   s o   t h a t   i f   y o u   h a v e   a   l a y e r   w i t h   n o   p a r a m e t e r s                   y o u   d o n ' t   h a v e   t o   i m p l e m e n t   t h i s .                   " " "                   r e t u r n          d and b  d methods will have to be implemented in our  The f concrete subclasses. Once we build a neural net, we’ll want to train it using gradient descent, which means we’ll want to update each parameter in the network using its gradient. Accordingly, we insist that each layer be able to tell us its parameters and gradients. Some layers  for example, a layer that applies s have no parameters to update, so we provide a default implementation that handles that case. Let’s look at that layer:  d to each of its inputs   There are a couple of things to notice here. One is that during the forward pass we saved the computed sigmoids so that we could use them later in the backward pass. Our layers will typically need to do this sort of thing. Second, you may be wondering where the s comes from. This is just the chain rule from calculus and corresponds to the            d e f   g r a d s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   " " "                   R e t u r n s   t h e   g r a d i e n t s ,   i n   t h e   s a m e   o r d e r   a s   p a r a m s     .                   " " "                   r e t u r n       o r w a r a c k w a r i g m o i f r o m   s c r a t c h . n e u r a l _ n e t w o r k s   i m p o r t   s i g m o i d     c l a s s   S i g m o i d   L a y e r   :           d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                   " " "                   A p p l y   s i g m o i d   t o   e a c h   e l e m e n t   o f   t h e   i n p u t   t e n s o r ,                   a n d   s a v e   t h e   r e s u l t s   t o   u s e   i n   b a c k p r o p a g a t i o n .                   " " "                   s e l f . s i g m o i d s   =   t e n s o r _ a p p l y   s i g m o i d ,   i n p u t                     r e t u r n   s e l f . s i g m o i d s             d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   T e n s o r :                   r e t u r n   t e n s o r _ c o m b i n e   l a m b d a   s i g ,   g r a d :   s i g   *     1   -   s i g     *   g r a d ,                                                               s e l f . s i g m o i d s ,                                                               g r a d i e n t   i g   *     1   -   s i g     *   g r a d    term in our previous  neural networks. Finally, you can see how we were able to make use of the t and the t functions similarly.  e functions. Most of our layers will use these  The Linear Layer The other piece we’ll need to duplicate the neural networks from Chapter 18 is a “linear” layer that represents the d part of the neurons. This layer will have parameters, which we’d like to initialize with random values. It turns out that the initial parameter values can make a huge difference in how quickly  and sometimes whether  the network trains. If weights are too big, they may produce large outputs in a range where the activation function has near-zero gradients. And parts of the network that have zero gradients necessarily can’t learn anything via gradient descent. Accordingly, we’ll implement three different schemes for randomly generating our weight tensors. The first is to choose each value from the random uniform distribution on [0, 1]—that is, as a r second  and default  is to choose each value randomly from a standard normal distribution. And the third is to use Xavier initialization, where each weight is initialized with a random draw from a normal distribution with mean 0 and variance 2    n s . It turns out this often works nicely for neural network weights. We’ll implement these with a r  m function and a r  l function:   . The  s + n  o u t p u t   *     1   -   o u t p u t     *     o u t p u t   -   t a r g e t e n s o r _ a p p l y e n s o r _ c o m b i n o t   w e i g h t s ,   i n p u t s   a n d o m . r a n d o m   u m _ i n p u t u m _ o u t p u t a n d o m _ u n i f o r a n d o m _ n o r m a i m p o r t   r a n d o m     f r o m   s c r a t c h . p r o b a b i l i t y   i m p o r t   i n v e r s e _ n o r m a l _ c d f     d e f   r a n d o m _ u n i f o r m   * d i m s :   i n t     - >   T e n s o r :    And then wrap them all in a r  r function:  Now we can define our linear layer. We need to initialize it with the dimension of the inputs  which tells us how many weights each neuron needs , the dimension of the outputs  which tells us how many neurons we should have , and the initialization scheme we want:          i f   l e n   d i m s     = =   1 :                   r e t u r n   [ r a n d o m . r a n d o m       f o r   _   i n   r a n g e   d i m s [ 0 ]   ]           e l s e :                   r e t u r n   [ r a n d o m _ u n i f o r m   * d i m s [ 1 : ]     f o r   _   i n   r a n g e   d i m s [ 0 ]   ]     d e f   r a n d o m _ n o r m a l   * d i m s :   i n t ,                                       m e a n :   f l o a t   =   0 . 0 ,                                       v a r i a n c e :   f l o a t   =   1 . 0     - >   T e n s o r :           i f   l e n   d i m s     = =   1 :                   r e t u r n   [ m e a n   +   v a r i a n c e   *   i n v e r s e _ n o r m a l _ c d f   r a n d o m . r a n d o m                                         f o r   _   i n   r a n g e   d i m s [ 0 ]   ]           e l s e :                   r e t u r n   [ r a n d o m _ n o r m a l   * d i m s [ 1 : ] ,   m e a n = m e a n ,   v a r i a n c e = v a r i a n c e                                     f o r   _   i n   r a n g e   d i m s [ 0 ]   ]     a s s e r t   s h a p e   r a n d o m _ u n i f o r m   2 ,   3 ,   4       = =   [ 2 ,   3 ,   4 ]   a s s e r t   s h a p e   r a n d o m _ n o r m a l   5 ,   6 ,   m e a n = 1 0       = =   [ 5 ,   6 ] a n d o m _ t e n s o d e f   r a n d o m _ t e n s o r   * d i m s :   i n t ,   i n i t :   s t r   =   ' n o r m a l '     - >   T e n s o r :           i f   i n i t   = =   ' n o r m a l ' :                   r e t u r n   r a n d o m _ n o r m a l   * d i m s             e l i f   i n i t   = =   ' u n i f o r m ' :                   r e t u r n   r a n d o m _ u n i f o r m   * d i m s             e l i f   i n i t   = =   ' x a v i e r ' :                   v a r i a n c e   =   l e n   d i m s         s u m   d i m s                     r e t u r n   r a n d o m _ n o r m a l   * d i m s ,   v a r i a n c e = v a r i a n c e             e l s e :                   r a i s e   V a l u e E r r o r   f " u n k n o w n   i n i t :   { i n i t } "   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t     c l a s s   L i n e a r   L a y e r   :           d e f   _ _ i n i t _ _   s e l f ,                                     i n p u t _ d i m :   i n t ,                                     o u t p u t _ d i m :   i n t ,                                     i n i t :   s t r   =   ' x a v i e r '     - >   N o n e :                   " " "    NOTE  In case you’re wondering how important the initialization schemes are, some of the networks in this chapter I couldn’t get to train at all with different initializations than the ones I used.  d method is easy to implement. We’ll get one output per neuron,  The f which we stick in a vector. And each neuron’s output is just the d weights with the input, plus its bias:  t of its  The b difficult:  d method is more involved, but if you know calculus it’s not                  A   l a y e r   o f   o u t p u t _ d i m   n e u r o n s ,   e a c h   w i t h   i n p u t _ d i m   w e i g h t s                     a n d   a   b i a s   .                   " " "                   s e l f . i n p u t _ d i m   =   i n p u t _ d i m                   s e l f . o u t p u t _ d i m   =   o u t p u t _ d i m                        s e l f . w [ o ]   i s   t h e   w e i g h t s   f o r   t h e   o t h   n e u r o n                   s e l f . w   =   r a n d o m _ t e n s o r   o u t p u t _ d i m ,   i n p u t _ d i m ,   i n i t = i n i t                          s e l f . b [ o ]   i s   t h e   b i a s   t e r m   f o r   t h e   o t h   n e u r o n                   s e l f . b   =   r a n d o m _ t e n s o r   o u t p u t _ d i m ,   i n i t = i n i t   o r w a r o         d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                      S a v e   t h e   i n p u t   t o   u s e   i n   t h e   b a c k w a r d   p a s s .                   s e l f . i n p u t   =   i n p u t                        R e t u r n   t h e   v e c t o r   o f   n e u r o n   o u t p u t s .                   r e t u r n   [ d o t   i n p u t ,   s e l f . w [ o ]     +   s e l f . b [ o ]                                   f o r   o   i n   r a n g e   s e l f . o u t p u t _ d i m   ] a c k w a r         d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   T e n s o r :                      E a c h   b [ o ]   g e t s   a d d e d   t o   o u t p u t [ o ] ,   w h i c h   m e a n s                      t h e   g r a d i e n t   o f   b   i s   t h e   s a m e   a s   t h e   o u t p u t   g r a d i e n t .                   s e l f . b _ g r a d   =   g r a d i e n t                        E a c h   w [ o ] [ i ]   m u l t i p l i e s   i n p u t [ i ]   a n d   g e t s   a d d e d   t o   o u t p u t [ o ] .                      S o   i t s   g r a d i e n t   i s   i n p u t [ i ]   *   g r a d i e n t [ o ] .                   s e l f . w _ g r a d   =   [ [ s e l f . i n p u t [ i ]   *   g r a d i e n t [ o ]    NOTE  In a “real” tensor library, these  and many other  operations would be represented as matrix or tensor multiplications, which those libraries are designed to do very quickly. Our library is very slow.  Finally, here we do need to implement p parameters and two corresponding gradients:  s and g  s. We have two  Neural Networks as a Sequence of Layers We’d like to think of neural networks as sequences of layers, so let’s come up with a way to combine multiple layers into one. The resulting neural network is itself a layer, and it implements the L obvious ways:  r methods in the                                                  f o r   i   i n   r a n g e   s e l f . i n p u t _ d i m   ]                                                 f o r   o   i n   r a n g e   s e l f . o u t p u t _ d i m   ]                        E a c h   i n p u t [ i ]   m u l t i p l i e s   e v e r y   w [ o ] [ i ]   a n d   g e t s   a d d e d   t o   e v e r y                      o u t p u t [ o ] .   S o   i t s   g r a d i e n t   i s   t h e   s u m   o f   w [ o ] [ i ]   *   g r a d i e n t [ o ]                      a c r o s s   a l l   t h e   o u t p u t s .                   r e t u r n   [ s u m   s e l f . w [ o ] [ i ]   *   g r a d i e n t [ o ]   f o r   o   i n   r a n g e   s e l f . o u t p u t _ d i m                                       f o r   i   i n   r a n g e   s e l f . i n p u t _ d i m   ] a r a m r a d         d e f   p a r a m s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . w ,   s e l f . b ]             d e f   g r a d s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . w _ g r a d ,   s e l f . b _ g r a d ] a y e f r o m   t y p i n g   i m p o r t   L i s t     c l a s s   S e q u e n t i a l   L a y e r   :           " " "           A   l a y e r   c o n s i s t i n g   o f   a   s e q u e n c e   o f   o t h e r   l a y e r s .           I t ' s   u p   t o   y o u   t o   m a k e   s u r e   t h a t   t h e   o u t p u t   o f   e a c h   l a y e r           m a k e s   s e n s e   a s   t h e   i n p u t   t o   t h e   n e x t   l a y e r .    So we could represent the neural network we used for XOR as:  But we still need a little more machinery to train it.  Loss and Optimization Previously we wrote out individual loss functions and gradient functions for our models. Here we’ll want to experiment with different loss functions, so  as usual  we’ll introduce a new L s abstraction that encapsulates both the loss computation and the gradient computation:          " " "           d e f   _ _ i n i t _ _   s e l f ,   l a y e r s :   L i s t [ L a y e r ]     - >   N o n e :                   s e l f . l a y e r s   =   l a y e r s             d e f   f o r w a r d   s e l f ,   i n p u t   :                   " " " J u s t   f o r w a r d   t h e   i n p u t   t h r o u g h   t h e   l a y e r s   i n   o r d e r . " " "                   f o r   l a y e r   i n   s e l f . l a y e r s :                           i n p u t   =   l a y e r . f o r w a r d   i n p u t                     r e t u r n   i n p u t             d e f   b a c k w a r d   s e l f ,   g r a d i e n t   :                   " " " J u s t   b a c k p r o p a g a t e   t h e   g r a d i e n t   t h r o u g h   t h e   l a y e r s   i n   r e v e r s e . " " "                   f o r   l a y e r   i n   r e v e r s e d   s e l f . l a y e r s   :                           g r a d i e n t   =   l a y e r . b a c k w a r d   g r a d i e n t                     r e t u r n   g r a d i e n t             d e f   p a r a m s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   " " " J u s t   r e t u r n   t h e   p a r a m s   f r o m   e a c h   l a y e r . " " "                   r e t u r n     p a r a m   f o r   l a y e r   i n   s e l f . l a y e r s   f o r   p a r a m   i n   l a y e r . p a r a m s                   d e f   g r a d s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   " " " J u s t   r e t u r n   t h e   g r a d s   f r o m   e a c h   l a y e r . " " "                   r e t u r n     g r a d   f o r   l a y e r   i n   s e l f . l a y e r s   f o r   g r a d   i n   l a y e r . g r a d s       x o r _ n e t   =   S e q u e n t i a l   [           L i n e a r   i n p u t _ d i m = 2 ,   o u t p u t _ d i m = 2   ,           S i g m o i d     ,           L i n e a r   i n p u t _ d i m = 2 ,   o u t p u t _ d i m = 1   ,           S i g m o i d       ]   o s  We’ve already worked many times with the loss that’s the sum of the squared errors, so we should have an easy time implementing that. The only trick is that we’ll need to use t  e:   We’ll look at a different loss function in a bit.  The last piece to figure out is gradient descent. Throughout the book we’ve done all of our gradient descent manually by having a training loop that involves something like:  Here that won’t quite work for us, for a couple reasons. The first is that our neural nets will have many parameters, and we’ll need to update all of  c l a s s   L o s s :           d e f   l o s s   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   f l o a t :                   " " " H o w   g o o d   a r e   o u r   p r e d i c t i o n s ?     L a r g e r   n u m b e r s   a r e   w o r s e .   " " "                   r a i s e   N o t I m p l e m e n t e d E r r o r             d e f   g r a d i e n t   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   T e n s o r :                   " " " H o w   d o e s   t h e   l o s s   c h a n g e   a s   t h e   p r e d i c t i o n s   c h a n g e ? " " "                   r a i s e   N o t I m p l e m e n t e d E r r o r e n s o r _ c o m b i n c l a s s   S S E   L o s s   :           " " " L o s s   f u n c t i o n   t h a t   c o m p u t e s   t h e   s u m   o f   t h e   s q u a r e d   e r r o r s . " " "           d e f   l o s s   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   f l o a t :                      C o m p u t e   t h e   t e n s o r   o f   s q u a r e d   d i f f e r e n c e s                   s q u a r e d _ e r r o r s   =   t e n s o r _ c o m b i n e                             l a m b d a   p r e d i c t e d ,   a c t u a l :     p r e d i c t e d   -   a c t u a l     * *   2 ,                           p r e d i c t e d ,                           a c t u a l                          A n d   j u s t   a d d   t h e m   u p                   r e t u r n   t e n s o r _ s u m   s q u a r e d _ e r r o r s               d e f   g r a d i e n t   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   T e n s o r :                   r e t u r n   t e n s o r _ c o m b i n e                             l a m b d a   p r e d i c t e d ,   a c t u a l :   2   *     p r e d i c t e d   -   a c t u a l   ,                           p r e d i c t e d ,                           a c t u a l   t h e t a   =   g r a d i e n t _ s t e p   t h e t a ,   g r a d ,   - l e a r n i n g _ r a t e    them. The second is that we’d like to be able to use more clever variants of gradient descent, and we don’t want to have to rewrite them each time. Accordingly, we’ll introduce a  you guessed it  O which gradient descent will be a specific instance:  r abstraction, of  After that it’s easy to implement gradient descent, again using  e:  The only thing that’s maybe surprising is the “slice assignment,” which is a reflection of the fact that reassigning a list doesn’t change its original value. That is, if you just did p redefining the local variable p m, but you would not be affecting the original parameter tensor stored in the layer. If you assign to the slice [ however, it actually changes the values inside the list. Here’s a simple example to demonstrate:   , you would be  ],  p t i m i z e c l a s s   O p t i m i z e r :           " " "           A n   o p t i m i z e r   u p d a t e s   t h e   w e i g h t s   o f   a   l a y e r     i n   p l a c e     u s i n g   i n f o r m a t i o n           k n o w n   b y   e i t h e r   t h e   l a y e r   o r   t h e   o p t i m i z e r     o r   b y   b o t h   .           " " "           d e f   s t e p   s e l f ,   l a y e r :   L a y e r     - >   N o n e :                   r a i s e   N o t I m p l e m e n t e d E r r o r t e n s o r _ c o m b i n c l a s s   G r a d i e n t D e s c e n t   O p t i m i z e r   :           d e f   _ _ i n i t _ _   s e l f ,   l e a r n i n g _ r a t e :   f l o a t   =   0 . 1     - >   N o n e :                   s e l f . l r   =   l e a r n i n g _ r a t e             d e f   s t e p   s e l f ,   l a y e r :   L a y e r     - >   N o n e :                   f o r   p a r a m ,   g r a d   i n   z i p   l a y e r . p a r a m s     ,   l a y e r . g r a d s       :                              U p d a t e   p a r a m   u s i n g   a   g r a d i e n t   s t e p                           p a r a m [ : ]   =   t e n s o r _ c o m b i n e                                     l a m b d a   p a r a m ,   g r a d :   p a r a m   -   g r a d   *   s e l f . l r ,                                   p a r a m ,                                   g r a d   a r a m   =   t e n s o r _ c o m b i n e   .   .   . a r a : t e n s o r   =   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ]     f o r   r o w   i n   t e n s o r :    If you are somewhat inexperienced in Python, this behavior may be surprising, so meditate on it and try examples yourself until it makes sense. To demonstrate the value of this abstraction, let’s implement another optimizer that uses momentum. The idea is that we don’t want to overreact to each new gradient, and so we maintain a running average of the gradients we’ve seen, updating it with each new gradient and taking a step in the direction of the average:          r o w   =   [ 0 ,   0 ]   a s s e r t   t e n s o r   = =   [ [ 1 ,   2 ] ,   [ 3 ,   4 ] ] ,   " a s s i g n m e n t   d o e s n ' t   u p d a t e   a   l i s t "     f o r   r o w   i n   t e n s o r :           r o w [ : ]   =   [ 0 ,   0 ]   a s s e r t   t e n s o r   = =   [ [ 0 ,   0 ] ,   [ 0 ,   0 ] ] ,   " b u t   s l i c e   a s s i g n m e n t   d o e s " c l a s s   M o m e n t u m   O p t i m i z e r   :           d e f   _ _ i n i t _ _   s e l f ,                                     l e a r n i n g _ r a t e :   f l o a t ,                                     m o m e n t u m :   f l o a t   =   0 . 9     - >   N o n e :                   s e l f . l r   =   l e a r n i n g _ r a t e                   s e l f . m o   =   m o m e n t u m                   s e l f . u p d a t e s :   L i s t [ T e n s o r ]   =   [ ]        r u n n i n g   a v e r a g e             d e f   s t e p   s e l f ,   l a y e r :   L a y e r     - >   N o n e :                      I f   w e   h a v e   n o   p r e v i o u s   u p d a t e s ,   s t a r t   w i t h   a l l   z e r o s                   i f   n o t   s e l f . u p d a t e s :                           s e l f . u p d a t e s   =   [ z e r o s _ l i k e   g r a d     f o r   g r a d   i n   l a y e r . g r a d s     ]                     f o r   u p d a t e ,   p a r a m ,   g r a d   i n   z i p   s e l f . u p d a t e s ,                                                                                 l a y e r . p a r a m s     ,                                                                                 l a y e r . g r a d s       :                              A p p l y   m o m e n t u m                           u p d a t e [ : ]   =   t e n s o r _ c o m b i n e                                     l a m b d a   u ,   g :   s e l f . m o   *   u   +     1   -   s e l f . m o     *   g ,                                   u p d a t e ,                                   g r a d                                  T h e n   t a k e   a   g r a d i e n t   s t e p                           p a r a m [ : ]   =   t e n s o r _ c o m b i n e                                     l a m b d a   p ,   u :   p   -   s e l f . l r   *   u ,                                   p a r a m ,                                   u p d a t e    Because we used an O our different optimizers.  r abstraction, we can easily switch between  Example: XOR Revisited Let’s see how easy it is to use our new framework to train a network that can compute XOR. We start by re-creating the training data:  and then we define the network, although now we can leave off the last sigmoid layer:  We can now write a simple training loop, except that now we can use the abstractions of O s. This allows us to easily try different ones:  r and L  p t i m i z e    t r a i n i n g   d a t a   x s   =   [ [ 0 . ,   0 ] ,   [ 0 . ,   1 ] ,   [ 1 . ,   0 ] ,   [ 1 . ,   1 ] ]   y s   =   [ [ 0 . ] ,   [ 1 . ] ,   [ 1 . ] ,   [ 0 . ] ] r a n d o m . s e e d   0       n e t   =   S e q u e n t i a l   [           L i n e a r   i n p u t _ d i m = 2 ,   o u t p u t _ d i m = 2   ,           S i g m o i d     ,           L i n e a r   i n p u t _ d i m = 2 ,   o u t p u t _ d i m = 1     ]   p t i m i z e o s i m p o r t   t q d m     o p t i m i z e r   =   G r a d i e n t D e s c e n t   l e a r n i n g _ r a t e = 0 . 1     l o s s   =   S S E         w i t h   t q d m . t r a n g e   3 0 0 0     a s   t :           f o r   e p o c h   i n   t :                   e p o c h _ l o s s   =   0 . 0                     f o r   x ,   y   i n   z i p   x s ,   y s   :                           p r e d i c t e d   =   n e t . f o r w a r d   x                             e p o c h _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   y                             g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   y      This should train quickly, and you should see the loss go down. And now we can inspect the weights:  For my network I find roughly:  1 activates if neither input is 1. h  2 activates if both inputs So h are 1. And o t activates if neither hidden output is 1—that is, if it’s not the case that neither input is 1 and it’s also not the case that both inputs are 1. Indeed, this is exactly the logic of XOR. Notice that this network learned different features than the one we trained in Chapter 18, but it still manages to do the same thing.  Other Activation Functions d function has fallen out of favor for a couple of reasons. One The s   equals 1 2, which means that a neuron whose reason is that s inputs sum to 0 has a positive output. Another is that its gradient is very close to 0 for very large and very small inputs, which means that its gradients can get “saturated” and its weights can get stuck. One popular replacement is t different sigmoid-shaped function that ranges from –1 to 1 and outputs 0 if  h  “hyperbolic tangent” , which is a                          n e t . b a c k w a r d   g r a d i e n t                               o p t i m i z e r . s t e p   n e t                       t . s e t _ d e s c r i p t i o n   f " x o r   l o s s   { e p o c h _ l o s s : . 3 f } "   f o r   p a r a m   i n   n e t . p a r a m s     :           p r i n t   p a r a m   h i d d e n 1   =   - 2 . 6   *   x 1   +   - 2 . 7   *   x 2   +   0 . 2        N O R   h i d d e n 2   =     2 . 1   *   x 1   +     2 . 1   *   x 2   -   3 . 4        A N D   o u t p u t   =     - 3 . 1   *   h 1   +   - 2 . 6   *   h 2   +   1 . 8        N O R i d d e n i d d e n u t p u i g m o i i g m o i d   0 a n  its input is 0. The derivative of t makes the layer easy to write:    is just 1  2, which  In larger networks another popular replacement is R negative inputs and the identity for positive inputs:  u, which is 0 for  There are many others. I encourage you to play around with them in your networks.  a n h   x   -   t a n h   x     * *   i m p o r t   m a t h     d e f   t a n h   x :   f l o a t     - >   f l o a t :              I f   x   i s   v e r y   l a r g e   o r   v e r y   s m a l l ,   t a n h   i s     e s s e n t i a l l y     1   o r   - 1 .              W e   c h e c k   f o r   t h i s   b e c a u s e ,   e . g . ,   m a t h . e x p   1 0 0 0     r a i s e s   a n   e r r o r .           i f   x   <   - 1 0 0 :     r e t u r n   - 1           e l i f   x   >   1 0 0 :   r e t u r n   1             e m 2 x   =   m a t h . e x p   - 2   *   x             r e t u r n     1   -   e m 2 x           1   +   e m 2 x       c l a s s   T a n h   L a y e r   :           d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                      S a v e   t a n h   o u t p u t   t o   u s e   i n   b a c k w a r d   p a s s .                   s e l f . t a n h   =   t e n s o r _ a p p l y   t a n h ,   i n p u t                     r e t u r n   s e l f . t a n h             d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   T e n s o r :                   r e t u r n   t e n s o r _ c o m b i n e                             l a m b d a   t a n h ,   g r a d :     1   -   t a n h   * *   2     *   g r a d ,                           s e l f . t a n h ,                           g r a d i e n t   e l c l a s s   R e l u   L a y e r   :           d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                   s e l f . i n p u t   =   i n p u t                   r e t u r n   t e n s o r _ a p p l y   l a m b d a   x :   m a x   x ,   0   ,   i n p u t               d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   T e n s o r :                   r e t u r n   t e n s o r _ c o m b i n e   l a m b d a   x ,   g r a d :   g r a d   i f   x   >   0   e l s e   0 ,                                                               s e l f . i n p u t ,                                                               g r a d i e n t    Example: FizzBuzz Revisited We can now use our “deep learning” framework to reproduce our solution from “Example: Fizz Buzz”. Let’s set up the data:  and create the network:  As we’re training, let’s also track our accuracy on the training set:  f r o m   s c r a t c h . n e u r a l _ n e t w o r k s   i m p o r t   b i n a r y _ e n c o d e ,   f i z z _ b u z z _ e n c o d e ,   a r g m a x     x s   =   [ b i n a r y _ e n c o d e   n     f o r   n   i n   r a n g e   1 0 1 ,   1 0 2 4   ]   y s   =   [ f i z z _ b u z z _ e n c o d e   n     f o r   n   i n   r a n g e   1 0 1 ,   1 0 2 4   ] N U M _ H I D D E N   =   2 5     r a n d o m . s e e d   0       n e t   =   S e q u e n t i a l   [           L i n e a r   i n p u t _ d i m = 1 0 ,   o u t p u t _ d i m = N U M _ H I D D E N ,   i n i t = ' u n i f o r m '   ,           T a n h     ,           L i n e a r   i n p u t _ d i m = N U M _ H I D D E N ,   o u t p u t _ d i m = 4 ,   i n i t = ' u n i f o r m '   ,           S i g m o i d       ]   d e f   f i z z b u z z _ a c c u r a c y   l o w :   i n t ,   h i :   i n t ,   n e t :   L a y e r     - >   f l o a t :           n u m _ c o r r e c t   =   0           f o r   n   i n   r a n g e   l o w ,   h i   :                   x   =   b i n a r y _ e n c o d e   n                     p r e d i c t e d   =   a r g m a x   n e t . f o r w a r d   x                       a c t u a l   =   a r g m a x   f i z z _ b u z z _ e n c o d e   n                       i f   p r e d i c t e d   = =   a c t u a l :                           n u m _ c o r r e c t   + =   1             r e t u r n   n u m _ c o r r e c t         h i   -   l o w   o p t i m i z e r   =   M o m e n t u m   l e a r n i n g _ r a t e = 0 . 1 ,   m o m e n t u m = 0 . 9     l o s s   =   S S E         w i t h   t q d m . t r a n g e   1 0 0 0     a s   t :           f o r   e p o c h   i n   t :                   e p o c h _ l o s s   =   0 . 0      After 1,000 training iterations, the model gets 90% accuracy on the test set; if you keep training it longer, it should do even better.  I don’t think it’s possible to train to 100% accuracy with only 25 hidden units, but it’s definitely possible if you go up to 50 hidden units.   Softmaxes and Cross-Entropy The neural net we used in the previous section ended in a S d layer, which means that its output was a vector of numbers between 0 and 1. In particular, it could output a vector that was entirely 0s, or it could output a vector that was entirely 1s. Yet when we’re doing classification problems, we’d like to output a 1 for the correct class and a 0 for all the incorrect classes. Generally our predictions will not be so perfect, but we’d at least like to predict an actual probability distribution over the classes. For example, if we have two classes, and our model outputs [ hard to make much sense of that. It doesn’t think the output belongs in either class? But if our model outputs [ that there’s a probability of 0.4 that our input belongs to the first class and 0.6 that our input belongs to the second class. In order to accomplish this, we typically forgo the final S instead use the s  d layer and x function, which converts a vector of real numbers  ], we can interpret it as a prediction  ], it’s                  f o r   x ,   y   i n   z i p   x s ,   y s   :                           p r e d i c t e d   =   n e t . f o r w a r d   x                             e p o c h _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   y                             g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   y                             n e t . b a c k w a r d   g r a d i e n t                               o p t i m i z e r . s t e p   n e t                       a c c u r a c y   =   f i z z b u z z _ a c c u r a c y   1 0 1 ,   1 0 2 4 ,   n e t                     t . s e t _ d e s c r i p t i o n   f " f b   l o s s :   { e p o c h _ l o s s : . 2 f }   a c c :   { a c c u r a c y : . 2 f } "          N o w   c h e c k   r e s u l t s   o n   t h e   t e s t   s e t   p r i n t   " t e s t   r e s u l t s " ,   f i z z b u z z _ a c c u r a c y   1 ,   1 0 1 ,   n e t     i g m o i 0 ,   0 0 . 4 ,   0 . 6 i g m o i o f t m a  to a vector of probabilities. We compute e   for each number in the vector, which results in a vector of positive numbers. After that, we just divide each of those positive numbers by the sum, which gives us a bunch of positive numbers that add up to 1—that is, a vector of probabilities.   we will get a Python If we ever end up trying to compute, say, e error, so before taking the e p we subtract off the largest value. This turns out to result in the same probabilities; it’s just safer to compute in Python:  Once our network produces probabilities, we often use a different loss function called cross-entropy  or sometimes “negative log likelihood” . You may recall that in “Maximum Likelihood Estimation”, we justified the use of least squares in linear regression by appealing to the fact that  under certain assumptions  the least squares coefficients maximized the likelihood of the observed data. Here we can do something similar: if our network outputs are probabilities, the cross-entropy loss represents the negative log likelihood of the observed data, which means that minimizing that loss is the same as maximizing the log likelihood  and hence the likelihood  of the training data. Typically we won’t include the s network itself. This is because it turns out that if s loss function but not part of the network itself, the gradients of the loss with respect to the network outputs are very easy to compute.  x function as part of the neural  x is part of your  x p   x x p   1 0 0 0 x d e f   s o f t m a x   t e n s o r :   T e n s o r     - >   T e n s o r :           " " " S o f t m a x   a l o n g   t h e   l a s t   d i m e n s i o n " " "           i f   i s _ 1 d   t e n s o r   :                      S u b t r a c t   l a r g e s t   v a l u e   f o r   n u m e r i c a l   s t a b i l i t y .                   l a r g e s t   =   m a x   t e n s o r                     e x p s   =   [ m a t h . e x p   x   -   l a r g e s t     f o r   x   i n   t e n s o r ]                     s u m _ o f _ e x p s   =   s u m   e x p s                                        T h i s   i s   t h e   t o t a l   " w e i g h t . "                   r e t u r n   [ e x p _ i       s u m _ o f _ e x p s                              P r o b a b i l i t y   i s   t h e   f r a c t i o n                                   f o r   e x p _ i   i n   e x p s ]                                o f   t h e   t o t a l   w e i g h t .           e l s e :                   r e t u r n   [ s o f t m a x   t e n s o r _ i     f o r   t e n s o r _ i   i n   t e n s o r ] o f t m a o f t m a  If I now train the same Fizz Buzz network using S loss, I find that it typically trains much faster  that is, in many fewer epochs . Presumably this is because it is much easier to find weights that d to a  x to a given distribution than it is to find weights that s  given distribution. That is, if I need to predict class 0  a vector with a 1 in the first position and 0s in the remaining positions , in the l d case I need the first output to be a large positive number and the remaining outputs to be large negative numbers. In the s to be larger than the remaining outputs. Clearly there are a lot more ways for the second case to happen, which suggests that it should be easier to find weights that make it so:  x case, however, I just need the first output  r + s  c l a s s   S o f t m a x C r o s s E n t r o p y   L o s s   :           " " "           T h i s   i s   t h e   n e g a t i v e - l o g - l i k e l i h o o d   o f   t h e   o b s e r v e d   v a l u e s ,   g i v e n   t h e           n e u r a l   n e t   m o d e l .   S o   i f   w e   c h o o s e   w e i g h t s   t o   m i n i m i z e   i t ,   o u r   m o d e l   w i l l           b e   m a x i m i z i n g   t h e   l i k e l i h o o d   o f   t h e   o b s e r v e d   d a t a .           " " "           d e f   l o s s   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   f l o a t :                      A p p l y   s o f t m a x   t o   g e t   p r o b a b i l i t i e s                   p r o b a b i l i t i e s   =   s o f t m a x   p r e d i c t e d                          T h i s   w i l l   b e   l o g   p _ i   f o r   t h e   a c t u a l   c l a s s   i   a n d   0   f o r   t h e   o t h e r                      c l a s s e s .   W e   a d d   a   t i n y   a m o u n t   t o   p   t o   a v o i d   t a k i n g   l o g   0   .                   l i k e l i h o o d s   =   t e n s o r _ c o m b i n e   l a m b d a   p ,   a c t :   m a t h . l o g   p   +   1 e - 3 0     *   a c t ,                                                                             p r o b a b i l i t i e s ,                                                                             a c t u a l                          A n d   t h e n   w e   j u s t   s u m   u p   t h e   n e g a t i v e s .                   r e t u r n   - t e n s o r _ s u m   l i k e l i h o o d s               d e f   g r a d i e n t   s e l f ,   p r e d i c t e d :   T e n s o r ,   a c t u a l :   T e n s o r     - >   T e n s o r :                   p r o b a b i l i t i e s   =   s o f t m a x   p r e d i c t e d                          I s n ' t   t h i s   a   p l e a s a n t   e q u a t i o n ?                   r e t u r n   t e n s o r _ c o m b i n e   l a m b d a   p ,   a c t u a l :   p   -   a c t u a l ,                                                               p r o b a b i l i t i e s ,                                                               a c t u a l   o f t m a x C r o s s E n t r o p y s o f t m a i g m o i i n e a i g m o i o f t m a  Dropout Like most machine learning models, neural networks are prone to overfitting to their training data. We’ve previously seen ways to ameliorate this; for example, in “Regularization” we penalized large weights and that helped prevent overfitting. A common way of regularizing neural networks is using dropout. At training time, we randomly turn off each neuron  that is, replace its output with 0  with some fixed probability. This means that the network can’t learn to depend on any individual neuron, which seems to help with overfitting.  r a n d o m . s e e d   0       n e t   =   S e q u e n t i a l   [           L i n e a r   i n p u t _ d i m = 1 0 ,   o u t p u t _ d i m = N U M _ H I D D E N ,   i n i t = ' u n i f o r m '   ,           T a n h     ,           L i n e a r   i n p u t _ d i m = N U M _ H I D D E N ,   o u t p u t _ d i m = 4 ,   i n i t = ' u n i f o r m '                N o   f i n a l   s i g m o i d   l a y e r   n o w   ]       o p t i m i z e r   =   M o m e n t u m   l e a r n i n g _ r a t e = 0 . 1 ,   m o m e n t u m = 0 . 9     l o s s   =   S o f t m a x C r o s s E n t r o p y         w i t h   t q d m . t r a n g e   1 0 0     a s   t :           f o r   e p o c h   i n   t :                   e p o c h _ l o s s   =   0 . 0                     f o r   x ,   y   i n   z i p   x s ,   y s   :                           p r e d i c t e d   =   n e t . f o r w a r d   x                             e p o c h _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   y                             g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   y                             n e t . b a c k w a r d   g r a d i e n t                               o p t i m i z e r . s t e p   n e t                       a c c u r a c y   =   f i z z b u z z _ a c c u r a c y   1 0 1 ,   1 0 2 4 ,   n e t                     t . s e t _ d e s c r i p t i o n   f " f b   l o s s :   { e p o c h _ l o s s : . 3 f }   a c c :   { a c c u r a c y : . 2 f } "          A g a i n   c h e c k   r e s u l t s   o n   t h e   t e s t   s e t   p r i n t   " t e s t   r e s u l t s " ,   f i z z b u z z _ a c c u r a c y   1 ,   1 0 1 ,   n e t      At evaluation time, we don’t want to dropout any neurons, so a D layer will need to know whether it’s training or not. In addition, at training time a D t layer only passes on some random fraction of its input. To make its output comparable during evaluation, we’ll scale down the outputs  uniformly  using that same fraction:  We’ll use this to help prevent our deep learning models from overfitting.    Example: MNIST MNIST is a dataset of handwritten digits that everyone uses to learn deep learning.  r o p o u t r o p o u c l a s s   D r o p o u t   L a y e r   :           d e f   _ _ i n i t _ _   s e l f ,   p :   f l o a t     - >   N o n e :                   s e l f . p   =   p                   s e l f . t r a i n   =   T r u e             d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                   i f   s e l f . t r a i n :                              C r e a t e   a   m a s k   o f   0 s   a n d   1 s   s h a p e d   l i k e   t h e   i n p u t                              u s i n g   t h e   s p e c i f i e d   p r o b a b i l i t y .                           s e l f . m a s k   =   t e n s o r _ a p p l y                                     l a m b d a   _ :   0   i f   r a n d o m . r a n d o m       <   s e l f . p   e l s e   1 ,                                   i n p u t                                M u l t i p l y   b y   t h e   m a s k   t o   d r o p o u t   i n p u t s .                           r e t u r n   t e n s o r _ c o m b i n e   o p e r a t o r . m u l ,   i n p u t ,   s e l f . m a s k                     e l s e :                              D u r i n g   e v a l u a t i o n   j u s t   s c a l e   d o w n   t h e   o u t p u t s   u n i f o r m l y .                           r e t u r n   t e n s o r _ a p p l y   l a m b d a   x :   x   *     1   -   s e l f . p   ,   i n p u t               d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   T e n s o r :                   i f   s e l f . t r a i n :                              O n l y   p r o p a g a t e   t h e   g r a d i e n t s   w h e r e   m a s k   = =   1 .                           r e t u r n   t e n s o r _ c o m b i n e   o p e r a t o r . m u l ,   g r a d i e n t ,   s e l f . m a s k                     e l s e :                           r a i s e   R u n t i m e E r r o r   " d o n ' t   c a l l   b a c k w a r d   w h e n   n o t   i n   t r a i n   m o d e "    It is available in a somewhat tricky binary format, so we’ll install the m library to work with it.  Yes, this part is technically not “from scratch.”   And then we can load the data:  Let’s plot the first 100 training images to see what they look like  Figure 19-1 :  n i s t p y t h o n   - m   p i p   i n s t a l l   m n i s t i m p o r t   m n i s t        T h i s   w i l l   d o w n l o a d   t h e   d a t a ;   c h a n g e   t h i s   t o   w h e r e   y o u   w a n t   i t .        Y e s ,   i t ' s   a   0 - a r g u m e n t   f u n c t i o n ,   t h a t ' s   w h a t   t h e   l i b r a r y   e x p e c t s .          Y e s ,   I ' m   a s s i g n i n g   a   l a m b d a   t o   a   v a r i a b l e ,   l i k e   I   s a i d   n e v e r   t o   d o .     m n i s t . t e m p o r a r y _ d i r   =   l a m b d a :   '   t m p '        E a c h   o f   t h e s e   f u n c t i o n s   f i r s t   d o w n l o a d s   t h e   d a t a   a n d   r e t u r n s   a   n u m p y   a r r a y .      W e   c a l l   . t o l i s t       b e c a u s e   o u r   " t e n s o r s "   a r e   j u s t   l i s t s .   t r a i n _ i m a g e s   =   m n i s t . t r a i n _ i m a g e s     . t o l i s t       t r a i n _ l a b e l s   =   m n i s t . t r a i n _ l a b e l s     . t o l i s t         a s s e r t   s h a p e   t r a i n _ i m a g e s     = =   [ 6 0 0 0 0 ,   2 8 ,   2 8 ]   a s s e r t   s h a p e   t r a i n _ l a b e l s     = =   [ 6 0 0 0 0 ] i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t     f i g ,   a x   =   p l t . s u b p l o t s   1 0 ,   1 0       f o r   i   i n   r a n g e   1 0   :           f o r   j   i n   r a n g e   1 0   :                      P l o t   e a c h   i m a g e   i n   b l a c k   a n d   w h i t e   a n d   h i d e   t h e   a x e s .                   a x [ i ] [ j ] . i m s h o w   t r a i n _ i m a g e s [ 1 0   *   i   +   j ] ,   c m a p = ' G r e y s '                     a x [ i ] [ j ] . x a x i s . s e t _ v i s i b l e   F a l s e                     a x [ i ] [ j ] . y a x i s . s e t _ v i s i b l e   F a l s e       p l t . s h o w      You can see that indeed they look like handwritten digits.  Figure 19-1. MNIST images  NOTE  My first attempt at showing the images resulted in yellow numbers on black backgrounds. I am neither clever nor subtle enough to know that I needed to add  s to get black-and-white images; I Googled it and found the solution on Stack Overflow. As a data scientist you will become quite adept at this workflow.  We also need to load the test images:  c m a p = G r e y t e s t _ i m a g e s   =   m n i s t . t e s t _ i m a g e s     . t o l i s t       t e s t _ l a b e l s   =   m n i s t . t e s t _ l a b e l s     . t o l i s t         a s s e r t   s h a p e   t e s t _ i m a g e s     = =   [ 1 0 0 0 0 ,   2 8 ,   2 8 ]   a s s e r t   s h a p e   t e s t _ l a b e l s     = =   [ 1 0 0 0 0 ]  Each image is 28 × 28 pixels, but our linear layers can only deal with one- dimensional inputs, so we’ll just flatten them  and also divide by 256 to get them between 0 and 1 . In addition, our neural net will train better if our inputs are 0 on average, so we’ll subtract out the average value:  We also want to one-hot-encode the targets, since we have 10 outputs. First let’s write a o  e function:  and then apply it to our data:  One of the strengths of our abstractions is that we can use the same training evaluation loop with a variety of models. So let’s write that first. We’ll pass it our model, the data, a loss function, and  if we’re training  an optimizer.     C o m p u t e   t h e   a v e r a g e   p i x e l   v a l u e   a v g   =   t e n s o r _ s u m   t r a i n _ i m a g e s         6 0 0 0 0       2 8       2 8        R e c e n t e r ,   r e s c a l e ,   a n d   f l a t t e n   t r a i n _ i m a g e s   =   [ [   p i x e l   -   a v g         2 5 6   f o r   r o w   i n   i m a g e   f o r   p i x e l   i n   r o w ]                                   f o r   i m a g e   i n   t r a i n _ i m a g e s ]   t e s t _ i m a g e s   =   [ [   p i x e l   -   a v g         2 5 6   f o r   r o w   i n   i m a g e   f o r   p i x e l   i n   r o w ]                                 f o r   i m a g e   i n   t e s t _ i m a g e s ]     a s s e r t   s h a p e   t r a i n _ i m a g e s     = =   [ 6 0 0 0 0 ,   7 8 4 ] ,   " i m a g e s   s h o u l d   b e   f l a t t e n e d "   a s s e r t   s h a p e   t e s t _ i m a g e s     = =   [ 1 0 0 0 0 ,   7 8 4 ] ,   " i m a g e s   s h o u l d   b e   f l a t t e n e d "        A f t e r   c e n t e r i n g ,   a v e r a g e   p i x e l   s h o u l d   b e   v e r y   c l o s e   t o   0   a s s e r t   - 0 . 0 0 0 1   <   t e n s o r _ s u m   t r a i n _ i m a g e s     <   0 . 0 0 0 1 n e _ h o t _ e n c o d d e f   o n e _ h o t _ e n c o d e   i :   i n t ,   n u m _ l a b e l s :   i n t   =   1 0     - >   L i s t [ f l o a t ] :           r e t u r n   [ 1 . 0   i f   j   = =   i   e l s e   0 . 0   f o r   j   i n   r a n g e   n u m _ l a b e l s   ]     a s s e r t   o n e _ h o t _ e n c o d e   3     = =   [ 0 ,   0 ,   0 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ]   a s s e r t   o n e _ h o t _ e n c o d e   2 ,   n u m _ l a b e l s = 5     = =   [ 0 ,   0 ,   1 ,   0 ,   0 ] t r a i n _ l a b e l s   =   [ o n e _ h o t _ e n c o d e   l a b e l     f o r   l a b e l   i n   t r a i n _ l a b e l s ]   t e s t _ l a b e l s   =   [ o n e _ h o t _ e n c o d e   l a b e l     f o r   l a b e l   i n   t e s t _ l a b e l s ]     a s s e r t   s h a p e   t r a i n _ l a b e l s     = =   [ 6 0 0 0 0 ,   1 0 ]   a s s e r t   s h a p e   t e s t _ l a b e l s     = =   [ 1 0 0 0 0 ,   1 0 ]  It will make a pass through our data, track performance, and  if we passed in an optimizer  update our parameters:  As a baseline, we can use our deep learning library to train a  multiclass  logistic regression model, which is just a single linear layer followed by a softmax. This model  in essence  just looks for 10 linear functions such that if the input represents, say, a 5, then the 5th linear function produces the largest output. One pass through our 60,000 training examples should be enough to learn the model:  i m p o r t   t q d m     d e f   l o o p   m o d e l :   L a y e r ,                     i m a g e s :   L i s t [ T e n s o r ] ,                     l a b e l s :   L i s t [ T e n s o r ] ,                     l o s s :   L o s s ,                     o p t i m i z e r :   O p t i m i z e r   =   N o n e     - >   N o n e :           c o r r e c t   =   0                      T r a c k   n u m b e r   o f   c o r r e c t   p r e d i c t i o n s .           t o t a l _ l o s s   =   0 . 0            T r a c k   t o t a l   l o s s .             w i t h   t q d m . t r a n g e   l e n   i m a g e s       a s   t :                   f o r   i   i n   t :                           p r e d i c t e d   =   m o d e l . f o r w a r d   i m a g e s [ i ]                                P r e d i c t .                           i f   a r g m a x   p r e d i c t e d     = =   a r g m a x   l a b e l s [ i ]   :                  C h e c k   f o r                                   c o r r e c t   + =   1                                                                      c o r r e c t n e s s .                           t o t a l _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   l a b e l s [ i ]              C o m p u t e   l o s s .                                I f   w e ' r e   t r a i n i n g ,   b a c k p r o p a g a t e   g r a d i e n t   a n d   u p d a t e   w e i g h t s .                           i f   o p t i m i z e r   i s   n o t   N o n e :                                   g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   l a b e l s [ i ]                                     m o d e l . b a c k w a r d   g r a d i e n t                                     o p t i m i z e r . s t e p   m o d e l                                  A n d   u p d a t e   o u r   m e t r i c s   i n   t h e   p r o g r e s s   b a r .                           a v g _ l o s s   =   t o t a l _ l o s s         i   +   1                             a c c   =   c o r r e c t         i   +   1                             t . s e t _ d e s c r i p t i o n   f " m n i s t   l o s s :   { a v g _ l o s s : . 3 f }   a c c :   { a c c : . 3 f } "   r a n d o m . s e e d   0          L o g i s t i c   r e g r e s s i o n   i s   j u s t   a   l i n e a r   l a y e r   f o l l o w e d   b y   s o f t m a x    This gets about 89% accuracy. Let’s see if we can do better with a deep neural network. We’ll use two hidden layers, the first with 30 neurons, and the second with 10 neurons. And we’ll use our T  h activation:  And we can just use the same training loop!  m o d e l   =   L i n e a r   7 8 4 ,   1 0     l o s s   =   S o f t m a x C r o s s E n t r o p y            T h i s   o p t i m i z e r   s e e m s   t o   w o r k   o p t i m i z e r   =   M o m e n t u m   l e a r n i n g _ r a t e = 0 . 0 1 ,   m o m e n t u m = 0 . 9 9          T r a i n   o n   t h e   t r a i n i n g   d a t a   l o o p   m o d e l ,   t r a i n _ i m a g e s ,   t r a i n _ l a b e l s ,   l o s s ,   o p t i m i z e r          T e s t   o n   t h e   t e s t   d a t a     n o   o p t i m i z e r   m e a n s   j u s t   e v a l u a t e     l o o p   m o d e l ,   t e s t _ i m a g e s ,   t e s t _ l a b e l s ,   l o s s   a n r a n d o m . s e e d   0          N a m e   t h e m   s o   w e   c a n   t u r n   t r a i n   o n   a n d   o f f   d r o p o u t 1   =   D r o p o u t   0 . 1     d r o p o u t 2   =   D r o p o u t   0 . 1       m o d e l   =   S e q u e n t i a l   [           L i n e a r   7 8 4 ,   3 0   ,        H i d d e n   l a y e r   1 :   s i z e   3 0           d r o p o u t 1 ,           T a n h     ,           L i n e a r   3 0 ,   1 0   ,          H i d d e n   l a y e r   2 :   s i z e   1 0           d r o p o u t 2 ,           T a n h     ,           L i n e a r   1 0 ,   1 0              O u t p u t   l a y e r :   s i z e   1 0   ]   o p t i m i z e r   =   M o m e n t u m   l e a r n i n g _ r a t e = 0 . 0 1 ,   m o m e n t u m = 0 . 9 9     l o s s   =   S o f t m a x C r o s s E n t r o p y            E n a b l e   d r o p o u t   a n d   t r a i n     t a k e s   >   2 0   m i n u t e s   o n   m y   l a p t o p !     d r o p o u t 1 . t r a i n   =   d r o p o u t 2 . t r a i n   =   T r u e   l o o p   m o d e l ,   t r a i n _ i m a g e s ,   t r a i n _ l a b e l s ,   l o s s ,   o p t i m i z e r          D i s a b l e   d r o p o u t   a n d   e v a l u a t e   d r o p o u t 1 . t r a i n   =   d r o p o u t 2 . t r a i n   =   F a l s e   l o o p   m o d e l ,   t e s t _ i m a g e s ,   t e s t _ l a b e l s ,   l o s s    Our deep model gets better than 92% accuracy on the test set, which is a nice improvement from the simple logistic model. The MNIST website describes a variety of models that outperform these. Many of them could be implemented using the machinery we’ve developed so far but would take an extremely long time to train in our lists-as-tensors framework. Some of the best models involve convolutional layers, which are important but unfortunately quite out of scope for an introductory book on data science.  Saving and Loading Models These models take a long time to train, so it would be nice if we could save them so that we don’t have to train them every time. Luckily, we can use the j For saving, we can use L list, and use j  n module to easily serialize model weights to a file.  s to collect the weights, stick them in a  p to save that list to a file:  Loading the weights back is only a little more work. We just use j to get the list of weights back from the file and slice assignment to set the weights of our model.  In particular, this means that we have to instantiate the model ourselves and then load the weights. An alternative approach would be to also save some representation of the model architecture and use that to instantiate the model. That’s not a terrible idea, but it would require a lot more code and changes to all our L  rs, so we’ll stick with the simpler way.   s o a y e r . p a r a m s o n . d u m i m p o r t   j s o n     d e f   s a v e _ w e i g h t s   m o d e l :   L a y e r ,   f i l e n a m e :   s t r     - >   N o n e :           w e i g h t s   =   l i s t   m o d e l . p a r a m s                 w i t h   o p e n   f i l e n a m e ,   ' w '     a s   f :                   j s o n . d u m p   w e i g h t s ,   f   s o n . l o a d a y e  Before we load the weights, we’d like to check that they have the same shapes as the model params we’re loading them into.  This is a safeguard against, for example, trying to load the weights for a saved deep network into a shallow network, or similar issues.   NOTE  JSON stores your data as text, which makes it an extremely inefficient representation. In real applications you’d probably use the p e serialization library, which serializes things to a more efficient binary format. Here I decided to keep it simple and human- readable.  You can download the weights for the various networks we train from the book’s GitHub repository.  For Further Exploration Deep learning is really hot right now, and in this chapter we barely scratched its surface. There are many good books and blog posts  and many, many bad blog posts  about almost any aspect of deep learning you’d like to know about.  The canonical textbook Deep Learning, by Ian Goodfellow, Yoshua Bengio, and Aaron Courville  MIT Press , is freely  d e f   l o a d _ w e i g h t s   m o d e l :   L a y e r ,   f i l e n a m e :   s t r     - >   N o n e :           w i t h   o p e n   f i l e n a m e     a s   f :                   w e i g h t s   =   j s o n . l o a d   f                  C h e c k   f o r   c o n s i s t e n c y           a s s e r t   a l l   s h a p e   p a r a m     = =   s h a p e   w e i g h t                                   f o r   p a r a m ,   w e i g h t   i n   z i p   m o d e l . p a r a m s     ,   w e i g h t s                    T h e n   l o a d   u s i n g   s l i c e   a s s i g n m e n t           f o r   p a r a m ,   w e i g h t   i n   z i p   m o d e l . p a r a m s     ,   w e i g h t s   :                   p a r a m [ : ]   =   w e i g h t i c k l  available online. It is very good, but it involves quite a bit of mathematics. Francois Chollet’s Deep Learning with Python  Manning  is a great introduction to the Keras library, after which our deep learning library is sort of patterned. I myself mostly use PyTorch for deep learning. Its website has lots of documentation and tutorials.   Chapter 20. Clustering  Where we such clusters had  As made us nobly wild, not mad  —Robert Herrick  Most of the algorithms in this book are what’s known as supervised learning algorithms, in that they start with a set of labeled data and use that as the basis for making predictions about new, unlabeled data. Clustering, however, is an example of unsupervised learning, in which we work with completely unlabeled data  or in which our data has labels but we ignore them .  The Idea Whenever you look at some source of data, it’s likely that the data will somehow form clusters. A dataset showing where millionaires live probably has clusters in places like Beverly Hills and Manhattan. A dataset showing how many hours people work each week probably has a cluster around 40  and if it’s taken from a state with laws mandating special benefits for people who work at least 20 hours a week, it probably has another cluster right around 19 . A dataset of demographics of registered voters likely forms a variety of clusters  e.g., “soccer moms,” “bored retirees,” “unemployed millennials”  that pollsters and political consultants consider relevant. Unlike some of the problems we’ve looked at, there is generally no “correct” clustering. An alternative clustering scheme might group some of the “unemployed millennials” with “grad students,” and others with “parents’ basement dwellers.” Neither scheme is necessarily more correct— instead, each is likely more optimal with respect to its own “how good are the clusters?” metric.   Furthermore, the clusters won’t label themselves. You’ll have to do that by looking at the data underlying each one.  t will be a vector in d-dimensional space, which, as usual,  The Model For us, each i we will represent as a list of numbers. Our goal will be to identify clusters of similar inputs and  sometimes  to find a representative value for each cluster. For example, each input could be a numeric vector that represents the title of a blog post, in which case the goal might be to find clusters of similar posts, perhaps in order to understand what our users are blogging about. Or imagine that we have a picture containing thousands of      colors and that we need to screen-print a 10-color version of it.  Clustering can help us choose 10 colors that will minimize the total “color error.” One of the simplest clustering methods is k-means, in which the number of clusters k is chosen in advance, after which the goal is to partition the inputs into sets S distances from each point to the mean of its assigned cluster. There are a lot of ways to assign n points to k clusters, which means that finding an optimal clustering is a very hard problem. We’ll settle for an iterative algorithm that usually finds a good clustering:  k in a way that minimizes the total sum of squared  1. Start with a set of k-means, which are points in d-dimensional  space.  2. Assign each point to the mean to which it is closest. 3. If no point’s assignment has changed, stop and keep the clusters. 4. If some point’s assignment has changed, recompute the means and  return to step 2.  n p u r e d ,   g r e e n , b l u e 1 , . . . , S  n function from Chapter 4, it’s pretty simple to create  Using the v a class that does this. To start with, we’ll create a helper function that measures how many coordinates two vectors differ in. We’ll use this to track our training progress:  We also need a function that, given some vectors and their assignments to clusters, computes the means of the clusters. It may be the case that some cluster has no points assigned to it. We can’t take the mean of an empty collection, so in that case we’ll just randomly pick one of the points to serve as the “mean” of that cluster:  And now we’re ready to code up our clusterer. As usual, we’ll use t track our progress, but here we don’t know how many iterations it will take, so we then use i we’ll r  t, which creates an infinite iterable, and  n out of it when we’re done:  m to  e c t o r _ m e a f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r     d e f   n u m _ d i f f e r e n c e s   v 1 :   V e c t o r ,   v 2 :   V e c t o r     - >   i n t :           a s s e r t   l e n   v 1     = =   l e n   v 2             r e t u r n   l e n   [ x 1   f o r   x 1 ,   x 2   i n   z i p   v 1 ,   v 2     i f   x 1   ! =   x 2 ]       a s s e r t   n u m _ d i f f e r e n c e s   [ 1 ,   2 ,   3 ] ,   [ 2 ,   1 ,   3 ]     = =   2   a s s e r t   n u m _ d i f f e r e n c e s   [ 1 ,   2 ] ,   [ 1 ,   2 ]     = =   0 f r o m   t y p i n g   i m p o r t   L i s t   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   v e c t o r _ m e a n     d e f   c l u s t e r _ m e a n s   k :   i n t ,                                       i n p u t s :   L i s t [ V e c t o r ] ,                                       a s s i g n m e n t s :   L i s t [ i n t ]     - >   L i s t [ V e c t o r ] :              c l u s t e r s [ i ]   c o n t a i n s   t h e   i n p u t s   w h o s e   a s s i g n m e n t   i s   i           c l u s t e r s   =   [ [ ]   f o r   i   i n   r a n g e   k   ]           f o r   i n p u t ,   a s s i g n m e n t   i n   z i p   i n p u t s ,   a s s i g n m e n t s   :                   c l u s t e r s [ a s s i g n m e n t ] . a p p e n d   i n p u t                  i f   a   c l u s t e r   i s   e m p t y ,   j u s t   u s e   a   r a n d o m   p o i n t           r e t u r n   [ v e c t o r _ m e a n   c l u s t e r     i f   c l u s t e r   e l s e   r a n d o m . c h o i c e   i n p u t s                             f o r   c l u s t e r   i n   c l u s t e r s ] q d t e r t o o l s . c o u n e t u r  Let’s take a look at how this works.  Example: Meetups To celebrate DataSciencester’s growth, your VP of User Rewards wants to organize several in-person meetups for your hometown users, complete with beer, pizza, and DataSciencester t-shirts. You know the locations of all  i m p o r t   i t e r t o o l s   i m p o r t   r a n d o m   i m p o r t   t q d m   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   s q u a r e d _ d i s t a n c e     c l a s s   K M e a n s :           d e f   _ _ i n i t _ _   s e l f ,   k :   i n t     - >   N o n e :                   s e l f . k   =   k                                                n u m b e r   o f   c l u s t e r s                   s e l f . m e a n s   =   N o n e             d e f   c l a s s i f y   s e l f ,   i n p u t :   V e c t o r     - >   i n t :                   " " " r e t u r n   t h e   i n d e x   o f   t h e   c l u s t e r   c l o s e s t   t o   t h e   i n p u t " " "                   r e t u r n   m i n   r a n g e   s e l f . k   ,                                         k e y = l a m b d a   i :   s q u a r e d _ d i s t a n c e   i n p u t ,   s e l f . m e a n s [ i ]                 d e f   t r a i n   s e l f ,   i n p u t s :   L i s t [ V e c t o r ]     - >   N o n e :                      S t a r t   w i t h   r a n d o m   a s s i g n m e n t s                   a s s i g n m e n t s   =   [ r a n d o m . r a n d r a n g e   s e l f . k     f o r   _   i n   i n p u t s ]                     w i t h   t q d m . t q d m   i t e r t o o l s . c o u n t         a s   t :                           f o r   _   i n   t :                                      C o m p u t e   m e a n s   a n d   f i n d   n e w   a s s i g n m e n t s                                   s e l f . m e a n s   =   c l u s t e r _ m e a n s   s e l f . k ,   i n p u t s ,   a s s i g n m e n t s                                     n e w _ a s s i g n m e n t s   =   [ s e l f . c l a s s i f y   i n p u t     f o r   i n p u t   i n   i n p u t s ]                                        C h e c k   h o w   m a n y   a s s i g n m e n t s   c h a n g e d   a n d   i f   w e ' r e   d o n e                                   n u m _ c h a n g e d   =   n u m _ d i f f e r e n c e s   a s s i g n m e n t s ,   n e w _ a s s i g n m e n t s                                     i f   n u m _ c h a n g e d   = =   0 :                                           r e t u r n                                        O t h e r w i s e   k e e p   t h e   n e w   a s s i g n m e n t s ,   a n d   c o m p u t e   n e w   m e a n s                                   a s s i g n m e n t s   =   n e w _ a s s i g n m e n t s                                   s e l f . m e a n s   =   c l u s t e r _ m e a n s   s e l f . k ,   i n p u t s ,   a s s i g n m e n t s                                     t . s e t _ d e s c r i p t i o n   f " c h a n g e d :   { n u m _ c h a n g e d }       { l e n   i n p u t s   } "    your local users  Figure 20-1 , and she’d like you to choose meetup locations that make it convenient for everyone to attend.  Figure 20-1. The locations of your hometown users  Depending on how you look at it, you probably see two or three clusters.  It’s easy to do visually because the data is only two-dimensional. With more dimensions, it would be a lot harder to eyeball.  Imagine first that she has enough budget for three meetups. You go to your computer and try this:  r a n d o m . s e e d   1 2                                            s o   y o u   g e t   t h e   s a m e   r e s u l t s   a s   m e   c l u s t e r e r   =   K M e a n s   k = 3     c l u s t e r e r . t r a i n   i n p u t s     m e a n s   =   s o r t e d   c l u s t e r e r . m e a n s            s o r t   f o r   t h e   u n i t   t e s t     a s s e r t   l e n   m e a n s     = =   3      You find three clusters centered at [–44, 5], [–16, –10], and [18, 20], and you look for meetup venues near those locations  Figure 20-2 .  Figure 20-2. User locations grouped into three clusters  You show your results to the VP, who informs you that now she only has enough budgeted for two meetups. “No problem,” you say:     C h e c k   t h a t   t h e   m e a n s   a r e   c l o s e   t o   w h a t   w e   e x p e c t   a s s e r t   s q u a r e d _ d i s t a n c e   m e a n s [ 0 ] ,   [ - 4 4 ,   5 ]     <   1   a s s e r t   s q u a r e d _ d i s t a n c e   m e a n s [ 1 ] ,   [ - 1 6 ,   - 1 0 ]     <   1   a s s e r t   s q u a r e d _ d i s t a n c e   m e a n s [ 2 ] ,   [ 1 8 ,   2 0 ]     <   1 r a n d o m . s e e d   0     c l u s t e r e r   =   K M e a n s   k = 2     c l u s t e r e r . t r a i n   i n p u t s     m e a n s   =   s o r t e d   c l u s t e r e r . m e a n s      As shown in Figure 20-3, one meetup should still be near [18, 20], but now the other should be near [–26, –5].  Figure 20-3. User locations grouped into two clusters  Choosing k In the previous example, the choice of k was driven by factors outside of our control. In general, this won’t be the case. There are various ways to choose a k. One that’s reasonably easy to understand involves plotting the sum of squared errors  between each point and the mean of its cluster  as a function of k and looking at where the graph “bends”:    a s s e r t   l e n   m e a n s     = =   2   a s s e r t   s q u a r e d _ d i s t a n c e   m e a n s [ 0 ] ,   [ - 2 6 ,   - 5 ]     <   1   a s s e r t   s q u a r e d _ d i s t a n c e   m e a n s [ 1 ] ,   [ 1 8 ,   2 0 ]     <   1  which we can apply to our previous example:  Looking at Figure 20-4, this method agrees with our original eyeballing that three is the “right” number of clusters.  f r o m   m a t p l o t l i b   i m p o r t   p y p l o t   a s   p l t     d e f   s q u a r e d _ c l u s t e r i n g _ e r r o r s   i n p u t s :   L i s t [ V e c t o r ] ,   k :   i n t     - >   f l o a t :           " " " f i n d s   t h e   t o t a l   s q u a r e d   e r r o r   f r o m   k - m e a n s   c l u s t e r i n g   t h e   i n p u t s " " "           c l u s t e r e r   =   K M e a n s   k             c l u s t e r e r . t r a i n   i n p u t s             m e a n s   =   c l u s t e r e r . m e a n s           a s s i g n m e n t s   =   [ c l u s t e r e r . c l a s s i f y   i n p u t     f o r   i n p u t   i n   i n p u t s ]             r e t u r n   s u m   s q u a r e d _ d i s t a n c e   i n p u t ,   m e a n s [ c l u s t e r ]                                   f o r   i n p u t ,   c l u s t e r   i n   z i p   i n p u t s ,   a s s i g n m e n t s        n o w   p l o t   f r o m   1   u p   t o   l e n   i n p u t s     c l u s t e r s     k s   =   r a n g e   1 ,   l e n   i n p u t s     +   1     e r r o r s   =   [ s q u a r e d _ c l u s t e r i n g _ e r r o r s   i n p u t s ,   k     f o r   k   i n   k s ]     p l t . p l o t   k s ,   e r r o r s     p l t . x t i c k s   k s     p l t . x l a b e l   " k "     p l t . y l a b e l   " t o t a l   s q u a r e d   e r r o r "     p l t . t i t l e   " T o t a l   E r r o r   v s .      o f   C l u s t e r s "     p l t . s h o w      Figure 20-4. Choosing a k  Example: Clustering Colors The VP of Swag has designed attractive DataSciencester stickers that he’d like you to hand out at meetups. Unfortunately, your sticker printer can print at most five colors per sticker. And since the VP of Art is on sabbatical, the VP of Swag asks if there’s some way you can take his design and modify it so that it contains only five colors. Computer images can be represented as two-dimensional arrays of pixels, where each pixel is itself a three-dimensional vector   indicating its color. Creating a five-color version of the image, then, entails:  1. Choosing five colors.  r e d ,   g r e e n ,   b l u e    2. Assigning one of those colors to each pixel.  It turns out this is a great task for k-means clustering, which can partition the pixels into five clusters in red-green-blue space. If we then recolor the pixels in each cluster to the mean color, we’re done. To start with, we’ll need a way to load an image into Python. We can do this with matplotlib, if we first install the pillow library:  Then we can just use m  d:  Behind the scenes i it as a list of lists of lists.  g is a NumPy array, but for our purposes, we can treat  ] is the pixel in the ith row and jth column, and each pixel is a list  ] of numbers between 0 and 1 indicating the color of  that pixel:  In particular, we can get a flattened list of all the pixels as:  and then feed them to our clusterer:  p y t h o n   - m   p i p   i n s t a l l   p i l l o w a t p l o t l i b . i m a g e . i m r e a i m a g e _ p a t h   =   r " g i r l _ w i t h _ b o o k . j p g "            w h e r e v e r   y o u r   i m a g e   i s   i m p o r t   m a t p l o t l i b . i m a g e   a s   m p i m g   i m g   =   m p i m g . i m r e a d   i m a g e _ p a t h         2 5 6        r e s c a l e   t o   b e t w e e n   0   a n d   1 m i m g [ i ] [ j [ r e d ,   g r e e n ,   b l u e t o p _ r o w   =   i m g [ 0 ]   t o p _ l e f t _ p i x e l   =   t o p _ r o w [ 0 ]   r e d ,   g r e e n ,   b l u e   =   t o p _ l e f t _ p i x e l    . t o l i s t       c o n v e r t s   a   N u m P y   a r r a y   t o   a   P y t h o n   l i s t   p i x e l s   =   [ p i x e l . t o l i s t       f o r   r o w   i n   i m g   f o r   p i x e l   i n   r o w ] c l u s t e r e r   =   K M e a n s   5     c l u s t e r e r . t r a i n   p i x e l s            t h i s   m i g h t   t a k e   a   w h i l e  Once it finishes, we just construct a new image with the same format:  and display it, using p  w:  It is difficult to show color results in a black-and-white book, but Figure 20- 5 shows grayscale versions of a full-color picture and the output of using this process to reduce it to five colors.  Figure 20-5. Original picture and its 5-means decoloring  Bottom-Up Hierarchical Clustering An alternative approach to clustering is to “grow” clusters from the bottom up. We can do this in the following way:  d e f   r e c o l o r   p i x e l :   V e c t o r     - >   V e c t o r :           c l u s t e r   =   c l u s t e r e r . c l a s s i f y   p i x e l                      i n d e x   o f   t h e   c l o s e s t   c l u s t e r           r e t u r n   c l u s t e r e r . m e a n s [ c l u s t e r ]                            m e a n   o f   t h e   c l o s e s t   c l u s t e r     n e w _ i m g   =   [ [ r e c o l o r   p i x e l     f o r   p i x e l   i n   r o w ]          r e c o l o r   t h i s   r o w   o f   p i x e l s                         f o r   r o w   i n   i m g ]                                              f o r   e a c h   r o w   i n   t h e   i m a g e l t . i m s h o p l t . i m s h o w   n e w _ i m g     p l t . a x i s   ' o f f '     p l t . s h o w      1. Make each input its own cluster of one. 2. As long as there are multiple clusters remaining, find the two  closest clusters and merge them.  At the end, we’ll have one giant cluster containing all the inputs. If we keep track of the merge order, we can re-create any number of clusters by unmerging. For example, if we want three clusters, we can just undo the last two merges. We’ll use a really simple representation of clusters. Our values will live in leaf clusters, which we will represent as N  es:  We’ll use these to grow merged clusters, which we will also represent as  es:  NOTE  This is another case where Python’s type annotations have let us down. You’d like to type hint M y doesn’t allow recursive types like that.  ] but m  n as T  a m e d T u p l f r o m   t y p i n g   i m p o r t   N a m e d T u p l e ,   U n i o n     c l a s s   L e a f   N a m e d T u p l e   :           v a l u e :   V e c t o r     l e a f 1   =   L e a f   [ 1 0 ,     2 0 ]     l e a f 2   =   L e a f   [ 3 0 ,   - 1 5 ]   N a m e d T u p l c l a s s   M e r g e d   N a m e d T u p l e   :           c h i l d r e n :   t u p l e           o r d e r :   i n t     m e r g e d   =   M e r g e d     l e a f 1 ,   l e a f 2   ,   o r d e r = 1       C l u s t e r   =   U n i o n [ L e a f ,   M e r g e d ] e r g e d . c h i l d r e u p l e [ C l u s t e r ,   C l u s t e r y p  We’ll talk about merge order in a bit, but first let’s create a helper function that recursively returns all the values contained in a  possibly merged  cluster:  In order to merge the closest clusters, we need some notion of the distance between clusters. We’ll use the minimum distance between elements of the two clusters, which merges the two clusters that are closest to touching  but will sometimes produce large chain-like clusters that aren’t very tight . If we wanted tight spherical clusters, we might use the maximum distance instead, as it merges the two clusters that fit in the smallest ball. Both are common choices, as is the average distance:  We’ll use the merge order slot to track the order in which we did the merging. Smaller numbers will represent later merges. This means when we want to unmerge clusters, we do so from lowest merge order to highest. f clusters were never merged, we’ll assign them infinity, the Since L  d e f   g e t _ v a l u e s   c l u s t e r :   C l u s t e r     - >   L i s t [ V e c t o r ] :           i f   i s i n s t a n c e   c l u s t e r ,   L e a f   :                   r e t u r n   [ c l u s t e r . v a l u e ]           e l s e :                   r e t u r n   [ v a l u e                                   f o r   c h i l d   i n   c l u s t e r . c h i l d r e n                                   f o r   v a l u e   i n   g e t _ v a l u e s   c h i l d   ]     a s s e r t   g e t _ v a l u e s   m e r g e d     = =   [ [ 1 0 ,   2 0 ] ,   [ 3 0 ,   - 1 5 ] ] f r o m   t y p i n g   i m p o r t   C a l l a b l e   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d i s t a n c e     d e f   c l u s t e r _ d i s t a n c e   c l u s t e r 1 :   C l u s t e r ,                                             c l u s t e r 2 :   C l u s t e r ,                                             d i s t a n c e _ a g g :   C a l l a b l e   =   m i n     - >   f l o a t :           " " "           c o m p u t e   a l l   t h e   p a i r w i s e   d i s t a n c e s   b e t w e e n   c l u s t e r 1   a n d   c l u s t e r 2           a n d   a p p l y   t h e   a g g r e g a t i o n   f u n c t i o n   _ d i s t a n c e _ a g g _   t o   t h e   r e s u l t i n g   l i s t           " " "           r e t u r n   d i s t a n c e _ a g g   [ d i s t a n c e   v 1 ,   v 2                                                       f o r   v 1   i n   g e t _ v a l u e s   c l u s t e r 1                                                       f o r   v 2   i n   g e t _ v a l u e s   c l u s t e r 2   ]   e a  highest possible value. And since they don’t have an . create a helper function:  r property, we’ll  Similarly, since L helper function for that:  f clusters don’t have children, we’ll create and add a  Now we’re ready to create the clustering algorithm:  o r d e d e f   g e t _ m e r g e _ o r d e r   c l u s t e r :   C l u s t e r     - >   f l o a t :           i f   i s i n s t a n c e   c l u s t e r ,   L e a f   :                   r e t u r n   f l o a t   ' i n f '          w a s   n e v e r   m e r g e d           e l s e :                   r e t u r n   c l u s t e r . o r d e r e a f r o m   t y p i n g   i m p o r t   T u p l e     d e f   g e t _ c h i l d r e n   c l u s t e r :   C l u s t e r   :           i f   i s i n s t a n c e   c l u s t e r ,   L e a f   :                   r a i s e   T y p e E r r o r   " L e a f   h a s   n o   c h i l d r e n "             e l s e :                   r e t u r n   c l u s t e r . c h i l d r e n d e f   b o t t o m _ u p _ c l u s t e r   i n p u t s :   L i s t [ V e c t o r ] ,                                               d i s t a n c e _ a g g :   C a l l a b l e   =   m i n     - >   C l u s t e r :              S t a r t   w i t h   a l l   l e a v e s           c l u s t e r s :   L i s t [ C l u s t e r ]   =   [ L e a f   i n p u t     f o r   i n p u t   i n   i n p u t s ]             d e f   p a i r _ d i s t a n c e   p a i r :   T u p l e [ C l u s t e r ,   C l u s t e r ]     - >   f l o a t :                   r e t u r n   c l u s t e r _ d i s t a n c e   p a i r [ 0 ] ,   p a i r [ 1 ] ,   d i s t a n c e _ a g g                  a s   l o n g   a s   w e   h a v e   m o r e   t h a n   o n e   c l u s t e r   l e f t . . .           w h i l e   l e n   c l u s t e r s     >   1 :                      f i n d   t h e   t w o   c l o s e s t   c l u s t e r s                   c 1 ,   c 2   =   m i n       c l u s t e r 1 ,   c l u s t e r 2                                                 f o r   i ,   c l u s t e r 1   i n   e n u m e r a t e   c l u s t e r s                                                 f o r   c l u s t e r 2   i n   c l u s t e r s [ : i ]   ,                                               k e y = p a i r _ d i s t a n c e                          r e m o v e   t h e m   f r o m   t h e   l i s t   o f   c l u s t e r s                   c l u s t e r s   =   [ c   f o r   c   i n   c l u s t e r s   i f   c   ! =   c 1   a n d   c   ! =   c 2 ]                        m e r g e   t h e m ,   u s i n g   m e r g e _ o r d e r   =      o f   c l u s t e r s   l e f t                   m e r g e d _ c l u s t e r   =   M e r g e d     c 1 ,   c 2   ,   o r d e r = l e n   c l u s t e r s        Its use is very simple:  This produces a clustering that looks as follows:  The numbers at the top indicate “merge order.” Since we had 20 inputs, it took 19 merges to get to this one cluster. The first merge created cluster 18 by combining the leaves [19, 28] and [21, 27]. And the last merge created cluster 0. If you wanted only two clusters, you’d split at the first fork  “0” , creating one cluster with six points and a second with the rest. For three clusters, you’d continue to the second fork  “1” , which indicates to split that first                       a n d   a d d   t h e i r   m e r g e                   c l u s t e r s . a p p e n d   m e r g e d _ c l u s t e r                  w h e n   t h e r e ' s   o n l y   o n e   c l u s t e r   l e f t ,   r e t u r n   i t           r e t u r n   c l u s t e r s [ 0 ] b a s e _ c l u s t e r   =   b o t t o m _ u p _ c l u s t e r   i n p u t s       0     1     2     3     4     5     6     7     8     9     1 0   1 1   1 2   1 3   1 4   1 5   1 6   1 7   1 8   ─ ─ ┬ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─   [ 1 9 ,   2 8 ]       │     │           │                                                                 │                       └ ─   [ 2 1 ,   2 7 ]       │     │           │                                                                 └ ─   [ 2 0 ,   2 3 ]       │     │           └ ─   [ 2 6 ,   1 3 ]       │     └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─   [ 1 1 ,   1 5 ]       │                                                                                               └ ─   [ 1 3 ,   1 3 ]       └ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─ ─ ┬ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─   [ - 4 9 ,   0 ]                   │           │     │                       │           └ ─   [ - 4 6 ,   5 ]                   │           │     │                       └ ─   [ - 4 1 ,   8 ]                   │           │     └ ─   [ - 4 9 ,   1 5 ]                   │           └ ─   [ - 3 4 ,   1 ]                   └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─ ─ ┬ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─   [ - 2 2 ,   - 1 6 ]                                           │     │     │           └ ─   [ - 1 9 ,   - 1 1 ]                                           │     │     └ ─   [ - 2 5 ,   - 9 ]                                           │     └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─ ─ ─ ─ ─ ┬ ─   [ - 1 1 ,   - 6 ]                                           │                                         │           │           └ ─   [ - 1 2 ,   - 8 ]                                           │                                         │           └ ─   [ - 1 4 ,   5 ]                                           │                                         └ ─   [ - 1 8 ,   - 3 ]                                           └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ ─   [ - 1 3 ,   - 1 9 ]                                                                               └ ─   [ - 9 ,   - 1 6 ]  cluster into the cluster with  [19, 28], [21, 27], [20, 23], [26, 13]  and the cluster with  [11, 15], [13, 13] . And so on. Generally, though, we don’t want to be squinting at nasty text representations like this. Instead, let’s write a function that generates any number of clusters by performing the appropriate number of unmerges:  So, for example, if we want to generate three clusters, we can just do:  which we can easily plot:  d e f   g e n e r a t e _ c l u s t e r s   b a s e _ c l u s t e r :   C l u s t e r ,                                               n u m _ c l u s t e r s :   i n t     - >   L i s t [ C l u s t e r ] :              s t a r t   w i t h   a   l i s t   w i t h   j u s t   t h e   b a s e   c l u s t e r           c l u s t e r s   =   [ b a s e _ c l u s t e r ]                a s   l o n g   a s   w e   d o n ' t   h a v e   e n o u g h   c l u s t e r s   y e t . . .           w h i l e   l e n   c l u s t e r s     <   n u m _ c l u s t e r s :                      c h o o s e   t h e   l a s t - m e r g e d   o f   o u r   c l u s t e r s                   n e x t _ c l u s t e r   =   m i n   c l u s t e r s ,   k e y = g e t _ m e r g e _ o r d e r                        r e m o v e   i t   f r o m   t h e   l i s t                   c l u s t e r s   =   [ c   f o r   c   i n   c l u s t e r s   i f   c   ! =   n e x t _ c l u s t e r ]                        a n d   a d d   i t s   c h i l d r e n   t o   t h e   l i s t     i . e . ,   u n m e r g e   i t                     c l u s t e r s . e x t e n d   g e t _ c h i l d r e n   n e x t _ c l u s t e r                    o n c e   w e   h a v e   e n o u g h   c l u s t e r s . . .           r e t u r n   c l u s t e r s t h r e e _ c l u s t e r s   =   [ g e t _ v a l u e s   c l u s t e r                                         f o r   c l u s t e r   i n   g e n e r a t e _ c l u s t e r s   b a s e _ c l u s t e r ,   3   ] f o r   i ,   c l u s t e r ,   m a r k e r ,   c o l o r   i n   z i p   [ 1 ,   2 ,   3 ] ,                                                                             t h r e e _ c l u s t e r s ,                                                                             [ ' D ' , ' o ' , ' * ' ] ,                                                                             [ ' r ' , ' g ' , ' b ' ]   :           x s ,   y s   =   z i p   * c l u s t e r          m a g i c   u n z i p p i n g   t r i c k           p l t . s c a t t e r   x s ,   y s ,   c o l o r = c o l o r ,   m a r k e r = m a r k e r                  p u t   a   n u m b e r   a t   t h e   m e a n   o f   t h e   c l u s t e r           x ,   y   =   v e c t o r _ m e a n   c l u s t e r             p l t . p l o t   x ,   y ,   m a r k e r = ' $ '   +   s t r   i     +   ' $ ' ,   c o l o r = ' b l a c k '        This gives very different results than k-means did, as shown in Figure 20-6.  Figure 20-6. Three bottom-up clusters using min distance  As mentioned previously, this is because using m tends to give chain-like clusters. If we instead use m clusters , it looks the same as the 3-means result  Figure 20-7 .  n in c  x  which gives tight  p l t . t i t l e   " U s e r   L o c a t i o n s   - -   3   B o t t o m - U p   C l u s t e r s ,   M i n "     p l t . x l a b e l   " b l o c k s   e a s t   o f   c i t y   c e n t e r "     p l t . y l a b e l   " b l o c k s   n o r t h   o f   c i t y   c e n t e r "     p l t . s h o w     i l u s t e r _ d i s t a n c e a  NOTE The previous b g implementation is relatively simple, but also shockingly inefficient. In particular, it recomputes the distance between each pair of inputs at every step. A more efficient implementation might instead precompute the distances between each pair of inputs and then perform a lookup inside  e. A really efficient implementation would likely also remember the es from the previous step.  Figure 20-7. Three bottom-up clusters using max distance  For Further Exploration  scikit-learn has an entire module, s several clustering algorithms including K  r, that contains  s and the W  o t t o m _ u p _ c l u s t e r i n c l u s t e r _ d i s t a n c c l u s t e r _ d i s t a n c k l e a r n . c l u s t e M e a n a r d  hierarchical clustering algorithm  which uses a different criterion for merging clusters than ours did .  SciPy has two clustering models: s k-means, and s hierarchical clustering algorithms.  q, which does y, which has a variety of  c i p y . c l u s t e r . v c i p y . c l u s t e r . h i e r a r c h  Chapter 21. Natural Language Processing  They have been at a great feast of languages, and stolen the scraps.  —William Shakespeare  Natural language processing  NLP  refers to computational techniques involving language. It’s a broad field, but we’ll look at a few techniques, both simple and not simple.  Word Clouds In Chapter 1, we computed word counts of users’ interests. One approach to visualizing words and counts is word clouds, which artistically depict the words at sizes proportional to their counts. Generally, though, data scientists don’t think much of word clouds, in large part because the placement of the words doesn’t mean anything other than “here’s some space where I was able to fit a word.” If you ever are forced to create a word cloud, think about whether you can make the axes convey something. For example, imagine that, for each of some collection of data science–related buzzwords, you have two numbers between 0 and 100—the first representing how frequently it appears in job postings, and the second how frequently it appears on résumés:  d a t a   =   [     " b i g   d a t a " ,   1 0 0 ,   1 5   ,     " H a d o o p " ,   9 5 ,   2 5   ,     " P y t h o n " ,   7 5 ,   5 0   ,                       " R " ,   5 0 ,   4 0   ,     " m a c h i n e   l e a r n i n g " ,   8 0 ,   2 0   ,     " s t a t i s t i c s " ,   2 0 ,   6 0   ,                       " d a t a   s c i e n c e " ,   6 0 ,   7 0   ,     " a n a l y t i c s " ,   9 0 ,   3   ,                       " t e a m   p l a y e r " ,   8 5 ,   8 5   ,     " d y n a m i c " ,   2 ,   9 0   ,     " s y n e r g i e s " ,   7 0 ,   0   ,                       " a c t i o n a b l e   i n s i g h t s " ,   4 0 ,   3 0   ,     " t h i n k   o u t   o f   t h e   b o x " ,   4 5 ,   1 0   ,                       " s e l f - s t a r t e r " ,   3 0 ,   5 0   ,     " c u s t o m e r   f o c u s " ,   6 5 ,   1 5   ,                       " t h o u g h t   l e a d e r s h i p " ,   3 5 ,   3 5   ]  The word cloud approach is just to arrange the words on a page in a cool- looking font  Figure 21-1 .  Figure 21-1. Buzzword cloud  This looks neat but doesn’t really tell us anything. A more interesting approach might be to scatter them so that horizontal position indicates posting popularity and vertical position indicates résumé popularity, which produces a visualization that conveys a few insights  Figure 21-2 :  f r o m   m a t p l o t l i b   i m p o r t   p y p l o t   a s   p l t     d e f   t e x t _ s i z e   t o t a l :   i n t     - >   f l o a t :           " " " e q u a l s   8   i f   t o t a l   i s   0 ,   2 8   i f   t o t a l   i s   2 0 0 " " "           r e t u r n   8   +   t o t a l       2 0 0   *   2 0     f o r   w o r d ,   j o b _ p o p u l a r i t y ,   r e s u m e _ p o p u l a r i t y   i n   d a t a :           p l t . t e x t   j o b _ p o p u l a r i t y ,   r e s u m e _ p o p u l a r i t y ,   w o r d ,                             h a = ' c e n t e r ' ,   v a = ' c e n t e r ' ,                             s i z e = t e x t _ s i z e   j o b _ p o p u l a r i t y   +   r e s u m e _ p o p u l a r i t y       p l t . x l a b e l   " P o p u l a r i t y   o n   J o b   P o s t i n g s "     p l t . y l a b e l   " P o p u l a r i t y   o n   R e s u m e s "      Figure 21-2. A more meaningful  if less attractive  word cloud  n-Gram Language Models The DataSciencester VP of Search Engine Marketing wants to create thousands of web pages about data science so that your site will rank higher in search results for data science–related terms.  You attempt to explain to her that search engine algorithms are clever enough that this won’t actually work, but she refuses to listen.  Of course, she doesn’t want to write thousands of web pages, nor does she want to pay a horde of “content strategists” to do so. Instead, she asks you whether you can somehow programmatically generate these web pages. To do this, we’ll need some way of modeling language.  p l t . a x i s   [ 0 ,   1 0 0 ,   0 ,   1 0 0 ]     p l t . x t i c k s   [ ]     p l t . y t i c k s   [ ]     p l t . s h o w      One approach is to start with a corpus of documents and learn a statistical model of language. In our case, we’ll start with Mike Loukides’s essay “What Is Data Science?” As in Chapter 9, we’ll use the Requests and Beautiful Soup libraries to retrieve the data. There are a couple of issues worth calling attention to. The first is that the apostrophes in the text are actually the Unicode character u normal apostrophes:  ". We’ll create a helper function to replace them with  The second issue is that once we get the text of the web page, we’ll want to split it into a sequence of words and periods  so that we can tell where sentences end . We can do this using r  l:  We certainly could  and likely should  clean this data further. There is still some amount of extraneous text in the document  for example, the first word is Section , and we’ve split on midsentence periods  for example, in Web 2.0 , and there are a handful of captions and lists sprinkled throughout. Having said that, we’ll work with the document as it is.  " \ u 2 0 1 9 d e f   f i x _ u n i c o d e   t e x t :   s t r     - >   s t r :           r e t u r n   t e x t . r e p l a c e   u " \ u 2 0 1 9 " ,   " ' "   e . f i n d a l i m p o r t   r e   f r o m   b s 4   i m p o r t   B e a u t i f u l S o u p   i m p o r t   r e q u e s t s     u r l   =   " h t t p s :     w w w . o r e i l l y . c o m   i d e a s   w h a t - i s - d a t a - s c i e n c e "   h t m l   =   r e q u e s t s . g e t   u r l   . t e x t   s o u p   =   B e a u t i f u l S o u p   h t m l ,   ' h t m l 5 l i b '       c o n t e n t   =   s o u p . f i n d   " d i v " ,   " a r t i c l e - b o d y "            f i n d   a r t i c l e - b o d y   d i v   r e g e x   =   r " [ \ w ' ] +  [ \ . ] "                                                  m a t c h e s   a   w o r d   o r   a   p e r i o d     d o c u m e n t   =   [ ]     f o r   p a r a g r a p h   i n   c o n t e n t   " p "   :           w o r d s   =   r e . f i n d a l l   r e g e x ,   f i x _ u n i c o d e   p a r a g r a p h . t e x t               d o c u m e n t . e x t e n d   w o r d s    Now that we have the text as a sequence of words, we can model language in the following way: given some starting word  say, book  we look at all the words that follow it in the source document. We randomly choose one of these to be the next word, and we repeat the process until we get to a period, which signifies the end of the sentence. We call this a bigram model, as it is determined completely by the frequencies of the bigrams  word pairs  in the original data. What about a starting word? We can just pick randomly from words that follow a period. To start, let’s precompute the possible word transitions. Recall that z  p stops when any of its inputs is done, so that z   gives us precisely the pairs of consecutive elements of  t:  Now we’re ready to generate sentences:  The sentences it produces are gibberish, but they’re the kind of gibberish you might put on your website if you were trying to sound data-sciencey. For example:  i i p   d o c u m e n t , d o c u m e n t [ 1 : ] d o c u m e n f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     t r a n s i t i o n s   =   d e f a u l t d i c t   l i s t     f o r   p r e v ,   c u r r e n t   i n   z i p   d o c u m e n t ,   d o c u m e n t [ 1 : ]   :           t r a n s i t i o n s [ p r e v ] . a p p e n d   c u r r e n t   d e f   g e n e r a t e _ u s i n g _ b i g r a m s       - >   s t r :           c u r r e n t   =   " . "          t h i s   m e a n s   t h e   n e x t   w o r d   w i l l   s t a r t   a   s e n t e n c e           r e s u l t   =   [ ]           w h i l e   T r u e :                   n e x t _ w o r d _ c a n d i d a t e s   =   t r a n s i t i o n s [ c u r r e n t ]            b i g r a m s     c u r r e n t ,   _                     c u r r e n t   =   r a n d o m . c h o i c e   n e x t _ w o r d _ c a n d i d a t e s          c h o o s e   o n e   a t   r a n d o m                   r e s u l t . a p p e n d   c u r r e n t                                                        a p p e n d   i t   t o   r e s u l t s                   i f   c u r r e n t   = =   " . " :   r e t u r n   "   " . j o i n   r e s u l t                i f   " . "   w e ' r e   d o n e  If you may know which are you want to data sort the data feeds web friend someone on trending topics as the data in Hadoop is the data science requires a book demonstrates why visualizations are but we do massive correlations across many commercial disk drives in Python language and creates more tractable form making connections then use and uses it to solve a data.  —Bigram Model  We can make the sentences less gibberishy by looking at trigrams, triplets of consecutive words.  More generally, you might look at n-grams consisting of n consecutive words, but three will be plenty for us.  Now the transitions will depend on the previous two words:  Notice that now we have to track the starting words separately. We can generate sentences in pretty much the same way:  This produces better sentences like:  t r i g r a m _ t r a n s i t i o n s   =   d e f a u l t d i c t   l i s t     s t a r t s   =   [ ]     f o r   p r e v ,   c u r r e n t ,   n e x t   i n   z i p   d o c u m e n t ,   d o c u m e n t [ 1 : ] ,   d o c u m e n t [ 2 : ]   :             i f   p r e v   = =   " . " :                                i f   t h e   p r e v i o u s   " w o r d "   w a s   a   p e r i o d                   s t a r t s . a p p e n d   c u r r e n t            t h e n   t h i s   i s   a   s t a r t   w o r d             t r i g r a m _ t r a n s i t i o n s [   p r e v ,   c u r r e n t   ] . a p p e n d   n e x t   d e f   g e n e r a t e _ u s i n g _ t r i g r a m s       - >   s t r :           c u r r e n t   =   r a n d o m . c h o i c e   s t a r t s            c h o o s e   a   r a n d o m   s t a r t i n g   w o r d           p r e v   =   " . "                                                    a n d   p r e c e d e   i t   w i t h   a   ' . '           r e s u l t   =   [ c u r r e n t ]           w h i l e   T r u e :                   n e x t _ w o r d _ c a n d i d a t e s   =   t r i g r a m _ t r a n s i t i o n s [   p r e v ,   c u r r e n t   ]                   n e x t _ w o r d   =   r a n d o m . c h o i c e   n e x t _ w o r d _ c a n d i d a t e s                       p r e v ,   c u r r e n t   =   c u r r e n t ,   n e x t _ w o r d                   r e s u l t . a p p e n d   c u r r e n t                       i f   c u r r e n t   = =   " . " :                           r e t u r n   "   " . j o i n   r e s u l t    In hindsight MapReduce seems like an epidemic and if so does that give us new insights into how economies work That’s not a question we could even have asked a few years there has been instrumented.  —Trigram Model  Of course, they sound better because at each step the generation process has fewer choices, and at many steps only a single choice. This means that we frequently generate sentences  or at least long phrases  that were seen verbatim in the original data. Having more data would help; it would also work better if we collected n-grams from multiple essays about data science.  Grammars A different approach to modeling language is with grammars, rules for generating acceptable sentences. In elementary school, you probably learned about parts of speech and how to combine them. For example, if you had a really bad English teacher, you might say that a sentence necessarily consists of a noun followed by a verb. If you then have a list of nouns and verbs, you can generate sentences according to the rule. We’ll define a slightly more complicated grammar:  f r o m   t y p i n g   i m p o r t   L i s t ,   D i c t        T y p e   a l i a s   t o   r e f e r   t o   g r a m m a r s   l a t e r   G r a m m a r   =   D i c t [ s t r ,   L i s t [ s t r ] ]     g r a m m a r   =   {           " _ S "     :   [ " _ N P   _ V P " ] ,           " _ N P "   :   [ " _ N " ,                             " _ A   _ N P   _ P   _ A   _ N " ] ,           " _ V P "   :   [ " _ V " ,                             " _ V   _ N P " ] ,           " _ N "     :   [ " d a t a   s c i e n c e " ,   " P y t h o n " ,   " r e g r e s s i o n " ] ,           " _ A "     :   [ " b i g " ,   " l i n e a r " ,   " l o g i s t i c " ] ,           " _ P "     :   [ " a b o u t " ,   " n e a r " ] ,           " _ V "     :   [ " l e a r n s " ,   " t r a i n s " ,   " t e s t s " ,   " i s " ]   }  "  “verb phrase”  rule.  " is the “sentence” rule, which produces an "  I made up the convention that names starting with underscores refer to rules that need further expanding, and that other names are terminals that don’t need further processing. So, for example, "  “noun phrase”  rule followed by a " The verb phrase rule can produce either the " rule followed by the noun phrase rule. Notice that the " Grammars can be recursive, which allows even finite grammars like this to generate infinitely many different sentences. How do we generate sentences from this grammar? We’ll start with a list containing the sentence rule [ each rule by replacing it with a randomly chosen one of its productions. We stop when we have a list consisting solely of terminals. For example, one such progression might look like:  " rule contains itself in one of its productions.  ]. And then we’ll repeatedly expand  "  “verb”  rule, or the verb  How do we implement this? Well, to start, we’ll create a simple helper function to identify terminals:  _ S _ N P " _ V P _ V _ N P " _ S " [ ' _ S ' ]   [ ' _ N P ' , ' _ V P ' ]   [ ' _ N ' , ' _ V P ' ]   [ ' P y t h o n ' , ' _ V P ' ]   [ ' P y t h o n ' , ' _ V ' , ' _ N P ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' _ N P ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' _ A ' , ' _ N P ' , ' _ P ' , ' _ A ' , ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' _ N P ' , ' _ P ' , ' _ A ' , ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' _ N ' , ' _ P ' , ' _ A ' , ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' d a t a   s c i e n c e ' , ' _ P ' , ' _ A ' , ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' d a t a   s c i e n c e ' , ' a b o u t ' , ' _ A ' ,   ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' d a t a   s c i e n c e ' , ' a b o u t ' , ' l o g i s t i c ' , ' _ N ' ]   [ ' P y t h o n ' , ' t r a i n s ' , ' l o g i s t i c ' , ' d a t a   s c i e n c e ' , ' a b o u t ' , ' l o g i s t i c ' , ' P y t h o n ' ] d e f   i s _ t e r m i n a l   t o k e n :   s t r     - >   b o o l :           r e t u r n   t o k e n [ 0 ]   ! =   " _ "  Next we need to write a function to turn a list of tokens into a sentence. We’ll look for the first nonterminal token. If we can’t find one, that means we have a completed sentence and we’re done. If we do find a nonterminal, then we randomly choose one of its productions. If that production is a terminal  i.e., a word , we simply replace the token with it. Otherwise, it’s a sequence of space-separated nonterminal tokens that we need to s tokens. Either way, we repeat the process on the new set of tokens. Putting it all together, we get:  t and then splice into the current  And now we can start generating sentences:  Try changing the grammar—add more words, add more rules, add your own parts of speech—until you’re ready to generate as many web pages as your company needs.  p l i d e f   e x p a n d   g r a m m a r :   G r a m m a r ,   t o k e n s :   L i s t [ s t r ]     - >   L i s t [ s t r ] :           f o r   i ,   t o k e n   i n   e n u m e r a t e   t o k e n s   :                      I f   t h i s   i s   a   t e r m i n a l   t o k e n ,   s k i p   i t .                   i f   i s _ t e r m i n a l   t o k e n   :   c o n t i n u e                        O t h e r w i s e ,   i t ' s   a   n o n t e r m i n a l   t o k e n ,                      s o   w e   n e e d   t o   c h o o s e   a   r e p l a c e m e n t   a t   r a n d o m .                   r e p l a c e m e n t   =   r a n d o m . c h o i c e   g r a m m a r [ t o k e n ]                       i f   i s _ t e r m i n a l   r e p l a c e m e n t   :                           t o k e n s [ i ]   =   r e p l a c e m e n t                   e l s e :                              R e p l a c e m e n t   c o u l d   b e ,   e . g . ,   " _ N P   _ V P " ,   s o   w e   n e e d   t o                              s p l i t   i t   o n   s p a c e s   a n d   s p l i c e   i t   i n .                           t o k e n s   =   t o k e n s [ : i ]   +   r e p l a c e m e n t . s p l i t       +   t o k e n s [   i + 1   : ]                        N o w   c a l l   e x p a n d   o n   t h e   n e w   l i s t   o f   t o k e n s .                   r e t u r n   e x p a n d   g r a m m a r ,   t o k e n s                  I f   w e   g e t   h e r e ,   w e   h a d   a l l   t e r m i n a l s   a n d   a r e   d o n e .           r e t u r n   t o k e n s d e f   g e n e r a t e _ s e n t e n c e   g r a m m a r :   G r a m m a r     - >   L i s t [ s t r ] :           r e t u r n   e x p a n d   g r a m m a r ,   [ " _ S " ]    Grammars are actually more interesting when they’re used in the other direction. Given a sentence, we can use a grammar to parse the sentence. This then allows us to identify subjects and verbs and helps us make sense of the sentence. Using data science to generate text is a neat trick; using it to understand text is more magical.  See “For Further Exploration” for libraries that you could use for this.   An Aside: Gibbs Sampling Generating samples from some distributions is easy. We can get uniform random variables with:  and normal random variables with:  But some distributions are harder to sample from. Gibbs sampling is a technique for generating samples from multidimensional distributions when we only know some of the conditional distributions. For example, imagine rolling two dice. Let x be the value of the first die and y be the sum of the dice, and imagine you wanted to generate lots of  x, y  pairs. In this case it’s easy to generate the samples directly:  r a n d o m . r a n d o m     i n v e r s e _ n o r m a l _ c d f   r a n d o m . r a n d o m       f r o m   t y p i n g   i m p o r t   T u p l e   i m p o r t   r a n d o m     d e f   r o l l _ a _ d i e       - >   i n t :           r e t u r n   r a n d o m . c h o i c e   [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ]       d e f   d i r e c t _ s a m p l e       - >   T u p l e [ i n t ,   i n t ] :           d 1   =   r o l l _ a _ d i e               d 2   =   r o l l _ a _ d i e               r e t u r n   d 1 ,   d 1   +   d 2  But imagine that you only knew the conditional distributions. The distribution of y conditional on x is easy—if you know the value of x, y is equally likely to be x + 1, x + 2, x + 3, x + 4, x + 5, or x + 6:  The other direction is more complicated. For example, if you know that y is 2, then necessarily x is 1  since the only way two dice can sum to 2 is if both of them are 1 . If you know y is 3, then x is equally likely to be 1 or 2. Similarly, if y is 11, then x has to be either 5 or 6:  The way Gibbs sampling works is that we start with any  valid  values for x and y and then repeatedly alternate replacing x with a random value picked conditional on y and replacing y with a random value picked conditional on x. After a number of iterations, the resulting values of x and y will represent a sample from the unconditional joint distribution:  You can check that this gives similar results to the direct sample:  d e f   r a n d o m _ y _ g i v e n _ x   x :   i n t     - >   i n t :           " " " e q u a l l y   l i k e l y   t o   b e   x   +   1 ,   x   +   2 ,   . . .   ,   x   +   6 " " "           r e t u r n   x   +   r o l l _ a _ d i e     d e f   r a n d o m _ x _ g i v e n _ y   y :   i n t     - >   i n t :           i f   y   < =   7 :                      i f   t h e   t o t a l   i s   7   o r   l e s s ,   t h e   f i r s t   d i e   i s   e q u a l l y   l i k e l y   t o   b e                      1 ,   2 ,   . . . ,     t o t a l   -   1                     r e t u r n   r a n d o m . r a n d r a n g e   1 ,   y             e l s e :                      i f   t h e   t o t a l   i s   7   o r   m o r e ,   t h e   f i r s t   d i e   i s   e q u a l l y   l i k e l y   t o   b e                        t o t a l   -   6   ,     t o t a l   -   5   ,   . . . ,   6                   r e t u r n   r a n d o m . r a n d r a n g e   y   -   6 ,   7   d e f   g i b b s _ s a m p l e   n u m _ i t e r s :   i n t   =   1 0 0     - >   T u p l e [ i n t ,   i n t ] :           x ,   y   =   1 ,   2      d o e s n ' t   r e a l l y   m a t t e r           f o r   _   i n   r a n g e   n u m _ i t e r s   :                   x   =   r a n d o m _ x _ g i v e n _ y   y                     y   =   r a n d o m _ y _ g i v e n _ x   x             r e t u r n   x ,   y d e f   c o m p a r e _ d i s t r i b u t i o n s   n u m _ s a m p l e s :   i n t   =   1 0 0 0     - >   D i c t [ i n t ,   L i s t [ i n t ] ] :           c o u n t s   =   d e f a u l t d i c t   l a m b d a :   [ 0 ,   0 ]      We’ll use this technique in the next section.  Topic Modeling When we built our “Data Scientists You May Know” recommender in Chapter 1, we simply looked for exact matches in people’s stated interests. A more sophisticated approach to understanding our users’ interests might try to identify the topics that underlie those interests. A technique called latent Dirichlet allocation  LDA  is commonly used to identify common topics in a set of documents. We’ll apply it to documents that consist of each user’s interests. LDA has some similarities to the Naive Bayes classifier we built in Chapter 13, in that it assumes a probabilistic model for documents. We’ll gloss over the hairier mathematical details, but for our purposes the model assumes that:  There is some fixed number K of topics. There is a random variable that assigns each topic an associated probability distribution over words. You should think of this distribution as the probability of seeing word w given topic k. There is another random variable that assigns each document a probability distribution over topics. You should think of this distribution as the mixture of topics in document d. Each word in a document was generated by first randomly picking a topic  from the document’s distribution of topics  and then randomly picking a word  from the topic’s distribution of words .          f o r   _   i n   r a n g e   n u m _ s a m p l e s   :                   c o u n t s [ g i b b s _ s a m p l e     ] [ 0 ]   + =   1                   c o u n t s [ d i r e c t _ s a m p l e     ] [ 1 ]   + =   1           r e t u r n   c o u n t s  In particular, we have a collection of d words. And we have a corresponding collection of d s that assigns a topic  here a number between 0 and K – 1  to each word in each document. So, the fifth word in the fourth document is:  s, each of which is a l  t of  and the topic from which that word was chosen is:  This very explicitly defines each document’s distribution over topics, and it implicitly defines each topic’s distribution over words. We can estimate the likelihood that topic 1 produces a certain word by comparing how many times topic 1 produces that word with how many times topic 1 produces any word.  Similarly, when we built a spam filter in Chapter 13, we compared how many times each word appeared in spams with the total number of words appearing in spams.  Although these topics are just numbers, we can give them descriptive names by looking at the words on which they put the heaviest weight. We just have to somehow generate the d s. This is where Gibbs sampling comes into play. We start by assigning every word in every document a topic completely at random. Now we go through each document one word at a time. For that word and document, we construct weights for each topic that depend on the  current  distribution of topics in that document and the  current  distribution of words for that topic. We then use those weights to sample a new topic for that word. If we iterate this process many times, we will end up with a joint sample from the topic–word distribution and the document– topic distribution.  o c u m e n t i s o c u m e n t _ t o p i c d o c u m e n t s [ 3 ] [ 4 ] d o c u m e n t _ t o p i c s [ 3 ] [ 4 ] o c u m e n t _ t o p i c  To start with, we’ll need a function to randomly choose an index based on an arbitrary set of weights:  For instance, if you give it weights [ will return 0, one-fifth of the time it will return 1, and three-fifths of the time it will return 2. Let’s write a test:  ], then one-fifth of the time it  Our documents are our users’ interests, which look like:  d e f   s a m p l e _ f r o m   w e i g h t s :   L i s t [ f l o a t ]     - >   i n t :           " " " r e t u r n s   i   w i t h   p r o b a b i l i t y   w e i g h t s [ i ]       s u m   w e i g h t s   " " "           t o t a l   =   s u m   w e i g h t s             r n d   =   t o t a l   *   r a n d o m . r a n d o m                    u n i f o r m   b e t w e e n   0   a n d   t o t a l           f o r   i ,   w   i n   e n u m e r a t e   w e i g h t s   :                   r n d   - =   w                                                  r e t u r n   t h e   s m a l l e s t   i   s u c h   t h a t                   i f   r n d   < =   0 :   r e t u r n   i                        w e i g h t s [ 0 ]   +   . . .   +   w e i g h t s [ i ]   > =   r n d 1 ,   1 ,   3 f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r        D r a w   1 0 0 0   t i m e s   a n d   c o u n t   d r a w s   =   C o u n t e r   s a m p l e _ f r o m   [ 0 . 1 ,   0 . 1 ,   0 . 8 ]     f o r   _   i n   r a n g e   1 0 0 0       a s s e r t   1 0   <   d r a w s [ 0 ]   <   1 9 0          s h o u l d   b e   ~ 1 0 % ,   t h i s   i s   a   r e a l l y   l o o s e   t e s t   a s s e r t   1 0   <   d r a w s [ 1 ]   <   1 9 0          s h o u l d   b e   ~ 1 0 % ,   t h i s   i s   a   r e a l l y   l o o s e   t e s t   a s s e r t   6 5 0   <   d r a w s [ 2 ]   <   9 5 0        s h o u l d   b e   ~ 8 0 % ,   t h i s   i s   a   r e a l l y   l o o s e   t e s t   a s s e r t   d r a w s [ 0 ]   +   d r a w s [ 1 ]   +   d r a w s [ 2 ]   = =   1 0 0 0 d o c u m e n t s   =   [           [ " H a d o o p " ,   " B i g   D a t a " ,   " H B a s e " ,   " J a v a " ,   " S p a r k " ,   " S t o r m " ,   " C a s s a n d r a " ] ,           [ " N o S Q L " ,   " M o n g o D B " ,   " C a s s a n d r a " ,   " H B a s e " ,   " P o s t g r e s " ] ,           [ " P y t h o n " ,   " s c i k i t - l e a r n " ,   " s c i p y " ,   " n u m p y " ,   " s t a t s m o d e l s " ,   " p a n d a s " ] ,           [ " R " ,   " P y t h o n " ,   " s t a t i s t i c s " ,   " r e g r e s s i o n " ,   " p r o b a b i l i t y " ] ,           [ " m a c h i n e   l e a r n i n g " ,   " r e g r e s s i o n " ,   " d e c i s i o n   t r e e s " ,   " l i b s v m " ] ,           [ " P y t h o n " ,   " R " ,   " J a v a " ,   " C + + " ,   " H a s k e l l " ,   " p r o g r a m m i n g   l a n g u a g e s " ] ,           [ " s t a t i s t i c s " ,   " p r o b a b i l i t y " ,   " m a t h e m a t i c s " ,   " t h e o r y " ] ,           [ " m a c h i n e   l e a r n i n g " ,   " s c i k i t - l e a r n " ,   " M a h o u t " ,   " n e u r a l   n e t w o r k s " ] ,           [ " n e u r a l   n e t w o r k s " ,   " d e e p   l e a r n i n g " ,   " B i g   D a t a " ,   " a r t i f i c i a l   i n t e l l i g e n c e " ] ,           [ " H a d o o p " ,   " J a v a " ,   " M a p R e d u c e " ,   " B i g   D a t a " ] ,           [ " s t a t i s t i c s " ,   " R " ,   " s t a t s m o d e l s " ] ,           [ " C + + " ,   " d e e p   l e a r n i n g " ,   " a r t i f i c i a l   i n t e l l i g e n c e " ,   " p r o b a b i l i t y " ] ,           [ " p a n d a s " ,   " R " ,   " P y t h o n " ] ,           [ " d a t a b a s e s " ,   " H B a s e " ,   " P o s t g r e s " ,   " M y S Q L " ,   " M o n g o D B " ] ,    And we’ll try to find:  topics. In order to calculate the sampling weights, we’ll need to keep track of several counts. Let’s first create the data structures for them.  How many times each topic is assigned to each document:  How many times each word is assigned to each topic:  The total number of words assigned to each topic:  The total number of words contained in each document:  The number of distinct words:          [ " l i b s v m " ,   " r e g r e s s i o n " ,   " s u p p o r t   v e c t o r   m a c h i n e s " ]   ] K   =   4    a   l i s t   o f   C o u n t e r s ,   o n e   f o r   e a c h   d o c u m e n t   d o c u m e n t _ t o p i c _ c o u n t s   =   [ C o u n t e r       f o r   _   i n   d o c u m e n t s ]    a   l i s t   o f   C o u n t e r s ,   o n e   f o r   e a c h   t o p i c   t o p i c _ w o r d _ c o u n t s   =   [ C o u n t e r       f o r   _   i n   r a n g e   K   ]    a   l i s t   o f   n u m b e r s ,   o n e   f o r   e a c h   t o p i c   t o p i c _ c o u n t s   =   [ 0   f o r   _   i n   r a n g e   K   ]    a   l i s t   o f   n u m b e r s ,   o n e   f o r   e a c h   d o c u m e n t   d o c u m e n t _ l e n g t h s   =   [ l e n   d o c u m e n t     f o r   d o c u m e n t   i n   d o c u m e n t s ] d i s t i n c t _ w o r d s   =   s e t   w o r d   f o r   d o c u m e n t   i n   d o c u m e n t s   f o r   w o r d   i n   d o c u m e n t     W   =   l e n   d i s t i n c t _ w o r d s    And the number of documents:  Once we populate these, we can find, for example, the number of words in  ] associated with topic 1 as follows:  And we can find the number of times nlp is associated with topic 2 as follows:  Now we’re ready to define our conditional probability functions. As in Chapter 13, each has a smoothing term that ensures every topic has a nonzero chance of being chosen in any document and that every word has a nonzero chance of being chosen for any topic:  We’ll use these to create the weights for updating topics:  D   =   l e n   d o c u m e n t s   d o c u m e n t s [ 3 d o c u m e n t _ t o p i c _ c o u n t s [ 3 ] [ 1 ] t o p i c _ w o r d _ c o u n t s [ 2 ] [ " n l p " ] d e f   p _ t o p i c _ g i v e n _ d o c u m e n t   t o p i c :   i n t ,   d :   i n t ,   a l p h a :   f l o a t   =   0 . 1     - >   f l o a t :           " " "           T h e   f r a c t i o n   o f   w o r d s   i n   d o c u m e n t   ' d '           t h a t   a r e   a s s i g n e d   t o   ' t o p i c '     p l u s   s o m e   s m o o t h i n g             " " "           r e t u r n       d o c u m e n t _ t o p i c _ c o u n t s [ d ] [ t o p i c ]   +   a l p h a                                   d o c u m e n t _ l e n g t h s [ d ]   +   K   *   a l p h a         d e f   p _ w o r d _ g i v e n _ t o p i c   w o r d :   s t r ,   t o p i c :   i n t ,   b e t a :   f l o a t   =   0 . 1     - >   f l o a t :           " " "           T h e   f r a c t i o n   o f   w o r d s   a s s i g n e d   t o   ' t o p i c '           t h a t   e q u a l   ' w o r d '     p l u s   s o m e   s m o o t h i n g             " " "           r e t u r n       t o p i c _ w o r d _ c o u n t s [ t o p i c ] [ w o r d ]   +   b e t a                                   t o p i c _ c o u n t s [ t o p i c ]   +   W   *   b e t a     d e f   t o p i c _ w e i g h t   d :   i n t ,   w o r d :   s t r ,   k :   i n t     - >   f l o a t :           " " "           G i v e n   a   d o c u m e n t   a n d   a   w o r d   i n   t h a t   d o c u m e n t ,    t is defined the  There are solid mathematical reasons why t way it is, but their details would lead us too far afield. Hopefully it makes at least intuitive sense that—given a word and its document—the likelihood of any topic choice depends on both how likely that topic is for the document and how likely that word is for the topic. This is all the machinery we need. We start by assigning every word to a random topic and populating our counters appropriately:  Our goal is to get a joint sample of the topics–word distribution and the documents–topic distribution. We do this using a form of Gibbs sampling that uses the conditional probabilities defined previously:          r e t u r n   t h e   w e i g h t   f o r   t h e   k t h   t o p i c           " " "           r e t u r n   p _ w o r d _ g i v e n _ t o p i c   w o r d ,   k     *   p _ t o p i c _ g i v e n _ d o c u m e n t   k ,   d       d e f   c h o o s e _ n e w _ t o p i c   d :   i n t ,   w o r d :   s t r     - >   i n t :           r e t u r n   s a m p l e _ f r o m   [ t o p i c _ w e i g h t   d ,   w o r d ,   k                                                     f o r   k   i n   r a n g e   K   ]   o p i c _ w e i g h r a n d o m . s e e d   0     d o c u m e n t _ t o p i c s   =   [ [ r a n d o m . r a n d r a n g e   K     f o r   w o r d   i n   d o c u m e n t ]                                         f o r   d o c u m e n t   i n   d o c u m e n t s ]     f o r   d   i n   r a n g e   D   :           f o r   w o r d ,   t o p i c   i n   z i p   d o c u m e n t s [ d ] ,   d o c u m e n t _ t o p i c s [ d ]   :                   d o c u m e n t _ t o p i c _ c o u n t s [ d ] [ t o p i c ]   + =   1                   t o p i c _ w o r d _ c o u n t s [ t o p i c ] [ w o r d ]   + =   1                   t o p i c _ c o u n t s [ t o p i c ]   + =   1 i m p o r t   t q d m     f o r   i t e r   i n   t q d m . t r a n g e   1 0 0 0   :           f o r   d   i n   r a n g e   D   :                   f o r   i ,     w o r d ,   t o p i c     i n   e n u m e r a t e   z i p   d o c u m e n t s [ d ] ,                                                                                               d o c u m e n t _ t o p i c s [ d ]     :                                r e m o v e   t h i s   w o r d       t o p i c   f r o m   t h e   c o u n t s                              s o   t h a t   i t   d o e s n ' t   i n f l u e n c e   t h e   w e i g h t s                           d o c u m e n t _ t o p i c _ c o u n t s [ d ] [ t o p i c ]   - =   1                           t o p i c _ w o r d _ c o u n t s [ t o p i c ] [ w o r d ]   - =   1    What are the topics? They’re just numbers 0, 1, 2, and 3. If we want names for them, we have to do that ourselves. Let’s look at the five most heavily weighted words for each  Table 21-1 :  Table 21-1. Most common words per topic Topic 3 Topic 0  Topic 1  Topic 2  Java  Big Data  Hadoop  R  HBase  regression  statistics  Postgres  libsvm  Python  MongoDB scikit-learn  deep learning  probability Cassandra machine learning  artificial intelligence pandas  NoSQL  neural networks  Based on these I’d probably assign topic names:                          t o p i c _ c o u n t s [ t o p i c ]   - =   1                           d o c u m e n t _ l e n g t h s [ d ]   - =   1                                c h o o s e   a   n e w   t o p i c   b a s e d   o n   t h e   w e i g h t s                           n e w _ t o p i c   =   c h o o s e _ n e w _ t o p i c   d ,   w o r d                             d o c u m e n t _ t o p i c s [ d ] [ i ]   =   n e w _ t o p i c                                a n d   n o w   a d d   i t   b a c k   t o   t h e   c o u n t s                           d o c u m e n t _ t o p i c _ c o u n t s [ d ] [ n e w _ t o p i c ]   + =   1                           t o p i c _ w o r d _ c o u n t s [ n e w _ t o p i c ] [ w o r d ]   + =   1                           t o p i c _ c o u n t s [ n e w _ t o p i c ]   + =   1                           d o c u m e n t _ l e n g t h s [ d ]   + =   1 f o r   k ,   w o r d _ c o u n t s   i n   e n u m e r a t e   t o p i c _ w o r d _ c o u n t s   :           f o r   w o r d ,   c o u n t   i n   w o r d _ c o u n t s . m o s t _ c o m m o n     :                   i f   c o u n t   >   0 :                           p r i n t   k ,   w o r d ,   c o u n t   t o p i c _ n a m e s   =   [ " B i g   D a t a   a n d   p r o g r a m m i n g   l a n g u a g e s " ,                                 " P y t h o n   a n d   s t a t i s t i c s " ,                                 " d a t a b a s e s " ,                                 " m a c h i n e   l e a r n i n g " ]  at which point we can see how the model assigns topics to each user’s interests:  which gives:  and so on. Given the “ands” we needed in some of our topic names, it’s possible we should use more topics, although most likely we don’t have enough data to successfully learn them.  Word Vectors A lot of recent advances in NLP involve deep learning. In the rest of this chapter we’ll look at a couple of them using the machinery we developed in Chapter 19. One important innovation involves representing words as low-dimensional vectors. These vectors can be compared, added together, fed into machine learning models, or anything else you want to do with them. They usually have nice properties; for example, similar words tend to have similar vectors. That is, typically the word vector for big is pretty close to the word vector for large, so that a model operating on word vectors can  to some degree  handle things like synonymy for free.  f o r   d o c u m e n t ,   t o p i c _ c o u n t s   i n   z i p   d o c u m e n t s ,   d o c u m e n t _ t o p i c _ c o u n t s   :           p r i n t   d o c u m e n t             f o r   t o p i c ,   c o u n t   i n   t o p i c _ c o u n t s . m o s t _ c o m m o n     :                   i f   c o u n t   >   0 :                           p r i n t   t o p i c _ n a m e s [ t o p i c ] ,   c o u n t             p r i n t     [ ' H a d o o p ' ,   ' B i g   D a t a ' ,   ' H B a s e ' ,   ' J a v a ' ,   ' S p a r k ' ,   ' S t o r m ' ,   ' C a s s a n d r a ' ]   B i g   D a t a   a n d   p r o g r a m m i n g   l a n g u a g e s   4   d a t a b a s e s   3   [ ' N o S Q L ' ,   ' M o n g o D B ' ,   ' C a s s a n d r a ' ,   ' H B a s e ' ,   ' P o s t g r e s ' ]   d a t a b a s e s   5   [ ' P y t h o n ' ,   ' s c i k i t - l e a r n ' ,   ' s c i p y ' ,   ' n u m p y ' ,   ' s t a t s m o d e l s ' ,   ' p a n d a s ' ]   P y t h o n   a n d   s t a t i s t i c s   5   m a c h i n e   l e a r n i n g   1  Frequently the vectors will exhibit delightful arithmetic properties as well. For instance, in some such models if you take the vector for king, subtract the vector for man, and add the vector for woman, you will end up with a vector that’s very close to the vector for queen. It can be interesting to ponder what this means about what the word vectors actually “learn,” although we won’t spend time on that here. Coming up with such vectors for a large vocabulary of words is a difficult undertaking, so typically we’ll learn them from a corpus of text. There are a couple of different schemes, but at a high level the task typically looks something like this:  1. Get a bunch of text. 2. Create a dataset where the goal is to predict a word given nearby  words  or alternatively, to predict nearby words given a word .  3. Train a neural net to do well on this task. 4. Take the internal states of the trained neural net as the word  vectors.  In particular, because the task is to predict a word given nearby words, words that occur in similar contexts  and hence have similar nearby words  should have similar internal states and therefore similar word vectors. Here we’ll measure “similarity” using cosine similarity, which is a number between –1 and 1 that measures the degree to which two vectors point in the same direction:  f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t ,   V e c t o r   i m p o r t   m a t h     d e f   c o s i n e _ s i m i l a r i t y   v 1 :   V e c t o r ,   v 2 :   V e c t o r     - >   f l o a t :           r e t u r n   d o t   v 1 ,   v 2         m a t h . s q r t   d o t   v 1 ,   v 1     *   d o t   v 2 ,   v 2         a s s e r t   c o s i n e _ s i m i l a r i t y   [ 1 . ,   1 ,   1 ] ,   [ 2 . ,   2 ,   2 ]     = =   1 ,   " s a m e   d i r e c t i o n "   a s s e r t   c o s i n e _ s i m i l a r i t y   [ - 1 . ,   - 1 ] ,   [ 2 . ,   2 ]     = =   - 1 ,         " o p p o s i t e   d i r e c t i o n "   a s s e r t   c o s i n e _ s i m i l a r i t y   [ 1 . ,   0 ] ,   [ 0 . ,   1 ]     = =   0 ,               " o r t h o g o n a l "  Let’s learn some word vectors to see how this works. To start with, we’ll need a toy dataset. The commonly used word vectors are typically derived from training on millions or even billions of words. As our toy library can’t cope with that much data, we’ll create an artificial dataset with some structure to it:  This will generate lots of sentences with similar structure but different words; for example, “The green boat seems quite slow.” Given this setup, the colors will mostly appear in “similar” contexts, as will the nouns, and so on. So if we do a good job of assigning word vectors, the colors should get similar vectors, and so on.  NOTE  In practical usage, you’d probably have a corpus of millions of sentences, in which case you’d get “enough” context from the sentences as they are. Here, with only 50 sentences, we have to make them somewhat artificial.  c o l o r s   =   [ " r e d " ,   " g r e e n " ,   " b l u e " ,   " y e l l o w " ,   " b l a c k " ,   " " ]   n o u n s   =   [ " b e d " ,   " c a r " ,   " b o a t " ,   " c a t " ]   v e r b s   =   [ " i s " ,   " w a s " ,   " s e e m s " ]   a d v e r b s   =   [ " v e r y " ,   " q u i t e " ,   " e x t r e m e l y " ,   " " ]   a d j e c t i v e s   =   [ " s l o w " ,   " f a s t " ,   " s o f t " ,   " h a r d " ]     d e f   m a k e _ s e n t e n c e       - >   s t r :           r e t u r n   "   " . j o i n   [                   " T h e " ,                   r a n d o m . c h o i c e   c o l o r s   ,                   r a n d o m . c h o i c e   n o u n s   ,                   r a n d o m . c h o i c e   v e r b s   ,                   r a n d o m . c h o i c e   a d v e r b s   ,                   r a n d o m . c h o i c e   a d j e c t i v e s   ,                   " . "           ]       N U M _ S E N T E N C E S   =   5 0     r a n d o m . s e e d   0     s e n t e n c e s   =   [ m a k e _ s e n t e n c e       f o r   _   i n   r a n g e   N U M _ S E N T E N C E S   ]  As mentioned earlier, we’ll want to one-hot-encode our words, which means we’ll need to convert them to IDs. We’ll introduce a V class to keep track of this mapping:  These are all things we could do manually, but it’s handy to have it in a class. We should probably test it:  o c a b u l a r y f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   T e n s o r     c l a s s   V o c a b u l a r y :           d e f   _ _ i n i t _ _   s e l f ,   w o r d s :   L i s t [ s t r ]   =   N o n e     - >   N o n e :                   s e l f . w 2 i :   D i c t [ s t r ,   i n t ]   =   { }        m a p p i n g   w o r d   - >   w o r d _ i d                   s e l f . i 2 w :   D i c t [ i n t ,   s t r ]   =   { }        m a p p i n g   w o r d _ i d   - >   w o r d                     f o r   w o r d   i n     w o r d s   o r   [ ]   :              I f   w o r d s   w e r e   p r o v i d e d ,                           s e l f . a d d   w o r d                                a d d   t h e m .             @ p r o p e r t y           d e f   s i z e   s e l f     - >   i n t :                   " " " h o w   m a n y   w o r d s   a r e   i n   t h e   v o c a b u l a r y " " "                   r e t u r n   l e n   s e l f . w 2 i               d e f   a d d   s e l f ,   w o r d :   s t r     - >   N o n e :                   i f   w o r d   n o t   i n   s e l f . w 2 i :                    I f   t h e   w o r d   i s   n e w   t o   u s :                           w o r d _ i d   =   l e n   s e l f . w 2 i                F i n d   t h e   n e x t   i d .                           s e l f . w 2 i [ w o r d ]   =   w o r d _ i d            A d d   t o   t h e   w o r d   - >   w o r d _ i d   m a p .                           s e l f . i 2 w [ w o r d _ i d ]   =   w o r d            A d d   t o   t h e   w o r d _ i d   - >   w o r d   m a p .             d e f   g e t _ i d   s e l f ,   w o r d :   s t r     - >   i n t :                   " " " r e t u r n   t h e   i d   o f   t h e   w o r d     o r   N o n e   " " "                   r e t u r n   s e l f . w 2 i . g e t   w o r d               d e f   g e t _ w o r d   s e l f ,   w o r d _ i d :   i n t     - >   s t r :                   " " " r e t u r n   t h e   w o r d   w i t h   t h e   g i v e n   i d     o r   N o n e   " " "                   r e t u r n   s e l f . i 2 w . g e t   w o r d _ i d               d e f   o n e _ h o t _ e n c o d e   s e l f ,   w o r d :   s t r     - >   T e n s o r :                   w o r d _ i d   =   s e l f . g e t _ i d   w o r d                     a s s e r t   w o r d _ i d   i s   n o t   N o n e ,   f " u n k n o w n   w o r d   { w o r d } "                     r e t u r n   [ 1 . 0   i f   i   = =   w o r d _ i d   e l s e   0 . 0   f o r   i   i n   r a n g e   s e l f . s i z e   ] v o c a b   =   V o c a b u l a r y   [ " a " ,   " b " ,   " c " ]     a s s e r t   v o c a b . s i z e   = =   3 ,                             " t h e r e   a r e   3   w o r d s   i n   t h e   v o c a b "    We should also write simple helper functions to save and load a vocabulary, just as we have for our deep learning models:  We’ll be using a word vector model called skip-gram that takes as input a word and generates probabilities for what words are likely to be seen near it. We will feed it training pairs   the S y loss.    and try to minimize  NOTE  Another common model, continuous bag-of-words  CBOW , takes the nearby words as the inputs and tries to predict the original word.  Let’s design our neural network. At its heart will be an embedding layer that takes as input a word ID and returns a word vector. Under the covers we can just use a lookup table for this.  a s s e r t   v o c a b . g e t _ i d   " b "     = =   1 ,               " b   s h o u l d   h a v e   w o r d _ i d   1 "   a s s e r t   v o c a b . o n e _ h o t _ e n c o d e   " b "     = =   [ 0 ,   1 ,   0 ]   a s s e r t   v o c a b . g e t _ i d   " z "     i s   N o n e ,         " z   i s   n o t   i n   t h e   v o c a b "   a s s e r t   v o c a b . g e t _ w o r d   2     = =   " c " ,           " w o r d _ i d   2   s h o u l d   b e   c "   v o c a b . a d d   " z "     a s s e r t   v o c a b . s i z e   = =   4 ,                             " n o w   t h e r e   a r e   4   w o r d s   i n   t h e   v o c a b "   a s s e r t   v o c a b . g e t _ i d   " z "     = =   3 ,               " n o w   z   s h o u l d   h a v e   i d   3 "   a s s e r t   v o c a b . o n e _ h o t _ e n c o d e   " z "     = =   [ 0 ,   0 ,   0 ,   1 ] i m p o r t   j s o n     d e f   s a v e _ v o c a b   v o c a b :   V o c a b u l a r y ,   f i l e n a m e :   s t r     - >   N o n e :           w i t h   o p e n   f i l e n a m e ,   ' w '     a s   f :                   j s o n . d u m p   v o c a b . w 2 i ,   f                    O n l y   n e e d   t o   s a v e   w 2 i     d e f   l o a d _ v o c a b   f i l e n a m e :   s t r     - >   V o c a b u l a r y :           v o c a b   =   V o c a b u l a r y               w i t h   o p e n   f i l e n a m e     a s   f :                      L o a d   w 2 i   a n d   g e n e r a t e   i 2 w   f r o m   i t                   v o c a b . w 2 i   =   j s o n . l o a d   f                     v o c a b . i 2 w   =   { i d :   w o r d   f o r   w o r d ,   i d   i n   v o c a b . w 2 i . i t e m s     }           r e t u r n   v o c a b w o r d ,   n e a r b y _ w o r d o f t m a x C r o s s E n t r o p  r layer with the same number of  We’ll then pass the word vector to a L outputs as we have words in our vocabulary. As before, we’ll use s to convert these outputs to probabilities over nearby words. As we use gradient descent to train the model, we will be updating the vectors in the lookup table. Once we’ve finished training, that lookup table gives us our word vectors. Let’s create that embedding layer. In practice we might want to embed things other than words, so we’ll construct a more general E  Later we’ll write a T vectors.  In its constructor we’ll provide the number and dimension of our embedding vectors, so it can create the embeddings  which will be standard random normals, initially :  g subclass that’s specifically for word  g layer.  In our case we’ll only be embedding one word at a time. However, in other models we might want to embed a sequence of words and get back a sequence of word vectors.  For example, if we wanted to train the CBOW model described earlier.  So an alternative design would take sequences of word IDs. We’ll stick with one at a time, to make things simpler.  i n e a o f t m a x m b e d d i n e x t E m b e d d i n f r o m   t y p i n g   i m p o r t   I t e r a b l e   f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   L a y e r ,   T e n s o r ,   r a n d o m _ t e n s o r ,   z e r o s _ l i k e     c l a s s   E m b e d d i n g   L a y e r   :           d e f   _ _ i n i t _ _   s e l f ,   n u m _ e m b e d d i n g s :   i n t ,   e m b e d d i n g _ d i m :   i n t     - >   N o n e :                   s e l f . n u m _ e m b e d d i n g s   =   n u m _ e m b e d d i n g s                   s e l f . e m b e d d i n g _ d i m   =   e m b e d d i n g _ d i m                        O n e   v e c t o r   o f   s i z e   e m b e d d i n g _ d i m   f o r   e a c h   d e s i r e d   e m b e d d i n g                   s e l f . e m b e d d i n g s   =   r a n d o m _ t e n s o r   n u m _ e m b e d d i n g s ,   e m b e d d i n g _ d i m                     s e l f . g r a d   =   z e r o s _ l i k e   s e l f . e m b e d d i n g s                          S a v e   l a s t   i n p u t   i d                   s e l f . l a s t _ i n p u t _ i d   =   N o n e         d e f   f o r w a r d   s e l f ,   i n p u t _ i d :   i n t     - >   T e n s o r :                   " " " J u s t   s e l e c t   t h e   e m b e d d i n g   v e c t o r   c o r r e s p o n d i n g   t o   t h e   i n p u t   i d " " "                   s e l f . i n p u t _ i d   =   i n p u t _ i d            r e m e m b e r   f o r   u s e   i n   b a c k p r o p a g a t i o n    For the backward pass we’ll get a gradient corresponding to the chosen embedding vector, and we’ll need to construct the corresponding gradient for s s, which is zero for every embedding other than the chosen one:  Because we have parameters and gradients, we need to override those methods:  As mentioned earlier, we’ll want a subclass specifically for word vectors. In that case our number of embeddings is determined by our vocabulary, so let’s just pass that in instead:                    r e t u r n   s e l f . e m b e d d i n g s [ i n p u t _ i d ] e l f . e m b e d d i n g         d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r     - >   N o n e :                      Z e r o   o u t   t h e   g r a d i e n t   c o r r e s p o n d i n g   t o   t h e   l a s t   i n p u t .                      T h i s   i s   w a y   c h e a p e r   t h a n   c r e a t i n g   a   n e w   a l l - z e r o   t e n s o r   e a c h   t i m e .                   i f   s e l f . l a s t _ i n p u t _ i d   i s   n o t   N o n e :                           z e r o _ r o w   =   [ 0   f o r   _   i n   r a n g e   s e l f . e m b e d d i n g _ d i m   ]                           s e l f . g r a d [ s e l f . l a s t _ i n p u t _ i d ]   =   z e r o _ r o w                     s e l f . l a s t _ i n p u t _ i d   =   s e l f . i n p u t _ i d                   s e l f . g r a d [ s e l f . i n p u t _ i d ]   =   g r a d i e n t         d e f   p a r a m s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . e m b e d d i n g s ]             d e f   g r a d s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . g r a d ] c l a s s   T e x t E m b e d d i n g   E m b e d d i n g   :           d e f   _ _ i n i t _ _   s e l f ,   v o c a b :   V o c a b u l a r y ,   e m b e d d i n g _ d i m :   i n t     - >   N o n e :                      C a l l   t h e   s u p e r c l a s s   c o n s t r u c t o r                   s u p e r     . _ _ i n i t _ _   v o c a b . s i z e ,   e m b e d d i n g _ d i m                          A n d   h a n g   o n t o   t h e   v o c a b                   s e l f . v o c a b   =   v o c a b  The other built-in methods will all work as is, but we’ll add a couple more methods specific to working with text. For example, we’d like to be able to retrieve the vector for a given word.  This is not part of the L r interface, but we are always free to add extra methods to specific layers as we like.   This dunder method will allow us to retrieve word vectors using indexing:  And we’d also like the embedding layer to tell us the closest words to a given word:  Our embedding layer just outputs vectors, which we can feed into a L layer. Now we’re ready to assemble our training data. For each input word, we’ll choose as target words the two words to its left and the two words to its right. Let’s start by lowercasing the sentences and splitting them into words:  a y e         d e f   _ _ g e t i t e m _ _   s e l f ,   w o r d :   s t r     - >   T e n s o r :                   w o r d _ i d   =   s e l f . v o c a b . g e t _ i d   w o r d                     i f   w o r d _ i d   i s   n o t   N o n e :                           r e t u r n   s e l f . e m b e d d i n g s [ w o r d _ i d ]                   e l s e :                           r e t u r n   N o n e w o r d _ v e c t o r   =   e m b e d d i n g [ " b l a c k " ]         d e f   c l o s e s t   s e l f ,   w o r d :   s t r ,   n :   i n t   =   5     - >   L i s t [ T u p l e [ f l o a t ,   s t r ] ] :                   " " " R e t u r n s   t h e   n   c l o s e s t   w o r d s   b a s e d   o n   c o s i n e   s i m i l a r i t y " " "                   v e c t o r   =   s e l f [ w o r d ]                        C o m p u t e   p a i r s     s i m i l a r i t y ,   o t h e r _ w o r d   ,   a n d   s o r t   m o s t   s i m i l a r   f i r s t                   s c o r e s   =   [   c o s i n e _ s i m i l a r i t y   v e c t o r ,   s e l f . e m b e d d i n g s [ i ]   ,   o t h e r _ w o r d                                         f o r   o t h e r _ w o r d ,   i   i n   s e l f . v o c a b . w 2 i . i t e m s     ]                   s c o r e s . s o r t   r e v e r s e = T r u e                       r e t u r n   s c o r e s [ : n ] i n e a r  at which point we can construct a vocabulary:  And now we can create training data:  With the machinery we’ve built up, it’s now easy to create our model:  i m p o r t   r e        T h i s   i s   n o t   a   g r e a t   r e g e x ,   b u t   i t   w o r k s   o n   o u r   d a t a .   t o k e n i z e d _ s e n t e n c e s   =   [ r e . f i n d a l l   " [ a - z ] +  [ . ] " ,   s e n t e n c e . l o w e r                                                       f o r   s e n t e n c e   i n   s e n t e n c e s ]    C r e a t e   a   v o c a b u l a r y     t h a t   i s ,   a   m a p p i n g   w o r d   - >   w o r d _ i d     b a s e d   o n   o u r   t e x t .   v o c a b   =   V o c a b u l a r y   w o r d                                         f o r   s e n t e n c e _ w o r d s   i n   t o k e n i z e d _ s e n t e n c e s                                         f o r   w o r d   i n   s e n t e n c e _ w o r d s   f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   T e n s o r ,   o n e _ h o t _ e n c o d e     i n p u t s :   L i s t [ i n t ]   =   [ ]   t a r g e t s :   L i s t [ T e n s o r ]   =   [ ]     f o r   s e n t e n c e   i n   t o k e n i z e d _ s e n t e n c e s :           f o r   i ,   w o r d   i n   e n u m e r a t e   s e n t e n c e   :                        F o r   e a c h   w o r d                   f o r   j   i n   [ i   -   2 ,   i   -   1 ,   i   +   1 ,   i   +   2 ] :          t a k e   t h e   n e a r b y   l o c a t i o n s                           i f   0   < =   j   <   l e n   s e n t e n c e   :                          t h a t   a r e n ' t   o u t   o f   b o u n d s                                   n e a r b y _ w o r d   =   s e n t e n c e [ j ]                    a n d   g e t   t h o s e   w o r d s .                                        A d d   a n   i n p u t   t h a t ' s   t h e   o r i g i n a l   w o r d _ i d                                   i n p u t s . a p p e n d   v o c a b . g e t _ i d   w o r d                                            A d d   a   t a r g e t   t h a t ' s   t h e   o n e - h o t - e n c o d e d   n e a r b y   w o r d                                   t a r g e t s . a p p e n d   v o c a b . o n e _ h o t _ e n c o d e   n e a r b y _ w o r d     f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   S e q u e n t i a l ,   L i n e a r     r a n d o m . s e e d   0     E M B E D D I N G _ D I M   =   5        s e e m s   l i k e   a   g o o d   s i z e        D e f i n e   t h e   e m b e d d i n g   l a y e r   s e p a r a t e l y ,   s o   w e   c a n   r e f e r e n c e   i t .   e m b e d d i n g   =   T e x t E m b e d d i n g   v o c a b = v o c a b ,   e m b e d d i n g _ d i m = E M B E D D I N G _ D I M       m o d e l   =   S e q u e n t i a l   [              G i v e n   a   w o r d     a s   a   v e c t o r   o f   w o r d _ i d s   ,   l o o k   u p   i t s   e m b e d d i n g .    Using the machinery from Chapter 19, it’s easy to train our model:  As you watch this train, you can see the colors getting closer to each other, the adjectives getting closer to each other, and the nouns getting closer to each other. Once the model is trained, it’s fun to explore the most similar words:  which  for me  results in:          e m b e d d i n g ,              A n d   u s e   a   l i n e a r   l a y e r   t o   c o m p u t e   s c o r e s   f o r   " n e a r b y   w o r d s . "           L i n e a r   i n p u t _ d i m = E M B E D D I N G _ D I M ,   o u t p u t _ d i m = v o c a b . s i z e     ]   f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   S o f t m a x C r o s s E n t r o p y ,   M o m e n t u m ,   G r a d i e n t D e s c e n t     l o s s   =   S o f t m a x C r o s s E n t r o p y       o p t i m i z e r   =   G r a d i e n t D e s c e n t   l e a r n i n g _ r a t e = 0 . 0 1       f o r   e p o c h   i n   r a n g e   1 0 0   :           e p o c h _ l o s s   =   0 . 0           f o r   i n p u t ,   t a r g e t   i n   z i p   i n p u t s ,   t a r g e t s   :                   p r e d i c t e d   =   m o d e l . f o r w a r d   i n p u t                     e p o c h _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   t a r g e t                     g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   t a r g e t                     m o d e l . b a c k w a r d   g r a d i e n t                     o p t i m i z e r . s t e p   m o d e l             p r i n t   e p o c h ,   e p o c h _ l o s s                              P r i n t   t h e   l o s s           p r i n t   e m b e d d i n g . c l o s e s t   " b l a c k "              a n d   a l s o   a   f e w   n e a r e s t   w o r d s           p r i n t   e m b e d d i n g . c l o s e s t   " s l o w "                s o   w e   c a n   s e e   w h a t ' s   b e i n g           p r i n t   e m b e d d i n g . c l o s e s t   " c a r "                  l e a r n e d . p a i r s   =   [   c o s i n e _ s i m i l a r i t y   e m b e d d i n g [ w 1 ] ,   e m b e d d i n g [ w 2 ]   ,   w 1 ,   w 2                       f o r   w 1   i n   v o c a b . w 2 i                     f o r   w 2   i n   v o c a b . w 2 i                     i f   w 1   <   w 2 ]   p a i r s . s o r t   r e v e r s e = T r u e     p r i n t   p a i r s [ : 5 ]   [   0 . 9 9 8 0 2 8 3 5 5 4 8 6 4 8 1 5 ,   ' b o a t ' ,   ' c a r '   ,       0 . 9 9 7 5 1 4 7 7 4 4 5 8 7 7 0 6 ,   ' b e d ' ,   ' c a t '   ,     Obviously bed and cat are not really similar, but in our training sentences they appear to be, and that’s what the model is capturing.  We can also extract the first two principal components and plot them:  which shows that similar words are indeed clustering together  Figure 21- 3 :      0 . 9 9 5 3 1 5 3 4 4 1 2 1 8 0 5 4 ,   ' s e e m s ' ,   ' w a s '   ,       0 . 9 9 2 7 1 0 7 4 4 0 3 7 7 9 7 5 ,   ' e x t r e m e l y ' ,   ' q u i t e '   ,       0 . 9 8 3 6 1 8 3 6 5 8 4 1 5 9 8 7 ,   ' b e d ' ,   ' c a r '   ] f r o m   s c r a t c h . w o r k i n g _ w i t h _ d a t a   i m p o r t   p c a ,   t r a n s f o r m   i m p o r t   m a t p l o t l i b . p y p l o t   a s   p l t        E x t r a c t   t h e   f i r s t   t w o   p r i n c i p a l   c o m p o n e n t s   a n d   t r a n s f o r m   t h e   w o r d   v e c t o r s   c o m p o n e n t s   =   p c a   e m b e d d i n g . e m b e d d i n g s ,   2     t r a n s f o r m e d   =   t r a n s f o r m   e m b e d d i n g . e m b e d d i n g s ,   c o m p o n e n t s          S c a t t e r   t h e   p o i n t s     a n d   m a k e   t h e m   w h i t e   s o   t h e y ' r e   " i n v i s i b l e "     f i g ,   a x   =   p l t . s u b p l o t s       a x . s c a t t e r   * z i p   * t r a n s f o r m e d   ,   m a r k e r = ' . ' ,   c o l o r = ' w '          A d d   a n n o t a t i o n s   f o r   e a c h   w o r d   a t   i t s   t r a n s f o r m e d   l o c a t i o n   f o r   w o r d ,   i d x   i n   v o c a b . w 2 i . i t e m s     :           a x . a n n o t a t e   w o r d ,   t r a n s f o r m e d [ i d x ]          A n d   h i d e   t h e   a x e s   a x . g e t _ x a x i s     . s e t _ v i s i b l e   F a l s e     a x . g e t _ y a x i s     . s e t _ v i s i b l e   F a l s e       p l t . s h o w      Figure 21-3. Word vectors  m?  that takes a list of vectors and  If you’re interested, it’s not hard to train CBOW word vectors. You’ll have to do a little work. First, you’ll need to modify the E g layer so that it takes as input a list of IDs and outputs a list of embedding vectors. Then you’ll have to create a new layer  S returns their sum. Each word represents a training example where the input is the word IDs for the surrounding words, and the target is the one-hot encoding of the word itself. The modified E vectors, the new S vector, and then a L xed to get a distribution representing “most likely words, given this context.”  g layer turns the surrounding words into a list of m layer collapses the list of vectors down to a single  r layer can produce scores that can be s  m b e d d i n u m b e d d i n u i n e a o f t m a  I found the CBOW model harder to train than the skip-gram one, but I encourage you to try it out.  Recurrent Neural Networks The word vectors we developed in the previous section are often used as the inputs to neural networks. One challenge to doing this is that sentences have varying lengths: you could think of a 3-word sentence as a [  ] tensor and a 10-word sentence as a [ ] tensor. In order to, say, pass them to a L  r layer, we  m layer  or a variant that takes the average ;  need to do something about that first variable-length dimension. One option is to use a S however, the order of the words in a sentence is usually important to its meaning. To take a common example, “dog bites man” and “man bites dog” are two very different stories! Another way of handling this is using recurrent neural networks  RNNs , which have a hidden state they maintain between inputs. In the simplest case, each input is combined with the current hidden state to produce an output, which is then used as the new hidden state. This allows such networks to “remember”  in a sense  the inputs they’ve seen, and to build up to a final output that depends on all the inputs and their order. We’ll create pretty much the simplest possible RNN layer, which will accept a single input  corresponding to, e.g., a single word in a sentence, or a single character in a word , and which will maintain its hidden state between calls. Recall that our L vector i  r layer had some weights, w, and a bias, b. It took a t using the logic:  t and produced a different vector as o  Here we’ll want to incorporate our hidden state, so we’ll have two sets of weights—one to apply to the i  t and one to apply to the previous  3 , e m b e d d i n g _ d i m 1 0 , e m b e d d i n g _ d i m i n e a u i n e a n p u u t p u o u t p u t [ o ]   =   d o t   w [ o ] ,   i n p u t     +   b [ o ] n p u  n state:  Next, we’ll use the o huge change, but it will allow our networks to do wonderful things.  t vector as the new value of h  n. This isn’t a  You can see that we start out the hidden state as a vector of 0s, and we provide a function that people using the network can call to reset the hidden state. Given this setup, the f least, it is if you remember and understand how our L  d function is reasonably straightforward  at  r layer worked :  h i d d e o u t p u t [ o ]   =   d o t   w [ o ] ,   i n p u t     +   d o t   u [ o ] ,   h i d d e n     +   b [ o ] u t p u i d d e f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   t e n s o r _ a p p l y ,   t a n h     c l a s s   S i m p l e R n n   L a y e r   :           " " " J u s t   a b o u t   t h e   s i m p l e s t   p o s s i b l e   r e c u r r e n t   l a y e r . " " "           d e f   _ _ i n i t _ _   s e l f ,   i n p u t _ d i m :   i n t ,   h i d d e n _ d i m :   i n t     - >   N o n e :                   s e l f . i n p u t _ d i m   =   i n p u t _ d i m                   s e l f . h i d d e n _ d i m   =   h i d d e n _ d i m                     s e l f . w   =   r a n d o m _ t e n s o r   h i d d e n _ d i m ,   i n p u t _ d i m ,   i n i t = ' x a v i e r '                     s e l f . u   =   r a n d o m _ t e n s o r   h i d d e n _ d i m ,   h i d d e n _ d i m ,   i n i t = ' x a v i e r '                     s e l f . b   =   r a n d o m _ t e n s o r   h i d d e n _ d i m                       s e l f . r e s e t _ h i d d e n _ s t a t e                 d e f   r e s e t _ h i d d e n _ s t a t e   s e l f     - >   N o n e :                   s e l f . h i d d e n   =   [ 0   f o r   _   i n   r a n g e   s e l f . h i d d e n _ d i m   ] o r w a r i n e a         d e f   f o r w a r d   s e l f ,   i n p u t :   T e n s o r     - >   T e n s o r :                   s e l f . i n p u t   =   i n p u t                                S a v e   b o t h   i n p u t   a n d   p r e v i o u s                   s e l f . p r e v _ h i d d e n   =   s e l f . h i d d e n        h i d d e n   s t a t e   t o   u s e   i n   b a c k p r o p .                     a   =   [   d o t   s e l f . w [ h ] ,   i n p u t     +                          w e i g h t s   @   i n p u t                               d o t   s e l f . u [ h ] ,   s e l f . h i d d e n     +              w e i g h t s   @   h i d d e n                               s e l f . b [ h ]                                                      b i a s                             f o r   h   i n   r a n g e   s e l f . h i d d e n _ d i m   ]                     s e l f . h i d d e n   =   t e n s o r _ a p p l y   t a n h ,   a          A p p l y   t a n h   a c t i v a t i o n                   r e t u r n   s e l f . h i d d e n                                          a n d   r e t u r n   t h e   r e s u l t .  The b needs to compute an additional set of gradients for the u weights:  d pass is similar to the one in our L  r layer, except that it  And finally we need to override the p  s and g  s methods:  This “simple” RNN is so simple that you probably shouldn’t use it in practice.  WARNING  a c k w a r i n e a         d e f   b a c k w a r d   s e l f ,   g r a d i e n t :   T e n s o r   :                      B a c k p r o p a g a t e   t h r o u g h   t h e   t a n h                   a _ g r a d   =   [ g r a d i e n t [ h ]   *     1   -   s e l f . h i d d e n [ h ]   * *   2                                         f o r   h   i n   r a n g e   s e l f . h i d d e n _ d i m   ]                        b   h a s   t h e   s a m e   g r a d i e n t   a s   a                   s e l f . b _ g r a d   =   a _ g r a d                        E a c h   w [ h ] [ i ]   i s   m u l t i p l i e d   b y   i n p u t [ i ]   a n d   a d d e d   t o   a [ h ] ,                      s o   e a c h   w _ g r a d [ h ] [ i ]   =   a _ g r a d [ h ]   *   i n p u t [ i ]                   s e l f . w _ g r a d   =   [ [ a _ g r a d [ h ]   *   s e l f . i n p u t [ i ]                                                   f o r   i   i n   r a n g e   s e l f . i n p u t _ d i m   ]                                                 f o r   h   i n   r a n g e   s e l f . h i d d e n _ d i m   ]                        E a c h   u [ h ] [ h 2 ]   i s   m u l t i p l i e d   b y   h i d d e n [ h 2 ]   a n d   a d d e d   t o   a [ h ] ,                      s o   e a c h   u _ g r a d [ h ] [ h 2 ]   =   a _ g r a d [ h ]   *   p r e v _ h i d d e n [ h 2 ]                   s e l f . u _ g r a d   =   [ [ a _ g r a d [ h ]   *   s e l f . p r e v _ h i d d e n [ h 2 ]                                                   f o r   h 2   i n   r a n g e   s e l f . h i d d e n _ d i m   ]                                                 f o r   h   i n   r a n g e   s e l f . h i d d e n _ d i m   ]                        E a c h   i n p u t [ i ]   i s   m u l t i p l i e d   b y   e v e r y   w [ h ] [ i ]   a n d   a d d e d   t o   a [ h ] ,                      s o   e a c h   i n p u t _ g r a d [ i ]   =   s u m   a _ g r a d [ h ]   *   w [ h ] [ i ]   f o r   h   i n   . . .                     r e t u r n   [ s u m   a _ g r a d [ h ]   *   s e l f . w [ h ] [ i ]   f o r   h   i n   r a n g e   s e l f . h i d d e n _ d i m                                       f o r   i   i n   r a n g e   s e l f . i n p u t _ d i m   ] a r a m r a d         d e f   p a r a m s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . w ,   s e l f . u ,   s e l f . b ]             d e f   g r a d s   s e l f     - >   I t e r a b l e [ T e n s o r ] :                   r e t u r n   [ s e l f . w _ g r a d ,   s e l f . u _ g r a d ,   s e l f . b _ g r a d ]  Our S n has a couple of undesirable features. One is that its entire hidden state is used to update the input every time you call it. The other is that the entire hidden state is overwritten every time you call it. Both of these make it difficult to train; in particular, they make it difficult for the model to learn long-range dependencies. For this reason, almost no one uses this kind of simple RNN. Instead, they use more complicated variants like the LSTM  “long short-term memory”  or the GRU  “gated recurrent unit” , which have many more parameters and use parameterized “gates” that allow only some of the state to be updated  and only some of the state to be used  at each timestep. There is nothing particularly difficult about these variants; however, they involve a great deal more code, which would not be  in my opinion  correspondingly more edifying to read. The code for this chapter on GitHub includes an LSTM implementation. I encourage you to check it out, but it’s somewhat tedious and so we won’t discuss it further here. One other quirk of our implementation is that it takes only one “step” at a time and requires us to manually reset the hidden state. A more practical RNN implementation might accept sequences of inputs, set its hidden state to 0s at the beginning of each sequence, and produce sequences of outputs. Ours could certainly be modified to behave this way; again, this would require more code and complexity for little gain in understanding.  Example: Using a Character-Level RNN The newly hired VP of Branding did not come up with the name DataSciencester himself, and  accordingly  he suspects that a better name might lead to more success for the company. He asks you to use data science to suggest candidates for replacement. One “cute” application of RNNs involves using characters  rather than words  as their inputs, training them to learn the subtle language patterns in some dataset, and then using them to generate fictional instances from that dataset.  i m p l e R n  For example, you could train an RNN on the names of alternative bands, use the trained model to generate new names for fake alternative bands, and then hand-select the funniest ones and share them on Twitter. Hilarity! Having seen this trick enough times to no longer consider it clever, you decide to give it a shot. After some digging, you find that the startup accelerator Y Combinator has published a list of its top 100  actually 101  most successful startups, which seems like a good starting point. Checking the page, you find that the company names all live inside < to use your web scraping skills to retrieve them:  > tags, which means it’s easy  As always, the page may change  or vanish , in which case this code won’t work. If so, you can use your newly learned data science skills to fix it or just get the list from the book’s GitHub site. So what is our plan? We’ll train a model to predict the next character of a name, given the current character and a hidden state representing all the characters we’ve seen so far. As usual, we’ll actually predict a probability distribution over characters and train our model to minimize the S Once our model is trained, we can use it to generate some probabilities, randomly sample a character according to those probabilities, and then feed that character as its next input. This will allow us to generate company names using the learned weights.  y loss.  b   c l a s s = " h 4 " f r o m   b s 4   i m p o r t   B e a u t i f u l S o u p   i m p o r t   r e q u e s t s     u r l   =   " h t t p s :     w w w . y c o m b i n a t o r . c o m   t o p c o m p a n i e s   "   s o u p   =   B e a u t i f u l S o u p   r e q u e s t s . g e t   u r l   . t e x t ,   ' h t m l 5 l i b '          W e   g e t   t h e   c o m p a n i e s   t w i c e ,   s o   u s e   a   s e t   c o m p r e h e n s i o n   t o   d e d u p l i c a t e .   c o m p a n i e s   =   l i s t   { b . t e x t                                       f o r   b   i n   s o u p   " b "                                         i f   " h 4 "   i n   b . g e t   " c l a s s " ,         }     a s s e r t   l e n   c o m p a n i e s     = =   1 0 1 o f t m a x C r o s s E n t r o p  To start with, we should build a V names:  y from the characters in the  In addition, we’ll use special tokens to signify the start and end of a company name. This allows the model to learn which characters should begin a company name and also to learn when a company name is finished. We’ll just use the regex characters for start and end, which  luckily  don’t appear in our list of companies:  For our model, we’ll one-hot-encode each character, pass it through two r layer to generate the scores for each  ns, and then use a L  possible next character:  Imagine for the moment that we’ve trained this model. Let’s write the function that uses it to generate new company names, using the  m function from “Topic Modeling”:  o c a b u l a r v o c a b   =   V o c a b u l a r y   [ c   f o r   c o m p a n y   i n   c o m p a n i e s   f o r   c   i n   c o m p a n y ]   S T A R T   =   " ^ "   S T O P   =   " $ "        W e   n e e d   t o   a d d   t h e m   t o   t h e   v o c a b u l a r y   t o o .   v o c a b . a d d   S T A R T     v o c a b . a d d   S T O P   S i m p l e R n i n e a H I D D E N _ D I M   =   3 2        Y o u   s h o u l d   e x p e r i m e n t   w i t h   d i f f e r e n t   s i z e s !     r n n 1   =     S i m p l e R n n   i n p u t _ d i m = v o c a b . s i z e ,   h i d d e n _ d i m = H I D D E N _ D I M     r n n 2   =     S i m p l e R n n   i n p u t _ d i m = H I D D E N _ D I M ,   h i d d e n _ d i m = H I D D E N _ D I M     l i n e a r   =   L i n e a r   i n p u t _ d i m = H I D D E N _ D I M ,   o u t p u t _ d i m = v o c a b . s i z e       m o d e l   =   S e q u e n t i a l   [           r n n 1 ,           r n n 2 ,           l i n e a r   ]   s a m p l e _ f r o  At long last, we’re ready to train our character-level RNN. It will take a while!  f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   s o f t m a x     d e f   g e n e r a t e   s e e d :   s t r   =   S T A R T ,   m a x _ l e n :   i n t   =   5 0     - >   s t r :           r n n 1 . r e s e t _ h i d d e n _ s t a t e            R e s e t   b o t h   h i d d e n   s t a t e s           r n n 2 . r e s e t _ h i d d e n _ s t a t e               o u t p u t   =   [ s e e d ]                            S t a r t   t h e   o u t p u t   w i t h   t h e   s p e c i f i e d   s e e d                K e e p   g o i n g   u n t i l   w e   p r o d u c e   t h e   S T O P   c h a r a c t e r   o r   r e a c h   t h e   m a x   l e n g t h           w h i l e   o u t p u t [ - 1 ]   ! =   S T O P   a n d   l e n   o u t p u t     <   m a x _ l e n :                      U s e   t h e   l a s t   c h a r a c t e r   a s   t h e   i n p u t                   i n p u t   =   v o c a b . o n e _ h o t _ e n c o d e   o u t p u t [ - 1 ]                          G e n e r a t e   s c o r e s   u s i n g   t h e   m o d e l                   p r e d i c t e d   =   m o d e l . f o r w a r d   i n p u t                          C o n v e r t   t h e m   t o   p r o b a b i l i t i e s   a n d   d r a w   a   r a n d o m   c h a r _ i d                   p r o b a b i l i t i e s   =   s o f t m a x   p r e d i c t e d                     n e x t _ c h a r _ i d   =   s a m p l e _ f r o m   p r o b a b i l i t i e s                          A d d   t h e   c o r r e s p o n d i n g   c h a r   t o   o u r   o u t p u t                   o u t p u t . a p p e n d   v o c a b . g e t _ w o r d   n e x t _ c h a r _ i d                    G e t   r i d   o f   S T A R T   a n d   E N D   c h a r a c t e r s   a n d   r e t u r n   t h e   w o r d           r e t u r n   ' ' . j o i n   o u t p u t [ 1 : - 1 ]   l o s s   =   S o f t m a x C r o s s E n t r o p y       o p t i m i z e r   =   M o m e n t u m   l e a r n i n g _ r a t e = 0 . 0 1 ,   m o m e n t u m = 0 . 9       f o r   e p o c h   i n   r a n g e   3 0 0   :           r a n d o m . s h u f f l e   c o m p a n i e s          T r a i n   i n   a   d i f f e r e n t   o r d e r   e a c h   e p o c h .           e p o c h _ l o s s   =   0                              T r a c k   t h e   l o s s .           f o r   c o m p a n y   i n   t q d m . t q d m   c o m p a n i e s   :                   r n n 1 . r e s e t _ h i d d e n _ s t a t e            R e s e t   b o t h   h i d d e n   s t a t e s .                   r n n 2 . r e s e t _ h i d d e n _ s t a t e                       c o m p a n y   =   S T A R T   +   c o m p a n y   +   S T O P          A d d   S T A R T   a n d   S T O P   c h a r a c t e r s .                        T h e   r e s t   i s   j u s t   o u r   u s u a l   t r a i n i n g   l o o p ,   e x c e p t   t h a t   t h e   i n p u t s                      a n d   t a r g e t   a r e   t h e   o n e - h o t - e n c o d e d   p r e v i o u s   a n d   n e x t   c h a r a c t e r s .                   f o r   p r e v ,   n e x t   i n   z i p   c o m p a n y ,   c o m p a n y [ 1 : ]   :                           i n p u t   =   v o c a b . o n e _ h o t _ e n c o d e   p r e v                             t a r g e t   =   v o c a b . o n e _ h o t _ e n c o d e   n e x t                             p r e d i c t e d   =   m o d e l . f o r w a r d   i n p u t                             e p o c h _ l o s s   + =   l o s s . l o s s   p r e d i c t e d ,   t a r g e t      After training, the model generates some actual names from the list  which isn’t surprising, since the model has a fair amount of capacity and not a lot of training data , as well as names that are only slightly different from training names  Scripe, Loinbare, Pozium , names that seem genuinely creative  Benuus, Cletpo, Equite, Vivest , and names that are garbage-y but still sort of word-like  SFitreasy, Sint ocanelp, GliyOx, Doorboronelhav . Unfortunately, like most character-level-RNN outputs, these are only mildly clever, and the VP of Branding ends up unable to use them. If I up the hidden dimension to 64, I get a lot more names verbatim from the list; if I drop it to 8, I get mostly garbage. The vocabulary and final weights for all these model sizes are available on the book’s GitHub site, and you can use l As mentioned previously, the GitHub code for this chapter also contains an implementation for an LSTM, which you should feel free to swap in as a replacement for the S  ns in our company name model.  b to use them yourself.  s and l  For Further Exploration  NLTK is a popular library of NLP tools for Python. It has its own entire book, which is available to read online. gensim is a Python library for topic modeling, which is a better bet than our from-scratch model.                          g r a d i e n t   =   l o s s . g r a d i e n t   p r e d i c t e d ,   t a r g e t                             m o d e l . b a c k w a r d   g r a d i e n t                             o p t i m i z e r . s t e p   m o d e l                  E a c h   e p o c h ,   p r i n t   t h e   l o s s   a n d   a l s o   g e n e r a t e   a   n a m e .           p r i n t   e p o c h ,   e p o c h _ l o s s ,   g e n e r a t e                      T u r n   d o w n   t h e   l e a r n i n g   r a t e   f o r   t h e   l a s t   1 0 0   e p o c h s .              T h e r e ' s   n o   p r i n c i p l e d   r e a s o n   f o r   t h i s ,   b u t   i t   s e e m s   t o   w o r k .           i f   e p o c h   = =   2 0 0 :                   o p t i m i z e r . l r   * =   0 . 1 o a d _ w e i g h t o a d _ v o c a i m p l e R n  spaCy is a library for “Industrial Strength Natural Language Processing in Python” and is also quite popular. Andrej Karpathy has a famous blog post, “The Unreasonable Effectiveness of Recurrent Neural Networks”, that’s very much worth reading. My day job involves building AllenNLP, a Python library for doing NLP research.  At least, as of the time this book went to press, it did.  The library is quite beyond the scope of this book, but you might still find it interesting, and it has a cool interactive demo of many state-of-the-art NLP models.   Chapter 22. Network Analysis  Your connections to all the things around you literally define who you are.  —Aaron O’Connell  Many interesting data problems can be fruitfully thought of in terms of networks, consisting of nodes of some type and the edges that join them. For instance, your Facebook friends form the nodes of a network whose edges are friendship relations. A less obvious example is the World Wide Web itself, with each web page a node and each hyperlink from one page to another an edge. Facebook friendship is mutual—if I am Facebook friends with you, then necessarily you are friends with me. In this case, we say that the edges are undirected. Hyperlinks are not—my website links to whitehouse.gov, but  for reasons inexplicable to me  whitehouse.gov refuses to link to my website. We call these types of edges directed. We’ll look at both kinds of networks.  Betweenness Centrality In Chapter 1, we computed the key connectors in the DataSciencester network by counting the number of friends each user had. Now we have enough machinery to take a look at other approaches. We will use the same network, but now we’ll use N es for the data. Recall that the network  Figure 22-1  comprised users:  a m e d T u p l f r o m   t y p i n g   i m p o r t   N a m e d T u p l e     c l a s s   U s e r   N a m e d T u p l e   :           i d :   i n t           n a m e :   s t r    and friendships:  Figure 22-1. The DataSciencester network  The friendships will be easier to work with as a d  t:  When we left off we were dissatisfied with our notion of degree centrality, which didn’t really agree with our intuition about who the key connectors of the network were.    u s e r s   =   [ U s e r   0 ,   " H e r o "   ,   U s e r   1 ,   " D u n n "   ,   U s e r   2 ,   " S u e "   ,   U s e r   3 ,   " C h i "   ,                     U s e r   4 ,   " T h o r "   ,   U s e r   5 ,   " C l i v e "   ,   U s e r   6 ,   " H i c k s "   ,                     U s e r   7 ,   " D e v i n "   ,   U s e r   8 ,   " K a t e "   ,   U s e r   9 ,   " K l e i n "   ] f r i e n d _ p a i r s   =   [   0 ,   1   ,     0 ,   2   ,     1 ,   2   ,     1 ,   3   ,     2 ,   3   ,     3 ,   4   ,                                     4 ,   5   ,     5 ,   6   ,     5 ,   7   ,     6 ,   8   ,     7 ,   8   ,     8 ,   9   ] i c f r o m   t y p i n g   i m p o r t   D i c t ,   L i s t        t y p e   a l i a s   f o r   k e e p i n g   t r a c k   o f   F r i e n d s h i p s   F r i e n d s h i p s   =   D i c t [ i n t ,   L i s t [ i n t ] ]     f r i e n d s h i p s :   F r i e n d s h i p s   =   { u s e r . i d :   [ ]   f o r   u s e r   i n   u s e r s }     f o r   i ,   j   i n   f r i e n d _ p a i r s :           f r i e n d s h i p s [ i ] . a p p e n d   j             f r i e n d s h i p s [ j ] . a p p e n d   i       a s s e r t   f r i e n d s h i p s [ 4 ]   = =   [ 3 ,   5 ]   a s s e r t   f r i e n d s h i p s [ 8 ]   = =   [ 6 ,   7 ,   9 ]  An alternative metric is betweenness centrality, which identifies people who frequently are on the shortest paths between pairs of other people. In particular, the betweenness centrality of node i is computed by adding up, for every other pair of nodes j and k, the proportion of shortest paths between node j and node k that pass through i. That is, to figure out Thor’s betweenness centrality, we’ll need to compute all the shortest paths between all pairs of people who aren’t Thor. And then we’ll need to count how many of those shortest paths pass through Thor. For instance, the only shortest path between Chi  i d 5  passes through Thor, while neither of the two shortest paths between Hero  i So, as a first step, we’ll need to figure out the shortest paths between all pairs of people. There are some pretty sophisticated algorithms for doing so efficiently, but  as is almost always the case  we will use a less efficient, easier-to-understand algorithm. This algorithm  an implementation of breadth-first search  is one of the more complicated ones in the book, so let’s talk through it carefully:  d 3  and Clive  i  d 0  and Chi  i  d 3  does.  1. Our goal is a function that takes a f  r and finds all shortest  paths to every other user.  2. We’ll represent a path as a l  t of user IDs. Since every path starts at f r, we won’t include her ID in the list. This means that the length of the list representing the path will be the length of the path itself.  3. We’ll maintain a dictionary called s  o where the  keys are user IDs and the values are lists of paths that end at the user with the specified ID. If there is a unique shortest path, the list will just contain that one path. If there are multiple shortest paths, the list will contain all of them.  4. We’ll also maintain a queue called f  r that contains the users we want to explore in the order we want to explore them.  r o m _ u s e i s r o m _ u s e h o r t e s t _ p a t h s _ t r o n t i e    so that we know  We’ll store them as pairs   how we got to each one. We initialize the queue with all the neighbors of f are data structures optimized for “add to the end” and “remove from the front” operations. In Python, they are implemented as e, which is actually a double-ended queue.   r.  We haven’t talked about queues, which  5. As we explore the graph, whenever we find new neighbors that we don’t already know the shortest paths to, we add them to the end of the queue to explore later, with the current user as p  r.  6. When we take a user off the queue, and we’ve never encountered that user before, we’ve definitely found one or more shortest paths to him—each of the shortest paths to p step added.  r with one extra  7. When we take a user off the queue and we have encountered that  user before, then either we’ve found another shortest path  in which case we should add it  or we’ve found a longer path  in which case we shouldn’t .  8. When no more users are left on the queue, we’ve explored the  whole graph  or, at least, the parts of it that are reachable from the starting user  and we’re done.  We can put this all together into a  large  function:  p r e v _ u s e r ,   u s e r r o m _ u s e c o l l e c t i o n s . d e q u r e v _ u s e r e v _ u s e f r o m   c o l l e c t i o n s   i m p o r t   d e q u e     P a t h   =   L i s t [ i n t ]     d e f   s h o r t e s t _ p a t h s _ f r o m   f r o m _ u s e r _ i d :   i n t ,                                                   f r i e n d s h i p s :   F r i e n d s h i p s     - >   D i c t [ i n t ,   L i s t [ P a t h ] ] :              A   d i c t i o n a r y   f r o m   u s e r _ i d   t o   * a l l *   s h o r t e s t   p a t h s   t o   t h a t   u s e r .           s h o r t e s t _ p a t h s _ t o :   D i c t [ i n t ,   L i s t [ P a t h ] ]   =   { f r o m _ u s e r _ i d :   [ [ ] ] }                A   q u e u e   o f     p r e v i o u s   u s e r ,   n e x t   u s e r     t h a t   w e   n e e d   t o   c h e c k .              S t a r t s   o u t   w i t h   a l l   p a i r s     f r o m _ u s e r ,   f r i e n d _ o f _ f r o m _ u s e r   .           f r o n t i e r   =   d e q u e     f r o m _ u s e r _ i d ,   f r i e n d _ i d                                               f o r   f r i e n d _ i d   i n   f r i e n d s h i p s [ f r o m _ u s e r _ i d ]      Now let’s compute all the shortest paths:  And we’re finally ready to compute betweenness centrality. For every pair of nodes i and j, we know the n shortest paths from i to j. Then, for each of those paths, we just add 1 n to the centrality of each node on that path:               K e e p   g o i n g   u n t i l   w e   e m p t y   t h e   q u e u e .           w h i l e   f r o n t i e r :                      R e m o v e   t h e   p a i r   t h a t ' s   n e x t   i n   t h e   q u e u e .                   p r e v _ u s e r _ i d ,   u s e r _ i d   =   f r o n t i e r . p o p l e f t                            B e c a u s e   o f   t h e   w a y   w e ' r e   a d d i n g   t o   t h e   q u e u e ,                      n e c e s s a r i l y   w e   a l r e a d y   k n o w   s o m e   s h o r t e s t   p a t h s   t o   p r e v _ u s e r .                   p a t h s _ t o _ p r e v _ u s e r   =   s h o r t e s t _ p a t h s _ t o [ p r e v _ u s e r _ i d ]                   n e w _ p a t h s _ t o _ u s e r   =   [ p a t h   +   [ u s e r _ i d ]   f o r   p a t h   i n   p a t h s _ t o _ p r e v _ u s e r ]                        I t ' s   p o s s i b l e   w e   a l r e a d y   k n o w   a   s h o r t e s t   p a t h   t o   u s e r _ i d .                   o l d _ p a t h s _ t o _ u s e r   =   s h o r t e s t _ p a t h s _ t o . g e t   u s e r _ i d ,   [ ]                          W h a t ' s   t h e   s h o r t e s t   p a t h   t o   h e r e   t h a t   w e ' v e   s e e n   s o   f a r ?                   i f   o l d _ p a t h s _ t o _ u s e r :                           m i n _ p a t h _ l e n g t h   =   l e n   o l d _ p a t h s _ t o _ u s e r [ 0 ]                     e l s e :                           m i n _ p a t h _ l e n g t h   =   f l o a t   ' i n f '                          O n l y   k e e p   p a t h s   t h a t   a r e n ' t   t o o   l o n g   a n d   a r e   a c t u a l l y   n e w .                   n e w _ p a t h s _ t o _ u s e r   =   [ p a t h                                                             f o r   p a t h   i n   n e w _ p a t h s _ t o _ u s e r                                                             i f   l e n   p a t h     < =   m i n _ p a t h _ l e n g t h                                                             a n d   p a t h   n o t   i n   o l d _ p a t h s _ t o _ u s e r ]                     s h o r t e s t _ p a t h s _ t o [ u s e r _ i d ]   =   o l d _ p a t h s _ t o _ u s e r   +   n e w _ p a t h s _ t o _ u s e r                        A d d   n e v e r - s e e n   n e i g h b o r s   t o   t h e   f r o n t i e r .                   f r o n t i e r . e x t e n d     u s e r _ i d ,   f r i e n d _ i d                                                     f o r   f r i e n d _ i d   i n   f r i e n d s h i p s [ u s e r _ i d ]                                                   i f   f r i e n d _ i d   n o t   i n   s h o r t e s t _ p a t h s _ t o               r e t u r n   s h o r t e s t _ p a t h s _ t o    F o r   e a c h   f r o m _ u s e r ,   f o r   e a c h   t o _ u s e r ,   a   l i s t   o f   s h o r t e s t   p a t h s .   s h o r t e s t _ p a t h s   =   { u s e r . i d :   s h o r t e s t _ p a t h s _ f r o m   u s e r . i d ,   f r i e n d s h i p s                                         f o r   u s e r   i n   u s e r s }  As shown in Figure 22-2, users 0 and 9 have centrality 0  as neither is on any shortest path between other users , whereas 3, 4, and 5 all have high centralities  as all three lie on many shortest paths .  Figure 22-2. The DataSciencester network sized by betweenness centrality  NOTE  Generally the centrality numbers aren’t that meaningful themselves. What we care about is how the numbers for each node compare to the numbers for other nodes.  Another measure we can look at is closeness centrality. First, for each user we compute her farness, which is the sum of the lengths of her shortest paths to each other user. Since we’ve already computed the shortest paths between each pair of nodes, it’s easy to add their lengths.  If there are multiple shortest paths, they all have the same length, so we can just look at the first one.   b e t w e e n n e s s _ c e n t r a l i t y   =   { u s e r . i d :   0 . 0   f o r   u s e r   i n   u s e r s }     f o r   s o u r c e   i n   u s e r s :           f o r   t a r g e t _ i d ,   p a t h s   i n   s h o r t e s t _ p a t h s [ s o u r c e . i d ] . i t e m s     :                   i f   s o u r c e . i d   <   t a r g e t _ i d :                d o n ' t   d o u b l e   c o u n t                           n u m _ p a t h s   =   l e n   p a t h s                h o w   m a n y   s h o r t e s t   p a t h s ?                           c o n t r i b   =   1       n u m _ p a t h s            c o n t r i b u t i o n   t o   c e n t r a l i t y                           f o r   p a t h   i n   p a t h s :                                   f o r   b e t w e e n _ i d   i n   p a t h :                                           i f   b e t w e e n _ i d   n o t   i n   [ s o u r c e . i d ,   t a r g e t _ i d ] :                                                   b e t w e e n n e s s _ c e n t r a l i t y [ b e t w e e n _ i d ]   + =   c o n t r i b  after which it’s very little work to compute closeness centrality  Figure 22- 3 :  Figure 22-3. The DataSciencester network sized by closeness centrality  There is much less variation here—even the very central nodes are still pretty far from the nodes out on the periphery. As we saw, computing shortest paths is kind of a pain. For this reason, betweenness and closeness centrality aren’t often used on large networks. The less intuitive  but generally easier to compute  eigenvector centrality is more frequently used.  Eigenvector Centrality In order to talk about eigenvector centrality, we have to talk about eigenvectors, and in order to talk about eigenvectors, we have to talk about matrix multiplication.  Matrix Multiplication  d e f   f a r n e s s   u s e r _ i d :   i n t     - >   f l o a t :           " " " t h e   s u m   o f   t h e   l e n g t h s   o f   t h e   s h o r t e s t   p a t h s   t o   e a c h   o t h e r   u s e r " " "           r e t u r n   s u m   l e n   p a t h s [ 0 ]                                   f o r   p a t h s   i n   s h o r t e s t _ p a t h s [ u s e r _ i d ] . v a l u e s       c l o s e n e s s _ c e n t r a l i t y   =   { u s e r . i d :   1       f a r n e s s   u s e r . i d     f o r   u s e r   i n   u s e r s }  m matrix and B is an m  If A is an n dimension of A is same as the first dimension of B , then their product AB is the n  k matrix  notice that the second  k matrix whose  i,j th entry is:  which is just the dot product of the ith row of A  thought of as a vector  with the jth column of B  also thought of as a vector . We can implement this using the m  x function from Chapter 4:  If we think of an m-dimensional vector as an   multiply it by an   think of as an n-dimensional vector. This means another way to think about an   mapping that transforms m-dimensional vectors into n-dimensional vectors:    matrix, which we can then    matrix is as a linear    matrix to get an      matrix, we can  × × × A i 1 B 1 j + A i 2 B 2 j + ⋯ + A i m B m j a k e _ m a t r i f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   M a t r i x ,   m a k e _ m a t r i x ,   s h a p e     d e f   m a t r i x _ t i m e s _ m a t r i x   m 1 :   M a t r i x ,   m 2 :   M a t r i x     - >   M a t r i x :           n r 1 ,   n c 1   =   s h a p e   m 1             n r 2 ,   n c 2   =   s h a p e   m 2             a s s e r t   n c 1   = =   n r 2 ,   " m u s t   h a v e        o f   c o l u m n s   i n   m 1     = =        o f   r o w s   i n   m 2   "             d e f   e n t r y _ f n   i :   i n t ,   j :   i n t     - >   f l o a t :                   " " " d o t   p r o d u c t   o f   i - t h   r o w   o f   m 1   w i t h   j - t h   c o l u m n   o f   m 2 " " "                   r e t u r n   s u m   m 1 [ i ] [ k ]   *   m 2 [ k ] [ j ]   f o r   k   i n   r a n g e   n c 1                 r e t u r n   m a k e _ m a t r i x   n r 1 ,   n c 2 ,   e n t r y _ f n   m ,   1 n ,   m n ,   1 n ,   m f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   V e c t o r ,   d o t     d e f   m a t r i x _ t i m e s _ v e c t o r   m :   M a t r i x ,   v :   V e c t o r     - >   V e c t o r :           n r ,   n c   =   s h a p e   m             n   =   l e n   v             a s s e r t   n c   = =   n ,   " m u s t   h a v e        o f   c o l s   i n   m     = =        o f   e l e m e n t s   i n   v   "             r e t u r n   [ d o t   r o w ,   v     f o r   r o w   i n   m ]        o u t p u t   h a s   l e n g t h   n r  When A is a square matrix, this operation maps n-dimensional vectors to other n-dimensional vectors. It’s possible that, for some matrix A and vector v, when A operates on v we get back a scalar multiple of v—that is, that the result is a vector that points in the same direction as v. When this happens  and when, in addition, v is not a vector of all zeros , we call v an eigenvector of A. And we call the multiplier an eigenvalue. One possible way to find an eigenvector of A is by picking a starting vector v, applying m r, rescaling the result to have magnitude 1, and repeating until the process converges:  By construction, the returned g  s is a vector such that, when you apply r to it and rescale it to have length 1, you get back a  vector very close to itself—which means it’s an eigenvector. Not all matrices of real numbers have eigenvectors and eigenvalues. For example, the matrix:  a t r i x _ t i m e s _ v e c t o f r o m   t y p i n g   i m p o r t   T u p l e   i m p o r t   r a n d o m   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   m a g n i t u d e ,   d i s t a n c e     d e f   f i n d _ e i g e n v e c t o r   m :   M a t r i x ,                                             t o l e r a n c e :   f l o a t   =   0 . 0 0 0 0 1     - >   T u p l e [ V e c t o r ,   f l o a t ] :           g u e s s   =   [ r a n d o m . r a n d o m       f o r   _   i n   m ]             w h i l e   T r u e :                   r e s u l t   =   m a t r i x _ t i m e s _ v e c t o r   m ,   g u e s s              t r a n s f o r m   g u e s s                   n o r m   =   m a g n i t u d e   r e s u l t                                          c o m p u t e   n o r m                   n e x t _ g u e s s   =   [ x       n o r m   f o r   x   i n   r e s u l t ]          r e s c a l e                     i f   d i s t a n c e   g u e s s ,   n e x t _ g u e s s     <   t o l e r a n c e :                              c o n v e r g e n c e   s o   r e t u r n     e i g e n v e c t o r ,   e i g e n v a l u e                             r e t u r n   n e x t _ g u e s s ,   n o r m                     g u e s s   =   n e x t _ g u e s s u e s m a t r i x _ t i m e s _ v e c t o r o t a t e   =   [ [   0 ,   1 ] ,                       [ - 1 ,   0 ] ]  rotates vectors 90 degrees clockwise, which means that the only vector it maps to a scalar multiple of itself is a vector of zeros. If you tried  eigenvectors can sometimes get stuck in cycles. Consider the matrix:    it would run forever. Even matrices that have  ] to [  ]. This means that, for  ] is an eigenvector with eigenvalue 1. However, if you start  This matrix maps any vector [ example, [ with a random vector with unequal coordinates, f r will just repeatedly swap the coordinates forever.  Not-from-scratch libraries like NumPy use different methods that would work in this case.  Nonetheless, when f indeed an eigenvector.  r does return a result, that result is  Centrality How does this help us understand the DataSciencester network? To start, we’ll need to represent the connections in our network as an  x, whose  i,j th entry is either 1  if user i and user j are  friends  or 0  if they’re not :  The eigenvector centrality for each user is then the entry corresponding to that user in the eigenvector returned by f r  Figure 22-4 .  f i n d _ e i g e n v e c t o r   r o t a t e f l i p   =   [ [ 0 ,   1 ] ,                   [ 1 ,   0 ] ] x ,   y y ,   x 1 ,   1 i n d _ e i g e n v e c t o i n d _ e i g e n v e c t o a d j a c e n c y _ m a t r i d e f   e n t r y _ f n   i :   i n t ,   j :   i n t   :           r e t u r n   1   i f     i ,   j     i n   f r i e n d _ p a i r s   o r     j ,   i     i n   f r i e n d _ p a i r s   e l s e   0     n   =   l e n   u s e r s     a d j a c e n c y _ m a t r i x   =   m a k e _ m a t r i x   n ,   n ,   e n t r y _ f n   i n d _ e i g e n v e c t o  Figure 22-4. The DataSciencester network sized by eigenvector centrality  NOTE  For technical reasons that are way beyond the scope of this book, any nonzero adjacency matrix necessarily has an eigenvector, all of whose values are nonnegative. And fortunately for us, for this a r function finds it.  x our f  Users with high eigenvector centrality should be those who have a lot of connections, and connections to people who themselves have high centrality. Here users 1 and 2 are the most central, as they both have three connections to people who are themselves highly central. As we move away from them, people’s centralities steadily drop off. On a network this small, eigenvector centrality behaves somewhat erratically. If you try adding or subtracting links, you’ll find that small changes in the network can dramatically change the centrality numbers. In a much larger network, this would not particularly be the case. We still haven’t motivated why an eigenvector might lead to a reasonable notion of centrality. Being an eigenvector means that if you compute:  d j a c e n c y _ m a t r i i n d _ e i g e n v e c t o e i g e n v e c t o r _ c e n t r a l i t i e s ,   _   =   f i n d _ e i g e n v e c t o r   a d j a c e n c y _ m a t r i x   m a t r i x _ t i m e s _ v e c t o r   a d j a c e n c y _ m a t r i x ,   e i g e n v e c t o r _ c e n t r a l i t i e s    the result is a scalar multiple of e If you look at how matrix multiplication works, m produces a vector whose ith element is:  s.  which is precisely the sum of the eigenvector centralities of the users connected to user i. In other words, eigenvector centralities are numbers, one per user, such that each user’s value is a constant multiple of the sum of his neighbors’ values. In this case centrality means being connected to people who themselves are central. The more centrality you are directly connected to, the more central you are. This is of course a circular definition—eigenvectors are the way of breaking out of the circularity. Another way of understanding this is by thinking about what  r is doing here. It starts by assigning each node a random  centrality. It then repeats the following two steps until the process converges:  1. Give each node a new centrality score that equals the sum of its  neighbors’  old  centrality scores.  2. Rescale the vector of centralities to have magnitude 1.  Although the mathematics behind it may seem somewhat opaque at first, the calculation itself is relatively straightforward  unlike, say, betweenness centrality  and is pretty easy to perform on even very large graphs.  At least, if you use a real linear algebra library it’s easy to perform on large graphs. If you used our matrices-as-lists implementation you’d struggle.   Directed Graphs and PageRank DataSciencester isn’t getting much traction, so the VP of Revenue considers pivoting from a friendship model to an endorsement model. It turns out that  i g e n v e c t o r _ c e n t r a l i t i e a t r i x _ t i m e s _ v e c t o r d o t   a d j a c e n c y _ m a t r i x [ i ] ,   e i g e n v e c t o r _ c e n t r a l i t i e s   f i n d _ e i g e n v e c t o  no one particularly cares which data scientists are friends with one another, but tech recruiters care very much which data scientists are respected by other data scientists. In this new model, we’ll track endorsements   longer represent a reciprocal relationship, but rather that s    that no e endorses  t as an awesome data scientist  Figure 22-5 .  Figure 22-5. The DataSciencester network of endorsements  We’ll need to account for this asymmetry:  after which we can easily find the m that information to recruiters:  d data scientists and sell  However, “number of endorsements” is an easy metric to game. All you need to do is create phony accounts and have them endorse you. Or arrange with your friends to endorse each other.  As users 0, 1, and 2 seem to have done.  A better metric would take into account who endorses you. Endorsements from people who have a lot of endorsements should somehow count more  s o u r c e ,   t a r g e t o u r c t a r g e e n d o r s e m e n t s   =   [   0 ,   1   ,     1 ,   0   ,     0 ,   2   ,     2 ,   0   ,     1 ,   2   ,                                     2 ,   1   ,     1 ,   3   ,     2 ,   3   ,     3 ,   4   ,     5 ,   4   ,                                     5 ,   6   ,     7 ,   5   ,     6 ,   8   ,     8 ,   7   ,     8 ,   9   ] o s t _ e n d o r s e f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     e n d o r s e m e n t _ c o u n t s   =   C o u n t e r   t a r g e t   f o r   s o u r c e ,   t a r g e t   i n   e n d o r s e m e n t s    than endorsements from people with few endorsements. This is the essence of the PageRank algorithm, used by Google to rank websites based on which other websites link to them, which other websites link to those, and so on.  If this sort of reminds you of the idea behind eigenvector centrality, it should.  A simplified version looks like this:  1. There is a total of 1.0  or 100%  PageRank in the network. 2. Initially this PageRank is equally distributed among nodes. 3. At each step, a large fraction of each node’s PageRank is  distributed evenly among its outgoing links.  4. At each step, the remainder of each node’s PageRank is distributed  evenly among all nodes.  i m p o r t   t q d m     d e f   p a g e _ r a n k   u s e r s :   L i s t [ U s e r ] ,                               e n d o r s e m e n t s :   L i s t [ T u p l e [ i n t ,   i n t ] ] ,                               d a m p i n g :   f l o a t   =   0 . 8 5 ,                               n u m _ i t e r s :   i n t   =   1 0 0     - >   D i c t [ i n t ,   f l o a t ] :              C o m p u t e   h o w   m a n y   p e o p l e   e a c h   p e r s o n   e n d o r s e s           o u t g o i n g _ c o u n t s   =   C o u n t e r   t a r g e t   f o r   s o u r c e ,   t a r g e t   i n   e n d o r s e m e n t s                  I n i t i a l l y   d i s t r i b u t e   P a g e R a n k   e v e n l y           n u m _ u s e r s   =   l e n   u s e r s             p r   =   { u s e r . i d   :   1       n u m _ u s e r s   f o r   u s e r   i n   u s e r s }                S m a l l   f r a c t i o n   o f   P a g e R a n k   t h a t   e a c h   n o d e   g e t s   e a c h   i t e r a t i o n           b a s e _ p r   =     1   -   d a m p i n g         n u m _ u s e r s             f o r   i t e r   i n   t q d m . t r a n g e   n u m _ i t e r s   :                   n e x t _ p r   =   { u s e r . i d   :   b a s e _ p r   f o r   u s e r   i n   u s e r s }        s t a r t   w i t h   b a s e _ p r                     f o r   s o u r c e ,   t a r g e t   i n   e n d o r s e m e n t s :                              A d d   d a m p e d   f r a c t i o n   o f   s o u r c e   p r   t o   t a r g e t                           n e x t _ p r [ t a r g e t ]   + =   d a m p i n g   *   p r [ s o u r c e ]       o u t g o i n g _ c o u n t s [ s o u r c e ]                     p r   =   n e x t _ p r    If we compute page ranks:  PageRank  Figure 22-6  identifies user 4  Thor  as the highest-ranked data scientist.  Figure 22-6. The DataSciencester network sized by PageRank  Even though Thor has fewer endorsements  two  than users 0, 1, and 2, his endorsements carry with them rank from their endorsements. Additionally, both of his endorsers endorsed only him, which means that he doesn’t have to divide their rank with anyone else.  For Further Exploration  There are many other notions of centrality besides the ones we used  although the ones we used are pretty much the most popular ones . NetworkX is a Python library for network analysis. It has functions for computing centralities and for visualizing graphs.            r e t u r n   p r p r   =   p a g e _ r a n k   u s e r s ,   e n d o r s e m e n t s          T h o r     u s e r _ i d   4     h a s   h i g h e r   p a g e   r a n k   t h a n   a n y o n e   e l s e   a s s e r t   p r [ 4 ]   >   m a x   p a g e _ r a n k                                         f o r   u s e r _ i d ,   p a g e _ r a n k   i n   p r . i t e m s                                             i f   u s e r _ i d   ! =   4    Gephi is a love-it hate-it GUI-based network visualization tool.   Chapter 23. Recommender Systems  O nature, nature, why art thou so dishonest, as ever to send men with these false recommendations into the world!  —Henry Fielding  Another common data problem is producing recommendations of some sort. Netflix recommends movies you might want to watch. Amazon recommends products you might want to buy. Twitter recommends users you might want to follow. In this chapter, we’ll look at several ways to use data to make recommendations. In particular, we’ll look at the dataset of u before:  s that we’ve used  And we’ll think about the problem of recommending new interests to a user based on her currently specified interests.  s e r s _ i n t e r e s t u s e r s _ i n t e r e s t s   =   [           [ " H a d o o p " ,   " B i g   D a t a " ,   " H B a s e " ,   " J a v a " ,   " S p a r k " ,   " S t o r m " ,   " C a s s a n d r a " ] ,           [ " N o S Q L " ,   " M o n g o D B " ,   " C a s s a n d r a " ,   " H B a s e " ,   " P o s t g r e s " ] ,           [ " P y t h o n " ,   " s c i k i t - l e a r n " ,   " s c i p y " ,   " n u m p y " ,   " s t a t s m o d e l s " ,   " p a n d a s " ] ,           [ " R " ,   " P y t h o n " ,   " s t a t i s t i c s " ,   " r e g r e s s i o n " ,   " p r o b a b i l i t y " ] ,           [ " m a c h i n e   l e a r n i n g " ,   " r e g r e s s i o n " ,   " d e c i s i o n   t r e e s " ,   " l i b s v m " ] ,           [ " P y t h o n " ,   " R " ,   " J a v a " ,   " C + + " ,   " H a s k e l l " ,   " p r o g r a m m i n g   l a n g u a g e s " ] ,           [ " s t a t i s t i c s " ,   " p r o b a b i l i t y " ,   " m a t h e m a t i c s " ,   " t h e o r y " ] ,           [ " m a c h i n e   l e a r n i n g " ,   " s c i k i t - l e a r n " ,   " M a h o u t " ,   " n e u r a l   n e t w o r k s " ] ,           [ " n e u r a l   n e t w o r k s " ,   " d e e p   l e a r n i n g " ,   " B i g   D a t a " ,   " a r t i f i c i a l   i n t e l l i g e n c e " ] ,           [ " H a d o o p " ,   " J a v a " ,   " M a p R e d u c e " ,   " B i g   D a t a " ] ,           [ " s t a t i s t i c s " ,   " R " ,   " s t a t s m o d e l s " ] ,           [ " C + + " ,   " d e e p   l e a r n i n g " ,   " a r t i f i c i a l   i n t e l l i g e n c e " ,   " p r o b a b i l i t y " ] ,           [ " p a n d a s " ,   " R " ,   " P y t h o n " ] ,           [ " d a t a b a s e s " ,   " H B a s e " ,   " P o s t g r e s " ,   " M y S Q L " ,   " M o n g o D B " ] ,           [ " l i b s v m " ,   " r e g r e s s i o n " ,   " s u p p o r t   v e c t o r   m a c h i n e s " ]   ]  Manual Curation Before the internet, when you needed book recommendations you would go to the library, where a librarian was available to suggest books that were relevant to your interests or similar to books you liked. Given DataSciencester’s limited number of users and interests, it would be easy for you to spend an afternoon manually recommending interests for each user. But this method doesn’t scale particularly well, and it’s limited by your personal knowledge and imagination.  Not that I’m suggesting that your personal knowledge and imagination are limited.  So let’s think about what we can do with data.  Recommending What’s Popular One easy approach is to simply recommend what’s popular:  which looks like:  Having computed this, we can just suggest to a user the most popular interests that he’s not already interested in:  f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     p o p u l a r _ i n t e r e s t s   =   C o u n t e r   i n t e r e s t                                                           f o r   u s e r _ i n t e r e s t s   i n   u s e r s _ i n t e r e s t s                                                           f o r   i n t e r e s t   i n   u s e r _ i n t e r e s t s   [   ' P y t h o n ' ,   4   ,       ' R ' ,   4   ,       ' J a v a ' ,   3   ,       ' r e g r e s s i o n ' ,   3   ,       ' s t a t i s t i c s ' ,   3   ,       ' p r o b a b i l i t y ' ,   3   ,        . . .   ] f r o m   t y p i n g   i m p o r t   L i s t ,   T u p l e      So, if you are user 1, with interests:  then we’d recommend you:  If you are user 3, who’s already interested in many of those things, you’d instead get:  Of course, “lots of people are interested in Python, so maybe you should be too” is not the most compelling sales pitch. If someone is brand new to our site and we don’t know anything about them, that’s possibly the best we can do. Let’s see how we can do better by basing each user’s recommendations on her existing interests.  User-Based Collaborative Filtering One way of taking a user’s interests into account is to look for users who are somehow similar to her, and then suggest the things that those users are interested in. In order to do that, we’ll need a way to measure how similar two users are. Here we’ll use cosine similarity, which we used in Chapter 21 to measure how similar two word vectors were.  d e f   m o s t _ p o p u l a r _ n e w _ i n t e r e s t s                     u s e r _ i n t e r e s t s :   L i s t [ s t r ] ,                   m a x _ r e s u l t s :   i n t   =   5     - >   L i s t [ T u p l e [ s t r ,   i n t ] ] :           s u g g e s t i o n s   =   [   i n t e r e s t ,   f r e q u e n c y                                           f o r   i n t e r e s t ,   f r e q u e n c y   i n   p o p u l a r _ i n t e r e s t s . m o s t _ c o m m o n                                             i f   i n t e r e s t   n o t   i n   u s e r _ i n t e r e s t s ]           r e t u r n   s u g g e s t i o n s [ : m a x _ r e s u l t s ] [ " N o S Q L " ,   " M o n g o D B " ,   " C a s s a n d r a " ,   " H B a s e " ,   " P o s t g r e s " ] [   ' P y t h o n ' ,   4   ,     ' R ' ,   4   ,     ' J a v a ' ,   3   ,     ' r e g r e s s i o n ' ,   3   ,     ' s t a t i s t i c s ' ,   3   ] [   ' J a v a ' ,   3   ,     ' H B a s e ' ,   3   ,     ' B i g   D a t a ' ,   3   ,       ' n e u r a l   n e t w o r k s ' ,   2   ,     ' H a d o o p ' ,   2   ]  We’ll apply this to vectors of 0s and 1s, each vector v representing one user’s interests. v ] will be 1 if the user specified the ith interest, and 0 otherwise. Accordingly, “similar users” will mean “users whose interest vectors most nearly point in the same direction.” Users with identical interests will have similarity 1. Users with no identical interests will have similarity 0. Otherwise, the similarity will fall in between, with numbers closer to 1 indicating “very similar” and numbers closer to 0 indicating “not very similar.” A good place to start is collecting the known interests and  implicitly  assigning indices to them. We can do this by using a set comprehension to find the unique interests, and then sorting them into a list. The first interest in the resulting list will be interest 0, and so on:  This gives us a list that starts:  Next we want to produce an “interest” vector of 0s and 1s for each user. We just need to iterate over the u user has each interest, and a 0 if not:  s list, substituting a 1 if the  [ i u n i q u e _ i n t e r e s t s   =   s o r t e d   { i n t e r e s t                                                         f o r   u s e r _ i n t e r e s t s   i n   u s e r s _ i n t e r e s t s                                                         f o r   i n t e r e s t   i n   u s e r _ i n t e r e s t s }   a s s e r t   u n i q u e _ i n t e r e s t s [ : 6 ]   = =   [           ' B i g   D a t a ' ,           ' C + + ' ,           ' C a s s a n d r a ' ,           ' H B a s e ' ,           ' H a d o o p ' ,           ' H a s k e l l ' ,              . . .   ] n i q u e _ i n t e r e s t d e f   m a k e _ u s e r _ i n t e r e s t _ v e c t o r   u s e r _ i n t e r e s t s :   L i s t [ s t r ]     - >   L i s t [ i n t ] :           " " "           G i v e n   a   l i s t   o f   i n t e r e s t s ,   p r o d u c e   a   v e c t o r   w h o s e   i t h   e l e m e n t   i s   1           i f   u n i q u e _ i n t e r e s t s [ i ]   i s   i n   t h e   l i s t ,   0   o t h e r w i s e           " " "    And now we can make a list of user interest vectors:  Now u j, and 0 otherwise. Because we have a small dataset, it’s no problem to compute the pairwise similarities between all of our users:  ] equals 1 if user i specified interest  after which u users i and j:  ] gives us the similarity between  In particular, u ] is the vector of user i’s similarities to every other user. We can use this to write a function that finds the most similar users to a given user. We’ll make sure not to include the user herself, nor any users with zero similarity. And we’ll sort the results from most similar to least similar:          r e t u r n   [ 1   i f   i n t e r e s t   i n   u s e r _ i n t e r e s t s   e l s e   0                           f o r   i n t e r e s t   i n   u n i q u e _ i n t e r e s t s ] u s e r _ i n t e r e s t _ v e c t o r s   =   [ m a k e _ u s e r _ i n t e r e s t _ v e c t o r   u s e r _ i n t e r e s t s                                                       f o r   u s e r _ i n t e r e s t s   i n   u s e r s _ i n t e r e s t s ] s e r _ i n t e r e s t _ v e c t o r s [ i ] [ j f r o m   s c r a t c h . n l p   i m p o r t   c o s i n e _ s i m i l a r i t y     u s e r _ s i m i l a r i t i e s   =   [ [ c o s i n e _ s i m i l a r i t y   i n t e r e s t _ v e c t o r _ i ,   i n t e r e s t _ v e c t o r _ j                                                 f o r   i n t e r e s t _ v e c t o r _ j   i n   u s e r _ i n t e r e s t _ v e c t o r s ]                                             f o r   i n t e r e s t _ v e c t o r _ i   i n   u s e r _ i n t e r e s t _ v e c t o r s ] s e r _ s i m i l a r i t i e s [ i ] [ j    U s e r s   0   a n d   9   s h a r e   i n t e r e s t s   i n   H a d o o p ,   J a v a ,   a n d   B i g   D a t a   a s s e r t   0 . 5 6   <   u s e r _ s i m i l a r i t i e s [ 0 ] [ 9 ]   <   0 . 5 8 ,   " s e v e r a l   s h a r e d   i n t e r e s t s "        U s e r s   0   a n d   8   s h a r e   o n l y   o n e   i n t e r e s t :   B i g   D a t a   a s s e r t   0 . 1 8   <   u s e r _ s i m i l a r i t i e s [ 0 ] [ 8 ]   <   0 . 2 0 ,   " o n l y   o n e   s h a r e d   i n t e r e s t " s e r _ s i m i l a r i t i e s [ i d e f   m o s t _ s i m i l a r _ u s e r s _ t o   u s e r _ i d :   i n t     - >   L i s t [ T u p l e [ i n t ,   f l o a t ] ] :           p a i r s   =   [   o t h e r _ u s e r _ i d ,   s i m i l a r i t y                                                  F i n d   o t h e r                             f o r   o t h e r _ u s e r _ i d ,   s i m i l a r i t y   i n                                      u s e r s   w i t h                                   e n u m e r a t e   u s e r _ s i m i l a r i t i e s [ u s e r _ i d ]                        n o n z e r o                             i f   u s e r _ i d   ! =   o t h e r _ u s e r _ i d   a n d   s i m i l a r i t y   >   0 ]        s i m i l a r i t y .    For instance, if we call m    we get:  How do we use this to suggest new interests to a user? For each interest, we can just add up the user similarities of the other users interested in it:  If we call u interests are:   , the first several suggested            r e t u r n   s o r t e d   p a i r s ,                                                                                S o r t   t h e m                                       k e y = l a m b d a   p a i r :   p a i r [ - 1 ] ,                                        m o s t   s i m i l a r                                       r e v e r s e = T r u e                                                                    f i r s t . o s t _ s i m i l a r _ u s e r s _ t o   0 [   9 ,   0 . 5 6 6 9 4 6 7 0 9 5 1 3 8 4 0 9   ,       1 ,   0 . 3 3 8 0 6 1 7 0 1 8 9 1 4 0 6 6   ,       8 ,   0 . 1 8 8 9 8 2 2 3 6 5 0 4 6 1 3 6   ,       1 3 ,   0 . 1 6 9 0 3 0 8 5 0 9 4 5 7 0 3 3   ,       5 ,   0 . 1 5 4 3 0 3 3 4 9 9 6 2 0 9 1 9   ] f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     d e f   u s e r _ b a s e d _ s u g g e s t i o n s   u s e r _ i d :   i n t ,                                                         i n c l u d e _ c u r r e n t _ i n t e r e s t s :   b o o l   =   F a l s e   :              S u m   u p   t h e   s i m i l a r i t i e s           s u g g e s t i o n s :   D i c t [ s t r ,   f l o a t ]   =   d e f a u l t d i c t   f l o a t             f o r   o t h e r _ u s e r _ i d ,   s i m i l a r i t y   i n   m o s t _ s i m i l a r _ u s e r s _ t o   u s e r _ i d   :                   f o r   i n t e r e s t   i n   u s e r s _ i n t e r e s t s [ o t h e r _ u s e r _ i d ] :                           s u g g e s t i o n s [ i n t e r e s t ]   + =   s i m i l a r i t y                C o n v e r t   t h e m   t o   a   s o r t e d   l i s t           s u g g e s t i o n s   =   s o r t e d   s u g g e s t i o n s . i t e m s     ,                                                     k e y = l a m b d a   p a i r :   p a i r [ - 1 ] ,        w e i g h t                                                     r e v e r s e = T r u e                  A n d     m a y b e     e x c l u d e   a l r e a d y   i n t e r e s t s           i f   i n c l u d e _ c u r r e n t _ i n t e r e s t s :                   r e t u r n   s u g g e s t i o n s           e l s e :                   r e t u r n   [   s u g g e s t i o n ,   w e i g h t                                     f o r   s u g g e s t i o n ,   w e i g h t   i n   s u g g e s t i o n s                                   i f   s u g g e s t i o n   n o t   i n   u s e r s _ i n t e r e s t s [ u s e r _ i d ] ] s e r _ b a s e d _ s u g g e s t i o n s   0  These seem like pretty decent suggestions for someone whose stated interests are “Big Data” and database-related.  The weights aren’t intrinsically meaningful; we just use them for ordering.  This approach doesn’t work as well when the number of items gets very large. Recall the curse of dimensionality from Chapter 12—in large- dimensional vector spaces most vectors are very far apart  and also point in very different directions . That is, when there are a large number of interests the “most similar users” to a given user might not be similar at all. Imagine a site like Amazon.com, from which I’ve bought thousands of items over the last couple of decades. You could attempt to identify similar users to me based on buying patterns, but most likely in all the world there’s no one whose purchase history looks even remotely like mine. Whoever my “most similar” shopper is, he’s probably not similar to me at all, and his purchases would almost certainly make for lousy recommendations.  Item-Based Collaborative Filtering An alternative approach is to compute similarities between interests directly. We can then generate suggestions for each user by aggregating interests that are similar to her current interests. To start with, we’ll want to transpose our user-interest matrix so that rows correspond to interests and columns correspond to users:  [   ' M a p R e d u c e ' ,   0 . 5 6 6 9 4 6 7 0 9 5 1 3 8 4 0 9   ,       ' M o n g o D B ' ,   0 . 5 0 7 0 9 2 5 5 2 8 3 7 1 1   ,       ' P o s t g r e s ' ,   0 . 5 0 7 0 9 2 5 5 2 8 3 7 1 1   ,       ' N o S Q L ' ,   0 . 3 3 8 0 6 1 7 0 1 8 9 1 4 0 6 6   ,       ' n e u r a l   n e t w o r k s ' ,   0 . 1 8 8 9 8 2 2 3 6 5 0 4 6 1 3 6   ,       ' d e e p   l e a r n i n g ' ,   0 . 1 8 8 9 8 2 2 3 6 5 0 4 6 1 3 6   ,       ' a r t i f i c i a l   i n t e l l i g e n c e ' ,   0 . 1 8 8 9 8 2 2 3 6 5 0 4 6 1 3 6   ,      . . .   ] i n t e r e s t _ u s e r _ m a t r i x   =   [ [ u s e r _ i n t e r e s t _ v e c t o r [ j ]                                                     f o r   u s e r _ i n t e r e s t _ v e c t o r   i n   u s e r _ i n t e r e s t _ v e c t o r s ]                                                   f o r   j ,   _   i n   e n u m e r a t e   u n i q u e _ i n t e r e s t s   ]  What does this look like? Row j of i  x is column j of  x. That is, it has 1 for each user with that interest  and 0 for each user without that interest. For example, u  ] is Big Data, and so  ] is:  because users 0, 8, and 9 indicated interest in Big Data. We can now use cosine similarity again. If precisely the same users are interested in two topics, their similarity will be 1. If no two users are interested in both topics, their similarity will be 0:  For example, we can find the interests most similar to Big Data  interest 0  using:  which suggests the following similar interests:  n t e r e s t _ u s e r _ m a t r i u s e r _ i n t e r e s t _ m a t r i n i q u e _ i n t e r e s t s [ 0 i n t e r e s t _ u s e r _ m a t r i x [ 0 [ 1 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   1 ,   1 ,   0 ,   0 ,   0 ,   0 ,   0 ] i n t e r e s t _ s i m i l a r i t i e s   =   [ [ c o s i n e _ s i m i l a r i t y   u s e r _ v e c t o r _ i ,   u s e r _ v e c t o r _ j                                                         f o r   u s e r _ v e c t o r _ j   i n   i n t e r e s t _ u s e r _ m a t r i x ]                                                     f o r   u s e r _ v e c t o r _ i   i n   i n t e r e s t _ u s e r _ m a t r i x ] d e f   m o s t _ s i m i l a r _ i n t e r e s t s _ t o   i n t e r e s t _ i d :   i n t   :           s i m i l a r i t i e s   =   i n t e r e s t _ s i m i l a r i t i e s [ i n t e r e s t _ i d ]           p a i r s   =   [   u n i q u e _ i n t e r e s t s [ o t h e r _ i n t e r e s t _ i d ] ,   s i m i l a r i t y                               f o r   o t h e r _ i n t e r e s t _ i d ,   s i m i l a r i t y   i n   e n u m e r a t e   s i m i l a r i t i e s                               i f   i n t e r e s t _ i d   ! =   o t h e r _ i n t e r e s t _ i d   a n d   s i m i l a r i t y   >   0 ]           r e t u r n   s o r t e d   p a i r s ,                                       k e y = l a m b d a   p a i r :   p a i r [ - 1 ] ,                                       r e v e r s e = T r u e   [   ' H a d o o p ' ,   0 . 8 1 6 4 9 6 5 8 0 9 2 7 7 2 6 1   ,       ' J a v a ' ,   0 . 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6   ,       ' M a p R e d u c e ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' S p a r k ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' S t o r m ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' C a s s a n d r a ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' a r t i f i c i a l   i n t e l l i g e n c e ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' d e e p   l e a r n i n g ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,    Now we can create recommendations for a user by summing up the similarities of the interests similar to his:  For user 0, this generates the following  seemingly reasonable  recommendations:      ' n e u r a l   n e t w o r k s ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' H B a s e ' ,   0 . 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3   ] d e f   i t e m _ b a s e d _ s u g g e s t i o n s   u s e r _ i d :   i n t ,                                                         i n c l u d e _ c u r r e n t _ i n t e r e s t s :   b o o l   =   F a l s e   :              A d d   u p   t h e   s i m i l a r   i n t e r e s t s           s u g g e s t i o n s   =   d e f a u l t d i c t   f l o a t             u s e r _ i n t e r e s t _ v e c t o r   =   u s e r _ i n t e r e s t _ v e c t o r s [ u s e r _ i d ]           f o r   i n t e r e s t _ i d ,   i s _ i n t e r e s t e d   i n   e n u m e r a t e   u s e r _ i n t e r e s t _ v e c t o r   :                   i f   i s _ i n t e r e s t e d   = =   1 :                           s i m i l a r _ i n t e r e s t s   =   m o s t _ s i m i l a r _ i n t e r e s t s _ t o   i n t e r e s t _ i d                             f o r   i n t e r e s t ,   s i m i l a r i t y   i n   s i m i l a r _ i n t e r e s t s :                                   s u g g e s t i o n s [ i n t e r e s t ]   + =   s i m i l a r i t y                S o r t   t h e m   b y   w e i g h t           s u g g e s t i o n s   =   s o r t e d   s u g g e s t i o n s . i t e m s     ,                                                     k e y = l a m b d a   p a i r :   p a i r [ - 1 ] ,                                                     r e v e r s e = T r u e               i f   i n c l u d e _ c u r r e n t _ i n t e r e s t s :                   r e t u r n   s u g g e s t i o n s           e l s e :                   r e t u r n   [   s u g g e s t i o n ,   w e i g h t                                     f o r   s u g g e s t i o n ,   w e i g h t   i n   s u g g e s t i o n s                                   i f   s u g g e s t i o n   n o t   i n   u s e r s _ i n t e r e s t s [ u s e r _ i d ] ] [   ' M a p R e d u c e ' ,   1 . 8 6 1 8 0 7 3 1 9 5 6 5 7 9 9   ,       ' P o s t g r e s ' ,   1 . 3 1 6 4 9 6 5 8 0 9 2 7 7 2 6 3   ,       ' M o n g o D B ' ,   1 . 3 1 6 4 9 6 5 8 0 9 2 7 7 2 6 3   ,       ' N o S Q L ' ,   1 . 2 8 4 4 5 7 0 5 0 3 7 6 1 7 3 2   ,       ' p r o g r a m m i n g   l a n g u a g e s ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' M y S Q L ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' H a s k e l l ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' d a t a b a s e s ' ,   0 . 5 7 7 3 5 0 2 6 9 1 8 9 6 2 5 8   ,       ' n e u r a l   n e t w o r k s ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' d e e p   l e a r n i n g ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' C + + ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,       ' a r t i f i c i a l   i n t e l l i g e n c e ' ,   0 . 4 0 8 2 4 8 2 9 0 4 6 3 8 6 3 1   ,    Matrix Factorization As we’ve seen, we can represent our users’ preferences as a [  ] matrix of 0s and 1s, where the 1s represent liked items and the  0s unliked items. Sometimes you might actually have numeric ratings; for example, when you write an Amazon review you assign the item a score ranging from 1 to 5 stars. You could still represent these by numbers in a [  ] matrix  ignoring for now the problem of what to do about  unrated items . In this section we’ll assume we have such ratings data and try to learn a model that can predict the rating for a given user and item. One way of approaching the problem is to assume that every user has some latent “type,” which can be represented as a vector of numbers, and that each item similarly has some latent “type.” If the user types are represented as a [ transpose of the item types is represented as a [ their product is a [ of building such a model is by “factoring” the preferences matrix into the product of a user matrix and an item matrix.  Possibly this idea of latent types reminds you of the word embeddings we developed in Chapter 21. Hold on to that idea.  Rather than working with our made-up 10-user dataset, we’ll work with the MovieLens 100k dataset, which contains ratings from 0 to 5 for many movies from many users. Each user has only rated a small subset of the movies. We’ll use this to try to build a system that can predict the rating for any given  user, movie  pair. We’ll train it to predict well on the movies  ] matrix, and the ] matrix, ] matrix. Accordingly, one way      ' P y t h o n ' ,   0 . 2 8 8 6 7 5 1 3 4 5 9 4 8 1 2 9   ,       ' R ' ,   0 . 2 8 8 6 7 5 1 3 4 5 9 4 8 1 2 9   ] n u m _ u s e r s , n u m _ i t e m s n u m _ u s e r s , n u m _ i t e m s n u m _ u s e r s ,   d i m d i m ,   n u m _ i t e m s n u m _ u s e r s ,   n u m _ i t e m s  each user has rated; hopefully then it will generalize to movies the user hasn’t rated. To start with, let’s acquire the dataset. You can download it from http:  files.grouplens.org datasets movielens ml-100k.zip. Unzip it and extract the files; we’ll only use two of them:  As is often the case, we’ll introduce a N work with:  e to make things easier to  NOTE  The movie ID and user IDs are actually integers, but they’re not consecutive, which means if we worked with them as integers we’d end up with a lot of wasted dimensions  unless we renumbered everything . So to keep it simpler we’ll just treat them as strings.  Now let’s read in the data and explore it. The movies file is pipe-delimited and has many columns. We only care about the first two, which are the ID and the title:     T h i s   p o i n t s   t o   t h e   c u r r e n t   d i r e c t o r y ,   m o d i f y   i f   y o u r   f i l e s   a r e   e l s e w h e r e .   M O V I E S   =   " u . i t e m "          p i p e - d e l i m i t e d :   m o v i e _ i d  t i t l e  . . .   R A T I N G S   =   " u . d a t a "        t a b - d e l i m i t e d :   u s e r _ i d ,   m o v i e _ i d ,   r a t i n g ,   t i m e s t a m p a m e d T u p l f r o m   t y p i n g   i m p o r t   N a m e d T u p l e     c l a s s   R a t i n g   N a m e d T u p l e   :           u s e r _ i d :   s t r           m o v i e _ i d :   s t r           r a t i n g :   f l o a t i m p o r t   c s v      W e   s p e c i f y   t h i s   e n c o d i n g   t o   a v o i d   a   U n i c o d e D e c o d e E r r o r .      S e e :   h t t p s :     s t a c k o v e r f l o w . c o m   a   5 3 1 3 6 1 6 8   1 0 7 6 3 4 6 .   w i t h   o p e n   M O V I E S ,   e n c o d i n g = " i s o - 8 8 5 9 - 1 "     a s   f :           r e a d e r   =   c s v . r e a d e r   f ,   d e l i m i t e r = "  "             m o v i e s   =   { m o v i e _ i d :   t i t l e   f o r   m o v i e _ i d ,   t i t l e ,   * _   i n   r e a d e r }  The ratings file is tab-delimited and contains four columns for u  d,  d, r  g  1 to 5 , and t  p. We’ll ignore the timestamp, as  we don’t need it:  There’s a lot of interesting exploratory analysis you can do on this data; for instance, you might be interested in the average ratings for Star Wars movies  the dataset is from 1998, which means it predates The Phantom Menace by a year :  They’re all pretty highly rated:  s e r _ i m o v i e _ i a t i n i m e s t a m    C r e a t e   a   l i s t   o f   [ R a t i n g ]   w i t h   o p e n   R A T I N G S ,   e n c o d i n g = " i s o - 8 8 5 9 - 1 "     a s   f :           r e a d e r   =   c s v . r e a d e r   f ,   d e l i m i t e r = " \ t "             r a t i n g s   =   [ R a t i n g   u s e r _ i d ,   m o v i e _ i d ,   f l o a t   r a t i n g                                     f o r   u s e r _ i d ,   m o v i e _ i d ,   r a t i n g ,   _   i n   r e a d e r ]        1 6 8 2   m o v i e s   r a t e d   b y   9 4 3   u s e r s   a s s e r t   l e n   m o v i e s     = =   1 6 8 2   a s s e r t   l e n   l i s t   { r a t i n g . u s e r _ i d   f o r   r a t i n g   i n   r a t i n g s }       = =   9 4 3 i m p o r t   r e        D a t a   s t r u c t u r e   f o r   a c c u m u l a t i n g   r a t i n g s   b y   m o v i e _ i d   s t a r _ w a r s _ r a t i n g s   =   { m o v i e _ i d :   [ ]                                             f o r   m o v i e _ i d ,   t i t l e   i n   m o v i e s . i t e m s                                                 i f   r e . s e a r c h   " S t a r   W a r s  E m p i r e   S t r i k e s  J e d i " ,   t i t l e   }        I t e r a t e   o v e r   r a t i n g s ,   a c c u m u l a t i n g   t h e   S t a r   W a r s   o n e s   f o r   r a t i n g   i n   r a t i n g s :           i f   r a t i n g . m o v i e _ i d   i n   s t a r _ w a r s _ r a t i n g s :                   s t a r _ w a r s _ r a t i n g s [ r a t i n g . m o v i e _ i d ] . a p p e n d   r a t i n g . r a t i n g          C o m p u t e   t h e   a v e r a g e   r a t i n g   f o r   e a c h   m o v i e   a v g _ r a t i n g s   =   [   s u m   t i t l e _ r a t i n g s         l e n   t i t l e _ r a t i n g s   ,   m o v i e _ i d                                   f o r   m o v i e _ i d ,   t i t l e _ r a t i n g s   i n   s t a r _ w a r s _ r a t i n g s . i t e m s     ]        A n d   t h e n   p r i n t   t h e m   i n   o r d e r   f o r   a v g _ r a t i n g ,   m o v i e _ i d   i n   s o r t e d   a v g _ r a t i n g s ,   r e v e r s e = T r u e   :           p r i n t   f " { a v g _ r a t i n g : . 2 f }   { m o v i e s [ m o v i e _ i d ] } "    So let’s try to come up with a model to predict these ratings. As a first step, let’s split the ratings data into train, validation, and test sets:  It’s always good to have a simple baseline model and make sure that ours does better than that. Here a simple baseline model might be “predict the average rating.” We’ll be using mean squared error as our metric, so let’s see how the baseline does on our test set:  Given our embeddings, the predicted ratings are given by the matrix product of the user embeddings and the movie embeddings. For a given user and movie, that value is just the dot product of the corresponding embeddings. So let’s start by creating the embeddings. We’ll represent them as d ts where the keys are IDs and the values are vectors, which will allow us to easily retrieve the embedding for a given ID:  4 . 3 6   S t a r   W a r s     1 9 7 7     4 . 2 0   E m p i r e   S t r i k e s   B a c k ,   T h e     1 9 8 0     4 . 0 1   R e t u r n   o f   t h e   J e d i     1 9 8 3   i m p o r t   r a n d o m   r a n d o m . s e e d   0     r a n d o m . s h u f f l e   r a t i n g s       s p l i t 1   =   i n t   l e n   r a t i n g s     *   0 . 7     s p l i t 2   =   i n t   l e n   r a t i n g s     *   0 . 8 5       t r a i n   =   r a t i n g s [ : s p l i t 1 ]                                7 0 %   o f   t h e   d a t a   v a l i d a t i o n   =   r a t i n g s [ s p l i t 1 : s p l i t 2 ]          1 5 %   o f   t h e   d a t a   t e s t   =   r a t i n g s [ s p l i t 2 : ]                                  1 5 %   o f   t h e   d a t a a v g _ r a t i n g   =   s u m   r a t i n g . r a t i n g   f o r   r a t i n g   i n   t r a i n         l e n   t r a i n     b a s e l i n e _ e r r o r   =   s u m     r a t i n g . r a t i n g   -   a v g _ r a t i n g     * *   2                                             f o r   r a t i n g   i n   t e s t         l e n   t e s t          T h i s   i s   w h a t   w e   h o p e   t o   d o   b e t t e r   t h a n   a s s e r t   1 . 2 6   <   b a s e l i n e _ e r r o r   <   1 . 2 7 i c  By now we should be pretty expert at writing training loops:  f r o m   s c r a t c h . d e e p _ l e a r n i n g   i m p o r t   r a n d o m _ t e n s o r     E M B E D D I N G _ D I M   =   2        F i n d   u n i q u e   i d s   u s e r _ i d s   =   { r a t i n g . u s e r _ i d   f o r   r a t i n g   i n   r a t i n g s }   m o v i e _ i d s   =   { r a t i n g . m o v i e _ i d   f o r   r a t i n g   i n   r a t i n g s }        T h e n   c r e a t e   a   r a n d o m   v e c t o r   p e r   i d   u s e r _ v e c t o r s   =   { u s e r _ i d :   r a n d o m _ t e n s o r   E M B E D D I N G _ D I M                                     f o r   u s e r _ i d   i n   u s e r _ i d s }   m o v i e _ v e c t o r s   =   { m o v i e _ i d :   r a n d o m _ t e n s o r   E M B E D D I N G _ D I M                                       f o r   m o v i e _ i d   i n   m o v i e _ i d s } f r o m   t y p i n g   i m p o r t   L i s t   i m p o r t   t q d m   f r o m   s c r a t c h . l i n e a r _ a l g e b r a   i m p o r t   d o t     d e f   l o o p   d a t a s e t :   L i s t [ R a t i n g ] ,                     l e a r n i n g _ r a t e :   f l o a t   =   N o n e     - >   N o n e :           w i t h   t q d m . t q d m   d a t a s e t     a s   t :                   l o s s   =   0 . 0                   f o r   i ,   r a t i n g   i n   e n u m e r a t e   t   :                           m o v i e _ v e c t o r   =   m o v i e _ v e c t o r s [ r a t i n g . m o v i e _ i d ]                           u s e r _ v e c t o r   =   u s e r _ v e c t o r s [ r a t i n g . u s e r _ i d ]                           p r e d i c t e d   =   d o t   u s e r _ v e c t o r ,   m o v i e _ v e c t o r                             e r r o r   =   p r e d i c t e d   -   r a t i n g . r a t i n g                           l o s s   + =   e r r o r   * *   2                             i f   l e a r n i n g _ r a t e   i s   n o t   N o n e :                                              p r e d i c t e d   =   m _ 0   *   u _ 0   +   . . .   +   m _ k   *   u _ k                                      S o   e a c h   u _ j   e n t e r s   o u t p u t   w i t h   c o e f f i c e n t   m _ j                                      a n d   e a c h   m _ j   e n t e r s   o u t p u t   w i t h   c o e f f i c i e n t   u _ j                                   u s e r _ g r a d i e n t   =   [ e r r o r   *   m _ j   f o r   m _ j   i n   m o v i e _ v e c t o r ]                                   m o v i e _ g r a d i e n t   =   [ e r r o r   *   u _ j   f o r   u _ j   i n   u s e r _ v e c t o r ]                                        T a k e   g r a d i e n t   s t e p s                                   f o r   j   i n   r a n g e   E M B E D D I N G _ D I M   :                                           u s e r _ v e c t o r [ j ]   - =   l e a r n i n g _ r a t e   *   u s e r _ g r a d i e n t [ j ]                                           m o v i e _ v e c t o r [ j ]   - =   l e a r n i n g _ r a t e   *   m o v i e _ g r a d i e n t [ j ]                             t . s e t _ d e s c r i p t i o n   f " a v g   l o s s :   { l o s s         i   +   1   } "    And now we can train our model  that is, find the optimal embeddings . For me it worked best if I decreased the learning rate a little each epoch:  This model is pretty apt to overfit the training set. I got the best results with  2, which got me an average loss on the test set of about  0.89.  NOTE  If you wanted higher-dimensional embeddings, you could try regularization like we used in “Regularization”. In particular, at each gradient update you could shrink the weights toward 0. I was not able to get any better results that way.  Now, inspect the learned vectors. There’s no reason to expect the two components to be particularly meaningful, so we’ll use principal component analysis:  Let’s transform our vectors to represent the principal components and join in the movie IDs and average ratings:  l e a r n i n g _ r a t e   =   0 . 0 5   f o r   e p o c h   i n   r a n g e   2 0   :           l e a r n i n g _ r a t e   * =   0 . 9           p r i n t   e p o c h ,   l e a r n i n g _ r a t e             l o o p   t r a i n ,   l e a r n i n g _ r a t e = l e a r n i n g _ r a t e             l o o p   v a l i d a t i o n     l o o p   t e s t   E M B E D D I N G _ D I M = f r o m   s c r a t c h . w o r k i n g _ w i t h _ d a t a   i m p o r t   p c a ,   t r a n s f o r m     o r i g i n a l _ v e c t o r s   =   [ v e c t o r   f o r   v e c t o r   i n   m o v i e _ v e c t o r s . v a l u e s     ]   c o m p o n e n t s   =   p c a   o r i g i n a l _ v e c t o r s ,   2   r a t i n g s _ b y _ m o v i e   =   d e f a u l t d i c t   l i s t     f o r   r a t i n g   i n   r a t i n g s :           r a t i n g s _ b y _ m o v i e [ r a t i n g . m o v i e _ i d ] . a p p e n d   r a t i n g . r a t i n g       v e c t o r s   =   [    The top 25 are all highly rated, while the bottom 25 are mostly low-rated  or unrated in the training data , which suggests that the first principal component is mostly capturing “how good is this movie?” It’s hard for me to make much sense of the second component; and, indeed the two-dimensional embeddings performed only slightly better than the one-dimensional embeddings, suggesting that whatever the second component captured is possibly very subtle.  Presumably one of the larger MovieLens datasets would have more interesting things going on.   For Further Exploration  Surprise is a Python library for “building and analyzing recommender systems” that seems reasonably popular and up-to- date. The Netflix Prize was a somewhat famous competition to build a better system to recommend movies to Netflix users.            m o v i e _ i d ,             s u m   r a t i n g s _ b y _ m o v i e [ m o v i e _ i d ]         l e n   r a t i n g s _ b y _ m o v i e [ m o v i e _ i d ]   ,             m o v i e s [ m o v i e _ i d ] ,             v e c t o r             f o r   m o v i e _ i d ,   v e c t o r   i n   z i p   m o v i e _ v e c t o r s . k e y s     ,                                                                   t r a n s f o r m   o r i g i n a l _ v e c t o r s ,   c o m p o n e n t s       ]        P r i n t   t o p   2 5   a n d   b o t t o m   2 5   b y   f i r s t   p r i n c i p a l   c o m p o n e n t   p r i n t   s o r t e d   v e c t o r s ,   k e y = l a m b d a   v :   v [ - 1 ] [ 0 ]   [ : 2 5 ]     p r i n t   s o r t e d   v e c t o r s ,   k e y = l a m b d a   v :   v [ - 1 ] [ 0 ]   [ - 2 5 : ]    Chapter 24. Databases and SQL  Memory is man’s greatest friend and worst enemy.  —Gilbert Parker  The data you need will often live in databases, systems designed for efficiently storing and querying data. The bulk of these are relational databases, such as PostgreSQL, MySQL, and SQL Server, which store data in tables and are typically queried using Structured Query Language  SQL , a declarative language for manipulating data. SQL is a pretty essential part of the data scientist’s toolkit. In this chapter, we’ll create NotQuiteABase, a Python implementation of something that’s not quite a database. We’ll also cover the basics of SQL while showing how they work in our not-quite database, which is the most “from scratch” way I could think of to help you understand what they’re doing. My hope is that solving problems in NotQuiteABase will give you a good sense of how you might solve the same problems using SQL.  CREATE TABLE and INSERT A relational database is a collection of tables, and of relationships among them. A table is simply a collection of rows, not unlike some of the matrices we’ve been working with. However, a table also has associated with it a fixed schema consisting of column names and column types. For example, imagine a u  s dataset containing for each user her  d, n  e, and n  s:  s e r u s e r _ i a m u m _ f r i e n d u s e r s   =   [ [ 0 ,   " H e r o " ,   0 ] ,                     [ 1 ,   " D u n n " ,   2 ] ,                     [ 2 ,   " S u e " ,   3 ] ,                     [ 3 ,   " C h i " ,   3 ] ]  In SQL, we might create this table with:  Notice that we specified that the u integers  and that u missing value and is sort of like our N string of length 200 or less. We’ll use Python types in a similar way.  d and n d isn’t allowed to be N  s must be L, which indicates a  e  and that the name should be a  NOTE  SQL is almost completely case and indentation insensitive. The capitalization and indentation style here is my preferred style. If you start learning SQL, you will surely encounter other examples styled differently.  You can insert the rows with I  T statements:  Notice also that SQL statements need to end with semicolons, and that SQL requires single quotes for its strings. In NotQuiteABase, you’ll create a T Then to insert a row, you’ll use the table’s i  e by specifying a similar schema. t method, which takes a t of row values that need to be in the same order as the table’s column  names. Behind the scenes, we’ll store each row as a d values. A real database would never use such a space-wasting representation, but doing so will make NotQuiteABase much easier to work with.  t from column names to  C R E A T E   T A B L E   u s e r s               u s e r _ i d   I N T   N O T   N U L L ,           n a m e   V A R C H A R   2 0 0   ,           n u m _ f r i e n d s   I N T   ; s e r _ i u m _ f r i e n d s e r _ i U L o n N S E R I N S E R T   I N T O   u s e r s     u s e r _ i d ,   n a m e ,   n u m _ f r i e n d s     V A L U E S     0 ,   ' H e r o ' ,   0   ; a b l n s e r l i s i c  We’ll implement the NotQuiteABase T implement one method at a time. Let’s start by getting out of the way some imports and type aliases:  e as a giant class, which we’ll  Let’s start with the constructor. To create a NotQuiteABase table, we’ll need to pass in a list of column names, and a list of column types, just as you would if you were creating a table in a SQL database:  We’ll add a helper method to get the type of a column:  And we’ll add an i inserting are valid. In particular, you have to provide the correct number of values, and each has to be the correct type  or N  t method that checks that the values you’re  e :  a b l f r o m   t y p i n g   i m p o r t   T u p l e ,   S e q u e n c e ,   L i s t ,   A n y ,   C a l l a b l e ,   D i c t ,   I t e r a t o r   f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t        A   f e w   t y p e   a l i a s e s   w e ' l l   u s e   l a t e r   R o w   =   D i c t [ s t r ,   A n y ]                                                    A   d a t a b a s e   r o w   W h e r e C l a u s e   =   C a l l a b l e [ [ R o w ] ,   b o o l ]                      P r e d i c a t e   f o r   a   s i n g l e   r o w   H a v i n g C l a u s e   =   C a l l a b l e [ [ L i s t [ R o w ] ] ,   b o o l ]        P r e d i c a t e   o v e r   m u l t i p l e   r o w s c l a s s   T a b l e :           d e f   _ _ i n i t _ _   s e l f ,   c o l u m n s :   L i s t [ s t r ] ,   t y p e s :   L i s t [ t y p e ]     - >   N o n e :                   a s s e r t   l e n   c o l u m n s     = =   l e n   t y p e s   ,   "    o f   c o l u m n s   m u s t   = =      o f   t y p e s "                     s e l f . c o l u m n s   =   c o l u m n s                      N a m e s   o f   c o l u m n s                   s e l f . t y p e s   =   t y p e s                              D a t a   t y p e s   o f   c o l u m n s                   s e l f . r o w s :   L i s t [ R o w ]   =   [ ]                  n o   d a t a   y e t           d e f   c o l 2 t y p e   s e l f ,   c o l :   s t r     - >   t y p e :                   i d x   =   s e l f . c o l u m n s . i n d e x   c o l                  F i n d   t h e   i n d e x   o f   t h e   c o l u m n ,                   r e t u r n   s e l f . t y p e s [ i d x ]                              a n d   r e t u r n   i t s   t y p e . n s e r o n         d e f   i n s e r t   s e l f ,   v a l u e s :   l i s t     - >   N o n e :                      C h e c k   f o r   r i g h t      o f   v a l u e s                   i f   l e n   v a l u e s     ! =   l e n   s e l f . t y p e s   :                           r a i s e   V a l u e E r r o r   f " Y o u   n e e d   t o   p r o v i d e   { l e n   s e l f . t y p e s   }   v a l u e s "                          C h e c k   f o r   r i g h t   t y p e s   o f   v a l u e s                   f o r   v a l u e ,   t y p 3   i n   z i p   v a l u e s ,   s e l f . t y p e s   :    In an actual SQL database you’d explicitly specify whether any given column was allowed to contain null  N e  values; to make our lives simpler we’ll just say that any column can. We’ll also introduce a few dunder methods that allow us to treat a table like a L  ], which we’ll mostly use for testing our code:  And we’ll add a method to pretty-print our table:  Now we can create our U  s table:                          i f   n o t   i s i n s t a n c e   v a l u e ,   t y p 3     a n d   v a l u e   i s   n o t   N o n e :                                   r a i s e   T y p e E r r o r   f " E x p e c t e d   t y p e   { t y p 3 }   b u t   g o t   { v a l u e } "                          A d d   t h e   c o r r e s p o n d i n g   d i c t   a s   a   " r o w "                   s e l f . r o w s . a p p e n d   d i c t   z i p   s e l f . c o l u m n s ,   v a l u e s       o n i s t [ R o w         d e f   _ _ g e t i t e m _ _   s e l f ,   i d x :   i n t     - >   R o w :                   r e t u r n   s e l f . r o w s [ i d x ]             d e f   _ _ i t e r _ _   s e l f     - >   I t e r a t o r [ R o w ] :                   r e t u r n   i t e r   s e l f . r o w s               d e f   _ _ l e n _ _   s e l f     - >   i n t :                   r e t u r n   l e n   s e l f . r o w s           d e f   _ _ r e p r _ _   s e l f   :                   " " " P r e t t y   r e p r e s e n t a t i o n   o f   t h e   t a b l e :   c o l u m n s   t h e n   r o w s " " "                   r o w s   =   " \ n " . j o i n   s t r   r o w     f o r   r o w   i n   s e l f . r o w s                       r e t u r n   f " { s e l f . c o l u m n s } \ n { r o w s } " s e r    C o n s t r u c t o r   r e q u i r e s   c o l u m n   n a m e s   a n d   t y p e s   u s e r s   =   T a b l e   [ ' u s e r _ i d ' ,   ' n a m e ' ,   ' n u m _ f r i e n d s ' ] ,   [ i n t ,   s t r ,   i n t ]     u s e r s . i n s e r t   [ 0 ,   " H e r o " ,   0 ]     u s e r s . i n s e r t   [ 1 ,   " D u n n " ,   2 ]     u s e r s . i n s e r t   [ 2 ,   " S u e " ,   3 ]     u s e r s . i n s e r t   [ 3 ,   " C h i " ,   3 ]     u s e r s . i n s e r t   [ 4 ,   " T h o r " ,   3 ]     u s e r s . i n s e r t   [ 5 ,   " C l i v e " ,   2 ]     u s e r s . i n s e r t   [ 6 ,   " H i c k s " ,   3 ]     u s e r s . i n s e r t   [ 7 ,   " D e v i n " ,   2 ]     u s e r s . i n s e r t   [ 8 ,   " K a t e " ,   2 ]      If you now p   , you’ll see:  The list-like API makes it easy to write tests:  We’ve got a lot more functionality to add.  UPDATE Sometimes you need to update the data that’s already in the database. For instance, if Dunn acquires another friend, you might need to do this:  The key features are:  What table to update Which rows to update Which fields to update What their new values should be  We’ll add a similar u will be a d  e method to NotQuiteABase. Its first argument  t whose keys are the columns to update and whose values are  u s e r s . i n s e r t   [ 9 ,   " K l e i n " ,   3 ]     u s e r s . i n s e r t   [ 1 0 ,   " J e n " ,   1 ]   r i n t   u s e r s [ ' u s e r _ i d ' ,   ' n a m e ' ,   ' n u m _ f r i e n d s ' ]   { ' u s e r _ i d ' :   0 ,   ' n a m e ' :   ' H e r o ' ,   ' n u m _ f r i e n d s ' :   0 }   { ' u s e r _ i d ' :   1 ,   ' n a m e ' :   ' D u n n ' ,   ' n u m _ f r i e n d s ' :   2 }   { ' u s e r _ i d ' :   2 ,   ' n a m e ' :   ' S u e ' ,   ' n u m _ f r i e n d s ' :   3 }   . . . a s s e r t   l e n   u s e r s     = =   1 1   a s s e r t   u s e r s [ 1 ] [ ' n a m e ' ]   = =   ' D u n n ' U P D A T E   u s e r s   S E T   n u m _ f r i e n d s   =   3   W H E R E   u s e r _ i d   =   1 ; p d a t i c  the new values for those fields. Its second  optional  argument should be a  e that returns T  e for rows that should be updated, and F  otherwise:  after which we can simply do this:  DELETE There are two ways to delete rows from a table in SQL. The dangerous way deletes every row from a table:  The less dangerous way adds a W match a certain condition:  E clause and deletes only rows that  p r e d i c a t r u a l s e         d e f   u p d a t e   s e l f ,                                 u p d a t e s :   D i c t [ s t r ,   A n y ] ,                                 p r e d i c a t e :   W h e r e C l a u s e   =   l a m b d a   r o w :   T r u e   :                      F i r s t   m a k e   s u r e   t h e   u p d a t e s   h a v e   v a l i d   n a m e s   a n d   t y p e s                   f o r   c o l u m n ,   n e w _ v a l u e   i n   u p d a t e s . i t e m s     :                           i f   c o l u m n   n o t   i n   s e l f . c o l u m n s :                                   r a i s e   V a l u e E r r o r   f " i n v a l i d   c o l u m n :   { c o l u m n } "                               t y p 3   =   s e l f . c o l 2 t y p e   c o l u m n                             i f   n o t   i s i n s t a n c e   n e w _ v a l u e ,   t y p 3     a n d   n e w _ v a l u e   i s   n o t   N o n e :                                   r a i s e   T y p e E r r o r   f " e x p e c t e d   t y p e   { t y p 3 } ,   b u t   g o t   { n e w _ v a l u e } "                          N o w   u p d a t e                   f o r   r o w   i n   s e l f . r o w s :                           i f   p r e d i c a t e   r o w   :                                   f o r   c o l u m n ,   n e w _ v a l u e   i n   u p d a t e s . i t e m s     :                                           r o w [ c o l u m n ]   =   n e w _ v a l u e a s s e r t   u s e r s [ 1 ] [ ' n u m _ f r i e n d s ' ]   = =   2                              O r i g i n a l   v a l u e     u s e r s . u p d a t e   { ' n u m _ f r i e n d s '   :   3 } ,                                  S e t   n u m _ f r i e n d s   =   3                             l a m b d a   r o w :   r o w [ ' u s e r _ i d ' ]   = =   1            i n   r o w s   w h e r e   u s e r _ i d   = =   1     a s s e r t   u s e r s [ 1 ] [ ' n u m _ f r i e n d s ' ]   = =   3                              U p d a t e d   v a l u e D E L E T E   F R O M   u s e r s ; H E R  It’s easy to add this functionality to our T  e:  e function  i.e., a W  If you supply a p the rows that satisfy it. If you don’t supply one, the default p always returns T For example:  e, and you will delete every row.  E clause , this deletes only  SELECT Typically you don’t inspect SQL tables directly. Instead you query them with a S  T statement:  You can also use S  T statements to calculate fields:  We’ll give our T method accepts two optional arguments:  e class a s  t method that returns a new T  e. The  s specifies the names of the columns you want to  keep in the result. If you don’t supply it, the result contains all the  D E L E T E   F R O M   u s e r s   W H E R E   u s e r _ i d   =   1 ; a b l         d e f   d e l e t e   s e l f ,   p r e d i c a t e :   W h e r e C l a u s e   =   l a m b d a   r o w :   T r u e     - >   N o n e :                   " " " D e l e t e   a l l   r o w s   m a t c h i n g   p r e d i c a t e " " "                   s e l f . r o w s   =   [ r o w   f o r   r o w   i n   s e l f . r o w s   i f   n o t   p r e d i c a t e   r o w   ] r e d i c a t H E R r e d i c a t e r u    W e ' r e   n o t   a c t u a l l y   g o i n g   t o   r u n   t h e s e   u s e r s . d e l e t e   l a m b d a   r o w :   r o w [ " u s e r _ i d " ]   = =   1          D e l e t e s   r o w s   w i t h   u s e r _ i d   = =   1   u s e r s . d e l e t e                                                                          D e l e t e s   e v e r y   r o w E L E C S E L E C T   *   F R O M   u s e r s ;                                                         - -   g e t   t h e   e n t i r e   c o n t e n t s   S E L E C T   *   F R O M   u s e r s   L I M I T   2 ;                                         - -   g e t   t h e   f i r s t   t w o   r o w s   S E L E C T   u s e r _ i d   F R O M   u s e r s ;                                             - -   o n l y   g e t   s p e c i f i c   c o l u m n s   S E L E C T   u s e r _ i d   F R O M   u s e r s   W H E R E   n a m e   =   ' D u n n ' ;     - -   o n l y   g e t   s p e c i f i c   r o w s E L E C S E L E C T   L E N G T H   n a m e     A S   n a m e _ l e n g t h   F R O M   u s e r s ; a b l e l e c a b l k e e p _ c o l u m n  columns.  s is a dictionary whose keys are new column names and whose values are functions specifying how to compute the values of the new columns. We’ll peek at the type annotations of those functions to figure out the types of the new columns, so the functions will need to have annotated return types.  If you were to supply neither of them, you’d simply get back a copy of the table:  a d d i t i o n a l _ c o l u m n         d e f   s e l e c t   s e l f ,                                 k e e p _ c o l u m n s :   L i s t [ s t r ]   =   N o n e ,                                 a d d i t i o n a l _ c o l u m n s :   D i c t [ s t r ,   C a l l a b l e ]   =   N o n e     - >   ' T a b l e ' :                     i f   k e e p _ c o l u m n s   i s   N o n e :                      I f   n o   c o l u m n s   s p e c i f i e d ,                           k e e p _ c o l u m n s   =   s e l f . c o l u m n s        r e t u r n   a l l   c o l u m n s                     i f   a d d i t i o n a l _ c o l u m n s   i s   N o n e :                           a d d i t i o n a l _ c o l u m n s   =   { }                        N e w   c o l u m n   n a m e s   a n d   t y p e s                   n e w _ c o l u m n s   =   k e e p _ c o l u m n s   +   l i s t   a d d i t i o n a l _ c o l u m n s . k e y s                         k e e p _ t y p e s   =   [ s e l f . c o l 2 t y p e   c o l     f o r   c o l   i n   k e e p _ c o l u m n s ]                        T h i s   i s   h o w   t o   g e t   t h e   r e t u r n   t y p e   f r o m   a   t y p e   a n n o t a t i o n .                      I t   w i l l   c r a s h   i f   ` c a l c u l a t i o n `   d o e s n ' t   h a v e   a   r e t u r n   t y p e .                   a d d _ t y p e s   =   [ c a l c u l a t i o n . _ _ a n n o t a t i o n s _ _ [ ' r e t u r n ' ]                                             f o r   c a l c u l a t i o n   i n   a d d i t i o n a l _ c o l u m n s . v a l u e s     ]                        C r e a t e   a   n e w   t a b l e   f o r   r e s u l t s                   n e w _ t a b l e   =   T a b l e   n e w _ c o l u m n s ,   k e e p _ t y p e s   +   a d d _ t y p e s                       f o r   r o w   i n   s e l f . r o w s :                           n e w _ r o w   =   [ r o w [ c o l u m n ]   f o r   c o l u m n   i n   k e e p _ c o l u m n s ]                           f o r   c o l u m n _ n a m e ,   c a l c u l a t i o n   i n   a d d i t i o n a l _ c o l u m n s . i t e m s     :                                   n e w _ r o w . a p p e n d   c a l c u l a t i o n   r o w                               n e w _ t a b l e . i n s e r t   n e w _ r o w                       r e t u r n   n e w _ t a b l e  NOTE  Remember way back in Chapter 2 when we said that type annotations don’t actually do anything? Well, here’s the counterexample. But look at the convoluted procedure we have to go through to get at them.  t returns a new T  e, while the typical SQL S  Our s produces some sort of transient result set  unless you explicitly insert the results into a table . We’ll also need w  t methods. Both are pretty simple:  e and l  T just  after which we can easily construct NotQuiteABase equivalents to the preceding SQL statements:  e l e c a b l E L E C h e r i m i         d e f   w h e r e   s e l f ,   p r e d i c a t e :   W h e r e C l a u s e   =   l a m b d a   r o w :   T r u e     - >   ' T a b l e ' :                   " " " R e t u r n   o n l y   t h e   r o w s   t h a t   s a t i s f y   t h e   s u p p l i e d   p r e d i c a t e " " "                   w h e r e _ t a b l e   =   T a b l e   s e l f . c o l u m n s ,   s e l f . t y p e s                     f o r   r o w   i n   s e l f . r o w s :                           i f   p r e d i c a t e   r o w   :                                   v a l u e s   =   [ r o w [ c o l u m n ]   f o r   c o l u m n   i n   s e l f . c o l u m n s ]                                   w h e r e _ t a b l e . i n s e r t   v a l u e s                     r e t u r n   w h e r e _ t a b l e             d e f   l i m i t   s e l f ,   n u m _ r o w s :   i n t     - >   ' T a b l e ' :                   " " " R e t u r n   o n l y   t h e   f i r s t   ` n u m _ r o w s `   r o w s " " "                   l i m i t _ t a b l e   =   T a b l e   s e l f . c o l u m n s ,   s e l f . t y p e s                     f o r   i ,   r o w   i n   e n u m e r a t e   s e l f . r o w s   :                           i f   i   > =   n u m _ r o w s :                                   b r e a k                           v a l u e s   =   [ r o w [ c o l u m n ]   f o r   c o l u m n   i n   s e l f . c o l u m n s ]                           l i m i t _ t a b l e . i n s e r t   v a l u e s                     r e t u r n   l i m i t _ t a b l e    S E L E C T   *   F R O M   u s e r s ;   a l l _ u s e r s   =   u s e r s . s e l e c t       a s s e r t   l e n   a l l _ u s e r s     = =   1 1        S E L E C T   *   F R O M   u s e r s   L I M I T   2 ;   t w o _ u s e r s   =   u s e r s . l i m i t   2     a s s e r t   l e n   t w o _ u s e r s     = =   2      Notice that for the multiline “fluent” queries we have to wrap the whole query in parentheses.  GROUP BY Another common SQL operation is G with identical values in specified columns and produces aggregate values like M For example, you might want to find the number of users and the smallest  Y, which groups together rows  T and S  X and C  N and M  M.  d for each possible name length:  Every field we S  T needs to be either in the G  h is  or an aggregate computation  which m  Y clause  which d and  s are .     S E L E C T   u s e r _ i d   F R O M   u s e r s ;   j u s t _ i d s   =   u s e r s . s e l e c t   k e e p _ c o l u m n s = [ " u s e r _ i d " ]     a s s e r t   j u s t _ i d s . c o l u m n s   = =   [ ' u s e r _ i d ' ]        S E L E C T   u s e r _ i d   F R O M   u s e r s   W H E R E   n a m e   =   ' D u n n ' ;   d u n n _ i d s   =               u s e r s           . w h e r e   l a m b d a   r o w :   r o w [ " n a m e " ]   = =   " D u n n "             . s e l e c t   k e e p _ c o l u m n s = [ " u s e r _ i d " ]         a s s e r t   l e n   d u n n _ i d s     = =   1   a s s e r t   d u n n _ i d s [ 0 ]   = =   { " u s e r _ i d " :   1 }        S E L E C T   L E N G T H   n a m e     A S   n a m e _ l e n g t h   F R O M   u s e r s ;   d e f   n a m e _ l e n g t h   r o w     - >   i n t :   r e t u r n   l e n   r o w [ " n a m e " ]       n a m e _ l e n g t h s   =   u s e r s . s e l e c t   k e e p _ c o l u m n s = [ ] ,                                                           a d d i t i o n a l _ c o l u m n s   =   { " n a m e _ l e n g t h " :   n a m e _ l e n g t h }     a s s e r t   n a m e _ l e n g t h s [ 0 ] [ ' n a m e _ l e n g t h ' ]   = =   l e n   " H e r o "   R O U P   B I A O U N U u s e r _ i S E L E C T   L E N G T H   n a m e     a s   n a m e _ l e n g t h ,     M I N   u s e r _ i d     A S   m i n _ u s e r _ i d ,     C O U N T   *     A S   n u m _ u s e r s   F R O M   u s e r s   G R O U P   B Y   L E N G T H   n a m e   ; E L E C R O U P   B n a m e _ l e n g t i n _ u s e r _ i n u m _ u s e r  G clause that behaves similarly to a W  SQL also supports a H clause, except that its filter is applied to the aggregates  whereas a W would filter out rows before aggregation even took place . You might want to know the average number of friends for users whose names start with specific letters but see only the results for letters whose corresponding average is greater than 1.  Yes, some of these examples are contrived.   NOTE  Functions for working with strings vary across SQL implementations; some databases might instead use S  G or something else.  You can also compute overall aggregates. In that case, you leave off the  Y:  To add this functionality to NotQuiteABase T es, we’ll add a g method. It takes the names of the columns you want to group by, a dictionary of the aggregation functions you want to run over each group, and an optional predicate called h g that operates on multiple rows. Then it does the following steps:  1. Creates a d  t to map t  es  of the group-by values  to  rows  containing the group-by values . Recall that you can’t use lists as d  t keys; you have to use tuples.  A V I N H E R E H E R E S E L E C T   S U B S T R   n a m e ,   1 ,   1     A S   f i r s t _ l e t t e r ,     A V G   n u m _ f r i e n d s     A S   a v g _ n u m _ f r i e n d s   F R O M   u s e r s   G R O U P   B Y   S U B S T R   n a m e ,   1 ,   1     H A V I N G   A V G   n u m _ f r i e n d s     >   1 ; U B S T R I N G R O U P   B S E L E C T   S U M   u s e r _ i d     a s   u s e r _ i d _ s u m   F R O M   u s e r s   W H E R E   u s e r _ i d   >   1 ; a b l r o u p _ b y a v i n e f a u l t d i c u p l i c  2. Iterates over the rows of the table, populating the d 3. Creates a new table with the correct output columns.  t.  4. Iterates over the d  t and populates the output table,  applying the h  g filter, if any.  An actual database would almost certainly do this in a more efficient manner.   NOTE  Again, let’s see how we would do the equivalent of the preceding SQL statements. The n  h metrics are:  e f a u l t d i c e f a u l t d i c a v i n         d e f   g r o u p _ b y   s e l f ,                                     g r o u p _ b y _ c o l u m n s :   L i s t [ s t r ] ,                                     a g g r e g a t e s :   D i c t [ s t r ,   C a l l a b l e ] ,                                     h a v i n g :   H a v i n g C l a u s e   =   l a m b d a   g r o u p :   T r u e     - >   ' T a b l e ' :                     g r o u p e d _ r o w s   =   d e f a u l t d i c t   l i s t                          P o p u l a t e   g r o u p s                   f o r   r o w   i n   s e l f . r o w s :                           k e y   =   t u p l e   r o w [ c o l u m n ]   f o r   c o l u m n   i n   g r o u p _ b y _ c o l u m n s                             g r o u p e d _ r o w s [ k e y ] . a p p e n d   r o w                          R e s u l t   t a b l e   c o n s i s t s   o f   g r o u p _ b y   c o l u m n s   a n d   a g g r e g a t e s                   n e w _ c o l u m n s   =   g r o u p _ b y _ c o l u m n s   +   l i s t   a g g r e g a t e s . k e y s                         g r o u p _ b y _ t y p e s   =   [ s e l f . c o l 2 t y p e   c o l     f o r   c o l   i n   g r o u p _ b y _ c o l u m n s ]                   a g g r e g a t e _ t y p e s   =   [ a g g . _ _ a n n o t a t i o n s _ _ [ ' r e t u r n ' ]                                                         f o r   a g g   i n   a g g r e g a t e s . v a l u e s     ]                   r e s u l t _ t a b l e   =   T a b l e   n e w _ c o l u m n s ,   g r o u p _ b y _ t y p e s   +   a g g r e g a t e _ t y p e s                       f o r   k e y ,   r o w s   i n   g r o u p e d _ r o w s . i t e m s     :                           i f   h a v i n g   r o w s   :                                   n e w _ r o w   =   l i s t   k e y                                     f o r   a g g r e g a t e _ n a m e ,   a g g r e g a t e _ f n   i n   a g g r e g a t e s . i t e m s     :                                           n e w _ r o w . a p p e n d   a g g r e g a t e _ f n   r o w s                                       r e s u l t _ t a b l e . i n s e r t   n e w _ r o w                       r e t u r n   r e s u l t _ t a b l e a m e _ l e n g t  The f  r metrics:  and the u  m is:  d e f   m i n _ u s e r _ i d   r o w s     - >   i n t :           r e t u r n   m i n   r o w [ " u s e r _ i d " ]   f o r   r o w   i n   r o w s       d e f   l e n g t h   r o w s     - >   i n t :           r e t u r n   l e n   r o w s       s t a t s _ b y _ l e n g t h   =               u s e r s           . s e l e c t   a d d i t i o n a l _ c o l u m n s = { " n a m e _ l e n g t h "   :   n a m e _ l e n g t h }             . g r o u p _ b y   g r o u p _ b y _ c o l u m n s = [ " n a m e _ l e n g t h " ] ,                               a g g r e g a t e s = { " m i n _ u s e r _ i d "   :   m i n _ u s e r _ i d ,                                                       " n u m _ u s e r s "   :   l e n g t h }       i r s t _ l e t t e d e f   f i r s t _ l e t t e r _ o f _ n a m e   r o w :   R o w     - >   s t r :           r e t u r n   r o w [ " n a m e " ] [ 0 ]   i f   r o w [ " n a m e " ]   e l s e   " "     d e f   a v e r a g e _ n u m _ f r i e n d s   r o w s :   L i s t [ R o w ]     - >   f l o a t :           r e t u r n   s u m   r o w [ " n u m _ f r i e n d s " ]   f o r   r o w   i n   r o w s         l e n   r o w s       d e f   e n o u g h _ f r i e n d s   r o w s :   L i s t [ R o w ]     - >   b o o l :           r e t u r n   a v e r a g e _ n u m _ f r i e n d s   r o w s     >   1     a v g _ f r i e n d s _ b y _ l e t t e r   =               u s e r s           . s e l e c t   a d d i t i o n a l _ c o l u m n s = { ' f i r s t _ l e t t e r '   :   f i r s t _ l e t t e r _ o f _ n a m e }             . g r o u p _ b y   g r o u p _ b y _ c o l u m n s = [ ' f i r s t _ l e t t e r ' ] ,                               a g g r e g a t e s = { " a v g _ n u m _ f r i e n d s "   :   a v e r a g e _ n u m _ f r i e n d s } ,                               h a v i n g = e n o u g h _ f r i e n d s       s e r _ i d _ s u d e f   s u m _ u s e r _ i d s   r o w s :   L i s t [ R o w ]     - >   i n t :           r e t u r n   s u m   r o w [ " u s e r _ i d " ]   f o r   r o w   i n   r o w s       u s e r _ i d _ s u m   =               u s e r s           . w h e r e   l a m b d a   r o w :   r o w [ " u s e r _ i d " ]   >   1             . g r o u p _ b y   g r o u p _ b y _ c o l u m n s = [ ] ,                               a g g r e g a t e s = {   " u s e r _ i d _ s u m "   :   s u m _ u s e r _ i d s   }        ORDER BY Frequently, you’ll want to sort your results. For example, you might want to know the  alphabetically  first two names of your users:  This is easy to implement by giving our T takes an o  r function:  e an o  y method that  which we can then use as follows:  The SQL O C  ascending  or D for each sort field; here we’d have to bake that into our o  Y lets you specify A  C  descending  r function.  JOIN Relational database tables are often normalized, which means that they’re organized to minimize redundancy. For example, when we work with our users’ interests in Python, we can just give each user a l t containing his interests. SQL tables can’t typically contain lists, so the typical solution is to create a second table called u  s containing the one-to-many  S E L E C T   *   F R O M   u s e r s   O R D E R   B Y   n a m e   L I M I T   2 ; a b l r d e r _ b r d e         d e f   o r d e r _ b y   s e l f ,   o r d e r :   C a l l a b l e [ [ R o w ] ,   A n y ]     - >   ' T a b l e ' :                   n e w _ t a b l e   =   s e l f . s e l e c t                      m a k e   a   c o p y                   n e w _ t a b l e . r o w s . s o r t   k e y = o r d e r                     r e t u r n   n e w _ t a b l e f r i e n d l i e s t _ l e t t e r s   =               a v g _ f r i e n d s _ b y _ l e t t e r           . o r d e r _ b y   l a m b d a   r o w :   - r o w [ " a v g _ n u m _ f r i e n d s " ]             . l i m i t   4       R D E R   B S E S r d e i s s e r _ i n t e r e s t  relationship between u  ds and i  ts. In SQL you might do:  whereas in NotQuiteABase you’d create the table:  NOTE  There’s still plenty of redundancy—the interest “SQL” is stored in two different places. In a real database you might store u table and then create a third table, i you could store the interest names only once each. Here that would just make our examples more complicated than they need to be.  s, mapping i  d in the u  d and i  d to i  t so  When our data lives across different tables, how do we analyze it? By  Ning the tables together. A J  N combines rows in the left table with  corresponding rows in the right table, where the meaning of “corresponding” is based on how we specify the join. For example, to find the users interested in SQL you’d query:  N says that, for each row in u  The J and associate that row with every row in u  s, we should look at the u  s containing the  s e r _ i n t e r e s C R E A T E   T A B L E   u s e r _ i n t e r e s t s               u s e r _ i d   I N T   N O T   N U L L ,           i n t e r e s t   V A R C H A R   1 0 0     N O T   N U L L     ; u s e r _ i n t e r e s t s   =   T a b l e   [ ' u s e r _ i d ' ,   ' i n t e r e s t ' ] ,   [ i n t ,   s t r ]     u s e r _ i n t e r e s t s . i n s e r t   [ 0 ,   " S Q L " ]     u s e r _ i n t e r e s t s . i n s e r t   [ 0 ,   " N o S Q L " ]     u s e r _ i n t e r e s t s . i n s e r t   [ 2 ,   " S Q L " ]     u s e r _ i n t e r e s t s . i n s e r t   [ 2 ,   " M y S Q L " ]   s e r _ i n t e r e s t _ i s e r _ i n t e r e s t s n t e r e s t n t e r e s t _ i n t e r e s J O I O I S E L E C T   u s e r s . n a m e   F R O M   u s e r s   J O I N   u s e r _ i n t e r e s t s   O N   u s e r s . u s e r _ i d   =   u s e r _ i n t e r e s t s . u s e r _ i d   W H E R E   u s e r _ i n t e r e s t s . i n t e r e s t   =   ' S Q L ' O I s e r s e r _ i d s e r _ i n t e r e s t  d.  N. This is an I  N and also which columns to N, which returns the combinations of rows  same u Notice we had to specify which tables to J join O  and only the combinations of rows  that match according to the specified join criteria. There is also a L N, which—in addition to the combinations of matching rows—returns a row for each left-table row with no matching rows  in which case, the fields that would have come from the right table are all N Using a L  N, it’s easy to count the number of interests each user has:  L .  The L the joined dataset  with N s , and C  N ensures that users with no interests will still have rows in  L values for the fields coming from T counts only values that are non-N  L.  The NotQuiteABase j simply joins two tables on whatever columns they have in common. Even so, it’s not trivial to write:  n implementation will be more restrictive—it  s e r _ i O I N N E R   J O I E F T   J O I U L E F T   J O I S E L E C T   u s e r s . i d ,   C O U N T   u s e r _ i n t e r e s t s . i n t e r e s t     A S   n u m _ i n t e r e s t s   F R O M   u s e r s   L E F T   J O I N   u s e r _ i n t e r e s t s   O N   u s e r s . u s e r _ i d   =   u s e r _ i n t e r e s t s . u s e r _ i d E F T   J O I U L u s e r _ i n t e r e s t O U N U L o i         d e f   j o i n   s e l f ,   o t h e r _ t a b l e :   ' T a b l e ' ,   l e f t _ j o i n :   b o o l   =   F a l s e     - >   ' T a b l e ' :                     j o i n _ o n _ c o l u m n s   =   [ c   f o r   c   i n   s e l f . c o l u m n s                          c o l u m n s   i n                                                         i f   c   i n   o t h e r _ t a b l e . c o l u m n s ]                b o t h   t a b l e s                     a d d i t i o n a l _ c o l u m n s   =   [ c   f o r   c   i n   o t h e r _ t a b l e . c o l u m n s      c o l u m n s   o n l y                                                               i f   c   n o t   i n   j o i n _ o n _ c o l u m n s ]          i n   r i g h t   t a b l e                        a l l   c o l u m n s   f r o m   l e f t   t a b l e   +   a d d i t i o n a l _ c o l u m n s   f r o m   r i g h t   t a b l e                   n e w _ c o l u m n s   =   s e l f . c o l u m n s   +   a d d i t i o n a l _ c o l u m n s                   n e w _ t y p e s   =   s e l f . t y p e s   +   [ o t h e r _ t a b l e . c o l 2 t y p e   c o l                                                                         f o r   c o l   i n   a d d i t i o n a l _ c o l u m n s ]                     j o i n _ t a b l e   =   T a b l e   n e w _ c o l u m n s ,   n e w _ t y p e s      So, we could find users interested in SQL with:  And we could get the interest counts with:  In SQL, there is also a R that have no matches, and a F  N, which keeps rows from the right table  N, which keeps rows from                    f o r   r o w   i n   s e l f . r o w s :                           d e f   i s _ j o i n   o t h e r _ r o w   :                                   r e t u r n   a l l   o t h e r _ r o w [ c ]   = =   r o w [ c ]   f o r   c   i n   j o i n _ o n _ c o l u m n s                               o t h e r _ r o w s   =   o t h e r _ t a b l e . w h e r e   i s _ j o i n   . r o w s                                E a c h   o t h e r   r o w   t h a t   m a t c h e s   t h i s   o n e   p r o d u c e s   a   r e s u l t   r o w .                           f o r   o t h e r _ r o w   i n   o t h e r _ r o w s :                                   j o i n _ t a b l e . i n s e r t   [ r o w [ c ]   f o r   c   i n   s e l f . c o l u m n s ]   +                                                                       [ o t h e r _ r o w [ c ]   f o r   c   i n   a d d i t i o n a l _ c o l u m n s ]                                  I f   n o   r o w s   m a t c h   a n d   i t ' s   a   l e f t   j o i n ,   o u t p u t   w i t h   N o n e s .                           i f   l e f t _ j o i n   a n d   n o t   o t h e r _ r o w s :                                   j o i n _ t a b l e . i n s e r t   [ r o w [ c ]   f o r   c   i n   s e l f . c o l u m n s ]   +                                                                       [ N o n e   f o r   c   i n   a d d i t i o n a l _ c o l u m n s ]                       r e t u r n   j o i n _ t a b l e s q l _ u s e r s   =               u s e r s           . j o i n   u s e r _ i n t e r e s t s             . w h e r e   l a m b d a   r o w :   r o w [ " i n t e r e s t " ]   = =   " S Q L "             . s e l e c t   k e e p _ c o l u m n s = [ " n a m e " ]       d e f   c o u n t _ i n t e r e s t s   r o w s :   L i s t [ R o w ]     - >   i n t :           " " " c o u n t s   h o w   m a n y   r o w s   h a v e   n o n - N o n e   i n t e r e s t s " " "           r e t u r n   l e n   [ r o w   f o r   r o w   i n   r o w s   i f   r o w [ " i n t e r e s t " ]   i s   n o t   N o n e ]       u s e r _ i n t e r e s t _ c o u n t s   =               u s e r s           . j o i n   u s e r _ i n t e r e s t s ,   l e f t _ j o i n = T r u e             . g r o u p _ b y   g r o u p _ b y _ c o l u m n s = [ " u s e r _ i d " ] ,                               a g g r e g a t e s = { " n u m _ i n t e r e s t s "   :   c o u n t _ i n t e r e s t s   }       I G H T   J O I U L L   O U T E R   J O I  both tables that have no matches. We won’t implement either of those.  Subqueries In SQL, you can S were tables. So, if you wanted to find the smallest u interested in SQL, you could use a subquery.  Of course, you could do the same calculation using a J  N, but that wouldn’t illustrate subqueries.   N  the results of queries as if they  T from  and J  d of anyone  Given the way we’ve designed NotQuiteABase, we get this for free.  Our query results are actual tables.   e is “Hero” ,  Indexes To find rows containing a specific value  say, where n NotQuiteABase has to inspect every row in the table. If the table has a lot of rows, this can take a very long time. Similarly, our j n algorithm is extremely inefficient. For each row in the left table, it inspects every row in the right table to see if it’s a match. With two large tables this could take approximately forever. Also, you’d often like to apply constraints to some of your columns. For example, in your u different users to have the same u  s table you probably don’t want to allow two  d.  E L E C O I s e r _ i O I S E L E C T   M I N   u s e r _ i d     A S   m i n _ u s e r _ i d   F R O M     S E L E C T   u s e r _ i d   F R O M   u s e r _ i n t e r e s t s   W H E R E   i n t e r e s t   =   ' S Q L '     s q l _ i n t e r e s t s ; l i k e s _ s q l _ u s e r _ i d s   =               u s e r _ i n t e r e s t s           . w h e r e   l a m b d a   r o w :   r o w [ " i n t e r e s t " ]   = =   " S Q L "             . s e l e c t   k e e p _ c o l u m n s = [ ' u s e r _ i d ' ]           l i k e s _ s q l _ u s e r _ i d s . g r o u p _ b y   g r o u p _ b y _ c o l u m n s = [ ] ,                                                           a g g r e g a t e s = {   " m i n _ u s e r _ i d "   :   m i n _ u s e r _ i d   }   a m o i s e r s e r _ i  Indexes solve all these problems. If the u on u scanning the whole table. If the u  d, a smart j  s table had an index n algorithm could find matches directly rather than  s table had a “unique” index on  d, you’d get an error if you tried to insert a duplicate.  Each table in a database can have one or more indexes, which allow you to quickly look up rows by key columns, efficiently join tables together, and enforce unique constraints on columns or combinations of columns. Designing and using indexes well is something of a black art  which varies somewhat depending on the specific database , but if you end up doing a lot of database work it’s worth learning about.  Query Optimization Recall the query to find all users who are interested in SQL:  In NotQuiteABase there are  at least  two different ways to write this query. You could filter the u  s table before performing the join:  Or you could filter the results of the join:  s e r _ i n t e r e s t s e r _ i o i s e r u s e r _ i S E L E C T   u s e r s . n a m e   F R O M   u s e r s   J O I N   u s e r _ i n t e r e s t s   O N   u s e r s . u s e r _ i d   =   u s e r _ i n t e r e s t s . u s e r _ i d   W H E R E   u s e r _ i n t e r e s t s . i n t e r e s t   =   ' S Q L ' s e r _ i n t e r e s t             u s e r _ i n t e r e s t s           . w h e r e   l a m b d a   r o w :   r o w [ " i n t e r e s t " ]   = =   " S Q L "             . j o i n   u s e r s             . s e l e c t   [ " n a m e " ]                   u s e r _ i n t e r e s t s           . j o i n   u s e r s             . w h e r e   l a m b d a   r o w :   r o w [ " i n t e r e s t " ]   = =   " S Q L "      You’ll end up with the same results either way, but filter-before-join is almost certainly more efficient, since in that case j n has many fewer rows to operate on. In SQL, you generally wouldn’t worry about this. You “declare” the results you want and leave it up to the query engine to execute them  and use indexes efficiently .  NoSQL A recent trend in databases is toward nonrelational “NoSQL” databases, which don’t represent data in tables. For instance, MongoDB is a popular schemaless database whose elements are arbitrarily complex JSON documents rather than rows. There are column databases that store data in columns instead of rows  good when data has many columns but queries need few of them , key value stores that are optimized for retrieving single  complex  values by their keys, databases for storing and traversing graphs, databases that are optimized to run across multiple datacenters, databases that are designed to run in memory, databases for storing time-series data, and hundreds more. Tomorrow’s flavor of the day might not even exist now, so I can’t do much more than let you know that NoSQL is a thing. So now you know. It’s a thing.  For Further Exploration  If you’d like to download a relational database to play with, SQLite is fast and tiny, while MySQL and PostgreSQL are larger and featureful. All are free and have lots of documentation.          . s e l e c t   [ " n a m e " ]       o i  If you want to explore NoSQL, MongoDB is very simple to get started with, which can be both a blessing and somewhat of a curse. It also has pretty good documentation. The Wikipedia article on NoSQL almost certainly now contains links to databases that didn’t even exist when this book was written.   Chapter 25. MapReduce  The future has already arrived. It’s just not evenly distributed yet.  —William Gibson  MapReduce is a programming model for performing parallel processing on large datasets. Although it is a powerful technique, its basics are relatively simple. Imagine we have a collection of items we’d like to process somehow. For instance, the items might be website logs, the texts of various books, image files, or anything else. A basic version of the MapReduce algorithm consists of the following steps:  1. Use a m  r function to turn each item into zero or more  key value pairs.  Often this is called the m already a Python function called m the two.   p function, but there is p and we don’t need to confuse  2. Collect together all the pairs with identical keys.  3. Use a r  r function on each collection of grouped values to  produce output values for the corresponding key.  NOTE  MapReduce is sort of passé, so much so that I considered removing this chapter from the second edition. But I decided it’s still an interesting topic, so I ended up leaving it in  obviously .  This is all sort of abstract, so let’s look at a specific example. There are few absolute rules of data science, but one of them is that your first MapReduce example has to involve counting words.  a p p e a a e d u c e  Example: Word Count DataSciencester has grown to millions of users! This is great for your job security, but it makes routine analyses slightly more difficult. For example, your VP of Content wants to know what sorts of things people are talking about in their status updates. As a first attempt, you decide to count the words that appear, so that you can prepare a report on the most frequent ones. When you had a few hundred users, this was simple to do:  s  status updates  is suddenly too  With millions of users the set of d big to fit on your computer. If you can just fit this into the MapReduce model, you can use some “big data” infrastructure that your engineers have implemented. First, we need a function that turns a document into a sequence of key value pairs. We’ll want our output to be grouped by word, which means that the keys should be words. And for each word, we’ll just emit the value 1 to indicate that this pair corresponds to one occurrence of the word:  f r o m   t y p i n g   i m p o r t   L i s t   f r o m   c o l l e c t i o n s   i m p o r t   C o u n t e r     d e f   t o k e n i z e   d o c u m e n t :   s t r     - >   L i s t [ s t r ] :           " " " J u s t   s p l i t   o n   w h i t e s p a c e " " "           r e t u r n   d o c u m e n t . s p l i t         d e f   w o r d _ c o u n t _ o l d   d o c u m e n t s :   L i s t [ s t r ]   :           " " " W o r d   c o u n t   n o t   u s i n g   M a p R e d u c e " " "           r e t u r n   C o u n t e r   w o r d                   f o r   d o c u m e n t   i n   d o c u m e n t s                   f o r   w o r d   i n   t o k e n i z e   d o c u m e n t     o c u m e n t f r o m   t y p i n g   i m p o r t   I t e r a t o r ,   T u p l e     d e f   w c _ m a p p e r   d o c u m e n t :   s t r     - >   I t e r a t o r [ T u p l e [ s t r ,   i n t ] ] :           " " " F o r   e a c h   w o r d   i n   t h e   d o c u m e n t ,   e m i t     w o r d ,   1   " " "           f o r   w o r d   i n   t o k e n i z e   d o c u m e n t   :                   y i e l d     w o r d ,   1    Skipping the “plumbing” step 2 for the moment, imagine that for some word we’ve collected a list of the corresponding counts we emitted. To produce the overall count for that word, then, we just need:  Returning to step 2, we now need to collect the results from w feed them to w one computer:  r. Let’s think about how we would do this on just  r and  Imagine that we have three documents [  ].  Then w  r applied to the first document yields the two pairs    and     . After we’ve gone through all three  documents, the c  r contains:  f r o m   t y p i n g   i m p o r t   I t e r a b l e     d e f   w c _ r e d u c e r   w o r d :   s t r ,                                 c o u n t s :   I t e r a b l e [ i n t ]     - >   I t e r a t o r [ T u p l e [ s t r ,   i n t ] ] :           " " " S u m   u p   t h e   c o u n t s   f o r   a   w o r d " " "           y i e l d     w o r d ,   s u m   c o u n t s     c _ m a p p e c _ r e d u c e f r o m   c o l l e c t i o n s   i m p o r t   d e f a u l t d i c t     d e f   w o r d _ c o u n t   d o c u m e n t s :   L i s t [ s t r ]     - >   L i s t [ T u p l e [ s t r ,   i n t ] ] :           " " " C o u n t   t h e   w o r d s   i n   t h e   i n p u t   d o c u m e n t s   u s i n g   M a p R e d u c e " " "             c o l l e c t o r   =   d e f a u l t d i c t   l i s t          T o   s t o r e   g r o u p e d   v a l u e s             f o r   d o c u m e n t   i n   d o c u m e n t s :                   f o r   w o r d ,   c o u n t   i n   w c _ m a p p e r   d o c u m e n t   :                           c o l l e c t o r [ w o r d ] . a p p e n d   c o u n t               r e t u r n   [ o u t p u t                           f o r   w o r d ,   c o u n t s   i n   c o l l e c t o r . i t e m s                               f o r   o u t p u t   i n   w c _ r e d u c e r   w o r d ,   c o u n t s   ] " d a t a   s c i e n c e " ,   " b i g   d a t a " , " s c i e n c e   f i c t i o n " c _ m a p p e   " d a t a " ,   1 " s c i e n c e " ,   1 o l l e c t o { " d a t a "   :   [ 1 ,   1 ] ,     " s c i e n c e "   :   [ 1 ,   1 ] ,     " b i g "   :   [ 1 ] ,     " f i c t i o n "   :   [ 1 ] }  Then w  r produces the counts for each word:  Why MapReduce? As mentioned earlier, the primary benefit of MapReduce is that it allows us to distribute computations by moving the processing to the data. Imagine we want to word-count across billions of documents. Our original  non-MapReduce  approach requires the machine doing the processing to have access to every document. This means that the documents all need to either live on that machine or else be transferred to it during processing. More important, it means that the machine can process only one document at a time.  NOTE  Possibly it can process up to a few at a time if it has multiple cores and if the code is rewritten to take advantage of them. But even so, all the documents still have to get to that machine.  Imagine now that our billions of documents are scattered across 100 machines. With the right infrastructure  and glossing over some of the details , we can do the following:  Have each machine run the mapper on its documents, producing lots of key value pairs. Distribute those key value pairs to a number of “reducing” machines, making sure that the pairs corresponding to any given key all end up on the same machine. Have each reducing machine group the pairs by key and then run the reducer on each set of values.  c _ r e d u c e [   " d a t a " ,   2   ,     " s c i e n c e " ,   2   ,     " b i g " ,   1   ,     " f i c t i o n " ,   1   ]  Return each  key, output  pair.  What is amazing about this is that it scales horizontally. If we double the number of machines, then  ignoring certain fixed costs of running a MapReduce system  our computation should run approximately twice as fast. Each mapper machine will only need to do half as much work, and  assuming there are enough distinct keys to further distribute the reducer work  the same is true for the reducer machines.  MapReduce More Generally If you think about it for a minute, all of the word count–specific code in the previous example is contained in the w functions. This means that with a couple of changes we have a much more general framework  that still runs on a single machine . We could use generic types to fully type-annotate our m but it would end up being kind of a mess pedagogically, so in this chapter we’ll be much more casual about our type annotations:  r and w  e function,  Now we can write a general m  e function:  c _ m a p p e c _ r e d u c e r a p _ r e d u c f r o m   t y p i n g   i m p o r t   C a l l a b l e ,   I t e r a b l e ,   A n y ,   T u p l e        A   k e y   v a l u e   p a i r   i s   j u s t   a   2 - t u p l e   K V   =   T u p l e [ A n y ,   A n y ]        A   M a p p e r   i s   a   f u n c t i o n   t h a t   r e t u r n s   a n   I t e r a b l e   o f   k e y   v a l u e   p a i r s   M a p p e r   =   C a l l a b l e [ . . . ,   I t e r a b l e [ K V ] ]        A   R e d u c e r   i s   a   f u n c t i o n   t h a t   t a k e s   a   k e y   a n d   a n   i t e r a b l e   o f   v a l u e s      a n d   r e t u r n s   a   k e y   v a l u e   p a i r   R e d u c e r   =   C a l l a b l e [ [ A n y ,   I t e r a b l e ] ,   K V ] a p _ r e d u c d e f   m a p _ r e d u c e   i n p u t s :   I t e r a b l e ,                                 m a p p e r :   M a p p e r ,                                 r e d u c e r :   R e d u c e r     - >   L i s t [ K V ] :           " " " R u n   M a p R e d u c e   o n   t h e   i n p u t s   u s i n g   m a p p e r   a n d   r e d u c e r " " "           c o l l e c t o r   =   d e f a u l t d i c t   l i s t      Then we can count words simply by using:  This gives us the flexibility to solve a wide variety of problems. Before we proceed, notice that w corresponding to each key. This kind of aggregation is common enough that it’s worth abstracting it out:  r is just summing the values  After which we can easily create:  and so on.            f o r   i n p u t   i n   i n p u t s :                   f o r   k e y ,   v a l u e   i n   m a p p e r   i n p u t   :                           c o l l e c t o r [ k e y ] . a p p e n d   v a l u e               r e t u r n   [ o u t p u t                           f o r   k e y ,   v a l u e s   i n   c o l l e c t o r . i t e m s                               f o r   o u t p u t   i n   r e d u c e r   k e y ,   v a l u e s   ] w o r d _ c o u n t s   =   m a p _ r e d u c e   d o c u m e n t s ,   w c _ m a p p e r ,   w c _ r e d u c e r   c _ r e d u c e d e f   v a l u e s _ r e d u c e r   v a l u e s _ f n :   C a l l a b l e     - >   R e d u c e r :           " " " R e t u r n   a   r e d u c e r   t h a t   j u s t   a p p l i e s   v a l u e s _ f n   t o   i t s   v a l u e s " " "           d e f   r e d u c e   k e y ,   v a l u e s :   I t e r a b l e     - >   K V :                   r e t u r n     k e y ,   v a l u e s _ f n   v a l u e s                 r e t u r n   r e d u c e s u m _ r e d u c e r   =   v a l u e s _ r e d u c e r   s u m     m a x _ r e d u c e r   =   v a l u e s _ r e d u c e r   m a x     m i n _ r e d u c e r   =   v a l u e s _ r e d u c e r   m i n     c o u n t _ d i s t i n c t _ r e d u c e r   =   v a l u e s _ r e d u c e r   l a m b d a   v a l u e s :   l e n   s e t   v a l u e s           a s s e r t   s u m _ r e d u c e r   " k e y " ,   [ 1 ,   2 ,   3 ,   3 ]     = =     " k e y " ,   9     a s s e r t   m i n _ r e d u c e r   " k e y " ,   [ 1 ,   2 ,   3 ,   3 ]     = =     " k e y " ,   1     a s s e r t   m a x _ r e d u c e r   " k e y " ,   [ 1 ,   2 ,   3 ,   3 ]     = =     " k e y " ,   3     a s s e r t   c o u n t _ d i s t i n c t _ r e d u c e r   " k e y " ,   [ 1 ,   2 ,   3 ,   3 ]     = =     " k e y " ,   3    Example: Analyzing Status Updates The content VP was impressed with the word counts and asks what else you can learn from people’s status updates. You manage to extract a dataset of status updates that look like:  Let’s say we need to figure out which day of the week people talk the most about data science. In order to find this, we’ll just count how many data science updates there are on each day of the week. This means we’ll need to group by the day of week, so that’s our key. And if we emit a value of 1 for each update that contains “data science,” we can simply get the total number using s  m:  As a slightly more complicated example, imagine we need to find out for each user the most common word that she puts in her status updates. There are three possible approaches that spring to mind for the m  r:  Put the username in the key; put the words and counts in the values.  s t a t u s _ u p d a t e s   =   [           { " i d " :   2 ,             " u s e r n a m e "   :   " j o e l g r u s " ,             " t e x t "   :   " S h o u l d   I   w r i t e   a   s e c o n d   e d i t i o n   o f   m y   d a t a   s c i e n c e   b o o k ? " ,             " c r e a t e d _ a t "   :   d a t e t i m e . d a t e t i m e   2 0 1 8 ,   2 ,   2 1 ,   1 1 ,   4 7 ,   0   ,             " l i k e d _ b y "   :   [ " d a t a _ g u y " ,   " d a t a _ g a l " ,   " m i k e " ]   } ,                . . .   ] u d e f   d a t a _ s c i e n c e _ d a y _ m a p p e r   s t a t u s _ u p d a t e :   d i c t     - >   I t e r a b l e :           " " " Y i e l d s     d a y _ o f _ w e e k ,   1     i f   s t a t u s _ u p d a t e   c o n t a i n s   " d a t a   s c i e n c e "   " " "           i f   " d a t a   s c i e n c e "   i n   s t a t u s _ u p d a t e [ " t e x t " ] . l o w e r     :                   d a y _ o f _ w e e k   =   s t a t u s _ u p d a t e [ " c r e a t e d _ a t " ] . w e e k d a y                       y i e l d     d a y _ o f _ w e e k ,   1       d a t a _ s c i e n c e _ d a y s   =   m a p _ r e d u c e   s t a t u s _ u p d a t e s ,                                                                 d a t a _ s c i e n c e _ d a y _ m a p p e r ,                                                                 s u m _ r e d u c e r   a p p e  Put the word in the key; put the usernames and counts in the values. Put the username and word in the key; put the counts in the values.  If you think about it a bit more, we definitely want to group by u e, because we want to consider each person’s words separately. And we don’t want to group by w d, since our reducer will need to see all the words for each person to find out which is the most popular. This means that the first option is the right choice:  Or we could find out the number of distinct status-likers for each user:  s e r n a m o r d e f   w o r d s _ p e r _ u s e r _ m a p p e r   s t a t u s _ u p d a t e :   d i c t   :           u s e r   =   s t a t u s _ u p d a t e [ " u s e r n a m e " ]           f o r   w o r d   i n   t o k e n i z e   s t a t u s _ u p d a t e [ " t e x t " ]   :                   y i e l d     u s e r ,     w o r d ,   1         d e f   m o s t _ p o p u l a r _ w o r d _ r e d u c e r   u s e r :   s t r ,                                                               w o r d s _ a n d _ c o u n t s :   I t e r a b l e [ K V ]   :           " " "           G i v e n   a   s e q u e n c e   o f     w o r d ,   c o u n t     p a i r s ,           r e t u r n   t h e   w o r d   w i t h   t h e   h i g h e s t   t o t a l   c o u n t           " " "           w o r d _ c o u n t s   =   C o u n t e r               f o r   w o r d ,   c o u n t   i n   w o r d s _ a n d _ c o u n t s :                   w o r d _ c o u n t s [ w o r d ]   + =   c o u n t             w o r d ,   c o u n t   =   w o r d _ c o u n t s . m o s t _ c o m m o n   1   [ 0 ]             y i e l d     u s e r ,     w o r d ,   c o u n t         u s e r _ w o r d s   =   m a p _ r e d u c e   s t a t u s _ u p d a t e s ,                                                   w o r d s _ p e r _ u s e r _ m a p p e r ,                                                   m o s t _ p o p u l a r _ w o r d _ r e d u c e r   d e f   l i k e r _ m a p p e r   s t a t u s _ u p d a t e :   d i c t   :           u s e r   =   s t a t u s _ u p d a t e [ " u s e r n a m e " ]           f o r   l i k e r   i n   s t a t u s _ u p d a t e [ " l i k e d _ b y " ] :                   y i e l d     u s e r ,   l i k e r       d i s t i n c t _ l i k e r s _ p e r _ u s e r   =   m a p _ r e d u c e   s t a t u s _ u p d a t e s ,    Example: Matrix Multiplication Recall from “Matrix Multiplication” that given an [ ] matrix B, we can multiply them to form an [ the element of C in row i and column j is given by:  ] matrix A and an ] matrix C, where  This works if we represent our matrices as lists of lists, as we’ve been doing. But large matrices are sometimes sparse, which means that most of their elements equal 0. For large sparse matrices, a list of lists can be a very wasteful representation. A more compact representation stores only the locations with nonzero values:  For example, a 1 billion × 1 billion matrix has 1 quintillion entries, which would not be easy to store on a computer. But if there are only a few nonzero entries in each row, this alternative representation is many orders of magnitude smaller. Given this sort of representation, it turns out that we can use MapReduce to perform matrix multiplication in a distributed manner. To motivate our algorithm, notice that each element A ] is only used to compute the elements of C in row i, and each element B ] is only used to compute the elements of C in column j. Our goal will be for each output                                                                              l i k e r _ m a p p e r ,                                                                               c o u n t _ d i s t i n c t _ r e d u c e r   n ,   m [ m ,   k n ,   k C [ i ] [ j ]   =   s u m   A [ i ] [ x ]   *   B [ x ] [ j ]   f o r   x   i n   r a n g e   m     f r o m   t y p i n g   i m p o r t   N a m e d T u p l e     c l a s s   E n t r y   N a m e d T u p l e   :           n a m e :   s t r           i :   i n t           j :   i n t           v a l u e :   f l o a t [ i ] [ j [ i ] [ j  of our r r to be a single entry of C, which means we’ll need our mapper to emit keys identifying a single entry of C. This suggests the following:  And then:  For example, if you had these two matrices:  e d u c e d e f   m a t r i x _ m u l t i p l y _ m a p p e r   n u m _ r o w s _ a :   i n t ,   n u m _ c o l s _ b :   i n t     - >   M a p p e r :              C [ x ] [ y ]   =   A [ x ] [ 0 ]   *   B [ 0 ] [ y ]   +   . . .   +   A [ x ] [ m ]   *   B [ m ] [ y ]                         s o   a n   e l e m e n t   A [ i ] [ j ]   g o e s   i n t o   e v e r y   C [ i ] [ y ]   w i t h   c o e f   B [ j ] [ y ]              a n d   a n   e l e m e n t   B [ i ] [ j ]   g o e s   i n t o   e v e r y   C [ x ] [ j ]   w i t h   c o e f   A [ x ] [ i ]           d e f   m a p p e r   e n t r y :   E n t r y   :                   i f   e n t r y . n a m e   = =   " A " :                           f o r   y   i n   r a n g e   n u m _ c o l s _ b   :                                   k e y   =     e n t r y . i ,   y                                  w h i c h   e l e m e n t   o f   C                                   v a l u e   =     e n t r y . j ,   e n t r y . v a l u e          w h i c h   e n t r y   i n   t h e   s u m                                   y i e l d     k e y ,   v a l u e                     e l s e :                           f o r   x   i n   r a n g e   n u m _ r o w s _ a   :                                   k e y   =     x ,   e n t r y . j                                  w h i c h   e l e m e n t   o f   C                                   v a l u e   =     e n t r y . i ,   e n t r y . v a l u e          w h i c h   e n t r y   i n   t h e   s u m                                   y i e l d     k e y ,   v a l u e               r e t u r n   m a p p e r d e f   m a t r i x _ m u l t i p l y _ r e d u c e r   k e y :   T u p l e [ i n t ,   i n t ] ,                                                           i n d e x e d _ v a l u e s :   I t e r a b l e [ T u p l e [ i n t ,   i n t ] ]   :           r e s u l t s _ b y _ i n d e x   =   d e f a u l t d i c t   l i s t               f o r   i n d e x ,   v a l u e   i n   i n d e x e d _ v a l u e s :                   r e s u l t s _ b y _ i n d e x [ i n d e x ] . a p p e n d   v a l u e                  M u l t i p l y   t h e   v a l u e s   f o r   p o s i t i o n s   w i t h   t w o   v a l u e s                o n e   f r o m   A ,   a n d   o n e   f r o m   B     a n d   s u m   t h e m   u p .           s u m p r o d u c t   =   s u m   v a l u e s [ 0 ]   *   v a l u e s [ 1 ]                                             f o r   v a l u e s   i n   r e s u l t s _ b y _ i n d e x . v a l u e s                                                 i f   l e n   v a l u e s     = =   2               i f   s u m p r o d u c t   ! =   0 . 0 :                   y i e l d     k e y ,   s u m p r o d u c t    you could rewrite them as tuples:  This isn’t terribly interesting on such small matrices, but if you had millions of rows and millions of columns, it could help you a lot.    and summing over the values, we could  An Aside: Combiners One thing you have probably noticed is that many of our mappers seem to include a bunch of extra information. For example, when counting words, rather than emitting   have emitted   One reason we didn’t do this is that, in the distributed setting, we sometimes want to use combiners to reduce the amount of data that has to be transferred around from machine to machine. If one of our mapper machines sees the word data 500 times, we can tell it to combine the 500 instances of   to the reducing machine. This results in a lot less data getting moved around, which can make our algorithm substantially faster still.    and just taken the length.    into a single      before handing off  A   =   [ [ 3 ,   2 ,   0 ] ,             [ 0 ,   0 ,   0 ] ]     B   =   [ [ 4 ,   - 1 ,   0 ] ,             [ 1 0 ,   0 ,   0 ] ,             [ 0 ,   0 ,   0 ] ] e n t r i e s   =   [ E n t r y   " A " ,   0 ,   0 ,   3   ,   E n t r y   " A " ,   0 ,   1 ,     2   ,   E n t r y   " B " ,   0 ,   0 ,   4   ,                         E n t r y   " B " ,   0 ,   1 ,   - 1   ,   E n t r y   " B " ,   1 ,   0 ,   1 0   ]       m a p p e r   =   m a t r i x _ m u l t i p l y _ m a p p e r   n u m _ r o w s _ a = 2 ,   n u m _ c o l s _ b = 3     r e d u c e r   =   m a t r i x _ m u l t i p l y _ r e d u c e r        P r o d u c t   s h o u l d   b e   [ [ 3 2 ,   - 3 ,   0 ] ,   [ 0 ,   0 ,   0 ] ] .      S o   i t   s h o u l d   h a v e   t w o   e n t r i e s .   a s s e r t     s e t   m a p _ r e d u c e   e n t r i e s ,   m a p p e r ,   r e d u c e r       = =                   {     0 ,   1   ,   - 3   ,       0 ,   0   ,   3 2   }   w o r d ,   1 w o r d ,   N o n e " d a t a " ,   1 " d a t a " ,   5 0 0  Because of the way we wrote our reducer, it would handle this combined data correctly.  If we’d written it using l  n, it would not have.   For Further Exploration  Like I said, MapReduce feels a lot less popular now than it did when I wrote the first edition. It’s probably not worth investing a ton of your time. That said, the most widely used MapReduce system is Hadoop. There are various commercial and noncommercial distributions and a huge ecosystem of Hadoop-related tools. Amazon.com offers an Elastic MapReduce service that’s probably easier than setting up your own cluster. Hadoop jobs are typically high-latency, which makes them a poor choice for “real-time” analytics. A popular choice for these workloads is Spark, which can be MapReduce-y.  e  Chapter 26. Data Ethics  Grub first, then ethics.  —Bertolt Brecht  What Is Data Ethics? With the use of data comes the misuse of data. This has pretty much always been the case, but recently this idea has been reified as “data ethics” and has featured somewhat prominently in the news. For instance, in the 2016 election, a company called Cambridge Analytica improperly accessed Facebook data and used that for political ad targeting. In 2018, an autonomous car being tested by Uber struck and killed a pedestrian  there was a “safety driver” in the car, but apparently she was not paying attention at the time . Algorithms are used to predict the risk that criminals will reoffend and to sentence them accordingly. Is this more or less fair than allowing judges to determine the same? Some airlines assign families separate seats, forcing them to pay extra to sit together. Should a data scientist have stepped in to prevent this?  Many data scientists in the linked thread seem to believe so.  “Data ethics” purports to provide answers to these questions, or at least a framework for wrestling with them. I’m not so arrogant as to tell you how to think about these things  and “these things” are changing quickly , so in this chapter we’ll just take a quick tour of some of the most relevant issues and  hopefully  inspire you to think about them further.  Alas, I am not a good enough philosopher to do ethics from scratch.    No, Really, What Is Data Ethics? Well, let’s start with “what is ethics?” If you take the average of every definition you can find, you end up with something like ethics is a framework for thinking about “right” and “wrong” behavior. Data ethics, then, is a framework for thinking about right and wrong behavior involving data. Some people talk as if “data ethics” is  perhaps implicitly  a set of commandments about what you may and may not do. Some of them are hard at work creating manifestos, others crafting mandatory pledges to which they hope to make you swear. Still others are campaigning for data ethics to be made a mandatory part of the data science curriculum—hence this chapter, as a means of hedging my bets in case they succeed.  NOTE  Curiously, there is not much data suggesting that ethics courses lead to ethical behavior, in which case perhaps this campaign is itself data-unethical!  Other people  for example, yours truly  think that reasonable people will frequently disagree over subtle matters of right and wrong, and that the important part of data ethics is committing to consider the ethical consequences of your behaviors. This requires understanding the sorts of things that many “data ethics” advocates don’t approve of, but it doesn’t necessarily require agreeing with their disapproval.  Should I Care About Data Ethics? You should care about ethics whatever your job. If your job involves data, you are free to characterize your caring as “data ethics,” but you should care just as much about ethics in the nondata parts of your job. Perhaps what’s different about technology jobs is that technology scales, and that decisions made by individuals working on technology problems    whether data-related or not  have potentially wide-reaching effects. A tiny change to a news discovery algorithm could be the difference between millions of people reading an article and no one reading it. A single flawed algorithm for granting parole that’s used all over the country systematically affects millions of people, whereas a flawed-in-its- own-way parole board affects only the people who come before it. So yes, in general, you should care about what effects your work has on the world. And the broader the effects of your work, the more you need to worry about these things. Unfortunately, some of the discourse around data ethics involves people trying to force their ethical conclusions on you. Whether you should care about the same things they care about is really up to you.  Building Bad Data Products Some “data ethics” issues are the result of building bad products. For example, Microsoft released a chat bot named Tay that parroted back things tweeted to it, which the internet quickly discovered enabled them to get Tay to tweet all sorts of offensive things. It seems unlikely that anyone at Microsoft debated the ethicality of releasing a “racist” bot; most likely they simply built a bot and failed to think through how it could be abused. This is perhaps a low bar, but let’s agree that you should think about how the things you build could be abused. Another example is that Google Photos at one point used an image recognition algorithm that would sometimes classify pictures of black people as “gorillas”. Again, it is extremely unlikely that anyone at Google explicitly decided to ship this feature  let alone grappled with the “ethics” of it . Here it seems likely the problem is some combination of bad training data, model inaccuracy, and the gross offensiveness of the mistake  if the model had occasionally categorized mailboxes as fire trucks, probably no one would have cared .   In this case the solution is less obvious: how can you ensure that your trained model won’t make predictions that are in some way offensive? Of course you should train  and test  your model on a diverse range of inputs, but can you ever be sure that there isn’t some input somewhere out there that will make your model behave in a way that embarrasses you? This is a hard problem.  Google seems to have “solved” it by simply refusing to ever predict “gorilla.”     Trading Off Accuracy and Fairness Imagine you are building a model that predicts how likely people are to take some action. You do a pretty good job  Table 26-1 .  Table 26-1. A pretty good job Prediction People Actions %  Unlikely  Likely  125  125  25  75  20%  60%  Of the people you predict are unlikely to take the action, only 20% of them do. Of the people you predict are likely to take the action, 60% of them do. Seems not terrible. Now imagine that the people can be split into two groups: A and B. Some of your colleagues are concerned that your model is unfair to one of the groups. Although the model does not take group membership into account, it does consider various other factors that correlate in complicated ways with group membership. Indeed, when you break down the predictions by group, you discover surprising statistics  Table 26-2 .   Table 26-2. Surprising statistics Group Prediction People Actions %  A  A  B  B  Unlikely  100  Likely  Unlikely  Likely  25  25  100  20  15  5  60  20%  60%  20%  60%  Is your model unfair? The data scientists on your team make a variety of arguments: Argument 1  Your model classifies 80% of group A as “unlikely” but 80% of group B as “likely.” This data scientist complains that the model is treating the two groups unfairly in the sense that it is generating vastly different predictions across the two groups.  Argument 2  Argument 3  Argument 4  Regardless of group membership, if we predict “unlikely” you have a 20% chance of action, and if we predict “likely” you have a 60% chance of action. This data scientist insists that the model is “accurate” in the sense that its predictions seem to mean the same things no matter which group you belong to.  40 125 = 32% of group B were falsely labeled “likely,” whereas only 10 125 = 8% of group A were falsely labeled “likely.” This data scientist  who considers a “likely” prediction to be a bad thing  insists that the model unfairly stigmatizes group B.   20 125 = 16% of group A were falsely labeled “unlikely,” whereas only 5 125 = 4% of group B were falsely labeled “unlikely.” This data scientist  who considers an “unlikely” prediction to be a bad thing  insists that the model unfairly stigmatizes group A.  Which of these data scientists is correct? Are any of them correct? Perhaps it depends on the context. Possibly you feel one way if the two groups are “men” and “women” and another way if the two groups are “R users” and “Python users.” Or possibly not if it turns out that Python users skew male and R users skew female? Possibly you feel one way if the model is for predicting whether a DataSciencester user will apply for a job through the DataSciencester job board and another way if the model is predicting whether a user will pass such an interview. Possibly your opinion depends on the model itself, what features it takes into account, and what data it was trained on. In any event, my point is to impress upon you that there can be a tradeoff between “accuracy” and “fairness”  depending, of course, on how you define them  and that these tradeoffs don’t always have obvious “right” solutions.  Collaboration A repressive  by your standards  country’s government officials have finally decided to allow citizens to join DataSciencester. However, they insist that the users from their country not be allowed to discuss deep learning. Furthermore, they want you to report to them the names of any users who even try to seek out information on deep learning. Are this country’s data scientists better off with access to the topic-limited  and surveilled  DataSciencester that you’d be allowed to offer? Or are the proposed restrictions so awful that they’d be better off with no access at all?   Interpretability The DataSciencester HR department asks you to develop a model predicting which employees are most at risk of leaving the company, so that it can intervene and try to make them happier.  Attrition rate is an important component of the “10 Happiest Workplaces” magazine feature that your CEO aspires to appear in.    You’ve collected an assortment of historical data and are considering three models:  A decision tree A neural network A high-priced “retention expert”  One of your data scientists insists that you should just use whichever model performs best. A second insists that you not use the neural network model, as only the other two can explain their predictions, and that only explanation of the predictions can help HR institute widespread changes  as opposed to one- off interventions . A third says that while the “expert” can offer an explanation for her predictions, there’s no reason to take her at her word that it describes the real reasons she predicted the way she did. As with our other examples, there is no absolute best choice here. In some circumstances  possibly for legal reasons or if your predictions are somehow life-changing  you might prefer a model that performs worse but whose predictions can be explained. In others, you might just want the model that predicts best. In still others, perhaps there is no interpretable model that performs well.   Recommendations As we discussed in Chapter 23, a common data science application involves recommending things to people. When someone watches a YouTube video, YouTube recommends videos they should watch next. YouTube makes money through advertising and  presumably  wants to recommend videos that you are more likely to watch, so that they can show you more advertisements. However, it turns out that people like to watch videos about conspiracy theories, which tend to feature in the recommendations.  NOTE  At the time I wrote this chapter, if you searched YouTube for “saturn” the third result was “Something Is Happening On Saturn… Are THEY Hiding It?” which maybe gives you a sense of the kinds of videos I’m talking about.  Does YouTube have an obligation not to recommend conspiracy videos? Even if that’s what lots of people seem to want to watch? A different example is that if you go to google.com  or bing.com  and start typing a search, the search engine will offer suggestions to autocomplete your search. These suggestions are based  at least in part  on other people’s searches; in particular, if other people are searching for unsavory things this may be reflected in your suggestions. Should a search engine try to affirmatively filter out suggestions it doesn’t like? Google  for whatever reason  seems intent on not suggesting things related to people’s religion. For example, if you type “mitt romney m” into Bing, the first suggestion is “mitt romney mormon”  which is what I would have expected , whereas Google refuses to provide that suggestion. Indeed, Google explicitly filters out autosuggestions that it considers “offensive or disparaging”.  How it decides what’s offensive or disparaging is left vague.  And yet sometimes the truth is offensive. Is protecting people   from those suggestions the ethical thing to do? Or is it an unethical thing to do? Or is it not a question of ethics at all?  Biased Data In “Word Vectors” we used a corpus of documents to learn vector embeddings for words. These vectors were designed to exhibit distributional similarity. That is, words that appear in similar contexts should have similar vectors. In particular, any biases that exist in the training data will be reflected in the word vectors themselves. For example, if our documents are all about how R users are moral reprobates and how Python users are paragons of virtue, most likely the model will learn such associations for “Python” and “R.” More commonly, word vectors are based on some combination of Google News articles, Wikipedia, books, and crawled web pages. This means that they’ll learn whatever distributional patterns are present in those sources. For example, if the majority of news articles about software engineers are about male software engineers, then the learned vector for “software” might lie closer to vectors for other “male” words than to the vectors for “female” words. At that point any downstream applications you build using these vectors might also exhibit this closeness. Depending on the application, this may or may not be a problem for you. In that case there are various techniques that you can try to “remove” specific biases, although you’ll probably never get all of them. But it’s something you should be aware of. Similarly, as in the “photos” example in “Building Bad Data Products”, if you train a model on nonrepresentative data, there’s a strong possibility it will perform poorly in the real world, possibly in ways that are offensive or embarrassing. Along different lines, it’s also possible that your algorithms might codify actual biases that exist out in the world. For example, your parole model   may do a perfect job of predicting which released criminals get rearrested, but if those rearrests are themselves the result of biased real-world processes, then your model might be perpetuating that bias.  Data Protection You know a lot about the DataSciencester users. You know what technologies they like, who their data scientist friends are, where they work, how much they earn, how much time they spend on the site, which job postings they click on, and so forth. The VP of Monetization wants to sell this data to advertisers, who are eager to market their various “big data” solutions to your users. The Chief Scientist wants to share this data with academic researchers, who are keen to publish papers about who becomes a data scientist. The VP of Electioneering has plans to provide this data to political campaigns, most of whom are eager to recruit their own data science organizations. And the VP of Government Affairs would like to use this data to answer questions from law enforcement. Thanks to a forward-thinking VP of Contracts, your users agreed to terms of service that guarantee you the right to do pretty much whatever you want with their data. However  as you have now come to expect , various of the data scientists on your team raise various objections to these various uses. One thinks it’s wrong to hand the data over to advertisers; another worries that academics can’t be trusted to safeguard the data responsibly. A third thinks that the company should stay out of politics, while the last insists that police can’t be trusted and that collaborating with law enforcement will harm innocent people. Do any of these data scientists have a point?  In Summary   These are a lot of things to worry about! And there are countless more we haven’t mentioned, and still more that will come up in the future but that would never occur to us today.      For Further Exploration  There is no shortage of people professing important thoughts about data ethics. Searching on Twitter  or your favorite news site  is probably the best way to find out about the most current data ethics controversy. If you want something slightly more practical, Mike Loukides, Hilary Mason, and DJ Patil have written a short ebook, Ethics and Data Science, on putting data ethics into practice, which I am honor-bound to recommend on account of Mike being the person who agreed to publish Data Science from Scratch way back in 2014.  Exercise: is this ethical of me?    Chapter 27. Go Forth and Do Data Science  And now, once again, I bid my hideous progeny go forth and prosper.  —Mary Shelley  Where do you go from here? Assuming I haven’t scared you off of data science, there are a number of things you should learn next.  IPython I mentioned IPython earlier in the book. It provides a shell with far more functionality than the standard Python shell, and it adds “magic functions” that allow you to  among other things  easily copy and paste code  which is normally complicated by the combination of blank lines and whitespace formatting  and run scripts from within the shell. Mastering IPython will make your life far easier.  Even learning just a little bit of IPython will make your life a lot easier.   NOTE  In the first edition, I also recommended that you learn about the IPython  now Jupyter  Notebook, a computational environment that allows you to combine text, live Python code, and visualizations. I’ve since become a notebook skeptic, as I find that they confuse beginners and encourage bad coding practices.  I have many other reasons too.  You will surely receive plenty of encouragement to use them from people who aren’t me, so just remember that I’m the dissenting voice.  Mathematics   Throughout this book, we dabbled in linear algebra  Chapter 4 , statistics  Chapter 5 , probability  Chapter 6 , and various aspects of machine learning. To be a good data scientist, you should know much more about these topics, and I encourage you to give each of them a more in-depth study, using the textbooks recommended at the ends of the chapters, your own preferred textbooks, online courses, or even real-life courses.  Not from Scratch Implementing things “from scratch” is great for understanding how they work. But it’s generally not great for performance  unless you’re implementing them specifically with performance in mind , ease of use, rapid prototyping, or error handling. In practice, you’ll want to use well-designed libraries that solidly implement the fundamentals. My original proposal for this book involved a second “now let’s learn the libraries” half that O’Reilly, thankfully, vetoed. Since the first edition came out, Jake VanderPlas has written the Python Data Science Handbook  O’Reilly , which is a good introduction to the relevant libraries and would be a good book for you to read next.  NumPy NumPy  for “Numeric Python”  provides facilities for doing “real” scientific computing. It features arrays that perform better than our l vectors, matrices that perform better than our l lots of numeric functions for working with them. NumPy is a building block for many other libraries, which makes it especially valuable to know.  t-of-l  t- t-matrices, and  pandas  i s i s i s  pandas provides additional data structures for working with datasets in Python. Its primary abstraction is the D e, which is conceptually e class we constructed in Chapter 24, similar to the NotQuiteABase T but with much more functionality and better performance. If you’re going to use Python to munge, slice, group, and manipulate datasets, pandas is an invaluable tool.  scikit-learn scikit-learn is probably the most popular library for doing machine learning in Python. It contains all the models we’ve implemented and many more that we haven’t. On a real problem, you’d never build a decision tree from scratch; you’d let scikit-learn do the heavy lifting. On a real problem, you’d never write an optimization algorithm by hand; you’d count on scikit-learn to already be using a really good one. Its documentation contains many, many examples of what it can do  and, more generally, what machine learning can do .  Visualization The matplotlib charts we’ve been creating have been clean and functional but not particularly stylish  and not at all interactive . If you want to get deeper into data visualization, you have several options. The first is to further explore matplotlib, only a handful of whose features we’ve actually covered. Its website contains many examples of its functionality and a gallery of some of the more interesting ones. If you want to create static visualizations  say, for printing in a book , this is probably your best next step. You should also check out seaborn, which is a library that  among other things  makes matplotlib more attractive. If you’d like to create interactive visualizations that you can share on the web, the obvious choice is probably D3.js, a JavaScript library for creating “data-driven documents”  those are the three Ds . Even if you don’t know  a t a F r a m a b l  much JavaScript, it’s often possible to crib examples from the D3 gallery and tweak them to work with your data.  Good data scientists copy from the D3 gallery; great data scientists steal from the D3 gallery.  Even if you have no interest in D3, just browsing the gallery is itself a pretty incredible education in data visualization. Bokeh is a project that brings D3-style functionality into Python.  R Although you can totally get away with not learning R, a lot of data scientists and data science projects use it, so it’s worth getting at least familiar with it. In part, this is so that you can understand people’s R-based blog posts and examples and code; in part, this is to help you better appreciate the  comparatively  clean elegance of Python; and in part, this is to help you be a more informed participant in the never-ending “R versus Python” flamewars.  Deep Learning You can be a data scientist without doing deep learning, but you can’t be a trendy data scientist without doing deep learning. The two most popular deep learning frameworks for Python are TensorFlow  created by Google  and PyTorch  created by Facebook . The internet is full of tutorials for them that range from wonderful to awful. TensorFlow is older and more widely used, but PyTorch is  in my opinion  much easier to use and  in particular  much more beginner-friendly. I prefer  and recommend  PyTorch, but—as they say—no one ever got fired for choosing TensorFlow.  Find Data   If you’re doing data science as part of your job, you’ll most likely get the data as part of your job  although not necessarily . What if you’re doing data science for fun? Data is everywhere, but here are some starting points:  Data.gov is the government’s open data portal. If you want data on anything that has to do with the government  which seems to be most things these days , it’s a good place to start. Reddit has a couple of forums, r datasets and r data, that are places to both ask for and discover data. Amazon.com maintains a collection of public datasets that they’d like you to analyze using their products  but that you can analyze with whatever products you want . Robb Seaton has a quirky list of curated datasets on his blog. Kaggle is a site that holds data science competitions. I never managed to get into it  I don’t have much of a competitive nature when it comes to data science , but you might. They host a lot of datasets. Google has a newish Dataset Search that lets you  you guessed it  search for datasets.  Do Data Science Looking through data catalogs is fine, but the best projects  and products  are ones that tickle some sort of itch. Here are a few that I’ve done.  Hacker News Hacker News is a news aggregation and discussion site for technology- related news. It collects lots and lots of articles, many of which aren’t interesting to me.   Accordingly, several years ago, I set out to build a Hacker News story classifier to predict whether I would or would not be interested in any given story. This did not go over so well with the users of Hacker News, who resented the idea that someone might not be interested in every story on the site. This involved hand-labeling a lot of stories  in order to have a training set , choosing story features  for example, words in the title, and domains of the links , and training a Naive Bayes classifier not unlike our spam filter. For reasons now lost to history, I built it in Ruby. Learn from my mistakes.  Fire Trucks For many years I lived on a major street in downtown Seattle, halfway between a fire station and most of the city’s fires  or so it seemed . Accordingly, I developed a recreational interest in the Seattle Fire Department. Luckily  from a data perspective , they maintain a Real-Time 911 site that lists every fire alarm along with the fire trucks involved. And so, to indulge my interest, I scraped many years’ worth of fire alarm data and performed a social network analysis of the fire trucks. Among other things, this required me to invent a fire-truck-specific notion of centrality, which I called TruckRank.  T-Shirts I have a young daughter, and an incessant source of frustration to me throughout her childhood has been that most “girls’ shirts” are quite boring, while many “boys’ shirts” are a lot of fun. In particular, it felt clear to me that there was a distinct difference between the shirts marketed to toddler boys and toddler girls. And so I asked myself if I could train a model to recognize these differences. Spoiler: I could.   This involved downloading the images of hundreds of shirts, shrinking them all to the same size, turning them into vectors of pixel colors, and using logistic regression to build a classifier. One approach looked simply at which colors were present in each shirt; a second found the first 10 principal components of the shirt image vectors and classified each shirt using its projections into the 10-dimensional space spanned by the “eigenshirts”  Figure 27-1 .  Figure 27-1. Eigenshirts corresponding to the first principal component  Tweets on a Globe For many years I’d wanted to build a “spinning globe” visualization. During the 2016 election, I built a small web app that listened for geotagged tweets matching some search  I used “Trump,” as it appeared in lots of tweets at that time , displayed them, and spun a globe to their location as they appeared. This was entirely a JavaScript data project, so maybe learn some JavaScript.  And You? What interests you? What questions keep you up at night? Look for a dataset  or scrape some websites  and do some data science. Let me know what you find! Email me at joelgrus@gmail.com or find me on Twitter at @joelgrus.   Index  A B tests, Example: Running an A B Test  accuracy, Correctness  activation functions, Other Activation Functions  AllenNLP, For Further Exploration  Altair library, For Further Exploration  Anaconda Python distribution, Getting Python  args, args and kwargs  argument unpacking, zip and Argument Unpacking  arithmetic operations, Vectors  arrays, Lists  artificial neural networks, Neural Networks  assert statements, Automated Testing and assert  automated testing, Automated Testing and assert  average  mean , Central Tendencies  A  B  backpropagation, Backpropagation  bagging, Random Forests  bar charts, Bar Charts-Line Charts   betweenness centrality, Betweenness Centrality-Betweenness Centrality  batch gradient descent, Minibatch and Stochastic Gradient Descent  Bayesian inference, Bayesian Inference  Bayes’s theorem, Bayes’s Theorem  Beautiful Soup library, HTML and the Parsing Thereof  bell-shaped curve, The Normal Distribution  BernoulliNB model, For Further Exploration  Beta distributions, Bayesian Inference  bias input, Feed-Forward Neural Networks  bias-variance tradeoff, The Bias-Variance Tradeoff  biased data, Biased Data  bigram models, n-Gram Language Models  binary judgments, Correctness  Binomial distributions, Bayesian Inference  binomial random variables, The Central Limit Theorem  Bokeh library, For Further Exploration, Visualization  Booleans, Truthiness  bootstrap aggregating, Random Forests  bootstrapping, Digression: The Bootstrap  bottom-up hierarchical clustering, Bottom-Up Hierarchical Clustering- Bottom-Up Hierarchical Clustering  breadth-first search, Betweenness Centrality   betweenness, Betweenness Centrality-Betweenness Centrality  business models, Modeling  Buzzword clouds, Word Clouds  C  centrality  causation, Correlation and Causation  central limit theorem, The Central Limit Theorem  central tendencies, Central Tendencies  closeness, Betweenness Centrality  degree, Finding Key Connectors  eigenvector, Eigenvector Centrality-Centrality  other types of, For Further Exploration  charts  bar charts, Bar Charts-Line Charts  line charts, matplotlib, Line Charts  scatterplots, Scatterplots-For Further Exploration  classes, Object-Oriented Programming  classification trees, What Is a Decision Tree?  cleaning data, Cleaning and Munging  closeness centrality, Betweenness Centrality  clustering  character-level RNNs, Example: Using a Character-Level RNN   bottom-up hierarchical clustering, Bottom-Up Hierarchical Clustering- Bottom-Up Hierarchical Clustering  choosing k, Choosing k  clustering colors example, Example: Clustering Colors  concept of, The Idea  meetups example, Example: Meetups  model for, The Model  tools for, For Further Exploration  unsupervised learning using, Clustering  code examples, obtaining and using, Using Code Examples, Data Science  coefficient of determination, The Model, Goodness of Fit  comma-separated files, Delimited Files  conda package manager, Virtual Environments  conditional probability, Conditional Probability  confidence intervals, Confidence Intervals  confounding variables, Simpson’s Paradox  confusion matrix, Correctness  continuity corrections, p-Values  continuous bag-of-words  CBOW , Word Vectors  continuous distributions, Continuous Distributions  control flow, Control Flow  convolutional layers, Example: MNIST   correctness, Correctness  correlation, Correlation-Correlation and Causation  correlation matrix, Many Dimensions  cosine similarity, Word Vectors  Counter instances, Counters  Coursera, For Further Exploration, For Further Exploration  covariance, Correlation  CREATE TABLE statement, CREATE TABLE and INSERT  cross-entropy loss function, Softmaxes and Cross-Entropy  csv module  Python , Delimited Files  cumulative distribution function  CDF , Continuous Distributions  curse of dimensionality, The Curse of Dimensionality  D3-style visualizations, For Further Exploration  D3.js library, For Further Exploration, Visualization  D  data  collecting  piping data with stdin and stdout, stdin and stdout  reading files, Reading Files  sources for, Find Data  tools for, For Further Exploration  using Twitter APIs, Example: Using the Twitter APIs-Using Twython   web scraping, Scraping the Web  describing single sets of dispersion, Dispersion  histograms, Describing a Single Set of Data  largest and smallest values, Describing a Single Set of Data  mean  average , Central Tendencies  median, Central Tendencies  mode, Central Tendencies  number of data points, Describing a Single Set of Data  quantile, Central Tendencies  specific positions of values, Describing a Single Set of Data  standard deviation, Dispersion  variance, Dispersion  working with  cleaning and munging, Cleaning and Munging  dataclasses, Dataclasses  dimensionality reduction, Dimensionality Reduction  exploring your data, Exploring Your Data-Many Dimensions  generating progress bars, An Aside: tqdm  manipulating data, Manipulating Data  rescaling, Rescaling  resources for learning about, For Further Exploration   tools for, For Further Exploration  using namedtuple class, Using NamedTuples  data ethics  biased data, Biased Data  censorship, Recommendations  definition of term, No, Really, What Is Data Ethics?  examples of data misuse, What Is Data Ethics?  government restrictions, Collaboration  issues resulting from bad products, Building Bad Data Products  model selection, Interpretability  offensive predictions, Building Bad Data Products  privacy, Data Protection  resources for learning about, For Further Exploration  tradeoffs between accuracy and fairness, Trading Off Accuracy and Fairness  wide-reaching effects of data science, Should I Care About Data Ethics?  data mining, What Is Machine Learning?  data science  applications of  extracting topics from data, Topics of Interest  Hacker News, Hacker News  network analysis, Finding Key Connectors-Finding Key Connectors, Fire Trucks   predictive models, Salaries and Experience-Paid Accounts  real-life examples of, What Is Data Science?  recommender systems, Data Scientists You May Know-Data Scientists You May Know  spinning globe visualization, Tweets on a Globe  T-shirt analysis, T-Shirts  ascendance of data, The Ascendance of Data  benefits of Python for, From Scratch  definition of term, What Is Data Science?  learning “from scratch”, From Scratch, Not from Scratch  data visualization  bar charts, Bar Charts-Line Charts  line charts, Line Charts  matplotlib library, matplotlib  resources for learning about, Visualization  scatterplots, Scatterplots-For Further Exploration  tools for, For Further Exploration, Visualization  uses for, Visualizing Data  Data.gov, Find Data  databases and SQL  DELETE, DELETE  CREATE TABLE and INSERT, CREATE TABLE and INSERT   query optimization, Query Optimization  resources for learning about, For Further Exploration  GROUP BY, GROUP BY  indexes, Indexes  JOIN, JOIN  NoSQL databases, NoSQL  ORDER BY, ORDER BY  SELECT, SELECT  subqueries, Subqueries  tools, For Further Exploration  UPDATE, UPDATE  dataclasses, Dataclasses  Dataset Search, Find Data  de-meaning data, Dimensionality Reduction  decision boundary, Support Vector Machines  decision nodes, Creating a Decision Tree  decision trees  benefits and drawbacks of, What Is a Decision Tree?  creating, Creating a Decision Tree  decision paths in, What Is a Decision Tree?  entropy and, Entropy  entropy of partitions, The Entropy of a Partition   gradient boosted decision trees, For Further Exploration  implementing, Putting It All Together  random forests technique, Random Forests  resources for learning about, For Further Exploration  tools for, For Further Exploration  types of, What Is a Decision Tree?  deep learning  definition of term, Deep Learning  dropout, Dropout  Fizz Buzz example, Example: FizzBuzz Revisited  Layers abstraction, The Layer Abstraction  linear layer, The Linear Layer  loss and optimization, Loss and Optimization  MNIST example, Example: MNIST-Example: MNIST  neural networks as sequences of layers, Neural Networks as a Sequence of Layers  other activation functions, Other Activation Functions  resources for learning about, For Further Exploration  saving and loading models, Saving and Loading Models  softmaxes and cross-entropy, Softmaxes and Cross-Entropy  tensors, The Tensor  tools for, For Further Exploration, Deep Learning   XOR example, Example: XOR Revisited  defaultdict, defaultdict  degree centrality, Finding Key Connectors  DELETE statement, DELETE  delimited files, Delimited Files  dependence, Dependence and Independence  dictionaries, Dictionaries  dimensionality reduction, Dimensionality Reduction  directed edges, Network Analysis  directed graphs, Directed Graphs and PageRank  discrete distributions, Continuous Distributions  dispersion, Dispersion  distributional similarity, Biased Data  domain expertise, Feature Extraction and Selection  dot product, Vectors  Dropout layer, Dropout  dunder methods, Object-Oriented Programming  dynamically typed languages, Type Annotations  E  edges, Network Analysis  eigenvector centrality centrality, Centrality   matrix multiplication, Matrix Multiplication  elements  creating sets of, Sets  finding in collections, Sets  embedding layer, Word Vectors  ensemble learning, Random Forests  entropy, Entropy  enumerate function, Iterables and Generators  equivalence classes, Using Our Model  ethics, No, Really, What Is Data Ethics?   see also data ethics   exceptions, Exceptions  F  f-strings, Strings  F1 scores, Correctness  false negatives false positives, Example: Flipping a Coin, Correctness  feature extraction and selection, Feature Extraction and Selection  features, Feed-Forward Neural Networks  feed-forward neural networks, Feed-Forward Neural Networks  files  basics of text files, The Basics of Text Files  delimited files, Delimited Files   serialization of text files, JSON and XML  first-class functions, Functions  Fizz Buzz example, Example: Fizz Buzz, Example: FizzBuzz Revisited  floating-point numbers, A More Sophisticated Spam Filter  functional programming, Functional Programming  functions, Functions  G  generators, Iterables and Generators  gensim, For Further Exploration  Gephi, For Further Exploration  get method, Dictionaries  Gibbs sampling, An Aside: Gibbs Sampling  gradient boosted decision trees, For Further Exploration  gradient descent  choosing step size, Choosing the Right Step Size  concept of, The Idea Behind Gradient Descent  estimating the gradient, Estimating the Gradient  minibatch and stochastic gradient descent, Minibatch and Stochastic Gradient Descent  Optimizer abstraction for, Loss and Optimization  resources for learning, For Further Exploration  simple linear regression using, Using Gradient Descent   using the gradient, Using the Gradient  using to fit models, Using Gradient Descent to Fit Models  grammars, Grammars  GROUP BY statement, GROUP BY  GRU  gated recurrent unit , Recurrent Neural Networks  Hacker News, Hacker News  harmonic mean, Correctness  hierarchical clustering, Bottom-Up Hierarchical Clustering-Bottom-Up Hierarchical Clustering  HTML parsing, HTML and the Parsing Thereof  hyperplanes, Support Vector Machines  hypothesis and inference  A B tests, Example: Running an A B Test  Bayesian inference, Bayesian Inference  coin flip example, Example: Flipping a Coin  confidence intervals, Confidence Intervals  p-hacking, p-Hacking  p-values, p-Values  resources for learning, For Further Exploration  statistical hypothesis testing, Statistical Hypothesis Testing  H  I   ID3 algorithm, Creating a Decision Tree  identity matrix, Matrices  if statements, Control Flow  if-then-else statements, Control Flow  indentation, tabs versus spaces, Whitespace Formatting  independence, Dependence and Independence  inference  see hypothesis and inference   INSERT statement, CREATE TABLE and INSERT  interactive visualizations, Visualization  IPython shell, Virtual Environments, For Further Exploration, IPython  Iris dataset example, Example: The Iris Dataset  item-based collaborative filtering, Item-Based Collaborative Filtering  iterables, Iterables and Generators  J  K  JavaScript Object Notation  JSON , JSON and XML  JOIN statement, JOIN  Jupyter notebook, IPython  k-means clustering, The Model  k-nearest neighbors  curse of dimensionality, The Curse of Dimensionality   key connectors, finding, Finding Key Connectors-Finding Key Connectors, Betweenness Centrality  Iris dataset example, Example: The Iris Dataset  model for, The Model  tools for, For Further Exploration  uses for, k-Nearest Neighbors  Kaggle, Find Data  kernel trick, Support Vector Machines  key value pairs, Dictionaries  kwargs, args and kwargs  L  language models, n-Gram Language Models  Latent Dirichlet Analysis  LDA , Topic Modeling  Layers abstraction  basics of, The Layer Abstraction  convolutional layers, Example: MNIST  Dropout layer, Dropout  linear layer, The Linear Layer  layers of neurons, Feed-Forward Neural Networks  least squares solution, The Model, Further Assumptions of the Least Squares Model  LIBSVM, For Further Investigation   linear independence, Further Assumptions of the Least Squares Model  line charts, matplotlib, Line Charts  linear algebra  matrices, Matrices-Matrices  resources for learning, For Further Exploration  tools for, For Further Exploration  vectors, Vectors-Vectors  linear layer, The Linear Layer  linear_model module, For Further Exploration  lists  appending items to, Lists  checking list membership, Lists  concatenating, Lists  getting nth element of, Lists  slicing, Lists  sorting, Sorting  transforming, List Comprehensions  unpacking, Lists  using as vectors, Vectors  versus arrays, Lists  logistic regression  goodness of fit, Goodness of Fit   logistic function, The Logistic Function  model application, Applying the Model  problem example, The Problem  support vector machines, Support Vector Machines  tools for, For Further Investigation  loss functions, Using Gradient Descent to Fit Models, Loss and Optimization, Softmaxes and Cross-Entropy  LSTM  long short-term memory , Recurrent Neural Networks  M  machine learning  bias-variance tradeoff, The Bias-Variance Tradeoff  correctness, Correctness  definition of term, What Is Machine Learning?  feature extraction and selection, Feature Extraction and Selection  modeling, Modeling  overfitting and underfitting, Overfitting and Underfitting  resources for learning about, For Further Exploration  magnitude, computing, Vectors  manipulating data, Manipulating Data  MapReduce  analyzing status updates example, Example: Analyzing Status Updates  basic algorithm, MapReduce   benefits of, Why MapReduce?  generalizing map_reduce function, MapReduce More Generally  matrix multiplication example, Example: Matrix Multiplication  uses for, MapReduce  word count example, Example: Word Count  mathematics  linear algebra, Linear Algebra-For Further Exploration  probability, Probability-For Further Exploration  statistics, Statistics-For Further Exploration  matplotlib library, matplotlib, For Further Exploration  matrices, Matrices-Matrices  matrix decomposition functions, For Further Exploration  matrix factorization, Matrix Factorization-Matrix Factorization  matrix multiplication, Matrix Multiplication, Example: Matrix Multiplication  maximum likelihood estimation, Maximum Likelihood Estimation  mean  average , Central Tendencies  mean squared error, Using Gradient Descent to Fit Models  median, Central Tendencies  meetups example  clustering , Example: Meetups  member functions, Object-Oriented Programming  methods   dunder methods, Object-Oriented Programming  private methods, Object-Oriented Programming  minibatch gradient descent, Minibatch and Stochastic Gradient Descent  MNIST dataset example, Example: MNIST-Example: MNIST  mode, Central Tendencies  modeling, Modeling, Topic Modeling-Topic Modeling  models of language, n-Gram Language Models  modules, Modules  momentum, Loss and Optimization  MongoDB, For Further Exploration  most_common method, Counters  Movie-Lens 100k dataset, Matrix Factorization  multi-dimensional datasets, Many Dimensions  multiline strings, Strings  multiple regression  assumptions of least square model, Further Assumptions of the Least Squares Model  bootstrapping new datasets, Digression: The Bootstrap  goodness of fit, Goodness of Fit  model fitting, Fitting the Model  model for, The Model  model interpretation, Interpreting the Model   regularization, Regularization  resources for learning about, For Further Exploration  standard errors of regression coefficients, Standard Errors of Regression Coefficients  tools for, For Further Exploration  munging data, Cleaning and Munging  MySQL, For Further Exploration  N  Naive Bayes  model testing, Testing Our Model  model use, Using Our Model  resources for learning about, For Further Exploration  spam filter examples, Naive Bayes-A More Sophisticated Spam Filter  spam filter implementation, Implementation  tools for, For Further Exploration  namedtuple class, Using NamedTuples  natural language processing  NLP   character-level RNN example, Example: Using a Character-Level RNN  definition of term, Natural Language Processing  Gibbs sampling, An Aside: Gibbs Sampling  grammars, Grammars  n-gram language models, n-Gram Language Models   recurrent neural networks  RNNs , Recurrent Neural Networks  resources for learning about, For Further Exploration  tools for, For Further Exploration  topic modeling, Topic Modeling-Topic Modeling  word clouds, Word Clouds  word vectors, Word Vectors-Word Vectors  nearest neighbors classification, k-Nearest Neighbors  Netflix Prize, For Further Exploration  network analysis  betweenness centrality, Betweenness Centrality-Betweenness Centrality  directed graphs and PageRank, Directed Graphs and PageRank  eigenvector centrality, Eigenvector Centrality-Centrality  finding key connectors example, Finding Key Connectors-Finding Key Connectors  nodes and edges in, Network Analysis  resources for learning about, For Further Exploration  tools for, For Further Exploration  Truck-Rank example, Fire Trucks  NetworkX, For Further Exploration  neural networks  as sequences of layers, Neural Networks as a Sequence of Layers  backpropagation, Backpropagation   components of, Neural Networks  feed-forward neural networks, Feed-Forward Neural Networks  Fizz Buzz example, Example: Fizz Buzz  perceptrons, Perceptrons  NLTK, For Further Exploration  nodes, Network Analysis  None value, Truthiness  nonrepresentative data, Biased Data  normal distribution, The Normal Distribution  NoSQL databases, NoSQL  null hypothesis, Statistical Hypothesis Testing  null values, Truthiness  NumPy library, Vectors, For Further Exploration, NumPy  object-oriented programming, Object-Oriented Programming  one-dimensional datasets, Exploring One-Dimensional Data  one-hot-encoding, Word Vectors  Optimizer abstraction, Loss and Optimization  ORDER BY statement, ORDER BY  overfitting and underfitting, Overfitting and Underfitting  O  P   p-hacking, p-Hacking  p-values, p-Values  PageRank, Directed Graphs and PageRank  pandas, For Further Exploration, Delimited Files, For Further Exploration, For Further Exploration, pandas  parameterized models, What Is Machine Learning?  partial derivatives, Estimating the Gradient  perceptrons, Perceptrons  pip package manager, Virtual Environments  popularity-based recommender systems, Recommending What’s Popular  Porter Stemmer, Using Our Model  posterior distributions, Bayesian Inference  PostgreSQL, For Further Exploration  precision, Correctness  predictive models  decision trees, Decision Trees-For Further Exploration  definition of modeling, Modeling  guarding against potentially offensive predictions, Building Bad Data Products  k-nearest neighbors, k-Nearest Neighbors-For Further Exploration  logistic regression, Logistic Regression-Support Vector Machines  machine learning and, What Is Machine Learning?  multiple regression, Multiple Regression-For Further Exploration   neural networks, Neural Networks-For Further Exploration  paid accounts example, Paid Accounts  salaries and experience example, Salaries and Experience-Salaries and Experience  simple linear regression, Simple Linear Regression-For Further Exploration  tradeoffs between accuracy and fairness, Trading Off Accuracy and Fairness  types of models, What Is Machine Learning?  principal component analysis  PCA , Dimensionality Reduction  prior distributions, Bayesian Inference  private methods, Object-Oriented Programming  probability  Bayes’s theorem, Bayes’s Theorem  central limit theorem, The Central Limit Theorem  conditional probability, Conditional Probability  continuous distributions, Continuous Distributions  definition of term, Probability  dependence and independence, Dependence and Independence  normal distribution, The Normal Distribution  random variables, Random Variables  resources for learning, For Further Exploration  tools for, For Further Exploration   probability density function  PDF , Continuous Distributions  progress bars, generating, An Aside: tqdm  pseudocounts, A More Sophisticated Spam Filter  Python  args, args and kwargs  argument unpacking, zip and Argument Unpacking  automated testing and assert statements, Automated Testing and assert  benefits of for data science, From Scratch  control flow, Control Flow  Counter instances, Counters  csv module, Delimited Files  default dict, defaultdict  dictionaries, Dictionaries  downloading and installing, Getting Python  exceptions, Exceptions  functional programming, Functional Programming  functions, Functions  iterables and generators, Iterables and Generators  json module, JSON and XML  kwargs, args and kwargs  list comprehensions, List Comprehensions  lists, Lists   modules, Modules  object-oriented programming, Object-Oriented Programming  randomness, Randomness  regular expressions, Regular Expressions  statsmodels module, For Further Exploration  sets, Sets  sorting, Sorting  strings, Strings  truthiness, Truthiness  tuples, Tuples  tutorials and documentation, For Further Exploration  type annotations, Type Annotations-How to Write Type Annotations  versions, Getting Python  virtual environments, Virtual Environments  whitespace formatting, Whitespace Formatting  Zen of Python, The Zen of Python  zip function, zip and Argument Unpacking  PyTorch, For Further Exploration, Deep Learning  quantile, Central Tendencies  Q  R   R, R  R-squared, The Model, Goodness of Fit  random forests technique, Random Forests  random variables, Random Variables  randomness, Randomness  raw strings, Strings  recall, Correctness  recommender systems  “Data Scientists You May Know” suggester, Data Scientists You May Know-Data Scientists You May Know  dataset of users_interests, Recommender Systems  item-based collaborative filtering, Item-Based Collaborative Filtering  manual curation, Manual Curation  matrix factorization, Matrix Factorization-Matrix Factorization  popularity-based, Recommending What’s Popular  tools for, For Further Exploration  user-based collaborative filtering, User-Based Collaborative Filtering  recurrent neural networks  RNNs , Recurrent Neural Networks  regression coefficients, Standard Errors of Regression Coefficients  regression trees, What Is a Decision Tree?  regular expressions, Regular Expressions  regularization, Regularization   reinforcement models, What Is Machine Learning?  relational databases, Databases and SQL  requests library, HTML and the Parsing Thereof  rescaling data, Rescaling  robots.txt files, Example: Keeping Tabs on Congress  S  scalar multiplication, Vectors  scale, Rescaling  scatterplot matrix, Many Dimensions  scatterplots, Scatterplots-For Further Exploration  scikit-learn, For Further Exploration, For Further Exploration, For Further Exploration, For Further Exploration, For Further Investigation, For Further Exploration, For Further Exploration, scikit-learn  SciPy, For Further Exploration, For Further Exploration  scipy.stats, For Further Exploration  Scrapy, For Further Exploration  seaborn, For Further Exploration, Visualization  SELECT statement, SELECT  semisupervised models, What Is Machine Learning?  serialization, JSON and XML  sets, Sets  sigmoid function, Feed-Forward Neural Networks, Other Activation Functions   significance, Example: Flipping a Coin  simple linear regression  maximum likelihood estimation, Maximum Likelihood Estimation  model for, The Model  using gradient descent, Using Gradient Descent  Simpson's paradox, Simpson’s Paradox  skip-gram model, Word Vectors  slicing lists, Lists  softmax function, Softmaxes and Cross-Entropy  sorting, Sorting  spaCy, For Further Exploration  spam filter example, Feature Extraction and Selection, Naive Bayes-Using Our Model  SpamAssassin public corpus, Using Our Model  SQLite, For Further Exploration  standard deviation, Dispersion  standard errors, Standard Errors of Regression Coefficients  standard normal distribution, The Normal Distribution  statically typed languages, Type Annotations  statistical models of language, n-Gram Language Models  statistics  correlation, Correlation-Correlation  causation and, Correlation and Causation   correlational caveats, Some Other Correlational Caveats  Simpson's paradox, Simpson’s Paradox  describing single sets of data, Describing a Single Set of Data-Dispersion  resources for learning, For Further Exploration  tools for, For Further Exploration  StatsModels, For Further Exploration  statsmodels, For Further Exploration  status updates, analyzing, Example: Analyzing Status Updates  stemmer functions, Using Our Model  stochastic gradient descent, Minibatch and Stochastic Gradient Descent  stride, Lists  strings, Strings, JSON and XML  Structured Query Language  SQL , Databases and SQL  see also databases and SQL   Student’s t-distribution, Standard Errors of Regression Coefficients  Sum layer, Recurrent Neural Networks  sum of squares, computing, Vectors  supervised models, What Is Machine Learning?  support vector machines, Support Vector Machines  Surprise, For Further Exploration  sys.stdin, stdin and stdout  sys.stdout, stdin and stdout   tab-separated files, Delimited Files  tanh function, Other Activation Functions  TensorFlow, Deep Learning  tensors, The Tensor  ternerary operators, Control Flow  test sets, Overfitting and Underfitting  text files, The Basics of Text Files, JSON and XML  topic modeling, Topic Modeling-Topic Modeling  tqdm library, An Aside: tqdm  training sets, Overfitting and Underfitting  trigrams, n-Gram Language Models  true positives true negatives, Correctness  truthiness, Truthiness  tuples, Tuples, Using NamedTuples  Twitter APIs, Example: Using the Twitter APIs-Using Twython  two-dimensional datasets, Two Dimensions  Twython library, Example: Using the Twitter APIs-Using Twython  type 1 type 2 errors, Example: Flipping a Coin, Correctness  type annotations, Type Annotations-How to Write Type Annotations  T  U   unauthenticated APIs, Using an Unauthenticated API  underfitting and overfitting, Overfitting and Underfitting  underflow, A More Sophisticated Spam Filter  undirected edges, Network Analysis  uniform distributions, Continuous Distributions  unit tests, Testing Our Model  unpacking lists, Lists  unsupervised learning, Clustering  unsupervised models, What Is Machine Learning?  UPDATE statement, UPDATE  user-based collaborative filtering, User-Based Collaborative Filtering  V  variables  validation sets, Overfitting and Underfitting  binomial random variables, The Central Limit Theorem  confounding variables, Simpson’s Paradox  random variables, Random Variables  variance, Dispersion, The Bias-Variance Tradeoff  vectors, Vectors-Vectors  virtual environments, Virtual Environments  W   weak learners, Random Forests  web scraping  HTML parsing, HTML and the Parsing Thereof  press release data example, Example: Keeping Tabs on Congress  using APIs, Using APIs  weight tensors, randomly generating, The Linear Layer  while loops, Control Flow  whitespace formatting, Whitespace Formatting  word clouds, Word Clouds  word counting, Counters, Example: Word Count  word vectors, Word Vectors-Word Vectors  X  Z  Xavier initialization, The Linear Layer  XGBoost, For Further Exploration  XOR example, Example: XOR Revisited  Zen of Python, The Zen of Python  zip function, zip and Argument Unpacking   About the Author Joel Grus is a research engineer at the Allen Institute for Artificial Intelligence. Previously he worked as a software engineer at Google and a data scientist at several startups. He lives in Seattle, where he regularly attends data science happy hours. He blogs infrequently at joelgrus.com and tweets all day long at @joelgrus.   Colophon The animal on the cover of Data Science from Scratch, Second Edition, is a rock ptarmigan  Lagopus muta . This hardy, chicken-sized member of the grouse family inhabits the tundra environments of the northern hemisphere, living in the arctic and subarctic regions of Eurasia and North America. A ground feeder, it forages across these grasslands on its well-feathered feet, eating birch and willow buds, as well as seeds, flowers, leaves, and berries. Rock ptarmigan chicks also eat insects. Rock ptarmigan are best known for the striking annual changes in their cryptic camouflage, having evolved to molt and regrow white and brownish-colored feathers a few times over the course of a year to best match the changing seasonal colors of their environment. In winter they have white feathers; in spring and fall, as snow cover mixes with open grassland, their feathers mix white and brown; and in summer, their patterned brown feathers match the varied coloring of the tundra. With this camouflage female ptarmigan can near-invisibly incubate their eggs, which are laid in nests on the ground. Mature male rock ptarmigan also have a fringed, red comb structure over their eyes. During breeding season this is used for courtship display as well as signaling between contending males  studies have shown a correlation between comb size and male testosterone levels . Ptarmigan populations are currently declining, though in their range they remain common  albeit difficult to spot . Ptarmigan have many predators, including arctic foxes, gyrfalcons, gulls, and jaegers. Also, in time, climate change may make their seasonal color changes a liability. Many of the animals on O’Reilly covers are endangered; all of them are important to the world. The cover image is from Cassell’s Book of Birds  1875 , by Thomas Rymer Jones. The cover fonts are Gilroy and Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono.
